{"kind": "Listing", "data": {"after": null, "dist": 23, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_a49okn69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "It's not always Old Man Jenkins...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_yfuknq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "ups": 345, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 345, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/sA-bzbNjvxfBKpEkemfzgqu1wFBORFXjNpVkbfnQK1U.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666977339.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/zus7bi9wxkw91.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/zus7bi9wxkw91.jpg?auto=webp&amp;s=a2f15b3eb8aa51ec865d00b7f228a6414ae904f8", "width": 500, "height": 666}, "resolutions": [{"url": "https://preview.redd.it/zus7bi9wxkw91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7803063a5ad84d1992e00a9aaa99b63fdb8e3a5e", "width": 108, "height": 143}, {"url": "https://preview.redd.it/zus7bi9wxkw91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8765e3b7b67e3a96d582d8a57bf6be4c339aa3c7", "width": 216, "height": 287}, {"url": "https://preview.redd.it/zus7bi9wxkw91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c11c903e0e7983d6de4ba65479b556eba8629351", "width": 320, "height": 426}], "variants": {}, "id": "efmOVN_2bpQ1mBzOoi_K8tGqMy2_DskeZ2Z9k5-C-6g"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "yfuknq", "is_robot_indexable": true, "report_reasons": null, "author": "Top-Substance2185", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yfuknq/its_not_always_old_man_jenkins/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/zus7bi9wxkw91.jpg", "subreddit_subscribers": 78262, "created_utc": 1666977339.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A lot of posts and advice seem to focus on getting into DE after college, or transitioning into DE from an outside field. I want to tell my story as an inspiration that; there are other related roles and industries that are easier to break into; as I did. Analyst, Business Intelligence Engineer, and Analytics Engineer are all noble roles that make for easy pivots into Data Engineering with a great deal of overlap in skill set with Data Engineering. \n\nHere\u2019s my career progression, to show you how I made it from $40k to $287k in 7 years:\n\nSalary: $40k\n\nTitle: Account Executive\n\nOut of college, first job in software sales. The company I worked for and product I sold was in the Business Intelligence space, so I wanted to learn everything about it. I quickly became the most technical salesperson in my org, and tried to transition to a more technical solutions engineer role, but was blocked by management. So I left after 18 months. \n\nSalary: $80k\n\nTitle: Account Executive\n\nI worked selling a competing product to the former product, again learning everything I could. I began to learn SQL. After 14 months, I was laid off as the whole division went under. \n\nSalary: $100k\n\nTitle: Sr. Analyst\n\nI went to work in the healthcare space. Because of how technical I had become in my first sales job, I easily qualified for a tool-specific specialist at healthcare company. I was by far the most advanced on my team in this tool. My SQL was my biggest weakness, and I learned fast and studied countless hours outside of work. I left after 3 years due to lack of opportunity for advancement and political messes. \n\nSalary: $150k+$15k bonus \n\nTitle: Technical Lead\n\nI worked as a contractor for a FAANG company which is a great brand for my resume, but I was just a lowly contractor. I led complex projects writing SQL and a tiny bit of python. I studied python a lot. After 2 years, I tried to convert to FTE and it became obvious that it wouldn\u2019t happen. For the last 5 months, I spent about 5 hours a day studying algorithms and data structures and/or interviewing. After 2.5 years, I resigned. \n\nSalary: $175k+$25k bonus+$87k stock+$40k sign on bonus\n\nTitle: Data Engineer\n\nI received probably 5 offers between about 30 interviews. I got 1 FAANG offer ($225k, L5 BIE) 1 Top N offer ($287k DE) and 1 fortune 100 offer ($250k Sr DE). My advice here is that; I knew algorithms and data structures would be my weakness, so I focused there. With solid SQL, Algos, and behavioral, the rest I would need to figure out as I went. I began making lists of of topics that I was weak in as I went through more and more interviews, and I would get a few inches deep into each topic and/or make study sheets and flash cards as I went. A large element of this was luck. I focused on concepts, not tools. Normal forms, for example, are conceptual and tool-agnostic. There was also a massive luck element to this game. Some companies went for hard algos questions; I failed those interviews. Some interviewers wanted to talk about optimizing a pig job; I failed that interview. Was pig worth learning because one company asked about it? No. I stayed the course of conceptual topics. \n\nDespite my title as a Technical Lead as a contractor at FAANG, I interviewed for a Sr. role. Because the scope of some of the projects I worked on didn\u2019t impact multiple technical teams, I was down-leveled to entry-level Data Engineer. I declined the offer, and planned to accept another offer. A week later, the recruiter contacted me again and told me things changed on their end and they really wanted me. While they weren\u2019t able to up-level me, they were able to negotiate the salary to the upper-end of the range for entry-level Data Engineer.", "author_fullname": "t2_5v6av4nm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How I landed a $287k offer for entry-level Data Engineer at FAANG+", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfx3m1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 139, "total_awards_received": 2, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "620fb7b8-ac9d-11eb-a99a-0ed5d8300de1", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 139, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666983185.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666982498.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A lot of posts and advice seem to focus on getting into DE after college, or transitioning into DE from an outside field. I want to tell my story as an inspiration that; there are other related roles and industries that are easier to break into; as I did. Analyst, Business Intelligence Engineer, and Analytics Engineer are all noble roles that make for easy pivots into Data Engineering with a great deal of overlap in skill set with Data Engineering. &lt;/p&gt;\n\n&lt;p&gt;Here\u2019s my career progression, to show you how I made it from $40k to $287k in 7 years:&lt;/p&gt;\n\n&lt;p&gt;Salary: $40k&lt;/p&gt;\n\n&lt;p&gt;Title: Account Executive&lt;/p&gt;\n\n&lt;p&gt;Out of college, first job in software sales. The company I worked for and product I sold was in the Business Intelligence space, so I wanted to learn everything about it. I quickly became the most technical salesperson in my org, and tried to transition to a more technical solutions engineer role, but was blocked by management. So I left after 18 months. &lt;/p&gt;\n\n&lt;p&gt;Salary: $80k&lt;/p&gt;\n\n&lt;p&gt;Title: Account Executive&lt;/p&gt;\n\n&lt;p&gt;I worked selling a competing product to the former product, again learning everything I could. I began to learn SQL. After 14 months, I was laid off as the whole division went under. &lt;/p&gt;\n\n&lt;p&gt;Salary: $100k&lt;/p&gt;\n\n&lt;p&gt;Title: Sr. Analyst&lt;/p&gt;\n\n&lt;p&gt;I went to work in the healthcare space. Because of how technical I had become in my first sales job, I easily qualified for a tool-specific specialist at healthcare company. I was by far the most advanced on my team in this tool. My SQL was my biggest weakness, and I learned fast and studied countless hours outside of work. I left after 3 years due to lack of opportunity for advancement and political messes. &lt;/p&gt;\n\n&lt;p&gt;Salary: $150k+$15k bonus &lt;/p&gt;\n\n&lt;p&gt;Title: Technical Lead&lt;/p&gt;\n\n&lt;p&gt;I worked as a contractor for a FAANG company which is a great brand for my resume, but I was just a lowly contractor. I led complex projects writing SQL and a tiny bit of python. I studied python a lot. After 2 years, I tried to convert to FTE and it became obvious that it wouldn\u2019t happen. For the last 5 months, I spent about 5 hours a day studying algorithms and data structures and/or interviewing. After 2.5 years, I resigned. &lt;/p&gt;\n\n&lt;p&gt;Salary: $175k+$25k bonus+$87k stock+$40k sign on bonus&lt;/p&gt;\n\n&lt;p&gt;Title: Data Engineer&lt;/p&gt;\n\n&lt;p&gt;I received probably 5 offers between about 30 interviews. I got 1 FAANG offer ($225k, L5 BIE) 1 Top N offer ($287k DE) and 1 fortune 100 offer ($250k Sr DE). My advice here is that; I knew algorithms and data structures would be my weakness, so I focused there. With solid SQL, Algos, and behavioral, the rest I would need to figure out as I went. I began making lists of of topics that I was weak in as I went through more and more interviews, and I would get a few inches deep into each topic and/or make study sheets and flash cards as I went. A large element of this was luck. I focused on concepts, not tools. Normal forms, for example, are conceptual and tool-agnostic. There was also a massive luck element to this game. Some companies went for hard algos questions; I failed those interviews. Some interviewers wanted to talk about optimizing a pig job; I failed that interview. Was pig worth learning because one company asked about it? No. I stayed the course of conceptual topics. &lt;/p&gt;\n\n&lt;p&gt;Despite my title as a Technical Lead as a contractor at FAANG, I interviewed for a Sr. role. Because the scope of some of the projects I worked on didn\u2019t impact multiple technical teams, I was down-leveled to entry-level Data Engineer. I declined the offer, and planned to accept another offer. A week later, the recruiter contacted me again and told me things changed on their end and they really wanted me. While they weren\u2019t able to up-level me, they were able to negotiate the salary to the upper-end of the range for entry-level Data Engineer.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 150, "id": "award_f44611f1-b89e-46dc-97fe-892280b13b82", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Thank you stranger. Shows the award.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Helpful", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png"}, {"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 50, "id": "award_02d9ab2c-162e-4c01-8438-317a016ed3d9", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=16&amp;height=16&amp;auto=webp&amp;s=10034f3fdf8214c8377134bb60c5b832d4bbf588", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=32&amp;height=32&amp;auto=webp&amp;s=100f785bf261fa9452a5d82ee0ef0793369dbfa5", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=48&amp;height=48&amp;auto=webp&amp;s=b15d030fdfbbe4af4a5b34ab9dc90a174df40a23", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=64&amp;height=64&amp;auto=webp&amp;s=601c75be6ee30dc4b47a5c65d64dea9a185502a1", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=128&amp;height=128&amp;auto=webp&amp;s=540f36e65c0e2f1347fe32020e4a1565e3680437", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "I'm in this with you.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Take My Energy", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=16&amp;height=16&amp;auto=webp&amp;s=045db73f47a9513c44823d132b4c393ab9241b6a", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=32&amp;height=32&amp;auto=webp&amp;s=298a02e0edbb5b5e293087eeede63802cbe1d2c7", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=48&amp;height=48&amp;auto=webp&amp;s=7d06d606eb23dbcd6dbe39ee0e60588c5eb89065", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=64&amp;height=64&amp;auto=webp&amp;s=ecd9854b14104a36a210028c43420f0dababd96b", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=128&amp;height=128&amp;auto=webp&amp;s=0d5d7b92c1d66aff435f2ad32e6330ca2b971f6d", "width": 128, "height": 128}], "icon_format": "PNG", "icon_height": 2048, "penny_price": 0, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Tech Lead", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yfx3m1", "is_robot_indexable": true, "report_reasons": null, "author": "Flat_Shower", "discussion_type": null, "num_comments": 96, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/yfx3m1/how_i_landed_a_287k_offer_for_entrylevel_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yfx3m1/how_i_landed_a_287k_offer_for_entrylevel_data/", "subreddit_subscribers": 78262, "created_utc": 1666982498.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nSome of my posts about DE projects (for portfolio) were well received in this subreddit. (e.g. [this](https://www.reddit.com/r/dataengineering/comments/nto0nd/data_engineering_project_for_beginners_v2/) and [this](https://www.reddit.com/r/dataengineering/comments/om3wl5/data_engineering_project_with_a_live_dashboard/))\n\n   But many readers reached out with difficulties in setting up the infrastructure, CI/CD, automated testing, and database changes. With that in mind, I wrote this article [https://www.startdataengineering.com/post/data-engineering-projects-with-free-template/](https://www.startdataengineering.com/post/data-engineering-projects-with-free-template/) which sets up an Airflow + Postgres + Metabase stack and can also set up AWS infra to run them, with the following tools\n\n1. **`local development`**: [Docker](https://www.docker.com/) &amp; [Docker compose](https://docs.docker.com/compose/)\n2. **`DB Migrations`**: [yoyo-migrations](https://ollycope.com/software/yoyo/latest/)\n3. **`IAC`**: [Terraform](https://www.terraform.io/)\n4. **`CI/CD`**: [Github Actions](https://github.com/features/actions)\n5. **`Testing`**: [Pytest](https://docs.pytest.org/en/7.1.x/)\n6. **`Formatting`**: [isort](https://pycqa.github.io/isort/) &amp; [black](https://github.com/psf/black)\n7. **`Lint check`**: [flake8](https://github.com/pycqa/flake8)\n8. **`Type check`**: [mypy](http://mypy-lang.org/)\n\nI also updated the below projects from my website to use these tools for easier setup.\n\n1. [DE Project Batch edition](https://www.startdataengineering.com/post/data-engineering-project-for-beginners-batch-edition/) Airflow, Redshift, EMR, S3, Metabase\n2. [DE Project to impress Hiring Manager](https://www.startdataengineering.com/post/data-engineering-project-to-impress-hiring-managers/) Cron, Postgres, Metabase\n3. [End-to-end DE project](https://www.startdataengineering.com/post/data-engineering-project-e2e/) Dagster, dbt, Postgres, Metabase\n\nAn easy-to-use template helps people start building data engineering projects (for portfolio) &amp; providing a good understanding of commonly used development practices. Any feedback is appreciated. I hope this helps someone :) \n\nTl; DR: Data infra is complex; use this template for your portfolio data projects \n\nBlog: https://www.startdataengineering.com/post/data-engineering-projects-with-free-template/\nCode: https://github.com/josephmachado/data_engineering_project_template", "author_fullname": "t2_5srxspj1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering projects with template: Airflow, dbt, Docker, Terraform (IAC), Github actions (CI/CD) &amp; more", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ygieh8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 84, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 84, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667050081.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667046586.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;Some of my posts about DE projects (for portfolio) were well received in this subreddit. (e.g. &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/nto0nd/data_engineering_project_for_beginners_v2/\"&gt;this&lt;/a&gt; and &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/om3wl5/data_engineering_project_with_a_live_dashboard/\"&gt;this&lt;/a&gt;)&lt;/p&gt;\n\n&lt;p&gt;But many readers reached out with difficulties in setting up the infrastructure, CI/CD, automated testing, and database changes. With that in mind, I wrote this article &lt;a href=\"https://www.startdataengineering.com/post/data-engineering-projects-with-free-template/\"&gt;https://www.startdataengineering.com/post/data-engineering-projects-with-free-template/&lt;/a&gt; which sets up an Airflow + Postgres + Metabase stack and can also set up AWS infra to run them, with the following tools&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;&lt;code&gt;local development&lt;/code&gt;&lt;/strong&gt;: &lt;a href=\"https://www.docker.com/\"&gt;Docker&lt;/a&gt; &amp;amp; &lt;a href=\"https://docs.docker.com/compose/\"&gt;Docker compose&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;&lt;code&gt;DB Migrations&lt;/code&gt;&lt;/strong&gt;: &lt;a href=\"https://ollycope.com/software/yoyo/latest/\"&gt;yoyo-migrations&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;&lt;code&gt;IAC&lt;/code&gt;&lt;/strong&gt;: &lt;a href=\"https://www.terraform.io/\"&gt;Terraform&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;&lt;code&gt;CI/CD&lt;/code&gt;&lt;/strong&gt;: &lt;a href=\"https://github.com/features/actions\"&gt;Github Actions&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;&lt;code&gt;Testing&lt;/code&gt;&lt;/strong&gt;: &lt;a href=\"https://docs.pytest.org/en/7.1.x/\"&gt;Pytest&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;&lt;code&gt;Formatting&lt;/code&gt;&lt;/strong&gt;: &lt;a href=\"https://pycqa.github.io/isort/\"&gt;isort&lt;/a&gt; &amp;amp; &lt;a href=\"https://github.com/psf/black\"&gt;black&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;&lt;code&gt;Lint check&lt;/code&gt;&lt;/strong&gt;: &lt;a href=\"https://github.com/pycqa/flake8\"&gt;flake8&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;&lt;code&gt;Type check&lt;/code&gt;&lt;/strong&gt;: &lt;a href=\"http://mypy-lang.org/\"&gt;mypy&lt;/a&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I also updated the below projects from my website to use these tools for easier setup.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;a href=\"https://www.startdataengineering.com/post/data-engineering-project-for-beginners-batch-edition/\"&gt;DE Project Batch edition&lt;/a&gt; Airflow, Redshift, EMR, S3, Metabase&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.startdataengineering.com/post/data-engineering-project-to-impress-hiring-managers/\"&gt;DE Project to impress Hiring Manager&lt;/a&gt; Cron, Postgres, Metabase&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.startdataengineering.com/post/data-engineering-project-e2e/\"&gt;End-to-end DE project&lt;/a&gt; Dagster, dbt, Postgres, Metabase&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;An easy-to-use template helps people start building data engineering projects (for portfolio) &amp;amp; providing a good understanding of commonly used development practices. Any feedback is appreciated. I hope this helps someone :) &lt;/p&gt;\n\n&lt;p&gt;Tl; DR: Data infra is complex; use this template for your portfolio data projects &lt;/p&gt;\n\n&lt;p&gt;Blog: &lt;a href=\"https://www.startdataengineering.com/post/data-engineering-projects-with-free-template/\"&gt;https://www.startdataengineering.com/post/data-engineering-projects-with-free-template/&lt;/a&gt;\nCode: &lt;a href=\"https://github.com/josephmachado/data_engineering_project_template\"&gt;https://github.com/josephmachado/data_engineering_project_template&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_0Q5vFOrE7KpYTqFgPCUz-1sLFT_JPpy8TW09LqeNmU.jpg?auto=webp&amp;s=6d5ec30373734a0ee7913bdbd0dcc0eeea343dce", "width": 1707, "height": 961}, "resolutions": [{"url": "https://external-preview.redd.it/_0Q5vFOrE7KpYTqFgPCUz-1sLFT_JPpy8TW09LqeNmU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=250b55a75d8b1fdc8a05a5dee90bccc382871ea7", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/_0Q5vFOrE7KpYTqFgPCUz-1sLFT_JPpy8TW09LqeNmU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=060d127153a950a6b861722b4140e26dc29c5a39", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/_0Q5vFOrE7KpYTqFgPCUz-1sLFT_JPpy8TW09LqeNmU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fcf8065593c3b3bd2377a28159f585fa63ea0301", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/_0Q5vFOrE7KpYTqFgPCUz-1sLFT_JPpy8TW09LqeNmU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3d40859dcb0bb90d4b49e0b10d47be5c3b026c28", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/_0Q5vFOrE7KpYTqFgPCUz-1sLFT_JPpy8TW09LqeNmU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=20512cacccae80096855c00629239e26f9ddb938", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/_0Q5vFOrE7KpYTqFgPCUz-1sLFT_JPpy8TW09LqeNmU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=692d3dcfa31077dd3c618e807c9f3b7fb892ec68", "width": 1080, "height": 608}], "variants": {}, "id": "35-OLZXPWHZTRGzuafvdWv9VwqHqY_S4pFJfcK7yGZQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "ygieh8", "is_robot_indexable": true, "report_reasons": null, "author": "joseph_machado", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ygieh8/data_engineering_projects_with_template_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ygieh8/data_engineering_projects_with_template_airflow/", "subreddit_subscribers": 78262, "created_utc": 1667046586.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "(And I don't mean Tableau)\n\nComing from a coding background, PowerBI feels like the worst parts of Excel, but on steroids.  I mean it. The no-code UI/UX -- which is somehow a selling point -- is painful.\n\nIn particular:\n\n* Testing? Traceability? Debugging?\n* Scalability (number, and complexity of models)\n* Reproducibility?\n* Documentation?? (i.e., how your .PBIX works)\n* Version control &amp; CI/DC?? (Ok, I know technically there's a kludgy way with the open-source add on, Tabular Editor, but yeesh)\n* The whole DAX experience is very odd.  More than just logically and lexically,  i.e., burying random bits of (depending on use cases, mandatory) code throughout the GUI.\n\n**This is not just a rant, I want to learn something:**\n\nAt companies big and small, are these faults accepted, or are there alternatives that are widely used?\n\nR Shiny?\n\nPython Dash?\n\n&amp;#x200B;\n\n**How about some examples...**\n\nHow is a company like, say, Wells Fargo or T-Mobile drawing those personalized analytics when you look at your account?  It can't be PowerBI, right?\n\nHow is Amazon drawing the usage analytics on your AWS account?\n\nJust looking for some perspective here...", "author_fullname": "t2_6fifg4n4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PowerBI: please tell me there's something better for enterprise use cases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yg223a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666995777.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666994957.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;(And I don&amp;#39;t mean Tableau)&lt;/p&gt;\n\n&lt;p&gt;Coming from a coding background, PowerBI feels like the worst parts of Excel, but on steroids.  I mean it. The no-code UI/UX -- which is somehow a selling point -- is painful.&lt;/p&gt;\n\n&lt;p&gt;In particular:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Testing? Traceability? Debugging?&lt;/li&gt;\n&lt;li&gt;Scalability (number, and complexity of models)&lt;/li&gt;\n&lt;li&gt;Reproducibility?&lt;/li&gt;\n&lt;li&gt;Documentation?? (i.e., how your .PBIX works)&lt;/li&gt;\n&lt;li&gt;Version control &amp;amp; CI/DC?? (Ok, I know technically there&amp;#39;s a kludgy way with the open-source add on, Tabular Editor, but yeesh)&lt;/li&gt;\n&lt;li&gt;The whole DAX experience is very odd.  More than just logically and lexically,  i.e., burying random bits of (depending on use cases, mandatory) code throughout the GUI.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;This is not just a rant, I want to learn something:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;At companies big and small, are these faults accepted, or are there alternatives that are widely used?&lt;/p&gt;\n\n&lt;p&gt;R Shiny?&lt;/p&gt;\n\n&lt;p&gt;Python Dash?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;How about some examples...&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;How is a company like, say, Wells Fargo or T-Mobile drawing those personalized analytics when you look at your account?  It can&amp;#39;t be PowerBI, right?&lt;/p&gt;\n\n&lt;p&gt;How is Amazon drawing the usage analytics on your AWS account?&lt;/p&gt;\n\n&lt;p&gt;Just looking for some perspective here...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yg223a", "is_robot_indexable": true, "report_reasons": null, "author": "icysandstone", "discussion_type": null, "num_comments": 46, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yg223a/powerbi_please_tell_me_theres_something_better/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yg223a/powerbi_please_tell_me_theres_something_better/", "subreddit_subscribers": 78262, "created_utc": 1666994957.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_b7f9ay9o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What Is Web Scraping And how to do with azure Synapse and Python and Spark Pool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_ygapri", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/J5VI-cZKZMM?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"What Is Web Scraping And how to do with azure Synapse and Python and Spark Pool\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "What Is Web Scraping And how to do with azure Synapse and Python and Spark Pool", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/J5VI-cZKZMM?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"What Is Web Scraping And how to do with azure Synapse and Python and Spark Pool\"&gt;&lt;/iframe&gt;", "author_name": "SoftWiz Circle", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/J5VI-cZKZMM/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/c/SoftWizCircle"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/J5VI-cZKZMM?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"What Is Web Scraping And how to do with azure Synapse and Python and Spark Pool\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/ygapri", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/8U_sT23cP_LhGaTY2wCZBknNiJWyRgEr63pQy4v7eTk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667020251.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/J5VI-cZKZMM", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fFUsk-1j11qnUiZffheBaX7MGDilmALvdB57TxdkFQc.jpg?auto=webp&amp;s=5eb7cda89ca485c987a567f111787aff7f396dca", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/fFUsk-1j11qnUiZffheBaX7MGDilmALvdB57TxdkFQc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=86140c987b95ff19af7f2fd56a80856097c36de2", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/fFUsk-1j11qnUiZffheBaX7MGDilmALvdB57TxdkFQc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a9e0781177527ab3542f574300ffff0183ed62e8", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/fFUsk-1j11qnUiZffheBaX7MGDilmALvdB57TxdkFQc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=99e3c800fe61efacb27b13cc5cfb11588011b186", "width": 320, "height": 240}], "variants": {}, "id": "b53gD5L-v_ALIZiQkYZUYVODvzMHqmxfZOHDocGRMCs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "ygapri", "is_robot_indexable": true, "report_reasons": null, "author": "balramprasad", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ygapri/what_is_web_scraping_and_how_to_do_with_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/J5VI-cZKZMM", "subreddit_subscribers": 78262, "created_utc": 1667020251.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "What Is Web Scraping And how to do with azure Synapse and Python and Spark Pool", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/J5VI-cZKZMM?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"What Is Web Scraping And how to do with azure Synapse and Python and Spark Pool\"&gt;&lt;/iframe&gt;", "author_name": "SoftWiz Circle", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/J5VI-cZKZMM/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/c/SoftWizCircle"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there,\n\nWe have a new data pipeline team. The rest of the engineering teams use react and node with dynamo db and kafka.\n\nShould we be looking for node skills to align more closely with the rest of engineering, or python as the \u2018go to\u2019 for DE?\n\nPipelines will be to / from internal systems plus some third parties, and into Snowflake DB for analysts.", "author_fullname": "t2_67xxz9mu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Node or python?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yga6bl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667018502.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there,&lt;/p&gt;\n\n&lt;p&gt;We have a new data pipeline team. The rest of the engineering teams use react and node with dynamo db and kafka.&lt;/p&gt;\n\n&lt;p&gt;Should we be looking for node skills to align more closely with the rest of engineering, or python as the \u2018go to\u2019 for DE?&lt;/p&gt;\n\n&lt;p&gt;Pipelines will be to / from internal systems plus some third parties, and into Snowflake DB for analysts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yga6bl", "is_robot_indexable": true, "report_reasons": null, "author": "Nydas_co", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yga6bl/node_or_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yga6bl/node_or_python/", "subreddit_subscribers": 78262, "created_utc": 1667018502.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "   I\u2019ve been tasked to pull down a large table (around 200 mill rows) into a lake. What\u2019s an optimal and efficient way to pull down a large database table, using Databricks? \n\nIs it more performant to land the file as a csv or parquet first? I am reading parquet has faster writes and is obviously, cheaper on storage? Should this be done in small blocks, using a loop that writes check points to avoid the source db running out of memory?", "author_fullname": "t2_tsg6kr0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using Databricks to load a large database table into parquet files or csv", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yg5jrn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667004530.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been tasked to pull down a large table (around 200 mill rows) into a lake. What\u2019s an optimal and efficient way to pull down a large database table, using Databricks? &lt;/p&gt;\n\n&lt;p&gt;Is it more performant to land the file as a csv or parquet first? I am reading parquet has faster writes and is obviously, cheaper on storage? Should this be done in small blocks, using a loop that writes check points to avoid the source db running out of memory?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yg5jrn", "is_robot_indexable": true, "report_reasons": null, "author": "lifec0ach", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yg5jrn/using_databricks_to_load_a_large_database_table/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yg5jrn/using_databricks_to_load_a_large_database_table/", "subreddit_subscribers": 78262, "created_utc": 1667004530.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nJust some context I work in a large bank and in a relatively branched off division. One thing about working in a large org is the left hand not knowing what the right hand does so there isn't much to gain outside from understanding \"enterprise supported tool\".\n\nI just want to ask as we're looking to transition towards optimizing and automating our data pipeline and end user BI reporting away from manual inputs. \n\nCurrently extracting from source data systems and from emails to excel sheets for analysis and then transferring those overall numbers to a consolidated reporting workbook which has formula refreshed for an overview of multiple metrics.\n\nI want to ask for anyone who may have some beneficial knowledge and experience what they think about how it should be done? I'm fairly new to the concept of data engineering but now found a passion for it with self learning of Python, SQL, and introductory understanding of data pipelines but looking to contribute to this project as much as possible.\n\nThank you all in advance!!!", "author_fullname": "t2_8hgp8fod", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is optimal ETL pipeline?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yg64cm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667006206.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;Just some context I work in a large bank and in a relatively branched off division. One thing about working in a large org is the left hand not knowing what the right hand does so there isn&amp;#39;t much to gain outside from understanding &amp;quot;enterprise supported tool&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;I just want to ask as we&amp;#39;re looking to transition towards optimizing and automating our data pipeline and end user BI reporting away from manual inputs. &lt;/p&gt;\n\n&lt;p&gt;Currently extracting from source data systems and from emails to excel sheets for analysis and then transferring those overall numbers to a consolidated reporting workbook which has formula refreshed for an overview of multiple metrics.&lt;/p&gt;\n\n&lt;p&gt;I want to ask for anyone who may have some beneficial knowledge and experience what they think about how it should be done? I&amp;#39;m fairly new to the concept of data engineering but now found a passion for it with self learning of Python, SQL, and introductory understanding of data pipelines but looking to contribute to this project as much as possible.&lt;/p&gt;\n\n&lt;p&gt;Thank you all in advance!!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yg64cm", "is_robot_indexable": true, "report_reasons": null, "author": "One_Station_1762", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yg64cm/what_is_optimal_etl_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yg64cm/what_is_optimal_etl_pipeline/", "subreddit_subscribers": 78262, "created_utc": 1667006206.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2ishbuf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Behind the Hype: Should you ever build a Data Vault in a Lakehouse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_yg0yrq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/RNMoWnSWcTo?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Behind the Hype: Should you ever build a Data Vault in a Lakehouse?\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Behind the Hype: Should you ever build a Data Vault in a Lakehouse?", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/RNMoWnSWcTo?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Behind the Hype: Should you ever build a Data Vault in a Lakehouse?\"&gt;&lt;/iframe&gt;", "author_name": "Advancing Analytics", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/RNMoWnSWcTo/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/c/AdvancingAnalytics"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/RNMoWnSWcTo?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Behind the Hype: Should you ever build a Data Vault in a Lakehouse?\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/yg0yrq", "height": 200}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/6gGcxfiQ93fl286IZigU3E6y5yDKza_VIduxeajTcfk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666992176.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/RNMoWnSWcTo", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XzdOdwUjwoAUZP43N76zAeXKEJ6ZJRYpR8tVsYDkrcQ.jpg?auto=webp&amp;s=ee70a1e8f3e8ca732545e63dd34694aacd45b293", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/XzdOdwUjwoAUZP43N76zAeXKEJ6ZJRYpR8tVsYDkrcQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=40976d02f683c78108540812f832bec631e7b6a5", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/XzdOdwUjwoAUZP43N76zAeXKEJ6ZJRYpR8tVsYDkrcQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=31602498a19ca8a8d428af6a8389529f6f8294a9", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/XzdOdwUjwoAUZP43N76zAeXKEJ6ZJRYpR8tVsYDkrcQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f1b38030617c1f4c7826c9ed476a01f62552da76", "width": 320, "height": 240}], "variants": {}, "id": "pk3v5rA6SydbpycNohoB1pc5PdOPctygpa6fsnXOmYM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yg0yrq", "is_robot_indexable": true, "report_reasons": null, "author": "youderkB", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yg0yrq/behind_the_hype_should_you_ever_build_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/RNMoWnSWcTo", "subreddit_subscribers": 78262, "created_utc": 1666992176.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Behind the Hype: Should you ever build a Data Vault in a Lakehouse?", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/RNMoWnSWcTo?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Behind the Hype: Should you ever build a Data Vault in a Lakehouse?\"&gt;&lt;/iframe&gt;", "author_name": "Advancing Analytics", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/RNMoWnSWcTo/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/c/AdvancingAnalytics"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone found good educational resources on interacting with APIs from a data engineering perspective? I feel like this in an areas that I need to round out in my skillset, as I've have almost zero opportunities to dig into this at my work. \n\nI'm honestly not sure where to start looking on this stuff, so anything would help!", "author_fullname": "t2_gtjfu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Educational resources for working with web/cloud APIs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfscjm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666973056.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone found good educational resources on interacting with APIs from a data engineering perspective? I feel like this in an areas that I need to round out in my skillset, as I&amp;#39;ve have almost zero opportunities to dig into this at my work. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m honestly not sure where to start looking on this stuff, so anything would help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yfscjm", "is_robot_indexable": true, "report_reasons": null, "author": "LemurPrime", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yfscjm/educational_resources_for_working_with_webcloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yfscjm/educational_resources_for_working_with_webcloud/", "subreddit_subscribers": 78262, "created_utc": 1666973056.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all. So, I'm a CompSci freshgraduate that's currently working as Junior Data Scientist in a small marketing agency.  \n\nI'm looking for another job because of monetary and location reasons and I want to switch to Data Engineering roles. I have updated my CV and modified it to fit DE openings.  \n\nI have applied to a lot of opening but only received a few HR calls. I think there's something wrong in my CV. I hope i can get some advice to fix my CV here.   Thank you in advance!\n\nhttps://preview.redd.it/1swolyr1tqw91.png?width=1700&amp;format=png&amp;auto=webp&amp;s=f6522ed73858eddede9368cf213308a9b0877484", "author_fullname": "t2_yvp0t4q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for advice to improve my CV", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"1swolyr1tqw91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 139, "x": 108, "u": "https://preview.redd.it/1swolyr1tqw91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5131ee8303fcf44e71f9a76a4ffcf75eac9909e5"}, {"y": 279, "x": 216, "u": "https://preview.redd.it/1swolyr1tqw91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1808d13e25da1240dd89e604c367c2d30d06c54b"}, {"y": 414, "x": 320, "u": "https://preview.redd.it/1swolyr1tqw91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=79d90d8991a798dadacad80a72fc1e2ae288990e"}, {"y": 828, "x": 640, "u": "https://preview.redd.it/1swolyr1tqw91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=cd2c6b9a40de7a5c8ece76d0fa1426569afe2b92"}, {"y": 1242, "x": 960, "u": "https://preview.redd.it/1swolyr1tqw91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=cacaa5e267824ce1a00a09d67a6a3404d699a0d4"}, {"y": 1397, "x": 1080, "u": "https://preview.redd.it/1swolyr1tqw91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0bc5454f8fe70bfad6c53b1385cf0dda10cd14d4"}], "s": {"y": 2200, "x": 1700, "u": "https://preview.redd.it/1swolyr1tqw91.png?width=1700&amp;format=png&amp;auto=webp&amp;s=f6522ed73858eddede9368cf213308a9b0877484"}, "id": "1swolyr1tqw91"}}, "name": "t3_ygj145", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/SDlVMGplkrDcPei18D4-3k8Eba7q8ca7i1VmbNvyJu8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667048384.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all. So, I&amp;#39;m a CompSci freshgraduate that&amp;#39;s currently working as Junior Data Scientist in a small marketing agency.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for another job because of monetary and location reasons and I want to switch to Data Engineering roles. I have updated my CV and modified it to fit DE openings.  &lt;/p&gt;\n\n&lt;p&gt;I have applied to a lot of opening but only received a few HR calls. I think there&amp;#39;s something wrong in my CV. I hope i can get some advice to fix my CV here.   Thank you in advance!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/1swolyr1tqw91.png?width=1700&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f6522ed73858eddede9368cf213308a9b0877484\"&gt;https://preview.redd.it/1swolyr1tqw91.png?width=1700&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f6522ed73858eddede9368cf213308a9b0877484&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "ygj145", "is_robot_indexable": true, "report_reasons": null, "author": "helmialf", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ygj145/looking_for_advice_to_improve_my_cv/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ygj145/looking_for_advice_to_improve_my_cv/", "subreddit_subscribers": 78262, "created_utc": 1667048384.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can anyone point me to any resources on the time and space complexity requirements for designing algorithms to handle high-velocity stream data?", "author_fullname": "t2_jmlaei7u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "References on Space and Time Complexity of Stream Algorithms", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yggyzn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667042129.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can anyone point me to any resources on the time and space complexity requirements for designing algorithms to handle high-velocity stream data?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yggyzn", "is_robot_indexable": true, "report_reasons": null, "author": "smf_ano", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yggyzn/references_on_space_and_time_complexity_of_stream/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yggyzn/references_on_space_and_time_complexity_of_stream/", "subreddit_subscribers": 78262, "created_utc": 1667042129.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Sounds silly but I'm still new however I feel everything can just be done on PySpark, is there something I'm missing?", "author_fullname": "t2_wqszb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When to use SQL or PySpark?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yggegm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667040189.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sounds silly but I&amp;#39;m still new however I feel everything can just be done on PySpark, is there something I&amp;#39;m missing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yggegm", "is_robot_indexable": true, "report_reasons": null, "author": "miridian19", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yggegm/when_to_use_sql_or_pyspark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yggegm/when_to_use_sql_or_pyspark/", "subreddit_subscribers": 78262, "created_utc": 1667040189.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I joined my current organization 7 months back as a Software Developer but was put into a big data project without prior knowledge of big data. I have been working on data warehousing and data computation projects using big data technologies like Spark, Scala, Hadoop and more for the last 6 months and I find my job really exciting, since I'm learning new things, but the company does not have really exciting big data projects and works only with not-so-big amounts of relational data. \n\nI want to switch to a new org in the next 1 year, and I don't know if I should do a certification in data engineering, personal projects, interview prep, data structures, what not. I feel lost and don't know how to navigate in this exciting but quite a bit unknown world of big data and data engineering. Any tips?", "author_fullname": "t2_acpiekwn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some career paths for an entry level Big Data Developer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfyncr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666986362.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I joined my current organization 7 months back as a Software Developer but was put into a big data project without prior knowledge of big data. I have been working on data warehousing and data computation projects using big data technologies like Spark, Scala, Hadoop and more for the last 6 months and I find my job really exciting, since I&amp;#39;m learning new things, but the company does not have really exciting big data projects and works only with not-so-big amounts of relational data. &lt;/p&gt;\n\n&lt;p&gt;I want to switch to a new org in the next 1 year, and I don&amp;#39;t know if I should do a certification in data engineering, personal projects, interview prep, data structures, what not. I feel lost and don&amp;#39;t know how to navigate in this exciting but quite a bit unknown world of big data and data engineering. Any tips?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yfyncr", "is_robot_indexable": true, "report_reasons": null, "author": "arrigatogozaimasu", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yfyncr/what_are_some_career_paths_for_an_entry_level_big/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yfyncr/what_are_some_career_paths_for_an_entry_level_big/", "subreddit_subscribers": 78262, "created_utc": 1666986362.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_1bnhotlu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cloud DevOps engineers are in high demand, these new bootcamps will equip you", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": true, "name": "t3_ygnbq7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.25, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/n-4GKqDN_iMHVUnWDZ15MRuIOflrp1Y44A74yUQh-zM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667059262.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "kanger.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://kanger.dev/cloud-devops-bootcamps-engineers/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/sLhT8ks1kB1NYu7uA3E2gHIS01ORw-Zx3F0SOTPYoaA.jpg?auto=webp&amp;s=4acd1ddb6bae4624234de69b56d35b42d9cbbcfe", "width": 1000, "height": 750}, "resolutions": [{"url": "https://external-preview.redd.it/sLhT8ks1kB1NYu7uA3E2gHIS01ORw-Zx3F0SOTPYoaA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=637d771513c8bd04520fa2ef7666e6ae9a97d7fb", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/sLhT8ks1kB1NYu7uA3E2gHIS01ORw-Zx3F0SOTPYoaA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5f4bca18cedc72a852e1a254bd131a2d68a14e96", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/sLhT8ks1kB1NYu7uA3E2gHIS01ORw-Zx3F0SOTPYoaA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=474cc50405473fa78e449e0d0811619a627786ab", "width": 320, "height": 240}, {"url": "https://external-preview.redd.it/sLhT8ks1kB1NYu7uA3E2gHIS01ORw-Zx3F0SOTPYoaA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9cdc9692bffe4a760a891a9e909b20d42670d0cd", "width": 640, "height": 480}, {"url": "https://external-preview.redd.it/sLhT8ks1kB1NYu7uA3E2gHIS01ORw-Zx3F0SOTPYoaA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=93c76e033045178981f38316878cca78d1e6374e", "width": 960, "height": 720}], "variants": {}, "id": "xRO_qkLQf2w8p8oD8HSdrv5f6RuzR3Z5s4ei-fGPHQs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "ygnbq7", "is_robot_indexable": true, "report_reasons": null, "author": "skj8", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ygnbq7/cloud_devops_engineers_are_in_high_demand_these/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://kanger.dev/cloud-devops-bootcamps-engineers/", "subreddit_subscribers": 78262, "created_utc": 1667059262.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How about a meetup in the bay , we will all grab a coffee and get to know each other .", "author_fullname": "t2_ak7znzn4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bay area meetup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_ygmfnk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667057041.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How about a meetup in the bay , we will all grab a coffee and get to know each other .&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ygmfnk", "is_robot_indexable": true, "report_reasons": null, "author": "Accomplished-Can-912", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ygmfnk/bay_area_meetup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ygmfnk/bay_area_meetup/", "subreddit_subscribers": 78262, "created_utc": 1667057041.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, i am very new to the data engineering field. So for that I have locally installed Hadoop and hive following online tutorials. What I wanted to do was create some databases and query them using hive just to get more hands on practice with it. Is it possible using some software or tool?\n\nI am also not sure how Hadoop runs locally, i have just followed some tutorials and got it to start using ./start-all.sh command, installed hive and Hadoop for a different user (somehow tutorial mentioned to create a new user for Hadoop)\n\nI have surfed the net and found some tool such as dbeaver might be useful here? Not sure if that's suited for my purpose\n\nCurrently on Linux machine (latest mint)", "author_fullname": "t2_jx4zrwe0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Testing hive queries locally", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_ygm4p5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667056307.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, i am very new to the data engineering field. So for that I have locally installed Hadoop and hive following online tutorials. What I wanted to do was create some databases and query them using hive just to get more hands on practice with it. Is it possible using some software or tool?&lt;/p&gt;\n\n&lt;p&gt;I am also not sure how Hadoop runs locally, i have just followed some tutorials and got it to start using ./start-all.sh command, installed hive and Hadoop for a different user (somehow tutorial mentioned to create a new user for Hadoop)&lt;/p&gt;\n\n&lt;p&gt;I have surfed the net and found some tool such as dbeaver might be useful here? Not sure if that&amp;#39;s suited for my purpose&lt;/p&gt;\n\n&lt;p&gt;Currently on Linux machine (latest mint)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ygm4p5", "is_robot_indexable": true, "report_reasons": null, "author": "sjdevelop", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ygm4p5/testing_hive_queries_locally/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ygm4p5/testing_hive_queries_locally/", "subreddit_subscribers": 78262, "created_utc": 1667056307.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I realize this limit is for interactive queries, but it looks like batch queries are subject to some queue time that is not described very deterministically...", "author_fullname": "t2_7spandv9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How should we plan for the 100 job concurrency limit in BigQuery\u2026? Is this limit per company, per project, or other? Is this shared across all running jobs - Ingestion jobs, Etl / Transform jobs, Dashboards / Reports? Can this be increased somehow?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ygkfol", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667052089.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I realize this limit is for interactive queries, but it looks like batch queries are subject to some queue time that is not described very deterministically...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ygkfol", "is_robot_indexable": true, "report_reasons": null, "author": "brrdprrsn", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ygkfol/how_should_we_plan_for_the_100_job_concurrency/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ygkfol/how_should_we_plan_for_the_100_job_concurrency/", "subreddit_subscribers": 78262, "created_utc": 1667052089.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\n\n[View Poll](https://www.reddit.com/poll/ygjvm3)", "author_fullname": "t2_eajtr4nz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much does your company spend on cloud data warehouses? How fast is this growing (if at all)? What are the main contributing factors - more queries? larger data volumes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ygjvm3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667050647.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/ygjvm3\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ygjvm3", "is_robot_indexable": true, "report_reasons": null, "author": "alneuman", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1667396248021, "options": [{"text": "&lt; $50k per year", "id": "19466622"}, {"text": "$ 50 - 150k per year", "id": "19466623"}, {"text": "$ 150 - 500k per year", "id": "19466624"}, {"text": "$ 500k  - $ 1M per year", "id": "19466625"}, {"text": "&gt; $ 1M per year", "id": "19466626"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 49, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ygjvm3/how_much_does_your_company_spend_on_cloud_data/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/ygjvm3/how_much_does_your_company_spend_on_cloud_data/", "subreddit_subscribers": 78262, "created_utc": 1667050647.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So, after using and exploring some of the tools and services out there (like Hightouch or Census) and being a bit annoyed with the pricing policy for those tools, I\u2019m considering starting a pet project that fits into that space.\n\nIs anyone here using those tools (or some other I do not know)? What do you miss from those services? How would an ideal service like that would look to you?", "author_fullname": "t2_pix46", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the \u201creverse ETL\u201d space lacking?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ygj2ra", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667048487.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, after using and exploring some of the tools and services out there (like Hightouch or Census) and being a bit annoyed with the pricing policy for those tools, I\u2019m considering starting a pet project that fits into that space.&lt;/p&gt;\n\n&lt;p&gt;Is anyone here using those tools (or some other I do not know)? What do you miss from those services? How would an ideal service like that would look to you?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ygj2ra", "is_robot_indexable": true, "report_reasons": null, "author": "Angry__Spaniard", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ygj2ra/what_is_the_reverse_etl_space_lacking/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ygj2ra/what_is_the_reverse_etl_space_lacking/", "subreddit_subscribers": 78262, "created_utc": 1667048487.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Let's say im looking for something specific in their docks, how do I search for postgress or cassandra excliding #C?", "author_fullname": "t2_4as7wsm1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to use advanced search in microsoft docks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ygglhf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667040894.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s say im looking for something specific in their docks, how do I search for postgress or cassandra excliding #C?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ygglhf", "is_robot_indexable": true, "report_reasons": null, "author": "Dawido090", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ygglhf/how_to_use_advanced_search_in_microsoft_docks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ygglhf/how_to_use_advanced_search_in_microsoft_docks/", "subreddit_subscribers": 78262, "created_utc": 1667040894.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our data was migrated to s3 recently. We are using redshift spectrum to query data but it\u2019s taking really long time to query and do small transformations. We started using partitioning, there is improvement but not very significant compared to our previous datawarehouses. What are we doing wrong? What else can we try? Any suggestions are welcome. We are a small startup and cost savings was cited as the reasoning by seniors to migrate to this architecture so can\u2019t go back to relational datawarehouses. TIA!", "author_fullname": "t2_845cr8yh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need suggestion on query optimization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfx7u6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666982802.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our data was migrated to s3 recently. We are using redshift spectrum to query data but it\u2019s taking really long time to query and do small transformations. We started using partitioning, there is improvement but not very significant compared to our previous datawarehouses. What are we doing wrong? What else can we try? Any suggestions are welcome. We are a small startup and cost savings was cited as the reasoning by seniors to migrate to this architecture so can\u2019t go back to relational datawarehouses. TIA!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yfx7u6", "is_robot_indexable": true, "report_reasons": null, "author": "chatsachin", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yfx7u6/need_suggestion_on_query_optimization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yfx7u6/need_suggestion_on_query_optimization/", "subreddit_subscribers": 78262, "created_utc": 1666982802.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey Everyone,\nCan you share an event-driven use case / pipeline / project you built in your work which led to drive more sales?\n\nI know all about getting data-driven decisions to drive more sales, but I am more into the automated/dev cases that made it happen. For example, personal recommendations.", "author_fullname": "t2_hhdac8t3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Event-driven to drive more sales", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yg3oe3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666999220.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Everyone,\nCan you share an event-driven use case / pipeline / project you built in your work which led to drive more sales?&lt;/p&gt;\n\n&lt;p&gt;I know all about getting data-driven decisions to drive more sales, but I am more into the automated/dev cases that made it happen. For example, personal recommendations.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yg3oe3", "is_robot_indexable": true, "report_reasons": null, "author": "yanivbh1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yg3oe3/eventdriven_to_drive_more_sales/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yg3oe3/eventdriven_to_drive_more_sales/", "subreddit_subscribers": 78262, "created_utc": 1666999220.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}