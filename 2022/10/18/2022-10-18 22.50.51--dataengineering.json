{"kind": "Listing", "data": {"after": null, "dist": 16, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_anyz9dbz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How are you exporting your prod DB tables to your data warehouse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_y7dxl4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 90, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 2400, "fallback_url": "https://v.redd.it/0opyq3brrlu91/DASH_720.mp4?source=fallback", "height": 720, "width": 551, "scrubber_media_url": "https://v.redd.it/0opyq3brrlu91/DASH_96.mp4", "dash_url": "https://v.redd.it/0opyq3brrlu91/DASHPlaylist.mpd?a=1668725451%2CNWU5NDIyYjgyMTkzNGFlMDEyMjIzOWIxZDc2MDQ0MGNmZjQyNjNiY2RjMTZiNGYzOTk4OTMyYTE3YjExNmM1MA%3D%3D&amp;v=1&amp;f=sd", "duration": 14, "hls_url": "https://v.redd.it/0opyq3brrlu91/HLSPlaylist.m3u8?a=1668725451%2CZTI3YWE5MjA5ZTgzZmU0ZTlhNTM0NjEzODEzZGVlMWNiZGI5OThiMzViZDFiMGI5ZTdhNzIwYmVhNTJlYzZjNg%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 90, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/2VvWJuGG7c6oyNdWu9ZgBxx_O_e8XA0Zr4SWcEVfMaU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666115689.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/0opyq3brrlu91", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/liZEqMjrKmaZOBfyA78-sk8I4vcjOdhJstI3NzOS3-o.png?format=pjpg&amp;auto=webp&amp;s=42be604bdc852b8b53302d2cfe75987612271b30", "width": 654, "height": 854}, "resolutions": [{"url": "https://external-preview.redd.it/liZEqMjrKmaZOBfyA78-sk8I4vcjOdhJstI3NzOS3-o.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=65fd757bbff20a34ddc38958f3f8381029f6ba02", "width": 108, "height": 141}, {"url": "https://external-preview.redd.it/liZEqMjrKmaZOBfyA78-sk8I4vcjOdhJstI3NzOS3-o.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=40994445e074fbe75157901709542f8a49afb91a", "width": 216, "height": 282}, {"url": "https://external-preview.redd.it/liZEqMjrKmaZOBfyA78-sk8I4vcjOdhJstI3NzOS3-o.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=a710944848efc09fa2cd1240d4950409fc4126f7", "width": 320, "height": 417}, {"url": "https://external-preview.redd.it/liZEqMjrKmaZOBfyA78-sk8I4vcjOdhJstI3NzOS3-o.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=b6593981d9500aa3dc55cacedc8168547c0f79e2", "width": 640, "height": 835}], "variants": {}, "id": "Aqs1DeJB8xCeUCp9KfxgJMrnxPxTtCEyhka_scWOpmE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "y7dxl4", "is_robot_indexable": true, "report_reasons": null, "author": "tchungry", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y7dxl4/how_are_you_exporting_your_prod_db_tables_to_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/0opyq3brrlu91", "subreddit_subscribers": 76956, "created_utc": 1666115689.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 2400, "fallback_url": "https://v.redd.it/0opyq3brrlu91/DASH_720.mp4?source=fallback", "height": 720, "width": 551, "scrubber_media_url": "https://v.redd.it/0opyq3brrlu91/DASH_96.mp4", "dash_url": "https://v.redd.it/0opyq3brrlu91/DASHPlaylist.mpd?a=1668725451%2CNWU5NDIyYjgyMTkzNGFlMDEyMjIzOWIxZDc2MDQ0MGNmZjQyNjNiY2RjMTZiNGYzOTk4OTMyYTE3YjExNmM1MA%3D%3D&amp;v=1&amp;f=sd", "duration": 14, "hls_url": "https://v.redd.it/0opyq3brrlu91/HLSPlaylist.m3u8?a=1668725451%2CZTI3YWE5MjA5ZTgzZmU0ZTlhNTM0NjEzODEzZGVlMWNiZGI5OThiMzViZDFiMGI5ZTdhNzIwYmVhNTJlYzZjNg%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been an analyst for about 3 years mostly using SQL, Python, and building Dashboards. I built and automated few dev tables before to base dashboards on but nothing major.\n\nI am considering trying to transition into a Data engineering role, but I have a business degree. Have anyone had a similar experience and can advise on good resources or how possible the transition is?", "author_fullname": "t2_lus61uk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggestions to Transition from Data Analyst to Data Engineering role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y6yj65", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 41, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666072978.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been an analyst for about 3 years mostly using SQL, Python, and building Dashboards. I built and automated few dev tables before to base dashboards on but nothing major.&lt;/p&gt;\n\n&lt;p&gt;I am considering trying to transition into a Data engineering role, but I have a business degree. Have anyone had a similar experience and can advise on good resources or how possible the transition is?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "y6yj65", "is_robot_indexable": true, "report_reasons": null, "author": "mohamedk97", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y6yj65/suggestions_to_transition_from_data_analyst_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y6yj65/suggestions_to_transition_from_data_analyst_to/", "subreddit_subscribers": 76956, "created_utc": 1666072978.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_casbd3z4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Puffin file format in Apache Iceberg. Wait we had Parquet, ORC, did we need a new one?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 94, "top_awarded_type": null, "hide_score": false, "name": "t3_y6s2io", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/X1Xcqwnqz4J6lSuL-Q1WH_9zqvRi_ijj1-5jSVFnsq8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666054216.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dremio.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.dremio.com/subsurface/puffins-and-icebergs-additional-stats-for-apache-iceberg-tables/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hbo3VOEKWtjZ8oJhpBPPT5lK3SC4Rhu5TA1GCkdt_Zg.jpg?auto=webp&amp;s=8b558d948a954242d64d0e491f4fea5a5dbb3b05", "width": 1024, "height": 691}, "resolutions": [{"url": "https://external-preview.redd.it/hbo3VOEKWtjZ8oJhpBPPT5lK3SC4Rhu5TA1GCkdt_Zg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bbc343f6a1d835e09d06acf2b0bc78a9a65b902a", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/hbo3VOEKWtjZ8oJhpBPPT5lK3SC4Rhu5TA1GCkdt_Zg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=296d840cd564a562b13945b68a19282d689e9531", "width": 216, "height": 145}, {"url": "https://external-preview.redd.it/hbo3VOEKWtjZ8oJhpBPPT5lK3SC4Rhu5TA1GCkdt_Zg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7b486115585c22fb1016ae93a59b81b22f913e37", "width": 320, "height": 215}, {"url": "https://external-preview.redd.it/hbo3VOEKWtjZ8oJhpBPPT5lK3SC4Rhu5TA1GCkdt_Zg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b0f86f1de4eaa1dea35736eb28fc0a8921a47ca6", "width": 640, "height": 431}, {"url": "https://external-preview.redd.it/hbo3VOEKWtjZ8oJhpBPPT5lK3SC4Rhu5TA1GCkdt_Zg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=558ea21d03040367eb64bd7ea3fbaa77f9077a7f", "width": 960, "height": 647}], "variants": {}, "id": "pGtVg6Wxc7afuym6mlmo1vIZUwqvCqEWpamsl0p8ROc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "y6s2io", "is_robot_indexable": true, "report_reasons": null, "author": "Altruistic-Judge-506", "discussion_type": null, "num_comments": 3, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y6s2io/puffin_file_format_in_apache_iceberg_wait_we_had/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.dremio.com/subsurface/puffins-and-icebergs-additional-stats-for-apache-iceberg-tables/", "subreddit_subscribers": 76956, "created_utc": 1666054216.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Open Source Intelligence has opportunities like Trace Labs where volunteers give time to help locate missing persons.\n\nTrace Labs is okay training up noobs, who can skill up and network.\n\nAre there any orgs out there looking for this type of work in Data Engineering? Or any Discords/Slack where matchmaking happens ? (For all skill levels from noob up to FANG god mode).", "author_fullname": "t2_t2wl82bi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any volunteer opportunities in Data Engineering to skill up ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y6oavn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666044482.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Open Source Intelligence has opportunities like Trace Labs where volunteers give time to help locate missing persons.&lt;/p&gt;\n\n&lt;p&gt;Trace Labs is okay training up noobs, who can skill up and network.&lt;/p&gt;\n\n&lt;p&gt;Are there any orgs out there looking for this type of work in Data Engineering? Or any Discords/Slack where matchmaking happens ? (For all skill levels from noob up to FANG god mode).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "y6oavn", "is_robot_indexable": true, "report_reasons": null, "author": "generic-d-engineer", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y6oavn/any_volunteer_opportunities_in_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y6oavn/any_volunteer_opportunities_in_data_engineering/", "subreddit_subscribers": 76956, "created_utc": 1666044482.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For a project I am working on, I need to test out ways to implement a feature - user uploads a Excel file from a UI and it gets uploaded to blob storage. From blob, it has to be copied to a Table.\n\nOn way is:\nAs soon as it loads to blob, it should trigger the pipeline which loads the data into a table. \n\nI know the basic structure but would like more expert advice on this. \n\nMy question is:\nWhat all things should I keep in mind while designing this pipeline? \n\nWhat all activities in data factory will be needed? \n\nIn the current system, most of the triggers to other pipelines are conducted by Azure functions. Will a event based trigger work better instead? \n\nI can share more details if you need that to answer.", "author_fullname": "t2_6qiqr02t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure Blob to SQL DB - ideas?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y6v0kw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666062304.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For a project I am working on, I need to test out ways to implement a feature - user uploads a Excel file from a UI and it gets uploaded to blob storage. From blob, it has to be copied to a Table.&lt;/p&gt;\n\n&lt;p&gt;On way is:\nAs soon as it loads to blob, it should trigger the pipeline which loads the data into a table. &lt;/p&gt;\n\n&lt;p&gt;I know the basic structure but would like more expert advice on this. &lt;/p&gt;\n\n&lt;p&gt;My question is:\nWhat all things should I keep in mind while designing this pipeline? &lt;/p&gt;\n\n&lt;p&gt;What all activities in data factory will be needed? &lt;/p&gt;\n\n&lt;p&gt;In the current system, most of the triggers to other pipelines are conducted by Azure functions. Will a event based trigger work better instead? &lt;/p&gt;\n\n&lt;p&gt;I can share more details if you need that to answer.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y6v0kw", "is_robot_indexable": true, "report_reasons": null, "author": "Ashysh", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y6v0kw/azure_blob_to_sql_db_ideas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y6v0kw/azure_blob_to_sql_db_ideas/", "subreddit_subscribers": 76956, "created_utc": 1666062304.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've got a lot of BI/DA YoE. Switching to DE. Want to jump in with both feet but already feeling imposter syndrome before even starting.\n\nI figured I'd do an ETL project a few different ways to learn tooling. Plan is to learn Terraform first to set up some EC2 instance, dev there, then grow it to add lambdas / S3 / DBs... Eventually maybe even rebuild it in Glue\n\nAm I wasting my time learning Terraform? I feel somewhat comfortable with the AWS CLI, but building stuff up and tearing it down with bash seems like an easy way to screw up as the infra gets bigger. At the same time, expanding an existing stack seems like the exact use case for TF. But I don't know if that's too DevOps-y for a crunched timeline", "author_fullname": "t2_dxmxxpnb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "1 Month to get up to speed on DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y6x8iw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666068826.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got a lot of BI/DA YoE. Switching to DE. Want to jump in with both feet but already feeling imposter syndrome before even starting.&lt;/p&gt;\n\n&lt;p&gt;I figured I&amp;#39;d do an ETL project a few different ways to learn tooling. Plan is to learn Terraform first to set up some EC2 instance, dev there, then grow it to add lambdas / S3 / DBs... Eventually maybe even rebuild it in Glue&lt;/p&gt;\n\n&lt;p&gt;Am I wasting my time learning Terraform? I feel somewhat comfortable with the AWS CLI, but building stuff up and tearing it down with bash seems like an easy way to screw up as the infra gets bigger. At the same time, expanding an existing stack seems like the exact use case for TF. But I don&amp;#39;t know if that&amp;#39;s too DevOps-y for a crunched timeline&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y6x8iw", "is_robot_indexable": true, "report_reasons": null, "author": "NotAfraidToAsk_", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y6x8iw/1_month_to_get_up_to_speed_on_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y6x8iw/1_month_to_get_up_to_speed_on_de/", "subreddit_subscribers": 76956, "created_utc": 1666068826.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I'm wondering what people have been using to train and deploy their Data Science pipelines and models. \n\nI have looked at a couple of solutions like MLFlow and PyCaret. However, I found these missing some important pieces. \n\n\\- RepeatedCrossValidation\n\n\\- Setting parameters for Scalers\n\n\\- Access the model and interpret SHAP. \n\nI have been trying out with PDPipe, but putting it in production is difficult because I can't export pipelines with lambda functions with pickle, only with Dill.\n\nOnce we try to put a model in production in a Docker container, we have to retrain the model in the Docker container, and also depend on libraries that are used for training but not required for inference, making the container much bigger than required.\n\nAnyone has any advise?", "author_fullname": "t2_52iwujry", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Deploy pipeline and model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y79ive", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666105423.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m wondering what people have been using to train and deploy their Data Science pipelines and models. &lt;/p&gt;\n\n&lt;p&gt;I have looked at a couple of solutions like MLFlow and PyCaret. However, I found these missing some important pieces. &lt;/p&gt;\n\n&lt;p&gt;- RepeatedCrossValidation&lt;/p&gt;\n\n&lt;p&gt;- Setting parameters for Scalers&lt;/p&gt;\n\n&lt;p&gt;- Access the model and interpret SHAP. &lt;/p&gt;\n\n&lt;p&gt;I have been trying out with PDPipe, but putting it in production is difficult because I can&amp;#39;t export pipelines with lambda functions with pickle, only with Dill.&lt;/p&gt;\n\n&lt;p&gt;Once we try to put a model in production in a Docker container, we have to retrain the model in the Docker container, and also depend on libraries that are used for training but not required for inference, making the container much bigger than required.&lt;/p&gt;\n\n&lt;p&gt;Anyone has any advise?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y79ive", "is_robot_indexable": true, "report_reasons": null, "author": "Groundbreaking_Dog47", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y79ive/deploy_pipeline_and_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y79ive/deploy_pipeline_and_model/", "subreddit_subscribers": 76956, "created_utc": 1666105423.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is my first time working with AWS, I\u2019m thinking to use Google Cloud Composer after some research and consideration. Flow will be from S3 to GCS then BQ.\n\nProblem:\nJSON fields contain \u2018invalid\u2019 characters restricted in BigQuery (ie, hyphen), changing the field names in each files seem inefficient for a bunch of files and future increment.\n\nCan anyone help to suggest or recommend ways to do this more effectively? \n\nI read about BigQuery Omni and BigQuery Data Transfer Service but unfortunately these options are not open to me at the moment due to access permission.", "author_fullname": "t2_7ya53d99", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Load S3 JSON Gzipped Files into BigQuery", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y70v8a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666083606.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666081177.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is my first time working with AWS, I\u2019m thinking to use Google Cloud Composer after some research and consideration. Flow will be from S3 to GCS then BQ.&lt;/p&gt;\n\n&lt;p&gt;Problem:\nJSON fields contain \u2018invalid\u2019 characters restricted in BigQuery (ie, hyphen), changing the field names in each files seem inefficient for a bunch of files and future increment.&lt;/p&gt;\n\n&lt;p&gt;Can anyone help to suggest or recommend ways to do this more effectively? &lt;/p&gt;\n\n&lt;p&gt;I read about BigQuery Omni and BigQuery Data Transfer Service but unfortunately these options are not open to me at the moment due to access permission.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y70v8a", "is_robot_indexable": true, "report_reasons": null, "author": "FarRiver9415", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y70v8a/load_s3_json_gzipped_files_into_bigquery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y70v8a/load_s3_json_gzipped_files_into_bigquery/", "subreddit_subscribers": 76956, "created_utc": 1666081177.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently my company is using SQL server and FME/python to get and push data to and from salesforce but it doesn\u2019t seem like the best solution. Wondering what would be a better solution for this? Im more comfortable with Python/SQL but my company wants to focus more on low code/ETL tools like FME or boomi.", "author_fullname": "t2_wojey", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What ETL tool or process are you using for salesforce pipeline?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7a92p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666107116.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently my company is using SQL server and FME/python to get and push data to and from salesforce but it doesn\u2019t seem like the best solution. Wondering what would be a better solution for this? Im more comfortable with Python/SQL but my company wants to focus more on low code/ETL tools like FME or boomi.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y7a92p", "is_robot_indexable": true, "report_reasons": null, "author": "Stonedsurfer", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y7a92p/what_etl_tool_or_process_are_you_using_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y7a92p/what_etl_tool_or_process_are_you_using_for/", "subreddit_subscribers": 76956, "created_utc": 1666107116.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been using dbt heavily in my Snowflake Data Warehouse. My dbt models are all SQL-based but I would like them to move them python due to modularity and hiring python devs is easier than SQL.\n\nI know dbt released support for python but the docs are almost non-existent and very few community articles. Also, Snowflake announced Snowpark for letting users write python. \n\nCan I just use Snowpark and eliminate dbt from my stack altogether? What would be the best approach here?", "author_fullname": "t2_42hc4int", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Migrating SQL-based dbt models to python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y6pypz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666048565.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been using dbt heavily in my Snowflake Data Warehouse. My dbt models are all SQL-based but I would like them to move them python due to modularity and hiring python devs is easier than SQL.&lt;/p&gt;\n\n&lt;p&gt;I know dbt released support for python but the docs are almost non-existent and very few community articles. Also, Snowflake announced Snowpark for letting users write python. &lt;/p&gt;\n\n&lt;p&gt;Can I just use Snowpark and eliminate dbt from my stack altogether? What would be the best approach here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y6pypz", "is_robot_indexable": true, "report_reasons": null, "author": "vanillacap", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y6pypz/migrating_sqlbased_dbt_models_to_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y6pypz/migrating_sqlbased_dbt_models_to_python/", "subreddit_subscribers": 76956, "created_utc": 1666048565.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_pl4q8ng7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt launches its semantic layer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_y7btdx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/8NloFZR3WRGKxevhoZW6mo8nw1JWr93wXuZxtuAN0gQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666110786.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "getdbt.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.getdbt.com/blog/frontiers-of-the-dbt-semantic-layer", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?auto=webp&amp;s=edabdd18634aef29128ecc0d5693053ba1a95f6e", "width": 2560, "height": 1440}, "resolutions": [{"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5df6a50eec64ce3d126f3a47e1746feaf267cebb", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6d02b260d5dddd4e2e7c80420970b653c3cdddab", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=aa646e05e744be5f524016d4c775b326ef90c2d1", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e29469bfc58fee1f76e41ce74322e006445b9bb6", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f7b72e416c6ef27bd12b9f3a5a19ef15ad9e8249", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=285b785bfdba2ba6f0da014cf261fbe2d5f57f3d", "width": 1080, "height": 607}], "variants": {}, "id": "1atsLEhqeX9kFaissrSt8acZk9ienTNBpjUXMcidAMU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y7btdx", "is_robot_indexable": true, "report_reasons": null, "author": "droppedorphan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y7btdx/dbt_launches_its_semantic_layer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.getdbt.com/blog/frontiers-of-the-dbt-semantic-layer", "subreddit_subscribers": 76956, "created_utc": 1666110786.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nHave a requirement to read data from Denodo (Data virtualization) tool to AWS S3 bucket. Has anyone done such integration. If so, what is the best practice/process to integrate Denodo with AWS S3 bucket. Any insight is appreciated.\n\nThanks.", "author_fullname": "t2_mspamalq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Integration of Denodo with AWS S3 bucket", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y79bnp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666104990.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;Have a requirement to read data from Denodo (Data virtualization) tool to AWS S3 bucket. Has anyone done such integration. If so, what is the best practice/process to integrate Denodo with AWS S3 bucket. Any insight is appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y79bnp", "is_robot_indexable": true, "report_reasons": null, "author": "Awsmason", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y79bnp/integration_of_denodo_with_aws_s3_bucket/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y79bnp/integration_of_denodo_with_aws_s3_bucket/", "subreddit_subscribers": 76956, "created_utc": 1666104990.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If you're considering a new data tool (not open source), which of these software review sites would you most likely check out (if any)?\n\n[View Poll](https://www.reddit.com/poll/y7dnes)", "author_fullname": "t2_gjrwx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you use software review sites when researching tools?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7dnes", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666118972.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666115028.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you&amp;#39;re considering a new data tool (not open source), which of these software review sites would you most likely check out (if any)?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/y7dnes\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y7dnes", "is_robot_indexable": true, "report_reasons": null, "author": "prutwo", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1666719828417, "options": [{"text": "G2.com", "id": "19228048"}, {"text": "Capterra.com", "id": "19228049"}, {"text": "Trustradius.com", "id": "19228050"}, {"text": "I don't consider review sites to be helpful", "id": "19228051"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 39, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y7dnes/do_you_use_software_review_sites_when_researching/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/y7dnes/do_you_use_software_review_sites_when_researching/", "subreddit_subscribers": 76956, "created_utc": 1666115028.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im a data engineer in a big company in korea, and am trying to move to us. I have 2 yr experience and used airflow spark-scala, hadoop, neo4j and have some experience building an api server. \nI am looking for a junior de opening, but not sure how to check if they accept foreigners and the visa work problem any tips on this matter and how to go on with this issue?", "author_fullname": "t2_8zbu75fr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how to ind us jobs as foreigner", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7bqk3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666110613.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im a data engineer in a big company in korea, and am trying to move to us. I have 2 yr experience and used airflow spark-scala, hadoop, neo4j and have some experience building an api server. \nI am looking for a junior de opening, but not sure how to check if they accept foreigners and the visa work problem any tips on this matter and how to go on with this issue?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y7bqk3", "is_robot_indexable": true, "report_reasons": null, "author": "Kakao_Trees", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y7bqk3/how_to_ind_us_jobs_as_foreigner/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y7bqk3/how_to_ind_us_jobs_as_foreigner/", "subreddit_subscribers": 76956, "created_utc": 1666110613.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_eogs2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The technical obstacles of Data Mesh in 2022", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y74bfd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1666092085.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "ansilo.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://ansilo.io/blog/the-technical-obstacles-of-data-mesh-in-2022", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "y74bfd", "is_robot_indexable": true, "report_reasons": null, "author": "TimeToogo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y74bfd/the_technical_obstacles_of_data_mesh_in_2022/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://ansilo.io/blog/the-technical-obstacles-of-data-mesh-in-2022", "subreddit_subscribers": 76956, "created_utc": 1666092085.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, currently learning SQL. I intend to become a data engineer. Should I continue down this path or go for the  Aws cloud practioneer cert?", "author_fullname": "t2_7a6p4jkb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y6reqa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666052400.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, currently learning SQL. I intend to become a data engineer. Should I continue down this path or go for the  Aws cloud practioneer cert?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y6reqa", "is_robot_indexable": true, "report_reasons": null, "author": "Specialist-Ask8890", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y6reqa/sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y6reqa/sql/", "subreddit_subscribers": 76956, "created_utc": 1666052400.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}