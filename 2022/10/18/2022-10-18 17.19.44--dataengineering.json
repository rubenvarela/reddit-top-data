{"kind": "Listing", "data": {"after": null, "dist": 21, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[Ergest Xheblati](https://www.linkedin.com/in/ergestxheblati/) is the author of [*Minimum Viable SQL Patterns*](https://ergestx.gumroad.com/l/sqlpatterns), and he's spent the last 15 years mastering SQL.  \n\nIn this [SQL workshop](https://youtu.be/UFiZx5NlzL4), Ergest teaches various SQL principles (patters) to help you take your SQL skills from intermediate to expert. More specifically, you'll learn about:   \n\ud83c\udfaf Query composition patterns - How to make your complex queries shorter, more legible, and more performant   \n\ud83c\udfaf Query maintainability patterns - Constructing CTEs that can be reused. In software engineering, it's called the DRY principle (don't repeat yourself)  \n\ud83c\udfaf Query robustness patterns - Constructing queries that don't break when the underlying data changes in unpredictable ways  \n\ud83c\udfaf Query performance patterns - Make your queries faster (and cheaper) regardless of specific database you\u2019re using.\n\nToward the end of the workshop, Ergest answers over a dozen questions from SQL professionals all over the world.  \n\nWatch the full workshop \ud83d\udc49 [**here**](https://www.youtube.com/watch?v=UFiZx5NlzL4) \ud83d\udc48. It's free, and don't worry, you're not being sold on a SaaS product \ud83e\udd23  \n\n\nIf you enjoyed this video, please join Ergest and +1,000 like minded data professionals in our Slack Community, the [OA Club](https://www.operationalanalytics.club/)! We're creating content like this all the time!", "author_fullname": "t2_nkrhcqia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL Workshop recording: Making SQL more efficient, readable, and easier to debug", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y6n37d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 79, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 79, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666041634.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.linkedin.com/in/ergestxheblati/\"&gt;Ergest Xheblati&lt;/a&gt; is the author of &lt;a href=\"https://ergestx.gumroad.com/l/sqlpatterns\"&gt;&lt;em&gt;Minimum Viable SQL Patterns&lt;/em&gt;&lt;/a&gt;, and he&amp;#39;s spent the last 15 years mastering SQL.  &lt;/p&gt;\n\n&lt;p&gt;In this &lt;a href=\"https://youtu.be/UFiZx5NlzL4\"&gt;SQL workshop&lt;/a&gt;, Ergest teaches various SQL principles (patters) to help you take your SQL skills from intermediate to expert. More specifically, you&amp;#39;ll learn about:&lt;br/&gt;\n\ud83c\udfaf Query composition patterns - How to make your complex queries shorter, more legible, and more performant&lt;br/&gt;\n\ud83c\udfaf Query maintainability patterns - Constructing CTEs that can be reused. In software engineering, it&amp;#39;s called the DRY principle (don&amp;#39;t repeat yourself)&lt;br/&gt;\n\ud83c\udfaf Query robustness patterns - Constructing queries that don&amp;#39;t break when the underlying data changes in unpredictable ways&lt;br/&gt;\n\ud83c\udfaf Query performance patterns - Make your queries faster (and cheaper) regardless of specific database you\u2019re using.&lt;/p&gt;\n\n&lt;p&gt;Toward the end of the workshop, Ergest answers over a dozen questions from SQL professionals all over the world.  &lt;/p&gt;\n\n&lt;p&gt;Watch the full workshop \ud83d\udc49 &lt;a href=\"https://www.youtube.com/watch?v=UFiZx5NlzL4\"&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt; \ud83d\udc48. It&amp;#39;s free, and don&amp;#39;t worry, you&amp;#39;re not being sold on a SaaS product \ud83e\udd23  &lt;/p&gt;\n\n&lt;p&gt;If you enjoyed this video, please join Ergest and +1,000 like minded data professionals in our Slack Community, the &lt;a href=\"https://www.operationalanalytics.club/\"&gt;OA Club&lt;/a&gt;! We&amp;#39;re creating content like this all the time!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 125, "id": "award_5f123e3d-4f48-42f4-9c11-e98b566d5897", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "When you come across a feel-good thing.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Wholesome", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "y6n37d", "is_robot_indexable": true, "report_reasons": null, "author": "JParkerRogers", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y6n37d/sql_workshop_recording_making_sql_more_efficient/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y6n37d/sql_workshop_recording_making_sql_more_efficient/", "subreddit_subscribers": 76899, "created_utc": 1666041634.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been an analyst for about 3 years mostly using SQL, Python, and building Dashboards. I built and automated few dev tables before to base dashboards on but nothing major.\n\nI am considering trying to transition into a Data engineering role, but I have a business degree. Have anyone had a similar experience and can advise on good resources or how possible the transition is?", "author_fullname": "t2_lus61uk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggestions to Transition from Data Analyst to Data Engineering role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y6yj65", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666072978.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been an analyst for about 3 years mostly using SQL, Python, and building Dashboards. I built and automated few dev tables before to base dashboards on but nothing major.&lt;/p&gt;\n\n&lt;p&gt;I am considering trying to transition into a Data engineering role, but I have a business degree. Have anyone had a similar experience and can advise on good resources or how possible the transition is?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "y6yj65", "is_robot_indexable": true, "report_reasons": null, "author": "mohamedk97", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y6yj65/suggestions_to_transition_from_data_analyst_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y6yj65/suggestions_to_transition_from_data_analyst_to/", "subreddit_subscribers": 76899, "created_utc": 1666072978.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_casbd3z4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Puffin file format in Apache Iceberg. Wait we had Parquet, ORC, did we need a new one?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 94, "top_awarded_type": null, "hide_score": false, "name": "t3_y6s2io", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/X1Xcqwnqz4J6lSuL-Q1WH_9zqvRi_ijj1-5jSVFnsq8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666054216.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dremio.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.dremio.com/subsurface/puffins-and-icebergs-additional-stats-for-apache-iceberg-tables/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hbo3VOEKWtjZ8oJhpBPPT5lK3SC4Rhu5TA1GCkdt_Zg.jpg?auto=webp&amp;s=8b558d948a954242d64d0e491f4fea5a5dbb3b05", "width": 1024, "height": 691}, "resolutions": [{"url": "https://external-preview.redd.it/hbo3VOEKWtjZ8oJhpBPPT5lK3SC4Rhu5TA1GCkdt_Zg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bbc343f6a1d835e09d06acf2b0bc78a9a65b902a", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/hbo3VOEKWtjZ8oJhpBPPT5lK3SC4Rhu5TA1GCkdt_Zg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=296d840cd564a562b13945b68a19282d689e9531", "width": 216, "height": 145}, {"url": "https://external-preview.redd.it/hbo3VOEKWtjZ8oJhpBPPT5lK3SC4Rhu5TA1GCkdt_Zg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7b486115585c22fb1016ae93a59b81b22f913e37", "width": 320, "height": 215}, {"url": "https://external-preview.redd.it/hbo3VOEKWtjZ8oJhpBPPT5lK3SC4Rhu5TA1GCkdt_Zg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b0f86f1de4eaa1dea35736eb28fc0a8921a47ca6", "width": 640, "height": 431}, {"url": "https://external-preview.redd.it/hbo3VOEKWtjZ8oJhpBPPT5lK3SC4Rhu5TA1GCkdt_Zg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=558ea21d03040367eb64bd7ea3fbaa77f9077a7f", "width": 960, "height": 647}], "variants": {}, "id": "pGtVg6Wxc7afuym6mlmo1vIZUwqvCqEWpamsl0p8ROc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "y6s2io", "is_robot_indexable": true, "report_reasons": null, "author": "Altruistic-Judge-506", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y6s2io/puffin_file_format_in_apache_iceberg_wait_we_had/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.dremio.com/subsurface/puffins-and-icebergs-additional-stats-for-apache-iceberg-tables/", "subreddit_subscribers": 76899, "created_utc": 1666054216.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Open Source Intelligence has opportunities like Trace Labs where volunteers give time to help locate missing persons.\n\nTrace Labs is okay training up noobs, who can skill up and network.\n\nAre there any orgs out there looking for this type of work in Data Engineering? Or any Discords/Slack where matchmaking happens ? (For all skill levels from noob up to FANG god mode).", "author_fullname": "t2_t2wl82bi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any volunteer opportunities in Data Engineering to skill up ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y6oavn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666044482.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Open Source Intelligence has opportunities like Trace Labs where volunteers give time to help locate missing persons.&lt;/p&gt;\n\n&lt;p&gt;Trace Labs is okay training up noobs, who can skill up and network.&lt;/p&gt;\n\n&lt;p&gt;Are there any orgs out there looking for this type of work in Data Engineering? Or any Discords/Slack where matchmaking happens ? (For all skill levels from noob up to FANG god mode).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "y6oavn", "is_robot_indexable": true, "report_reasons": null, "author": "generic-d-engineer", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y6oavn/any_volunteer_opportunities_in_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y6oavn/any_volunteer_opportunities_in_data_engineering/", "subreddit_subscribers": 76899, "created_utc": 1666044482.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For a project I am working on, I need to test out ways to implement a feature - user uploads a Excel file from a UI and it gets uploaded to blob storage. From blob, it has to be copied to a Table.\n\nOn way is:\nAs soon as it loads to blob, it should trigger the pipeline which loads the data into a table. \n\nI know the basic structure but would like more expert advice on this. \n\nMy question is:\nWhat all things should I keep in mind while designing this pipeline? \n\nWhat all activities in data factory will be needed? \n\nIn the current system, most of the triggers to other pipelines are conducted by Azure functions. Will a event based trigger work better instead? \n\nI can share more details if you need that to answer.", "author_fullname": "t2_6qiqr02t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure Blob to SQL DB - ideas?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y6v0kw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666062304.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For a project I am working on, I need to test out ways to implement a feature - user uploads a Excel file from a UI and it gets uploaded to blob storage. From blob, it has to be copied to a Table.&lt;/p&gt;\n\n&lt;p&gt;On way is:\nAs soon as it loads to blob, it should trigger the pipeline which loads the data into a table. &lt;/p&gt;\n\n&lt;p&gt;I know the basic structure but would like more expert advice on this. &lt;/p&gt;\n\n&lt;p&gt;My question is:\nWhat all things should I keep in mind while designing this pipeline? &lt;/p&gt;\n\n&lt;p&gt;What all activities in data factory will be needed? &lt;/p&gt;\n\n&lt;p&gt;In the current system, most of the triggers to other pipelines are conducted by Azure functions. Will a event based trigger work better instead? &lt;/p&gt;\n\n&lt;p&gt;I can share more details if you need that to answer.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y6v0kw", "is_robot_indexable": true, "report_reasons": null, "author": "Ashysh", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y6v0kw/azure_blob_to_sql_db_ideas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y6v0kw/azure_blob_to_sql_db_ideas/", "subreddit_subscribers": 76899, "created_utc": 1666062304.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've got a lot of BI/DA YoE. Switching to DE. Want to jump in with both feet but already feeling imposter syndrome before even starting.\n\nI figured I'd do an ETL project a few different ways to learn tooling. Plan is to learn Terraform first to set up some EC2 instance, dev there, then grow it to add lambdas / S3 / DBs... Eventually maybe even rebuild it in Glue\n\nAm I wasting my time learning Terraform? I feel somewhat comfortable with the AWS CLI, but building stuff up and tearing it down with bash seems like an easy way to screw up as the infra gets bigger. At the same time, expanding an existing stack seems like the exact use case for TF. But I don't know if that's too DevOps-y for a crunched timeline", "author_fullname": "t2_dxmxxpnb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "1 Month to get up to speed on DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y6x8iw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666068826.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got a lot of BI/DA YoE. Switching to DE. Want to jump in with both feet but already feeling imposter syndrome before even starting.&lt;/p&gt;\n\n&lt;p&gt;I figured I&amp;#39;d do an ETL project a few different ways to learn tooling. Plan is to learn Terraform first to set up some EC2 instance, dev there, then grow it to add lambdas / S3 / DBs... Eventually maybe even rebuild it in Glue&lt;/p&gt;\n\n&lt;p&gt;Am I wasting my time learning Terraform? I feel somewhat comfortable with the AWS CLI, but building stuff up and tearing it down with bash seems like an easy way to screw up as the infra gets bigger. At the same time, expanding an existing stack seems like the exact use case for TF. But I don&amp;#39;t know if that&amp;#39;s too DevOps-y for a crunched timeline&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y6x8iw", "is_robot_indexable": true, "report_reasons": null, "author": "NotAfraidToAsk_", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y6x8iw/1_month_to_get_up_to_speed_on_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y6x8iw/1_month_to_get_up_to_speed_on_de/", "subreddit_subscribers": 76899, "created_utc": 1666068826.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is my first time working with AWS, I\u2019m thinking to use Google Cloud Composer after some research and consideration. Flow will be from S3 to GCS then BQ.\n\nProblem:\nJSON fields contain \u2018invalid\u2019 characters restricted in BigQuery (ie, hyphen), changing the field names in each files seem inefficient for a bunch of files and future increment.\n\nCan anyone help to suggest or recommend ways to do this more effectively? \n\nI read about BigQuery Omni and BigQuery Data Transfer Service but unfortunately these options are not open to me at the moment due to access permission.", "author_fullname": "t2_7ya53d99", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Load S3 JSON Gzipped Files into BigQuery", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y70v8a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666083606.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666081177.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is my first time working with AWS, I\u2019m thinking to use Google Cloud Composer after some research and consideration. Flow will be from S3 to GCS then BQ.&lt;/p&gt;\n\n&lt;p&gt;Problem:\nJSON fields contain \u2018invalid\u2019 characters restricted in BigQuery (ie, hyphen), changing the field names in each files seem inefficient for a bunch of files and future increment.&lt;/p&gt;\n\n&lt;p&gt;Can anyone help to suggest or recommend ways to do this more effectively? &lt;/p&gt;\n\n&lt;p&gt;I read about BigQuery Omni and BigQuery Data Transfer Service but unfortunately these options are not open to me at the moment due to access permission.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y70v8a", "is_robot_indexable": true, "report_reasons": null, "author": "FarRiver9415", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y70v8a/load_s3_json_gzipped_files_into_bigquery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y70v8a/load_s3_json_gzipped_files_into_bigquery/", "subreddit_subscribers": 76899, "created_utc": 1666081177.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I'm wondering what people have been using to train and deploy their Data Science pipelines and models. \n\nI have looked at a couple of solutions like MLFlow and PyCaret. However, I found these missing some important pieces. \n\n\\- RepeatedCrossValidation\n\n\\- Setting parameters for Scalers\n\n\\- Access the model and interpret SHAP. \n\nI have been trying out with PDPipe, but putting it in production is difficult because I can't export pipelines with lambda functions with pickle, only with Dill.\n\nOnce we try to put a model in production in a Docker container, we have to retrain the model in the Docker container, and also depend on libraries that are used for training but not required for inference, making the container much bigger than required.\n\nAnyone has any advise?", "author_fullname": "t2_52iwujry", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Deploy pipeline and model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y79ive", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666105423.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m wondering what people have been using to train and deploy their Data Science pipelines and models. &lt;/p&gt;\n\n&lt;p&gt;I have looked at a couple of solutions like MLFlow and PyCaret. However, I found these missing some important pieces. &lt;/p&gt;\n\n&lt;p&gt;- RepeatedCrossValidation&lt;/p&gt;\n\n&lt;p&gt;- Setting parameters for Scalers&lt;/p&gt;\n\n&lt;p&gt;- Access the model and interpret SHAP. &lt;/p&gt;\n\n&lt;p&gt;I have been trying out with PDPipe, but putting it in production is difficult because I can&amp;#39;t export pipelines with lambda functions with pickle, only with Dill.&lt;/p&gt;\n\n&lt;p&gt;Once we try to put a model in production in a Docker container, we have to retrain the model in the Docker container, and also depend on libraries that are used for training but not required for inference, making the container much bigger than required.&lt;/p&gt;\n\n&lt;p&gt;Anyone has any advise?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y79ive", "is_robot_indexable": true, "report_reasons": null, "author": "Groundbreaking_Dog47", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y79ive/deploy_pipeline_and_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y79ive/deploy_pipeline_and_model/", "subreddit_subscribers": 76899, "created_utc": 1666105423.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been using dbt heavily in my Snowflake Data Warehouse. My dbt models are all SQL-based but I would like them to move them python due to modularity and hiring python devs is easier than SQL.\n\nI know dbt released support for python but the docs are almost non-existent and very few community articles. Also, Snowflake announced Snowpark for letting users write python. \n\nCan I just use Snowpark and eliminate dbt from my stack altogether? What would be the best approach here?", "author_fullname": "t2_42hc4int", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Migrating SQL-based dbt models to python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y6pypz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666048565.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been using dbt heavily in my Snowflake Data Warehouse. My dbt models are all SQL-based but I would like them to move them python due to modularity and hiring python devs is easier than SQL.&lt;/p&gt;\n\n&lt;p&gt;I know dbt released support for python but the docs are almost non-existent and very few community articles. Also, Snowflake announced Snowpark for letting users write python. &lt;/p&gt;\n\n&lt;p&gt;Can I just use Snowpark and eliminate dbt from my stack altogether? What would be the best approach here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y6pypz", "is_robot_indexable": true, "report_reasons": null, "author": "vanillacap", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y6pypz/migrating_sqlbased_dbt_models_to_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y6pypz/migrating_sqlbased_dbt_models_to_python/", "subreddit_subscribers": 76899, "created_utc": 1666048565.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nHave a requirement to read data from Denodo (Data virtualization) tool to AWS S3 bucket. Has anyone done such integration. If so, what is the best practice/process to integrate Denodo with AWS S3 bucket. Any insight is appreciated.\n\nThanks.", "author_fullname": "t2_mspamalq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Integration of Denodo with AWS S3 bucket", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y79bnp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666104990.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;Have a requirement to read data from Denodo (Data virtualization) tool to AWS S3 bucket. Has anyone done such integration. If so, what is the best practice/process to integrate Denodo with AWS S3 bucket. Any insight is appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y79bnp", "is_robot_indexable": true, "report_reasons": null, "author": "Awsmason", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y79bnp/integration_of_denodo_with_aws_s3_bucket/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y79bnp/integration_of_denodo_with_aws_s3_bucket/", "subreddit_subscribers": 76899, "created_utc": 1666104990.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My org has petabytes stored on Amazon, and it\u2019s not even a big org. This got me thinking how much total data Amazon likely has stored on S3? Gotta be yotta-scale but could it be higher?", "author_fullname": "t2_jbae1pg4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Estimation - how much total data is stored on S3?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y6lb2v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666037589.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My org has petabytes stored on Amazon, and it\u2019s not even a big org. This got me thinking how much total data Amazon likely has stored on S3? Gotta be yotta-scale but could it be higher?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y6lb2v", "is_robot_indexable": true, "report_reasons": null, "author": "Capital_Delivery_833", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y6lb2v/estimation_how_much_total_data_is_stored_on_s3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y6lb2v/estimation_how_much_total_data_is_stored_on_s3/", "subreddit_subscribers": 76899, "created_utc": 1666037589.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im sure everyone here hates spreadsheets and wants to avoid them like the plague. With that in mind, what is the best implementation of taking data from a spreadsheet and loading it into snowflake or big query?\n\nI'm looking to design a tool to enable other teams that need this capability, and want to avoid insane maintenance. How do you handle: \n\n* incremental vs truncate/replace\n* schema change \n* merged headers/footers\n\nEtc in a way that would be as most self service / minimal developer involvement? \n\nCurious to see how other DE people have had to tackle this \ud83d\ude05", "author_fullname": "t2_5e0ue", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the best/most reliable way implementation of spreadsheet to database pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y6i24o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666029981.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im sure everyone here hates spreadsheets and wants to avoid them like the plague. With that in mind, what is the best implementation of taking data from a spreadsheet and loading it into snowflake or big query?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking to design a tool to enable other teams that need this capability, and want to avoid insane maintenance. How do you handle: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;incremental vs truncate/replace&lt;/li&gt;\n&lt;li&gt;schema change &lt;/li&gt;\n&lt;li&gt;merged headers/footers&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Etc in a way that would be as most self service / minimal developer involvement? &lt;/p&gt;\n\n&lt;p&gt;Curious to see how other DE people have had to tackle this \ud83d\ude05&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y6i24o", "is_robot_indexable": true, "report_reasons": null, "author": "harrytrumanprimate", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y6i24o/what_is_the_bestmost_reliable_way_implementation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y6i24o/what_is_the_bestmost_reliable_way_implementation/", "subreddit_subscribers": 76899, "created_utc": 1666029981.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_pl4q8ng7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt launches its semantic layer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": true, "name": "t3_y7btdx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/8NloFZR3WRGKxevhoZW6mo8nw1JWr93wXuZxtuAN0gQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666110786.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "getdbt.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.getdbt.com/blog/frontiers-of-the-dbt-semantic-layer", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?auto=webp&amp;s=edabdd18634aef29128ecc0d5693053ba1a95f6e", "width": 2560, "height": 1440}, "resolutions": [{"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5df6a50eec64ce3d126f3a47e1746feaf267cebb", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6d02b260d5dddd4e2e7c80420970b653c3cdddab", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=aa646e05e744be5f524016d4c775b326ef90c2d1", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e29469bfc58fee1f76e41ce74322e006445b9bb6", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f7b72e416c6ef27bd12b9f3a5a19ef15ad9e8249", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=285b785bfdba2ba6f0da014cf261fbe2d5f57f3d", "width": 1080, "height": 607}], "variants": {}, "id": "1atsLEhqeX9kFaissrSt8acZk9ienTNBpjUXMcidAMU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y7btdx", "is_robot_indexable": true, "report_reasons": null, "author": "droppedorphan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y7btdx/dbt_launches_its_semantic_layer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.getdbt.com/blog/frontiers-of-the-dbt-semantic-layer", "subreddit_subscribers": 76899, "created_utc": 1666110786.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im a data engineer in a big company in korea, and am trying to move to us. I have 2 yr experience and used airflow spark-scala, hadoop, neo4j and have some experience building an api server. \nI am looking for a junior de opening, but not sure how to check if they accept foreigners and the visa work problem any tips on this matter and how to go on with this issue?", "author_fullname": "t2_8zbu75fr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how to ind us jobs as foreigner", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_y7bqk3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666110613.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im a data engineer in a big company in korea, and am trying to move to us. I have 2 yr experience and used airflow spark-scala, hadoop, neo4j and have some experience building an api server. \nI am looking for a junior de opening, but not sure how to check if they accept foreigners and the visa work problem any tips on this matter and how to go on with this issue?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y7bqk3", "is_robot_indexable": true, "report_reasons": null, "author": "Kakao_Trees", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y7bqk3/how_to_ind_us_jobs_as_foreigner/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y7bqk3/how_to_ind_us_jobs_as_foreigner/", "subreddit_subscribers": 76899, "created_utc": 1666110613.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently my company is using SQL server and FME/python to get and push data to and from salesforce but it doesn\u2019t seem like the best solution. Wondering what would be a better solution for this? Im more comfortable with Python/SQL but my company wants to focus more on low code/ETL tools like FME or boomi.", "author_fullname": "t2_wojey", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What ETL tool or process are you using for salesforce pipeline?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_y7a92p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666107116.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently my company is using SQL server and FME/python to get and push data to and from salesforce but it doesn\u2019t seem like the best solution. Wondering what would be a better solution for this? Im more comfortable with Python/SQL but my company wants to focus more on low code/ETL tools like FME or boomi.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y7a92p", "is_robot_indexable": true, "report_reasons": null, "author": "Stonedsurfer", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y7a92p/what_etl_tool_or_process_are_you_using_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y7a92p/what_etl_tool_or_process_are_you_using_for/", "subreddit_subscribers": 76899, "created_utc": 1666107116.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_eogs2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The technical obstacles of Data Mesh in 2022", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y74bfd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1666092085.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "ansilo.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://ansilo.io/blog/the-technical-obstacles-of-data-mesh-in-2022", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "y74bfd", "is_robot_indexable": true, "report_reasons": null, "author": "TimeToogo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y74bfd/the_technical_obstacles_of_data_mesh_in_2022/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://ansilo.io/blog/the-technical-obstacles-of-data-mesh-in-2022", "subreddit_subscribers": 76899, "created_utc": 1666092085.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I plan on starting my own Data Engineering blog and am wondering what kind of tutorials people prefer to learn from.   \nPlease do comment below if you think there is a particular topic that currently doesn't have good tutorials out there. Thank you!  \n\n[View Poll](https://www.reddit.com/poll/y6kl1r)", "author_fullname": "t2_3tsn4xyv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What kind of tutorials do you prefer to learn from?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y6kl1r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666035939.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I plan on starting my own Data Engineering blog and am wondering what kind of tutorials people prefer to learn from.&lt;br/&gt;\nPlease do comment below if you think there is a particular topic that currently doesn&amp;#39;t have good tutorials out there. Thank you!  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/y6kl1r\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "y6kl1r", "is_robot_indexable": true, "report_reasons": null, "author": "brownstrom", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1666295139629, "options": [{"text": "Videos", "id": "19207688"}, {"text": "Blog (Text)", "id": "19207689"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 153, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/y6kl1r/what_kind_of_tutorials_do_you_prefer_to_learn_from/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/y6kl1r/what_kind_of_tutorials_do_you_prefer_to_learn_from/", "subreddit_subscribers": 76899, "created_utc": 1666035939.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello All,\n\nI have a manual airflow job which has a pyspark job.  This job needs a date parameter currently, I need to update my code manually and then run the spark job. How can I pass this date value from airflow?", "author_fullname": "t2_ix7cgn3y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how to pass date parameter from airflow to spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y6i8ua", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666030426.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello All,&lt;/p&gt;\n\n&lt;p&gt;I have a manual airflow job which has a pyspark job.  This job needs a date parameter currently, I need to update my code manually and then run the spark job. How can I pass this date value from airflow?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y6i8ua", "is_robot_indexable": true, "report_reasons": null, "author": "bommu99", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y6i8ua/how_to_pass_date_parameter_from_airflow_to_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y6i8ua/how_to_pass_date_parameter_from_airflow_to_spark/", "subreddit_subscribers": 76899, "created_utc": 1666030426.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, currently learning SQL. I intend to become a data engineer. Should I continue down this path or go for the  Aws cloud practioneer cert?", "author_fullname": "t2_7a6p4jkb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y6reqa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666052400.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, currently learning SQL. I intend to become a data engineer. Should I continue down this path or go for the  Aws cloud practioneer cert?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y6reqa", "is_robot_indexable": true, "report_reasons": null, "author": "Specialist-Ask8890", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y6reqa/sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y6reqa/sql/", "subreddit_subscribers": 76899, "created_utc": 1666052400.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Vote :)\n\n[View Poll](https://www.reddit.com/poll/y6imum)", "author_fullname": "t2_8dnn00ks", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What\u2019s your Favourite Cloud Provider for Data Engineering and why?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y6imum", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666031335.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Vote :)&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/y6imum\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y6imum", "is_robot_indexable": true, "report_reasons": null, "author": "Se7enEl11ven", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1666290535853, "options": [{"text": "GCP", "id": "19206006"}, {"text": "Aws", "id": "19206007"}, {"text": "Azure", "id": "19206008"}, {"text": "Other (comment)", "id": "19206009"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 196, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y6imum/whats_your_favourite_cloud_provider_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/y6imum/whats_your_favourite_cloud_provider_for_data/", "subreddit_subscribers": 76899, "created_utc": 1666031335.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "so before i test it does anyone know what will happen to phone (a) which Is a iPhone will the iPhone just prevent it from happing or will it render the phone useless until wiped and how about phone b which is just a pixel 6 will it do the same and the zip bomb file is one of mine own designs, and its only 59 MBs into 250's TBs (ik i could have done better with the compression but my laptop was lagging hard making it) and if i do send it to my test phones is there a way to prevent them from any damage by like a security software or app before the unzipping i did try to find out on online what could happen but i could not find the best results", "author_fullname": "t2_gfw0yjn5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "testing a zip bomb on two phones", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y78g6v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666102980.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;so before i test it does anyone know what will happen to phone (a) which Is a iPhone will the iPhone just prevent it from happing or will it render the phone useless until wiped and how about phone b which is just a pixel 6 will it do the same and the zip bomb file is one of mine own designs, and its only 59 MBs into 250&amp;#39;s TBs (ik i could have done better with the compression but my laptop was lagging hard making it) and if i do send it to my test phones is there a way to prevent them from any damage by like a security software or app before the unzipping i did try to find out on online what could happen but i could not find the best results&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y78g6v", "is_robot_indexable": true, "report_reasons": null, "author": "bossqueenelsibith", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y78g6v/testing_a_zip_bomb_on_two_phones/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y78g6v/testing_a_zip_bomb_on_two_phones/", "subreddit_subscribers": 76899, "created_utc": 1666102980.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}