{"kind": "Listing", "data": {"after": "t3_y6r3pz", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "The `data \\w+` gold rush has been a blessing and a curse, blessing in that many of us are getting filthy rich off it, curse in that many (frankly unskilled) people see the job market and think \u201cwow I gotta get me a piece of that\u201d and proceed to bombard every specialist board with mentorship requests and e-begging for a crumb of interview. \n\nFrankly I wouldn\u2019t mind this if the people asking had done some cursory research beforehand and asked politely, but it seems like every jerkoff who\u2019s caught a whiff of an Excel spreadsheet thinks they can land a FAANG job overnight and, instead of looking on Google for \u201chow to data job pls to help\u201d and seeing the ten trillion useless Medium articles made by the endless morons trying to resume pad and slip their jimmy into an Amazon L3 role that would tell them practically everything they need to know (even if by and large anything posted on Medium is worthless) they choose to pepper subs like /r/dataengineering, /r/dataanalysis, and this one with the same \u201chow to data job please give me six figures\u201d - it\u2019s like asking /r/personalfinance \u201chelp how do I own a bank account\u201d repeated for every hapless schmuck who\u2019s been hiding their Benjamins in granny\u2019s cookie tin for the last sixteen years of their childhood. \n\nNot even getting into the fact that doing basic research on the topic at hand is probably *the* fundamental skill for any data-*whatever* role, what\u2019s even funnier is that I\u2019d hazard a guess that most of us who *actually work in the industry* have better things to do during the day, so the people answering questions are probably majority kids trying to get their first data-whatever job - blind leading the blind all over again. \n\nTLDR: Screw you guys I\u2019m going to /r/Statistics", "author_fullname": "t2_gtodeuwk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[UNHINGED RANT] It\u2019s kind of annoying to see that, in general, most data-related spaces are flush with \u201chow do I get a job\u201d and comparatively little discussion around the actual topic", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "meta", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y6w5ab", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 437, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meta", "can_mod_post": false, "score": 437, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666065579.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The &lt;code&gt;data \\w+&lt;/code&gt; gold rush has been a blessing and a curse, blessing in that many of us are getting filthy rich off it, curse in that many (frankly unskilled) people see the job market and think \u201cwow I gotta get me a piece of that\u201d and proceed to bombard every specialist board with mentorship requests and e-begging for a crumb of interview. &lt;/p&gt;\n\n&lt;p&gt;Frankly I wouldn\u2019t mind this if the people asking had done some cursory research beforehand and asked politely, but it seems like every jerkoff who\u2019s caught a whiff of an Excel spreadsheet thinks they can land a FAANG job overnight and, instead of looking on Google for \u201chow to data job pls to help\u201d and seeing the ten trillion useless Medium articles made by the endless morons trying to resume pad and slip their jimmy into an Amazon L3 role that would tell them practically everything they need to know (even if by and large anything posted on Medium is worthless) they choose to pepper subs like &lt;a href=\"/r/dataengineering\"&gt;/r/dataengineering&lt;/a&gt;, &lt;a href=\"/r/dataanalysis\"&gt;/r/dataanalysis&lt;/a&gt;, and this one with the same \u201chow to data job please give me six figures\u201d - it\u2019s like asking &lt;a href=\"/r/personalfinance\"&gt;/r/personalfinance&lt;/a&gt; \u201chelp how do I own a bank account\u201d repeated for every hapless schmuck who\u2019s been hiding their Benjamins in granny\u2019s cookie tin for the last sixteen years of their childhood. &lt;/p&gt;\n\n&lt;p&gt;Not even getting into the fact that doing basic research on the topic at hand is probably &lt;em&gt;the&lt;/em&gt; fundamental skill for any data-&lt;em&gt;whatever&lt;/em&gt; role, what\u2019s even funnier is that I\u2019d hazard a guess that most of us who &lt;em&gt;actually work in the industry&lt;/em&gt; have better things to do during the day, so the people answering questions are probably majority kids trying to get their first data-whatever job - blind leading the blind all over again. &lt;/p&gt;\n\n&lt;p&gt;TLDR: Screw you guys I\u2019m going to &lt;a href=\"/r/Statistics\"&gt;/r/Statistics&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y6w5ab", "is_robot_indexable": true, "report_reasons": null, "author": "sigma_hyperborean", "discussion_type": null, "num_comments": 94, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y6w5ab/unhinged_rant_its_kind_of_annoying_to_see_that_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y6w5ab/unhinged_rant_its_kind_of_annoying_to_see_that_in/", "subreddit_subscribers": 814161, "created_utc": 1666065579.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I was recently hired as the first (and only) data scientist for a municipal government. My position will essentially be starting from a totally blank slate: other city employees are familiar with Microsoft Power BI and Excel, and that's it. \n\nMy question is this: what languages and/or software tools should I set up as the \"standard\" going forward? I have mediocre Python skills, and I'm *very* good with R, but I'm worried that R is maybe too niche to build a whole DS program around? Maybe it's asking too much to expect future city employees to be familiar with R?\n\nOn the other hand, I'm not sure I will *ever* have other DS-inclined coworkers... So maybe this is a moot point? If I want to cater my code to my real coworkers, is either R or Python better at interacting with Microsoft Excel (meeting them where they are)? Sorry if this is a weird set of questions, I just want to try and think things through before I go too far down any path, hopefully to \"future proof\" my work.", "author_fullname": "t2_7nhni", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Starting a city government DS program: which language should I use?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y6nr7c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666043207.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was recently hired as the first (and only) data scientist for a municipal government. My position will essentially be starting from a totally blank slate: other city employees are familiar with Microsoft Power BI and Excel, and that&amp;#39;s it. &lt;/p&gt;\n\n&lt;p&gt;My question is this: what languages and/or software tools should I set up as the &amp;quot;standard&amp;quot; going forward? I have mediocre Python skills, and I&amp;#39;m &lt;em&gt;very&lt;/em&gt; good with R, but I&amp;#39;m worried that R is maybe too niche to build a whole DS program around? Maybe it&amp;#39;s asking too much to expect future city employees to be familiar with R?&lt;/p&gt;\n\n&lt;p&gt;On the other hand, I&amp;#39;m not sure I will &lt;em&gt;ever&lt;/em&gt; have other DS-inclined coworkers... So maybe this is a moot point? If I want to cater my code to my real coworkers, is either R or Python better at interacting with Microsoft Excel (meeting them where they are)? Sorry if this is a weird set of questions, I just want to try and think things through before I go too far down any path, hopefully to &amp;quot;future proof&amp;quot; my work.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y6nr7c", "is_robot_indexable": true, "report_reasons": null, "author": "dankatheist420", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y6nr7c/starting_a_city_government_ds_program_which/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y6nr7c/starting_a_city_government_ds_program_which/", "subreddit_subscribers": 814161, "created_utc": 1666043207.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am trying to use nltk VADER to do sentiment analysis to see the emotions associated with a certain word. For example, let\u2019s say the keyword is \u201cpizza\u201d. Unfortunately, If I were the analyze the sentence \n\n\u201cI hate broccoli, carrots, and turnips, and fries are awful, although pizza is delicious\u201d\n\nIt would have a fairly high \u201cnegative\u201d score because the sentence, overall, is fairly negative. However, clearly there is actually positive sentiment towards the keyword \u201cpizza\u201d. Is there a specific model or a clever way to analyze the sentiment toward a particular word like this?", "author_fullname": "t2_g7jmnu5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sentiment analysis for a single keyword", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y6dyla", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666020327.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to use nltk VADER to do sentiment analysis to see the emotions associated with a certain word. For example, let\u2019s say the keyword is \u201cpizza\u201d. Unfortunately, If I were the analyze the sentence &lt;/p&gt;\n\n&lt;p&gt;\u201cI hate broccoli, carrots, and turnips, and fries are awful, although pizza is delicious\u201d&lt;/p&gt;\n\n&lt;p&gt;It would have a fairly high \u201cnegative\u201d score because the sentence, overall, is fairly negative. However, clearly there is actually positive sentiment towards the keyword \u201cpizza\u201d. Is there a specific model or a clever way to analyze the sentiment toward a particular word like this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y6dyla", "is_robot_indexable": true, "report_reasons": null, "author": "_hairyberry_", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y6dyla/sentiment_analysis_for_a_single_keyword/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y6dyla/sentiment_analysis_for_a_single_keyword/", "subreddit_subscribers": 814161, "created_utc": 1666020327.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm just going to make up an example here.  Imagine you want to predict a stock price.  Your feature is today's price and your target is tomorrow's price.  \n\nHere would be a simple case:\nFeature = [100, 105, 110, 115, 120...]\nTarget = [105, 110, 115, 120, 125...]\n\nAre we allowed to do cross validation on this?  \n\nEven though we are never using future data to predict the past, I still feel like cross validation should not be allowed in this case.  Better approaches would be a walk-forward validation or a rolling window validation.  \n\nAm I correct in my assumption that cross validation should not be allowed?", "author_fullname": "t2_cn54oiy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cross Validation with Time Series", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y6v261", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666062429.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m just going to make up an example here.  Imagine you want to predict a stock price.  Your feature is today&amp;#39;s price and your target is tomorrow&amp;#39;s price.  &lt;/p&gt;\n\n&lt;p&gt;Here would be a simple case:\nFeature = [100, 105, 110, 115, 120...]\nTarget = [105, 110, 115, 120, 125...]&lt;/p&gt;\n\n&lt;p&gt;Are we allowed to do cross validation on this?  &lt;/p&gt;\n\n&lt;p&gt;Even though we are never using future data to predict the past, I still feel like cross validation should not be allowed in this case.  Better approaches would be a walk-forward validation or a rolling window validation.  &lt;/p&gt;\n\n&lt;p&gt;Am I correct in my assumption that cross validation should not be allowed?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y6v261", "is_robot_indexable": true, "report_reasons": null, "author": "BlackLotus8888", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y6v261/cross_validation_with_time_series/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y6v261/cross_validation_with_time_series/", "subreddit_subscribers": 814161, "created_utc": 1666062429.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Let's say I have a sequence of terms. Each term could be any string of alphabetical characters. `['abc', 'stg', 'drT']`. Now let's say I have millions of such sequences of varying length (might be 1 term, might be 1000) and some of them are 'bad'. But their combination matters toward that badness. So I'm baselining and looking for outliers, which should have a high correlation with 'bad' in my dataset. Term might indicate 'badness' in one combination but is totally benign in another.\n\nSo that's our search-space and problem statement. I am not educated in DS. But I understand the basic idea: Correlate traits and relationships of features in one or more data-sets to answer a question / solve a problem. But which features to select? It seems like an interesting question, since as analysts we don't know everything and if we try to select feature manually, there's a good chance we might miss something. Right? There might be some combination of features which, when correlated with some combination of other features ends up being a good indicator that we wouldn't have manually expected. Maybe 3 features plotted on a 3D chart with K-Means clustering or just human viewing reveals something interesting / creates a valuable signal that we might not have guessed or tested if we were hand-picking the features we thought might be useful.\n\nSo I'm computing an exhaustive list of features globally and locally, like:\n\nHow standard / deviant is the feature locally?\n\n* local occurence count\n* local occurence as % of total local feature count\n\nHow standard / deviant is the feature globally?\n\n* global occurence count\n* global occurence count as % of global feature count\n\nHow is the feature related to other features locally?\n\n* for each term: for each other term: min distance, where distance is in terms of index\n* for each term: for each other term: max distance, where distance is in terms of index\n* for each term: for each other term: avg distance, where distance is in terms of index\n* for each term: for each other term: min distance, where distance is in terms of character count\n* for each term: for each other term: max distance, where distance is in terms of character count\n* for each term: for each other term: avg distance, where distance is in terms of character count\n\nHow globally standard / deviant is the feature's relationships to other features locally?\n\n* for each term: for each other term: min distance as % of all global min distances between these two symbols, where distance is in terms of index\n* for each term: for each other term: max distance as % of all global max distances between these two symbols, where distance is in terms of index\n* for each term: for each other term: avg distance as % of all global avg distances between these two symbols, where distance is in terms of index\n* for each term: for each other term: min distance as % of all global min distances between these two symbols, where distance is in terms of character count\n* for each term: for each other term: max distance as % of all global max distances between these two symbols, where distance is in terms of character count\n* for each term: for each other term: avg distance as % of all global avg distances between these two symbols, where distance is in terms of character count\n\nThat's the theory I'm experimenting with, planning to just produce every possible chart, perhaps thousands, and then do some simple clustering on all of them and see if features associated with known-bad sample have a statistical tendency to end up in distinct clusters in any of those plots.\n\nAm I potentially on the right track? Is this a known strategy in data science? It's my first real run-in with cleaning data, isolating / computing features, so I'm still really just shooting in the dark at this point.", "author_fullname": "t2_8yytz5qc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it sometimes a good strategy to identify / prep all possible features, model them all dynamically (with recursive code) and measure which collection of features end up correlating more often than others to identify whatever signal you're looking for?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y6txbs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666063704.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666059259.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s say I have a sequence of terms. Each term could be any string of alphabetical characters. &lt;code&gt;[&amp;#39;abc&amp;#39;, &amp;#39;stg&amp;#39;, &amp;#39;drT&amp;#39;]&lt;/code&gt;. Now let&amp;#39;s say I have millions of such sequences of varying length (might be 1 term, might be 1000) and some of them are &amp;#39;bad&amp;#39;. But their combination matters toward that badness. So I&amp;#39;m baselining and looking for outliers, which should have a high correlation with &amp;#39;bad&amp;#39; in my dataset. Term might indicate &amp;#39;badness&amp;#39; in one combination but is totally benign in another.&lt;/p&gt;\n\n&lt;p&gt;So that&amp;#39;s our search-space and problem statement. I am not educated in DS. But I understand the basic idea: Correlate traits and relationships of features in one or more data-sets to answer a question / solve a problem. But which features to select? It seems like an interesting question, since as analysts we don&amp;#39;t know everything and if we try to select feature manually, there&amp;#39;s a good chance we might miss something. Right? There might be some combination of features which, when correlated with some combination of other features ends up being a good indicator that we wouldn&amp;#39;t have manually expected. Maybe 3 features plotted on a 3D chart with K-Means clustering or just human viewing reveals something interesting / creates a valuable signal that we might not have guessed or tested if we were hand-picking the features we thought might be useful.&lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;m computing an exhaustive list of features globally and locally, like:&lt;/p&gt;\n\n&lt;p&gt;How standard / deviant is the feature locally?&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;local occurence count&lt;/li&gt;\n&lt;li&gt;local occurence as % of total local feature count&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;How standard / deviant is the feature globally?&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;global occurence count&lt;/li&gt;\n&lt;li&gt;global occurence count as % of global feature count&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;How is the feature related to other features locally?&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;for each term: for each other term: min distance, where distance is in terms of index&lt;/li&gt;\n&lt;li&gt;for each term: for each other term: max distance, where distance is in terms of index&lt;/li&gt;\n&lt;li&gt;for each term: for each other term: avg distance, where distance is in terms of index&lt;/li&gt;\n&lt;li&gt;for each term: for each other term: min distance, where distance is in terms of character count&lt;/li&gt;\n&lt;li&gt;for each term: for each other term: max distance, where distance is in terms of character count&lt;/li&gt;\n&lt;li&gt;for each term: for each other term: avg distance, where distance is in terms of character count&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;How globally standard / deviant is the feature&amp;#39;s relationships to other features locally?&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;for each term: for each other term: min distance as % of all global min distances between these two symbols, where distance is in terms of index&lt;/li&gt;\n&lt;li&gt;for each term: for each other term: max distance as % of all global max distances between these two symbols, where distance is in terms of index&lt;/li&gt;\n&lt;li&gt;for each term: for each other term: avg distance as % of all global avg distances between these two symbols, where distance is in terms of index&lt;/li&gt;\n&lt;li&gt;for each term: for each other term: min distance as % of all global min distances between these two symbols, where distance is in terms of character count&lt;/li&gt;\n&lt;li&gt;for each term: for each other term: max distance as % of all global max distances between these two symbols, where distance is in terms of character count&lt;/li&gt;\n&lt;li&gt;for each term: for each other term: avg distance as % of all global avg distances between these two symbols, where distance is in terms of character count&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;That&amp;#39;s the theory I&amp;#39;m experimenting with, planning to just produce every possible chart, perhaps thousands, and then do some simple clustering on all of them and see if features associated with known-bad sample have a statistical tendency to end up in distinct clusters in any of those plots.&lt;/p&gt;\n\n&lt;p&gt;Am I potentially on the right track? Is this a known strategy in data science? It&amp;#39;s my first real run-in with cleaning data, isolating / computing features, so I&amp;#39;m still really just shooting in the dark at this point.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y6txbs", "is_robot_indexable": true, "report_reasons": null, "author": "Jonathan-Todd", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y6txbs/is_it_sometimes_a_good_strategy_to_identify_prep/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y6txbs/is_it_sometimes_a_good_strategy_to_identify_prep/", "subreddit_subscribers": 814161, "created_utc": 1666059259.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "[Ergest Xheblati](https://www.linkedin.com/in/ergestxheblati/) is the author of [*Minimum Viable SQL Patterns*](https://ergestx.gumroad.com/l/sqlpatterns), and he's spent the last 15 years mastering SQL.  \n\nIn this [SQL workshop](https://youtu.be/UFiZx5NlzL4), Ergest teaches various SQL principles (patters) to help you take your SQL skills from intermediate to expert. More specifically, you'll learn about:   \n\ud83c\udfaf Query composition patterns - How to make your complex queries shorter, more legible, and more performant   \n\ud83c\udfaf Query maintainability patterns - Constructing CTEs that can be reused. In software engineering, it's called the DRY principle (don't repeat yourself)  \n\ud83c\udfaf Query robustness patterns - Constructing queries that don't break when the underlying data changes in unpredictable ways  \n\ud83c\udfaf Query performance patterns - Make your queries faster (and cheaper) regardless of specific database you\u2019re using.\n\nToward the end of the workshop, Ergest answers over a dozen questions from SQL professionals all over the world.  \n\nWatch the full workshop \ud83d\udc49 [**here**](https://www.youtube.com/watch?v=UFiZx5NlzL4) \ud83d\udc48. It's free, and don't worry, you're not being sold on a SaaS product \ud83e\udd23  \n\n\nIf you enjoyed this video, please join Ergest and +1,000 like minded data professionals in our Slack Community, the [OA Club](https://www.operationalanalytics.club/)! We're creating content like this all the time!", "author_fullname": "t2_nkrhcqia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL Workshop recording: Making SQL more efficient, readable, and easier to debug", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y6n2tm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666041610.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.linkedin.com/in/ergestxheblati/\"&gt;Ergest Xheblati&lt;/a&gt; is the author of &lt;a href=\"https://ergestx.gumroad.com/l/sqlpatterns\"&gt;&lt;em&gt;Minimum Viable SQL Patterns&lt;/em&gt;&lt;/a&gt;, and he&amp;#39;s spent the last 15 years mastering SQL.  &lt;/p&gt;\n\n&lt;p&gt;In this &lt;a href=\"https://youtu.be/UFiZx5NlzL4\"&gt;SQL workshop&lt;/a&gt;, Ergest teaches various SQL principles (patters) to help you take your SQL skills from intermediate to expert. More specifically, you&amp;#39;ll learn about:&lt;br/&gt;\n\ud83c\udfaf Query composition patterns - How to make your complex queries shorter, more legible, and more performant&lt;br/&gt;\n\ud83c\udfaf Query maintainability patterns - Constructing CTEs that can be reused. In software engineering, it&amp;#39;s called the DRY principle (don&amp;#39;t repeat yourself)&lt;br/&gt;\n\ud83c\udfaf Query robustness patterns - Constructing queries that don&amp;#39;t break when the underlying data changes in unpredictable ways&lt;br/&gt;\n\ud83c\udfaf Query performance patterns - Make your queries faster (and cheaper) regardless of specific database you\u2019re using.&lt;/p&gt;\n\n&lt;p&gt;Toward the end of the workshop, Ergest answers over a dozen questions from SQL professionals all over the world.  &lt;/p&gt;\n\n&lt;p&gt;Watch the full workshop \ud83d\udc49 &lt;a href=\"https://www.youtube.com/watch?v=UFiZx5NlzL4\"&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt; \ud83d\udc48. It&amp;#39;s free, and don&amp;#39;t worry, you&amp;#39;re not being sold on a SaaS product \ud83e\udd23  &lt;/p&gt;\n\n&lt;p&gt;If you enjoyed this video, please join Ergest and +1,000 like minded data professionals in our Slack Community, the &lt;a href=\"https://www.operationalanalytics.club/\"&gt;OA Club&lt;/a&gt;! We&amp;#39;re creating content like this all the time!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y6n2tm", "is_robot_indexable": true, "report_reasons": null, "author": "JParkerRogers", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y6n2tm/sql_workshop_recording_making_sql_more_efficient/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y6n2tm/sql_workshop_recording_making_sql_more_efficient/", "subreddit_subscribers": 814161, "created_utc": 1666041610.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I notice that some times after completing a really exciting/impactful project I tend to feel pretty \u2018meh\u2019 about doing other work for a bit of time (even follow on work). Do you feel the same way? I dunno, maybe I want some victory laps or something \ud83d\ude02", "author_fullname": "t2_1xj38rmh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Peaks and valleys", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y6mvcz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666041122.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I notice that some times after completing a really exciting/impactful project I tend to feel pretty \u2018meh\u2019 about doing other work for a bit of time (even follow on work). Do you feel the same way? I dunno, maybe I want some victory laps or something \ud83d\ude02&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y6mvcz", "is_robot_indexable": true, "report_reasons": null, "author": "eomar2828", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y6mvcz/peaks_and_valleys/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y6mvcz/peaks_and_valleys/", "subreddit_subscribers": 814161, "created_utc": 1666041122.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I'm relatively new to time-series modeling and am not quite sure how to approach this problem. Let's say I have data on 100 students and their 100 most recent test scores (assuming that each test is the same across all students and of varying difficulty successively), and I want to understand what kind of exponential smoothing value is optimal to predict each student's next test score.\n\nBecause there must be some information contained within the population's overall performance across tests, I want to leverage that. But am I able to do so using something like R's forecast package's ETS function? I know that it can handle a single-subject time series but how can it assess the overall alpha value given 100 subjects?", "author_fullname": "t2_21w9l2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Method for Optimal Exponential Smoothing of Time Series across samples?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y6va5a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666063062.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m relatively new to time-series modeling and am not quite sure how to approach this problem. Let&amp;#39;s say I have data on 100 students and their 100 most recent test scores (assuming that each test is the same across all students and of varying difficulty successively), and I want to understand what kind of exponential smoothing value is optimal to predict each student&amp;#39;s next test score.&lt;/p&gt;\n\n&lt;p&gt;Because there must be some information contained within the population&amp;#39;s overall performance across tests, I want to leverage that. But am I able to do so using something like R&amp;#39;s forecast package&amp;#39;s ETS function? I know that it can handle a single-subject time series but how can it assess the overall alpha value given 100 subjects?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y6va5a", "is_robot_indexable": true, "report_reasons": null, "author": "DataScience0", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y6va5a/method_for_optimal_exponential_smoothing_of_time/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y6va5a/method_for_optimal_exponential_smoothing_of_time/", "subreddit_subscribers": 814161, "created_utc": 1666063062.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "OK, I know this question will make a lot of you mad. I can see the replies now: Data science means different things at different companies, different algos are used for different contexts, Python vs R, senior vs junior roles, you're focusing on technologies and implementation while neglecting business context, etc. Yeah, I get it. My goal with this post is, with your help, to build a list of technologies/platform/skills from the broad array of what's considered data science and should be known by a DS with about 3 years of experience, in the opinion of the poster (that's you). Nothing is too broad or specific. For example, Naive Bayes, GNNs, containerization, and Docker are all valid answers (yes, I realize Docker is an implementation of containerization, and that's my point..) Please, if you would be so kind, include why you think it's important and to what depth/capability a DS with 3 years of experience should have with it. Since I'm a python person, let's exclude R from the conversation.\n\nWhy am I asking this? In full candor, I feel like I am seriously stagnating. I am really the only DS in my company, so it's very easy to lose sight of where the field is currently because so much of my job is simple excel/pandas stuff. I would potentially like to start interviewing, but I feel like I am far behind where a typical DS with my YOE would be. Like, for example, I have no clue how to use airflow or any non-AWS scheduler, every time I do anything related to ML (a very rare occurrence, unfortunately), I have completely forgotten the sklearn syntax, I know pretty much nothing about actually training an NN, I know in theory what a basic NN is, but I have no idea about graph NNs or graph databases or graph anything. I still have no clue what distinguishes a data warehouse from a database after reading countless articles. I feel like I don't even know what I don't know; for anything I do know, it's hard to tell if what I'm doing is the best practice.\n\nMany thanks in advance!", "author_fullname": "t2_i7wlt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What technologies/skills should a data scientist with ~ 3 years of experience be familiar with?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_y78uss", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666104212.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666103915.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;OK, I know this question will make a lot of you mad. I can see the replies now: Data science means different things at different companies, different algos are used for different contexts, Python vs R, senior vs junior roles, you&amp;#39;re focusing on technologies and implementation while neglecting business context, etc. Yeah, I get it. My goal with this post is, with your help, to build a list of technologies/platform/skills from the broad array of what&amp;#39;s considered data science and should be known by a DS with about 3 years of experience, in the opinion of the poster (that&amp;#39;s you). Nothing is too broad or specific. For example, Naive Bayes, GNNs, containerization, and Docker are all valid answers (yes, I realize Docker is an implementation of containerization, and that&amp;#39;s my point..) Please, if you would be so kind, include why you think it&amp;#39;s important and to what depth/capability a DS with 3 years of experience should have with it. Since I&amp;#39;m a python person, let&amp;#39;s exclude R from the conversation.&lt;/p&gt;\n\n&lt;p&gt;Why am I asking this? In full candor, I feel like I am seriously stagnating. I am really the only DS in my company, so it&amp;#39;s very easy to lose sight of where the field is currently because so much of my job is simple excel/pandas stuff. I would potentially like to start interviewing, but I feel like I am far behind where a typical DS with my YOE would be. Like, for example, I have no clue how to use airflow or any non-AWS scheduler, every time I do anything related to ML (a very rare occurrence, unfortunately), I have completely forgotten the sklearn syntax, I know pretty much nothing about actually training an NN, I know in theory what a basic NN is, but I have no idea about graph NNs or graph databases or graph anything. I still have no clue what distinguishes a data warehouse from a database after reading countless articles. I feel like I don&amp;#39;t even know what I don&amp;#39;t know; for anything I do know, it&amp;#39;s hard to tell if what I&amp;#39;m doing is the best practice.&lt;/p&gt;\n\n&lt;p&gt;Many thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y78uss", "is_robot_indexable": true, "report_reasons": null, "author": "jewami", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y78uss/what_technologiesskills_should_a_data_scientist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y78uss/what_technologiesskills_should_a_data_scientist/", "subreddit_subscribers": 814161, "created_utc": 1666103915.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Throughout my life, I haven't really known what I wanted to do as a job until now. I love the idea of working from home and I'm also excited to start learning to code, but the affordable university I have chosen doesn't have a computer science course, which would be more suited for me imo as it would be more programming oriented, however, I suppose I can program on my own in my free time.\n\nWhat they do have is the computational mathematics course, I've never heard of this before but it is heavily math based with a few programming classes sprinkled here and there. As I don't know much about these classes yet, I'd like to ask your advice if taking all of the ones listed is what will definitely help me gain the framework to have the brain of a data scientist. So here they are:\n\nSo they have calculus and analytic geometry, intro to statistic analysis and intro to discrete mathematics, matrix and linear algebra (I've heard that this one is very useful for the career), abstract algebraic structures, multivariable calculus, applied differential equations, probability I, and mathematical molding and simulation.\n\nThe reason why I listed all of them is because I want to hear your advice to know for sure if taking all of these is worth it or if some of it might be a waste. If any of you are familiar with these courses please let me know. I don't know much yet what path I should take, so any advice would be appreciated.\n\nAlso, if you can tell me what websites or links you used to study certain programming courses, or the names of books that teach them, I would like to hear it as well.\n\nThanks.", "author_fullname": "t2_jemak9dw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Going for a bachelors in computational mathematics, will this help me gain the fundamental skills to become a Data Scientist?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y6mmvo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666040587.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Throughout my life, I haven&amp;#39;t really known what I wanted to do as a job until now. I love the idea of working from home and I&amp;#39;m also excited to start learning to code, but the affordable university I have chosen doesn&amp;#39;t have a computer science course, which would be more suited for me imo as it would be more programming oriented, however, I suppose I can program on my own in my free time.&lt;/p&gt;\n\n&lt;p&gt;What they do have is the computational mathematics course, I&amp;#39;ve never heard of this before but it is heavily math based with a few programming classes sprinkled here and there. As I don&amp;#39;t know much about these classes yet, I&amp;#39;d like to ask your advice if taking all of the ones listed is what will definitely help me gain the framework to have the brain of a data scientist. So here they are:&lt;/p&gt;\n\n&lt;p&gt;So they have calculus and analytic geometry, intro to statistic analysis and intro to discrete mathematics, matrix and linear algebra (I&amp;#39;ve heard that this one is very useful for the career), abstract algebraic structures, multivariable calculus, applied differential equations, probability I, and mathematical molding and simulation.&lt;/p&gt;\n\n&lt;p&gt;The reason why I listed all of them is because I want to hear your advice to know for sure if taking all of these is worth it or if some of it might be a waste. If any of you are familiar with these courses please let me know. I don&amp;#39;t know much yet what path I should take, so any advice would be appreciated.&lt;/p&gt;\n\n&lt;p&gt;Also, if you can tell me what websites or links you used to study certain programming courses, or the names of books that teach them, I would like to hear it as well.&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y6mmvo", "is_robot_indexable": true, "report_reasons": null, "author": "SleepingPooper", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y6mmvo/going_for_a_bachelors_in_computational/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y6mmvo/going_for_a_bachelors_in_computational/", "subreddit_subscribers": 814161, "created_utc": 1666040587.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm choosing between popular methods like keybert, spacy, textrank, rake and yake to create a baseline for keyword extraction. So nothing fancy at this point. What criteria should I consider? It's going to be used on open domain scientific texts.", "author_fullname": "t2_3ow77bmq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to select a model for Keyword extraction?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y6e7nq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666020914.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m choosing between popular methods like keybert, spacy, textrank, rake and yake to create a baseline for keyword extraction. So nothing fancy at this point. What criteria should I consider? It&amp;#39;s going to be used on open domain scientific texts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y6e7nq", "is_robot_indexable": true, "report_reasons": null, "author": "soldierpie", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y6e7nq/how_to_select_a_model_for_keyword_extraction/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y6e7nq/how_to_select_a_model_for_keyword_extraction/", "subreddit_subscribers": 814161, "created_utc": 1666020914.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Someone pointed out to me recently that there isn\u2019t enough criticism of the data field. If we want data science to be a field that\u2019s taken seriously we have to call out the crap. Each week I\u2019ll be posting bad examples around data/data science. I call it Garbage In Garbage Out. \n\nThis week I discuss a survey in the UK with results that look great on TV but don\u2019t seem to hold up under scrutiny.", "author_fullname": "t2_a0kcgwo4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Terrible survey. Are 37% of teenagers in the UK being prescribed anti-depressants?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": true, "name": "t3_y79fgp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/e3nxw3Qe_ucsoopJc9ZGYIWPqbCMbVT5rMl54ELlgb0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666105214.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "datafantic.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Someone pointed out to me recently that there isn\u2019t enough criticism of the data field. If we want data science to be a field that\u2019s taken seriously we have to call out the crap. Each week I\u2019ll be posting bad examples around data/data science. I call it Garbage In Garbage Out. &lt;/p&gt;\n\n&lt;p&gt;This week I discuss a survey in the UK with results that look great on TV but don\u2019t seem to hold up under scrutiny.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.datafantic.com/garbage-in-garbage-out-2/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/K3pUJ6OObwTvMcPgH_SP2WgiL-ToFPsAXAskQORyYEE.jpg?auto=webp&amp;s=333b586bec85843aff3124f8887998eded769a16", "width": 2000, "height": 1333}, "resolutions": [{"url": "https://external-preview.redd.it/K3pUJ6OObwTvMcPgH_SP2WgiL-ToFPsAXAskQORyYEE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d453499c446fe73ff7c32a89db491c965020cf7c", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/K3pUJ6OObwTvMcPgH_SP2WgiL-ToFPsAXAskQORyYEE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=df6dc397b9085e727944f1c89e920abd7a7dd953", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/K3pUJ6OObwTvMcPgH_SP2WgiL-ToFPsAXAskQORyYEE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=27e1e1b5ac0451dc1383581a5992a25a9e8acb52", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/K3pUJ6OObwTvMcPgH_SP2WgiL-ToFPsAXAskQORyYEE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=85eed6c03c081084d60fdaa1bfd878f32f2ccc21", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/K3pUJ6OObwTvMcPgH_SP2WgiL-ToFPsAXAskQORyYEE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6d4e821be10d628723217e942f3d5788133964b2", "width": 960, "height": 639}, {"url": "https://external-preview.redd.it/K3pUJ6OObwTvMcPgH_SP2WgiL-ToFPsAXAskQORyYEE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=caa41c6a3bd367e4658ba3431e313231b2575db1", "width": 1080, "height": 719}], "variants": {}, "id": "8vDEu7IOPHxgRu6kMgw8xIohoMK7y1A2Uc0GwkihlfY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "y79fgp", "is_robot_indexable": true, "report_reasons": null, "author": "robert_ritz", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y79fgp/terrible_survey_are_37_of_teenagers_in_the_uk/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.datafantic.com/garbage-in-garbage-out-2/", "subreddit_subscribers": 814161, "created_utc": 1666105214.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "hey everyone, I need to annotate data for a relation extraction model.\n\nNever did annotation in this fashion before and tried to experiment around a little. While I am finding something that \"feels right\" to me - it would be nice if there is some (universal) guidelines to label data or possibly specifically entities or relations between entities. Do you know any articles or texts for a similar purpose before?", "author_fullname": "t2_4d143ffg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Annotation \"Bible\"?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_y78zzw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666104252.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey everyone, I need to annotate data for a relation extraction model.&lt;/p&gt;\n\n&lt;p&gt;Never did annotation in this fashion before and tried to experiment around a little. While I am finding something that &amp;quot;feels right&amp;quot; to me - it would be nice if there is some (universal) guidelines to label data or possibly specifically entities or relations between entities. Do you know any articles or texts for a similar purpose before?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y78zzw", "is_robot_indexable": true, "report_reasons": null, "author": "hardwareDE", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y78zzw/data_annotation_bible/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y78zzw/data_annotation_bible/", "subreddit_subscribers": 814161, "created_utc": 1666104252.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CYBERSOC HACKLAB PROJECT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y77rcw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_7qir32tk", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "cybersocitlibrary", "selftext": "Information technology and cyber security require a strong technical foundation in knowledge and skills. Most employees learn about the basics in school, on the job, or through training or certifications. After mastering the foundations and becoming a professional in IT and cyber security, how does one improve their knowledge? They need hands-on technical training in an isolated and secure lab environment in order to stay current and improve their technical skills. The most effective strategy for doing this is to build virtualized hacking laboratories. The CYBERSOC HACKLAB PROJECT can provide specialized training, be used to prepare employees for a scenario, and help employees in improving their technical abilities, making them better all-around technical staff. You may learn how to build your own hacking lab on this channel.\n\nSubscribe to our Channel at [https://bit.ly/3D1HkcN](https://bit.ly/3D1HkcN)  Thank you for your support and God Bless!", "author_fullname": "t2_7qir32tk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CYBERSOC HACKLAB PROJECT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/cybersocitlibrary", "hidden": false, "pwls": null, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y70yq4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666081539.0, "link_flair_type": "text", "wls": null, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.cybersocitlibrary", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Information technology and cyber security require a strong technical foundation in knowledge and skills. Most employees learn about the basics in school, on the job, or through training or certifications. After mastering the foundations and becoming a professional in IT and cyber security, how does one improve their knowledge? They need hands-on technical training in an isolated and secure lab environment in order to stay current and improve their technical skills. The most effective strategy for doing this is to build virtualized hacking laboratories. The CYBERSOC HACKLAB PROJECT can provide specialized training, be used to prepare employees for a scenario, and help employees in improving their technical abilities, making them better all-around technical staff. You may learn how to build your own hacking lab on this channel.&lt;/p&gt;\n\n&lt;p&gt;Subscribe to our Channel at &lt;a href=\"https://bit.ly/3D1HkcN\"&gt;https://bit.ly/3D1HkcN&lt;/a&gt;  Thank you for your support and God Bless!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YZwrWxk6g1GSAR3eruJk-HikT6JwKK-Yz3rR2X62g78.jpg?auto=webp&amp;s=dc4ed5cae4898ea896acb6520dc6322eb7601686", "width": 900, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/YZwrWxk6g1GSAR3eruJk-HikT6JwKK-Yz3rR2X62g78.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0dfbca34ab64640fa5feca71576dd26b74991d4e", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/YZwrWxk6g1GSAR3eruJk-HikT6JwKK-Yz3rR2X62g78.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4ca714c952db94e9c9488f9f228bfa72baa42c13", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/YZwrWxk6g1GSAR3eruJk-HikT6JwKK-Yz3rR2X62g78.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=57a888d39d000c6ddf90ee7c2c368f40302cd349", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/YZwrWxk6g1GSAR3eruJk-HikT6JwKK-Yz3rR2X62g78.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=31cc2497e7a890dc78a36c7682557e68762f09ad", "width": 640, "height": 640}], "variants": {}, "id": "XE_yW0dkHKdc-XpE5ityrR9JG1ujmll591g8v1_FXtk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_68chyo", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y70yq4", "is_robot_indexable": true, "report_reasons": null, "author": "cybersocdm", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": null, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/cybersocitlibrary/comments/y70yq4/cybersoc_hacklab_project/", "parent_whitelist_status": null, "stickied": false, "url": "https://old.reddit.com/r/cybersocitlibrary/comments/y70yq4/cybersoc_hacklab_project/", "subreddit_subscribers": 1067, "created_utc": 1666081539.0, "num_crossposts": 29, "media": null, "is_video": false}], "created": 1666101360.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.cybersocitlibrary", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/cybersocitlibrary/comments/y70yq4/cybersoc_hacklab_project/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YZwrWxk6g1GSAR3eruJk-HikT6JwKK-Yz3rR2X62g78.jpg?auto=webp&amp;s=dc4ed5cae4898ea896acb6520dc6322eb7601686", "width": 900, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/YZwrWxk6g1GSAR3eruJk-HikT6JwKK-Yz3rR2X62g78.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0dfbca34ab64640fa5feca71576dd26b74991d4e", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/YZwrWxk6g1GSAR3eruJk-HikT6JwKK-Yz3rR2X62g78.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4ca714c952db94e9c9488f9f228bfa72baa42c13", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/YZwrWxk6g1GSAR3eruJk-HikT6JwKK-Yz3rR2X62g78.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=57a888d39d000c6ddf90ee7c2c368f40302cd349", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/YZwrWxk6g1GSAR3eruJk-HikT6JwKK-Yz3rR2X62g78.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=31cc2497e7a890dc78a36c7682557e68762f09ad", "width": 640, "height": 640}], "variants": {}, "id": "XE_yW0dkHKdc-XpE5ityrR9JG1ujmll591g8v1_FXtk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y77rcw", "is_robot_indexable": true, "report_reasons": null, "author": "cybersocdm", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_y70yq4", "author_flair_text_color": null, "permalink": "/r/datascience/comments/y77rcw/cybersoc_hacklab_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/cybersocitlibrary/comments/y70yq4/cybersoc_hacklab_project/", "subreddit_subscribers": 814161, "created_utc": 1666101360.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Join us at Data Science Salon NYC on Dec 7, the only data science conference that brings together specialists in finance and technology!\n\n\ud83d\udccd Wednesday, December 7, 2022, at The Theater Center in Broadway's Theater District\n\n\ud83d\udde3\ufe0f 15 talks and panels covering cutting-edge AI and ML research and use cases\n\n\ud83c\udfa4 Speakers from S&amp;P Global, Capital One, Freddie Mac, PayPal, Point72, Morgan Stanley, Sofi, Federal Reserve Bank of NY, and many others!\n\n\ud83e\udd1d 200+ attendees, giving DSS the intimate feel where you can meet everyone you want to connect with in-person  \n\ud83d\ude4b Q&amp;A sessions with expert speakers and industry leaders Surprise act!\n\nGet your Early Bird Ticket NOW and s[ave $200: https://www.datascience.salon/newy](https://www.datascience.salon/)ork/\n\n\\#DSSNYC will be live-streamed, so make sure to save your virtual ticket if you're from outside New York.", "author_fullname": "t2_tgtv00m4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science Salon New York", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7728y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666099611.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Join us at Data Science Salon NYC on Dec 7, the only data science conference that brings together specialists in finance and technology!&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udccd Wednesday, December 7, 2022, at The Theater Center in Broadway&amp;#39;s Theater District&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udde3\ufe0f 15 talks and panels covering cutting-edge AI and ML research and use cases&lt;/p&gt;\n\n&lt;p&gt;\ud83c\udfa4 Speakers from S&amp;amp;P Global, Capital One, Freddie Mac, PayPal, Point72, Morgan Stanley, Sofi, Federal Reserve Bank of NY, and many others!&lt;/p&gt;\n\n&lt;p&gt;\ud83e\udd1d 200+ attendees, giving DSS the intimate feel where you can meet everyone you want to connect with in-person&lt;br/&gt;\n\ud83d\ude4b Q&amp;amp;A sessions with expert speakers and industry leaders Surprise act!&lt;/p&gt;\n\n&lt;p&gt;Get your Early Bird Ticket NOW and s&lt;a href=\"https://www.datascience.salon/\"&gt;ave $200: https://www.datascience.salon/newy&lt;/a&gt;ork/&lt;/p&gt;\n\n&lt;p&gt;#DSSNYC will be live-streamed, so make sure to save your virtual ticket if you&amp;#39;re from outside New York.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/t-JKUK_ceGv0adOivB2bGCUx6zQX5LchanOcgQVmKNw.jpg?auto=webp&amp;s=c7282b829922a8657dc177186e421091e54f6dd3", "width": 1200, "height": 500}, "resolutions": [{"url": "https://external-preview.redd.it/t-JKUK_ceGv0adOivB2bGCUx6zQX5LchanOcgQVmKNw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e14d52f8c9441d6d12397be2f9533e9de9f2a418", "width": 108, "height": 45}, {"url": "https://external-preview.redd.it/t-JKUK_ceGv0adOivB2bGCUx6zQX5LchanOcgQVmKNw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0c049c190048df78688e23313b63767ac9b4c9f6", "width": 216, "height": 90}, {"url": "https://external-preview.redd.it/t-JKUK_ceGv0adOivB2bGCUx6zQX5LchanOcgQVmKNw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0e41d6af74ebdb7e8035dde945d1c36e3563f2b6", "width": 320, "height": 133}, {"url": "https://external-preview.redd.it/t-JKUK_ceGv0adOivB2bGCUx6zQX5LchanOcgQVmKNw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c1a3e5b2e00d8493747e8ecf80047f048eceeceb", "width": 640, "height": 266}, {"url": "https://external-preview.redd.it/t-JKUK_ceGv0adOivB2bGCUx6zQX5LchanOcgQVmKNw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1ecf6130d7810e169e771070d2464f11e5a76962", "width": 960, "height": 400}, {"url": "https://external-preview.redd.it/t-JKUK_ceGv0adOivB2bGCUx6zQX5LchanOcgQVmKNw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=557a473858e90032d07a01367e641f78d2a3ac43", "width": 1080, "height": 450}], "variants": {}, "id": "0kkitvF1edkOQ4GdvKpOMcH102MiCaGN-LLDU_1MGL8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7728y", "is_robot_indexable": true, "report_reasons": null, "author": "TemporaryPrize198", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7728y/data_science_salon_new_york/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7728y/data_science_salon_new_york/", "subreddit_subscribers": 814161, "created_utc": 1666099611.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I want to start posting content here on Reddit once a week in a data related subreddit. Stuff like cool libraries, updated laws and regulations about handling data, and other cool stuff. It\u2019s something that\u2019ll help me learn and add value to a community that\u2019s been really helpful to me. So what kind of stuff do you want to see more of here?", "author_fullname": "t2_2gd0s9mj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are you interested in?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y770h7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666099485.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to start posting content here on Reddit once a week in a data related subreddit. Stuff like cool libraries, updated laws and regulations about handling data, and other cool stuff. It\u2019s something that\u2019ll help me learn and add value to a community that\u2019s been really helpful to me. So what kind of stuff do you want to see more of here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y770h7", "is_robot_indexable": true, "report_reasons": null, "author": "milkmanbran", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y770h7/what_are_you_interested_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y770h7/what_are_you_interested_in/", "subreddit_subscribers": 814161, "created_utc": 1666099485.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_amfdjuba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Q] If you have an input variable that has a 0.5 Pearson Correlation with the Target Variable using the whole dataset, what would be your \"expected\" test/blind set performance (in R^2) when applying a machine learning model?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y762ix", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666097058.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y762ix", "is_robot_indexable": true, "report_reasons": null, "author": "limedove", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y762ix/q_if_you_have_an_input_variable_that_has_a_05/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y762ix/q_if_you_have_an_input_variable_that_has_a_05/", "subreddit_subscribers": 814161, "created_utc": 1666097058.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My second year anniversary at Wise is just around the corner! Within this short period of time, my team of analysts grew 4.5X \ud83d\ude80 \n\nWhile there is still so much to learn, I attempted to share back a few of my wins and failures that led me to embrace some core principles around building teams.\n\nI'd love to hear if any of this resonates and any other tips &amp; tricks from my fellow Analytics / DS Leaders.", "author_fullname": "t2_iggbuh3h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to 4x your team size without it (&amp; you) falling apart", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_y75jiy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/MQgC_T10cU5KZckgwXtvPGEkS1DkOnFgK3Gfk763-44.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666095577.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "hazal-muhtar.medium.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My second year anniversary at Wise is just around the corner! Within this short period of time, my team of analysts grew 4.5X \ud83d\ude80 &lt;/p&gt;\n\n&lt;p&gt;While there is still so much to learn, I attempted to share back a few of my wins and failures that led me to embrace some core principles around building teams.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to hear if any of this resonates and any other tips &amp;amp; tricks from my fellow Analytics / DS Leaders.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://hazal-muhtar.medium.com/how-to-4x-your-team-size-without-it-you-falling-apart-bff7fe8d90e3", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7X7AVL3Wqys9XaPTh_-d89YQP5ZO8tQZtjS2ZVtlKTE.jpg?auto=webp&amp;s=936b39c7bc0731d905eef7acb8b8841c34b19455", "width": 1200, "height": 799}, "resolutions": [{"url": "https://external-preview.redd.it/7X7AVL3Wqys9XaPTh_-d89YQP5ZO8tQZtjS2ZVtlKTE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ac710808e9bc1c8bae91a0c7846c19cd6bca2f35", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/7X7AVL3Wqys9XaPTh_-d89YQP5ZO8tQZtjS2ZVtlKTE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d612f28cd7704f6917a525fa60a406a2d7e6c3fc", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/7X7AVL3Wqys9XaPTh_-d89YQP5ZO8tQZtjS2ZVtlKTE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=62fa921bbd85e5d423be1d0cc752fd80036921d4", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/7X7AVL3Wqys9XaPTh_-d89YQP5ZO8tQZtjS2ZVtlKTE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=35e25a81044b8b9f4155ac257e7bc2d58a689a33", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/7X7AVL3Wqys9XaPTh_-d89YQP5ZO8tQZtjS2ZVtlKTE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a124e9599262d29ee6fda084974b19fd0cc8f0f5", "width": 960, "height": 639}, {"url": "https://external-preview.redd.it/7X7AVL3Wqys9XaPTh_-d89YQP5ZO8tQZtjS2ZVtlKTE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=56536f622eec8f655e2143ddead9ee2d3b33552c", "width": 1080, "height": 719}], "variants": {}, "id": "lLgOA3K_Wer2No7HgZ28tRywTRhHUxu8RTWTwOR8WlE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "y75jiy", "is_robot_indexable": true, "report_reasons": null, "author": "ConcentrateWest4353", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y75jiy/how_to_4x_your_team_size_without_it_you_falling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://hazal-muhtar.medium.com/how-to-4x-your-team-size-without-it-you-falling-apart-bff7fe8d90e3", "subreddit_subscribers": 814161, "created_utc": 1666095577.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am doing a analysis to understand a decreasing trend on a KPI. My main goal here was explain which metrics are impacting this KPI and, if possible, how much are they impacting.\n\nStarted doing a lot of visualization and trying to find any kind of corelation between the KPI and other important metrics. I have found a metric, lets call it X, that it is VERY positive correlated (0.9) with my KPI.\n\nAt the end of the analysis tried to create an Linear Regression using all of the variables that seemed to be important/impacting my KPI. Ended up with some pretty good metrics (R squared and MAE).\n\nSomething, although, is making me very confuse... even if my X variable have a pretty strong positive correlation, its coefficient (when checking the Linear Regression) is negative. Does it makes sense ? Shouldnt the coefficient be positive as well as the correlation metric ?\n\nThe negative coefficient tells me that if I increase the X metric, my KPI will deacrese, which goes the opposite way of what my correlation says...\n\nAny help will be appreciated", "author_fullname": "t2_8ej2plie", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Linear Regression Coefficients", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y75gzh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666095370.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am doing a analysis to understand a decreasing trend on a KPI. My main goal here was explain which metrics are impacting this KPI and, if possible, how much are they impacting.&lt;/p&gt;\n\n&lt;p&gt;Started doing a lot of visualization and trying to find any kind of corelation between the KPI and other important metrics. I have found a metric, lets call it X, that it is VERY positive correlated (0.9) with my KPI.&lt;/p&gt;\n\n&lt;p&gt;At the end of the analysis tried to create an Linear Regression using all of the variables that seemed to be important/impacting my KPI. Ended up with some pretty good metrics (R squared and MAE).&lt;/p&gt;\n\n&lt;p&gt;Something, although, is making me very confuse... even if my X variable have a pretty strong positive correlation, its coefficient (when checking the Linear Regression) is negative. Does it makes sense ? Shouldnt the coefficient be positive as well as the correlation metric ?&lt;/p&gt;\n\n&lt;p&gt;The negative coefficient tells me that if I increase the X metric, my KPI will deacrese, which goes the opposite way of what my correlation says...&lt;/p&gt;\n\n&lt;p&gt;Any help will be appreciated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y75gzh", "is_robot_indexable": true, "report_reasons": null, "author": "miiguelkf", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y75gzh/linear_regression_coefficients/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y75gzh/linear_regression_coefficients/", "subreddit_subscribers": 814161, "created_utc": 1666095370.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Which solutions do you see for the following problem?\n\nGiven full training session (15-20 minutes) wearable sensors time-series data (accelerometer, etc.), identify the \"moment\" when a specific test was performed. The test can be a combination of activities: sit2stand+walk+stand2sit or walk+turn+walk+turn or something similar. Obviously, duration can be different, but the test is present within the session. Walking detection model is available, there is some training data, but not excessive amounts. I am just trying to see what the best approach would be? I am thinking about training a convolutional NN with short window size of 1/2 sec to detect each required test element and then see where they best align together. Also how to deal with the fact if the model doesn't find such a test, but it certainly was done?", "author_fullname": "t2_f3y80e7s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Series of events identification within given time-series data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y70yok", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666081534.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Which solutions do you see for the following problem?&lt;/p&gt;\n\n&lt;p&gt;Given full training session (15-20 minutes) wearable sensors time-series data (accelerometer, etc.), identify the &amp;quot;moment&amp;quot; when a specific test was performed. The test can be a combination of activities: sit2stand+walk+stand2sit or walk+turn+walk+turn or something similar. Obviously, duration can be different, but the test is present within the session. Walking detection model is available, there is some training data, but not excessive amounts. I am just trying to see what the best approach would be? I am thinking about training a convolutional NN with short window size of 1/2 sec to detect each required test element and then see where they best align together. Also how to deal with the fact if the model doesn&amp;#39;t find such a test, but it certainly was done?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y70yok", "is_robot_indexable": true, "report_reasons": null, "author": "docoja1739", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y70yok/series_of_events_identification_within_given/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y70yok/series_of_events_identification_within_given/", "subreddit_subscribers": 814161, "created_utc": 1666081534.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I one-hot-encoded features and want to calculate similarity with the Jaccard index.\nBut, I am 100% sure that features have different importance for my clustering (i.e. some features are more important than others to calculate distance between my users )\n\nThinking about how Jaccard is calculated, the most obvious answer is to duplicate the important features as they count twice in these cases for the similarity.\nIs there any other way?", "author_fullname": "t2_5ydjc5q5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weight features in jaccard distance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y70g2h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666079644.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I one-hot-encoded features and want to calculate similarity with the Jaccard index.\nBut, I am 100% sure that features have different importance for my clustering (i.e. some features are more important than others to calculate distance between my users )&lt;/p&gt;\n\n&lt;p&gt;Thinking about how Jaccard is calculated, the most obvious answer is to duplicate the important features as they count twice in these cases for the similarity.\nIs there any other way?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y70g2h", "is_robot_indexable": true, "report_reasons": null, "author": "alexreddor", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y70g2h/weight_features_in_jaccard_distance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y70g2h/weight_features_in_jaccard_distance/", "subreddit_subscribers": 814161, "created_utc": 1666079644.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I have recently joined a newly formed data science team in a bank and my background has mainly been in retail and marketing analytics and modeling.\n\nNow from a banks perspective credit decisoning and delinquency modeling in the commercial space are obviously good use cases, but I was wondering if someone could provide examples of other use cases as well which would be relevant to institutional banking and lending practices.\n\nAn example could be credit limit optimization of borrowers. Any suggestion would be greatly appreciated! TIA", "author_fullname": "t2_2nqwlzun", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for professional project recommendations in the commercial and institutional banking space", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y6vgur", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666063604.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I have recently joined a newly formed data science team in a bank and my background has mainly been in retail and marketing analytics and modeling.&lt;/p&gt;\n\n&lt;p&gt;Now from a banks perspective credit decisoning and delinquency modeling in the commercial space are obviously good use cases, but I was wondering if someone could provide examples of other use cases as well which would be relevant to institutional banking and lending practices.&lt;/p&gt;\n\n&lt;p&gt;An example could be credit limit optimization of borrowers. Any suggestion would be greatly appreciated! TIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y6vgur", "is_robot_indexable": true, "report_reasons": null, "author": "saiko1993", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y6vgur/looking_for_professional_project_recommendations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y6vgur/looking_for_professional_project_recommendations/", "subreddit_subscribers": 814161, "created_utc": 1666063604.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My goal is to learn hypothesis testing. My understanding is that we do not have the population data. Therefore, we do not know the estimated population mean. So, we guess the population mean. If that so, can we change the population mean until the p-value is below 0.05, so we have enough evidence to reject the null hypothesis?\n\nThe code\n```\nimport pandas as pd\nfrom scipy import stats\n\nsample = pd.Series([1,2,3,4,5,6,7,8,9,10])\n\n# Hypothesis Testing:\n#\n# H0: \u03bc &lt;= 3.5 (previously it was \u03bc &lt;= 5.5, \n#               then 5, then 4.5, I change it until I get p value less than 0.05)\n# H1: \u03bc &gt; 3.5\n\nt_stat, p_value = stats.ttest_1samp(a = sample, popmean=3.5, alternative=\"greater\")\n\nprint(\"sample mean:\", sample.mean())\nprint(\"t-statistic: {0:.2f} p-value: {1:.2f}\".format(t_stat, p_value))\n\nprint(\"since we do not have the population data, \"\n      \"popmean=3.5 is not meaningful, \"\n      \"we can change it until we get enough evidence to reject the null hypothesis\")\n\nprint(\"critical value: 5%, therefore confidence interval: 90%\")\n\nprint(\"because p-value is below 0.05, we have enough evidence to reject the null hypothesis. \"\n      \"therefore, we can conclude that the mean population is more than 3.5\")\n\nprint(\"population standard deviation {0:.2f}\".format(sample.std(ddof=0)))\n\nprint(\"if we imagine the sample as the weight of waste, the conclusion is, \"\n      \"90% of population data is between population mean + 3 * population standard deviation, \"\n      \"in this case 3.5 +- 3 * 2.87\")\n```", "author_fullname": "t2_5yye765o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can we change the estimated population mean in Hypothesis Testing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y6v9fc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666063002.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My goal is to learn hypothesis testing. My understanding is that we do not have the population data. Therefore, we do not know the estimated population mean. So, we guess the population mean. If that so, can we change the population mean until the p-value is below 0.05, so we have enough evidence to reject the null hypothesis?&lt;/p&gt;\n\n&lt;p&gt;The code\n```\nimport pandas as pd\nfrom scipy import stats&lt;/p&gt;\n\n&lt;p&gt;sample = pd.Series([1,2,3,4,5,6,7,8,9,10])&lt;/p&gt;\n\n&lt;h1&gt;Hypothesis Testing:&lt;/h1&gt;\n\n&lt;h1&gt;H0: \u03bc &amp;lt;= 3.5 (previously it was \u03bc &amp;lt;= 5.5,&lt;/h1&gt;\n\n&lt;h1&gt;then 5, then 4.5, I change it until I get p value less than 0.05)&lt;/h1&gt;\n\n&lt;h1&gt;H1: \u03bc &amp;gt; 3.5&lt;/h1&gt;\n\n&lt;p&gt;t_stat, p_value = stats.ttest_1samp(a = sample, popmean=3.5, alternative=&amp;quot;greater&amp;quot;)&lt;/p&gt;\n\n&lt;p&gt;print(&amp;quot;sample mean:&amp;quot;, sample.mean())\nprint(&amp;quot;t-statistic: {0:.2f} p-value: {1:.2f}&amp;quot;.format(t_stat, p_value))&lt;/p&gt;\n\n&lt;p&gt;print(&amp;quot;since we do not have the population data, &amp;quot;\n      &amp;quot;popmean=3.5 is not meaningful, &amp;quot;\n      &amp;quot;we can change it until we get enough evidence to reject the null hypothesis&amp;quot;)&lt;/p&gt;\n\n&lt;p&gt;print(&amp;quot;critical value: 5%, therefore confidence interval: 90%&amp;quot;)&lt;/p&gt;\n\n&lt;p&gt;print(&amp;quot;because p-value is below 0.05, we have enough evidence to reject the null hypothesis. &amp;quot;\n      &amp;quot;therefore, we can conclude that the mean population is more than 3.5&amp;quot;)&lt;/p&gt;\n\n&lt;p&gt;print(&amp;quot;population standard deviation {0:.2f}&amp;quot;.format(sample.std(ddof=0)))&lt;/p&gt;\n\n&lt;p&gt;print(&amp;quot;if we imagine the sample as the weight of waste, the conclusion is, &amp;quot;\n      &amp;quot;90% of population data is between population mean + 3 * population standard deviation, &amp;quot;\n      &amp;quot;in this case 3.5 +- 3 * 2.87&amp;quot;)\n```&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y6v9fc", "is_robot_indexable": true, "report_reasons": null, "author": "kidfromtheast", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y6v9fc/can_we_change_the_estimated_population_mean_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y6v9fc/can_we_change_the_estimated_population_mean_in/", "subreddit_subscribers": 814161, "created_utc": 1666063002.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_amfdjuba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Q] What are AutoML packages easily useable with M1 Macs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y6su7s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666056304.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y6su7s", "is_robot_indexable": true, "report_reasons": null, "author": "limedove", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y6su7s/q_what_are_automl_packages_easily_useable_with_m1/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y6su7s/q_what_are_automl_packages_easily_useable_with_m1/", "subreddit_subscribers": 814161, "created_utc": 1666056304.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Creating a framework for high-performance, cloud-native object storage need not be a mystery. Learn more from The Buyer\u2019s Guide to Software Defined #ObjectStorage to understand the key capabilities.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_y6r3pz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_90p5s", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/5NmL1wYqCwWgwXIXv_DIZnr6NSP7CfeFWGiZ7AEgxNQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "minio", "selftext": "", "author_fullname": "t2_90p5s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Creating a framework for high-performance, cloud-native object storage need not be a mystery. Learn more from The Buyer\u2019s Guide to Software Defined #ObjectStorage to understand the key capabilities.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/minio", "hidden": false, "pwls": null, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_y6r3fi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/5NmL1wYqCwWgwXIXv_DIZnr6NSP7CfeFWGiZ7AEgxNQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666051553.0, "link_flair_type": "text", "wls": null, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.min.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.min.io/the-buyers-guide-to-software-defined-object-storage/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hzUDa9motX-TeigJq1Z0AgffvO7HUBaIpqqIj22FZQA.jpg?auto=webp&amp;s=4c9d700643a7a50f07c41d3b8224cc2271fe9eda", "width": 2000, "height": 2500}, "resolutions": [{"url": "https://external-preview.redd.it/hzUDa9motX-TeigJq1Z0AgffvO7HUBaIpqqIj22FZQA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2a7269efca35f3bea41359d9025aa0874089f6aa", "width": 108, "height": 135}, {"url": "https://external-preview.redd.it/hzUDa9motX-TeigJq1Z0AgffvO7HUBaIpqqIj22FZQA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8f69046d0f8d7aa8b06b9424f3dd7657e611f35b", "width": 216, "height": 270}, {"url": "https://external-preview.redd.it/hzUDa9motX-TeigJq1Z0AgffvO7HUBaIpqqIj22FZQA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2cce2526b804aa922ac5567b83b8d8423772dd99", "width": 320, "height": 400}, {"url": "https://external-preview.redd.it/hzUDa9motX-TeigJq1Z0AgffvO7HUBaIpqqIj22FZQA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=df9fd20727ca180aacd3779768de4ab4e82dd314", "width": 640, "height": 800}, {"url": "https://external-preview.redd.it/hzUDa9motX-TeigJq1Z0AgffvO7HUBaIpqqIj22FZQA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a472c8451f0e2b54e8788df3e76c8598910bfe80", "width": 960, "height": 1200}, {"url": "https://external-preview.redd.it/hzUDa9motX-TeigJq1Z0AgffvO7HUBaIpqqIj22FZQA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=00af793804249180718bb5711c7906431b23e9d8", "width": 1080, "height": 1350}], "variants": {}, "id": "P4iZZpW8gmFxT4qxHV2RCB-P5u7REB9eId2NuZ5PUpI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "427dbc5c-5868-11ec-81a8-7e4604f56887", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_3ahsh", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#00a6a5", "id": "y6r3fi", "is_robot_indexable": true, "report_reasons": null, "author": "prtkgpt", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": null, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/minio/comments/y6r3fi/creating_a_framework_for_highperformance/", "parent_whitelist_status": null, "stickied": false, "url": "https://blog.min.io/the-buyers-guide-to-software-defined-object-storage/", "subreddit_subscribers": 502, "created_utc": 1666051553.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1666051575.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.min.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://blog.min.io/the-buyers-guide-to-software-defined-object-storage/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hzUDa9motX-TeigJq1Z0AgffvO7HUBaIpqqIj22FZQA.jpg?auto=webp&amp;s=4c9d700643a7a50f07c41d3b8224cc2271fe9eda", "width": 2000, "height": 2500}, "resolutions": [{"url": "https://external-preview.redd.it/hzUDa9motX-TeigJq1Z0AgffvO7HUBaIpqqIj22FZQA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2a7269efca35f3bea41359d9025aa0874089f6aa", "width": 108, "height": 135}, {"url": "https://external-preview.redd.it/hzUDa9motX-TeigJq1Z0AgffvO7HUBaIpqqIj22FZQA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8f69046d0f8d7aa8b06b9424f3dd7657e611f35b", "width": 216, "height": 270}, {"url": "https://external-preview.redd.it/hzUDa9motX-TeigJq1Z0AgffvO7HUBaIpqqIj22FZQA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2cce2526b804aa922ac5567b83b8d8423772dd99", "width": 320, "height": 400}, {"url": "https://external-preview.redd.it/hzUDa9motX-TeigJq1Z0AgffvO7HUBaIpqqIj22FZQA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=df9fd20727ca180aacd3779768de4ab4e82dd314", "width": 640, "height": 800}, {"url": "https://external-preview.redd.it/hzUDa9motX-TeigJq1Z0AgffvO7HUBaIpqqIj22FZQA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a472c8451f0e2b54e8788df3e76c8598910bfe80", "width": 960, "height": 1200}, {"url": "https://external-preview.redd.it/hzUDa9motX-TeigJq1Z0AgffvO7HUBaIpqqIj22FZQA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=00af793804249180718bb5711c7906431b23e9d8", "width": 1080, "height": 1350}], "variants": {}, "id": "P4iZZpW8gmFxT4qxHV2RCB-P5u7REB9eId2NuZ5PUpI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y6r3pz", "is_robot_indexable": true, "report_reasons": null, "author": "prtkgpt", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_y6r3fi", "author_flair_text_color": null, "permalink": "/r/datascience/comments/y6r3pz/creating_a_framework_for_highperformance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.min.io/the-buyers-guide-to-software-defined-object-storage/", "subreddit_subscribers": 814161, "created_utc": 1666051575.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}