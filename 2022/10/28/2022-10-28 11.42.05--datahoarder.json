{"kind": "Listing", "data": {"after": "t3_yf03pc", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_23nomvne", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "we still using VirtualDub to try and salvage bad DVD transfers ? how to deal with this hot mess of vertical ghosting from the Avatar DVD. This is from the VOB.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 85, "top_awarded_type": null, "hide_score": false, "name": "t3_yf25k6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "ups": 286, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 286, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/F2Uox7rxy_7jnId-aurlA_XXdSpskR0AVszJ5iframU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666901802.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/5btdsdj0pew91.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/5btdsdj0pew91.png?auto=webp&amp;s=8f4bb63f33db865ef3b4b930632db922ffa84e23", "width": 1912, "height": 1170}, "resolutions": [{"url": "https://preview.redd.it/5btdsdj0pew91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=dde15b347b47d6ac79da5bca77445d6635f48822", "width": 108, "height": 66}, {"url": "https://preview.redd.it/5btdsdj0pew91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f794e218a70765245b77d348baa2fa57c4dc487b", "width": 216, "height": 132}, {"url": "https://preview.redd.it/5btdsdj0pew91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4db4a98d9256e334bbcb23290f163b8512047080", "width": 320, "height": 195}, {"url": "https://preview.redd.it/5btdsdj0pew91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=04c6e3cd3b924827ee9f833940a07d2e30fa0095", "width": 640, "height": 391}, {"url": "https://preview.redd.it/5btdsdj0pew91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=7464064894536becaf0fbd704569d4e4c6249f61", "width": 960, "height": 587}, {"url": "https://preview.redd.it/5btdsdj0pew91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9b7987159833941106dbe67115f3e27a66005797", "width": 1080, "height": 660}], "variants": {}, "id": "pPF8HyJbY1ZZrnUM1DcRMNrcKP3OrYxjqPUJ-uW99fg"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "yf25k6", "is_robot_indexable": true, "report_reasons": null, "author": "ImaginaryCheetah", "discussion_type": null, "num_comments": 56, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yf25k6/we_still_using_virtualdub_to_try_and_salvage_bad/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/5btdsdj0pew91.png", "subreddit_subscribers": 649423, "created_utc": 1666901802.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_4v1y3v4g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Finally expanded my DIY nettop based NAS and cleaned up the mess", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 102, "top_awarded_type": null, "hide_score": false, "media_metadata": {"it9twubekdw91": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 78, "x": 108, "u": "https://preview.redd.it/it9twubekdw91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e5cbf923507857b1643e3b02ba27887d04811e1c"}, {"y": 157, "x": 216, "u": "https://preview.redd.it/it9twubekdw91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8e87f79cf5c045de78d84491844e5b66ccf74440"}, {"y": 233, "x": 320, "u": "https://preview.redd.it/it9twubekdw91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e397f79f976b5dc5325d45572f153aea4b6f612c"}, {"y": 467, "x": 640, "u": "https://preview.redd.it/it9twubekdw91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7d09f99194d84d6bd7b8a0032a7dc2e6250a763b"}, {"y": 701, "x": 960, "u": "https://preview.redd.it/it9twubekdw91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b13922042ba40bb676a33c1f9a0e44baaa801f65"}, {"y": 788, "x": 1080, "u": "https://preview.redd.it/it9twubekdw91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=685c36c3ade45bea134943c1a2e78df19e3366ea"}], "s": {"y": 2443, "x": 3345, "u": "https://preview.redd.it/it9twubekdw91.jpg?width=3345&amp;format=pjpg&amp;auto=webp&amp;s=6e2bd5a704c8409f482eccd8ef0bc4cd72ffd08a"}, "id": "it9twubekdw91"}, "e724b8yckdw91": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 166, "x": 108, "u": "https://preview.redd.it/e724b8yckdw91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=349cb9418b46f70c10fea8c97a89f640b2162ea7"}, {"y": 332, "x": 216, "u": "https://preview.redd.it/e724b8yckdw91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a57b38cdb7de70533649181572fc37eeb4a9a91c"}, {"y": 492, "x": 320, "u": "https://preview.redd.it/e724b8yckdw91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f537faaa667af11ac8e657fe196a2a7f17bb99e2"}, {"y": 985, "x": 640, "u": "https://preview.redd.it/e724b8yckdw91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ac96968726788d3c642a22149db0ef18e6ffb39b"}, {"y": 1477, "x": 960, "u": "https://preview.redd.it/e724b8yckdw91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4df1ac7cb21342fd89a10afa7878a996ca229d03"}, {"y": 1662, "x": 1080, "u": "https://preview.redd.it/e724b8yckdw91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4334ca1e5470ceda60a74a6c2392939ca6875451"}], "s": {"y": 3453, "x": 2243, "u": "https://preview.redd.it/e724b8yckdw91.jpg?width=2243&amp;format=pjpg&amp;auto=webp&amp;s=71f7bdb356c53478978890b9909530d9eced8f1e"}, "id": "e724b8yckdw91"}, "oxbznmj9kdw91": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 79, "x": 108, "u": "https://preview.redd.it/oxbznmj9kdw91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bb6a3b09794f4604c20e7ebc070b69faa06382f6"}, {"y": 158, "x": 216, "u": "https://preview.redd.it/oxbznmj9kdw91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=304a6bfe26680148b8fb1b8604358898dc4da85e"}, {"y": 234, "x": 320, "u": "https://preview.redd.it/oxbznmj9kdw91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5896eb3e0fc9ba50e28f4317e9e9a5365c2562fb"}, {"y": 468, "x": 640, "u": "https://preview.redd.it/oxbznmj9kdw91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=cbcd077a9f2ffab75fefaf95fe179d2e9d532f52"}, {"y": 703, "x": 960, "u": "https://preview.redd.it/oxbznmj9kdw91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6ff41d070b197cf9613bdb3f90b2c7fe2c0da19f"}, {"y": 790, "x": 1080, "u": "https://preview.redd.it/oxbznmj9kdw91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f9270ea8bbd58bf7260f8cc0a1c58a09d01a4836"}], "s": {"y": 1995, "x": 2724, "u": "https://preview.redd.it/oxbznmj9kdw91.jpg?width=2724&amp;format=pjpg&amp;auto=webp&amp;s=c55fb587258c964e5f0d186508ce55bd57a44cf9"}, "id": "oxbznmj9kdw91"}, "vjztwi2ckdw91": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 35, "x": 108, "u": "https://preview.redd.it/vjztwi2ckdw91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a77fa735449b26f7e2dd3301313dfb7155f9fa3f"}, {"y": 71, "x": 216, "u": "https://preview.redd.it/vjztwi2ckdw91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=77ea8ad28c8abc2068c6f6e941d8e27b93258f30"}, {"y": 105, "x": 320, "u": "https://preview.redd.it/vjztwi2ckdw91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=293ff35b0954d9462f65916b04138d4562abbb49"}], "s": {"y": 196, "x": 594, "u": "https://preview.redd.it/vjztwi2ckdw91.jpg?width=594&amp;format=pjpg&amp;auto=webp&amp;s=b26db008ce30105c8f3ecc907d7c1693722212a2"}, "id": "vjztwi2ckdw91"}}, "name": "t3_yewe3z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "ups": 150, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"caption": "Final result", "media_id": "oxbznmj9kdw91", "id": 202605380}, {"media_id": "vjztwi2ckdw91", "id": 202605381}, {"caption": "The Mess", "media_id": "e724b8yckdw91", "id": 202605382}, {"media_id": "it9twubekdw91", "id": 202605383}]}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 150, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/sw8deZY04NT75BJv4dxs4F9s-9V3_IT9B4ZOYssk-VA.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666888134.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/yewe3z", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "6TB OMV Safe", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yewe3z", "is_robot_indexable": true, "report_reasons": null, "author": "Le55more", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/yewe3z/finally_expanded_my_diy_nettop_based_nas_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/yewe3z", "subreddit_subscribers": 649423, "created_utc": 1666888134.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "The world is a crazy place, and most of us only really know that because of the internet. I have been manually saving webpages of news webpages that tell stories I feel will be forgotten, or disappear.\n\nI currently archive these webpages by using Safari's \"Save to PDF\" function. It makes a really clean PDF with no page breaks. However, there isn't a keyboard shortcut for it by default, and the prompt that comes up asking where to save it has a delay, and saving a separate file with the original URL (with a similar filename so it can be correlated to its respective PDF) can only be done manually by dragging the URL bar to a Finder window.\n\nI currently have over 500 webpages in my queue. My existing methods get me through about 2.5 a minute, which is still absurdly long. I have a server where my data is, and can host nearly any OS. Is there any way I can expedite this process, or perhaps get a new one?\n\nI'm looking to render the webpage, not save cookies, save it as a PDF, and have that PDF have the URL on it, or a partnered process that saves the URL separately. Any help would be appreciated.", "author_fullname": "t2_6lst6hg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Batch saving webpages to PDFs? (Sub wiki page deleted)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yf6k6s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666912347.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The world is a crazy place, and most of us only really know that because of the internet. I have been manually saving webpages of news webpages that tell stories I feel will be forgotten, or disappear.&lt;/p&gt;\n\n&lt;p&gt;I currently archive these webpages by using Safari&amp;#39;s &amp;quot;Save to PDF&amp;quot; function. It makes a really clean PDF with no page breaks. However, there isn&amp;#39;t a keyboard shortcut for it by default, and the prompt that comes up asking where to save it has a delay, and saving a separate file with the original URL (with a similar filename so it can be correlated to its respective PDF) can only be done manually by dragging the URL bar to a Finder window.&lt;/p&gt;\n\n&lt;p&gt;I currently have over 500 webpages in my queue. My existing methods get me through about 2.5 a minute, which is still absurdly long. I have a server where my data is, and can host nearly any OS. Is there any way I can expedite this process, or perhaps get a new one?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking to render the webpage, not save cookies, save it as a PDF, and have that PDF have the URL on it, or a partnered process that saves the URL separately. Any help would be appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yf6k6s", "is_robot_indexable": true, "report_reasons": null, "author": "YoitsTmac", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yf6k6s/batch_saving_webpages_to_pdfs_sub_wiki_page/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yf6k6s/batch_saving_webpages_to_pdfs_sub_wiki_page/", "subreddit_subscribers": 649423, "created_utc": 1666912347.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I want to hoard old Mac OSes. I have had good luck finding all pre-OS X and about half of the versions of OS X.\n\n* Pre-OS X versions are available from WinWorldPC [https://winworldpc.com/library/operating-systems](https://winworldpc.com/library/operating-systems)\n* Mac OS X 10.0 Cheetah, 10.1 Puma, 10.2 Jaguar, and 10.3 Panther are also available from WinWorldPC [https://winworldpc.com/product/mac-os-x/100](https://winworldpc.com/product/mac-os-x/100)\n* Mac OS X 10.7 Lion, 10.8 Mountain Lion, 10.10 Yosemite, 10.11 El Capitan, and 10.12 Sierra are available from Apple (see this page) [https://osxdaily.com/where-download-macos-installers/](https://osxdaily.com/where-download-macos-installers/)\n\nHowever, I can't find downloads of:\n\n1. 10.4 Tiger\n2. 10.5 Leopard\n3. 10.6 Snow Leopard\n4. 10.9 Mavericks\n5. 10.13 High Sierra\n6. 10.14 Mojave\n7. 10.15 Catalina\n8. 11 Big Sur\n9. 12 Monterey\n10. 13 Ventura\n\nWould anyone know where to get these?\n\nI checked [archive.org](https://archive.org) , but I don't know if someone could have uploaded malware...\n\nPS. I am not on Mac, so I don't know what to do with a \"macappstore\" link.", "author_fullname": "t2_g516jddh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where to find old versions of Mac OS X?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yf0r52", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666898451.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to hoard old Mac OSes. I have had good luck finding all pre-OS X and about half of the versions of OS X.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Pre-OS X versions are available from WinWorldPC &lt;a href=\"https://winworldpc.com/library/operating-systems\"&gt;https://winworldpc.com/library/operating-systems&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Mac OS X 10.0 Cheetah, 10.1 Puma, 10.2 Jaguar, and 10.3 Panther are also available from WinWorldPC &lt;a href=\"https://winworldpc.com/product/mac-os-x/100\"&gt;https://winworldpc.com/product/mac-os-x/100&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Mac OS X 10.7 Lion, 10.8 Mountain Lion, 10.10 Yosemite, 10.11 El Capitan, and 10.12 Sierra are available from Apple (see this page) &lt;a href=\"https://osxdaily.com/where-download-macos-installers/\"&gt;https://osxdaily.com/where-download-macos-installers/&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;However, I can&amp;#39;t find downloads of:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;10.4 Tiger&lt;/li&gt;\n&lt;li&gt;10.5 Leopard&lt;/li&gt;\n&lt;li&gt;10.6 Snow Leopard&lt;/li&gt;\n&lt;li&gt;10.9 Mavericks&lt;/li&gt;\n&lt;li&gt;10.13 High Sierra&lt;/li&gt;\n&lt;li&gt;10.14 Mojave&lt;/li&gt;\n&lt;li&gt;10.15 Catalina&lt;/li&gt;\n&lt;li&gt;11 Big Sur&lt;/li&gt;\n&lt;li&gt;12 Monterey&lt;/li&gt;\n&lt;li&gt;13 Ventura&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Would anyone know where to get these?&lt;/p&gt;\n\n&lt;p&gt;I checked &lt;a href=\"https://archive.org\"&gt;archive.org&lt;/a&gt; , but I don&amp;#39;t know if someone could have uploaded malware...&lt;/p&gt;\n\n&lt;p&gt;PS. I am not on Mac, so I don&amp;#39;t know what to do with a &amp;quot;macappstore&amp;quot; link.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yf0r52", "is_robot_indexable": true, "report_reasons": null, "author": "Reasonable_Sport_754", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yf0r52/where_to_find_old_versions_of_mac_os_x/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yf0r52/where_to_find_old_versions_of_mac_os_x/", "subreddit_subscribers": 649423, "created_utc": 1666898451.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_ayza6h03", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "r/thatHappened", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "friday", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_yfjl3y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Free-Post Friday!", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/kxfhgkZ3XGwwwJMLTPvFcxVyzxqXBUepY8LeW3pc1ro.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666949806.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.imgur.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.imgur.com/a3HWqQ7.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Fit2ZziT6PLVX5OrB7VSwMuC7vbCF_3pnkhOvb2C9hM.png?auto=webp&amp;s=0cf7e9ba3e6378eef67eb62d63332eeaac3fa654", "width": 1346, "height": 1741}, "resolutions": [{"url": "https://external-preview.redd.it/Fit2ZziT6PLVX5OrB7VSwMuC7vbCF_3pnkhOvb2C9hM.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=bae26ebb5e1db274df0bceef8afff91eeaa20655", "width": 108, "height": 139}, {"url": "https://external-preview.redd.it/Fit2ZziT6PLVX5OrB7VSwMuC7vbCF_3pnkhOvb2C9hM.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c680baaff04bc04154f96dbc05ff73b11826ce9b", "width": 216, "height": 279}, {"url": "https://external-preview.redd.it/Fit2ZziT6PLVX5OrB7VSwMuC7vbCF_3pnkhOvb2C9hM.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=608f337d1f0949e97b4abc6265786ba149262d64", "width": 320, "height": 413}, {"url": "https://external-preview.redd.it/Fit2ZziT6PLVX5OrB7VSwMuC7vbCF_3pnkhOvb2C9hM.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d6e308ed0e3dd16a51c5ce2bae1ae3282f51c46f", "width": 640, "height": 827}, {"url": "https://external-preview.redd.it/Fit2ZziT6PLVX5OrB7VSwMuC7vbCF_3pnkhOvb2C9hM.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=b64d6be05524eb0d67b43a03d0b207423b287851", "width": 960, "height": 1241}, {"url": "https://external-preview.redd.it/Fit2ZziT6PLVX5OrB7VSwMuC7vbCF_3pnkhOvb2C9hM.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=aee790bfc24506ee7a8b6677fbeba673417956e7", "width": 1080, "height": 1396}], "variants": {}, "id": "30zr7Xzwko_sba49ILIC9Yd3UuGj1lxvO2XIZb4MPCs"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82f515be-b94e-11eb-9f8a-0e1030dba663", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yfjl3y", "is_robot_indexable": true, "report_reasons": null, "author": "ufs2", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yfjl3y/rthathappened/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.imgur.com/a3HWqQ7.png", "subreddit_subscribers": 649423, "created_utc": 1666949806.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Tried a Czur ET24 for yearbook scanning. While the speed and software was good, was disappointed not as good as a flatbed, particularly for photo/graphic details. Like I scanned a black and white page and would give it a C grade. I scanned a regular color photo and I'd give the scan quality a D grade. Big disappointment. Any overhead scanner better such as the fujitsu? Or even an affordable large format scanner rec? Anyone have scan image comparisons?", "author_fullname": "t2_rpe0y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anything better than Czur ET24?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yf36px", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666923632.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666904303.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Tried a Czur ET24 for yearbook scanning. While the speed and software was good, was disappointed not as good as a flatbed, particularly for photo/graphic details. Like I scanned a black and white page and would give it a C grade. I scanned a regular color photo and I&amp;#39;d give the scan quality a D grade. Big disappointment. Any overhead scanner better such as the fujitsu? Or even an affordable large format scanner rec? Anyone have scan image comparisons?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yf36px", "is_robot_indexable": true, "report_reasons": null, "author": "gaudog", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yf36px/anything_better_than_czur_et24/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yf36px/anything_better_than_czur_et24/", "subreddit_subscribers": 649423, "created_utc": 1666904303.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am very new to this scene and situation I was hoping I could get answers to. I have a 3 drive bay in my PC and I want to make a raid array that will be for storing my movie collection, I may also use it to store things like backups. How would I go about this in the most cost affective way? I want 8tb of storage so would I get 2 4tb drives and an 8tb drive to mirror? If I were to go with that method would I run the array in raid 1? I still have plenty of power and sata slots for the drives, and I am planning on going with western digital red pros. Is this setup incorrect? Do all the drives have to be the same size for raid to work correctly?", "author_fullname": "t2_13w655", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New to data hoarding.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yf4gun", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666907323.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am very new to this scene and situation I was hoping I could get answers to. I have a 3 drive bay in my PC and I want to make a raid array that will be for storing my movie collection, I may also use it to store things like backups. How would I go about this in the most cost affective way? I want 8tb of storage so would I get 2 4tb drives and an 8tb drive to mirror? If I were to go with that method would I run the array in raid 1? I still have plenty of power and sata slots for the drives, and I am planning on going with western digital red pros. Is this setup incorrect? Do all the drives have to be the same size for raid to work correctly?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yf4gun", "is_robot_indexable": true, "report_reasons": null, "author": "striker1116", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yf4gun/new_to_data_hoarding/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yf4gun/new_to_data_hoarding/", "subreddit_subscribers": 649423, "created_utc": 1666907323.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My team have an upcoming project where we have to upload videos from our conference every day to an s3 bucket so other members of our team can then download and edit those videos at a later time.  \nWe have a 1GB/s wired network connection and are looking to max it out when uploading the rather large files (20-40gb/ea) to S3.  \nMy question is- what software is the fastest to upload to S3? It is probably a Mac, but we should have access to a Windows box if needed.  It has to be a GUI as the user is somewhat technical, but not comfortable with the command line.", "author_fullname": "t2_5hqsm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the fastest upload client for aws s3?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yerxy5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666877172.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My team have an upcoming project where we have to upload videos from our conference every day to an s3 bucket so other members of our team can then download and edit those videos at a later time.&lt;br/&gt;\nWe have a 1GB/s wired network connection and are looking to max it out when uploading the rather large files (20-40gb/ea) to S3.&lt;br/&gt;\nMy question is- what software is the fastest to upload to S3? It is probably a Mac, but we should have access to a Windows box if needed.  It has to be a GUI as the user is somewhat technical, but not comfortable with the command line.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "70TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yerxy5", "is_robot_indexable": true, "report_reasons": null, "author": "el_heffe80", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/yerxy5/what_is_the_fastest_upload_client_for_aws_s3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yerxy5/what_is_the_fastest_upload_client_for_aws_s3/", "subreddit_subscribers": 649423, "created_utc": 1666877172.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019ve got 1T of PDFs that I\u2019d like to be able to easily access and reference. My computer struggles since they are mostly image scans of 19th century book (also Adobe reader is a dogshit program). My plan is to buy some kind of external storage for my entire PDF library, so I am looking for recommendations for what drive or device to buy. Also, is there some kind of external storage that has its own built in memory to make it easier for my computer to view?", "author_fullname": "t2_zqqlk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PDF storage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yeyjg2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666893055.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve got 1T of PDFs that I\u2019d like to be able to easily access and reference. My computer struggles since they are mostly image scans of 19th century book (also Adobe reader is a dogshit program). My plan is to buy some kind of external storage for my entire PDF library, so I am looking for recommendations for what drive or device to buy. Also, is there some kind of external storage that has its own built in memory to make it easier for my computer to view?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yeyjg2", "is_robot_indexable": true, "report_reasons": null, "author": "Riccma02", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yeyjg2/pdf_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yeyjg2/pdf_storage/", "subreddit_subscribers": 649423, "created_utc": 1666893055.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello!\n\nI am trying to see if there is a simple way to mass-export articles. I've been playing around with IMPORTXML in GoogleSheets, while I have been able to pull dates, titles, descriptions, images of articles, I have been unable to pull the actual article content itself.\n\nFor context, I'm basically working on a passion project of some transcripts of a podcast I like, that I wanted to print and bind for personal reading. There are over 50 posts so I was curious if there was some way to mass export these. I'm dreading copying and pasting the content from each article. \n\nI should note that I am not a developer and know nothing about writing/running scripts. Hoping there might be an easy way for a novice to pull this. \n\n&amp;#x200B;\n\nThank you for any help or direction!", "author_fullname": "t2_tbqxmu6h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Export Blog/Article Content", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yesdup", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666878336.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;I am trying to see if there is a simple way to mass-export articles. I&amp;#39;ve been playing around with IMPORTXML in GoogleSheets, while I have been able to pull dates, titles, descriptions, images of articles, I have been unable to pull the actual article content itself.&lt;/p&gt;\n\n&lt;p&gt;For context, I&amp;#39;m basically working on a passion project of some transcripts of a podcast I like, that I wanted to print and bind for personal reading. There are over 50 posts so I was curious if there was some way to mass export these. I&amp;#39;m dreading copying and pasting the content from each article. &lt;/p&gt;\n\n&lt;p&gt;I should note that I am not a developer and know nothing about writing/running scripts. Hoping there might be an easy way for a novice to pull this. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you for any help or direction!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yesdup", "is_robot_indexable": true, "report_reasons": null, "author": "AccioFawkes", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yesdup/export_blogarticle_content/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yesdup/export_blogarticle_content/", "subreddit_subscribers": 649423, "created_utc": 1666878336.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I am about to buy a LSI SAS 9212-4i4e PCI Express to 6Gb/s SAS HBA. \n\nFeatures are:\n\nhttps://preview.redd.it/1075j1dbpcw91.png?width=527&amp;format=png&amp;auto=webp&amp;s=d046ca4038968ffa8bfef62a73f10a8894bba6e7\n\nBut I am still quite confused with the specs and information I found online...\n\nCan I use 16 HDDs with this card, without the card bottlenecking? Because its just PCIe 2.0 x8", "author_fullname": "t2_69o8ab94", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LSI SAS 9212-4i4e with 16 HDDs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 67, "top_awarded_type": null, "hide_score": false, "media_metadata": {"1075j1dbpcw91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 52, "x": 108, "u": "https://preview.redd.it/1075j1dbpcw91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d08d876764a6693b0ed3fcdc27256fa646a4b2d4"}, {"y": 104, "x": 216, "u": "https://preview.redd.it/1075j1dbpcw91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c3a83ff85fc8fbeb7e27482d74664c9fd222c2dd"}, {"y": 154, "x": 320, "u": "https://preview.redd.it/1075j1dbpcw91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ba3d0700b2469ceee1e9b19e3c7c15d8460705ff"}], "s": {"y": 254, "x": 527, "u": "https://preview.redd.it/1075j1dbpcw91.png?width=527&amp;format=png&amp;auto=webp&amp;s=d046ca4038968ffa8bfef62a73f10a8894bba6e7"}, "id": "1075j1dbpcw91"}}, "name": "t3_yesa7d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/Qg42SYAqNxTsLVW2hsQhgPXL_V920flwfKYGmLS7200.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666878073.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I am about to buy a LSI SAS 9212-4i4e PCI Express to 6Gb/s SAS HBA. &lt;/p&gt;\n\n&lt;p&gt;Features are:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/1075j1dbpcw91.png?width=527&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d046ca4038968ffa8bfef62a73f10a8894bba6e7\"&gt;https://preview.redd.it/1075j1dbpcw91.png?width=527&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d046ca4038968ffa8bfef62a73f10a8894bba6e7&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;But I am still quite confused with the specs and information I found online...&lt;/p&gt;\n\n&lt;p&gt;Can I use 16 HDDs with this card, without the card bottlenecking? Because its just PCIe 2.0 x8&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yesa7d", "is_robot_indexable": true, "report_reasons": null, "author": "clouder300", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yesa7d/lsi_sas_92124i4e_with_16_hdds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yesa7d/lsi_sas_92124i4e_with_16_hdds/", "subreddit_subscribers": 649423, "created_utc": 1666878073.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I got a 2 drive bay enclosure (it was a random one from StarTech) for some extra backup storage, just direct attached only, very simple, I'm using zfs mirror. It'll mostly stay cold and disconnected, and I'll update to it regularly.\n\nI'm having some problems when doing a heavy operation like rsync, and the drives are suddenly disconnected (don't appear anymore under the disk tool in Ubuntu).\nRebooting and then everything is fine. But this makes the whole setup unusable, because I can never complete a backup.\n\nThe enclosure has its own power cable, and is connected to my machine via USB.\n\nI'm worried that the enclosure itself is bad and the sata to USB interface inside it is faulty, or gets overloaded and gets an error.\n\nThe enclosure also has an esata port. My thoughts are that this esata port probably won't have as many issues as the internal sata to USB converter? And that I instead should connect directly using esata.\n\nI have seen cables from esata to normal sata that I can just plug into the motherboard, but that is a bit annoying.\n\nDoes anyone know of any nice pcie cards for esata (or just normal sata too is possible I guess) so I can actually have a port on my machine to plug stuff into?\nmust work on Linux.\n\nI guess it could be nice to have such a port available should I get more enclosures with esata on them.\n\nAnyways, is esata a stupid idea or is this something I should try out?", "author_fullname": "t2_17a2ry", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "connecting drive bay with esata?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yfkbf3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666952367.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got a 2 drive bay enclosure (it was a random one from StarTech) for some extra backup storage, just direct attached only, very simple, I&amp;#39;m using zfs mirror. It&amp;#39;ll mostly stay cold and disconnected, and I&amp;#39;ll update to it regularly.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m having some problems when doing a heavy operation like rsync, and the drives are suddenly disconnected (don&amp;#39;t appear anymore under the disk tool in Ubuntu).\nRebooting and then everything is fine. But this makes the whole setup unusable, because I can never complete a backup.&lt;/p&gt;\n\n&lt;p&gt;The enclosure has its own power cable, and is connected to my machine via USB.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m worried that the enclosure itself is bad and the sata to USB interface inside it is faulty, or gets overloaded and gets an error.&lt;/p&gt;\n\n&lt;p&gt;The enclosure also has an esata port. My thoughts are that this esata port probably won&amp;#39;t have as many issues as the internal sata to USB converter? And that I instead should connect directly using esata.&lt;/p&gt;\n\n&lt;p&gt;I have seen cables from esata to normal sata that I can just plug into the motherboard, but that is a bit annoying.&lt;/p&gt;\n\n&lt;p&gt;Does anyone know of any nice pcie cards for esata (or just normal sata too is possible I guess) so I can actually have a port on my machine to plug stuff into?\nmust work on Linux.&lt;/p&gt;\n\n&lt;p&gt;I guess it could be nice to have such a port available should I get more enclosures with esata on them.&lt;/p&gt;\n\n&lt;p&gt;Anyways, is esata a stupid idea or is this something I should try out?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yfkbf3", "is_robot_indexable": true, "report_reasons": null, "author": "_technically", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yfkbf3/connecting_drive_bay_with_esata/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yfkbf3/connecting_drive_bay_with_esata/", "subreddit_subscribers": 649423, "created_utc": 1666952367.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey there I need to upgrade my storage and just found out about the HBA card mentioned. I still have some questions and maybe you can help me with that. I found so many informations, that I am confused right now. \n\nI am running a PC which is turned on 24/7 (Win 10). It also functions as a Plex Server. All SATA ports are occupied and there is no space left so I need to attach some more storage. \n\nIf I use the HBA adapter, is it possible to show every single HDD as an individual one, just by connecting them and power them in? Kind of plugging in 16 HDDs via USB or directly to a SATA port. File system would be NFTS. \nI was just wondering, cause I was always reading about JBOD, zfs etc. And acutely I do not want JBOD as of now. Maybe in the future when I upgrade my PC I was thinking about to switch to unRAID or something similar. \n\nThanks in advance :)", "author_fullname": "t2_82bvqag6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about LSI SAS9200-16e HBA", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfj2im", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666947963.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there I need to upgrade my storage and just found out about the HBA card mentioned. I still have some questions and maybe you can help me with that. I found so many informations, that I am confused right now. &lt;/p&gt;\n\n&lt;p&gt;I am running a PC which is turned on 24/7 (Win 10). It also functions as a Plex Server. All SATA ports are occupied and there is no space left so I need to attach some more storage. &lt;/p&gt;\n\n&lt;p&gt;If I use the HBA adapter, is it possible to show every single HDD as an individual one, just by connecting them and power them in? Kind of plugging in 16 HDDs via USB or directly to a SATA port. File system would be NFTS. \nI was just wondering, cause I was always reading about JBOD, zfs etc. And acutely I do not want JBOD as of now. Maybe in the future when I upgrade my PC I was thinking about to switch to unRAID or something similar. &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yfj2im", "is_robot_indexable": true, "report_reasons": null, "author": "locopivo", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yfj2im/question_about_lsi_sas920016e_hba/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yfj2im/question_about_lsi_sas920016e_hba/", "subreddit_subscribers": 649423, "created_utc": 1666947963.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "And please consider the Sample Rate, Bit Depth, and Bit Rate of FLAC &amp; WAV.  Oh! And also there's .iso too, for music/audio storage.\n\n\\-Thanks!", "author_fullname": "t2_nvkg0kma", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WAV vs. FLAC, so in my recent post we concluded that PNG is better than BMP. But what about WAV vs. FLAC?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfc237", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.47, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666926714.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666926333.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;And please consider the Sample Rate, Bit Depth, and Bit Rate of FLAC &amp;amp; WAV.  Oh! And also there&amp;#39;s .iso too, for music/audio storage.&lt;/p&gt;\n\n&lt;p&gt;-Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yfc237", "is_robot_indexable": true, "report_reasons": null, "author": "FuckReddit442", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yfc237/wav_vs_flac_so_in_my_recent_post_we_concluded/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yfc237/wav_vs_flac_so_in_my_recent_post_we_concluded/", "subreddit_subscribers": 649423, "created_utc": 1666926333.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Backstory\n\nI live in Europe and back in 2018 a friend of mine was in the US and picked up a few Easystore 8TBs for me. I shucked them all and put them in my Synology NAS. All worked bar one which could not be detected. I connected it back to my PC first using a WD Elements adapter/case (the Euro version of the Easystore) and the drive was not even detected. Then I used the Easystore \"adapter\" and it powered up but it was detected as a 2TB drive and I could do nothing with it. Windows Disk Manager said it needed to be initialized but threw an error when I tried.  WD Utilities said the SMART test failed and that I had apparently entered a password wrong 5 times. The only option was to Erase but then it threw an exception with no details when I tried that. It was a legit disk too, not one that someone had swaped out and sent back to the store. Since I was not in the US and I had shucked it I assumed I would get no help from WD and put it in a box and forgot about it.\n\nSo now in 2022 its out of warranty and I am curious if there is anything I can do to revive it? Amazingly I still had the adapter from the Easystore case attached to it. I plugged it in again today and it was the same as before. I dont hear any funny sounds either. It spins up when I connect it to the computer, shows up in Disk Manager, still as 2TB but I still cant do anything with it.\n\nOne thing I am not sure about is whether the Easystore adapter I am using is the one that came with the 8TB drive. I had a batch of Easystore 3TB drives previously and it may be from those so maybe that is having trouble with the 8TB drive. The product id is 25fb firmware revision 3004 according to WD Utilities", "author_fullname": "t2_4ercn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trying to revive a WD 8TB Easystore white label I shucked a few years ago that never worked", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yev4xa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666885913.0, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666885055.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Backstory&lt;/p&gt;\n\n&lt;p&gt;I live in Europe and back in 2018 a friend of mine was in the US and picked up a few Easystore 8TBs for me. I shucked them all and put them in my Synology NAS. All worked bar one which could not be detected. I connected it back to my PC first using a WD Elements adapter/case (the Euro version of the Easystore) and the drive was not even detected. Then I used the Easystore &amp;quot;adapter&amp;quot; and it powered up but it was detected as a 2TB drive and I could do nothing with it. Windows Disk Manager said it needed to be initialized but threw an error when I tried.  WD Utilities said the SMART test failed and that I had apparently entered a password wrong 5 times. The only option was to Erase but then it threw an exception with no details when I tried that. It was a legit disk too, not one that someone had swaped out and sent back to the store. Since I was not in the US and I had shucked it I assumed I would get no help from WD and put it in a box and forgot about it.&lt;/p&gt;\n\n&lt;p&gt;So now in 2022 its out of warranty and I am curious if there is anything I can do to revive it? Amazingly I still had the adapter from the Easystore case attached to it. I plugged it in again today and it was the same as before. I dont hear any funny sounds either. It spins up when I connect it to the computer, shows up in Disk Manager, still as 2TB but I still cant do anything with it.&lt;/p&gt;\n\n&lt;p&gt;One thing I am not sure about is whether the Easystore adapter I am using is the one that came with the 8TB drive. I had a batch of Easystore 3TB drives previously and it may be from those so maybe that is having trouble with the 8TB drive. The product id is 25fb firmware revision 3004 according to WD Utilities&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "90TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yev4xa", "is_robot_indexable": true, "report_reasons": null, "author": "brimur", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/yev4xa/trying_to_revive_a_wd_8tb_easystore_white_label_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yev4xa/trying_to_revive_a_wd_8tb_easystore_white_label_i/", "subreddit_subscribers": 649423, "created_utc": 1666885055.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a large collection of clippings from [newspapers.com](https://newspapers.com). Is there a way to grab them all at once instead of downloading them one at a time. I ask because there are thousands, and 1 by 1 downloading would quite a while.", "author_fullname": "t2_s7xdm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bulk Clipping Aquisition", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yeuhsa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666883501.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a large collection of clippings from &lt;a href=\"https://newspapers.com\"&gt;newspapers.com&lt;/a&gt;. Is there a way to grab them all at once instead of downloading them one at a time. I ask because there are thousands, and 1 by 1 downloading would quite a while.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yeuhsa", "is_robot_indexable": true, "report_reasons": null, "author": "macstratdb", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yeuhsa/bulk_clipping_aquisition/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yeuhsa/bulk_clipping_aquisition/", "subreddit_subscribers": 649423, "created_utc": 1666883501.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019m looking at getting a 20tb drive to put into my PC. I\u2019d write to it overnight from the SSD I record 4K gameplay to during the day. I wouldn\u2019t hear the writing at night since the PC is in my office. I would read 4K video from it though while editing on Premiere.\n\nOne question I can\u2019t seem to find an answer on is how much noise differs between basic, NAS, Enterprise drives *when at idle* (or just doing simple reads). Would I notice any difference between, say, a WD Red Pro vs. a WD Gold just sitting there? Or a Seagate Ironwolf Pro vs. Seagate Exos? Are these both any louder than even a typical WD Red or Seagate Barracuda?\n\nBecause if not then I have no issue with getting the enterprise drive instead of the NAS, given the former\u2019s more impressive specs.\n\nYour advice is appreciated.", "author_fullname": "t2_3zfljicy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much does NAS vs. Enterprise hard drive noise differ in idle use?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yes45p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666877894.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666877624.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m looking at getting a 20tb drive to put into my PC. I\u2019d write to it overnight from the SSD I record 4K gameplay to during the day. I wouldn\u2019t hear the writing at night since the PC is in my office. I would read 4K video from it though while editing on Premiere.&lt;/p&gt;\n\n&lt;p&gt;One question I can\u2019t seem to find an answer on is how much noise differs between basic, NAS, Enterprise drives &lt;em&gt;when at idle&lt;/em&gt; (or just doing simple reads). Would I notice any difference between, say, a WD Red Pro vs. a WD Gold just sitting there? Or a Seagate Ironwolf Pro vs. Seagate Exos? Are these both any louder than even a typical WD Red or Seagate Barracuda?&lt;/p&gt;\n\n&lt;p&gt;Because if not then I have no issue with getting the enterprise drive instead of the NAS, given the former\u2019s more impressive specs.&lt;/p&gt;\n\n&lt;p&gt;Your advice is appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yes45p", "is_robot_indexable": true, "report_reasons": null, "author": "sharingmyxp", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yes45p/how_much_does_nas_vs_enterprise_hard_drive_noise/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yes45p/how_much_does_nas_vs_enterprise_hard_drive_noise/", "subreddit_subscribers": 649423, "created_utc": 1666877624.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am currently in the process of building a new server and in the process of looking for parts someone is offering me (those would be additional to my new main server, the more storage the better? :p ) \n\na bundle of  three older netapp JBODs (including disks see image)  \n1. NetApp Unnamed 24bay 2.5\" 2x IOM6 Sas controllers and 15x 600gb  \n2. NetApp FS2040 with 12x 600gb  \n3. NetApp DS14M4 with 14x 300gb\n\nFor 250\u20ac / 250 USD\n\nI am not sure if this is a good deal tho, but i am thinking of it bc i got a bunch (like 25x 3.5\" 3tb) Sas drives laying around i dont really have a place for since i am usually only using higher capacity exos drives in my newer servers.\n\n[https://cache.willhaben.at/mmo/2/614/813/572\\_-1961687663.jpg](https://cache.willhaben.at/mmo/2/614/813/572_-1961687663.jpg)", "author_fullname": "t2_8jnr5wv6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice | A good idea to buy old Netapps for Backup storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yerhxd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666875968.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently in the process of building a new server and in the process of looking for parts someone is offering me (those would be additional to my new main server, the more storage the better? :p ) &lt;/p&gt;\n\n&lt;p&gt;a bundle of  three older netapp JBODs (including disks see image)&lt;br/&gt;\n1. NetApp Unnamed 24bay 2.5&amp;quot; 2x IOM6 Sas controllers and 15x 600gb&lt;br/&gt;\n2. NetApp FS2040 with 12x 600gb&lt;br/&gt;\n3. NetApp DS14M4 with 14x 300gb&lt;/p&gt;\n\n&lt;p&gt;For 250\u20ac / 250 USD&lt;/p&gt;\n\n&lt;p&gt;I am not sure if this is a good deal tho, but i am thinking of it bc i got a bunch (like 25x 3.5&amp;quot; 3tb) Sas drives laying around i dont really have a place for since i am usually only using higher capacity exos drives in my newer servers.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://cache.willhaben.at/mmo/2/614/813/572_-1961687663.jpg\"&gt;https://cache.willhaben.at/mmo/2/614/813/572_-1961687663.jpg&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/j-7r26GYbfBsNLoVWcKbXJAxGsAR9Esz7yMerVEP5hM.jpg?auto=webp&amp;s=24c89c5044d404c4338817afcd3b0479c588cd81", "width": 992, "height": 1024}, "resolutions": [{"url": "https://external-preview.redd.it/j-7r26GYbfBsNLoVWcKbXJAxGsAR9Esz7yMerVEP5hM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1a9108f305248371feeb4bfc726c07f1e8d325af", "width": 108, "height": 111}, {"url": "https://external-preview.redd.it/j-7r26GYbfBsNLoVWcKbXJAxGsAR9Esz7yMerVEP5hM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ab90f537645678feb707929c2204db03ebc918fa", "width": 216, "height": 222}, {"url": "https://external-preview.redd.it/j-7r26GYbfBsNLoVWcKbXJAxGsAR9Esz7yMerVEP5hM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ddf146dbfa560d00ee9f4347919adf29e06fe08b", "width": 320, "height": 330}, {"url": "https://external-preview.redd.it/j-7r26GYbfBsNLoVWcKbXJAxGsAR9Esz7yMerVEP5hM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0def5ad521e22b2a1157dbfa1b9b6123245d798b", "width": 640, "height": 660}, {"url": "https://external-preview.redd.it/j-7r26GYbfBsNLoVWcKbXJAxGsAR9Esz7yMerVEP5hM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2c789165a1a7dc0fdc460e752028db5c1710c5dd", "width": 960, "height": 990}], "variants": {}, "id": "dA6zF67vtl4neOBm5qXd_2xvhQjhKrcoHIy9A4fs68o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yerhxd", "is_robot_indexable": true, "report_reasons": null, "author": "Pommes254", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yerhxd/advice_a_good_idea_to_buy_old_netapps_for_backup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yerhxd/advice_a_good_idea_to_buy_old_netapps_for_backup/", "subreddit_subscribers": 649423, "created_utc": 1666875968.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi\n\nI am looking for ideas on how to back up my entire PC including OS with an external hard drive using this Windows Image thing.\n\nFrom what I understand so far is I\u2019ll need to partition a portion to format for the OS to be stored.\n\nI want this system to be almost entirely autonomous and purely used as a fail safe, every time I save a document or any kind progress on my PC, the external hard drive will update itself simultaneously. A like for like. Should the worst happen, I set up my external hard drive to a new system and set up everything as it was as if nothing happened.\n\nAnd maybe a 3rd partition for manual general use/extra storage I don\u2019t have a particular need on my PC, all about having options!\n\nIs what I\u2019m think of entirely possible? If not what can I do?\n\nAlso advice on reputable brands and drives you use, I have been eyeing up the WD Elements or WD My Book and also the Seagate FireCuda Gaming Hub, the RGB chroma isn\u2019t necessary but a nice touch nonetheless.\n\nLooking forward to your thoughts!", "author_fullname": "t2_6z8llexv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automatic Back-Up of Entire System", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yep6at", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666869154.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi&lt;/p&gt;\n\n&lt;p&gt;I am looking for ideas on how to back up my entire PC including OS with an external hard drive using this Windows Image thing.&lt;/p&gt;\n\n&lt;p&gt;From what I understand so far is I\u2019ll need to partition a portion to format for the OS to be stored.&lt;/p&gt;\n\n&lt;p&gt;I want this system to be almost entirely autonomous and purely used as a fail safe, every time I save a document or any kind progress on my PC, the external hard drive will update itself simultaneously. A like for like. Should the worst happen, I set up my external hard drive to a new system and set up everything as it was as if nothing happened.&lt;/p&gt;\n\n&lt;p&gt;And maybe a 3rd partition for manual general use/extra storage I don\u2019t have a particular need on my PC, all about having options!&lt;/p&gt;\n\n&lt;p&gt;Is what I\u2019m think of entirely possible? If not what can I do?&lt;/p&gt;\n\n&lt;p&gt;Also advice on reputable brands and drives you use, I have been eyeing up the WD Elements or WD My Book and also the Seagate FireCuda Gaming Hub, the RGB chroma isn\u2019t necessary but a nice touch nonetheless.&lt;/p&gt;\n\n&lt;p&gt;Looking forward to your thoughts!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yep6at", "is_robot_indexable": true, "report_reasons": null, "author": "CompanyHot885", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yep6at/automatic_backup_of_entire_system/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yep6at/automatic_backup_of_entire_system/", "subreddit_subscribers": 649423, "created_utc": 1666869154.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I guess, you all probably have sold your large HDD's second-hand to replace them with even larger disks. To sell disks, one would need to erase the disk and do bad sector checking. But each of them would take 10 ~ 20 hours on a big disk. Is there a tool that does the two at the same time?\n\nI mean, it should not be that difficult, just generate random data, write the random data on one sector, read that data back to compare them, and repeat it for each and every sector. (I know that there are \"military-grade\" erasing methods, but I think in most cases, overwriting once with random data would be enough.) I could write such a programme myself, but doesn't such a tool already exist?", "author_fullname": "t2_nvkhy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tool that does erasing and sector checking at the same time?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfi6eu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666944666.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I guess, you all probably have sold your large HDD&amp;#39;s second-hand to replace them with even larger disks. To sell disks, one would need to erase the disk and do bad sector checking. But each of them would take 10 ~ 20 hours on a big disk. Is there a tool that does the two at the same time?&lt;/p&gt;\n\n&lt;p&gt;I mean, it should not be that difficult, just generate random data, write the random data on one sector, read that data back to compare them, and repeat it for each and every sector. (I know that there are &amp;quot;military-grade&amp;quot; erasing methods, but I think in most cases, overwriting once with random data would be enough.) I could write such a programme myself, but doesn&amp;#39;t such a tool already exist?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yfi6eu", "is_robot_indexable": true, "report_reasons": null, "author": "evolution2015", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yfi6eu/tool_that_does_erasing_and_sector_checking_at_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yfi6eu/tool_that_does_erasing_and_sector_checking_at_the/", "subreddit_subscribers": 649423, "created_utc": 1666944666.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm running out of storage space at home and have been looking at buying the largest drive I can without breaking the bank. The cheapest option I've seen so far is the Seagate One Touch Hub 20tb but I have 2 questions before buying and I'm hoping someone here can help.\n\n1) Does anyone know if it's shuckable? I'm pretty sure that line is, but I just want to confirm.\n\n2) At 20tb I must be getting either an EXOS or (more likely) IronWolf, right? (2b - any issues with either of those? How would they compare with a WD Ultrastar hc560?)\nThanks in advance for your help!!\n\nEdit:", "author_fullname": "t2_3zl6e9be", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seagate One Touch with Hub 20TB questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfdntg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666931547.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666930694.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m running out of storage space at home and have been looking at buying the largest drive I can without breaking the bank. The cheapest option I&amp;#39;ve seen so far is the Seagate One Touch Hub 20tb but I have 2 questions before buying and I&amp;#39;m hoping someone here can help.&lt;/p&gt;\n\n&lt;p&gt;1) Does anyone know if it&amp;#39;s shuckable? I&amp;#39;m pretty sure that line is, but I just want to confirm.&lt;/p&gt;\n\n&lt;p&gt;2) At 20tb I must be getting either an EXOS or (more likely) IronWolf, right? (2b - any issues with either of those? How would they compare with a WD Ultrastar hc560?)\nThanks in advance for your help!!&lt;/p&gt;\n\n&lt;p&gt;Edit:&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yfdntg", "is_robot_indexable": true, "report_reasons": null, "author": "HFhutz", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yfdntg/seagate_one_touch_with_hub_20tb_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yfdntg/seagate_one_touch_with_hub_20tb_questions/", "subreddit_subscribers": 649423, "created_utc": 1666930694.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have no idea what I\u2019m doing. I have the drobo setup. Works over usb but slow. No idea how to set up iSCSI. Tried just plugging it into my router and it didn\u2019t read anything. \n\nI need HELP", "author_fullname": "t2_6ka1n6ed", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Old DroboPro iSCSI HELP", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfcbxn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666927083.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have no idea what I\u2019m doing. I have the drobo setup. Works over usb but slow. No idea how to set up iSCSI. Tried just plugging it into my router and it didn\u2019t read anything. &lt;/p&gt;\n\n&lt;p&gt;I need HELP&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yfcbxn", "is_robot_indexable": true, "report_reasons": null, "author": "washbuns", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yfcbxn/old_drobopro_iscsi_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yfcbxn/old_drobopro_iscsi_help/", "subreddit_subscribers": 649423, "created_utc": 1666927083.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking for a way to mirror git repos, while also keeping them up to date, but I also don't want to just blindly update the mirror should the repo be force-pushed with nothing, or the repo deleted / taken down.\n\nAny thoughts?", "author_fullname": "t2_j5m47", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mirroring git repos, and keeping the mirrors up to date?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yf33ez", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666904077.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for a way to mirror git repos, while also keeping them up to date, but I also don&amp;#39;t want to just blindly update the mirror should the repo be force-pushed with nothing, or the repo deleted / taken down.&lt;/p&gt;\n\n&lt;p&gt;Any thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "30TB unRAID", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yf33ez", "is_robot_indexable": true, "report_reasons": null, "author": "DanTheMan827", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/yf33ez/mirroring_git_repos_and_keeping_the_mirrors_up_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yf33ez/mirroring_git_repos_and_keeping_the_mirrors_up_to/", "subreddit_subscribers": 649423, "created_utc": 1666904077.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "This seems like the right group of consummate professionals to ask:\n\nDo you fine folks diversify your drives across NAS/NVR units periodically?  I have a modest 2-4x8TB NAS units and a single 4x8TB NVR unit.  I am about to expand to a third NAS and a second NVR unit in a second physical location on my WAN.  When I buy the new drives, I am considering hot-swapping them into my existing deployment to create a diversified mix of drive ages in each unit.  Presently, the operating units each have drives of all the same age and power time, although each unit was deployed at a different point in time.", "author_fullname": "t2_12irlx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Drive Diversification across Units", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yf1fiq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666900057.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This seems like the right group of consummate professionals to ask:&lt;/p&gt;\n\n&lt;p&gt;Do you fine folks diversify your drives across NAS/NVR units periodically?  I have a modest 2-4x8TB NAS units and a single 4x8TB NVR unit.  I am about to expand to a third NAS and a second NVR unit in a second physical location on my WAN.  When I buy the new drives, I am considering hot-swapping them into my existing deployment to create a diversified mix of drive ages in each unit.  Presently, the operating units each have drives of all the same age and power time, although each unit was deployed at a different point in time.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "yf1fiq", "is_robot_indexable": true, "report_reasons": null, "author": "kandurb", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yf1fiq/drive_diversification_across_units/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yf1fiq/drive_diversification_across_units/", "subreddit_subscribers": 649423, "created_utc": 1666900057.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "**Objective:** Replace buggy Marvell-based PCIe eSATA card with suitable SAS HBA in a ***Desktop*** computer running Windows 10 Pro, for use with individual drives in self-powered eSATA enclosures.\n\n**Question:** Can this support connecting SATA drives in external, self-powered **eSATA** connector enclosures that can be connected **while the PC is** ***booted up*** **and** ***Windows is running*** ? And conversely, will it be possible to disconnect such drives with the Windows option to \"Safely Remove Hardware\" while the PC is running?\n\nI've searched for hours and can't find answer to this question, but perhaps I'm not asking correctly, and this is actually a question of \"Can you hot swap external drives connected to SAS HBA\" ? \ud83e\udd10 \n\nI realize most people are using HBA cards for more extensive, dedicated, always-on storage purposes. I really want to have option to connect SATA drives in external eSATA enclosures to my Win10 PC, AND have the option to attach them while Windows is running, and remove them using the *Safely Remove Hardware* option, also while Windows is running. I'd also like to be able to connect more than 2 at the same time.\n\nYour experience and guidance here will be **VERY** appreciated....**THANKS !**\n\n(The eSATA PCIe card currently installed, now causing problems: [IOCrest/Syba SD-SA2PEX-2E](https://www.sybausa.com/index.php?route=product/product&amp;product_id=168) )", "author_fullname": "t2_suissw8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Replace eSATA PCIe in Win10 PC with SAS HBA for connecting self-powered eSATA drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yf03pc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666896869.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Objective:&lt;/strong&gt; Replace buggy Marvell-based PCIe eSATA card with suitable SAS HBA in a &lt;strong&gt;&lt;em&gt;Desktop&lt;/em&gt;&lt;/strong&gt; computer running Windows 10 Pro, for use with individual drives in self-powered eSATA enclosures.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Question:&lt;/strong&gt; Can this support connecting SATA drives in external, self-powered &lt;strong&gt;eSATA&lt;/strong&gt; connector enclosures that can be connected &lt;strong&gt;while the PC is&lt;/strong&gt; &lt;strong&gt;&lt;em&gt;booted up&lt;/em&gt;&lt;/strong&gt; &lt;strong&gt;and&lt;/strong&gt; &lt;strong&gt;&lt;em&gt;Windows is running&lt;/em&gt;&lt;/strong&gt; ? And conversely, will it be possible to disconnect such drives with the Windows option to &amp;quot;Safely Remove Hardware&amp;quot; while the PC is running?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve searched for hours and can&amp;#39;t find answer to this question, but perhaps I&amp;#39;m not asking correctly, and this is actually a question of &amp;quot;Can you hot swap external drives connected to SAS HBA&amp;quot; ? \ud83e\udd10 &lt;/p&gt;\n\n&lt;p&gt;I realize most people are using HBA cards for more extensive, dedicated, always-on storage purposes. I really want to have option to connect SATA drives in external eSATA enclosures to my Win10 PC, AND have the option to attach them while Windows is running, and remove them using the &lt;em&gt;Safely Remove Hardware&lt;/em&gt; option, also while Windows is running. I&amp;#39;d also like to be able to connect more than 2 at the same time.&lt;/p&gt;\n\n&lt;p&gt;Your experience and guidance here will be &lt;strong&gt;VERY&lt;/strong&gt; appreciated....&lt;strong&gt;THANKS !&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;(The eSATA PCIe card currently installed, now causing problems: &lt;a href=\"https://www.sybausa.com/index.php?route=product/product&amp;amp;product_id=168\"&gt;IOCrest/Syba SD-SA2PEX-2E&lt;/a&gt; )&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yf03pc", "is_robot_indexable": true, "report_reasons": null, "author": "Redditations2u", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yf03pc/replace_esata_pcie_in_win10_pc_with_sas_hba_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yf03pc/replace_esata_pcie_in_win10_pc_with_sas_hba_for/", "subreddit_subscribers": 649423, "created_utc": 1666896869.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}