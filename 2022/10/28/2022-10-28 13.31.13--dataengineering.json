{"kind": "Listing", "data": {"after": null, "dist": 18, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_n5n50", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "It's cron all the way down", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_yez0ad", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "ups": 208, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 208, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/MwYU41FHiIcEBAI85vrnfPDevtFvvInRFv0d-dk1TIc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666894200.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/yaeal5qi2ew91.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/yaeal5qi2ew91.png?auto=webp&amp;s=852a00695350cf3b53d3b12f6e0b768ffb674e52", "width": 491, "height": 668}, "resolutions": [{"url": "https://preview.redd.it/yaeal5qi2ew91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=cd87e1377ad8483c4d7be12d098843c6e94b552d", "width": 108, "height": 146}, {"url": "https://preview.redd.it/yaeal5qi2ew91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=884cf89534e839ae088fbad7b62c86c8339fd0f0", "width": 216, "height": 293}, {"url": "https://preview.redd.it/yaeal5qi2ew91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=679d791cac63dfb5ebc616c8bcc18d16bf314d2d", "width": 320, "height": 435}], "variants": {}, "id": "4S2EpRx0f1SPFIO8tuJkQjwqwfmjqojxHLWrE24pFwU"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "yez0ad", "is_robot_indexable": true, "report_reasons": null, "author": "FireflyCaptain", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yez0ad/its_cron_all_the_way_down/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/yaeal5qi2ew91.png", "subreddit_subscribers": 78134, "created_utc": 1666894200.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know it varies on background, but what do you expect from a junior / medior / senior DE? What are the \"must-know\" questions based on seniority? \n\nDo you usually do live coding? If yes what kind of problems do you focus on?\n\nIf the candidate has a personal project do you care about it? Even if its a medior/senior candidate?", "author_fullname": "t2_xcba5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Technical interviewers! Based on seniority what do you usually expect from candidates?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yesj6s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 39, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 39, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666878728.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know it varies on background, but what do you expect from a junior / medior / senior DE? What are the &amp;quot;must-know&amp;quot; questions based on seniority? &lt;/p&gt;\n\n&lt;p&gt;Do you usually do live coding? If yes what kind of problems do you focus on?&lt;/p&gt;\n\n&lt;p&gt;If the candidate has a personal project do you care about it? Even if its a medior/senior candidate?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "yesj6s", "is_robot_indexable": true, "report_reasons": null, "author": "mackbenc", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yesj6s/technical_interviewers_based_on_seniority_what_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yesj6s/technical_interviewers_based_on_seniority_what_do/", "subreddit_subscribers": 78134, "created_utc": 1666878728.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2mhgth69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to reuse TaskGroups in Airflow and make better DAGs!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 115, "top_awarded_type": null, "hide_score": false, "name": "t3_yet4s9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/kQej6qOOo8JGH9ju51v0FDrUiUDJVpdZ3-F0OA8Z6Xk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666880210.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "linkedin.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.linkedin.com/feed/update/urn:li:activity:6991398253325869056/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/wjBoxa4Xip5X_Ad91SVIwaPQTeC0x7_DdtkeJbEE4UM.jpg?auto=webp&amp;s=a0763b5976d29e8e4384e2962bc4b36f4bcc686a", "width": 1070, "height": 884}, "resolutions": [{"url": "https://external-preview.redd.it/wjBoxa4Xip5X_Ad91SVIwaPQTeC0x7_DdtkeJbEE4UM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=200ec977c8639c6dbac5d6f33a9ef1a21441e02c", "width": 108, "height": 89}, {"url": "https://external-preview.redd.it/wjBoxa4Xip5X_Ad91SVIwaPQTeC0x7_DdtkeJbEE4UM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3047e22b937f4b8151b527b23aa77afd4eb06997", "width": 216, "height": 178}, {"url": "https://external-preview.redd.it/wjBoxa4Xip5X_Ad91SVIwaPQTeC0x7_DdtkeJbEE4UM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e5eec2d89144e34c161e689b3da410e9aa830fd8", "width": 320, "height": 264}, {"url": "https://external-preview.redd.it/wjBoxa4Xip5X_Ad91SVIwaPQTeC0x7_DdtkeJbEE4UM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0929bb8f062b909c1a14b85e6c84046f6d875afc", "width": 640, "height": 528}, {"url": "https://external-preview.redd.it/wjBoxa4Xip5X_Ad91SVIwaPQTeC0x7_DdtkeJbEE4UM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=aef87130e11caa93c395a6fc3425dbd43080da0d", "width": 960, "height": 793}], "variants": {}, "id": "0Tq7PdBUStgC5qLm6ITurkrMJDr7r6CwK2viNt1k3dY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yet4s9", "is_robot_indexable": true, "report_reasons": null, "author": "marclamberti", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yet4s9/how_to_reuse_taskgroups_in_airflow_and_make/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.linkedin.com/feed/update/urn:li:activity:6991398253325869056/", "subreddit_subscribers": 78134, "created_utc": 1666880210.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Will put the sign up link in the comments. You'll need to apply to join their Slack org, then check the #oa-book-club channel to review dates and other information.", "author_fullname": "t2_4041g9mz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Operational Analytics (Club) Book Club: Fundamentals of Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yf34ge", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666904151.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Will put the sign up link in the comments. You&amp;#39;ll need to apply to join their Slack org, then check the #oa-book-club channel to review dates and other information.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yf34ge", "is_robot_indexable": true, "report_reasons": null, "author": "aamoscodes", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yf34ge/operational_analytics_club_book_club_fundamentals/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yf34ge/operational_analytics_club_book_club_fundamentals/", "subreddit_subscribers": 78134, "created_utc": 1666904151.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In Berlin, what should be the salary expectation for someone who has been working as a DE for 3 years and before that as Backend Dev 3 more years? \n\nI mostly worked at small companies where the role required both a bit backend and data experience, I fit in this pretty well. For example at my current place we work with Neo4j, ElasticSearch and GraphQL, separate for different tenants/customers. I am responsible for all the steps for integration of a new data source, from analysis and modelling to pushing, to exposing the data via ES and GraphQL API. We do ETLs on Databricks with PySpark and Pandas. I don't manage teams but I do guide one or two juniors we have in my team.\n\nSo far I am quite okay with my current pay but I feel like I am constantly underselling myself specially because I suck at negotiations.", "author_fullname": "t2_12lkky", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Salary expectations for Berlin, Germany", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yewd6n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666888050.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In Berlin, what should be the salary expectation for someone who has been working as a DE for 3 years and before that as Backend Dev 3 more years? &lt;/p&gt;\n\n&lt;p&gt;I mostly worked at small companies where the role required both a bit backend and data experience, I fit in this pretty well. For example at my current place we work with Neo4j, ElasticSearch and GraphQL, separate for different tenants/customers. I am responsible for all the steps for integration of a new data source, from analysis and modelling to pushing, to exposing the data via ES and GraphQL API. We do ETLs on Databricks with PySpark and Pandas. I don&amp;#39;t manage teams but I do guide one or two juniors we have in my team.&lt;/p&gt;\n\n&lt;p&gt;So far I am quite okay with my current pay but I feel like I am constantly underselling myself specially because I suck at negotiations.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yewd6n", "is_robot_indexable": true, "report_reasons": null, "author": "ratulotron", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yewd6n/salary_expectations_for_berlin_germany/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yewd6n/salary_expectations_for_berlin_germany/", "subreddit_subscribers": 78134, "created_utc": 1666888050.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What is the difference between a data engineer and etl developer? What would be the differentiating use of tools/languages? What methodologies/best practices should either know? I am aware there is often overlap of responsibilities/similarities in tasks between the two, but need to know if a role I applied to internally should be titled ETL developer or am right in asking for the role to be titled Data Engineer instead.", "author_fullname": "t2_3h5wixaf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineer vs ETL developer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yezrg0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666896029.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is the difference between a data engineer and etl developer? What would be the differentiating use of tools/languages? What methodologies/best practices should either know? I am aware there is often overlap of responsibilities/similarities in tasks between the two, but need to know if a role I applied to internally should be titled ETL developer or am right in asking for the role to be titled Data Engineer instead.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yezrg0", "is_robot_indexable": true, "report_reasons": null, "author": "J0hnDutt00n", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yezrg0/data_engineer_vs_etl_developer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yezrg0/data_engineer_vs_etl_developer/", "subreddit_subscribers": 78134, "created_utc": 1666896029.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was reading about how compression works in parquet file format while doing so I landed on this table from data bricks docs.\n\nCan someone please explain? Thanks in advance\n\nhttps://preview.redd.it/zzek3263ijw91.png?width=865&amp;format=png&amp;auto=webp&amp;s=a30d4963e7652282f4045049f8128459a7e43f5b", "author_fullname": "t2_drv960av", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does 1 TB of data stored in S3 when scanned come out to be 1.15 TB?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 96, "top_awarded_type": null, "hide_score": true, "media_metadata": {"zzek3263ijw91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 74, "x": 108, "u": "https://preview.redd.it/zzek3263ijw91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ef09a4e09530a64327c03a971c025f117c292340"}, {"y": 148, "x": 216, "u": "https://preview.redd.it/zzek3263ijw91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d2e6e1fea75b67a5b95780e55118cd5646aa987c"}, {"y": 220, "x": 320, "u": "https://preview.redd.it/zzek3263ijw91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=0c1d505bf8b0f916a86930e1ddd66b6cfcb207e5"}, {"y": 440, "x": 640, "u": "https://preview.redd.it/zzek3263ijw91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a94b6d024c8eb764584c5903a4b77cf61a362ee4"}], "s": {"y": 595, "x": 865, "u": "https://preview.redd.it/zzek3263ijw91.png?width=865&amp;format=png&amp;auto=webp&amp;s=a30d4963e7652282f4045049f8128459a7e43f5b"}, "id": "zzek3263ijw91"}}, "name": "t3_yfmqs9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/vOs_2W0ushxi485NvhoHrwsShRSNTkxSQMbjS7iNVw8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666959785.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was reading about how compression works in parquet file format while doing so I landed on this table from data bricks docs.&lt;/p&gt;\n\n&lt;p&gt;Can someone please explain? Thanks in advance&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/zzek3263ijw91.png?width=865&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a30d4963e7652282f4045049f8128459a7e43f5b\"&gt;https://preview.redd.it/zzek3263ijw91.png?width=865&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a30d4963e7652282f4045049f8128459a7e43f5b&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yfmqs9", "is_robot_indexable": true, "report_reasons": null, "author": "Difficult_Buyer7243", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yfmqs9/how_does_1_tb_of_data_stored_in_s3_when_scanned/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yfmqs9/how_does_1_tb_of_data_stored_in_s3_when_scanned/", "subreddit_subscribers": 78134, "created_utc": 1666959785.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Today we used requests and os libraries to write object oriented programs that help us to fetch data from the web (html files) and store them in a temp folder. We put these tasks in apache airflow and saw how airflow schedules these tasks to fetch web data. Here is the video https://www.youtube.com/watch?v=NvU5kxgtUpE", "author_fullname": "t2_ck47kwls", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "using airflow to fetch web data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yf4seh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666908085.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Today we used requests and os libraries to write object oriented programs that help us to fetch data from the web (html files) and store them in a temp folder. We put these tasks in apache airflow and saw how airflow schedules these tasks to fetch web data. Here is the video &lt;a href=\"https://www.youtube.com/watch?v=NvU5kxgtUpE\"&gt;https://www.youtube.com/watch?v=NvU5kxgtUpE&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1e25_scX4wJ_YpFSTVZczuYMCTsmW9UHt9TpSMsPODw.jpg?auto=webp&amp;s=1113a2c334403c48e65782a13567f1a6acbb818e", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/1e25_scX4wJ_YpFSTVZczuYMCTsmW9UHt9TpSMsPODw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a653a99d1b5d5c137de5483d47ff0f7defe6f857", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/1e25_scX4wJ_YpFSTVZczuYMCTsmW9UHt9TpSMsPODw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=341ec7eb87d1c4e59481c7316495ffd986decbbc", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/1e25_scX4wJ_YpFSTVZczuYMCTsmW9UHt9TpSMsPODw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4c02396ddc791a3cc73e936e7c4cbaf0f70a83f1", "width": 320, "height": 240}], "variants": {}, "id": "eE41GQD9d0XY9OK9AaKrtI1yeFDpGfgy-bQXha-6oVM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yf4seh", "is_robot_indexable": true, "report_reasons": null, "author": "DaliCodes", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yf4seh/using_airflow_to_fetch_web_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yf4seh/using_airflow_to_fetch_web_data/", "subreddit_subscribers": 78134, "created_utc": 1666908085.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have an interview coming up with Tesla for DE and wanted to know if anyone here has given interviews at Tesla for DE. Would really help :)", "author_fullname": "t2_ahi836bi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tesla Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yf23eu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666901657.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an interview coming up with Tesla for DE and wanted to know if anyone here has given interviews at Tesla for DE. Would really help :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yf23eu", "is_robot_indexable": true, "report_reasons": null, "author": "yyforthewin", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yf23eu/tesla_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yf23eu/tesla_data_engineering/", "subreddit_subscribers": 78134, "created_utc": 1666901657.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone\n\nAfter putting some thought into it I have decided the best way to showcase my skills in data integration/DE is to build a portfolio of ETL pipelines (with transformations, cleaning, modeling etc. etc.) based on a fairly complex database/dataset.\n\nThe problem now is I cannot find the kind of DB i'm looking for, since resources like Kaggle and other websites are focused on data science/statistics side, so the database they make available are mostly very simple CSV files that are really good to do DS (apply algorithms etc.) but are not that interesting from the point of view of someone who does data integration. How can I showcase my skills if the base data is one CSV with 10 columns? \n\nIdeally the database I'm looking for would have:\n\n* messy, redundant, non conformed data, lots of table not modeled in a star schema (ex: a DB dump from an application maybe?)\n* different source types (some sql, some files, some apis I guess)\n* High volume, at least more than 1GB so that I'm forced to put a bit of optimization\n\nThese are the first that come to mind, if you have any suggestion or can point me to a github repo or something that can help me I would be extremely grateful!\n\nTHANKS", "author_fullname": "t2_ehpb7yoc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fairly complex database/set to build a ETL portfolio on - any help?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfjmvq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666949986.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone&lt;/p&gt;\n\n&lt;p&gt;After putting some thought into it I have decided the best way to showcase my skills in data integration/DE is to build a portfolio of ETL pipelines (with transformations, cleaning, modeling etc. etc.) based on a fairly complex database/dataset.&lt;/p&gt;\n\n&lt;p&gt;The problem now is I cannot find the kind of DB i&amp;#39;m looking for, since resources like Kaggle and other websites are focused on data science/statistics side, so the database they make available are mostly very simple CSV files that are really good to do DS (apply algorithms etc.) but are not that interesting from the point of view of someone who does data integration. How can I showcase my skills if the base data is one CSV with 10 columns? &lt;/p&gt;\n\n&lt;p&gt;Ideally the database I&amp;#39;m looking for would have:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;messy, redundant, non conformed data, lots of table not modeled in a star schema (ex: a DB dump from an application maybe?)&lt;/li&gt;\n&lt;li&gt;different source types (some sql, some files, some apis I guess)&lt;/li&gt;\n&lt;li&gt;High volume, at least more than 1GB so that I&amp;#39;m forced to put a bit of optimization&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;These are the first that come to mind, if you have any suggestion or can point me to a github repo or something that can help me I would be extremely grateful!&lt;/p&gt;\n\n&lt;p&gt;THANKS&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yfjmvq", "is_robot_indexable": true, "report_reasons": null, "author": "schizo_coder", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yfjmvq/fairly_complex_databaseset_to_build_a_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yfjmvq/fairly_complex_databaseset_to_build_a_etl/", "subreddit_subscribers": 78134, "created_utc": 1666949986.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, \n\n  \nI am converting a unix time column to a datetime human readable format, and while using the function below I have a weird behaviour.  \n\nThe column creationDate contains unix stamps like : `1666828800032`\n\nWhat is also weird is the year is the only anomaly. the rest is fine.\n\nUsing external conversion tools showed that the original format is correct.\n\nThanks!  \n\n\nhttps://preview.redd.it/2olqs5azcdw91.png?width=600&amp;format=png&amp;auto=webp&amp;s=a558bbd1c23bd076c08598c2d5ac2b64853f7b56", "author_fullname": "t2_o1lpjxry", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PySpark from_unixtime year not working as expected.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 130, "top_awarded_type": null, "hide_score": false, "media_metadata": {"2olqs5azcdw91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 100, "x": 108, "u": "https://preview.redd.it/2olqs5azcdw91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ddf7e7485806641393a4da2538164c318b750bc5"}, {"y": 200, "x": 216, "u": "https://preview.redd.it/2olqs5azcdw91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d13e56eda982a17567ee7faae55903d133a8386e"}, {"y": 297, "x": 320, "u": "https://preview.redd.it/2olqs5azcdw91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=45c94555e8c1eaf762319ea04a440fb4dea817e8"}], "s": {"y": 558, "x": 600, "u": "https://preview.redd.it/2olqs5azcdw91.png?width=600&amp;format=png&amp;auto=webp&amp;s=a558bbd1c23bd076c08598c2d5ac2b64853f7b56"}, "id": "2olqs5azcdw91"}}, "name": "t3_yevc6n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/1QsNuqylwhtXWrMSxGyb7QH1hchOGlSwEnWhrnhiVl8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666885543.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, &lt;/p&gt;\n\n&lt;p&gt;I am converting a unix time column to a datetime human readable format, and while using the function below I have a weird behaviour.  &lt;/p&gt;\n\n&lt;p&gt;The column creationDate contains unix stamps like : &lt;code&gt;1666828800032&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;What is also weird is the year is the only anomaly. the rest is fine.&lt;/p&gt;\n\n&lt;p&gt;Using external conversion tools showed that the original format is correct.&lt;/p&gt;\n\n&lt;p&gt;Thanks!  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/2olqs5azcdw91.png?width=600&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a558bbd1c23bd076c08598c2d5ac2b64853f7b56\"&gt;https://preview.redd.it/2olqs5azcdw91.png?width=600&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a558bbd1c23bd076c08598c2d5ac2b64853f7b56&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yevc6n", "is_robot_indexable": true, "report_reasons": null, "author": "Minimum-Freedom9865", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yevc6n/pyspark_from_unixtime_year_not_working_as_expected/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yevc6n/pyspark_from_unixtime_year_not_working_as_expected/", "subreddit_subscribers": 78134, "created_utc": 1666885543.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! Curious to know how folks in the community address corrections and adjustments in datapoints in their data pipelines. \n\nExample is if a sensor returns a wild value and you want to null that value, or replace it with something else, where does that sit in your process. \n\nI\u2019ve got an excel file right now that matches a few fields up and corrects it that way, but I don\u2019t think it\u2019s scales very well. Basically have to reprocess the entire pipeline (ETL) to reflect the changes. \n\nThoughts?", "author_fullname": "t2_ahu1o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Correcting data in pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yermwm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666876344.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! Curious to know how folks in the community address corrections and adjustments in datapoints in their data pipelines. &lt;/p&gt;\n\n&lt;p&gt;Example is if a sensor returns a wild value and you want to null that value, or replace it with something else, where does that sit in your process. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve got an excel file right now that matches a few fields up and corrects it that way, but I don\u2019t think it\u2019s scales very well. Basically have to reprocess the entire pipeline (ETL) to reflect the changes. &lt;/p&gt;\n\n&lt;p&gt;Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yermwm", "is_robot_indexable": true, "report_reasons": null, "author": "Namur007", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yermwm/correcting_data_in_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yermwm/correcting_data_in_pipeline/", "subreddit_subscribers": 78134, "created_utc": 1666876344.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_bvkm0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What Exactly *Isn't* dbt?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 97, "top_awarded_type": null, "hide_score": false, "name": "t3_yfj9df", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/NN16eeNur8YGrU_clqf9T7E3Jt-ExFHPYLVQ6B8UIVs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666948652.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "stkbailey.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://stkbailey.substack.com/p/what-exactly-isnt-dbt", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Y4iDwkP0oerE2Pj-fhyg2yX9_6e-r0ObtE4xaxqRozM.jpg?auto=webp&amp;s=70aa9f2b5b4c26268850dc9e88748a39e288ade8", "width": 859, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/Y4iDwkP0oerE2Pj-fhyg2yX9_6e-r0ObtE4xaxqRozM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9f7c7821b0bfa34d2028b62ddfde8030efc68d2b", "width": 108, "height": 75}, {"url": "https://external-preview.redd.it/Y4iDwkP0oerE2Pj-fhyg2yX9_6e-r0ObtE4xaxqRozM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ee5d8a0e4f758f624fbf75e4a138824c522c102e", "width": 216, "height": 150}, {"url": "https://external-preview.redd.it/Y4iDwkP0oerE2Pj-fhyg2yX9_6e-r0ObtE4xaxqRozM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e2e80cb8283ddbf15f991043b6db2b41052783c9", "width": 320, "height": 223}, {"url": "https://external-preview.redd.it/Y4iDwkP0oerE2Pj-fhyg2yX9_6e-r0ObtE4xaxqRozM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b71953a84550ff68e5dd8bf0538901414b70492e", "width": 640, "height": 447}], "variants": {}, "id": "SUYqamml5Hw7wKOmN2-Fy2Iqs5U9GU7olebjOzvWR0s"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yfj9df", "is_robot_indexable": true, "report_reasons": null, "author": "rmoff", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yfj9df/what_exactly_isnt_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://stkbailey.substack.com/p/what-exactly-isnt-dbt", "subreddit_subscribers": 78134, "created_utc": 1666948652.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I'm just starting to get exposure into AWS and I'm having a hard time understanding if an architecture that was handed to me makes any sense. Wanted to hear people's takes on how they would approach this problem.\n\nThere is a snowflake datalake that contains data representing the back end of an existing application.\n\nOur team is replacing that application, and as part of that process we need to hydrate our existing our new application database (dynamoDB) with the old data.\n\nThe data model has shifted between the two applications, but in theory we have a mapping between the old application data data and the api endpoints of the new application  (not the new application data model).\n\nThe proposal was to use AWS Glue to extract data from Snowflake into S3, and from S3 run a lambda or further leverage Glue to transform the data and feed it into the API. Hitting the dynamoDB backend directly was rejected due to some backend work that occurs in the new data model.\n\nThis would be a one time activity with the caveat being that there would need to be some delta loading while the current application is shut down and replaced with the new application.\n\nThe proposed solution so far has been use AWS Glue -&gt; S3 (Read from SFLK into S3) and then use lambdas or some other kind of compute to decompose the tables into individual api calls.\n\nThere are obvious red flags with hitting the API with that much load, as well as how slow it would be to decompose a table into rows and feed those piecemeal into an API.\n\nMy current thoughts after trying to absorb all of this is to try to get Snowflake to directly COPY that into S3 and from there try persuading the API team to expose some kind of batch endpoint or just perform a proper mapping from the old DB to DynamoDB (which would be challenging because the old DB was a relational model).\n\nAny help or experience in the same vein would be gratefully appreciated!", "author_fullname": "t2_6d49ikq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on hydrating an AWS hosted API with data from Snowflake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yf736o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666913648.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;m just starting to get exposure into AWS and I&amp;#39;m having a hard time understanding if an architecture that was handed to me makes any sense. Wanted to hear people&amp;#39;s takes on how they would approach this problem.&lt;/p&gt;\n\n&lt;p&gt;There is a snowflake datalake that contains data representing the back end of an existing application.&lt;/p&gt;\n\n&lt;p&gt;Our team is replacing that application, and as part of that process we need to hydrate our existing our new application database (dynamoDB) with the old data.&lt;/p&gt;\n\n&lt;p&gt;The data model has shifted between the two applications, but in theory we have a mapping between the old application data data and the api endpoints of the new application  (not the new application data model).&lt;/p&gt;\n\n&lt;p&gt;The proposal was to use AWS Glue to extract data from Snowflake into S3, and from S3 run a lambda or further leverage Glue to transform the data and feed it into the API. Hitting the dynamoDB backend directly was rejected due to some backend work that occurs in the new data model.&lt;/p&gt;\n\n&lt;p&gt;This would be a one time activity with the caveat being that there would need to be some delta loading while the current application is shut down and replaced with the new application.&lt;/p&gt;\n\n&lt;p&gt;The proposed solution so far has been use AWS Glue -&amp;gt; S3 (Read from SFLK into S3) and then use lambdas or some other kind of compute to decompose the tables into individual api calls.&lt;/p&gt;\n\n&lt;p&gt;There are obvious red flags with hitting the API with that much load, as well as how slow it would be to decompose a table into rows and feed those piecemeal into an API.&lt;/p&gt;\n\n&lt;p&gt;My current thoughts after trying to absorb all of this is to try to get Snowflake to directly COPY that into S3 and from there try persuading the API team to expose some kind of batch endpoint or just perform a proper mapping from the old DB to DynamoDB (which would be challenging because the old DB was a relational model).&lt;/p&gt;\n\n&lt;p&gt;Any help or experience in the same vein would be gratefully appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yf736o", "is_robot_indexable": true, "report_reasons": null, "author": "poppinstacks", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yf736o/thoughts_on_hydrating_an_aws_hosted_api_with_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yf736o/thoughts_on_hydrating_an_aws_hosted_api_with_data/", "subreddit_subscribers": 78134, "created_utc": 1666913648.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need a solution that scales and shrinks as needed.", "author_fullname": "t2_tfwkz0xa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hey! Any tips on how I can build a Webhook on Google Cloud Run that receives JSON POST requests, do a little transformation and store them into a Google MySQL DB?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yewc5i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666887956.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need a solution that scales and shrinks as needed.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yewc5i", "is_robot_indexable": true, "report_reasons": null, "author": "Far_Object_7904", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yewc5i/hey_any_tips_on_how_i_can_build_a_webhook_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yewc5i/hey_any_tips_on_how_i_can_build_a_webhook_on/", "subreddit_subscribers": 78134, "created_utc": 1666887956.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is anyone from Perth, Western Australia who knows a bit about the tech consultancy space in Perth willing to catch up for lunch? My treat :) Or alternatively, coffee catchup or a phone call or email exchange. Whatever is preferable!\n\nI'm a BI developer / mech eng working in a oil and gas company and would like to transition to a tech consultancy in the near future. I would love to dip my hands in some data engineering at some point too... But I have no clue on what companies are players in Perth, and which are good/bad or big/small etc. Any conversation would be immensely helpful!\n\nI've heard of a few and chatted to two of them... Empired, insight, servian, data divers, journey one, velrada... visagio? Deloitte? Don't know what's what!\n\nAlso going to post in Power BI subreddit to see if anyone pops up.\n\nThanks!", "author_fullname": "t2_g0zthzyh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone in Perth WA working know much about tech consultancies?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yfnj2h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666961967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is anyone from Perth, Western Australia who knows a bit about the tech consultancy space in Perth willing to catch up for lunch? My treat :) Or alternatively, coffee catchup or a phone call or email exchange. Whatever is preferable!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a BI developer / mech eng working in a oil and gas company and would like to transition to a tech consultancy in the near future. I would love to dip my hands in some data engineering at some point too... But I have no clue on what companies are players in Perth, and which are good/bad or big/small etc. Any conversation would be immensely helpful!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve heard of a few and chatted to two of them... Empired, insight, servian, data divers, journey one, velrada... visagio? Deloitte? Don&amp;#39;t know what&amp;#39;s what!&lt;/p&gt;\n\n&lt;p&gt;Also going to post in Power BI subreddit to see if anyone pops up.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yfnj2h", "is_robot_indexable": true, "report_reasons": null, "author": "FarLeading2825", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yfnj2h/anyone_in_perth_wa_working_know_much_about_tech/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yfnj2h/anyone_in_perth_wa_working_know_much_about_tech/", "subreddit_subscribers": 78134, "created_utc": 1666961967.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am in the early stages of building out a data model / data warehouse in my company. We are loosely following star schema design patterns. \n\nOne of the common analyses our users need is sales / orders by new and repeat users at all levels in our product hierarchy.\n\nIs anyone aware of any design patterns or approaches we could use to model our data?", "author_fullname": "t2_128qvy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Modelling new and repeat customers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yextvb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666891360.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am in the early stages of building out a data model / data warehouse in my company. We are loosely following star schema design patterns. &lt;/p&gt;\n\n&lt;p&gt;One of the common analyses our users need is sales / orders by new and repeat users at all levels in our product hierarchy.&lt;/p&gt;\n\n&lt;p&gt;Is anyone aware of any design patterns or approaches we could use to model our data?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yextvb", "is_robot_indexable": true, "report_reasons": null, "author": "mathewtrivett", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yextvb/modelling_new_and_repeat_customers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yextvb/modelling_new_and_repeat_customers/", "subreddit_subscribers": 78134, "created_utc": 1666891360.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a web activity in ADF which returns a JSON object, part of the structure of the object is like this:\n\n    {\n        \"links\": [\n            {\n                \"rel\": \"next\",\n                \"href\": \"https://some-service?limit=10&amp;offset=10\"\n            },\n            {\n                \"rel\": \"last\",\n                \"href\": \"https://some-service?limit=10&amp;offset=9990\"\n            },\n            {\n                \"rel\": \"self\",\n                \"href\": \"https://some-service?limit=10&amp;offset=0\"\n            }\n        ]\n\nI want to run a set variable task after this one and set the variable to the value of the \"next\" URL, it's part of a loop. \n\nThe problem is I don't know how to address that part of the JSON in the set variable task. I know I could go  \n\n    @activity('Web1').output.links[0].href \n\nBut the problem is that after the first call two more elements are added to the list \"first\" and \"previous\".\n\nWhat I really want to do is dynamically look for the entry where rel = \"next\"\n\nBut I'm not sure how to code that. Any thoughts?", "author_fullname": "t2_vj5jo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to access json items in list with the same name", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yeu808", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666882837.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a web activity in ADF which returns a JSON object, part of the structure of the object is like this:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;{\n    &amp;quot;links&amp;quot;: [\n        {\n            &amp;quot;rel&amp;quot;: &amp;quot;next&amp;quot;,\n            &amp;quot;href&amp;quot;: &amp;quot;https://some-service?limit=10&amp;amp;offset=10&amp;quot;\n        },\n        {\n            &amp;quot;rel&amp;quot;: &amp;quot;last&amp;quot;,\n            &amp;quot;href&amp;quot;: &amp;quot;https://some-service?limit=10&amp;amp;offset=9990&amp;quot;\n        },\n        {\n            &amp;quot;rel&amp;quot;: &amp;quot;self&amp;quot;,\n            &amp;quot;href&amp;quot;: &amp;quot;https://some-service?limit=10&amp;amp;offset=0&amp;quot;\n        }\n    ]\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I want to run a set variable task after this one and set the variable to the value of the &amp;quot;next&amp;quot; URL, it&amp;#39;s part of a loop. &lt;/p&gt;\n\n&lt;p&gt;The problem is I don&amp;#39;t know how to address that part of the JSON in the set variable task. I know I could go  &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;@activity(&amp;#39;Web1&amp;#39;).output.links[0].href \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;But the problem is that after the first call two more elements are added to the list &amp;quot;first&amp;quot; and &amp;quot;previous&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;What I really want to do is dynamically look for the entry where rel = &amp;quot;next&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;But I&amp;#39;m not sure how to code that. Any thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yeu808", "is_robot_indexable": true, "report_reasons": null, "author": "Enigma1984", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yeu808/how_to_access_json_items_in_list_with_the_same/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yeu808/how_to_access_json_items_in_list_with_the_same/", "subreddit_subscribers": 78134, "created_utc": 1666882837.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}