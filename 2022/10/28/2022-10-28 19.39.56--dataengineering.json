{"kind": "Listing", "data": {"after": null, "dist": 18, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_a49okn69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "It's not always Old Man Jenkins...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_yfuknq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 43, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 43, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/sA-bzbNjvxfBKpEkemfzgqu1wFBORFXjNpVkbfnQK1U.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666977339.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/zus7bi9wxkw91.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/zus7bi9wxkw91.jpg?auto=webp&amp;s=a2f15b3eb8aa51ec865d00b7f228a6414ae904f8", "width": 500, "height": 666}, "resolutions": [{"url": "https://preview.redd.it/zus7bi9wxkw91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7803063a5ad84d1992e00a9aaa99b63fdb8e3a5e", "width": 108, "height": 143}, {"url": "https://preview.redd.it/zus7bi9wxkw91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8765e3b7b67e3a96d582d8a57bf6be4c339aa3c7", "width": 216, "height": 287}, {"url": "https://preview.redd.it/zus7bi9wxkw91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c11c903e0e7983d6de4ba65479b556eba8629351", "width": 320, "height": 426}], "variants": {}, "id": "efmOVN_2bpQ1mBzOoi_K8tGqMy2_DskeZ2Z9k5-C-6g"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "yfuknq", "is_robot_indexable": true, "report_reasons": null, "author": "Top-Substance2185", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yfuknq/its_not_always_old_man_jenkins/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/zus7bi9wxkw91.jpg", "subreddit_subscribers": 78173, "created_utc": 1666977339.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was reading about how compression works in parquet file format while doing so I landed on this table from data bricks docs.\n\nCan someone please explain? Thanks in advance\n\nhttps://preview.redd.it/zzek3263ijw91.png?width=865&amp;format=png&amp;auto=webp&amp;s=a30d4963e7652282f4045049f8128459a7e43f5b", "author_fullname": "t2_drv960av", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does 1 TB of data stored in S3 when scanned come out to be 1.15 TB?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 96, "top_awarded_type": null, "hide_score": false, "media_metadata": {"zzek3263ijw91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 74, "x": 108, "u": "https://preview.redd.it/zzek3263ijw91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ef09a4e09530a64327c03a971c025f117c292340"}, {"y": 148, "x": 216, "u": "https://preview.redd.it/zzek3263ijw91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d2e6e1fea75b67a5b95780e55118cd5646aa987c"}, {"y": 220, "x": 320, "u": "https://preview.redd.it/zzek3263ijw91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=0c1d505bf8b0f916a86930e1ddd66b6cfcb207e5"}, {"y": 440, "x": 640, "u": "https://preview.redd.it/zzek3263ijw91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a94b6d024c8eb764584c5903a4b77cf61a362ee4"}], "s": {"y": 595, "x": 865, "u": "https://preview.redd.it/zzek3263ijw91.png?width=865&amp;format=png&amp;auto=webp&amp;s=a30d4963e7652282f4045049f8128459a7e43f5b"}, "id": "zzek3263ijw91"}}, "name": "t3_yfmqs9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/vOs_2W0ushxi485NvhoHrwsShRSNTkxSQMbjS7iNVw8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666959785.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was reading about how compression works in parquet file format while doing so I landed on this table from data bricks docs.&lt;/p&gt;\n\n&lt;p&gt;Can someone please explain? Thanks in advance&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/zzek3263ijw91.png?width=865&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a30d4963e7652282f4045049f8128459a7e43f5b\"&gt;https://preview.redd.it/zzek3263ijw91.png?width=865&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a30d4963e7652282f4045049f8128459a7e43f5b&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yfmqs9", "is_robot_indexable": true, "report_reasons": null, "author": "Difficult_Buyer7243", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yfmqs9/how_does_1_tb_of_data_stored_in_s3_when_scanned/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yfmqs9/how_does_1_tb_of_data_stored_in_s3_when_scanned/", "subreddit_subscribers": 78173, "created_utc": 1666959785.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Will put the sign up link in the comments. You'll need to apply to join their Slack org, then check the #oa-book-club channel to review dates and other information.", "author_fullname": "t2_4041g9mz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Operational Analytics (Club) Book Club: Fundamentals of Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yf34ge", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666904151.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Will put the sign up link in the comments. You&amp;#39;ll need to apply to join their Slack org, then check the #oa-book-club channel to review dates and other information.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yf34ge", "is_robot_indexable": true, "report_reasons": null, "author": "aamoscodes", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yf34ge/operational_analytics_club_book_club_fundamentals/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yf34ge/operational_analytics_club_book_club_fundamentals/", "subreddit_subscribers": 78173, "created_utc": 1666904151.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have an interview coming up with Tesla for DE and wanted to know if anyone here has given interviews at Tesla for DE. Would really help :)", "author_fullname": "t2_ahi836bi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tesla Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yf23eu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666901657.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an interview coming up with Tesla for DE and wanted to know if anyone here has given interviews at Tesla for DE. Would really help :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yf23eu", "is_robot_indexable": true, "report_reasons": null, "author": "yyforthewin", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yf23eu/tesla_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yf23eu/tesla_data_engineering/", "subreddit_subscribers": 78173, "created_utc": 1666901657.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone\n\nAfter putting some thought into it I have decided the best way to showcase my skills in data integration/DE is to build a portfolio of ETL pipelines (with transformations, cleaning, modeling etc. etc.) based on a fairly complex database/dataset.\n\nThe problem now is I cannot find the kind of DB i'm looking for, since resources like Kaggle and other websites are focused on data science/statistics side, so the database they make available are mostly very simple CSV files that are really good to do DS (apply algorithms etc.) but are not that interesting from the point of view of someone who does data integration. How can I showcase my skills if the base data is one CSV with 10 columns? \n\nIdeally the database I'm looking for would have:\n\n* messy, redundant, non conformed data, lots of table not modeled in a star schema (ex: a DB dump from an application maybe?)\n* different source types (some sql, some files, some apis I guess)\n* High volume, at least more than 1GB so that I'm forced to put a bit of optimization\n\nThese are the first that come to mind, if you have any suggestion or can point me to a github repo or something that can help me I would be extremely grateful!\n\nTHANKS", "author_fullname": "t2_ehpb7yoc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fairly complex database/set to build a ETL portfolio on - any help?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfjmvq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666949986.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone&lt;/p&gt;\n\n&lt;p&gt;After putting some thought into it I have decided the best way to showcase my skills in data integration/DE is to build a portfolio of ETL pipelines (with transformations, cleaning, modeling etc. etc.) based on a fairly complex database/dataset.&lt;/p&gt;\n\n&lt;p&gt;The problem now is I cannot find the kind of DB i&amp;#39;m looking for, since resources like Kaggle and other websites are focused on data science/statistics side, so the database they make available are mostly very simple CSV files that are really good to do DS (apply algorithms etc.) but are not that interesting from the point of view of someone who does data integration. How can I showcase my skills if the base data is one CSV with 10 columns? &lt;/p&gt;\n\n&lt;p&gt;Ideally the database I&amp;#39;m looking for would have:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;messy, redundant, non conformed data, lots of table not modeled in a star schema (ex: a DB dump from an application maybe?)&lt;/li&gt;\n&lt;li&gt;different source types (some sql, some files, some apis I guess)&lt;/li&gt;\n&lt;li&gt;High volume, at least more than 1GB so that I&amp;#39;m forced to put a bit of optimization&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;These are the first that come to mind, if you have any suggestion or can point me to a github repo or something that can help me I would be extremely grateful!&lt;/p&gt;\n\n&lt;p&gt;THANKS&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yfjmvq", "is_robot_indexable": true, "report_reasons": null, "author": "schizo_coder", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yfjmvq/fairly_complex_databaseset_to_build_a_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yfjmvq/fairly_complex_databaseset_to_build_a_etl/", "subreddit_subscribers": 78173, "created_utc": 1666949986.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Today we used requests and os libraries to write object oriented programs that help us to fetch data from the web (html files) and store them in a temp folder. We put these tasks in apache airflow and saw how airflow schedules these tasks to fetch web data. Here is the video https://www.youtube.com/watch?v=NvU5kxgtUpE", "author_fullname": "t2_ck47kwls", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "using airflow to fetch web data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yf4seh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666908085.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Today we used requests and os libraries to write object oriented programs that help us to fetch data from the web (html files) and store them in a temp folder. We put these tasks in apache airflow and saw how airflow schedules these tasks to fetch web data. Here is the video &lt;a href=\"https://www.youtube.com/watch?v=NvU5kxgtUpE\"&gt;https://www.youtube.com/watch?v=NvU5kxgtUpE&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1e25_scX4wJ_YpFSTVZczuYMCTsmW9UHt9TpSMsPODw.jpg?auto=webp&amp;s=1113a2c334403c48e65782a13567f1a6acbb818e", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/1e25_scX4wJ_YpFSTVZczuYMCTsmW9UHt9TpSMsPODw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a653a99d1b5d5c137de5483d47ff0f7defe6f857", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/1e25_scX4wJ_YpFSTVZczuYMCTsmW9UHt9TpSMsPODw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=341ec7eb87d1c4e59481c7316495ffd986decbbc", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/1e25_scX4wJ_YpFSTVZczuYMCTsmW9UHt9TpSMsPODw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4c02396ddc791a3cc73e936e7c4cbaf0f70a83f1", "width": 320, "height": 240}], "variants": {}, "id": "eE41GQD9d0XY9OK9AaKrtI1yeFDpGfgy-bQXha-6oVM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yf4seh", "is_robot_indexable": true, "report_reasons": null, "author": "DaliCodes", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yf4seh/using_airflow_to_fetch_web_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yf4seh/using_airflow_to_fetch_web_data/", "subreddit_subscribers": 78173, "created_utc": 1666908085.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is anyone from Perth, Western Australia who knows a bit about the tech consultancy space in Perth willing to catch up for lunch? My treat :) Or alternatively, coffee catchup or a phone call or email exchange. Whatever is preferable!\n\nI'm a BI developer / mech eng working in a oil and gas company and would like to transition to a tech consultancy in the near future. I would love to dip my hands in some data engineering at some point too... But I have no clue on what companies are players in Perth, and which are good/bad or big/small etc. Any conversation would be immensely helpful!\n\nI've heard of a few and chatted to two of them... Empired, insight, servian, data divers, journey one, velrada... visagio? Deloitte? Don't know what's what!\n\nAlso going to post in Power BI subreddit to see if anyone pops up.\n\nThanks!", "author_fullname": "t2_g0zthzyh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone in Perth WA working know much about tech consultancies?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfnj2h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666961967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is anyone from Perth, Western Australia who knows a bit about the tech consultancy space in Perth willing to catch up for lunch? My treat :) Or alternatively, coffee catchup or a phone call or email exchange. Whatever is preferable!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a BI developer / mech eng working in a oil and gas company and would like to transition to a tech consultancy in the near future. I would love to dip my hands in some data engineering at some point too... But I have no clue on what companies are players in Perth, and which are good/bad or big/small etc. Any conversation would be immensely helpful!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve heard of a few and chatted to two of them... Empired, insight, servian, data divers, journey one, velrada... visagio? Deloitte? Don&amp;#39;t know what&amp;#39;s what!&lt;/p&gt;\n\n&lt;p&gt;Also going to post in Power BI subreddit to see if anyone pops up.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yfnj2h", "is_robot_indexable": true, "report_reasons": null, "author": "FarLeading2825", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yfnj2h/anyone_in_perth_wa_working_know_much_about_tech/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yfnj2h/anyone_in_perth_wa_working_know_much_about_tech/", "subreddit_subscribers": 78173, "created_utc": 1666961967.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_bvkm0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What Exactly *Isn't* dbt?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 97, "top_awarded_type": null, "hide_score": false, "name": "t3_yfj9df", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/NN16eeNur8YGrU_clqf9T7E3Jt-ExFHPYLVQ6B8UIVs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666948652.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "stkbailey.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://stkbailey.substack.com/p/what-exactly-isnt-dbt", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Y4iDwkP0oerE2Pj-fhyg2yX9_6e-r0ObtE4xaxqRozM.jpg?auto=webp&amp;s=70aa9f2b5b4c26268850dc9e88748a39e288ade8", "width": 859, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/Y4iDwkP0oerE2Pj-fhyg2yX9_6e-r0ObtE4xaxqRozM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9f7c7821b0bfa34d2028b62ddfde8030efc68d2b", "width": 108, "height": 75}, {"url": "https://external-preview.redd.it/Y4iDwkP0oerE2Pj-fhyg2yX9_6e-r0ObtE4xaxqRozM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ee5d8a0e4f758f624fbf75e4a138824c522c102e", "width": 216, "height": 150}, {"url": "https://external-preview.redd.it/Y4iDwkP0oerE2Pj-fhyg2yX9_6e-r0ObtE4xaxqRozM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e2e80cb8283ddbf15f991043b6db2b41052783c9", "width": 320, "height": 223}, {"url": "https://external-preview.redd.it/Y4iDwkP0oerE2Pj-fhyg2yX9_6e-r0ObtE4xaxqRozM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b71953a84550ff68e5dd8bf0538901414b70492e", "width": 640, "height": 447}], "variants": {}, "id": "SUYqamml5Hw7wKOmN2-Fy2Iqs5U9GU7olebjOzvWR0s"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yfj9df", "is_robot_indexable": true, "report_reasons": null, "author": "rmoff", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yfj9df/what_exactly_isnt_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://stkbailey.substack.com/p/what-exactly-isnt-dbt", "subreddit_subscribers": 78173, "created_utc": 1666948652.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_1bmh3guw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on how you think this will affect the industry? I would expect data engineering to be pretty important for Twitter.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 131, "top_awarded_type": null, "hide_score": true, "name": "t3_yfwuzu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/GFG3KsGSifyWohJXY-3A_UMBElsiSi2ZQe3lJ6Sy4bI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666981889.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/gtypb9zdblw91.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/gtypb9zdblw91.png?auto=webp&amp;s=b5d0f3baa5eb381afa6086f2c0f5dcbe4f164ae2", "width": 1192, "height": 1120}, "resolutions": [{"url": "https://preview.redd.it/gtypb9zdblw91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=57e52c358cd2c6a02776f0e0eed57c5492a481ab", "width": 108, "height": 101}, {"url": "https://preview.redd.it/gtypb9zdblw91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=68fdaa0d17d668e35dd3e0bd65b4ac0ea6eb1294", "width": 216, "height": 202}, {"url": "https://preview.redd.it/gtypb9zdblw91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d7de8b3574cda0fecbc33a8f58873466e4ae3598", "width": 320, "height": 300}, {"url": "https://preview.redd.it/gtypb9zdblw91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=45408b0d15fb05a04f75ce13d8b6d14a50ff577d", "width": 640, "height": 601}, {"url": "https://preview.redd.it/gtypb9zdblw91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=08ab75a5b63302ae0b685f0179696bd60602a547", "width": 960, "height": 902}, {"url": "https://preview.redd.it/gtypb9zdblw91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f79d15ffd81f4a5cb30f8fa499077155931a1ba1", "width": 1080, "height": 1014}], "variants": {}, "id": "Q0vYE9_ooO4o2v7aC_F62Fo1bLp60ZbdGcIeBdI3KKo"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yfwuzu", "is_robot_indexable": true, "report_reasons": null, "author": "freebird348", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yfwuzu/thoughts_on_how_you_think_this_will_affect_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/gtypb9zdblw91.png", "subreddit_subscribers": 78173, "created_utc": 1666981889.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, what is the SQL client you use for BigData. I am using Dbeaver (as it's free) but honestly because of the metadata of BigData databases refresh takes forever. Also it shows the tool has connected to the DB but until it syncs the metadata queries fail with connectivity issues. This is quite irritating.\n\nSo what tips do you have for using SQL client for BigData databases and is it paid?", "author_fullname": "t2_umfhx4d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which SQL Client for BigData do you use?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfo4kx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666963509.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, what is the SQL client you use for BigData. I am using Dbeaver (as it&amp;#39;s free) but honestly because of the metadata of BigData databases refresh takes forever. Also it shows the tool has connected to the DB but until it syncs the metadata queries fail with connectivity issues. This is quite irritating.&lt;/p&gt;\n\n&lt;p&gt;So what tips do you have for using SQL client for BigData databases and is it paid?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yfo4kx", "is_robot_indexable": true, "report_reasons": null, "author": "demince", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yfo4kx/which_sql_client_for_bigdata_do_you_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yfo4kx/which_sql_client_for_bigdata_do_you_use/", "subreddit_subscribers": 78173, "created_utc": 1666963509.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A lot of posts and advice seem to focus on getting into DE after college, or transitioning into DE from an outside field. I want to tell my story as an inspiration that; there are other related roles and industries that are easier to break into; as I did. Analyst, Business Intelligence Engineer, and Analytics Engineer are all noble roles that make for easy pivots into Data Engineering with a great deal of overlap in skill set with Data Engineering. \n\nHere\u2019s my career progression, to show you how I made it from $40k to $287k in 7 years:\n\nSalary: $40k\n\nTitle: Account Executive\n\nOut of college, first job in software sales. The company I worked for and product I sold was in the Business Intelligence space, so I wanted to learn everything about it. I quickly became the most technical salesperson in my org, and tried to transition to a more technical solutions engineer role, but was blocked by management. So I left after 18 months. \n\nSalary: $80k\n\nTitle: Account Executive\n\nI worked selling a competing product to the former product, again learning everything I could. I began to learn SQL. After 14 months, I was laid off as the whole division went under. \n\nSalary: $100k\n\nTitle: Sr. Analyst\n\nI went to work in the healthcare space. Because of how technical I had become in my first sales job, I easily qualified for a tool-specific specialist at healthcare company. I was by far the most advanced on my team in this tool. My SQL was my biggest weakness, and I learned fast and studied countless hours outside of work. I left after 3 years due to lack of opportunity for advancement and political messes. \n\nSalary: $150k+$15k bonus \n\nTitle: Technical Lead\n\nI worked as a contractor for a FAANG company which is a great brand for my resume, but I was just a lowly contractor. I led complex projects writing SQL and a tiny bit of python. I studied python a lot. After 2 years, I tried to convert to FTE and it became obvious that it wouldn\u2019t happen. For the last 5 months, I spent about 5 hours a day studying algorithms and data structures and/or interviewing. After 2.5 years, I resigned. \n\nSalary: $175k+$25k bonus+$87k stock+$40k sign on bonus\n\nTitle: Data Engineer\n\nI received probably 5 offers between about 30 interviews. I got 1 FAANG offer ($225k, L5 BIE) 1 Top N offer ($287k DE) and 1 fortune 100 offer ($250k Sr DE). My advice here is that; I knew algorithms and data structures would be my weakness, so I focused there. With solid SQL, Algos, and behavioral, the rest I would need to figure out as I went. I began making lists of of topics that I was weak in as I went through more and more interviews, and I would get a few inches deep into each topic and/or make study sheets and flash cards as I went. A large element of this was luck. I focused on concepts, not tools. Normal forms, for example, are conceptual and tool-agnostic. There was also a massive luck element to this game. Some companies went for hard algos questions; I failed those interviews. Some interviewers wanted to talk about optimizing a pig job; I failed that interview. Was pig worth learning because one company asked about it? No. I stayed the course of conceptual topics. \n\nDespite my title as a Technical Lead as a contractor at FAANG, I interviewed for a Sr. role. Because the scope of some of the projects I worked on didn\u2019t impact multiple technical teams, I was down-leveled to entry-level Data Engineer. I declined the offer, and planned to accept another offer. A week later, the recruiter contacted me again and told me things changed on their end and they really wanted me. While they weren\u2019t able to up-level me, they were able to negotiate the salary to the upper-end of the range for entry-level Data Engineer.", "author_fullname": "t2_5v6av4nm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How I landed a $287k offer for entry-level Data Engineer at FAANG+", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yfx3m1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.27, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "620fb7b8-ac9d-11eb-a99a-0ed5d8300de1", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666983185.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666982498.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A lot of posts and advice seem to focus on getting into DE after college, or transitioning into DE from an outside field. I want to tell my story as an inspiration that; there are other related roles and industries that are easier to break into; as I did. Analyst, Business Intelligence Engineer, and Analytics Engineer are all noble roles that make for easy pivots into Data Engineering with a great deal of overlap in skill set with Data Engineering. &lt;/p&gt;\n\n&lt;p&gt;Here\u2019s my career progression, to show you how I made it from $40k to $287k in 7 years:&lt;/p&gt;\n\n&lt;p&gt;Salary: $40k&lt;/p&gt;\n\n&lt;p&gt;Title: Account Executive&lt;/p&gt;\n\n&lt;p&gt;Out of college, first job in software sales. The company I worked for and product I sold was in the Business Intelligence space, so I wanted to learn everything about it. I quickly became the most technical salesperson in my org, and tried to transition to a more technical solutions engineer role, but was blocked by management. So I left after 18 months. &lt;/p&gt;\n\n&lt;p&gt;Salary: $80k&lt;/p&gt;\n\n&lt;p&gt;Title: Account Executive&lt;/p&gt;\n\n&lt;p&gt;I worked selling a competing product to the former product, again learning everything I could. I began to learn SQL. After 14 months, I was laid off as the whole division went under. &lt;/p&gt;\n\n&lt;p&gt;Salary: $100k&lt;/p&gt;\n\n&lt;p&gt;Title: Sr. Analyst&lt;/p&gt;\n\n&lt;p&gt;I went to work in the healthcare space. Because of how technical I had become in my first sales job, I easily qualified for a tool-specific specialist at healthcare company. I was by far the most advanced on my team in this tool. My SQL was my biggest weakness, and I learned fast and studied countless hours outside of work. I left after 3 years due to lack of opportunity for advancement and political messes. &lt;/p&gt;\n\n&lt;p&gt;Salary: $150k+$15k bonus &lt;/p&gt;\n\n&lt;p&gt;Title: Technical Lead&lt;/p&gt;\n\n&lt;p&gt;I worked as a contractor for a FAANG company which is a great brand for my resume, but I was just a lowly contractor. I led complex projects writing SQL and a tiny bit of python. I studied python a lot. After 2 years, I tried to convert to FTE and it became obvious that it wouldn\u2019t happen. For the last 5 months, I spent about 5 hours a day studying algorithms and data structures and/or interviewing. After 2.5 years, I resigned. &lt;/p&gt;\n\n&lt;p&gt;Salary: $175k+$25k bonus+$87k stock+$40k sign on bonus&lt;/p&gt;\n\n&lt;p&gt;Title: Data Engineer&lt;/p&gt;\n\n&lt;p&gt;I received probably 5 offers between about 30 interviews. I got 1 FAANG offer ($225k, L5 BIE) 1 Top N offer ($287k DE) and 1 fortune 100 offer ($250k Sr DE). My advice here is that; I knew algorithms and data structures would be my weakness, so I focused there. With solid SQL, Algos, and behavioral, the rest I would need to figure out as I went. I began making lists of of topics that I was weak in as I went through more and more interviews, and I would get a few inches deep into each topic and/or make study sheets and flash cards as I went. A large element of this was luck. I focused on concepts, not tools. Normal forms, for example, are conceptual and tool-agnostic. There was also a massive luck element to this game. Some companies went for hard algos questions; I failed those interviews. Some interviewers wanted to talk about optimizing a pig job; I failed that interview. Was pig worth learning because one company asked about it? No. I stayed the course of conceptual topics. &lt;/p&gt;\n\n&lt;p&gt;Despite my title as a Technical Lead as a contractor at FAANG, I interviewed for a Sr. role. Because the scope of some of the projects I worked on didn\u2019t impact multiple technical teams, I was down-leveled to entry-level Data Engineer. I declined the offer, and planned to accept another offer. A week later, the recruiter contacted me again and told me things changed on their end and they really wanted me. While they weren\u2019t able to up-level me, they were able to negotiate the salary to the upper-end of the range for entry-level Data Engineer.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Tech Lead", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yfx3m1", "is_robot_indexable": true, "report_reasons": null, "author": "Flat_Shower", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/yfx3m1/how_i_landed_a_287k_offer_for_entrylevel_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yfx3m1/how_i_landed_a_287k_offer_for_entrylevel_data/", "subreddit_subscribers": 78173, "created_utc": 1666982498.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone found good educational resources on interacting with APIs from a data engineering perspective? I feel like this in an areas that I need to round out in my skillset, as I've have almost zero opportunities to dig into this at my work. \n\nI'm honestly not sure where to start looking on this stuff, so anything would help!", "author_fullname": "t2_gtjfu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Educational resources for working with web/cloud APIs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfscjm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666973056.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone found good educational resources on interacting with APIs from a data engineering perspective? I feel like this in an areas that I need to round out in my skillset, as I&amp;#39;ve have almost zero opportunities to dig into this at my work. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m honestly not sure where to start looking on this stuff, so anything would help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yfscjm", "is_robot_indexable": true, "report_reasons": null, "author": "LemurPrime", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yfscjm/educational_resources_for_working_with_webcloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yfscjm/educational_resources_for_working_with_webcloud/", "subreddit_subscribers": 78173, "created_utc": 1666973056.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I'm just starting to get exposure into AWS and I'm having a hard time understanding if an architecture that was handed to me makes any sense. Wanted to hear people's takes on how they would approach this problem.\n\nThere is a snowflake datalake that contains data representing the back end of an existing application.\n\nOur team is replacing that application, and as part of that process we need to hydrate our existing our new application database (dynamoDB) with the old data.\n\nThe data model has shifted between the two applications, but in theory we have a mapping between the old application data data and the api endpoints of the new application  (not the new application data model).\n\nThe proposal was to use AWS Glue to extract data from Snowflake into S3, and from S3 run a lambda or further leverage Glue to transform the data and feed it into the API. Hitting the dynamoDB backend directly was rejected due to some backend work that occurs in the new data model.\n\nThis would be a one time activity with the caveat being that there would need to be some delta loading while the current application is shut down and replaced with the new application.\n\nThe proposed solution so far has been use AWS Glue -&gt; S3 (Read from SFLK into S3) and then use lambdas or some other kind of compute to decompose the tables into individual api calls.\n\nThere are obvious red flags with hitting the API with that much load, as well as how slow it would be to decompose a table into rows and feed those piecemeal into an API.\n\nMy current thoughts after trying to absorb all of this is to try to get Snowflake to directly COPY that into S3 and from there try persuading the API team to expose some kind of batch endpoint or just perform a proper mapping from the old DB to DynamoDB (which would be challenging because the old DB was a relational model).\n\nAny help or experience in the same vein would be gratefully appreciated!", "author_fullname": "t2_6d49ikq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on hydrating an AWS hosted API with data from Snowflake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yf736o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666913648.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;m just starting to get exposure into AWS and I&amp;#39;m having a hard time understanding if an architecture that was handed to me makes any sense. Wanted to hear people&amp;#39;s takes on how they would approach this problem.&lt;/p&gt;\n\n&lt;p&gt;There is a snowflake datalake that contains data representing the back end of an existing application.&lt;/p&gt;\n\n&lt;p&gt;Our team is replacing that application, and as part of that process we need to hydrate our existing our new application database (dynamoDB) with the old data.&lt;/p&gt;\n\n&lt;p&gt;The data model has shifted between the two applications, but in theory we have a mapping between the old application data data and the api endpoints of the new application  (not the new application data model).&lt;/p&gt;\n\n&lt;p&gt;The proposal was to use AWS Glue to extract data from Snowflake into S3, and from S3 run a lambda or further leverage Glue to transform the data and feed it into the API. Hitting the dynamoDB backend directly was rejected due to some backend work that occurs in the new data model.&lt;/p&gt;\n\n&lt;p&gt;This would be a one time activity with the caveat being that there would need to be some delta loading while the current application is shut down and replaced with the new application.&lt;/p&gt;\n\n&lt;p&gt;The proposed solution so far has been use AWS Glue -&amp;gt; S3 (Read from SFLK into S3) and then use lambdas or some other kind of compute to decompose the tables into individual api calls.&lt;/p&gt;\n\n&lt;p&gt;There are obvious red flags with hitting the API with that much load, as well as how slow it would be to decompose a table into rows and feed those piecemeal into an API.&lt;/p&gt;\n\n&lt;p&gt;My current thoughts after trying to absorb all of this is to try to get Snowflake to directly COPY that into S3 and from there try persuading the API team to expose some kind of batch endpoint or just perform a proper mapping from the old DB to DynamoDB (which would be challenging because the old DB was a relational model).&lt;/p&gt;\n\n&lt;p&gt;Any help or experience in the same vein would be gratefully appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yf736o", "is_robot_indexable": true, "report_reasons": null, "author": "poppinstacks", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yf736o/thoughts_on_hydrating_an_aws_hosted_api_with_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yf736o/thoughts_on_hydrating_an_aws_hosted_api_with_data/", "subreddit_subscribers": 78173, "created_utc": 1666913648.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our data was migrated to s3 recently. We are using redshift spectrum to query data but it\u2019s taking really long time to query and do small transformations. We started using partitioning, there is improvement but not very significant compared to our previous datawarehouses. What are we doing wrong? What else can we try? Any suggestions are welcome. We are a small startup and cost savings was cited as the reasoning by seniors to migrate to this architecture so can\u2019t go back to relational datawarehouses. TIA!", "author_fullname": "t2_845cr8yh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need suggestion on query optimization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yfx7u6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666982802.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our data was migrated to s3 recently. We are using redshift spectrum to query data but it\u2019s taking really long time to query and do small transformations. We started using partitioning, there is improvement but not very significant compared to our previous datawarehouses. What are we doing wrong? What else can we try? Any suggestions are welcome. We are a small startup and cost savings was cited as the reasoning by seniors to migrate to this architecture so can\u2019t go back to relational datawarehouses. TIA!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yfx7u6", "is_robot_indexable": true, "report_reasons": null, "author": "chatsachin", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yfx7u6/need_suggestion_on_query_optimization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yfx7u6/need_suggestion_on_query_optimization/", "subreddit_subscribers": 78173, "created_utc": 1666982802.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all,\n\nSince 2018 I've been working as a BI Analyst primarily with Tableau, Alteryx, and MS SQL Server. My undergrad degree is in Middle Eastern Studies, and my journey into data has been largely self-taught. Currently, I am working in the auto industry where I build and maintain data pipelines for my company, as well as build Tableau reports for different business units.\n\nThat being said, I have felt over the last year that I need to move away from Alteryx and Tableau as they are highly expensive, and I don't want to handcuff my career to those two tools. As such, I set my sights on an online masters degree with Georgia Tech in Analytics (OMSA) and have taken two of their core courses to see how I would fare in the world of machine learning + data science. Honestly, I am doing really well grades-wise and it has been a great experience learning and coding in Python. However, I've come to realize that the whole aspect of turning math/statistics-into-code is not something that appeals to me. I have come to love Python/R and manipulating datasets, but I just abhor reading through mathematical formulas, linear algebra concepts, and statistical tests.\n\nWith that in mind, I am weighing the option of diving deep into the aspects of my job and coursework that I do enjoy - connecting to data, cleansing it, and manipulating it to create new views and datasets in a repeatable way which seems to be what data engineering is all about. \n\nAll of this context aside, here are my questions that I would love to hear your opinions on:\n\n1. Are there graduate degree/programs in data engineering that come highly recommend?\n\n2. Are certifications a big deal/resume booster in this industry? I ask since my undergraduate degree may cause my resume to be overlooked if I were to apply for jobs.\n\n3. Aside from the skillset I've mentioned, what are some other languages/programs/methodologies that I should research?\n\n4. If you were to hire someone mid-level, what are the top 5 qualities/skills you would expect them to have?\n\nI appreciate your time and thoughts in helping me out. Thank you.", "author_fullname": "t2_65kba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking advice on career next steps", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfrlhv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666971613.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;Since 2018 I&amp;#39;ve been working as a BI Analyst primarily with Tableau, Alteryx, and MS SQL Server. My undergrad degree is in Middle Eastern Studies, and my journey into data has been largely self-taught. Currently, I am working in the auto industry where I build and maintain data pipelines for my company, as well as build Tableau reports for different business units.&lt;/p&gt;\n\n&lt;p&gt;That being said, I have felt over the last year that I need to move away from Alteryx and Tableau as they are highly expensive, and I don&amp;#39;t want to handcuff my career to those two tools. As such, I set my sights on an online masters degree with Georgia Tech in Analytics (OMSA) and have taken two of their core courses to see how I would fare in the world of machine learning + data science. Honestly, I am doing really well grades-wise and it has been a great experience learning and coding in Python. However, I&amp;#39;ve come to realize that the whole aspect of turning math/statistics-into-code is not something that appeals to me. I have come to love Python/R and manipulating datasets, but I just abhor reading through mathematical formulas, linear algebra concepts, and statistical tests.&lt;/p&gt;\n\n&lt;p&gt;With that in mind, I am weighing the option of diving deep into the aspects of my job and coursework that I do enjoy - connecting to data, cleansing it, and manipulating it to create new views and datasets in a repeatable way which seems to be what data engineering is all about. &lt;/p&gt;\n\n&lt;p&gt;All of this context aside, here are my questions that I would love to hear your opinions on:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Are there graduate degree/programs in data engineering that come highly recommend?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Are certifications a big deal/resume booster in this industry? I ask since my undergraduate degree may cause my resume to be overlooked if I were to apply for jobs.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Aside from the skillset I&amp;#39;ve mentioned, what are some other languages/programs/methodologies that I should research?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;If you were to hire someone mid-level, what are the top 5 qualities/skills you would expect them to have?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I appreciate your time and thoughts in helping me out. Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yfrlhv", "is_robot_indexable": true, "report_reasons": null, "author": "SoloArtist91", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yfrlhv/seeking_advice_on_career_next_steps/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yfrlhv/seeking_advice_on_career_next_steps/", "subreddit_subscribers": 78173, "created_utc": 1666971613.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anyone gotten the Google Cloud Professional Data Engineer Certification? It is not even clear how to study for the certification? Much less the format of the test? From what I have been looking up on-line. Can anyone advise on how to prepare and where to find study materials?  I saw the list breakdown of topics, but I am looking more for a quizlet or flashcard or test bank of the material to study from in a similar fashion as what you can find for cyber certs. Does that exist? How does someone study for this certification?", "author_fullname": "t2_lmumunvr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google Cloud Professional Data Engineer Certification", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfqwq7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666970246.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone gotten the Google Cloud Professional Data Engineer Certification? It is not even clear how to study for the certification? Much less the format of the test? From what I have been looking up on-line. Can anyone advise on how to prepare and where to find study materials?  I saw the list breakdown of topics, but I am looking more for a quizlet or flashcard or test bank of the material to study from in a similar fashion as what you can find for cyber certs. Does that exist? How does someone study for this certification?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yfqwq7", "is_robot_indexable": true, "report_reasons": null, "author": "Technical_Ad_9732", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yfqwq7/google_cloud_professional_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yfqwq7/google_cloud_professional_data_engineer/", "subreddit_subscribers": 78173, "created_utc": 1666970246.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What's your take on [Datafusion](https://github.com/apache/arrow-datafusion) ? Will it someday replace Spark ?", "author_fullname": "t2_to6i6cdw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Datafusion VS Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfoahz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666963921.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What&amp;#39;s your take on &lt;a href=\"https://github.com/apache/arrow-datafusion\"&gt;Datafusion&lt;/a&gt; ? Will it someday replace Spark ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/HZqOAXIgvL5Fo3Oz08xl0Fp7xRzRt_EtIZiVi6yqQ5c.jpg?auto=webp&amp;s=19afd3a18cc3990fd32177cb77a11e397bf26fbc", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/HZqOAXIgvL5Fo3Oz08xl0Fp7xRzRt_EtIZiVi6yqQ5c.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=091a60c1ae110a3e132ef51e223673c6d5e53513", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/HZqOAXIgvL5Fo3Oz08xl0Fp7xRzRt_EtIZiVi6yqQ5c.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ee91871a5ebbfb44b15ce416c0895801f85e309c", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/HZqOAXIgvL5Fo3Oz08xl0Fp7xRzRt_EtIZiVi6yqQ5c.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=08277c50a765ed94e876f2edf3017668191a1bd3", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/HZqOAXIgvL5Fo3Oz08xl0Fp7xRzRt_EtIZiVi6yqQ5c.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=14e1e9db417529080a0ee4ae66784fa3c4f98671", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/HZqOAXIgvL5Fo3Oz08xl0Fp7xRzRt_EtIZiVi6yqQ5c.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=493ecc03e2625df8eea5c8ab9c4e582c312b3e52", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/HZqOAXIgvL5Fo3Oz08xl0Fp7xRzRt_EtIZiVi6yqQ5c.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cbd32efc776357b7a4e38ea57fce9c7f3aa9dc22", "width": 1080, "height": 540}], "variants": {}, "id": "SkYkuh2Nq5i_pGiCN2mNn1WsEw1iyAet-hT43UgHILc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yfoahz", "is_robot_indexable": true, "report_reasons": null, "author": "LabAway8794", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yfoahz/datafusion_vs_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yfoahz/datafusion_vs_spark/", "subreddit_subscribers": 78173, "created_utc": 1666963921.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi.\n\nI am new to Airflow, and I am writing a DAG to read a file from a GCS Bucket and insert it into BigQuery. \n\nSo far, I have written the following code, which has my schema:\n```\nload_csv = gcs_to_bq.GoogleCloudStorageToBigQueryOperator(\n    task_id='gcs_to_bq_example',\n    bucket='cloud-samples-data',\n    source_objects=['bigquery/us-states/us-states.csv'],\n    destination_project_dataset_table='airflow_test.gcs_to_bq_table',\n    schema_fields=[\n        {'name': 'name', 'type': 'STRING', 'mode': 'NULLABLE'},\n        {'name': 'insertion_date', 'type': 'DATE', 'mode': 'NULLABLE'},\n    ],\n    write_disposition='WRITE_TRUNCATE',\n    dag=dag)\n```\n\nIn my schema, I have a column called ```insertion_date```, and I want it to store the current time stamp of when the data gets inserted into BigQuery.\n\nFor example, as today is 28-10-2022, if I run my DAG and execute it successfully today, then the ```insertion_date``` column will store today's date.\n\nAny help would be appreciated.", "author_fullname": "t2_13ussz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow: How to get the current timestamp of when data is inserted into BigQuery?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfpc11", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666966505.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi.&lt;/p&gt;\n\n&lt;p&gt;I am new to Airflow, and I am writing a DAG to read a file from a GCS Bucket and insert it into BigQuery. &lt;/p&gt;\n\n&lt;p&gt;So far, I have written the following code, which has my schema:\n&lt;code&gt;\nload_csv = gcs_to_bq.GoogleCloudStorageToBigQueryOperator(\n    task_id=&amp;#39;gcs_to_bq_example&amp;#39;,\n    bucket=&amp;#39;cloud-samples-data&amp;#39;,\n    source_objects=[&amp;#39;bigquery/us-states/us-states.csv&amp;#39;],\n    destination_project_dataset_table=&amp;#39;airflow_test.gcs_to_bq_table&amp;#39;,\n    schema_fields=[\n        {&amp;#39;name&amp;#39;: &amp;#39;name&amp;#39;, &amp;#39;type&amp;#39;: &amp;#39;STRING&amp;#39;, &amp;#39;mode&amp;#39;: &amp;#39;NULLABLE&amp;#39;},\n        {&amp;#39;name&amp;#39;: &amp;#39;insertion_date&amp;#39;, &amp;#39;type&amp;#39;: &amp;#39;DATE&amp;#39;, &amp;#39;mode&amp;#39;: &amp;#39;NULLABLE&amp;#39;},\n    ],\n    write_disposition=&amp;#39;WRITE_TRUNCATE&amp;#39;,\n    dag=dag)\n&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;In my schema, I have a column called &lt;code&gt;insertion_date&lt;/code&gt;, and I want it to store the current time stamp of when the data gets inserted into BigQuery.&lt;/p&gt;\n\n&lt;p&gt;For example, as today is 28-10-2022, if I run my DAG and execute it successfully today, then the &lt;code&gt;insertion_date&lt;/code&gt; column will store today&amp;#39;s date.&lt;/p&gt;\n\n&lt;p&gt;Any help would be appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yfpc11", "is_robot_indexable": true, "report_reasons": null, "author": "saucyhambon", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yfpc11/airflow_how_to_get_the_current_timestamp_of_when/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yfpc11/airflow_how_to_get_the_current_timestamp_of_when/", "subreddit_subscribers": 78173, "created_utc": 1666966505.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}