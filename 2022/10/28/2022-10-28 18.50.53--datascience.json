{"kind": "Listing", "data": {"after": "t3_yfbebv", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_2xjdvpun", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "kaggle is wild (\u2060\u30fb\u2060o\u2060\u30fb\u2060)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_yfnbab", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 190, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 190, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/JshsXvQAazpuSWBL8tKtnyIMsS3vQo3IAhN5_X602OM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666961386.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/especdi14lw91.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/especdi14lw91.png?auto=webp&amp;s=66ef51efdccb64609e9121272ab8a805ea32f190", "width": 1080, "height": 1473}, "resolutions": [{"url": "https://preview.redd.it/especdi14lw91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a147cd6ed91ccc113c6ecfc8d849ca698e448268", "width": 108, "height": 147}, {"url": "https://preview.redd.it/especdi14lw91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a9cc6bed0b48683bde9b4691d10fc35ffedbfece", "width": 216, "height": 294}, {"url": "https://preview.redd.it/especdi14lw91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d36deb6a41910ee278703e1e523afdc433e4cb05", "width": 320, "height": 436}, {"url": "https://preview.redd.it/especdi14lw91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=18fbfc9dd98895410b8fd25f93ab2dc90bd3029a", "width": 640, "height": 872}, {"url": "https://preview.redd.it/especdi14lw91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=b899ad1c04a2dc5fdd09603161d6baeedf5d6f15", "width": 960, "height": 1309}, {"url": "https://preview.redd.it/especdi14lw91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a89a5de533e66fa94a3095270db0429d6e2845f9", "width": 1080, "height": 1473}], "variants": {}, "id": "ozHlhbL--sD-arUoVdRtVi4kezXQMNn-ItoyjzUHlNU"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfnbab", "is_robot_indexable": true, "report_reasons": null, "author": "deepcontractor", "discussion_type": null, "num_comments": 90, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfnbab/kaggle_is_wild_o/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/especdi14lw91.png", "subreddit_subscribers": 815929, "created_utc": 1666961386.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a working junior data scientist. I am in a Masters in Data Science program as well as self studying data science technologies on the side. However, it is overwhelming to give focus to both + work full time, so I need help deciding how to split my time, or if I should split my time at all. \n\nHow should I split my time between MS courses and self studying the modern data technologies and frameworks being used in the real world?", "author_fullname": "t2_dbas4m3c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How should I split my time between my studying my Masters in DS program and self studying?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yf7ahw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 78, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 78, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666914158.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a working junior data scientist. I am in a Masters in Data Science program as well as self studying data science technologies on the side. However, it is overwhelming to give focus to both + work full time, so I need help deciding how to split my time, or if I should split my time at all. &lt;/p&gt;\n\n&lt;p&gt;How should I split my time between MS courses and self studying the modern data technologies and frameworks being used in the real world?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yf7ahw", "is_robot_indexable": true, "report_reasons": null, "author": "Proof_Hyena4223", "discussion_type": null, "num_comments": 45, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yf7ahw/how_should_i_split_my_time_between_my_studying_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yf7ahw/how_should_i_split_my_time_between_my_studying_my/", "subreddit_subscribers": 815929, "created_utc": 1666914158.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been working as a Data Scientist for only a short time. I spent a year working as a graduate and have recently been promoted to a permenant position. I find that within my team everyone seems to have side projects going on or be reading textbooks and listening to podcasts about Data Science in their free time. I enjoy working in Data Science and am always eager to learn more, but to be honest, I still see it as work and like to completely disconnect outside of my job to pursue and enjoy other things. I have no real desire to extend the time I spend working on or reading about the field outside of my work hours. Is this likely to hurt me in my career?", "author_fullname": "t2_jip2g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can I succeed as a Data Scientist without wanting to do extra outside of work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfhubz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666943468.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been working as a Data Scientist for only a short time. I spent a year working as a graduate and have recently been promoted to a permenant position. I find that within my team everyone seems to have side projects going on or be reading textbooks and listening to podcasts about Data Science in their free time. I enjoy working in Data Science and am always eager to learn more, but to be honest, I still see it as work and like to completely disconnect outside of my job to pursue and enjoy other things. I have no real desire to extend the time I spend working on or reading about the field outside of my work hours. Is this likely to hurt me in my career?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfhubz", "is_robot_indexable": true, "report_reasons": null, "author": "RastaSalad", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfhubz/can_i_succeed_as_a_data_scientist_without_wanting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfhubz/can_i_succeed_as_a_data_scientist_without_wanting/", "subreddit_subscribers": 815929, "created_utc": 1666943468.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys so I'm a month in at my new job as a data engineer. There are so many initiatives and so much data. I'm very new to this kind of thing to be honest with you and was hired for my general knowledge of key databases and some coding skills that I just kind of picked up at my previous role at the same company. So we are running this model in sas and they already put me in charge of data governance. I have meetings with our consultants but I basically need to drive them and ensure they are doing what they are supposed to be doing. \n\nSo I guess my question is what should I be focusing on? What are the typical key metrics that you use to validate the model, the input output data? What can I do to be successful at this? \n\nIt's a lot of new info so very overwhelming, any help is very appreciated. \n\nThank youu!!!!", "author_fullname": "t2_a8yt6gr6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "new to ml ops, having trouble", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yf6zs0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666913415.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys so I&amp;#39;m a month in at my new job as a data engineer. There are so many initiatives and so much data. I&amp;#39;m very new to this kind of thing to be honest with you and was hired for my general knowledge of key databases and some coding skills that I just kind of picked up at my previous role at the same company. So we are running this model in sas and they already put me in charge of data governance. I have meetings with our consultants but I basically need to drive them and ensure they are doing what they are supposed to be doing. &lt;/p&gt;\n\n&lt;p&gt;So I guess my question is what should I be focusing on? What are the typical key metrics that you use to validate the model, the input output data? What can I do to be successful at this? &lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s a lot of new info so very overwhelming, any help is very appreciated. &lt;/p&gt;\n\n&lt;p&gt;Thank youu!!!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yf6zs0", "is_robot_indexable": true, "report_reasons": null, "author": "MembershipNice2192", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yf6zs0/new_to_ml_ops_having_trouble/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yf6zs0/new_to_ml_ops_having_trouble/", "subreddit_subscribers": 815929, "created_utc": 1666913415.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Is it just me or is the internship grind brutal? I\u2019m applying to dozens and dozens, getting rejected by maybe 1/4. MS in biostats if that matters. My resume was said to be \u201cperfect\u201d by an interviewer so I\u2019m not worried about that. (Failed final round smh). Anybody else having the same issues?", "author_fullname": "t2_36xu0l69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Internship Grind", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfqma5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666969548.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it just me or is the internship grind brutal? I\u2019m applying to dozens and dozens, getting rejected by maybe 1/4. MS in biostats if that matters. My resume was said to be \u201cperfect\u201d by an interviewer so I\u2019m not worried about that. (Failed final round smh). Anybody else having the same issues?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "yfqma5", "is_robot_indexable": true, "report_reasons": null, "author": "GottaBeMD", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfqma5/internship_grind/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfqma5/internship_grind/", "subreddit_subscribers": 815929, "created_utc": 1666969548.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In my experience notebooks are a surprisingly controversial topic. I've seen things ranging from Databricks building tools for data scientists and data engineers that can seemingly only run on notebooks unless you install the notoriously buggy databricks connect to people using the word \"notebook\"  antithesis of good programming habits.\n\nRecently I've been listening to more talks about interactive vs batch programming and have just been reflecting on how I write code myself. Here's my own set of hot takes:\n\n&amp;#x200B;\n\n1. **The name of notebooks explains what they are meant for**. They are for experimenting, prototyping, potentially automating reports with markdown, etc. Essentially, you use them to jot down ideas as you would on a piece of paper.\n2. **You should build systems/features/... with notebooks and not with regular scripts to save time.**  You should treat your notebook as a debugger that is always on. Writing code in notebooks is a great way to build code interactively and incrementally. If you have IO sitting around and waiting to load data out of your DB to train a model each run doesn't make sense.\n3. **Notebooks DO encourage poor programming standards if you don't watch out. People say this as a buzzword without ever clarifying what they mean.** The biggest one here is the (ab)use of global variables and the fact that notebooks are typically self contained units. Having a proper project structure and reusing code across your project is important. Ideally you define building blocks in functions/classes somewhere in your project and run them in your notebooks, **if so your notebook is equivalent to production code.**\n4. **Using a notebook as a scratchpad and porting it to \"production code\" is faster than writing production code in a .py file.** This is the summary of the following 3 points and what I personally do. The overhead of porting a notebook to 4-5 different files in a clear directory structure with a main somewhere that runs them, in the same order as a notebook would, is imo just less than building it from scratch like that.\n5. **Don't delete your scratchpads, keep them around as documentation for your streamlined production workflow.** Why? Because running each block in a notebook is ime gives you more freedom than fighting with your debugger if/when something does go wrong.\n\n&amp;#x200B;\n\nSidenote:  this is why I think people have issues transitioning from R to Python or from Spyder to another IDE/text editor. R (studio) and Spyder are a lot closer to interactive programming because you can run your code line by line and not lose your variables. This is how programming should be, but not how the vast majority of people learnt it and people don't like change.", "author_fullname": "t2_5p0cu2ub", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A critical reflection of jupyter notebooks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfsxrn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666974716.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666974181.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my experience notebooks are a surprisingly controversial topic. I&amp;#39;ve seen things ranging from Databricks building tools for data scientists and data engineers that can seemingly only run on notebooks unless you install the notoriously buggy databricks connect to people using the word &amp;quot;notebook&amp;quot;  antithesis of good programming habits.&lt;/p&gt;\n\n&lt;p&gt;Recently I&amp;#39;ve been listening to more talks about interactive vs batch programming and have just been reflecting on how I write code myself. Here&amp;#39;s my own set of hot takes:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;The name of notebooks explains what they are meant for&lt;/strong&gt;. They are for experimenting, prototyping, potentially automating reports with markdown, etc. Essentially, you use them to jot down ideas as you would on a piece of paper.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;You should build systems/features/... with notebooks and not with regular scripts to save time.&lt;/strong&gt;  You should treat your notebook as a debugger that is always on. Writing code in notebooks is a great way to build code interactively and incrementally. If you have IO sitting around and waiting to load data out of your DB to train a model each run doesn&amp;#39;t make sense.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Notebooks DO encourage poor programming standards if you don&amp;#39;t watch out. People say this as a buzzword without ever clarifying what they mean.&lt;/strong&gt; The biggest one here is the (ab)use of global variables and the fact that notebooks are typically self contained units. Having a proper project structure and reusing code across your project is important. Ideally you define building blocks in functions/classes somewhere in your project and run them in your notebooks, &lt;strong&gt;if so your notebook is equivalent to production code.&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Using a notebook as a scratchpad and porting it to &amp;quot;production code&amp;quot; is faster than writing production code in a .py file.&lt;/strong&gt; This is the summary of the following 3 points and what I personally do. The overhead of porting a notebook to 4-5 different files in a clear directory structure with a main somewhere that runs them, in the same order as a notebook would, is imo just less than building it from scratch like that.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Don&amp;#39;t delete your scratchpads, keep them around as documentation for your streamlined production workflow.&lt;/strong&gt; Why? Because running each block in a notebook is ime gives you more freedom than fighting with your debugger if/when something does go wrong.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Sidenote:  this is why I think people have issues transitioning from R to Python or from Spyder to another IDE/text editor. R (studio) and Spyder are a lot closer to interactive programming because you can run your code line by line and not lose your variables. This is how programming should be, but not how the vast majority of people learnt it and people don&amp;#39;t like change.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfsxrn", "is_robot_indexable": true, "report_reasons": null, "author": "Aggressive_Ad_3178", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfsxrn/a_critical_reflection_of_jupyter_notebooks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfsxrn/a_critical_reflection_of_jupyter_notebooks/", "subreddit_subscribers": 815929, "created_utc": 1666974181.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a tad confused and a noob, please be patient.\n\nI was watching one of my co-workers analyse and visualise some data and he said he was going to normalise the data. For normalisation I normally used the mean, standard deviation and standarise the data using those.\n\nHowever, this is what he did:\n\nCalculated the regression equation.\n\nUsing the independent variable coefficient and the intercept (from the previous step) he calculated the predicted y.\n\nProceeded to substract the actual y against the predicted y and then add the average of all of the predicted y.\n\nWhat essentially happened is that he got rid of the independent variable coefficient (if you were to graph it, the trendline would be flat). Now:\n\nIS this actually normalising data or is it integration? if neither, what would this be? and why should I do it?\n\nI am asking since he had to go.", "author_fullname": "t2_q2cte", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Simple question about normalising and integrating data.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfe464", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666931955.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a tad confused and a noob, please be patient.&lt;/p&gt;\n\n&lt;p&gt;I was watching one of my co-workers analyse and visualise some data and he said he was going to normalise the data. For normalisation I normally used the mean, standard deviation and standarise the data using those.&lt;/p&gt;\n\n&lt;p&gt;However, this is what he did:&lt;/p&gt;\n\n&lt;p&gt;Calculated the regression equation.&lt;/p&gt;\n\n&lt;p&gt;Using the independent variable coefficient and the intercept (from the previous step) he calculated the predicted y.&lt;/p&gt;\n\n&lt;p&gt;Proceeded to substract the actual y against the predicted y and then add the average of all of the predicted y.&lt;/p&gt;\n\n&lt;p&gt;What essentially happened is that he got rid of the independent variable coefficient (if you were to graph it, the trendline would be flat). Now:&lt;/p&gt;\n\n&lt;p&gt;IS this actually normalising data or is it integration? if neither, what would this be? and why should I do it?&lt;/p&gt;\n\n&lt;p&gt;I am asking since he had to go.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfe464", "is_robot_indexable": true, "report_reasons": null, "author": "manuelgcg", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfe464/simple_question_about_normalising_and_integrating/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfe464/simple_question_about_normalising_and_integrating/", "subreddit_subscribers": 815929, "created_utc": 1666931955.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Currently a Biochemistry grad working in research for a blood banking company. Hate it. Thinking about a masters in data science or pursuing certs on my free time without a masters. \n\nWould anyone like to give a realistic run down of what a typical day looks like for you working in data science? \n\n\nAlso, is data science similar to computer science in the aspect that you don\u2019t need a degree just need to know your stuff to secure a job? (Unlike the translational side of science, degree means everything\ud83d\ude43) \n\nThanks in advance!", "author_fullname": "t2_9csm8sf4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career Switch", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yez6vq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666894655.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently a Biochemistry grad working in research for a blood banking company. Hate it. Thinking about a masters in data science or pursuing certs on my free time without a masters. &lt;/p&gt;\n\n&lt;p&gt;Would anyone like to give a realistic run down of what a typical day looks like for you working in data science? &lt;/p&gt;\n\n&lt;p&gt;Also, is data science similar to computer science in the aspect that you don\u2019t need a degree just need to know your stuff to secure a job? (Unlike the translational side of science, degree means everything\ud83d\ude43) &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yez6vq", "is_robot_indexable": true, "report_reasons": null, "author": "SprayPsychological86", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yez6vq/career_switch/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yez6vq/career_switch/", "subreddit_subscribers": 815929, "created_utc": 1666894655.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently participating in datacamp competition,I need some help selecting my model for the output\n\n# Project Goal\n\n**Using the network analysis, in which departments would you recommend the HR team focus to boost collaboration?**\n\n# Data Set Info\n\n\\#### Messages has information on the sender, receiver, and time.\n\n\\- \"sender\" - represents the employee id of the employee sending the message.\n\n\\- \"receiver\" - represents the employee id of the employee receiving the message.\n\n\\- \"timestamp\" - the date of the message.\n\n\\- \"message\\_length\" - the length in words of the message.\n\n&amp;#x200B;\n\n\\#### Employees has information on each employee;\n\n\\- \"id\" - represents the employee id of the employee.\n\n\\- \"department\" - is the department within the company. \n\n\\- \"location\" - is the country where the employee lives.\n\n\\- \"age\" - is the age of the employee.\n\n[https://drive.google.com/drive/folders/1aijyRGETvelAkT6x0ew2skIjmxxryHPV?usp=sharing](https://drive.google.com/drive/folders/1aijyRGETvelAkT6x0ew2skIjmxxryHPV?usp=sharing)\n\n&amp;#x200B;\n\n# My work till now\n\nI haven't made many changes to the dataset. just tried to find the co-relation between different attributes and some visualization which was required for the project ( lmk if they are shit)\n\n&amp;#x200B;\n\n[Messages sent based on time and department](https://preview.redd.it/nnodk91egjw91.png?width=944&amp;format=png&amp;auto=webp&amp;s=86c5bc7a3bb11bc32bfd5244ba38950cd62448ae)\n\n[Number of messages sent based on location](https://preview.redd.it/2judthi3gjw91.png?width=807&amp;format=png&amp;auto=webp&amp;s=e322fd8d1a42b741953b973e1844f80f32e3e74f)\n\n&amp;#x200B;\n\n[No. of messages sent based on department](https://preview.redd.it/eio4rqp8gjw91.png?width=1433&amp;format=png&amp;auto=webp&amp;s=516fc47091a330c7ba78bc6bd3f273f7e17ab06c)\n\nObservations: \n\n1. All Branches has sales as largest department except US\n\n2. Largest department in US is operations, second is Brazil and UK has no Operation dep\n\n3. Germany has highest Sales department, with 68.45% of total branch and Brazil Coming in no. 2\n\n4. It's weird that only first 2 months have high conversations\n\nCreate a report that covers the following:  \n\n  1. Which departments are the most/least active? \n\ni)  Most:-  Sales(1.55k msg)\n\nii) least:- Marketing(16 msgs)\n\n  2. Which employee has the most connections?  - \n\ni)  Sender  :- 605(459, Admin)\n\nii) Receiver:- 281(60,Sales) \n\n  3. Which Department has the most connections? \n\ni) sender Department:- Sales(1.5k)\n\nii) receiver Dep:- Sales(1.23k)\n\n&amp;#x200B;\n\n&gt;**I know my data might be just random with no path followed, well this is partially truth, since 3 factors are affecting the message sent 1. Time, 2. Location, 3. Department**\n\n&amp;#x200B;\n\n&gt;My first thoughts were to look it as a time series model but after looking at the msg based on time graph It was dissolved  \n&gt;  \n&gt;My second thoughts was to look it as a network model like graph with sender and receiver as nodes and msgs as edge weight but I don't much clue on how to deal with it", "author_fullname": "t2_3hg5hlo7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best model for network Analysis", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 53, "top_awarded_type": null, "hide_score": false, "media_metadata": {"2judthi3gjw91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 104, "x": 108, "u": "https://preview.redd.it/2judthi3gjw91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f4914cfa061400ddc67bbc6af034e7cc37c95987"}, {"y": 208, "x": 216, "u": "https://preview.redd.it/2judthi3gjw91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=022e2127a831c48e0daf76bfb488c2bb4fb6adbd"}, {"y": 309, "x": 320, "u": "https://preview.redd.it/2judthi3gjw91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=1e1601daacb1a977defefddaeaa5f4eb30dddc19"}, {"y": 618, "x": 640, "u": "https://preview.redd.it/2judthi3gjw91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=211a3e2852378fcb708ce709e160d1e99043c0d3"}], "s": {"y": 780, "x": 807, "u": "https://preview.redd.it/2judthi3gjw91.png?width=807&amp;format=png&amp;auto=webp&amp;s=e322fd8d1a42b741953b973e1844f80f32e3e74f"}, "id": "2judthi3gjw91"}, "eio4rqp8gjw91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/eio4rqp8gjw91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6f8a97a8c91a8fc1683183f90a8e666bd78754f0"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/eio4rqp8gjw91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d1790cfe40d4db06a90e14f31f1dff2f08f9b585"}, {"y": 179, "x": 320, "u": "https://preview.redd.it/eio4rqp8gjw91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3da26c8fd3fec597272eb7a6de46c673430a4360"}, {"y": 359, "x": 640, "u": "https://preview.redd.it/eio4rqp8gjw91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=32211baab0e86ab02cc4239a4526d79b33fb2c48"}, {"y": 538, "x": 960, "u": "https://preview.redd.it/eio4rqp8gjw91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=b4e5f40dda1a65162828b42e28c16a39d2a57877"}, {"y": 605, "x": 1080, "u": "https://preview.redd.it/eio4rqp8gjw91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=15eeae2ce4bd5cb4470b65f9b639f9cda73c2852"}], "s": {"y": 804, "x": 1433, "u": "https://preview.redd.it/eio4rqp8gjw91.png?width=1433&amp;format=png&amp;auto=webp&amp;s=516fc47091a330c7ba78bc6bd3f273f7e17ab06c"}, "id": "eio4rqp8gjw91"}, "nnodk91egjw91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 41, "x": 108, "u": "https://preview.redd.it/nnodk91egjw91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7a43d24da16d39c3ea2b498a5ec1b8ae271fb538"}, {"y": 82, "x": 216, "u": "https://preview.redd.it/nnodk91egjw91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=05d4ae3b24915ddaa5c76e05fd7b4517165cdec4"}, {"y": 122, "x": 320, "u": "https://preview.redd.it/nnodk91egjw91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c39b177336e6a6e580d097d7c9ca9c9c96b0a0aa"}, {"y": 245, "x": 640, "u": "https://preview.redd.it/nnodk91egjw91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ebb17ec1627a8a2e4d4f054228cece4b0ded4de7"}], "s": {"y": 362, "x": 944, "u": "https://preview.redd.it/nnodk91egjw91.png?width=944&amp;format=png&amp;auto=webp&amp;s=86c5bc7a3bb11bc32bfd5244ba38950cd62448ae"}, "id": "nnodk91egjw91"}}, "name": "t3_yfmry5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/kGVMenG6zW_kSwqvSBLqHuFFu6I-vOVHawBUyiiZPTE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666959881.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently participating in datacamp competition,I need some help selecting my model for the output&lt;/p&gt;\n\n&lt;h1&gt;Project Goal&lt;/h1&gt;\n\n&lt;p&gt;&lt;strong&gt;Using the network analysis, in which departments would you recommend the HR team focus to boost collaboration?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;h1&gt;Data Set Info&lt;/h1&gt;\n\n&lt;p&gt;#### Messages has information on the sender, receiver, and time.&lt;/p&gt;\n\n&lt;p&gt;- &amp;quot;sender&amp;quot; - represents the employee id of the employee sending the message.&lt;/p&gt;\n\n&lt;p&gt;- &amp;quot;receiver&amp;quot; - represents the employee id of the employee receiving the message.&lt;/p&gt;\n\n&lt;p&gt;- &amp;quot;timestamp&amp;quot; - the date of the message.&lt;/p&gt;\n\n&lt;p&gt;- &amp;quot;message_length&amp;quot; - the length in words of the message.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;#### Employees has information on each employee;&lt;/p&gt;\n\n&lt;p&gt;- &amp;quot;id&amp;quot; - represents the employee id of the employee.&lt;/p&gt;\n\n&lt;p&gt;- &amp;quot;department&amp;quot; - is the department within the company. &lt;/p&gt;\n\n&lt;p&gt;- &amp;quot;location&amp;quot; - is the country where the employee lives.&lt;/p&gt;\n\n&lt;p&gt;- &amp;quot;age&amp;quot; - is the age of the employee.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://drive.google.com/drive/folders/1aijyRGETvelAkT6x0ew2skIjmxxryHPV?usp=sharing\"&gt;https://drive.google.com/drive/folders/1aijyRGETvelAkT6x0ew2skIjmxxryHPV?usp=sharing&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;h1&gt;My work till now&lt;/h1&gt;\n\n&lt;p&gt;I haven&amp;#39;t made many changes to the dataset. just tried to find the co-relation between different attributes and some visualization which was required for the project ( lmk if they are shit)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/nnodk91egjw91.png?width=944&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=86c5bc7a3bb11bc32bfd5244ba38950cd62448ae\"&gt;Messages sent based on time and department&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/2judthi3gjw91.png?width=807&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e322fd8d1a42b741953b973e1844f80f32e3e74f\"&gt;Number of messages sent based on location&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/eio4rqp8gjw91.png?width=1433&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=516fc47091a330c7ba78bc6bd3f273f7e17ab06c\"&gt;No. of messages sent based on department&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Observations: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;All Branches has sales as largest department except US&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Largest department in US is operations, second is Brazil and UK has no Operation dep&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Germany has highest Sales department, with 68.45% of total branch and Brazil Coming in no. 2&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;It&amp;#39;s weird that only first 2 months have high conversations&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Create a report that covers the following:  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Which departments are the most/least active? &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;i)  Most:-  Sales(1.55k msg)&lt;/p&gt;\n\n&lt;p&gt;ii) least:- Marketing(16 msgs)&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Which employee has the most connections?  - &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;i)  Sender  :- 605(459, Admin)&lt;/p&gt;\n\n&lt;p&gt;ii) Receiver:- 281(60,Sales) &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Which Department has the most connections? &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;i) sender Department:- Sales(1.5k)&lt;/p&gt;\n\n&lt;p&gt;ii) receiver Dep:- Sales(1.23k)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;&lt;strong&gt;I know my data might be just random with no path followed, well this is partially truth, since 3 factors are affecting the message sent 1. Time, 2. Location, 3. Department&lt;/strong&gt;&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;My first thoughts were to look it as a time series model but after looking at the msg based on time graph It was dissolved  &lt;/p&gt;\n\n&lt;p&gt;My second thoughts was to look it as a network model like graph with sender and receiver as nodes and msgs as edge weight but I don&amp;#39;t much clue on how to deal with it&lt;/p&gt;\n&lt;/blockquote&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfmry5", "is_robot_indexable": true, "report_reasons": null, "author": "SupaSTaZz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfmry5/best_model_for_network_analysis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfmry5/best_model_for_network_analysis/", "subreddit_subscribers": 815929, "created_utc": 1666959881.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Need assistance helping a set of patients. I have a dataset of events recording a non-continuous time value, meaning I get a WhatsApp message every time such event happens. Now the data set is In the order of thousands so I was wondering if there is a way to predict when the next event will be so we can:\n\n1) Measure a closer before and after on a set of physiological features \n2) try to counteract the onset with a special drug", "author_fullname": "t2_es9dac8d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help predicting the future!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yflwvf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666957378.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Need assistance helping a set of patients. I have a dataset of events recording a non-continuous time value, meaning I get a WhatsApp message every time such event happens. Now the data set is In the order of thousands so I was wondering if there is a way to predict when the next event will be so we can:&lt;/p&gt;\n\n&lt;p&gt;1) Measure a closer before and after on a set of physiological features \n2) try to counteract the onset with a special drug&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yflwvf", "is_robot_indexable": true, "report_reasons": null, "author": "SlowAndLate", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yflwvf/help_predicting_the_future/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yflwvf/help_predicting_the_future/", "subreddit_subscribers": 815929, "created_utc": 1666957378.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am working on a ML project and need data for population density (I live in small country with not much data) . Is it possible to find a website from which I can download satellite pictures (compiled every day for an year) at night of my town, so I can estimate the population concentration by the given lights. Thanks.", "author_fullname": "t2_aws8tyj4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Satellite images data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfir8m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666946824.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working on a ML project and need data for population density (I live in small country with not much data) . Is it possible to find a website from which I can download satellite pictures (compiled every day for an year) at night of my town, so I can estimate the population concentration by the given lights. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfir8m", "is_robot_indexable": true, "report_reasons": null, "author": "AnyJello605", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfir8m/satellite_images_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfir8m/satellite_images_data/", "subreddit_subscribers": 815929, "created_utc": 1666946824.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\nMost of the e2e DS tutorials cover feature engineering (OHE, LE, Norm, etc.) and splitting complete data into train and test sets. As you know, in real life, there is no x\\_train and y\\_train. You need to do labeling using your raw data. However, there are no tutorials covering **tabular** data labeling. Are there any recommended tutorials, git repositories, or blog posts to learn and exercise for labeling? It can be related churn labeling, likelihood to buy, or spend forecasting etc.\n\nTLDR: Looking for tutorials about **tabular data labeling** (creating target variable).", "author_fullname": "t2_rehw0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for tabular data prep/labeling tutorials", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfhhhp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666942149.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;Most of the e2e DS tutorials cover feature engineering (OHE, LE, Norm, etc.) and splitting complete data into train and test sets. As you know, in real life, there is no x_train and y_train. You need to do labeling using your raw data. However, there are no tutorials covering &lt;strong&gt;tabular&lt;/strong&gt; data labeling. Are there any recommended tutorials, git repositories, or blog posts to learn and exercise for labeling? It can be related churn labeling, likelihood to buy, or spend forecasting etc.&lt;/p&gt;\n\n&lt;p&gt;TLDR: Looking for tutorials about &lt;strong&gt;tabular data labeling&lt;/strong&gt; (creating target variable).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfhhhp", "is_robot_indexable": true, "report_reasons": null, "author": "silverstone1903", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfhhhp/looking_for_tabular_data_preplabeling_tutorials/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfhhhp/looking_for_tabular_data_preplabeling_tutorials/", "subreddit_subscribers": 815929, "created_utc": 1666942149.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "i basically have 1-2-3 (high medium low quality) and want to plot the counts, stacked, on a histogram. Only thing is I want something like an interactive button to bring the selected histogram to the front  \n\n\nWhat can I easily do this with in python?  \n\n\nI will then make it web runnable on steamlit", "author_fullname": "t2_lww73a7r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I make an interactive histogram in python?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfaot7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666922693.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i basically have 1-2-3 (high medium low quality) and want to plot the counts, stacked, on a histogram. Only thing is I want something like an interactive button to bring the selected histogram to the front  &lt;/p&gt;\n\n&lt;p&gt;What can I easily do this with in python?  &lt;/p&gt;\n\n&lt;p&gt;I will then make it web runnable on steamlit&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfaot7", "is_robot_indexable": true, "report_reasons": null, "author": "fartuni4", "discussion_type": null, "num_comments": 11, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfaot7/how_can_i_make_an_interactive_histogram_in_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfaot7/how_can_i_make_an_interactive_histogram_in_python/", "subreddit_subscribers": 815929, "created_utc": 1666922693.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m curious to know what the consensus on best online master\u2019s in data science is? I am a little less price dependent as my company would cover $30k or so.\n\nThe 3 I keep seeing as being rated pretty well are Georgia Tech, Texas, and Illinois.\n\nIs this accurate?\n\nWould love to hear where different people went, how the program was, and roughly how much time they spent per class per week.\n\nThank you so much in advance!\n\nEdit:\n\nBackground: I double majored in undergrad in CS and business (CS department is ranked top or so from what I\u2019ve seen). I will say that I consider my math background to be weaker. I took stats, discrete, calc, etc but not linear algebra.\n\nI have spent the 2.5ish years since graduation as a data analyst.", "author_fullname": "t2_17qwjq21", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best online master\u2019s in data science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfaiou", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666964695.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666922270.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m curious to know what the consensus on best online master\u2019s in data science is? I am a little less price dependent as my company would cover $30k or so.&lt;/p&gt;\n\n&lt;p&gt;The 3 I keep seeing as being rated pretty well are Georgia Tech, Texas, and Illinois.&lt;/p&gt;\n\n&lt;p&gt;Is this accurate?&lt;/p&gt;\n\n&lt;p&gt;Would love to hear where different people went, how the program was, and roughly how much time they spent per class per week.&lt;/p&gt;\n\n&lt;p&gt;Thank you so much in advance!&lt;/p&gt;\n\n&lt;p&gt;Edit:&lt;/p&gt;\n\n&lt;p&gt;Background: I double majored in undergrad in CS and business (CS department is ranked top or so from what I\u2019ve seen). I will say that I consider my math background to be weaker. I took stats, discrete, calc, etc but not linear algebra.&lt;/p&gt;\n\n&lt;p&gt;I have spent the 2.5ish years since graduation as a data analyst.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfaiou", "is_robot_indexable": true, "report_reasons": null, "author": "PowerfulSquirrel4", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfaiou/best_online_masters_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfaiou/best_online_masters_in_data_science/", "subreddit_subscribers": 815929, "created_utc": 1666922270.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a fairly large dataset where I'm supposed to use independent variables to predict the dependent variable (classic). However, I know for certain that there is an underlying equation linking my independent variables to my dependent variable which explains them fully. The problem is I have no idea how to uncover this relationship. This relationship is likely non-linear but additive. How do I go about decomposing this problem?", "author_fullname": "t2_l7hoj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to uncover underlying equation between independent and dependent variables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfsf52", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666973188.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a fairly large dataset where I&amp;#39;m supposed to use independent variables to predict the dependent variable (classic). However, I know for certain that there is an underlying equation linking my independent variables to my dependent variable which explains them fully. The problem is I have no idea how to uncover this relationship. This relationship is likely non-linear but additive. How do I go about decomposing this problem?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfsf52", "is_robot_indexable": true, "report_reasons": null, "author": "ReaperJr", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfsf52/how_to_uncover_underlying_equation_between/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfsf52/how_to_uncover_underlying_equation_between/", "subreddit_subscribers": 815929, "created_utc": 1666973188.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For an example, lets say i take on an NLP project to anonymise and classify some text.\n\nTypically id start with a simple approch to solve the problem and meet the scope of the project. This might mean using some prebuilt package to anonymise, and a fairly simple tree model to classify.\n\nThis meets the scope and means we can progress to get something into production, wit the view that when its productionised, we can hot swap improvements in the pipeline.\n\nMy question is, how do you justify to the business these improvements if they view the problem as solved? \n\nFor small changes like replacing a random forest with a lgbm, thats not so bad. However, i mean like replacing the anonymisation package with a more custom CNN or LSTM approach? Thats a much bigger change.\n\nI feel like the answer is \u2018why bother if the business doesn\u2019t see value in it/the current solution doing the job\u2019. But part of our teams role is to progress data science in the business - so we cant just go off what the business thinks as they dont know the art of the possible.\n\nYes its down to the data scientist to communicate the value of the work, but how would you justify such a change in this usecase?", "author_fullname": "t2_gm8b3iu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "For those in industry - how do you know when to/ justify revisiting a project?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfl2t4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666954860.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For an example, lets say i take on an NLP project to anonymise and classify some text.&lt;/p&gt;\n\n&lt;p&gt;Typically id start with a simple approch to solve the problem and meet the scope of the project. This might mean using some prebuilt package to anonymise, and a fairly simple tree model to classify.&lt;/p&gt;\n\n&lt;p&gt;This meets the scope and means we can progress to get something into production, wit the view that when its productionised, we can hot swap improvements in the pipeline.&lt;/p&gt;\n\n&lt;p&gt;My question is, how do you justify to the business these improvements if they view the problem as solved? &lt;/p&gt;\n\n&lt;p&gt;For small changes like replacing a random forest with a lgbm, thats not so bad. However, i mean like replacing the anonymisation package with a more custom CNN or LSTM approach? Thats a much bigger change.&lt;/p&gt;\n\n&lt;p&gt;I feel like the answer is \u2018why bother if the business doesn\u2019t see value in it/the current solution doing the job\u2019. But part of our teams role is to progress data science in the business - so we cant just go off what the business thinks as they dont know the art of the possible.&lt;/p&gt;\n\n&lt;p&gt;Yes its down to the data scientist to communicate the value of the work, but how would you justify such a change in this usecase?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfl2t4", "is_robot_indexable": true, "report_reasons": null, "author": "poppycocknbalderdash", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfl2t4/for_those_in_industry_how_do_you_know_when_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfl2t4/for_those_in_industry_how_do_you_know_when_to/", "subreddit_subscribers": 815929, "created_utc": 1666954860.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Pretty much what the title says. Do you have any you'd recommend?\n\nFor reference, I'm about to get out of undergrad. I didn't practice much of statistics but through side projects doing data analysis &amp; machine learning, I realized how important this was kind of late imo.  I'm vaguely familiar with calculus, it's been a while since I've looked at multivariable, I already have a book for that for review. \n\nLooking for statistics mainly. But if you do happen to have one for linear algebra you'd recommend, that'd be appreciated as well. ; )\n\nAnything to help understand these models more lol.", "author_fullname": "t2_u7pn8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommendations for introductory statistical texts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfi7k2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666945150.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666944783.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Pretty much what the title says. Do you have any you&amp;#39;d recommend?&lt;/p&gt;\n\n&lt;p&gt;For reference, I&amp;#39;m about to get out of undergrad. I didn&amp;#39;t practice much of statistics but through side projects doing data analysis &amp;amp; machine learning, I realized how important this was kind of late imo.  I&amp;#39;m vaguely familiar with calculus, it&amp;#39;s been a while since I&amp;#39;ve looked at multivariable, I already have a book for that for review. &lt;/p&gt;\n\n&lt;p&gt;Looking for statistics mainly. But if you do happen to have one for linear algebra you&amp;#39;d recommend, that&amp;#39;d be appreciated as well. ; )&lt;/p&gt;\n\n&lt;p&gt;Anything to help understand these models more lol.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfi7k2", "is_robot_indexable": true, "report_reasons": null, "author": "pekkalacd", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfi7k2/recommendations_for_introductory_statistical_texts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfi7k2/recommendations_for_introductory_statistical_texts/", "subreddit_subscribers": 815929, "created_utc": 1666944783.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ve recently started at a new company in a hybrid DS/engineering role. It\u2019s an older company in the utility industry, so there\u2019s a pretty healthy mix of \u201ctraditional\u201d &amp; modern ways of keeping track of things (events, equipment, project status, etc). Thankfully we do have some Oracle DBs in place that a couple members on the team are using to build new dashboards and analytics scripts from. However, lots of existing/historical work tracking is done through random Excel sheets scattered about the network drives. There always exists a desire to move forward and advance our current practices to increase effectiveness &amp; efficiency within the company\u2019s data handling schemes. \n\nWe can develop new scripts/dashboards and do all kinds of cool stuff on that side of things. I\u2019m just curious as to what methods other people may be using to bridge gaps between scattered Excel data/reporting sheets and more centralized dashboarding/SW development practices. \n\nIf you couldn\u2019t tell, I\u2019m a bit new the DS working side. I\u2019ve done lots with Python, SQL, and a few dashboard platforms, but I\u2019m still new to the real world applications of DS. \n\nThanks!", "author_fullname": "t2_dv1qy8c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bridging the gap between old &amp; new methods of DS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yf5883", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666909123.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve recently started at a new company in a hybrid DS/engineering role. It\u2019s an older company in the utility industry, so there\u2019s a pretty healthy mix of \u201ctraditional\u201d &amp;amp; modern ways of keeping track of things (events, equipment, project status, etc). Thankfully we do have some Oracle DBs in place that a couple members on the team are using to build new dashboards and analytics scripts from. However, lots of existing/historical work tracking is done through random Excel sheets scattered about the network drives. There always exists a desire to move forward and advance our current practices to increase effectiveness &amp;amp; efficiency within the company\u2019s data handling schemes. &lt;/p&gt;\n\n&lt;p&gt;We can develop new scripts/dashboards and do all kinds of cool stuff on that side of things. I\u2019m just curious as to what methods other people may be using to bridge gaps between scattered Excel data/reporting sheets and more centralized dashboarding/SW development practices. &lt;/p&gt;\n\n&lt;p&gt;If you couldn\u2019t tell, I\u2019m a bit new the DS working side. I\u2019ve done lots with Python, SQL, and a few dashboard platforms, but I\u2019m still new to the real world applications of DS. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yf5883", "is_robot_indexable": true, "report_reasons": null, "author": "ljh78", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yf5883/bridging_the_gap_between_old_new_methods_of_ds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yf5883/bridging_the_gap_between_old_new_methods_of_ds/", "subreddit_subscribers": 815929, "created_utc": 1666909123.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What is the one advice you would give, to someone  starting Data Science from zero?", "author_fullname": "t2_lz0gar3p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need Some Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yfv1a4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666978227.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is the one advice you would give, to someone  starting Data Science from zero?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfv1a4", "is_robot_indexable": true, "report_reasons": null, "author": "TranslatorClean1924", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfv1a4/need_some_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfv1a4/need_some_advice/", "subreddit_subscribers": 815929, "created_utc": 1666978227.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "https://thedatascientist.com/podcast-kate-dudzik-ai-ethics-product-based-data-science/", "author_fullname": "t2_ru389j1n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Podcast: Kate Dudzik on AI ethics, product-led data science and more!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yfttfy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666975886.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://thedatascientist.com/podcast-kate-dudzik-ai-ethics-product-based-data-science/\"&gt;https://thedatascientist.com/podcast-kate-dudzik-ai-ethics-product-based-data-science/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfttfy", "is_robot_indexable": true, "report_reasons": null, "author": "AI_Datascientist", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfttfy/podcast_kate_dudzik_on_ai_ethics_productled_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfttfy/podcast_kate_dudzik_on_ai_ethics_productled_data/", "subreddit_subscribers": 815929, "created_utc": 1666975886.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I would like to transfer some powerbi dashboards in python using dash/plotly. The power I dashboards read data from SQL and are pretty good at navigating the complex data schema of the database. I am looking to implement something similar in Dash. However, I am struggling with creating dynamic drop downs and joining data from different tables. Has anyone done anything similar and could offer some tips/ resources? Is what I am trying to do completely bonkers? Feel free to give me feedback. Thanks", "author_fullname": "t2_hp8zd1sv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dashboards using Dash/Plotly that read data from Azure SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yft5rr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666974613.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like to transfer some powerbi dashboards in python using dash/plotly. The power I dashboards read data from SQL and are pretty good at navigating the complex data schema of the database. I am looking to implement something similar in Dash. However, I am struggling with creating dynamic drop downs and joining data from different tables. Has anyone done anything similar and could offer some tips/ resources? Is what I am trying to do completely bonkers? Feel free to give me feedback. Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yft5rr", "is_robot_indexable": true, "report_reasons": null, "author": "Living-Stable9651", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yft5rr/dashboards_using_dashplotly_that_read_data_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yft5rr/dashboards_using_dashplotly_that_read_data_from/", "subreddit_subscribers": 815929, "created_utc": 1666974613.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,\n\nI'm going to work on a problem where the goal is to define a way to predict the parameters (x_1, x_2, ..., x_n) that result in a certain value of the target feature (y) which is a numerical variable. The features are a mixture of numerical and categorical variables.\n\nThe data is a result of an experiment where for a desired output value (y_desired), we set a different parameters (x_1, x_2, ..., x_n), conduct the experiment and record the actual output (y_actual). The goal here is to create a model that helps in defining the input parameters to minimize the gap between the desired and the actual output (y_desired and y_actual).\n\nWhat would my options in terms of methods and algorithms in this case?", "author_fullname": "t2_7zfg2ptp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Predicting input parameters from target value", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfqabl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666968776.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m going to work on a problem where the goal is to define a way to predict the parameters (x_1, x_2, ..., x_n) that result in a certain value of the target feature (y) which is a numerical variable. The features are a mixture of numerical and categorical variables.&lt;/p&gt;\n\n&lt;p&gt;The data is a result of an experiment where for a desired output value (y_desired), we set a different parameters (x_1, x_2, ..., x_n), conduct the experiment and record the actual output (y_actual). The goal here is to create a model that helps in defining the input parameters to minimize the gap between the desired and the actual output (y_desired and y_actual).&lt;/p&gt;\n\n&lt;p&gt;What would my options in terms of methods and algorithms in this case?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfqabl", "is_robot_indexable": true, "report_reasons": null, "author": "ARFGHA", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfqabl/predicting_input_parameters_from_target_value/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfqabl/predicting_input_parameters_from_target_value/", "subreddit_subscribers": 815929, "created_utc": 1666968776.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As the title says, I am interested in gauging the availability of totally remote part time entry level data jobs (analytics/DS/MLE/DE) paying in USD or other high valued currency. I work as a full time junior data scientist and transitioning into a part time remote job would be perfect for working on my masters degree and personal studies. My goal is to prepare for this during 2023, basically grinding on whatever I need to to achieve this (thinking on getting a few certs and go hard on leetcode) and landing said job by jan/2024.\n\nDoes anyone know if this is possible? Are my plans too far fetched? Any tips for this?", "author_fullname": "t2_bge735fm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Availability of 100% Remote Part Time Entry Level Jobs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfolrz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666964723.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title says, I am interested in gauging the availability of totally remote part time entry level data jobs (analytics/DS/MLE/DE) paying in USD or other high valued currency. I work as a full time junior data scientist and transitioning into a part time remote job would be perfect for working on my masters degree and personal studies. My goal is to prepare for this during 2023, basically grinding on whatever I need to to achieve this (thinking on getting a few certs and go hard on leetcode) and landing said job by jan/2024.&lt;/p&gt;\n\n&lt;p&gt;Does anyone know if this is possible? Are my plans too far fetched? Any tips for this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "yfolrz", "is_robot_indexable": true, "report_reasons": null, "author": "computerblood", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfolrz/availability_of_100_remote_part_time_entry_level/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfolrz/availability_of_100_remote_part_time_entry_level/", "subreddit_subscribers": 815929, "created_utc": 1666964723.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm trying to analyze how total nitrogen and total sugar levels respond to the control or if there is even a relationship between the two. Does this require a multivariate multiple regression? If not, what would be the most effective method of statistical analysis?\n\nhttps://preview.redd.it/yni8thsyfjw91.png?width=528&amp;format=png&amp;auto=webp&amp;s=6cc1388aec9b64d31b7e59d455c3a41ea5172eb7", "author_fullname": "t2_ql5c6gd2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does this dataset require multivariate regression?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"yni8thsyfjw91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 137, "x": 108, "u": "https://preview.redd.it/yni8thsyfjw91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=335cd0864fa6ccb862b22c69277f6a29eae4694e"}, {"y": 275, "x": 216, "u": "https://preview.redd.it/yni8thsyfjw91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7993b653259039211910cf46077bf0be2836d730"}, {"y": 407, "x": 320, "u": "https://preview.redd.it/yni8thsyfjw91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b4e5a99f2013a27bcd41a26671b356e2b1e2f68d"}], "s": {"y": 673, "x": 528, "u": "https://preview.redd.it/yni8thsyfjw91.png?width=528&amp;format=png&amp;auto=webp&amp;s=6cc1388aec9b64d31b7e59d455c3a41ea5172eb7"}, "id": "yni8thsyfjw91"}}, "name": "t3_yfmlhj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/73xjUj3M73hEgaTJDU909GSBkO-QtQt2saX-NuyL81Y.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666959367.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to analyze how total nitrogen and total sugar levels respond to the control or if there is even a relationship between the two. Does this require a multivariate multiple regression? If not, what would be the most effective method of statistical analysis?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/yni8thsyfjw91.png?width=528&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=6cc1388aec9b64d31b7e59d455c3a41ea5172eb7\"&gt;https://preview.redd.it/yni8thsyfjw91.png?width=528&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=6cc1388aec9b64d31b7e59d455c3a41ea5172eb7&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfmlhj", "is_robot_indexable": true, "report_reasons": null, "author": "AmphibianNew3975", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfmlhj/does_this_dataset_require_multivariate_regression/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfmlhj/does_this_dataset_require_multivariate_regression/", "subreddit_subscribers": 815929, "created_utc": 1666959367.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello yall,\n\nI am doing a project for my economics class and was wondering if anyone in this subreddit has any interesting articles or studies that can show causality between tax-breaks and  economic growth or income. I need to isolate and use methods such as difference-in-difference or other methods to somehow show that a tax break helped or didn't help a state or city. Any thoughts or suggestions or other ways to look at this project? \n\nP.S. my professor said, how will I isolate for the tax-break? What if a big company had just moved into town and brought jobs and investments? How can I show that it was the tax-break that helped or didn't help. \n\nTHIS IS NOT HOMEWORK HELP, I JUST NEED DIFFERENT WAYS TO APPROACH THIS.", "author_fullname": "t2_7chxigz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Isolating for main outcome variables for a tax-break project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfbebv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666924533.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello yall,&lt;/p&gt;\n\n&lt;p&gt;I am doing a project for my economics class and was wondering if anyone in this subreddit has any interesting articles or studies that can show causality between tax-breaks and  economic growth or income. I need to isolate and use methods such as difference-in-difference or other methods to somehow show that a tax break helped or didn&amp;#39;t help a state or city. Any thoughts or suggestions or other ways to look at this project? &lt;/p&gt;\n\n&lt;p&gt;P.S. my professor said, how will I isolate for the tax-break? What if a big company had just moved into town and brought jobs and investments? How can I show that it was the tax-break that helped or didn&amp;#39;t help. &lt;/p&gt;\n\n&lt;p&gt;THIS IS NOT HOMEWORK HELP, I JUST NEED DIFFERENT WAYS TO APPROACH THIS.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfbebv", "is_robot_indexable": true, "report_reasons": null, "author": "bakerintheforest", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfbebv/isolating_for_main_outcome_variables_for_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfbebv/isolating_for_main_outcome_variables_for_a/", "subreddit_subscribers": 815929, "created_utc": 1666924533.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}