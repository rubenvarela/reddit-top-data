{"kind": "Listing", "data": {"after": "t3_yft5rr", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_2xjdvpun", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "kaggle is wild (\u2060\u30fb\u2060o\u2060\u30fb\u2060)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_yfnbab", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 253, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 253, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/JshsXvQAazpuSWBL8tKtnyIMsS3vQo3IAhN5_X602OM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666961386.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/especdi14lw91.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/especdi14lw91.png?auto=webp&amp;s=66ef51efdccb64609e9121272ab8a805ea32f190", "width": 1080, "height": 1473}, "resolutions": [{"url": "https://preview.redd.it/especdi14lw91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a147cd6ed91ccc113c6ecfc8d849ca698e448268", "width": 108, "height": 147}, {"url": "https://preview.redd.it/especdi14lw91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a9cc6bed0b48683bde9b4691d10fc35ffedbfece", "width": 216, "height": 294}, {"url": "https://preview.redd.it/especdi14lw91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d36deb6a41910ee278703e1e523afdc433e4cb05", "width": 320, "height": 436}, {"url": "https://preview.redd.it/especdi14lw91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=18fbfc9dd98895410b8fd25f93ab2dc90bd3029a", "width": 640, "height": 872}, {"url": "https://preview.redd.it/especdi14lw91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=b899ad1c04a2dc5fdd09603161d6baeedf5d6f15", "width": 960, "height": 1309}, {"url": "https://preview.redd.it/especdi14lw91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a89a5de533e66fa94a3095270db0429d6e2845f9", "width": 1080, "height": 1473}], "variants": {}, "id": "ozHlhbL--sD-arUoVdRtVi4kezXQMNn-ItoyjzUHlNU"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfnbab", "is_robot_indexable": true, "report_reasons": null, "author": "deepcontractor", "discussion_type": null, "num_comments": 110, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfnbab/kaggle_is_wild_o/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/especdi14lw91.png", "subreddit_subscribers": 815957, "created_utc": 1666961386.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a working junior data scientist. I am in a Masters in Data Science program as well as self studying data science technologies on the side. However, it is overwhelming to give focus to both + work full time, so I need help deciding how to split my time, or if I should split my time at all. \n\nHow should I split my time between MS courses and self studying the modern data technologies and frameworks being used in the real world?", "author_fullname": "t2_dbas4m3c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How should I split my time between my studying my Masters in DS program and self studying?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yf7ahw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 85, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 85, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666914158.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a working junior data scientist. I am in a Masters in Data Science program as well as self studying data science technologies on the side. However, it is overwhelming to give focus to both + work full time, so I need help deciding how to split my time, or if I should split my time at all. &lt;/p&gt;\n\n&lt;p&gt;How should I split my time between MS courses and self studying the modern data technologies and frameworks being used in the real world?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yf7ahw", "is_robot_indexable": true, "report_reasons": null, "author": "Proof_Hyena4223", "discussion_type": null, "num_comments": 45, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yf7ahw/how_should_i_split_my_time_between_my_studying_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yf7ahw/how_should_i_split_my_time_between_my_studying_my/", "subreddit_subscribers": 815957, "created_utc": 1666914158.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been working as a Data Scientist for only a short time. I spent a year working as a graduate and have recently been promoted to a permenant position. I find that within my team everyone seems to have side projects going on or be reading textbooks and listening to podcasts about Data Science in their free time. I enjoy working in Data Science and am always eager to learn more, but to be honest, I still see it as work and like to completely disconnect outside of my job to pursue and enjoy other things. I have no real desire to extend the time I spend working on or reading about the field outside of my work hours. Is this likely to hurt me in my career?", "author_fullname": "t2_jip2g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can I succeed as a Data Scientist without wanting to do extra outside of work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfhubz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666943468.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been working as a Data Scientist for only a short time. I spent a year working as a graduate and have recently been promoted to a permenant position. I find that within my team everyone seems to have side projects going on or be reading textbooks and listening to podcasts about Data Science in their free time. I enjoy working in Data Science and am always eager to learn more, but to be honest, I still see it as work and like to completely disconnect outside of my job to pursue and enjoy other things. I have no real desire to extend the time I spend working on or reading about the field outside of my work hours. Is this likely to hurt me in my career?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfhubz", "is_robot_indexable": true, "report_reasons": null, "author": "RastaSalad", "discussion_type": null, "num_comments": 44, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfhubz/can_i_succeed_as_a_data_scientist_without_wanting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfhubz/can_i_succeed_as_a_data_scientist_without_wanting/", "subreddit_subscribers": 815957, "created_utc": 1666943468.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys so I'm a month in at my new job as a data engineer. There are so many initiatives and so much data. I'm very new to this kind of thing to be honest with you and was hired for my general knowledge of key databases and some coding skills that I just kind of picked up at my previous role at the same company. So we are running this model in sas and they already put me in charge of data governance. I have meetings with our consultants but I basically need to drive them and ensure they are doing what they are supposed to be doing. \n\nSo I guess my question is what should I be focusing on? What are the typical key metrics that you use to validate the model, the input output data? What can I do to be successful at this? \n\nIt's a lot of new info so very overwhelming, any help is very appreciated. \n\nThank youu!!!!", "author_fullname": "t2_a8yt6gr6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "new to ml ops, having trouble", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yf6zs0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666913415.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys so I&amp;#39;m a month in at my new job as a data engineer. There are so many initiatives and so much data. I&amp;#39;m very new to this kind of thing to be honest with you and was hired for my general knowledge of key databases and some coding skills that I just kind of picked up at my previous role at the same company. So we are running this model in sas and they already put me in charge of data governance. I have meetings with our consultants but I basically need to drive them and ensure they are doing what they are supposed to be doing. &lt;/p&gt;\n\n&lt;p&gt;So I guess my question is what should I be focusing on? What are the typical key metrics that you use to validate the model, the input output data? What can I do to be successful at this? &lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s a lot of new info so very overwhelming, any help is very appreciated. &lt;/p&gt;\n\n&lt;p&gt;Thank youu!!!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yf6zs0", "is_robot_indexable": true, "report_reasons": null, "author": "MembershipNice2192", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yf6zs0/new_to_ml_ops_having_trouble/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yf6zs0/new_to_ml_ops_having_trouble/", "subreddit_subscribers": 815957, "created_utc": 1666913415.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In my experience notebooks are a surprisingly controversial topic. I've seen things ranging from Databricks building tools for data scientists and data engineers that can seemingly only run on notebooks unless you install the notoriously buggy databricks connect to people using the word \"notebook\"  antithesis of good programming habits.\n\nRecently I've been listening to more talks about interactive vs batch programming and have just been reflecting on how I write code myself. Here's my own set of hot takes:\n\n&amp;#x200B;\n\n1. **The name of notebooks explains what they are meant for**. They are for experimenting, prototyping, potentially automating reports with markdown, etc. Essentially, you use them to jot down ideas as you would on a piece of paper.\n2. **You should build systems/features/... with notebooks and not with regular scripts to save time.**  You should treat your notebook as a debugger that is always on. Writing code in notebooks is a great way to build code interactively and incrementally. If you have IO sitting around and waiting to load data out of your DB to train a model each run doesn't make sense.\n3. **Notebooks DO encourage poor programming standards if you don't watch out. People say this as a buzzword without ever clarifying what they mean.** The biggest one here is the (ab)use of global variables and the fact that notebooks are typically self contained units. Having a proper project structure and reusing code across your project is important. Ideally you define building blocks in functions/classes somewhere in your project and run them in your notebooks, **if so your notebook is equivalent to production code.**\n4. **Using a notebook as a scratchpad and porting it to \"production code\" is faster than writing production code in a .py file.** This is the summary of the following 3 points and what I personally do. The overhead of porting a notebook to 4-5 different files in a clear directory structure with a main somewhere that runs them, in the same order as a notebook would, is imo just less than building it from scratch like that.\n5. **Don't delete your scratchpads, keep them around as documentation for your streamlined production workflow.** Why? Because running each block in a notebook is ime gives you more freedom than fighting with your debugger if/when something does go wrong.\n\n&amp;#x200B;\n\nSidenote:  this is why I think people have issues transitioning from R to Python or from Spyder to another IDE/text editor. R (studio) and Spyder are a lot closer to interactive programming because you can run your code line by line and not lose your variables. This is how programming should be, but not how the vast majority of people learnt it and people don't like change.", "author_fullname": "t2_5p0cu2ub", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A critical reflection of jupyter notebooks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfsxrn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666974716.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666974181.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my experience notebooks are a surprisingly controversial topic. I&amp;#39;ve seen things ranging from Databricks building tools for data scientists and data engineers that can seemingly only run on notebooks unless you install the notoriously buggy databricks connect to people using the word &amp;quot;notebook&amp;quot;  antithesis of good programming habits.&lt;/p&gt;\n\n&lt;p&gt;Recently I&amp;#39;ve been listening to more talks about interactive vs batch programming and have just been reflecting on how I write code myself. Here&amp;#39;s my own set of hot takes:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;The name of notebooks explains what they are meant for&lt;/strong&gt;. They are for experimenting, prototyping, potentially automating reports with markdown, etc. Essentially, you use them to jot down ideas as you would on a piece of paper.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;You should build systems/features/... with notebooks and not with regular scripts to save time.&lt;/strong&gt;  You should treat your notebook as a debugger that is always on. Writing code in notebooks is a great way to build code interactively and incrementally. If you have IO sitting around and waiting to load data out of your DB to train a model each run doesn&amp;#39;t make sense.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Notebooks DO encourage poor programming standards if you don&amp;#39;t watch out. People say this as a buzzword without ever clarifying what they mean.&lt;/strong&gt; The biggest one here is the (ab)use of global variables and the fact that notebooks are typically self contained units. Having a proper project structure and reusing code across your project is important. Ideally you define building blocks in functions/classes somewhere in your project and run them in your notebooks, &lt;strong&gt;if so your notebook is equivalent to production code.&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Using a notebook as a scratchpad and porting it to &amp;quot;production code&amp;quot; is faster than writing production code in a .py file.&lt;/strong&gt; This is the summary of the following 3 points and what I personally do. The overhead of porting a notebook to 4-5 different files in a clear directory structure with a main somewhere that runs them, in the same order as a notebook would, is imo just less than building it from scratch like that.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Don&amp;#39;t delete your scratchpads, keep them around as documentation for your streamlined production workflow.&lt;/strong&gt; Why? Because running each block in a notebook is ime gives you more freedom than fighting with your debugger if/when something does go wrong.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Sidenote:  this is why I think people have issues transitioning from R to Python or from Spyder to another IDE/text editor. R (studio) and Spyder are a lot closer to interactive programming because you can run your code line by line and not lose your variables. This is how programming should be, but not how the vast majority of people learnt it and people don&amp;#39;t like change.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfsxrn", "is_robot_indexable": true, "report_reasons": null, "author": "Aggressive_Ad_3178", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfsxrn/a_critical_reflection_of_jupyter_notebooks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfsxrn/a_critical_reflection_of_jupyter_notebooks/", "subreddit_subscribers": 815957, "created_utc": 1666974181.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a tad confused and a noob, please be patient.\n\nI was watching one of my co-workers analyse and visualise some data and he said he was going to normalise the data. For normalisation I normally used the mean, standard deviation and standarise the data using those.\n\nHowever, this is what he did:\n\nCalculated the regression equation.\n\nUsing the independent variable coefficient and the intercept (from the previous step) he calculated the predicted y.\n\nProceeded to substract the actual y against the predicted y and then add the average of all of the predicted y.\n\nWhat essentially happened is that he got rid of the independent variable coefficient (if you were to graph it, the trendline would be flat). Now:\n\nIS this actually normalising data or is it integration? if neither, what would this be? and why should I do it?\n\nI am asking since he had to go.", "author_fullname": "t2_q2cte", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Simple question about normalising and integrating data.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfe464", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666931955.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a tad confused and a noob, please be patient.&lt;/p&gt;\n\n&lt;p&gt;I was watching one of my co-workers analyse and visualise some data and he said he was going to normalise the data. For normalisation I normally used the mean, standard deviation and standarise the data using those.&lt;/p&gt;\n\n&lt;p&gt;However, this is what he did:&lt;/p&gt;\n\n&lt;p&gt;Calculated the regression equation.&lt;/p&gt;\n\n&lt;p&gt;Using the independent variable coefficient and the intercept (from the previous step) he calculated the predicted y.&lt;/p&gt;\n\n&lt;p&gt;Proceeded to substract the actual y against the predicted y and then add the average of all of the predicted y.&lt;/p&gt;\n\n&lt;p&gt;What essentially happened is that he got rid of the independent variable coefficient (if you were to graph it, the trendline would be flat). Now:&lt;/p&gt;\n\n&lt;p&gt;IS this actually normalising data or is it integration? if neither, what would this be? and why should I do it?&lt;/p&gt;\n\n&lt;p&gt;I am asking since he had to go.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfe464", "is_robot_indexable": true, "report_reasons": null, "author": "manuelgcg", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfe464/simple_question_about_normalising_and_integrating/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfe464/simple_question_about_normalising_and_integrating/", "subreddit_subscribers": 815957, "created_utc": 1666931955.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm a Data Scientist / Data analyst and currently I'm looking for a job (sabbatical on my current company), but I feel that I'm not a data scientist anymore. In my last 2.5 years I've been basically doing  ETL with SQL and data visualization with PBI and Tableau and I don't remember almost anything else. So whenever I read the requirements on a new job opportunity I feel that I can't do 50-60% of the job requirements.\n\nI'm searching for end to end data science projects that I could do and add to my portfolio that would bring me back up to speed on the field.\n\nI've stumbled upon a site projectpro.io that seem to have tons of data science projects explained and solved but the subscription fee is enormous and tbh the website looks sketchy.\n\nCould anyone recommend me projects to do or something that would help me regain my skill.\n\nAny help would be much appreciated.", "author_fullname": "t2_3fmejzrr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Impostor Syndrome", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfy5ix", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666985146.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a Data Scientist / Data analyst and currently I&amp;#39;m looking for a job (sabbatical on my current company), but I feel that I&amp;#39;m not a data scientist anymore. In my last 2.5 years I&amp;#39;ve been basically doing  ETL with SQL and data visualization with PBI and Tableau and I don&amp;#39;t remember almost anything else. So whenever I read the requirements on a new job opportunity I feel that I can&amp;#39;t do 50-60% of the job requirements.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m searching for end to end data science projects that I could do and add to my portfolio that would bring me back up to speed on the field.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve stumbled upon a site projectpro.io that seem to have tons of data science projects explained and solved but the subscription fee is enormous and tbh the website looks sketchy.&lt;/p&gt;\n\n&lt;p&gt;Could anyone recommend me projects to do or something that would help me regain my skill.&lt;/p&gt;\n\n&lt;p&gt;Any help would be much appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfy5ix", "is_robot_indexable": true, "report_reasons": null, "author": "djpo10", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfy5ix/impostor_syndrome/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfy5ix/impostor_syndrome/", "subreddit_subscribers": 815957, "created_utc": 1666985146.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently participating in datacamp competition,I need some help selecting my model for the output\n\n# Project Goal\n\n**Using the network analysis, in which departments would you recommend the HR team focus to boost collaboration?**\n\n# Data Set Info\n\n\\#### Messages has information on the sender, receiver, and time.\n\n\\- \"sender\" - represents the employee id of the employee sending the message.\n\n\\- \"receiver\" - represents the employee id of the employee receiving the message.\n\n\\- \"timestamp\" - the date of the message.\n\n\\- \"message\\_length\" - the length in words of the message.\n\n&amp;#x200B;\n\n\\#### Employees has information on each employee;\n\n\\- \"id\" - represents the employee id of the employee.\n\n\\- \"department\" - is the department within the company. \n\n\\- \"location\" - is the country where the employee lives.\n\n\\- \"age\" - is the age of the employee.\n\n[https://drive.google.com/drive/folders/1aijyRGETvelAkT6x0ew2skIjmxxryHPV?usp=sharing](https://drive.google.com/drive/folders/1aijyRGETvelAkT6x0ew2skIjmxxryHPV?usp=sharing)\n\n&amp;#x200B;\n\n# My work till now\n\nI haven't made many changes to the dataset. just tried to find the co-relation between different attributes and some visualization which was required for the project ( lmk if they are shit)\n\n&amp;#x200B;\n\n[Messages sent based on time and department](https://preview.redd.it/nnodk91egjw91.png?width=944&amp;format=png&amp;auto=webp&amp;s=86c5bc7a3bb11bc32bfd5244ba38950cd62448ae)\n\n[Number of messages sent based on location](https://preview.redd.it/2judthi3gjw91.png?width=807&amp;format=png&amp;auto=webp&amp;s=e322fd8d1a42b741953b973e1844f80f32e3e74f)\n\n&amp;#x200B;\n\n[No. of messages sent based on department](https://preview.redd.it/eio4rqp8gjw91.png?width=1433&amp;format=png&amp;auto=webp&amp;s=516fc47091a330c7ba78bc6bd3f273f7e17ab06c)\n\nObservations: \n\n1. All Branches has sales as largest department except US\n\n2. Largest department in US is operations, second is Brazil and UK has no Operation dep\n\n3. Germany has highest Sales department, with 68.45% of total branch and Brazil Coming in no. 2\n\n4. It's weird that only first 2 months have high conversations\n\nCreate a report that covers the following:  \n\n  1. Which departments are the most/least active? \n\ni)  Most:-  Sales(1.55k msg)\n\nii) least:- Marketing(16 msgs)\n\n  2. Which employee has the most connections?  - \n\ni)  Sender  :- 605(459, Admin)\n\nii) Receiver:- 281(60,Sales) \n\n  3. Which Department has the most connections? \n\ni) sender Department:- Sales(1.5k)\n\nii) receiver Dep:- Sales(1.23k)\n\n&amp;#x200B;\n\n&gt;**I know my data might be just random with no path followed, well this is partially truth, since 3 factors are affecting the message sent 1. Time, 2. Location, 3. Department**\n\n&amp;#x200B;\n\n&gt;My first thoughts were to look it as a time series model but after looking at the msg based on time graph It was dissolved  \n&gt;  \n&gt;My second thoughts was to look it as a network model like graph with sender and receiver as nodes and msgs as edge weight but I don't much clue on how to deal with it", "author_fullname": "t2_3hg5hlo7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best model for network Analysis", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 53, "top_awarded_type": null, "hide_score": false, "media_metadata": {"2judthi3gjw91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 104, "x": 108, "u": "https://preview.redd.it/2judthi3gjw91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f4914cfa061400ddc67bbc6af034e7cc37c95987"}, {"y": 208, "x": 216, "u": "https://preview.redd.it/2judthi3gjw91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=022e2127a831c48e0daf76bfb488c2bb4fb6adbd"}, {"y": 309, "x": 320, "u": "https://preview.redd.it/2judthi3gjw91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=1e1601daacb1a977defefddaeaa5f4eb30dddc19"}, {"y": 618, "x": 640, "u": "https://preview.redd.it/2judthi3gjw91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=211a3e2852378fcb708ce709e160d1e99043c0d3"}], "s": {"y": 780, "x": 807, "u": "https://preview.redd.it/2judthi3gjw91.png?width=807&amp;format=png&amp;auto=webp&amp;s=e322fd8d1a42b741953b973e1844f80f32e3e74f"}, "id": "2judthi3gjw91"}, "eio4rqp8gjw91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/eio4rqp8gjw91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6f8a97a8c91a8fc1683183f90a8e666bd78754f0"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/eio4rqp8gjw91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d1790cfe40d4db06a90e14f31f1dff2f08f9b585"}, {"y": 179, "x": 320, "u": "https://preview.redd.it/eio4rqp8gjw91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3da26c8fd3fec597272eb7a6de46c673430a4360"}, {"y": 359, "x": 640, "u": "https://preview.redd.it/eio4rqp8gjw91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=32211baab0e86ab02cc4239a4526d79b33fb2c48"}, {"y": 538, "x": 960, "u": "https://preview.redd.it/eio4rqp8gjw91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=b4e5f40dda1a65162828b42e28c16a39d2a57877"}, {"y": 605, "x": 1080, "u": "https://preview.redd.it/eio4rqp8gjw91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=15eeae2ce4bd5cb4470b65f9b639f9cda73c2852"}], "s": {"y": 804, "x": 1433, "u": "https://preview.redd.it/eio4rqp8gjw91.png?width=1433&amp;format=png&amp;auto=webp&amp;s=516fc47091a330c7ba78bc6bd3f273f7e17ab06c"}, "id": "eio4rqp8gjw91"}, "nnodk91egjw91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 41, "x": 108, "u": "https://preview.redd.it/nnodk91egjw91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7a43d24da16d39c3ea2b498a5ec1b8ae271fb538"}, {"y": 82, "x": 216, "u": "https://preview.redd.it/nnodk91egjw91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=05d4ae3b24915ddaa5c76e05fd7b4517165cdec4"}, {"y": 122, "x": 320, "u": "https://preview.redd.it/nnodk91egjw91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c39b177336e6a6e580d097d7c9ca9c9c96b0a0aa"}, {"y": 245, "x": 640, "u": "https://preview.redd.it/nnodk91egjw91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ebb17ec1627a8a2e4d4f054228cece4b0ded4de7"}], "s": {"y": 362, "x": 944, "u": "https://preview.redd.it/nnodk91egjw91.png?width=944&amp;format=png&amp;auto=webp&amp;s=86c5bc7a3bb11bc32bfd5244ba38950cd62448ae"}, "id": "nnodk91egjw91"}}, "name": "t3_yfmry5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/kGVMenG6zW_kSwqvSBLqHuFFu6I-vOVHawBUyiiZPTE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666959881.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently participating in datacamp competition,I need some help selecting my model for the output&lt;/p&gt;\n\n&lt;h1&gt;Project Goal&lt;/h1&gt;\n\n&lt;p&gt;&lt;strong&gt;Using the network analysis, in which departments would you recommend the HR team focus to boost collaboration?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;h1&gt;Data Set Info&lt;/h1&gt;\n\n&lt;p&gt;#### Messages has information on the sender, receiver, and time.&lt;/p&gt;\n\n&lt;p&gt;- &amp;quot;sender&amp;quot; - represents the employee id of the employee sending the message.&lt;/p&gt;\n\n&lt;p&gt;- &amp;quot;receiver&amp;quot; - represents the employee id of the employee receiving the message.&lt;/p&gt;\n\n&lt;p&gt;- &amp;quot;timestamp&amp;quot; - the date of the message.&lt;/p&gt;\n\n&lt;p&gt;- &amp;quot;message_length&amp;quot; - the length in words of the message.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;#### Employees has information on each employee;&lt;/p&gt;\n\n&lt;p&gt;- &amp;quot;id&amp;quot; - represents the employee id of the employee.&lt;/p&gt;\n\n&lt;p&gt;- &amp;quot;department&amp;quot; - is the department within the company. &lt;/p&gt;\n\n&lt;p&gt;- &amp;quot;location&amp;quot; - is the country where the employee lives.&lt;/p&gt;\n\n&lt;p&gt;- &amp;quot;age&amp;quot; - is the age of the employee.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://drive.google.com/drive/folders/1aijyRGETvelAkT6x0ew2skIjmxxryHPV?usp=sharing\"&gt;https://drive.google.com/drive/folders/1aijyRGETvelAkT6x0ew2skIjmxxryHPV?usp=sharing&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;h1&gt;My work till now&lt;/h1&gt;\n\n&lt;p&gt;I haven&amp;#39;t made many changes to the dataset. just tried to find the co-relation between different attributes and some visualization which was required for the project ( lmk if they are shit)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/nnodk91egjw91.png?width=944&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=86c5bc7a3bb11bc32bfd5244ba38950cd62448ae\"&gt;Messages sent based on time and department&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/2judthi3gjw91.png?width=807&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e322fd8d1a42b741953b973e1844f80f32e3e74f\"&gt;Number of messages sent based on location&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/eio4rqp8gjw91.png?width=1433&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=516fc47091a330c7ba78bc6bd3f273f7e17ab06c\"&gt;No. of messages sent based on department&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Observations: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;All Branches has sales as largest department except US&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Largest department in US is operations, second is Brazil and UK has no Operation dep&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Germany has highest Sales department, with 68.45% of total branch and Brazil Coming in no. 2&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;It&amp;#39;s weird that only first 2 months have high conversations&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Create a report that covers the following:  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Which departments are the most/least active? &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;i)  Most:-  Sales(1.55k msg)&lt;/p&gt;\n\n&lt;p&gt;ii) least:- Marketing(16 msgs)&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Which employee has the most connections?  - &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;i)  Sender  :- 605(459, Admin)&lt;/p&gt;\n\n&lt;p&gt;ii) Receiver:- 281(60,Sales) &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Which Department has the most connections? &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;i) sender Department:- Sales(1.5k)&lt;/p&gt;\n\n&lt;p&gt;ii) receiver Dep:- Sales(1.23k)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;&lt;strong&gt;I know my data might be just random with no path followed, well this is partially truth, since 3 factors are affecting the message sent 1. Time, 2. Location, 3. Department&lt;/strong&gt;&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;My first thoughts were to look it as a time series model but after looking at the msg based on time graph It was dissolved  &lt;/p&gt;\n\n&lt;p&gt;My second thoughts was to look it as a network model like graph with sender and receiver as nodes and msgs as edge weight but I don&amp;#39;t much clue on how to deal with it&lt;/p&gt;\n&lt;/blockquote&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfmry5", "is_robot_indexable": true, "report_reasons": null, "author": "SupaSTaZz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfmry5/best_model_for_network_analysis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfmry5/best_model_for_network_analysis/", "subreddit_subscribers": 815957, "created_utc": 1666959881.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am working on a ML project and need data for population density (I live in small country with not much data) . Is it possible to find a website from which I can download satellite pictures (compiled every day for an year) at night of my town, so I can estimate the population concentration by the given lights. Thanks.", "author_fullname": "t2_aws8tyj4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Satellite images data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfir8m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666946824.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working on a ML project and need data for population density (I live in small country with not much data) . Is it possible to find a website from which I can download satellite pictures (compiled every day for an year) at night of my town, so I can estimate the population concentration by the given lights. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfir8m", "is_robot_indexable": true, "report_reasons": null, "author": "AnyJello605", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfir8m/satellite_images_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfir8m/satellite_images_data/", "subreddit_subscribers": 815957, "created_utc": 1666946824.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\nMost of the e2e DS tutorials cover feature engineering (OHE, LE, Norm, etc.) and splitting complete data into train and test sets. As you know, in real life, there is no x\\_train and y\\_train. You need to do labeling using your raw data. However, there are no tutorials covering **tabular** data labeling. Are there any recommended tutorials, git repositories, or blog posts to learn and exercise for labeling? It can be related churn labeling, likelihood to buy, or spend forecasting etc.\n\nTLDR: Looking for tutorials about **tabular data labeling** (creating target variable).", "author_fullname": "t2_rehw0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for tabular data prep/labeling tutorials", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfhhhp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666942149.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;Most of the e2e DS tutorials cover feature engineering (OHE, LE, Norm, etc.) and splitting complete data into train and test sets. As you know, in real life, there is no x_train and y_train. You need to do labeling using your raw data. However, there are no tutorials covering &lt;strong&gt;tabular&lt;/strong&gt; data labeling. Are there any recommended tutorials, git repositories, or blog posts to learn and exercise for labeling? It can be related churn labeling, likelihood to buy, or spend forecasting etc.&lt;/p&gt;\n\n&lt;p&gt;TLDR: Looking for tutorials about &lt;strong&gt;tabular data labeling&lt;/strong&gt; (creating target variable).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfhhhp", "is_robot_indexable": true, "report_reasons": null, "author": "silverstone1903", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfhhhp/looking_for_tabular_data_preplabeling_tutorials/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfhhhp/looking_for_tabular_data_preplabeling_tutorials/", "subreddit_subscribers": 815957, "created_utc": 1666942149.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "i basically have 1-2-3 (high medium low quality) and want to plot the counts, stacked, on a histogram. Only thing is I want something like an interactive button to bring the selected histogram to the front  \n\n\nWhat can I easily do this with in python?  \n\n\nI will then make it web runnable on steamlit", "author_fullname": "t2_lww73a7r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I make an interactive histogram in python?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfaot7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666922693.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i basically have 1-2-3 (high medium low quality) and want to plot the counts, stacked, on a histogram. Only thing is I want something like an interactive button to bring the selected histogram to the front  &lt;/p&gt;\n\n&lt;p&gt;What can I easily do this with in python?  &lt;/p&gt;\n\n&lt;p&gt;I will then make it web runnable on steamlit&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfaot7", "is_robot_indexable": true, "report_reasons": null, "author": "fartuni4", "discussion_type": null, "num_comments": 11, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfaot7/how_can_i_make_an_interactive_histogram_in_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfaot7/how_can_i_make_an_interactive_histogram_in_python/", "subreddit_subscribers": 815957, "created_utc": 1666922693.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m curious to know what the consensus on best online master\u2019s in data science is? I am a little less price dependent as my company would cover $30k or so.\n\nThe 3 I keep seeing as being rated pretty well are Georgia Tech, Texas, and Illinois.\n\nIs this accurate?\n\nWould love to hear where different people went, how the program was, and roughly how much time they spent per class per week.\n\nThank you so much in advance!\n\nEdit:\n\nBackground: I double majored in undergrad in CS and business (CS department is ranked top or so from what I\u2019ve seen). I will say that I consider my math background to be weaker. I took stats, discrete, calc, etc but not linear algebra.\n\nI have spent the 2.5ish years since graduation as a data analyst.", "author_fullname": "t2_17qwjq21", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best online master\u2019s in data science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfaiou", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666964695.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666922270.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m curious to know what the consensus on best online master\u2019s in data science is? I am a little less price dependent as my company would cover $30k or so.&lt;/p&gt;\n\n&lt;p&gt;The 3 I keep seeing as being rated pretty well are Georgia Tech, Texas, and Illinois.&lt;/p&gt;\n\n&lt;p&gt;Is this accurate?&lt;/p&gt;\n\n&lt;p&gt;Would love to hear where different people went, how the program was, and roughly how much time they spent per class per week.&lt;/p&gt;\n\n&lt;p&gt;Thank you so much in advance!&lt;/p&gt;\n\n&lt;p&gt;Edit:&lt;/p&gt;\n\n&lt;p&gt;Background: I double majored in undergrad in CS and business (CS department is ranked top or so from what I\u2019ve seen). I will say that I consider my math background to be weaker. I took stats, discrete, calc, etc but not linear algebra.&lt;/p&gt;\n\n&lt;p&gt;I have spent the 2.5ish years since graduation as a data analyst.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfaiou", "is_robot_indexable": true, "report_reasons": null, "author": "PowerfulSquirrel4", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfaiou/best_online_masters_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfaiou/best_online_masters_in_data_science/", "subreddit_subscribers": 815957, "created_utc": 1666922270.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What was it and what was your manager's reaction?", "author_fullname": "t2_jjuvhqid", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Have you ever committed a big or small mistake at work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yg09c7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666990379.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What was it and what was your manager&amp;#39;s reaction?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yg09c7", "is_robot_indexable": true, "report_reasons": null, "author": "VeliVoy", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yg09c7/have_you_ever_committed_a_big_or_small_mistake_at/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yg09c7/have_you_ever_committed_a_big_or_small_mistake_at/", "subreddit_subscribers": 815957, "created_utc": 1666990379.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a fairly large dataset where I'm supposed to use independent variables to predict the dependent variable (classic). However, I know for certain that there is an underlying equation linking my independent variables to my dependent variable which explains them fully. The problem is I have no idea how to uncover this relationship. This relationship is likely non-linear but additive. How do I go about decomposing this problem?", "author_fullname": "t2_l7hoj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to uncover underlying equation between independent and dependent variables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfsf52", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666973188.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a fairly large dataset where I&amp;#39;m supposed to use independent variables to predict the dependent variable (classic). However, I know for certain that there is an underlying equation linking my independent variables to my dependent variable which explains them fully. The problem is I have no idea how to uncover this relationship. This relationship is likely non-linear but additive. How do I go about decomposing this problem?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfsf52", "is_robot_indexable": true, "report_reasons": null, "author": "ReaperJr", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfsf52/how_to_uncover_underlying_equation_between/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfsf52/how_to_uncover_underlying_equation_between/", "subreddit_subscribers": 815957, "created_utc": 1666973188.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For an example, lets say i take on an NLP project to anonymise and classify some text.\n\nTypically id start with a simple approch to solve the problem and meet the scope of the project. This might mean using some prebuilt package to anonymise, and a fairly simple tree model to classify.\n\nThis meets the scope and means we can progress to get something into production, wit the view that when its productionised, we can hot swap improvements in the pipeline.\n\nMy question is, how do you justify to the business these improvements if they view the problem as solved? \n\nFor small changes like replacing a random forest with a lgbm, thats not so bad. However, i mean like replacing the anonymisation package with a more custom CNN or LSTM approach? Thats a much bigger change.\n\nI feel like the answer is \u2018why bother if the business doesn\u2019t see value in it/the current solution doing the job\u2019. But part of our teams role is to progress data science in the business - so we cant just go off what the business thinks as they dont know the art of the possible.\n\nYes its down to the data scientist to communicate the value of the work, but how would you justify such a change in this usecase?", "author_fullname": "t2_gm8b3iu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "For those in industry - how do you know when to/ justify revisiting a project?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfl2t4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666954860.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For an example, lets say i take on an NLP project to anonymise and classify some text.&lt;/p&gt;\n\n&lt;p&gt;Typically id start with a simple approch to solve the problem and meet the scope of the project. This might mean using some prebuilt package to anonymise, and a fairly simple tree model to classify.&lt;/p&gt;\n\n&lt;p&gt;This meets the scope and means we can progress to get something into production, wit the view that when its productionised, we can hot swap improvements in the pipeline.&lt;/p&gt;\n\n&lt;p&gt;My question is, how do you justify to the business these improvements if they view the problem as solved? &lt;/p&gt;\n\n&lt;p&gt;For small changes like replacing a random forest with a lgbm, thats not so bad. However, i mean like replacing the anonymisation package with a more custom CNN or LSTM approach? Thats a much bigger change.&lt;/p&gt;\n\n&lt;p&gt;I feel like the answer is \u2018why bother if the business doesn\u2019t see value in it/the current solution doing the job\u2019. But part of our teams role is to progress data science in the business - so we cant just go off what the business thinks as they dont know the art of the possible.&lt;/p&gt;\n\n&lt;p&gt;Yes its down to the data scientist to communicate the value of the work, but how would you justify such a change in this usecase?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfl2t4", "is_robot_indexable": true, "report_reasons": null, "author": "poppycocknbalderdash", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfl2t4/for_those_in_industry_how_do_you_know_when_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfl2t4/for_those_in_industry_how_do_you_know_when_to/", "subreddit_subscribers": 815957, "created_utc": 1666954860.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Pretty much what the title says. Do you have any you'd recommend?\n\nFor reference, I'm about to get out of undergrad. I didn't practice much of statistics but through side projects doing data analysis &amp; machine learning, I realized how important this was kind of late imo.  I'm vaguely familiar with calculus, it's been a while since I've looked at multivariable, I already have a book for that for review. \n\nLooking for statistics mainly. But if you do happen to have one for linear algebra you'd recommend, that'd be appreciated as well. ; )\n\nAnything to help understand these models more lol.", "author_fullname": "t2_u7pn8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommendations for introductory statistical texts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfi7k2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666945150.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666944783.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Pretty much what the title says. Do you have any you&amp;#39;d recommend?&lt;/p&gt;\n\n&lt;p&gt;For reference, I&amp;#39;m about to get out of undergrad. I didn&amp;#39;t practice much of statistics but through side projects doing data analysis &amp;amp; machine learning, I realized how important this was kind of late imo.  I&amp;#39;m vaguely familiar with calculus, it&amp;#39;s been a while since I&amp;#39;ve looked at multivariable, I already have a book for that for review. &lt;/p&gt;\n\n&lt;p&gt;Looking for statistics mainly. But if you do happen to have one for linear algebra you&amp;#39;d recommend, that&amp;#39;d be appreciated as well. ; )&lt;/p&gt;\n\n&lt;p&gt;Anything to help understand these models more lol.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfi7k2", "is_robot_indexable": true, "report_reasons": null, "author": "pekkalacd", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfi7k2/recommendations_for_introductory_statistical_texts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfi7k2/recommendations_for_introductory_statistical_texts/", "subreddit_subscribers": 815957, "created_utc": 1666944783.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ve recently started at a new company in a hybrid DS/engineering role. It\u2019s an older company in the utility industry, so there\u2019s a pretty healthy mix of \u201ctraditional\u201d &amp; modern ways of keeping track of things (events, equipment, project status, etc). Thankfully we do have some Oracle DBs in place that a couple members on the team are using to build new dashboards and analytics scripts from. However, lots of existing/historical work tracking is done through random Excel sheets scattered about the network drives. There always exists a desire to move forward and advance our current practices to increase effectiveness &amp; efficiency within the company\u2019s data handling schemes. \n\nWe can develop new scripts/dashboards and do all kinds of cool stuff on that side of things. I\u2019m just curious as to what methods other people may be using to bridge gaps between scattered Excel data/reporting sheets and more centralized dashboarding/SW development practices. \n\nIf you couldn\u2019t tell, I\u2019m a bit new the DS working side. I\u2019ve done lots with Python, SQL, and a few dashboard platforms, but I\u2019m still new to the real world applications of DS. \n\nThanks!", "author_fullname": "t2_dv1qy8c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bridging the gap between old &amp; new methods of DS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yf5883", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666909123.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve recently started at a new company in a hybrid DS/engineering role. It\u2019s an older company in the utility industry, so there\u2019s a pretty healthy mix of \u201ctraditional\u201d &amp;amp; modern ways of keeping track of things (events, equipment, project status, etc). Thankfully we do have some Oracle DBs in place that a couple members on the team are using to build new dashboards and analytics scripts from. However, lots of existing/historical work tracking is done through random Excel sheets scattered about the network drives. There always exists a desire to move forward and advance our current practices to increase effectiveness &amp;amp; efficiency within the company\u2019s data handling schemes. &lt;/p&gt;\n\n&lt;p&gt;We can develop new scripts/dashboards and do all kinds of cool stuff on that side of things. I\u2019m just curious as to what methods other people may be using to bridge gaps between scattered Excel data/reporting sheets and more centralized dashboarding/SW development practices. &lt;/p&gt;\n\n&lt;p&gt;If you couldn\u2019t tell, I\u2019m a bit new the DS working side. I\u2019ve done lots with Python, SQL, and a few dashboard platforms, but I\u2019m still new to the real world applications of DS. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yf5883", "is_robot_indexable": true, "report_reasons": null, "author": "ljh78", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yf5883/bridging_the_gap_between_old_new_methods_of_ds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yf5883/bridging_the_gap_between_old_new_methods_of_ds/", "subreddit_subscribers": 815957, "created_utc": 1666909123.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work for a university. In my experience, it's been a common phenomenon that any new business unit (these are mostly non professors) that we pitch our existing work to show how others are using predictive models, they immediately start obsessing over the model (P-value, attributes, change of coef over time - irrespective of the whether it's regression/tree/nn) rather than how the a model might help/fit in their work. Very curious to know is this a common experience for other here? \n\nI'm seriously pissed at these P-value warriors - who considers P-value is everything and 0.05 is the heavenly number that'll show them the way to salvation \ud83d\ude24", "author_fullname": "t2_9axqyq8u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "(Half ranting) How often do you find business users more worried about the stats i.e. \"p value\" than how a model will be useful for their work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yg0c7s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666990588.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work for a university. In my experience, it&amp;#39;s been a common phenomenon that any new business unit (these are mostly non professors) that we pitch our existing work to show how others are using predictive models, they immediately start obsessing over the model (P-value, attributes, change of coef over time - irrespective of the whether it&amp;#39;s regression/tree/nn) rather than how the a model might help/fit in their work. Very curious to know is this a common experience for other here? &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m seriously pissed at these P-value warriors - who considers P-value is everything and 0.05 is the heavenly number that&amp;#39;ll show them the way to salvation \ud83d\ude24&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yg0c7s", "is_robot_indexable": true, "report_reasons": null, "author": "Difficult-Big-3890", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yg0c7s/half_ranting_how_often_do_you_find_business_users/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yg0c7s/half_ranting_how_often_do_you_find_business_users/", "subreddit_subscribers": 815957, "created_utc": 1666990588.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "The model part does not some difficult whatsoever by time consuming considering the \u201cask\u201d. Also I was caught off guard after the HR guy asked to do a SQL assessment. Have any of you been blind sided like that in the past or did HR just make a mistake? \nIt\u2019s for a senior lead analyst at an insurance company", "author_fullname": "t2_a35f24qv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Was asked to do a SQL assessment for a job interview and it\u2019s turned into a model development and presentation\u2026 anyone seen this in the past", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yg06y6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "spoiler", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666990207.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The model part does not some difficult whatsoever by time consuming considering the \u201cask\u201d. Also I was caught off guard after the HR guy asked to do a SQL assessment. Have any of you been blind sided like that in the past or did HR just make a mistake? \nIt\u2019s for a senior lead analyst at an insurance company&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": true, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yg06y6", "is_robot_indexable": true, "report_reasons": null, "author": "hartwickw", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yg06y6/was_asked_to_do_a_sql_assessment_for_a_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yg06y6/was_asked_to_do_a_sql_assessment_for_a_job/", "subreddit_subscribers": 815957, "created_utc": 1666990207.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Last DS project I did was 5 month's ago , due to some problems I couldn't practice data science for a long time now , what's the best way to come back ? should I take a course to refresh concepts or start a project  right ahead ?", "author_fullname": "t2_kmj1xtch", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to refresh your data science skills ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yg03on", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666989969.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Last DS project I did was 5 month&amp;#39;s ago , due to some problems I couldn&amp;#39;t practice data science for a long time now , what&amp;#39;s the best way to come back ? should I take a course to refresh concepts or start a project  right ahead ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yg03on", "is_robot_indexable": true, "report_reasons": null, "author": "beselaa", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yg03on/how_to_refresh_your_data_science_skills/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yg03on/how_to_refresh_your_data_science_skills/", "subreddit_subscribers": 815957, "created_utc": 1666989969.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In terms of early career growth, exit opportunities, etc", "author_fullname": "t2_3c9mnyyx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Opinions on DS at a bank", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yfyw9z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666986965.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In terms of early career growth, exit opportunities, etc&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfyw9z", "is_robot_indexable": true, "report_reasons": null, "author": "heyyitsemyy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfyw9z/opinions_on_ds_at_a_bank/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfyw9z/opinions_on_ds_at_a_bank/", "subreddit_subscribers": 815957, "created_utc": 1666986965.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_av2wthwe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone have a method to treat large JSON files that are invalid to a proper tabular csv format? Any help would be nice. Thanks.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfy737", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666985255.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfy737", "is_robot_indexable": true, "report_reasons": null, "author": "D_Mystic_Topaz", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfy737/does_anyone_have_a_method_to_treat_large_json/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfy737/does_anyone_have_a_method_to_treat_large_json/", "subreddit_subscribers": 815957, "created_utc": 1666985255.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I need to work with ImageNet but the complete dataset needs a lot of space and I would like to see what you could suggest to achieve this in a simple way.\n\nI am currently thinking of buying 4TB ssd to download the dataset there (a bit expensive solution).\n\n So, I was wondering if there was any other alternative that would require less resources.", "author_fullname": "t2_4373kfz1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need to work with ImageNet but I never imagined it took so much space", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfx41h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666982529.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need to work with ImageNet but the complete dataset needs a lot of space and I would like to see what you could suggest to achieve this in a simple way.&lt;/p&gt;\n\n&lt;p&gt;I am currently thinking of buying 4TB ssd to download the dataset there (a bit expensive solution).&lt;/p&gt;\n\n&lt;p&gt;So, I was wondering if there was any other alternative that would require less resources.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfx41h", "is_robot_indexable": true, "report_reasons": null, "author": "nooob_Master_69", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfx41h/i_need_to_work_with_imagenet_but_i_never_imagined/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfx41h/i_need_to_work_with_imagenet_but_i_never_imagined/", "subreddit_subscribers": 815957, "created_utc": 1666982529.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone!\n\nI\u2019ll start an internship soon as medical data scientist at a company working with blood tests. I wanted to ask if there is anything you wish you would\u2019ve done/known before your first medical related data science job or internship.", "author_fullname": "t2_6q7a2p0c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any tips before starting a medical data science internship?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfw8fb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666982102.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666980604.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone!&lt;/p&gt;\n\n&lt;p&gt;I\u2019ll start an internship soon as medical data scientist at a company working with blood tests. I wanted to ask if there is anything you wish you would\u2019ve done/known before your first medical related data science job or internship.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfw8fb", "is_robot_indexable": true, "report_reasons": null, "author": "jeffrey_56", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfw8fb/any_tips_before_starting_a_medical_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfw8fb/any_tips_before_starting_a_medical_data_science/", "subreddit_subscribers": 815957, "created_utc": 1666980604.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I would like to transfer some powerbi dashboards in python using dash/plotly. The power I dashboards read data from SQL and are pretty good at navigating the complex data schema of the database. I am looking to implement something similar in Dash. However, I am struggling with creating dynamic drop downs and joining data from different tables. Has anyone done anything similar and could offer some tips/ resources? Is what I am trying to do completely bonkers? Feel free to give me feedback. Thanks", "author_fullname": "t2_hp8zd1sv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dashboards using Dash/Plotly that read data from Azure SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yft5rr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666974613.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like to transfer some powerbi dashboards in python using dash/plotly. The power I dashboards read data from SQL and are pretty good at navigating the complex data schema of the database. I am looking to implement something similar in Dash. However, I am struggling with creating dynamic drop downs and joining data from different tables. Has anyone done anything similar and could offer some tips/ resources? Is what I am trying to do completely bonkers? Feel free to give me feedback. Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yft5rr", "is_robot_indexable": true, "report_reasons": null, "author": "Living-Stable9651", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yft5rr/dashboards_using_dashplotly_that_read_data_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yft5rr/dashboards_using_dashplotly_that_read_data_from/", "subreddit_subscribers": 815957, "created_utc": 1666974613.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}