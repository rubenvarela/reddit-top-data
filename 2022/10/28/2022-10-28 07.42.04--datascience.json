{"kind": "Listing", "data": {"after": "t3_yf86uq", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I understand how to perform PCA , and why it's done and the theory behind it and how features are reduced in lower dimensional using eigen vectors and how to normalize the data before finding PCA. \n\nMy question is: in Linear Regression (LR), if I have (say)10 features then my LR looks like this y=c1x1+c2x2+.....+ c10x10. If I reduce my features to (say) 2 components then my LR looks like y=C1PC1+C2PC2 (where C = constant &amp; PC = principle components).\n\nhow is this equation useful to me because now my y is represented in terms of Principle components (PC) instead of actual variables. \n\nI haven't been able to find this answer online. Please help.", "author_fullname": "t2_13t60b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can someone please explain what to do next after getting PCA (Principle component analysis)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yex3pq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 206, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 206, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_1": 1}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666889642.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I understand how to perform PCA , and why it&amp;#39;s done and the theory behind it and how features are reduced in lower dimensional using eigen vectors and how to normalize the data before finding PCA. &lt;/p&gt;\n\n&lt;p&gt;My question is: in Linear Regression (LR), if I have (say)10 features then my LR looks like this y=c1x1+c2x2+.....+ c10x10. If I reduce my features to (say) 2 components then my LR looks like y=C1PC1+C2PC2 (where C = constant &amp;amp; PC = principle components).&lt;/p&gt;\n\n&lt;p&gt;how is this equation useful to me because now my y is represented in terms of Principle components (PC) instead of actual variables. &lt;/p&gt;\n\n&lt;p&gt;I haven&amp;#39;t been able to find this answer online. Please help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 100, "id": "gid_1", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Shows the Silver Award... and that's it.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Silver", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yex3pq", "is_robot_indexable": true, "report_reasons": null, "author": "drugsarebadmky", "discussion_type": null, "num_comments": 89, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yex3pq/can_someone_please_explain_what_to_do_next_after/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yex3pq/can_someone_please_explain_what_to_do_next_after/", "subreddit_subscribers": 815866, "created_utc": 1666889642.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a working junior data scientist. I am in a Masters in Data Science program as well as self studying data science technologies on the side. However, it is overwhelming to give focus to both + work full time, so I need help deciding how to split my time, or if I should split my time at all. \n\nHow should I split my time between MS courses and self studying the modern data technologies and frameworks being used in the real world?", "author_fullname": "t2_dbas4m3c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How should I split my time between my studying my Masters in DS program and self studying?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yf7ahw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 41, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666914158.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a working junior data scientist. I am in a Masters in Data Science program as well as self studying data science technologies on the side. However, it is overwhelming to give focus to both + work full time, so I need help deciding how to split my time, or if I should split my time at all. &lt;/p&gt;\n\n&lt;p&gt;How should I split my time between MS courses and self studying the modern data technologies and frameworks being used in the real world?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yf7ahw", "is_robot_indexable": true, "report_reasons": null, "author": "Proof_Hyena4223", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yf7ahw/how_should_i_split_my_time_between_my_studying_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yf7ahw/how_should_i_split_my_time_between_my_studying_my/", "subreddit_subscribers": 815866, "created_utc": 1666914158.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys so I'm a month in at my new job as a data engineer. There are so many initiatives and so much data. I'm very new to this kind of thing to be honest with you and was hired for my general knowledge of key databases and some coding skills that I just kind of picked up at my previous role at the same company. So we are running this model in sas and they already put me in charge of data governance. I have meetings with our consultants but I basically need to drive them and ensure they are doing what they are supposed to be doing. \n\nSo I guess my question is what should I be focusing on? What are the typical key metrics that you use to validate the model, the input output data? What can I do to be successful at this? \n\nIt's a lot of new info so very overwhelming, any help is very appreciated. \n\nThank youu!!!!", "author_fullname": "t2_a8yt6gr6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "new to ml ops, having trouble", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yf6zs0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666913415.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys so I&amp;#39;m a month in at my new job as a data engineer. There are so many initiatives and so much data. I&amp;#39;m very new to this kind of thing to be honest with you and was hired for my general knowledge of key databases and some coding skills that I just kind of picked up at my previous role at the same company. So we are running this model in sas and they already put me in charge of data governance. I have meetings with our consultants but I basically need to drive them and ensure they are doing what they are supposed to be doing. &lt;/p&gt;\n\n&lt;p&gt;So I guess my question is what should I be focusing on? What are the typical key metrics that you use to validate the model, the input output data? What can I do to be successful at this? &lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s a lot of new info so very overwhelming, any help is very appreciated. &lt;/p&gt;\n\n&lt;p&gt;Thank youu!!!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yf6zs0", "is_robot_indexable": true, "report_reasons": null, "author": "MembershipNice2192", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yf6zs0/new_to_ml_ops_having_trouble/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yf6zs0/new_to_ml_ops_having_trouble/", "subreddit_subscribers": 815866, "created_utc": 1666913415.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Hi, \n\nI've just published my recent article titled \"**The baseline for Precision-Recall curve: A Bayesian approach\".** \n\nThis article is a review of the nuts and bolts \ud83d\udd29 of Precision-Recall curve. Demystifying its baseline mathematically and empirically using some fun\ud83c\udf88**Python** codes for better understanding.  \n\n\nlink: [https://itnext.io/the-baseline-for-precision-recall-curve-a-bayesian-approach-1611c690607](https://itnext.io/the-baseline-for-precision-recall-curve-a-bayesian-approach-1611c690607)", "author_fullname": "t2_69i5g4ss", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The baseline for Precision-Recall curve: A Bayesian approach", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yeviy5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666885989.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve just published my recent article titled &amp;quot;&lt;strong&gt;The baseline for Precision-Recall curve: A Bayesian approach&amp;quot;.&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;This article is a review of the nuts and bolts \ud83d\udd29 of Precision-Recall curve. Demystifying its baseline mathematically and empirically using some fun\ud83c\udf88&lt;strong&gt;Python&lt;/strong&gt; codes for better understanding.  &lt;/p&gt;\n\n&lt;p&gt;link: &lt;a href=\"https://itnext.io/the-baseline-for-precision-recall-curve-a-bayesian-approach-1611c690607\"&gt;https://itnext.io/the-baseline-for-precision-recall-curve-a-bayesian-approach-1611c690607&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/F57Nwp4h7vdlKYYnI-ZxsRA61Ea7_hbfYggGZVc5c_A.jpg?auto=webp&amp;s=fdc4fcfcf9c72a528071c7d8843d4c818c55fb18", "width": 1200, "height": 515}, "resolutions": [{"url": "https://external-preview.redd.it/F57Nwp4h7vdlKYYnI-ZxsRA61Ea7_hbfYggGZVc5c_A.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ac8441b5f7e94a0dae0b357609e1dda0ddbfdaec", "width": 108, "height": 46}, {"url": "https://external-preview.redd.it/F57Nwp4h7vdlKYYnI-ZxsRA61Ea7_hbfYggGZVc5c_A.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d976fa8c68593b3336a6e15a9496b0afce6e3aef", "width": 216, "height": 92}, {"url": "https://external-preview.redd.it/F57Nwp4h7vdlKYYnI-ZxsRA61Ea7_hbfYggGZVc5c_A.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fe7c60d55379e8db1a49731ee3ec57ee3142d0f8", "width": 320, "height": 137}, {"url": "https://external-preview.redd.it/F57Nwp4h7vdlKYYnI-ZxsRA61Ea7_hbfYggGZVc5c_A.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7b95720527e1a78613f9caf2ce171f2b53bf7aee", "width": 640, "height": 274}, {"url": "https://external-preview.redd.it/F57Nwp4h7vdlKYYnI-ZxsRA61Ea7_hbfYggGZVc5c_A.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0500a44fedc7b23fc645d5b6338c6665ee751a55", "width": 960, "height": 412}, {"url": "https://external-preview.redd.it/F57Nwp4h7vdlKYYnI-ZxsRA61Ea7_hbfYggGZVc5c_A.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fbedd1028edba9e7c245801c0fd0bf2a3302d192", "width": 1080, "height": 463}], "variants": {}, "id": "GAsNMjcpg4eCcxJSspR7kI3t_WueG7Tpsw39Rsa1ZWU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yeviy5", "is_robot_indexable": true, "report_reasons": null, "author": "s_arme", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yeviy5/the_baseline_for_precisionrecall_curve_a_bayesian/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yeviy5/the_baseline_for_precisionrecall_curve_a_bayesian/", "subreddit_subscribers": 815866, "created_utc": 1666885989.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_30o1hb10", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Predictive analytics in Venture investing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_yesu7y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/vdJiMiIVinGYL0Iy_mb-tFzBvTmfr6PnNGPUZ6pKvAM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666879488.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "parsers.vc", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://parsers.vc/blog/predictive-analytics-in-venture-investing/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/oe8oczGXfZb5rpoM5ieKJfNllZql8qPUEEf5aYvYvWY.jpg?auto=webp&amp;s=2173ad66f527e425c033ff88d2a944c9918e7177", "width": 1104, "height": 736}, "resolutions": [{"url": "https://external-preview.redd.it/oe8oczGXfZb5rpoM5ieKJfNllZql8qPUEEf5aYvYvWY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fc6f2d5745de9e6c67128e3de3d1dc5479dc17e9", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/oe8oczGXfZb5rpoM5ieKJfNllZql8qPUEEf5aYvYvWY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2857a33558c222328a235f88b705a9622feb195e", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/oe8oczGXfZb5rpoM5ieKJfNllZql8qPUEEf5aYvYvWY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=529c3585884372e23cdcf13f287ebff500fb41e7", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/oe8oczGXfZb5rpoM5ieKJfNllZql8qPUEEf5aYvYvWY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9d89057078b02ce088c55357cfe6af60c29c5ce6", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/oe8oczGXfZb5rpoM5ieKJfNllZql8qPUEEf5aYvYvWY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7dadd17ef98fe2522236fc76d01a25733f774fa3", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/oe8oczGXfZb5rpoM5ieKJfNllZql8qPUEEf5aYvYvWY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1ff0d81311f0db15edb0982c738c731cf571cf0f", "width": 1080, "height": 720}], "variants": {}, "id": "x4e4t3q1y1fhczqKO2Mh5jJWbb6BvXFs0A1NzCTGjC8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "yesu7y", "is_robot_indexable": true, "report_reasons": null, "author": "Gill_Chloet", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yesu7y/predictive_analytics_in_venture_investing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://parsers.vc/blog/predictive-analytics-in-venture-investing/", "subreddit_subscribers": 815866, "created_utc": 1666879488.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Currently a Biochemistry grad working in research for a blood banking company. Hate it. Thinking about a masters in data science or pursuing certs on my free time without a masters. \n\nWould anyone like to give a realistic run down of what a typical day looks like for you working in data science? \n\n\nAlso, is data science similar to computer science in the aspect that you don\u2019t need a degree just need to know your stuff to secure a job? (Unlike the translational side of science, degree means everything\ud83d\ude43) \n\nThanks in advance!", "author_fullname": "t2_9csm8sf4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career Switch", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yez6vq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666894655.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently a Biochemistry grad working in research for a blood banking company. Hate it. Thinking about a masters in data science or pursuing certs on my free time without a masters. &lt;/p&gt;\n\n&lt;p&gt;Would anyone like to give a realistic run down of what a typical day looks like for you working in data science? &lt;/p&gt;\n\n&lt;p&gt;Also, is data science similar to computer science in the aspect that you don\u2019t need a degree just need to know your stuff to secure a job? (Unlike the translational side of science, degree means everything\ud83d\ude43) &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yez6vq", "is_robot_indexable": true, "report_reasons": null, "author": "SprayPsychological86", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yez6vq/career_switch/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yez6vq/career_switch/", "subreddit_subscribers": 815866, "created_utc": 1666894655.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ve recently started at a new company in a hybrid DS/engineering role. It\u2019s an older company in the utility industry, so there\u2019s a pretty healthy mix of \u201ctraditional\u201d &amp; modern ways of keeping track of things (events, equipment, project status, etc). Thankfully we do have some Oracle DBs in place that a couple members on the team are using to build new dashboards and analytics scripts from. However, lots of existing/historical work tracking is done through random Excel sheets scattered about the network drives. There always exists a desire to move forward and advance our current practices to increase effectiveness &amp; efficiency within the company\u2019s data handling schemes. \n\nWe can develop new scripts/dashboards and do all kinds of cool stuff on that side of things. I\u2019m just curious as to what methods other people may be using to bridge gaps between scattered Excel data/reporting sheets and more centralized dashboarding/SW development practices. \n\nIf you couldn\u2019t tell, I\u2019m a bit new the DS working side. I\u2019ve done lots with Python, SQL, and a few dashboard platforms, but I\u2019m still new to the real world applications of DS. \n\nThanks!", "author_fullname": "t2_dv1qy8c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bridging the gap between old &amp; new methods of DS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yf5883", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666909123.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve recently started at a new company in a hybrid DS/engineering role. It\u2019s an older company in the utility industry, so there\u2019s a pretty healthy mix of \u201ctraditional\u201d &amp;amp; modern ways of keeping track of things (events, equipment, project status, etc). Thankfully we do have some Oracle DBs in place that a couple members on the team are using to build new dashboards and analytics scripts from. However, lots of existing/historical work tracking is done through random Excel sheets scattered about the network drives. There always exists a desire to move forward and advance our current practices to increase effectiveness &amp;amp; efficiency within the company\u2019s data handling schemes. &lt;/p&gt;\n\n&lt;p&gt;We can develop new scripts/dashboards and do all kinds of cool stuff on that side of things. I\u2019m just curious as to what methods other people may be using to bridge gaps between scattered Excel data/reporting sheets and more centralized dashboarding/SW development practices. &lt;/p&gt;\n\n&lt;p&gt;If you couldn\u2019t tell, I\u2019m a bit new the DS working side. I\u2019ve done lots with Python, SQL, and a few dashboard platforms, but I\u2019m still new to the real world applications of DS. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yf5883", "is_robot_indexable": true, "report_reasons": null, "author": "ljh78", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yf5883/bridging_the_gap_between_old_new_methods_of_ds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yf5883/bridging_the_gap_between_old_new_methods_of_ds/", "subreddit_subscribers": 815866, "created_utc": 1666909123.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a tad confused and a noob, please be patient.\n\nI was watching one of my co-workers analyse and visualise some data and he said he was going to normalise the data. For normalisation I normally used the mean, standard deviation and standarise the data using those.\n\nHowever, this is what he did:\n\nCalculated the regression equation.\n\nUsing the independent variable coefficient and the intercept (from the previous step) he calculated the predicted y.\n\nProceeded to substract the actual y against the predicted y and then add the average of all of the predicted y.\n\nWhat essentially happened is that he got rid of the independent variable coefficient (if you were to graph it, the trendline would be flat). Now:\n\nIS this actually normalising data or is it integration? if neither, what would this be? and why should I do it?\n\nI am asking since he had to go.", "author_fullname": "t2_q2cte", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Simple question about normalising and integrating data.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfe464", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666931955.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a tad confused and a noob, please be patient.&lt;/p&gt;\n\n&lt;p&gt;I was watching one of my co-workers analyse and visualise some data and he said he was going to normalise the data. For normalisation I normally used the mean, standard deviation and standarise the data using those.&lt;/p&gt;\n\n&lt;p&gt;However, this is what he did:&lt;/p&gt;\n\n&lt;p&gt;Calculated the regression equation.&lt;/p&gt;\n\n&lt;p&gt;Using the independent variable coefficient and the intercept (from the previous step) he calculated the predicted y.&lt;/p&gt;\n\n&lt;p&gt;Proceeded to substract the actual y against the predicted y and then add the average of all of the predicted y.&lt;/p&gt;\n\n&lt;p&gt;What essentially happened is that he got rid of the independent variable coefficient (if you were to graph it, the trendline would be flat). Now:&lt;/p&gt;\n\n&lt;p&gt;IS this actually normalising data or is it integration? if neither, what would this be? and why should I do it?&lt;/p&gt;\n\n&lt;p&gt;I am asking since he had to go.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfe464", "is_robot_indexable": true, "report_reasons": null, "author": "manuelgcg", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfe464/simple_question_about_normalising_and_integrating/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfe464/simple_question_about_normalising_and_integrating/", "subreddit_subscribers": 815866, "created_utc": 1666931955.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "i basically have 1-2-3 (high medium low quality) and want to plot the counts, stacked, on a histogram. Only thing is I want something like an interactive button to bring the selected histogram to the front  \n\n\nWhat can I easily do this with in python?  \n\n\nI will then make it web runnable on steamlit", "author_fullname": "t2_lww73a7r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I make an interactive histogram in python?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfaot7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666922693.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i basically have 1-2-3 (high medium low quality) and want to plot the counts, stacked, on a histogram. Only thing is I want something like an interactive button to bring the selected histogram to the front  &lt;/p&gt;\n\n&lt;p&gt;What can I easily do this with in python?  &lt;/p&gt;\n\n&lt;p&gt;I will then make it web runnable on steamlit&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfaot7", "is_robot_indexable": true, "report_reasons": null, "author": "fartuni4", "discussion_type": null, "num_comments": 7, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfaot7/how_can_i_make_an_interactive_histogram_in_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfaot7/how_can_i_make_an_interactive_histogram_in_python/", "subreddit_subscribers": 815866, "created_utc": 1666922693.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I wanted to download data from the realized library. However, access to the library seems to be impossible. Most of their webpages are down.\n\nDoes anyone have more information on this and are there any alternatives for accessing realized volatility data on stocks and indices?\n\nThanks!", "author_fullname": "t2_9b52fl7q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Oxford-Man Institute\u2019s Realized Library", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yen4z8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666861973.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wanted to download data from the realized library. However, access to the library seems to be impossible. Most of their webpages are down.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have more information on this and are there any alternatives for accessing realized volatility data on stocks and indices?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yen4z8", "is_robot_indexable": true, "report_reasons": null, "author": "DigSerious8047", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yen4z8/oxfordman_institutes_realized_library/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yen4z8/oxfordman_institutes_realized_library/", "subreddit_subscribers": 815866, "created_utc": 1666861973.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unraveling the Mystery of the Universe", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 74, "top_awarded_type": null, "hide_score": true, "name": "t3_yfgkrr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_dt6ya2pz", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/OaDu191F5_Iqk33m7vso8YJOOtmVYhvzYusQPkc7Qf4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "u_addlerkuhn", "selftext": "We have always been curious about the universe \u2014 to seek the unknown and understand what lies beyond Earth. With [data analytics](http://www.cubeware.com/advanced-analytics) and [Business Intelligence](http://www.cubeware.com/) (BI) solutions revolutionizing the way we conduct astronomy, we can now better understand the mysteries of the universe \u2014 such as, dark matter, the Milky Way galaxy, other planets, and more.\n\nOne of the greatest examples in modern astronomy is the unveiling of the images NASA\u2019s James Webb Space Telescope recently captured of our universe. Webb is a collaboration between the European Space Agency (ESA) and Canadian Space Agency (CSA), and as the public received the first glimpse of its potential, it launched a deeper understanding into how our universe began.\n\nhttps://preview.redd.it/tsrfbruwrhw91.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;s=54ba20189d1d6a2e49e5162b9ceb70fe9fc592e5\n\nOn 12th July 2022, the first data from the Webb telescope came in with a batch of full-color scientific photos and spectra. Webb\u2019s findings reveal a history of the unseen universe throughout several stages of cosmic evolution \u2014 from nearby planets that are distant from our solar system (i.e., exoplanets) to the most faraway detectable galaxies in the early cosmos. The [publications](https://www.nasa.gov/webbfirstimages) include Carina Nebula, Stephan\u2019s Quintet, Southern Ring Nebula, WASP-96 b, and SMACS 0723.\n\nDue to the telescope\u2019s ability to see extremely far away, and given the speed of light, the images we\u2019re seeing are of how objects were 4.6-13.5 billion years ago (just after the Big Bang). Data analysis tools \u2014 such as the ones in the JWST post-pipeline data analysis ecosystem \u2014 have been paramount in this project due to the sheer volume of infrared datapoints that needed to be processed. From analysis to visualization, these tools were able to sort through, clean, model, and visualize the data into the images we see today.\n\nLearn more about the crucial ways in which data has transformed our study of astronomy here: [Unraveling the Mystery of the Universe](https://www.linkedin.com/pulse/unraveling-mystery-universe-cubeware-gmbh/)", "author_fullname": "t2_dt6ya2pz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unraveling the Mystery of the Universe", "link_flair_richtext": [], "subreddit_name_prefixed": "u/addlerkuhn", "hidden": false, "pwls": null, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 74, "top_awarded_type": null, "hide_score": true, "media_metadata": {"tsrfbruwrhw91": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 57, "x": 108, "u": "https://preview.redd.it/tsrfbruwrhw91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fa49042f26699e167b2392b199dc54da405a2cc4"}, {"y": 114, "x": 216, "u": "https://preview.redd.it/tsrfbruwrhw91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5c73781e2dc9870b76e5679ba9a46fa2046909f6"}, {"y": 169, "x": 320, "u": "https://preview.redd.it/tsrfbruwrhw91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=141c1f5bd4f752238455f37da8557505b07422b7"}, {"y": 339, "x": 640, "u": "https://preview.redd.it/tsrfbruwrhw91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3cdb9ba94058aae870290fbede29371db0197160"}, {"y": 509, "x": 960, "u": "https://preview.redd.it/tsrfbruwrhw91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=31d553b224bd5c7a6c08834b5a0659096dee6a67"}, {"y": 572, "x": 1080, "u": "https://preview.redd.it/tsrfbruwrhw91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8c3ca674faa73c938bf3cbd223817d6abe2b2b7b"}], "s": {"y": 679, "x": 1280, "u": "https://preview.redd.it/tsrfbruwrhw91.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;s=54ba20189d1d6a2e49e5162b9ceb70fe9fc592e5"}, "id": "tsrfbruwrhw91"}}, "name": "t3_yfgj10", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "user", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/OaDu191F5_Iqk33m7vso8YJOOtmVYhvzYusQPkc7Qf4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666939032.0, "link_flair_type": "text", "wls": null, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.addlerkuhn", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have always been curious about the universe \u2014 to seek the unknown and understand what lies beyond Earth. With &lt;a href=\"http://www.cubeware.com/advanced-analytics\"&gt;data analytics&lt;/a&gt; and &lt;a href=\"http://www.cubeware.com/\"&gt;Business Intelligence&lt;/a&gt; (BI) solutions revolutionizing the way we conduct astronomy, we can now better understand the mysteries of the universe \u2014 such as, dark matter, the Milky Way galaxy, other planets, and more.&lt;/p&gt;\n\n&lt;p&gt;One of the greatest examples in modern astronomy is the unveiling of the images NASA\u2019s James Webb Space Telescope recently captured of our universe. Webb is a collaboration between the European Space Agency (ESA) and Canadian Space Agency (CSA), and as the public received the first glimpse of its potential, it launched a deeper understanding into how our universe began.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/tsrfbruwrhw91.jpg?width=1280&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=54ba20189d1d6a2e49e5162b9ceb70fe9fc592e5\"&gt;https://preview.redd.it/tsrfbruwrhw91.jpg?width=1280&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=54ba20189d1d6a2e49e5162b9ceb70fe9fc592e5&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;On 12th July 2022, the first data from the Webb telescope came in with a batch of full-color scientific photos and spectra. Webb\u2019s findings reveal a history of the unseen universe throughout several stages of cosmic evolution \u2014 from nearby planets that are distant from our solar system (i.e., exoplanets) to the most faraway detectable galaxies in the early cosmos. The &lt;a href=\"https://www.nasa.gov/webbfirstimages\"&gt;publications&lt;/a&gt; include Carina Nebula, Stephan\u2019s Quintet, Southern Ring Nebula, WASP-96 b, and SMACS 0723.&lt;/p&gt;\n\n&lt;p&gt;Due to the telescope\u2019s ability to see extremely far away, and given the speed of light, the images we\u2019re seeing are of how objects were 4.6-13.5 billion years ago (just after the Big Bang). Data analysis tools \u2014 such as the ones in the JWST post-pipeline data analysis ecosystem \u2014 have been paramount in this project due to the sheer volume of infrared datapoints that needed to be processed. From analysis to visualization, these tools were able to sort through, clean, model, and visualize the data into the images we see today.&lt;/p&gt;\n\n&lt;p&gt;Learn more about the crucial ways in which data has transformed our study of astronomy here: &lt;a href=\"https://www.linkedin.com/pulse/unraveling-mystery-universe-cubeware-gmbh/\"&gt;Unraveling the Mystery of the Universe&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "qa", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/wQASW9yj3WtZZPh5OA2R-ry9lpzY08wJLxmVyZ8PCoQ.jpg?auto=webp&amp;s=8c69ac989a744c80c4ed916996ce31d8d128e880", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/wQASW9yj3WtZZPh5OA2R-ry9lpzY08wJLxmVyZ8PCoQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=35c5733509161ba2f7d978adb14511cb97554805", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/wQASW9yj3WtZZPh5OA2R-ry9lpzY08wJLxmVyZ8PCoQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=caf4e9e34e24510c7bf2d17c70fc99f181f88f56", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/wQASW9yj3WtZZPh5OA2R-ry9lpzY08wJLxmVyZ8PCoQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7eb603c98717383208956083ca0216af207a38b0", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/wQASW9yj3WtZZPh5OA2R-ry9lpzY08wJLxmVyZ8PCoQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3e69f749d88e14620d6b09a7075b73451dd921de", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/wQASW9yj3WtZZPh5OA2R-ry9lpzY08wJLxmVyZ8PCoQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9e913cbe7ff49cd3f2b8d2bb8867cb9c46908a34", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/wQASW9yj3WtZZPh5OA2R-ry9lpzY08wJLxmVyZ8PCoQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=aa15d457e0e5c3f51abe5d263c501ea8c1c0da48", "width": 1080, "height": 565}], "variants": {}, "id": "ubzUXxWhGJz0oln_zbIMMZlQQnhs85A8z3G6XVk0_2Q"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_6uqcib", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfgj10", "is_robot_indexable": true, "report_reasons": null, "author": "addlerkuhn", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": null, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/u_addlerkuhn/comments/yfgj10/unraveling_the_mystery_of_the_universe/", "parent_whitelist_status": null, "stickied": false, "url": "https://old.reddit.com/r/u_addlerkuhn/comments/yfgj10/unraveling_the_mystery_of_the_universe/", "subreddit_subscribers": 0, "created_utc": 1666939032.0, "num_crossposts": 7, "media": null, "is_video": false}], "created": 1666939178.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.addlerkuhn", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/user/addlerkuhn/comments/yfgj10/unraveling_the_mystery_of_the_universe/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/wQASW9yj3WtZZPh5OA2R-ry9lpzY08wJLxmVyZ8PCoQ.jpg?auto=webp&amp;s=8c69ac989a744c80c4ed916996ce31d8d128e880", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/wQASW9yj3WtZZPh5OA2R-ry9lpzY08wJLxmVyZ8PCoQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=35c5733509161ba2f7d978adb14511cb97554805", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/wQASW9yj3WtZZPh5OA2R-ry9lpzY08wJLxmVyZ8PCoQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=caf4e9e34e24510c7bf2d17c70fc99f181f88f56", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/wQASW9yj3WtZZPh5OA2R-ry9lpzY08wJLxmVyZ8PCoQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7eb603c98717383208956083ca0216af207a38b0", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/wQASW9yj3WtZZPh5OA2R-ry9lpzY08wJLxmVyZ8PCoQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3e69f749d88e14620d6b09a7075b73451dd921de", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/wQASW9yj3WtZZPh5OA2R-ry9lpzY08wJLxmVyZ8PCoQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9e913cbe7ff49cd3f2b8d2bb8867cb9c46908a34", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/wQASW9yj3WtZZPh5OA2R-ry9lpzY08wJLxmVyZ8PCoQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=aa15d457e0e5c3f51abe5d263c501ea8c1c0da48", "width": 1080, "height": 565}], "variants": {}, "id": "ubzUXxWhGJz0oln_zbIMMZlQQnhs85A8z3G6XVk0_2Q"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfgkrr", "is_robot_indexable": true, "report_reasons": null, "author": "addlerkuhn", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_yfgj10", "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfgkrr/unraveling_the_mystery_of_the_universe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/user/addlerkuhn/comments/yfgj10/unraveling_the_mystery_of_the_universe/", "subreddit_subscribers": 815866, "created_utc": 1666939178.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Generating statistics with a free or cheap survey platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfc3jb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_7rpkz", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "AskStatistics", "selftext": "I'm looking for a survey tool for about 150 people that won't cost me much or anything for this reason:\n\nI'm a social scientist wanting to include a cute pop social science survey along with my wedding save-the-dates. It will ask silly questions using things like Big Five personality quiz and silly things like felling thermometers toward cats and dogs (and maybe some text-as-data components and other popular question batteries). Then, I will create a GitHub site for the wedding and post some pretty R visualizations about our guests as they differ from bride and groom guests and compare them to nationally representative surveys when applicable (I know how to do that part). Obviously this is very nerdy, but that's the vibe. \n\nI recently lost access to Qualtrics (which would have worked perfectly) and need something that can get the job done. Any recommendations?", "author_fullname": "t2_7rpkz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Generating statistics with a free or cheap survey platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/AskStatistics", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfbyw1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666926079.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.AskStatistics", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for a survey tool for about 150 people that won&amp;#39;t cost me much or anything for this reason:&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a social scientist wanting to include a cute pop social science survey along with my wedding save-the-dates. It will ask silly questions using things like Big Five personality quiz and silly things like felling thermometers toward cats and dogs (and maybe some text-as-data components and other popular question batteries). Then, I will create a GitHub site for the wedding and post some pretty R visualizations about our guests as they differ from bride and groom guests and compare them to nationally representative surveys when applicable (I know how to do that part). Obviously this is very nerdy, but that&amp;#39;s the vibe. &lt;/p&gt;\n\n&lt;p&gt;I recently lost access to Qualtrics (which would have worked perfectly) and need something that can get the job done. Any recommendations?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sioa", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfbyw1", "is_robot_indexable": true, "report_reasons": null, "author": "PeripheralVisions", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/AskStatistics/comments/yfbyw1/generating_statistics_with_a_free_or_cheap_survey/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/AskStatistics/comments/yfbyw1/generating_statistics_with_a_free_or_cheap_survey/", "subreddit_subscribers": 57167, "created_utc": 1666926079.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1666926441.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.AskStatistics", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/AskStatistics/comments/yfbyw1/generating_statistics_with_a_free_or_cheap_survey/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfc3jb", "is_robot_indexable": true, "report_reasons": null, "author": "PeripheralVisions", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_yfbyw1", "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfc3jb/generating_statistics_with_a_free_or_cheap_survey/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/AskStatistics/comments/yfbyw1/generating_statistics_with_a_free_or_cheap_survey/", "subreddit_subscribers": 815866, "created_utc": 1666926441.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello yall,\n\nI am doing a project for my economics class and was wondering if anyone in this subreddit has any interesting articles or studies that can show causality between tax-breaks and  economic growth or income. I need to isolate and use methods such as difference-in-difference or other methods to somehow show that a tax break helped or didn't help a state or city. Any thoughts or suggestions or other ways to look at this project? \n\nP.S. my professor said, how will I isolate for the tax-break? What if a big company had just moved into town and brought jobs and investments? How can I show that it was the tax-break that helped or didn't help. \n\nTHIS IS NOT HOMEWORK HELP, I JUST NEED DIFFERENT WAYS TO APPROACH THIS.", "author_fullname": "t2_7chxigz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Isolating for main outcome variables for a tax-break project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfbebv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666924533.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello yall,&lt;/p&gt;\n\n&lt;p&gt;I am doing a project for my economics class and was wondering if anyone in this subreddit has any interesting articles or studies that can show causality between tax-breaks and  economic growth or income. I need to isolate and use methods such as difference-in-difference or other methods to somehow show that a tax break helped or didn&amp;#39;t help a state or city. Any thoughts or suggestions or other ways to look at this project? &lt;/p&gt;\n\n&lt;p&gt;P.S. my professor said, how will I isolate for the tax-break? What if a big company had just moved into town and brought jobs and investments? How can I show that it was the tax-break that helped or didn&amp;#39;t help. &lt;/p&gt;\n\n&lt;p&gt;THIS IS NOT HOMEWORK HELP, I JUST NEED DIFFERENT WAYS TO APPROACH THIS.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfbebv", "is_robot_indexable": true, "report_reasons": null, "author": "bakerintheforest", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfbebv/isolating_for_main_outcome_variables_for_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfbebv/isolating_for_main_outcome_variables_for_a/", "subreddit_subscribers": 815866, "created_utc": 1666924533.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ve been working as an applied ML engineer for almost a decade now, and in recent years I find I\u2019m spending a lot less time fiddling with model architectures and a lot more time digging into the data - rebalancing the data, removing bad labels, figuring out features we should add, and sourcing new labeled examples of cases where the model is weak.\n\nOften I\u2019ve found this means collaborating with less-technical folks (e.g. PMs, managers, annotators, data domain experts, etc.) on the team to dig through individual examples in our training set. While the engineers and data scientists on the team are usually comfortable looking at examples in a Python notebook environment, with the non-technical folks, I often need to screen-share my notebook with them, or we hack together a Google spreadsheet where we can comment/collaborate on identifying issues with mispredicted examples. Sometimes I\u2019ll write a script to generate an HTML dump that visualizes a slice of examples just so that we can gain more intuition than what we get from putting it all in a spreadsheet.\n\nI\u2019ve been working on a prototype to ideally reduce a lot of the friction behind this hand-off and collaboration process. It\u2019s still rough around the edges, but the basic flow is:\n\n* You import a slice of your dataset / predictions via a one-liner function call in a Python notebook or by manually uploading from your hard drive via a GUI.\n* You can then quickly customize how the dataset examples are visualized via a web interface: you can choose grid/table layouts, pick a subset of features to display, modify text size and color, render URLs as images, visualize bounding boxes, format enums to be color-coded and human-readable, or you can do something entirely custom.\n* You then get a link that you can share with the rest of your team so that everyone can comment and collaborate by looking at individual model predictions and diagnose next steps for improving the model.\n\nAnyway, I was wondering if there was anyone here who\u2019d be interested in trying out the prototype and providing some feedback on how to improve it? Alternatively, are there any existing tools/processes you all like to use to make this collaboration process easier? Thanks!\n\n**TL;DR:** Looking for feedback on a prototype of a tool to help ML engineers &amp; data scientists easily collaborate with non-technical team members when curating a dataset.", "author_fullname": "t2_qwbxg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for feedback on a dataset collaboration tool for ML projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yf8dvd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666916904.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been working as an applied ML engineer for almost a decade now, and in recent years I find I\u2019m spending a lot less time fiddling with model architectures and a lot more time digging into the data - rebalancing the data, removing bad labels, figuring out features we should add, and sourcing new labeled examples of cases where the model is weak.&lt;/p&gt;\n\n&lt;p&gt;Often I\u2019ve found this means collaborating with less-technical folks (e.g. PMs, managers, annotators, data domain experts, etc.) on the team to dig through individual examples in our training set. While the engineers and data scientists on the team are usually comfortable looking at examples in a Python notebook environment, with the non-technical folks, I often need to screen-share my notebook with them, or we hack together a Google spreadsheet where we can comment/collaborate on identifying issues with mispredicted examples. Sometimes I\u2019ll write a script to generate an HTML dump that visualizes a slice of examples just so that we can gain more intuition than what we get from putting it all in a spreadsheet.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been working on a prototype to ideally reduce a lot of the friction behind this hand-off and collaboration process. It\u2019s still rough around the edges, but the basic flow is:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;You import a slice of your dataset / predictions via a one-liner function call in a Python notebook or by manually uploading from your hard drive via a GUI.&lt;/li&gt;\n&lt;li&gt;You can then quickly customize how the dataset examples are visualized via a web interface: you can choose grid/table layouts, pick a subset of features to display, modify text size and color, render URLs as images, visualize bounding boxes, format enums to be color-coded and human-readable, or you can do something entirely custom.&lt;/li&gt;\n&lt;li&gt;You then get a link that you can share with the rest of your team so that everyone can comment and collaborate by looking at individual model predictions and diagnose next steps for improving the model.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Anyway, I was wondering if there was anyone here who\u2019d be interested in trying out the prototype and providing some feedback on how to improve it? Alternatively, are there any existing tools/processes you all like to use to make this collaboration process easier? Thanks!&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;TL;DR:&lt;/strong&gt; Looking for feedback on a prototype of a tool to help ML engineers &amp;amp; data scientists easily collaborate with non-technical team members when curating a dataset.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yf8dvd", "is_robot_indexable": true, "report_reasons": null, "author": "arkmastermind", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yf8dvd/looking_for_feedback_on_a_dataset_collaboration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yf8dvd/looking_for_feedback_on_a_dataset_collaboration/", "subreddit_subscribers": 815866, "created_utc": 1666916904.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "RAID-1 creates redundancies. But I read that erroneous data will be saved in both HDD.  Do you use RAID-1? What method do you use to save and store data?", "author_fullname": "t2_pwxlrv27", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you use RAID-1 to save data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yf44w2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666906551.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;RAID-1 creates redundancies. But I read that erroneous data will be saved in both HDD.  Do you use RAID-1? What method do you use to save and store data?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yf44w2", "is_robot_indexable": true, "report_reasons": null, "author": "Fast-Group-8501", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yf44w2/do_you_use_raid1_to_save_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yf44w2/do_you_use_raid1_to_save_data/", "subreddit_subscribers": 815866, "created_utc": 1666906551.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Ever wondered how Tesla's autopilot is able to make so many predictions in real time? It's because instead of \n\ndesigning multiple neural networks for different tasks, they design neural networks with a common backbone \n\ndoing multiple tasks. These neural networks are called Hydranets. Having known about them I revived\n\nmy old project on a self-driving car and designed a hydranet for predicting both the steering angle and throttle\n\nin a single pass. To know more you can visit this blog link:\n\n&amp;#x200B;\n\n[https://medium.com/geekculture/building-a-hydranet-for-self-driving-car-simulation-cd08543feffe](https://medium.com/geekculture/building-a-hydranet-for-self-driving-car-simulation-cd08543feffe)\n\n&amp;#x200B;\n\nThere is also a youtube link in the blog which shows the working of the system in real time.", "author_fullname": "t2_5n4y6isg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building a HydraNet for Self-driving car simulation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yevcvu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666885587.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Ever wondered how Tesla&amp;#39;s autopilot is able to make so many predictions in real time? It&amp;#39;s because instead of &lt;/p&gt;\n\n&lt;p&gt;designing multiple neural networks for different tasks, they design neural networks with a common backbone &lt;/p&gt;\n\n&lt;p&gt;doing multiple tasks. These neural networks are called Hydranets. Having known about them I revived&lt;/p&gt;\n\n&lt;p&gt;my old project on a self-driving car and designed a hydranet for predicting both the steering angle and throttle&lt;/p&gt;\n\n&lt;p&gt;in a single pass. To know more you can visit this blog link:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/geekculture/building-a-hydranet-for-self-driving-car-simulation-cd08543feffe\"&gt;https://medium.com/geekculture/building-a-hydranet-for-self-driving-car-simulation-cd08543feffe&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;There is also a youtube link in the blog which shows the working of the system in real time.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rZAv-LIYN1pNN2jrBY-dd020w0oO2q4PEdUT0VwdJWA.jpg?auto=webp&amp;s=9130a9ceacdb694d01ee9f715d34a83e707be4ab", "width": 1200, "height": 960}, "resolutions": [{"url": "https://external-preview.redd.it/rZAv-LIYN1pNN2jrBY-dd020w0oO2q4PEdUT0VwdJWA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=12ab01ec1559421ed9490d0a8fdcaffe96a3ae78", "width": 108, "height": 86}, {"url": "https://external-preview.redd.it/rZAv-LIYN1pNN2jrBY-dd020w0oO2q4PEdUT0VwdJWA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=082e2064f243fde2f8c8094a1372748ba9739e77", "width": 216, "height": 172}, {"url": "https://external-preview.redd.it/rZAv-LIYN1pNN2jrBY-dd020w0oO2q4PEdUT0VwdJWA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4322a861db8f22dbcb2b8055589d990cb12997df", "width": 320, "height": 256}, {"url": "https://external-preview.redd.it/rZAv-LIYN1pNN2jrBY-dd020w0oO2q4PEdUT0VwdJWA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=80d8dfa24d1f29a38b18ebfa3747a34ff256e6f1", "width": 640, "height": 512}, {"url": "https://external-preview.redd.it/rZAv-LIYN1pNN2jrBY-dd020w0oO2q4PEdUT0VwdJWA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=db5966268af13cece89b0902f6f239ad1377f59f", "width": 960, "height": 768}, {"url": "https://external-preview.redd.it/rZAv-LIYN1pNN2jrBY-dd020w0oO2q4PEdUT0VwdJWA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cb41fbd93d0ceab9b7716f7144273210464cabf4", "width": 1080, "height": 864}], "variants": {}, "id": "iIqcll9FNIE46fGW_tKFBGy_JWXm1X25XkkJhC1GDFc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yevcvu", "is_robot_indexable": true, "report_reasons": null, "author": "VikasOjha666", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yevcvu/building_a_hydranet_for_selfdriving_car_simulation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yevcvu/building_a_hydranet_for_selfdriving_car_simulation/", "subreddit_subscribers": 815866, "created_utc": 1666885587.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "The first offer is a 4-months data science internship role in marketing domain(they're known to hire fulltime if the intern was good). \nThe other one is a fulltime BI dev role in insurance (will learn some ETL during). Downside here is that there will be no building data models. Just sql and BI. \nThis will be my first job in the field. Which one will be better in the long run? \nThank you", "author_fullname": "t2_9mpmbpc8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I want to become a data scientist and I have 2 job offers. What do I choose?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yerqya", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666876652.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The first offer is a 4-months data science internship role in marketing domain(they&amp;#39;re known to hire fulltime if the intern was good). \nThe other one is a fulltime BI dev role in insurance (will learn some ETL during). Downside here is that there will be no building data models. Just sql and BI. \nThis will be my first job in the field. Which one will be better in the long run? \nThank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yerqya", "is_robot_indexable": true, "report_reasons": null, "author": "anonynimiti", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yerqya/i_want_to_become_a_data_scientist_and_i_have_2/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yerqya/i_want_to_become_a_data_scientist_and_i_have_2/", "subreddit_subscribers": 815866, "created_utc": 1666876652.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "[https://github.com/datacamp/datacamp-light](https://github.com/datacamp/datacamp-light)\n\nAre there any open source tools like this to add in some blog or website to make it an interactive platform?", "author_fullname": "t2_7mleycpk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any open source packages like datacamp light?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yeqbr1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666872695.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://github.com/datacamp/datacamp-light\"&gt;https://github.com/datacamp/datacamp-light&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Are there any open source tools like this to add in some blog or website to make it an interactive platform?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MCnVzSoUqbi_slUzyaXJWih8Q5Um3GL6QAAZlWg27is.jpg?auto=webp&amp;s=3b34aca42862abcb2c23e6d4c63759c87bfbf7c7", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/MCnVzSoUqbi_slUzyaXJWih8Q5Um3GL6QAAZlWg27is.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7ec4b04822aadf08cee04d86fcd65064eccbfcb0", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/MCnVzSoUqbi_slUzyaXJWih8Q5Um3GL6QAAZlWg27is.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ec3655eae5110219b9b191e77239a4477452c014", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/MCnVzSoUqbi_slUzyaXJWih8Q5Um3GL6QAAZlWg27is.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fa4a8bf4366c8615eac06fedc80795a5b53dcf89", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/MCnVzSoUqbi_slUzyaXJWih8Q5Um3GL6QAAZlWg27is.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7f2b47c42ce42d48e32e8c7bb41a1a77a3beb492", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/MCnVzSoUqbi_slUzyaXJWih8Q5Um3GL6QAAZlWg27is.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4f1c3841ebdb09afeeffab157f89ea8b0dc0af60", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/MCnVzSoUqbi_slUzyaXJWih8Q5Um3GL6QAAZlWg27is.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c7d939b2de30f01bc7990d5eb2c67d73e66812c3", "width": 1080, "height": 540}], "variants": {}, "id": "slVAZFG_wASPl9zrCvOIa2UMCQqAXYg8kP3bGucWG1o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yeqbr1", "is_robot_indexable": true, "report_reasons": null, "author": "abhishek_rath_01", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yeqbr1/are_there_any_open_source_packages_like_datacamp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yeqbr1/are_there_any_open_source_packages_like_datacamp/", "subreddit_subscribers": 815866, "created_utc": 1666872695.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Is it legal to partially replicate a proprietary machine learning algorithm by:\n\n* Spamming the algorithm's API with random data inputs\n* Recording what you put in and what the algorithm spat out\n* Training your own algorithm using that data\n\nWould it only become illegal if I tried to sell such an algorithm?\n\nI have no intention to do this, but interesting thought experiment", "author_fullname": "t2_d8yt2ssh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Illegal to partially replicate a proprietary algorithm?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yen7gx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666862238.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it legal to partially replicate a proprietary machine learning algorithm by:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Spamming the algorithm&amp;#39;s API with random data inputs&lt;/li&gt;\n&lt;li&gt;Recording what you put in and what the algorithm spat out&lt;/li&gt;\n&lt;li&gt;Training your own algorithm using that data&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Would it only become illegal if I tried to sell such an algorithm?&lt;/p&gt;\n\n&lt;p&gt;I have no intention to do this, but interesting thought experiment&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yen7gx", "is_robot_indexable": true, "report_reasons": null, "author": "Competitive-Unit-385", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yen7gx/illegal_to_partially_replicate_a_proprietary/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yen7gx/illegal_to_partially_replicate_a_proprietary/", "subreddit_subscribers": 815866, "created_utc": 1666862238.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m curious to know what the consensus on best online master\u2019s in data science is? I am a little less price dependent as my company would cover $30k or so.\n\nThe 3 I keep seeing as being rated pretty well are Georgia Tech, Texas, and Illinois.\n\nIs this accurate?\n\nWould love to hear where different people went, how the program was, and roughly how much time they spent per class per week.\n\nThank you so much in advance!", "author_fullname": "t2_17qwjq21", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best online master\u2019s in data science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfaiou", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666922270.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m curious to know what the consensus on best online master\u2019s in data science is? I am a little less price dependent as my company would cover $30k or so.&lt;/p&gt;\n\n&lt;p&gt;The 3 I keep seeing as being rated pretty well are Georgia Tech, Texas, and Illinois.&lt;/p&gt;\n\n&lt;p&gt;Is this accurate?&lt;/p&gt;\n\n&lt;p&gt;Would love to hear where different people went, how the program was, and roughly how much time they spent per class per week.&lt;/p&gt;\n\n&lt;p&gt;Thank you so much in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfaiou", "is_robot_indexable": true, "report_reasons": null, "author": "PowerfulSquirrel4", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfaiou/best_online_masters_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfaiou/best_online_masters_in_data_science/", "subreddit_subscribers": 815866, "created_utc": 1666922270.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Invoices Auto-labeling using LayoutLM", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yez4hi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_32tnavmg", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "u_UBIAI", "selftext": "Do you want to accelerate your labeling process in just a few clicks?\n\n\nIn this tutorial, we'll show you how to auto-label your data in a couple of simple steps:\n\n- We will begin by fine-tuning Microsoft's layoutLM model on an invoice dataset.\n\n- Next, we will correct the mislabeled entities and retrain the model to improve accuracy and speed up the process.\n\nCheck it out and start saving time and effort right away!\n\nhttps://medium.com/mlearning-ai/invoice-auto-labeling-using-layoutlm-8b0e5cffc837", "author_fullname": "t2_32tnavmg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Invoices Auto-labeling using LayoutLM", "link_flair_richtext": [], "subreddit_name_prefixed": "u/UBIAI", "hidden": false, "pwls": null, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yez3m2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "user", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666894432.0, "link_flair_type": "text", "wls": null, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.UBIAI", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you want to accelerate your labeling process in just a few clicks?&lt;/p&gt;\n\n&lt;p&gt;In this tutorial, we&amp;#39;ll show you how to auto-label your data in a couple of simple steps:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;We will begin by fine-tuning Microsoft&amp;#39;s layoutLM model on an invoice dataset.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Next, we will correct the mislabeled entities and retrain the model to improve accuracy and speed up the process.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Check it out and start saving time and effort right away!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/mlearning-ai/invoice-auto-labeling-using-layoutlm-8b0e5cffc837\"&gt;https://medium.com/mlearning-ai/invoice-auto-labeling-using-layoutlm-8b0e5cffc837&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "qa", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/3BI8TaSflL0BpNCq4ePP7l1hXTBdzgzEyIQbgxr6m1Y.jpg?auto=webp&amp;s=95d5c33b0636a797f6761dcfad95329c166f662d", "width": 861, "height": 946}, "resolutions": [{"url": "https://external-preview.redd.it/3BI8TaSflL0BpNCq4ePP7l1hXTBdzgzEyIQbgxr6m1Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=545af0a01380324a5400131334c2a52a6398ebca", "width": 108, "height": 118}, {"url": "https://external-preview.redd.it/3BI8TaSflL0BpNCq4ePP7l1hXTBdzgzEyIQbgxr6m1Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ebc6715fb9318720d392e2d9fa7e128a3790b20f", "width": 216, "height": 237}, {"url": "https://external-preview.redd.it/3BI8TaSflL0BpNCq4ePP7l1hXTBdzgzEyIQbgxr6m1Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a43e86f265677af299355053d59643a7b6c95880", "width": 320, "height": 351}, {"url": "https://external-preview.redd.it/3BI8TaSflL0BpNCq4ePP7l1hXTBdzgzEyIQbgxr6m1Y.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6645111a9607e524e2fa68d9f94433e4c7c8cc6d", "width": 640, "height": 703}], "variants": {}, "id": "iG4S2wKKH-g1_pmS5Elo1A9m1v2kETpQUIaxaW5oWy8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2lnnxo", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yez3m2", "is_robot_indexable": true, "report_reasons": null, "author": "UBIAI", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": null, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/u_UBIAI/comments/yez3m2/invoices_autolabeling_using_layoutlm/", "parent_whitelist_status": null, "stickied": false, "url": "https://old.reddit.com/r/u_UBIAI/comments/yez3m2/invoices_autolabeling_using_layoutlm/", "subreddit_subscribers": 0, "created_utc": 1666894432.0, "num_crossposts": 4, "media": null, "is_video": false}], "created": 1666894492.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.UBIAI", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/user/UBIAI/comments/yez3m2/invoices_autolabeling_using_layoutlm/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/3BI8TaSflL0BpNCq4ePP7l1hXTBdzgzEyIQbgxr6m1Y.jpg?auto=webp&amp;s=95d5c33b0636a797f6761dcfad95329c166f662d", "width": 861, "height": 946}, "resolutions": [{"url": "https://external-preview.redd.it/3BI8TaSflL0BpNCq4ePP7l1hXTBdzgzEyIQbgxr6m1Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=545af0a01380324a5400131334c2a52a6398ebca", "width": 108, "height": 118}, {"url": "https://external-preview.redd.it/3BI8TaSflL0BpNCq4ePP7l1hXTBdzgzEyIQbgxr6m1Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ebc6715fb9318720d392e2d9fa7e128a3790b20f", "width": 216, "height": 237}, {"url": "https://external-preview.redd.it/3BI8TaSflL0BpNCq4ePP7l1hXTBdzgzEyIQbgxr6m1Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a43e86f265677af299355053d59643a7b6c95880", "width": 320, "height": 351}, {"url": "https://external-preview.redd.it/3BI8TaSflL0BpNCq4ePP7l1hXTBdzgzEyIQbgxr6m1Y.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6645111a9607e524e2fa68d9f94433e4c7c8cc6d", "width": 640, "height": 703}], "variants": {}, "id": "iG4S2wKKH-g1_pmS5Elo1A9m1v2kETpQUIaxaW5oWy8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yez4hi", "is_robot_indexable": true, "report_reasons": null, "author": "UBIAI", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_yez3m2", "author_flair_text_color": null, "permalink": "/r/datascience/comments/yez4hi/invoices_autolabeling_using_layoutlm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/user/UBIAI/comments/yez3m2/invoices_autolabeling_using_layoutlm/", "subreddit_subscribers": 815866, "created_utc": 1666894492.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I just finished the dataquest Data Science track and can recommend it for programming newbies and people who want to learn how to wrangle with data.\n\nOn top of the Black Friday offer there is the additional chance to receive 15$ off:\n\n[here](https://app.dataquest.io/referral-signup/yos33u0r/)", "author_fullname": "t2_th3ew6uu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learn the basics through Dataquest", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yeyv3d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666893832.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just finished the dataquest Data Science track and can recommend it for programming newbies and people who want to learn how to wrangle with data.&lt;/p&gt;\n\n&lt;p&gt;On top of the Black Friday offer there is the additional chance to receive 15$ off:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://app.dataquest.io/referral-signup/yos33u0r/\"&gt;here&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yeyv3d", "is_robot_indexable": true, "report_reasons": null, "author": "dada_data", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yeyv3d/learn_the_basics_through_dataquest/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yeyv3d/learn_the_basics_through_dataquest/", "subreddit_subscribers": 815866, "created_utc": 1666893832.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hallo!  \n\n\nI am currently deciding on my master thesis, enrolled in Computer Science focusing on Big Data and AI. Based out of Berlin, Germany.\n\nI use Python as my scripting language, versed with Pandas, Numpy, SciPy, Seaborn, matplotlib, Understand machine learning models in theory and regression and classification models in practice. I also have basic understanding of DB and can use SQL in practice.\n\nI still haven't found a field that I really want to work in. Music Information Retrieval (MIR) is interesting as I had done a mini project earlier. Given the time frame, I have to submit a thesis proposal in 2 weeks. I am researching and reading up on papers but I would like to work on my Master thesis with a company as I want to be exposed to real work environment as well. I lack guidance and direction, and working under someone would not only be beneficial for me, but would also give me a second supervisor that my University mandates.\n\nCan someone help me out with this? I'll be happy to share my resume and hold further talks regarding the same. I can be an asset to any team and good with research work. I am seeking a topics under companies as I am open to work in different fields.\n\nTime is crucial and scarce right now.", "author_fullname": "t2_yafrnev", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Regarding guidance for Master Thesis", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yertzi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666876882.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hallo!  &lt;/p&gt;\n\n&lt;p&gt;I am currently deciding on my master thesis, enrolled in Computer Science focusing on Big Data and AI. Based out of Berlin, Germany.&lt;/p&gt;\n\n&lt;p&gt;I use Python as my scripting language, versed with Pandas, Numpy, SciPy, Seaborn, matplotlib, Understand machine learning models in theory and regression and classification models in practice. I also have basic understanding of DB and can use SQL in practice.&lt;/p&gt;\n\n&lt;p&gt;I still haven&amp;#39;t found a field that I really want to work in. Music Information Retrieval (MIR) is interesting as I had done a mini project earlier. Given the time frame, I have to submit a thesis proposal in 2 weeks. I am researching and reading up on papers but I would like to work on my Master thesis with a company as I want to be exposed to real work environment as well. I lack guidance and direction, and working under someone would not only be beneficial for me, but would also give me a second supervisor that my University mandates.&lt;/p&gt;\n\n&lt;p&gt;Can someone help me out with this? I&amp;#39;ll be happy to share my resume and hold further talks regarding the same. I can be an asset to any team and good with research work. I am seeking a topics under companies as I am open to work in different fields.&lt;/p&gt;\n\n&lt;p&gt;Time is crucial and scarce right now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yertzi", "is_robot_indexable": true, "report_reasons": null, "author": "samwham7", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yertzi/regarding_guidance_for_master_thesis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yertzi/regarding_guidance_for_master_thesis/", "subreddit_subscribers": 815866, "created_utc": 1666876882.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm working as a Senior Data Scientist in one of the top companies. I work from 9-5 and they are doing good stuff. But somehow I'm not enjoying it. I'm not excited about the work I'm doing. I want to work on some side projects that can be either be learning for me or help some small scale business with their work. Long term, I think I want to start my own startup or work for one. Any suggestions are appreciated.", "author_fullname": "t2_ji5eacqx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for side project tech/ DS projects to be more productive in free time", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yfb9p0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666924202.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working as a Senior Data Scientist in one of the top companies. I work from 9-5 and they are doing good stuff. But somehow I&amp;#39;m not enjoying it. I&amp;#39;m not excited about the work I&amp;#39;m doing. I want to work on some side projects that can be either be learning for me or help some small scale business with their work. Long term, I think I want to start my own startup or work for one. Any suggestions are appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yfb9p0", "is_robot_indexable": true, "report_reasons": null, "author": "Rude-Evidence246", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yfb9p0/looking_for_side_project_tech_ds_projects_to_be/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yfb9p0/looking_for_side_project_tech_ds_projects_to_be/", "subreddit_subscribers": 815866, "created_utc": 1666924202.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I did my undergrad in IR and Russian. That said, I also took coding courses in Python in high school and did some basic data analysis courses in college + systems engineering. I\u2019m possibly looking to do a Masters in Data Science. Would it be a pipe dream to start down this path? I actually really like working with data and I love the work/life balance that the profession offers. Would you guys have any advice?", "author_fullname": "t2_6yj6vpw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "International Relations and Russian", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yf86uq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666916406.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I did my undergrad in IR and Russian. That said, I also took coding courses in Python in high school and did some basic data analysis courses in college + systems engineering. I\u2019m possibly looking to do a Masters in Data Science. Would it be a pipe dream to start down this path? I actually really like working with data and I love the work/life balance that the profession offers. Would you guys have any advice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yf86uq", "is_robot_indexable": true, "report_reasons": null, "author": "efuc", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yf86uq/international_relations_and_russian/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yf86uq/international_relations_and_russian/", "subreddit_subscribers": 815866, "created_utc": 1666916406.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}