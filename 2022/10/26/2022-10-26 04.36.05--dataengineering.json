{"kind": "Listing", "data": {"after": "t3_ydj6tz", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6pc6xjl3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "U.K. gov consider this a decent package for a Lead DE\u2026", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_yd28wn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 169, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 169, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/U516ly52f6ctuog4RwKMKHcwzKLaq59pVIaSzphWkM8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666696559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/q5oli442rxv91.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/q5oli442rxv91.jpg?auto=webp&amp;s=5048f997709278782cdf525acddd8c778685669f", "width": 1170, "height": 1337}, "resolutions": [{"url": "https://preview.redd.it/q5oli442rxv91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=88b112df9828dd6038eadc65597be0eee38a4455", "width": 108, "height": 123}, {"url": "https://preview.redd.it/q5oli442rxv91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f50d43f8cfc9f68e9e5cd102f649275b7fbfb3f7", "width": 216, "height": 246}, {"url": "https://preview.redd.it/q5oli442rxv91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b802427eabe8990bd3f15015df75e51b4ec80ca1", "width": 320, "height": 365}, {"url": "https://preview.redd.it/q5oli442rxv91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b84f4f3789e0192286e677da5bf131d67b0d5e51", "width": 640, "height": 731}, {"url": "https://preview.redd.it/q5oli442rxv91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=05d81880dc1199fc8f47e3d8a36bc2c4419d7098", "width": 960, "height": 1097}, {"url": "https://preview.redd.it/q5oli442rxv91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3b4ca6cc6bb1ca75138d504edf61e2e65816e2f9", "width": 1080, "height": 1234}], "variants": {}, "id": "1poI9XFqPqr6oMYqs6Bdh9CVKPR-52T1rRerEOrZsug"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yd28wn", "is_robot_indexable": true, "report_reasons": null, "author": "tawaiii", "discussion_type": null, "num_comments": 83, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yd28wn/uk_gov_consider_this_a_decent_package_for_a_lead/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/q5oli442rxv91.jpg", "subreddit_subscribers": 77774, "created_utc": 1666696559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_anyz9dbz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you do when your data pipeline depends on someone else\u2019s pipeline and that upstream pipeline fails?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_ydg0g9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "ups": 70, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 1200, "fallback_url": "https://v.redd.it/rbl58o15q0w91/DASH_480.mp4?source=fallback", "height": 480, "width": 480, "scrubber_media_url": "https://v.redd.it/rbl58o15q0w91/DASH_96.mp4", "dash_url": "https://v.redd.it/rbl58o15q0w91/DASHPlaylist.mpd?a=1669350965%2CNTk1MGUyMjk3NWY3Y2VhMmQ1MTVmYjQwNGU4OTIxZmVkOWY5MjY1YjU3YWQ1ZTJlYTJkNGVmNTU4YWMwNDI1NQ%3D%3D&amp;v=1&amp;f=sd", "duration": 9, "hls_url": "https://v.redd.it/rbl58o15q0w91/HLSPlaylist.m3u8?a=1669350965%2CNTExNjA4MWYwMDgzZmUzMjU4MGI1YmZjYzE5ODJhNTI5MDhiN2UwMGM2ZmE0OTBhMjgwYTMyMjU3NzYyNmY5Yg%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 70, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/QjEC_cURE42AfrncU9uBn8xTfO_V_IBSLGF8bxScrtA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666732599.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/rbl58o15q0w91", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/HV5BVVsGXLrhk-lwml9mvBh3vdK8uEZKxa_f9Mjd1nw.png?format=pjpg&amp;auto=webp&amp;s=fdd6fca210cf305e0bc8ccb860e7a4de59b49fdf", "width": 480, "height": 480}, "resolutions": [{"url": "https://external-preview.redd.it/HV5BVVsGXLrhk-lwml9mvBh3vdK8uEZKxa_f9Mjd1nw.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=a73c83be2768b03b03a1805ca02ab757286832fc", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/HV5BVVsGXLrhk-lwml9mvBh3vdK8uEZKxa_f9Mjd1nw.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=cae283a12c293345ddf62c4e421d20206831846d", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/HV5BVVsGXLrhk-lwml9mvBh3vdK8uEZKxa_f9Mjd1nw.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=c7fe9445e161c6054b92620a744423932669fda9", "width": 320, "height": 320}], "variants": {}, "id": "6PjWrLpAl3G16r_b35yJxv6RyPIPmepaViFCmRXrJ3o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "ydg0g9", "is_robot_indexable": true, "report_reasons": null, "author": "tchungry", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ydg0g9/what_do_you_do_when_your_data_pipeline_depends_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/rbl58o15q0w91", "subreddit_subscribers": 77774, "created_utc": 1666732599.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 1200, "fallback_url": "https://v.redd.it/rbl58o15q0w91/DASH_480.mp4?source=fallback", "height": 480, "width": 480, "scrubber_media_url": "https://v.redd.it/rbl58o15q0w91/DASH_96.mp4", "dash_url": "https://v.redd.it/rbl58o15q0w91/DASHPlaylist.mpd?a=1669350965%2CNTk1MGUyMjk3NWY3Y2VhMmQ1MTVmYjQwNGU4OTIxZmVkOWY5MjY1YjU3YWQ1ZTJlYTJkNGVmNTU4YWMwNDI1NQ%3D%3D&amp;v=1&amp;f=sd", "duration": 9, "hls_url": "https://v.redd.it/rbl58o15q0w91/HLSPlaylist.m3u8?a=1669350965%2CNTExNjA4MWYwMDgzZmUzMjU4MGI1YmZjYzE5ODJhNTI5MDhiN2UwMGM2ZmE0OTBhMjgwYTMyMjU3NzYyNmY5Yg%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So for the last 3 months, my time has been almost solely dedicated to interviewing, onboarding, and training new people at my work. Throughout the whole process, I\u2019ve been able to identify a couple patterns that I think would be useful to work on before going into interviews or if you are looking to have better chances at getting hired at popular companies.\n\nNeedless to say, these are my opinions alone and should be taken with a grain of salt. I might be a Sr. engineer but I still have much to learn and my experiences might be not a true reflection of the market.\n\n# Things To Consider:\n\n* This is more specific for boot camp grads. An interviewer will see the same \"Airflow pipeline with &lt;insert name of free API  here&gt; data\" project a million times with the same structure, tests, and GitHub readme. A lot of bootcamps (and online courses) tend to steer their students to reuse projects from previous years over and over, which leaves you at a huge disadvantage. If you think this is you, take the time to work on other things.  \n\n* I thought everyone knew this but obviously, some missed the memo. Data engineering is not exempt from TDD practices. If can't talk about testing during the interview, this is a massive red flag.  \n\n* Unwillingness to learn SWE concepts/topics will hurt you in the long run. It will not make it easy to interview at companies where Data Engineers are treated as specialized software engineers, or where you are expected to work with other engineers (Backend, DevOps, Architecture, Networking, etc).   \n\n* Focus on collaboration during technical interviews. Getting to the right answer is great, but a lot of companies will not consider you if you don't communicate with whoever is interviewing you. Being silent during the entire coding session makes it awkward and makes interviewers think you won't be a good fit in a collaborative team.   \n\n* For the love of god, come prepared with questions before an interview. And something else besides \"what is &lt;insert name of company&gt;, what do you do?\".   \n\n* If you are applying to a position but have no experience (internships, coops, freelancing, etc.) or just come straight out of an 18-week boot camp course. Please understand that you must put in 300% more effort in the interview and your portfolio than most candidates. I would love to hire folks like this, mentor them, and see them become great developers (and I have). Unfortunately, for 1 job application I publish, I get \\~170 applicants within a couple days sometimes. It is hard to say no to experience when jobs in the DE space are so popular these days. Maybe get an internship first or find a small startup that is willing to give you a shot.   \n\n* There are sooooo many companies out there misusing the term \"Data Engineering\" in job postings. Some are just glorified BI/DA positions with fancy titles or jobs where you don't code and end up becoming stuck in a career where you will have a hard time making moves to other engineering positions. In my opinion, data engineers shouldn't settle for such jobs. Ask questions to weed out these jobs during the interview process if you really want to become a proper DE (sorry if it sounds a bit harsh, I truly appreciate good BI developers and Data analysts)  \n\n* Finally, weekend projects and open-source contributions are always cool to see. I support those who want to keep their personal time completely separate from doing anything related to development. But you know, it's cool to see folks passionate about learning or contributing to our community. \n\nThese are just a couple things that jumped out at me during the past three months. I think paying attention to some of these points will make you a more well-rounded candidate and possibly give you better chances in the long run.", "author_fullname": "t2_ueuz4", "saved": false, "mod_reason_title": null, "gilded": 1, "clicked": false, "title": "A Few Pointers for Boot Camp Grads and Uni Students From a Sr. Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ydedn2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 33, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_2": 1}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666728515.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So for the last 3 months, my time has been almost solely dedicated to interviewing, onboarding, and training new people at my work. Throughout the whole process, I\u2019ve been able to identify a couple patterns that I think would be useful to work on before going into interviews or if you are looking to have better chances at getting hired at popular companies.&lt;/p&gt;\n\n&lt;p&gt;Needless to say, these are my opinions alone and should be taken with a grain of salt. I might be a Sr. engineer but I still have much to learn and my experiences might be not a true reflection of the market.&lt;/p&gt;\n\n&lt;h1&gt;Things To Consider:&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;This is more specific for boot camp grads. An interviewer will see the same &amp;quot;Airflow pipeline with &amp;lt;insert name of free API  here&amp;gt; data&amp;quot; project a million times with the same structure, tests, and GitHub readme. A lot of bootcamps (and online courses) tend to steer their students to reuse projects from previous years over and over, which leaves you at a huge disadvantage. If you think this is you, take the time to work on other things.  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I thought everyone knew this but obviously, some missed the memo. Data engineering is not exempt from TDD practices. If can&amp;#39;t talk about testing during the interview, this is a massive red flag.  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Unwillingness to learn SWE concepts/topics will hurt you in the long run. It will not make it easy to interview at companies where Data Engineers are treated as specialized software engineers, or where you are expected to work with other engineers (Backend, DevOps, Architecture, Networking, etc).   &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Focus on collaboration during technical interviews. Getting to the right answer is great, but a lot of companies will not consider you if you don&amp;#39;t communicate with whoever is interviewing you. Being silent during the entire coding session makes it awkward and makes interviewers think you won&amp;#39;t be a good fit in a collaborative team.   &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;For the love of god, come prepared with questions before an interview. And something else besides &amp;quot;what is &amp;lt;insert name of company&amp;gt;, what do you do?&amp;quot;.   &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;If you are applying to a position but have no experience (internships, coops, freelancing, etc.) or just come straight out of an 18-week boot camp course. Please understand that you must put in 300% more effort in the interview and your portfolio than most candidates. I would love to hire folks like this, mentor them, and see them become great developers (and I have). Unfortunately, for 1 job application I publish, I get ~170 applicants within a couple days sometimes. It is hard to say no to experience when jobs in the DE space are so popular these days. Maybe get an internship first or find a small startup that is willing to give you a shot.   &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;There are sooooo many companies out there misusing the term &amp;quot;Data Engineering&amp;quot; in job postings. Some are just glorified BI/DA positions with fancy titles or jobs where you don&amp;#39;t code and end up becoming stuck in a career where you will have a hard time making moves to other engineering positions. In my opinion, data engineers shouldn&amp;#39;t settle for such jobs. Ask questions to weed out these jobs during the interview process if you really want to become a proper DE (sorry if it sounds a bit harsh, I truly appreciate good BI developers and Data analysts)  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Finally, weekend projects and open-source contributions are always cool to see. I support those who want to keep their personal time completely separate from doing anything related to development. But you know, it&amp;#39;s cool to see folks passionate about learning or contributing to our community. &lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;These are just a couple things that jumped out at me during the past three months. I think paying attention to some of these points will make you a more well-rounded candidate and possibly give you better chances in the long run.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 500, "id": "gid_2", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 100, "icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png", "days_of_premium": 7, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Gives 100 Reddit Coins and a week of r/lounge access and ad-free browsing.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Gold", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ydedn2", "is_robot_indexable": true, "report_reasons": null, "author": "uncomfortablepanda", "discussion_type": null, "num_comments": 23, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ydedn2/a_few_pointers_for_boot_camp_grads_and_uni/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ydedn2/a_few_pointers_for_boot_camp_grads_and_uni/", "subreddit_subscribers": 77774, "created_utc": 1666728515.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do you experience the same thing? I work for an infra team in a data org, and it seems like the researchers don\u2019t understand basic engineering processes like:\n\n- how to use git\n\n- how to modularize their Python code\n\n- how to not perform full table scan\n\netc.", "author_fullname": "t2_4p45n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it just my feelings or many scientists/analysts don\u2019t know proper engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yd8goa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 35, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666713893.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you experience the same thing? I work for an infra team in a data org, and it seems like the researchers don\u2019t understand basic engineering processes like:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;how to use git&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;how to modularize their Python code&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;how to not perform full table scan&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yd8goa", "is_robot_indexable": true, "report_reasons": null, "author": "pinpinbo", "discussion_type": null, "num_comments": 38, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yd8goa/is_it_just_my_feelings_or_many_scientistsanalysts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yd8goa/is_it_just_my_feelings_or_many_scientistsanalysts/", "subreddit_subscribers": 77774, "created_utc": 1666713893.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Or your parents, spouce, sibling, or someone who is just not technical in general", "author_fullname": "t2_c2wij", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you explain SQL at a party?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycz8st", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666685190.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Or your parents, spouce, sibling, or someone who is just not technical in general&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ycz8st", "is_robot_indexable": true, "report_reasons": null, "author": "Wh0_am_1", "discussion_type": null, "num_comments": 80, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycz8st/how_would_you_explain_sql_at_a_party/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycz8st/how_would_you_explain_sql_at_a_party/", "subreddit_subscribers": 77774, "created_utc": 1666685190.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been working with dbt for the last couple of years and I would never go back to the way things were before, idempotent, source controlled code with  CI/CD really changed things. \n\nI was wondering, is there a technology out there that is doing the same thing for Reporting and Dashboarding? Currently I'm using Power BI, and it gets the job done, but afaik, there is no way to have source control, at least without any hacks.", "author_fullname": "t2_9d1jjuxh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "a dbt equivalent for visualization?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycxeq6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666677748.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working with dbt for the last couple of years and I would never go back to the way things were before, idempotent, source controlled code with  CI/CD really changed things. &lt;/p&gt;\n\n&lt;p&gt;I was wondering, is there a technology out there that is doing the same thing for Reporting and Dashboarding? Currently I&amp;#39;m using Power BI, and it gets the job done, but afaik, there is no way to have source control, at least without any hacks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ycxeq6", "is_robot_indexable": true, "report_reasons": null, "author": "boggle_thy_mind", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycxeq6/a_dbt_equivalent_for_visualization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycxeq6/a_dbt_equivalent_for_visualization/", "subreddit_subscribers": 77774, "created_utc": 1666677748.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been experimenting with moving parts of my data pipeline to Delta Live Tables and have found some limitations:\n\n1. No JVM support - this means no scala, no Py4J and most importantly, no spark-xml;\n2. No pivot support - this isn't a hard rule, but you can't pivot between live tables;\n3. Only 1 supported DLT storage location per pipeline;\n4. No XML support - I mentioned this in #1, but it deserves it's own callout.\n\nI'm wondering who's using this tool considering these limitations. I can see the usefulness for silver/gold, but I see plenty of guidance around using autoloader with DLT, but I struggle to see how that would work if you have xml sources or sources that need to be pivoted.\n\nI would like to hear if you have evaluated DLT and if you're using it, your use case, especially if you're using it with autoloader!", "author_fullname": "t2_41da5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are You Using Databricks Delta Live Tables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yd59hx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666705643.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been experimenting with moving parts of my data pipeline to Delta Live Tables and have found some limitations:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;No JVM support - this means no scala, no Py4J and most importantly, no spark-xml;&lt;/li&gt;\n&lt;li&gt;No pivot support - this isn&amp;#39;t a hard rule, but you can&amp;#39;t pivot between live tables;&lt;/li&gt;\n&lt;li&gt;Only 1 supported DLT storage location per pipeline;&lt;/li&gt;\n&lt;li&gt;No XML support - I mentioned this in #1, but it deserves it&amp;#39;s own callout.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;m wondering who&amp;#39;s using this tool considering these limitations. I can see the usefulness for silver/gold, but I see plenty of guidance around using autoloader with DLT, but I struggle to see how that would work if you have xml sources or sources that need to be pivoted.&lt;/p&gt;\n\n&lt;p&gt;I would like to hear if you have evaluated DLT and if you&amp;#39;re using it, your use case, especially if you&amp;#39;re using it with autoloader!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yd59hx", "is_robot_indexable": true, "report_reasons": null, "author": "dylanberry", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yd59hx/are_you_using_databricks_delta_live_tables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yd59hx/are_you_using_databricks_delta_live_tables/", "subreddit_subscribers": 77774, "created_utc": 1666705643.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the subject says , I'm going to focus more on the SQL from scratch as i see a good future in the SQL . So I'm going to strengthen my skill in SQL in flavour of data engineering . Can someone recommend a good course paid or free to achieve my targets by Dec 2022.\n\ndaily study time is approx. 1.5 hours/day.", "author_fullname": "t2_3sqs3uub", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best SQL course to Solve Hacker Rank atleast Intermediate levels", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycwwwh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666675893.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the subject says , I&amp;#39;m going to focus more on the SQL from scratch as i see a good future in the SQL . So I&amp;#39;m going to strengthen my skill in SQL in flavour of data engineering . Can someone recommend a good course paid or free to achieve my targets by Dec 2022.&lt;/p&gt;\n\n&lt;p&gt;daily study time is approx. 1.5 hours/day.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ycwwwh", "is_robot_indexable": true, "report_reasons": null, "author": "priyasweety1", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycwwwh/best_sql_course_to_solve_hacker_rank_atleast/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycwwwh/best_sql_course_to_solve_hacker_rank_atleast/", "subreddit_subscribers": 77774, "created_utc": 1666675893.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been using GCP for quite some time and I play the role of a senior data engineer in a consulting form. Now I have 2 roles to choose from where I am very confused:   \n\n\n1.Principal Data Engineer (GCP) at one of the country's leading insurance firms. They are migrating from on prem to GCP and would like me to be their SME for the engineering, road map and DBT practices. The role is quite lucrative for me as I want to grow more into the Data Architecting Space, and I will be working closely with a senior data architect here  \n\n\n2. Chief Data Engineer at a Startup Fintech (domain: investment portfolio management) - 8bn worth of assets locked. They use AZURE &amp; SNOWFLAKE heavily and they don't have any data engineer in the team. Most of the pipelines are by the data scientist themselves. I will be in charge to put down framework and bring change/processes. The remuneration is really good to ignore the offer totally.  \n\n\nI am very confused at the moment to which one to proceed with!! As a data engineer should we be wary about the Cloud platform we work on, or should we be cloud agnostic?  I can hear things like \"AWS is the past, Azure is the present, GCP is the future\"! I have little exposure to Azure and did not like the experience. Azure seems to be very much \"DATABRICK\"-ish while they try to bring in new features at par with other cloud. On first glance ADF seems to be just rebranding SSIS with some new features.   \n\n\nWhile GCP is not the big elephant, it provides a very good ecosystem for data &amp; analytics. Now they have introduced, big lake, iceberg support, dataplex etc. Azure has no equivalent counterpart and rather they seem to borrow more from other service providers (databricks).  Even Kubernetes, Apache beam has their history originating from Google.  Also, GCP is really getting smarter &amp; creative as an ecosystem for Data and Analytics. Big query is their MVP and is really playing head-to-head with Snowflake. People are moving out of Spark/Hadoop framework and going back to such cloud-based SQL providers. Synapse is very new and i don't know how much people have embraced Synapse.\n\nThinking about future I felt enterprises would love to go ahead with GCP rather than Azure for Data Engineering/Analytics platform (unless they have some Licensing dependencies of legacy systems). I felt it is easier to engineer on GCP compared to Azure. \n\nSo, trying to validate if my understanding is correct or I am totally wrong about this. Some discussions/clarifications on this would help me to take the next jump in my career.", "author_fullname": "t2_781vl0qw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "As a data engineer should we be wary about the Cloud platform we work on, or should we be cloud agnostic? #gcp #azure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ydmgv5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666750891.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been using GCP for quite some time and I play the role of a senior data engineer in a consulting form. Now I have 2 roles to choose from where I am very confused:   &lt;/p&gt;\n\n&lt;p&gt;1.Principal Data Engineer (GCP) at one of the country&amp;#39;s leading insurance firms. They are migrating from on prem to GCP and would like me to be their SME for the engineering, road map and DBT practices. The role is quite lucrative for me as I want to grow more into the Data Architecting Space, and I will be working closely with a senior data architect here  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Chief Data Engineer at a Startup Fintech (domain: investment portfolio management) - 8bn worth of assets locked. They use AZURE &amp;amp; SNOWFLAKE heavily and they don&amp;#39;t have any data engineer in the team. Most of the pipelines are by the data scientist themselves. I will be in charge to put down framework and bring change/processes. The remuneration is really good to ignore the offer totally.&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I am very confused at the moment to which one to proceed with!! As a data engineer should we be wary about the Cloud platform we work on, or should we be cloud agnostic?  I can hear things like &amp;quot;AWS is the past, Azure is the present, GCP is the future&amp;quot;! I have little exposure to Azure and did not like the experience. Azure seems to be very much &amp;quot;DATABRICK&amp;quot;-ish while they try to bring in new features at par with other cloud. On first glance ADF seems to be just rebranding SSIS with some new features.   &lt;/p&gt;\n\n&lt;p&gt;While GCP is not the big elephant, it provides a very good ecosystem for data &amp;amp; analytics. Now they have introduced, big lake, iceberg support, dataplex etc. Azure has no equivalent counterpart and rather they seem to borrow more from other service providers (databricks).  Even Kubernetes, Apache beam has their history originating from Google.  Also, GCP is really getting smarter &amp;amp; creative as an ecosystem for Data and Analytics. Big query is their MVP and is really playing head-to-head with Snowflake. People are moving out of Spark/Hadoop framework and going back to such cloud-based SQL providers. Synapse is very new and i don&amp;#39;t know how much people have embraced Synapse.&lt;/p&gt;\n\n&lt;p&gt;Thinking about future I felt enterprises would love to go ahead with GCP rather than Azure for Data Engineering/Analytics platform (unless they have some Licensing dependencies of legacy systems). I felt it is easier to engineer on GCP compared to Azure. &lt;/p&gt;\n\n&lt;p&gt;So, trying to validate if my understanding is correct or I am totally wrong about this. Some discussions/clarifications on this would help me to take the next jump in my career.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ydmgv5", "is_robot_indexable": true, "report_reasons": null, "author": "SnooDingos3356", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ydmgv5/as_a_data_engineer_should_we_be_wary_about_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ydmgv5/as_a_data_engineer_should_we_be_wary_about_the/", "subreddit_subscribers": 77774, "created_utc": 1666750891.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I taught myself SQL on my Linux machine, beginner stuff. I'm taking Python at Data Camp...\n\nAm I likely to get a job in DE if my BS and MS are in speech therapy? \n\nAny advice to up my chances? Phrasing in my cover letter and resume? Please and thanks", "author_fullname": "t2_s05lz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE job outlooks without CS degree? (I have other degrees)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yd8zm9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666715160.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I taught myself SQL on my Linux machine, beginner stuff. I&amp;#39;m taking Python at Data Camp...&lt;/p&gt;\n\n&lt;p&gt;Am I likely to get a job in DE if my BS and MS are in speech therapy? &lt;/p&gt;\n\n&lt;p&gt;Any advice to up my chances? Phrasing in my cover letter and resume? Please and thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yd8zm9", "is_robot_indexable": true, "report_reasons": null, "author": "Easygoing_E", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yd8zm9/de_job_outlooks_without_cs_degree_i_have_other/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yd8zm9/de_job_outlooks_without_cs_degree_i_have_other/", "subreddit_subscribers": 77774, "created_utc": 1666715160.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_tvcne", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ERD-as-code", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ydjipg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1666742175.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "docs.tryeraser.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://docs.tryeraser.com/docs/examples-1", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ydjipg", "is_robot_indexable": true, "report_reasons": null, "author": "Xtcars", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ydjipg/erdascode/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://docs.tryeraser.com/docs/examples-1", "subreddit_subscribers": 77774, "created_utc": 1666742175.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work for a software company doing data migrations mostly using T-SQL with occasionally Python scripts to facilitate something. Been doing this work for several years but I don\u2019t have a lot of the breadth I really need to be considered a data engineer, I don\u2019t think. I have a lot of flexibility in my role (as long as I can get the work done) and we may be migrating to Azure at some point I\u2019m the future, so I am thinking of doing a few Azure Crete including the DE one. Along the way I\u2019d like to be able to have my own Azure environment to build pipelines, intent data, etc.\n\nI know the cost can vary, but I\u2019m curious how much I\u2019d be realistically looking to spend per month. Just a ballpark will do. I think having this sort of environment will be necessary in order to really start progressing my skill set, but as I\u2019ll be paying out of pocket I want to keep it as economic as possible.", "author_fullname": "t2_ay2nitaj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much would I realistically need to spend on Azure to get some good DE experience?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ydgiem", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666733881.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work for a software company doing data migrations mostly using T-SQL with occasionally Python scripts to facilitate something. Been doing this work for several years but I don\u2019t have a lot of the breadth I really need to be considered a data engineer, I don\u2019t think. I have a lot of flexibility in my role (as long as I can get the work done) and we may be migrating to Azure at some point I\u2019m the future, so I am thinking of doing a few Azure Crete including the DE one. Along the way I\u2019d like to be able to have my own Azure environment to build pipelines, intent data, etc.&lt;/p&gt;\n\n&lt;p&gt;I know the cost can vary, but I\u2019m curious how much I\u2019d be realistically looking to spend per month. Just a ballpark will do. I think having this sort of environment will be necessary in order to really start progressing my skill set, but as I\u2019ll be paying out of pocket I want to keep it as economic as possible.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ydgiem", "is_robot_indexable": true, "report_reasons": null, "author": "theloons", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ydgiem/how_much_would_i_realistically_need_to_spend_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ydgiem/how_much_would_i_realistically_need_to_spend_on/", "subreddit_subscribers": 77774, "created_utc": 1666733881.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all! After a technical assessment, I had a technical interview with a senior data engineer. He asked me a couple of questions and it was tough for me, let me share the questions that I can remember.\n\n&gt;\\-What is the difference between renting a virtual machine and installing a mysql server and using bigquery directly? why do we use bigquery?  \n&gt;  \n&gt;\\-What is HDFS? (then what is hadoop)  \n&gt;  \n&gt;\\-What is Kafka? Why should we use Kafka instead of writing code and transferring data elsewhere?  \n&gt;  \n&gt;\\-(Suppose it is more cost-effective). What difference does it make for us if I merge the tables under a single table instead of separating them with join functions in relational databases?  \n&gt;  \n&gt;\\-What does \"this service is serverless\" mean?\n\nThis was not all of them but that's all I can remember. So I wonder,(also I'm not a ceng student, I'm studying ba but learning deng and data) isn't it too unmerciful for a 20 yo intern candidate? He also asked different detailed things but I already forgot. So guys that's all and I can add more detail below if I can remember. Write your suggestions and we can chat from dm if you want to say special. Thank you!", "author_fullname": "t2_366ahhed", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Questions that asked to me in DEng intern program technical interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ydfedx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666731062.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all! After a technical assessment, I had a technical interview with a senior data engineer. He asked me a couple of questions and it was tough for me, let me share the questions that I can remember.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;-What is the difference between renting a virtual machine and installing a mysql server and using bigquery directly? why do we use bigquery?  &lt;/p&gt;\n\n&lt;p&gt;-What is HDFS? (then what is hadoop)  &lt;/p&gt;\n\n&lt;p&gt;-What is Kafka? Why should we use Kafka instead of writing code and transferring data elsewhere?  &lt;/p&gt;\n\n&lt;p&gt;-(Suppose it is more cost-effective). What difference does it make for us if I merge the tables under a single table instead of separating them with join functions in relational databases?  &lt;/p&gt;\n\n&lt;p&gt;-What does &amp;quot;this service is serverless&amp;quot; mean?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;This was not all of them but that&amp;#39;s all I can remember. So I wonder,(also I&amp;#39;m not a ceng student, I&amp;#39;m studying ba but learning deng and data) isn&amp;#39;t it too unmerciful for a 20 yo intern candidate? He also asked different detailed things but I already forgot. So guys that&amp;#39;s all and I can add more detail below if I can remember. Write your suggestions and we can chat from dm if you want to say special. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "ydfedx", "is_robot_indexable": true, "report_reasons": null, "author": "erngkky", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ydfedx/questions_that_asked_to_me_in_deng_intern_program/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ydfedx/questions_that_asked_to_me_in_deng_intern_program/", "subreddit_subscribers": 77774, "created_utc": 1666731062.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This feels like SUCH a newb question, but I don't know where else to look/ask (&amp; I've tried a few places already).\n\nI'm using Hevo to load the Google Ads API data and I've chosen Standard Reports.  The \"gender view\" sounds interesting to start - lots of data to check out .... but where is gender? How can I get the gender value with the data?  \n\n\nIn my mind the gender view would show .... male vs female (or maybe more) for all the metrics, but I can't see the gender field at all.", "author_fullname": "t2_353ucr1h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hevo / Google Ads - Gender view", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ydmcnp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666750540.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This feels like SUCH a newb question, but I don&amp;#39;t know where else to look/ask (&amp;amp; I&amp;#39;ve tried a few places already).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using Hevo to load the Google Ads API data and I&amp;#39;ve chosen Standard Reports.  The &amp;quot;gender view&amp;quot; sounds interesting to start - lots of data to check out .... but where is gender? How can I get the gender value with the data?  &lt;/p&gt;\n\n&lt;p&gt;In my mind the gender view would show .... male vs female (or maybe more) for all the metrics, but I can&amp;#39;t see the gender field at all.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ydmcnp", "is_robot_indexable": true, "report_reasons": null, "author": "cmcau", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ydmcnp/hevo_google_ads_gender_view/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ydmcnp/hevo_google_ads_gender_view/", "subreddit_subscribers": 77774, "created_utc": 1666750540.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I'm a Junior DE in a consulty firm and rencently I was assigned 3 projects that are \"big\" for me (first time working with Azure); a POC (Proof of Concept) in Azure Synapse, migrate databases and SSIS packages to newest MSQL and finally create a DWH in MSQL on premises (with SSIS).\n\nThis made me wondering, it is a high work load? or it is normal for a DE work in 3 projects at same time. How much projects normally have a DE in a consulty firm?? And I suppose that differ between levels of expertise (junior, senior, etc) or for all is equals??", "author_fullname": "t2_3va9gp07", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Work Load of Data Engineers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ydltw4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666748992.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m a Junior DE in a consulty firm and rencently I was assigned 3 projects that are &amp;quot;big&amp;quot; for me (first time working with Azure); a POC (Proof of Concept) in Azure Synapse, migrate databases and SSIS packages to newest MSQL and finally create a DWH in MSQL on premises (with SSIS).&lt;/p&gt;\n\n&lt;p&gt;This made me wondering, it is a high work load? or it is normal for a DE work in 3 projects at same time. How much projects normally have a DE in a consulty firm?? And I suppose that differ between levels of expertise (junior, senior, etc) or for all is equals??&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ydltw4", "is_robot_indexable": true, "report_reasons": null, "author": "Javosch", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ydltw4/work_load_of_data_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ydltw4/work_load_of_data_engineers/", "subreddit_subscribers": 77774, "created_utc": 1666748992.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_dfcot0zg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Had some cool discussions yesterday about Window Functions. Anyone read this book it's updated for 2019. I have his two other T-SQL books so I'm gonna go grab this too.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_yd5nsb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/1NNQk60TYzGmqNHCD0XVV4kNaWqVOGddwH_pWLet_Nc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666706659.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/asn99e8l20w91.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/asn99e8l20w91.png?auto=webp&amp;s=37cbc375dd271c080dbe84af2157546b026ccf8d", "width": 1080, "height": 1502}, "resolutions": [{"url": "https://preview.redd.it/asn99e8l20w91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4c3e3c14ef1e53830822afcab9728ff12e66b8b0", "width": 108, "height": 150}, {"url": "https://preview.redd.it/asn99e8l20w91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6425dfdb6eba99d500975dedb189d736418f99f7", "width": 216, "height": 300}, {"url": "https://preview.redd.it/asn99e8l20w91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7b9d5f57395057030ebd571461836cb5f362f80b", "width": 320, "height": 445}, {"url": "https://preview.redd.it/asn99e8l20w91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=fcad977270500f65adc2e5adc3d457a427535779", "width": 640, "height": 890}, {"url": "https://preview.redd.it/asn99e8l20w91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=c62687b9d1e2596289af98c509f4e67233ea5c18", "width": 960, "height": 1335}, {"url": "https://preview.redd.it/asn99e8l20w91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ab375f1d7f88f41d1cfcec183695bc06147e5aec", "width": 1080, "height": 1502}], "variants": {}, "id": "OWZwHhMLAX1bWwIlVrYXh0B2oj_7n9CnnXmKJDlnpd8"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yd5nsb", "is_robot_indexable": true, "report_reasons": null, "author": "DrRedmondNYC", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yd5nsb/had_some_cool_discussions_yesterday_about_window/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/asn99e8l20w91.png", "subreddit_subscribers": 77774, "created_utc": 1666706659.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm an analytics engineer and I've been asked to bring some high level metrics of our clients into Salesforce to attach to the accounts (reverse ETL / data activation). This might be total revenue to date, last 6 months etc.\n\nWhen I asked what this would be used for or what actions the sales team would do off the back of this, they said that sales could notify operations of lower than expected revenue.\n\nTo me, these metrics did not seem relevant to the sales team's operations. It feels as though this could lead to more metric requests in Salesforce when we already have a self serve bi platform the whole company can access.\n\nAre my concerns of Salesforce becoming a BI Platform legitimate or do I just need to get the task done?\n\nI do see the benefit of some metrics in Salesforce but I'm thinking along the lines around indicators of Churn, score cards etc.", "author_fullname": "t2_2x2iij2a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Salesforce as a BI Platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ydf9su", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666730734.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m an analytics engineer and I&amp;#39;ve been asked to bring some high level metrics of our clients into Salesforce to attach to the accounts (reverse ETL / data activation). This might be total revenue to date, last 6 months etc.&lt;/p&gt;\n\n&lt;p&gt;When I asked what this would be used for or what actions the sales team would do off the back of this, they said that sales could notify operations of lower than expected revenue.&lt;/p&gt;\n\n&lt;p&gt;To me, these metrics did not seem relevant to the sales team&amp;#39;s operations. It feels as though this could lead to more metric requests in Salesforce when we already have a self serve bi platform the whole company can access.&lt;/p&gt;\n\n&lt;p&gt;Are my concerns of Salesforce becoming a BI Platform legitimate or do I just need to get the task done?&lt;/p&gt;\n\n&lt;p&gt;I do see the benefit of some metrics in Salesforce but I&amp;#39;m thinking along the lines around indicators of Churn, score cards etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ydf9su", "is_robot_indexable": true, "report_reasons": null, "author": "ChickenChowMean", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ydf9su/salesforce_as_a_bi_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ydf9su/salesforce_as_a_bi_platform/", "subreddit_subscribers": 77774, "created_utc": 1666730734.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A two-day virtual event packed with demos, AMAs, and hands-on labs created by builders, for builders. Immerse yourself in improving your apps, data pipelines, machine learning workflows, and much more. Join here - [https://www.snowflake.com/build/?utm\\_source=dataops.live&amp;utm\\_medium=partner&amp;utm\\_campaign=na-us-en-&amp;utm\\_content=-evv-build-virtual-](https://www.snowflake.com/build/?utm_source=dataops.live&amp;utm_medium=partner&amp;utm_campaign=na-us-en-&amp;utm_content=-evv-build-virtual-)\n\n[Snowflake Build - DataOps.live](https://preview.redd.it/6m4yb5wv50w91.png?width=1200&amp;format=png&amp;auto=webp&amp;s=8c74b932a764b6b86b4f4b83c959240cb29562ca)", "author_fullname": "t2_12li6zgs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake BUILD '22 - The Data Cloud Dev Virtual Summit (NOV 15-16)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "media_metadata": {"6m4yb5wv50w91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 56, "x": 108, "u": "https://preview.redd.it/6m4yb5wv50w91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a0d5524019ff358784c4cb1f4ea59106dc489f48"}, {"y": 113, "x": 216, "u": "https://preview.redd.it/6m4yb5wv50w91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ba5cf3ba73b6d773ca774af56c88ffa5346a5f70"}, {"y": 167, "x": 320, "u": "https://preview.redd.it/6m4yb5wv50w91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=22c33b96e783f6e96d3013f6bfafb7a605dfac3c"}, {"y": 334, "x": 640, "u": "https://preview.redd.it/6m4yb5wv50w91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=38a42e8c9dc9f43e5502c030939e0cd8d4ef64e5"}, {"y": 502, "x": 960, "u": "https://preview.redd.it/6m4yb5wv50w91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=47b306bd0d19f5da0ec24344212e2d5ad7a24da8"}, {"y": 565, "x": 1080, "u": "https://preview.redd.it/6m4yb5wv50w91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9b405677af2146b6f9eb37d624987ac4b062f900"}], "s": {"y": 628, "x": 1200, "u": "https://preview.redd.it/6m4yb5wv50w91.png?width=1200&amp;format=png&amp;auto=webp&amp;s=8c74b932a764b6b86b4f4b83c959240cb29562ca"}, "id": "6m4yb5wv50w91"}}, "name": "t3_yddpbm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/2Ze2TDkBmRn-wnSD6yb_CEI7u-Y4m7KOqOacZRkVfao.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666726832.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A two-day virtual event packed with demos, AMAs, and hands-on labs created by builders, for builders. Immerse yourself in improving your apps, data pipelines, machine learning workflows, and much more. Join here - &lt;a href=\"https://www.snowflake.com/build/?utm_source=dataops.live&amp;amp;utm_medium=partner&amp;amp;utm_campaign=na-us-en-&amp;amp;utm_content=-evv-build-virtual-\"&gt;https://www.snowflake.com/build/?utm_source=dataops.live&amp;amp;utm_medium=partner&amp;amp;utm_campaign=na-us-en-&amp;amp;utm_content=-evv-build-virtual-&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/6m4yb5wv50w91.png?width=1200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8c74b932a764b6b86b4f4b83c959240cb29562ca\"&gt;Snowflake Build - DataOps.live&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yddpbm", "is_robot_indexable": true, "report_reasons": null, "author": "Dkreig", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yddpbm/snowflake_build_22_the_data_cloud_dev_virtual/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yddpbm/snowflake_build_22_the_data_cloud_dev_virtual/", "subreddit_subscribers": 77774, "created_utc": 1666726832.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How can I save the output of a variable (one specific value i.e. sql query used to get the latest BatchID) to use and reference in another variable, variable B?\n\nCurrently, I am trying to do just that - reference variable A in variable B - I just want the output of variable A (the latest BatchID) to use in the WHERE clause of variable B.\n\nHowever, when I evaluate the expression - it's showing the whole query used to obtain the output of variable A as well as variable B (so it looks like two queries, when in reality, I just want the value of variable A to reference in variable B).\n\nDoes that make sense? Does this sound right? Or what am I doing wrong?", "author_fullname": "t2_gsch4oaq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SSIS Variables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yddind", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666726360.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How can I save the output of a variable (one specific value i.e. sql query used to get the latest BatchID) to use and reference in another variable, variable B?&lt;/p&gt;\n\n&lt;p&gt;Currently, I am trying to do just that - reference variable A in variable B - I just want the output of variable A (the latest BatchID) to use in the WHERE clause of variable B.&lt;/p&gt;\n\n&lt;p&gt;However, when I evaluate the expression - it&amp;#39;s showing the whole query used to obtain the output of variable A as well as variable B (so it looks like two queries, when in reality, I just want the value of variable A to reference in variable B).&lt;/p&gt;\n\n&lt;p&gt;Does that make sense? Does this sound right? Or what am I doing wrong?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yddind", "is_robot_indexable": true, "report_reasons": null, "author": "xxEiGhTyxx", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yddind/ssis_variables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yddind/ssis_variables/", "subreddit_subscribers": 77774, "created_utc": 1666726360.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "With all the discussion of OBT/Wide Tables, I having a devil of a time finding **actual examples**.  I thought I might be crazy for asking, but [another post](https://www.reddit.com/r/dataengineering/comments/oy8b2x/does_obt_one_big_table_really_mean_one_big_table/) convinced me I'm not.\n\n**Can a few of you please show an example of wide tables that actually gets used in production?**\n\nI have 15GB of data in Bigquery (not that much).  It doesn't change often (annually).  But, the data is not typical business transactional data, but education data (e.g. enrollment, student performance, staffing, finances).  I need to ask questions across these domains and am finding NO examples of how we might do it with wide tables in practice.\n\nI have an example galaxy schema set up for an intermediate step, but it seems like lots of work to ultimately turn it into wide tables for analysis anyway.", "author_fullname": "t2_4d8caxd5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need example of OBT or Wide Tables for data warehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ydc5cr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666722900.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With all the discussion of OBT/Wide Tables, I having a devil of a time finding &lt;strong&gt;actual examples&lt;/strong&gt;.  I thought I might be crazy for asking, but &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/oy8b2x/does_obt_one_big_table_really_mean_one_big_table/\"&gt;another post&lt;/a&gt; convinced me I&amp;#39;m not.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Can a few of you please show an example of wide tables that actually gets used in production?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I have 15GB of data in Bigquery (not that much).  It doesn&amp;#39;t change often (annually).  But, the data is not typical business transactional data, but education data (e.g. enrollment, student performance, staffing, finances).  I need to ask questions across these domains and am finding NO examples of how we might do it with wide tables in practice.&lt;/p&gt;\n\n&lt;p&gt;I have an example galaxy schema set up for an intermediate step, but it seems like lots of work to ultimately turn it into wide tables for analysis anyway.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ydc5cr", "is_robot_indexable": true, "report_reasons": null, "author": "realistdreamer69", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ydc5cr/need_example_of_obt_or_wide_tables_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ydc5cr/need_example_of_obt_or_wide_tables_for_data/", "subreddit_subscribers": 77774, "created_utc": 1666722900.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi fellow members. I hope you have a great start to the day.  \n\n\nI am beginning my Data Engineering journey and I wanted to let you guys know that this subreddit has been of great help to me.  \n\n\nI wanted your opinion as there are experienced and newbies in this field regarding a project that I have started for self-learning. Also, let me know if it is good enough for building my portfolio.  \n\n\nSo here it goes.  \n\n\nI have elevated twitter access. I am fetching tweets using Tweepy.   \nI fetch 10 tweets and I save the last tweet's ID in a text file. I have created a scheduler that gets the last tweet's ID from the text file and fetches a batch of the next 10 tweets. Moving forward, I parse the JSON response and filter out a few columns.   \n\n\n(Below is the part that I am about to build)  \nI would use a Postgres DB (docker image) for Data Warehousing. Furthermore, I am thinking of using Apache Airflow for data pipeline management.   \n\n\nI would love your opinions in guiding me toward a better understanding of the pathway I am following.", "author_fullname": "t2_ecv06uk8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this a good approach for starters?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ydajxs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666718928.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi fellow members. I hope you have a great start to the day.  &lt;/p&gt;\n\n&lt;p&gt;I am beginning my Data Engineering journey and I wanted to let you guys know that this subreddit has been of great help to me.  &lt;/p&gt;\n\n&lt;p&gt;I wanted your opinion as there are experienced and newbies in this field regarding a project that I have started for self-learning. Also, let me know if it is good enough for building my portfolio.  &lt;/p&gt;\n\n&lt;p&gt;So here it goes.  &lt;/p&gt;\n\n&lt;p&gt;I have elevated twitter access. I am fetching tweets using Tweepy.&lt;br/&gt;\nI fetch 10 tweets and I save the last tweet&amp;#39;s ID in a text file. I have created a scheduler that gets the last tweet&amp;#39;s ID from the text file and fetches a batch of the next 10 tweets. Moving forward, I parse the JSON response and filter out a few columns.   &lt;/p&gt;\n\n&lt;p&gt;(Below is the part that I am about to build)&lt;br/&gt;\nI would use a Postgres DB (docker image) for Data Warehousing. Furthermore, I am thinking of using Apache Airflow for data pipeline management.   &lt;/p&gt;\n\n&lt;p&gt;I would love your opinions in guiding me toward a better understanding of the pathway I am following.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ydajxs", "is_robot_indexable": true, "report_reasons": null, "author": "ShahSawari", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ydajxs/is_this_a_good_approach_for_starters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ydajxs/is_this_a_good_approach_for_starters/", "subreddit_subscribers": 77774, "created_utc": 1666718928.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys!\n\nSo i started to work on a personal project with the purpose of learning as many as possible about data engineering.\n\nThe goal is to have as less costs as possible, cause I wont make any $$ out of it, I just want to learn.\n\nTill now: \nI started on render.com (not sure if was the right option) by creating a postgreSQL DB.\n\nI've  wrote a python script that retrieves data from an API source and then stores the data in the DB.\n\nThen some data retrieved from the 1st API source, I am using it as input to a 2nd API source, from which I retrieve data and then again I am storing in the DB.\n\nNow I would like to ask for advice regarding how I should proceed and if is possible to keep going on render.com or if I should shift.\n\nNow I want to:\n\n- run that script daily and append new data to the postgreSQL tables (I have experience with airflow DAGs and tasks but not sure how i can integrate it)\n\n- i guess i need a repo and a VM instance that will run that (but again not sure about the steps in here)\n\n- I want to build also an API that will access the data (I would know how to do that with FastAPI, but not sure how i can make it in the same Repo with the whole thing)\n\n\nBasically I have parts of knowledge from these processes,but I've eve understood how I can have the together with a production &amp; staging environment, how I am actually hosting it, how thea real combination of everything happens.\n\nIf you have any sources I can learn from or advice to give, I would be really thankful.\n\nThank you for your time!", "author_fullname": "t2_b4ypm8ew", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Next steps for an 'app'", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ydab3i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666718343.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys!&lt;/p&gt;\n\n&lt;p&gt;So i started to work on a personal project with the purpose of learning as many as possible about data engineering.&lt;/p&gt;\n\n&lt;p&gt;The goal is to have as less costs as possible, cause I wont make any $$ out of it, I just want to learn.&lt;/p&gt;\n\n&lt;p&gt;Till now: \nI started on render.com (not sure if was the right option) by creating a postgreSQL DB.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve  wrote a python script that retrieves data from an API source and then stores the data in the DB.&lt;/p&gt;\n\n&lt;p&gt;Then some data retrieved from the 1st API source, I am using it as input to a 2nd API source, from which I retrieve data and then again I am storing in the DB.&lt;/p&gt;\n\n&lt;p&gt;Now I would like to ask for advice regarding how I should proceed and if is possible to keep going on render.com or if I should shift.&lt;/p&gt;\n\n&lt;p&gt;Now I want to:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;run that script daily and append new data to the postgreSQL tables (I have experience with airflow DAGs and tasks but not sure how i can integrate it)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;i guess i need a repo and a VM instance that will run that (but again not sure about the steps in here)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I want to build also an API that will access the data (I would know how to do that with FastAPI, but not sure how i can make it in the same Repo with the whole thing)&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Basically I have parts of knowledge from these processes,but I&amp;#39;ve eve understood how I can have the together with a production &amp;amp; staging environment, how I am actually hosting it, how thea real combination of everything happens.&lt;/p&gt;\n\n&lt;p&gt;If you have any sources I can learn from or advice to give, I would be really thankful.&lt;/p&gt;\n\n&lt;p&gt;Thank you for your time!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ydab3i", "is_robot_indexable": true, "report_reasons": null, "author": "Koxinfster", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ydab3i/next_steps_for_an_app/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ydab3i/next_steps_for_an_app/", "subreddit_subscribers": 77774, "created_utc": 1666718343.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_40ihn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Build a poor man\u2019s data lake from scratch with DuckDB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_yd8ek2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/j19A4gjER4Fhwr0vY1pNx396M63K__MPvGuoQzeyk80.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666713745.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dagster.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://dagster.io/blog/duckdb-data-lake", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9RGWtZ4-Z8omJHxqjou-b1AKtNA-JVZnZc0ds4kNLgE.jpg?auto=webp&amp;s=2e6c2f96643c1dcfc7cc7764de763ca0dd95b1f2", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/9RGWtZ4-Z8omJHxqjou-b1AKtNA-JVZnZc0ds4kNLgE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3033e0f7e8f632ae74930d6dadb1239e520aa9d0", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/9RGWtZ4-Z8omJHxqjou-b1AKtNA-JVZnZc0ds4kNLgE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fde9f0a8a50a6af8a5bdaeaaced07a68b713ab4e", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/9RGWtZ4-Z8omJHxqjou-b1AKtNA-JVZnZc0ds4kNLgE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fe1fc403c19dced88afe11bb301296d719c46aaf", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/9RGWtZ4-Z8omJHxqjou-b1AKtNA-JVZnZc0ds4kNLgE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3e3a43c984c9a9e94d1749cd3f658ae173bc369c", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/9RGWtZ4-Z8omJHxqjou-b1AKtNA-JVZnZc0ds4kNLgE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c96c60ee4bf81a32138efdb5dbec178cf4cf191f", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/9RGWtZ4-Z8omJHxqjou-b1AKtNA-JVZnZc0ds4kNLgE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=04be9cd82ad6ddea129eddc97844a60ae37d26b0", "width": 1080, "height": 607}], "variants": {}, "id": "8jnj5t96vjt3Yjp7iltc9A9N4DlNne1k-U36rzPAqto"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yd8ek2", "is_robot_indexable": true, "report_reasons": null, "author": "floydophone", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yd8ek2/build_a_poor_mans_data_lake_from_scratch_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dagster.io/blog/duckdb-data-lake", "subreddit_subscribers": 77774, "created_utc": 1666713745.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone built an address validation/standardization pipeline or have any advice for my thoughts here? The tools our pipelines are using are FiveTran, Databricks and DBT. \n\nMy basic idea for this pipeline is hit either anyone of the various APIs, SmartyStreets, Melissa, Loqate etc using their respective python SDKs, nightly in a batch process as apart of the cleansing/cleaning process of our loads. \n\nWhen the data is cleaned, we will add a new column for the validated/standardized address. \n\n1. Ingest new records into our raw tables daily (for now twice daily, in the future more frequently)\n2. Create a dataframe from the raw table, but filter on where the standardized address column is null\n3. Create a dictionary with the primary key and the associated address\n4. Send the info to the API in batches\n5. Join the cleaned data back to the dataframe\n6. Join the dataframe back to the table, adding the new cleaned address column\n\nAm I thinking about this correctly? My biggest fear is how long this might take to hit the API several times. Is this something that could be overcome with spark and parallelizing the API call (I haven't looked into this yet)?", "author_fullname": "t2_19klta65", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Address Validation Pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yd58yu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666705604.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone built an address validation/standardization pipeline or have any advice for my thoughts here? The tools our pipelines are using are FiveTran, Databricks and DBT. &lt;/p&gt;\n\n&lt;p&gt;My basic idea for this pipeline is hit either anyone of the various APIs, SmartyStreets, Melissa, Loqate etc using their respective python SDKs, nightly in a batch process as apart of the cleansing/cleaning process of our loads. &lt;/p&gt;\n\n&lt;p&gt;When the data is cleaned, we will add a new column for the validated/standardized address. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Ingest new records into our raw tables daily (for now twice daily, in the future more frequently)&lt;/li&gt;\n&lt;li&gt;Create a dataframe from the raw table, but filter on where the standardized address column is null&lt;/li&gt;\n&lt;li&gt;Create a dictionary with the primary key and the associated address&lt;/li&gt;\n&lt;li&gt;Send the info to the API in batches&lt;/li&gt;\n&lt;li&gt;Join the cleaned data back to the dataframe&lt;/li&gt;\n&lt;li&gt;Join the dataframe back to the table, adding the new cleaned address column&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Am I thinking about this correctly? My biggest fear is how long this might take to hit the API several times. Is this something that could be overcome with spark and parallelizing the API call (I haven&amp;#39;t looked into this yet)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yd58yu", "is_robot_indexable": true, "report_reasons": null, "author": "DRUKSTOP", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yd58yu/address_validation_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yd58yu/address_validation_pipeline/", "subreddit_subscribers": 77774, "created_utc": 1666705604.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What I am looking for is some sort of practice tasks, perfectly test type exercises where I would have to select the correct DAG graph given the situation or answer a question and that there would be an explanation provided in case my selected answer is incorrect. I feel like I have read enough theory but still don't feel confident about my understanding. A website for such practice would be amazing.", "author_fullname": "t2_917g34y9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need to get some practice on Causal DAGs. Is there a good online website to practice?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ydj6tz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666741210.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What I am looking for is some sort of practice tasks, perfectly test type exercises where I would have to select the correct DAG graph given the situation or answer a question and that there would be an explanation provided in case my selected answer is incorrect. I feel like I have read enough theory but still don&amp;#39;t feel confident about my understanding. A website for such practice would be amazing.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ydj6tz", "is_robot_indexable": true, "report_reasons": null, "author": "Sand-Frosty", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ydj6tz/i_need_to_get_some_practice_on_causal_dags_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ydj6tz/i_need_to_get_some_practice_on_causal_dags_is/", "subreddit_subscribers": 77774, "created_utc": 1666741210.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}