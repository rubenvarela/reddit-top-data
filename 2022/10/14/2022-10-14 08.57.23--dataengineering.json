{"kind": "Listing", "data": {"after": "t3_y3ai11", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it just me or are ETL tools painful for working with APIs? My team uses Pentaho and making simple API calls is fine but anything complex turns into a mess of string manipulation. My boss wants the team to continue using Pentaho but APIs just seem so much easier to work with in python, especially if they have a good sdk.  \n\n\nIs it just me? Is it the tool?", "author_fullname": "t2_mo4lb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL Tools for Rest APIs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y381x6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665690497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it just me or are ETL tools painful for working with APIs? My team uses Pentaho and making simple API calls is fine but anything complex turns into a mess of string manipulation. My boss wants the team to continue using Pentaho but APIs just seem so much easier to work with in python, especially if they have a good sdk.  &lt;/p&gt;\n\n&lt;p&gt;Is it just me? Is it the tool?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y381x6", "is_robot_indexable": true, "report_reasons": null, "author": "Phantazein", "discussion_type": null, "num_comments": 42, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y381x6/etl_tools_for_rest_apis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y381x6/etl_tools_for_rest_apis/", "subreddit_subscribers": 76386, "created_utc": 1665690497.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just a word of caution.  Lots of engineers dis product managers.  I am not a PM, but I can say that talking negatively about your colleagues (in any function) will come back to bite you in the ass.  You know what they say about karma. She is not kind. If you are working with a product manager who has some gaps in her/his knowledge, do the right thing and help to educate and support them.  You are on the same team.", "author_fullname": "t2_pl4q8ng7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stop dissing product managers (career advice)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y3ifb7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665717173.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just a word of caution.  Lots of engineers dis product managers.  I am not a PM, but I can say that talking negatively about your colleagues (in any function) will come back to bite you in the ass.  You know what they say about karma. She is not kind. If you are working with a product manager who has some gaps in her/his knowledge, do the right thing and help to educate and support them.  You are on the same team.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "y3ifb7", "is_robot_indexable": true, "report_reasons": null, "author": "droppedorphan", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y3ifb7/stop_dissing_product_managers_career_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y3ifb7/stop_dissing_product_managers_career_advice/", "subreddit_subscribers": 76386, "created_utc": 1665717173.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey r/DE! We're currently working on a transition from SQL Server/In-house tools to a Databricks implementation and I have some concerns/questions about its direction. Hoping I can get someone else's perspective or further materials to read before I go into battle with the consultants.\n\n \n\nHigh level, we take client's data in, we clean it up, and run analysis on the cleaned up data. The cleaning and analysis portions are a mix of standard and custom processes. We're looking to standardize this into a bronze, silver, gold process where bronze is loaded raw data, the cleanup happens in silver, and the gold layer has the final presentation needed for our analysis. Makes sense in theory, but as we know the devil is in the details. Below are my main concerns about the current proposal:\n\n \n\n**The silver cleanup process can pull directly from clean gold data.**\n\nIn my opinion, this makes a dependency nightmare, and also the whole process non-deterministic. We do need to sometimes reference the output of our measurement in the data cleanup process. I would think in situations like this we would store the output of gold, and then have that then be an input to the bronze layer. This way we would have a set of inputs always equal the same output, and not create a state machine. \n\n \n\n**Data gets loaded to silver and then edited in-place**\n\nIn their proposal we aggregate bronze data, load it into silver, and then run processes that manipulate the tables while they're still in silver. In my opinion, this makes silver data time-dependent. I would think these cleanup processes would be a part of the pipeline from bronze to silver. I understand that the data does have to live somewhere so maybe this is a common practice that I am unfamiliar with. The datasets we're working with are generally 20 to 350 million lines and haven't surpassed 5gb but may in the future.\n\n \n\nAny thoughts or further reading materials on the above would be much appreciated. Thank you all in advance!!", "author_fullname": "t2_3rvgz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks Architecture Best Practices", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y36nxq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665687220.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey &lt;a href=\"/r/DE\"&gt;r/DE&lt;/a&gt;! We&amp;#39;re currently working on a transition from SQL Server/In-house tools to a Databricks implementation and I have some concerns/questions about its direction. Hoping I can get someone else&amp;#39;s perspective or further materials to read before I go into battle with the consultants.&lt;/p&gt;\n\n&lt;p&gt;High level, we take client&amp;#39;s data in, we clean it up, and run analysis on the cleaned up data. The cleaning and analysis portions are a mix of standard and custom processes. We&amp;#39;re looking to standardize this into a bronze, silver, gold process where bronze is loaded raw data, the cleanup happens in silver, and the gold layer has the final presentation needed for our analysis. Makes sense in theory, but as we know the devil is in the details. Below are my main concerns about the current proposal:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The silver cleanup process can pull directly from clean gold data.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;In my opinion, this makes a dependency nightmare, and also the whole process non-deterministic. We do need to sometimes reference the output of our measurement in the data cleanup process. I would think in situations like this we would store the output of gold, and then have that then be an input to the bronze layer. This way we would have a set of inputs always equal the same output, and not create a state machine. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Data gets loaded to silver and then edited in-place&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;In their proposal we aggregate bronze data, load it into silver, and then run processes that manipulate the tables while they&amp;#39;re still in silver. In my opinion, this makes silver data time-dependent. I would think these cleanup processes would be a part of the pipeline from bronze to silver. I understand that the data does have to live somewhere so maybe this is a common practice that I am unfamiliar with. The datasets we&amp;#39;re working with are generally 20 to 350 million lines and haven&amp;#39;t surpassed 5gb but may in the future.&lt;/p&gt;\n\n&lt;p&gt;Any thoughts or further reading materials on the above would be much appreciated. Thank you all in advance!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y36nxq", "is_robot_indexable": true, "report_reasons": null, "author": "EggLampBasket", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y36nxq/databricks_architecture_best_practices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y36nxq/databricks_architecture_best_practices/", "subreddit_subscribers": 76386, "created_utc": 1665687220.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Ever since WFH has become the norm there seems to be a new craze going on called over employment. Essentially people work 2-3 work from home jobs concurrently either with or without the permission of their employers.\n\nThis ranges a whole spectrum of industries and there is a whole sub reddit dedicated to it but I wanted to bring the discussion here because Data Engineering and other data related positions seem like they would be ideal for this type of set up. Specifically because of the automation scripting that are used in so many data related task.\n\nWhat I am seeing is people are able to automate the most basic job functions and only require manual intervention in the event that something breaks or when making upgrades or enhancements. It seems there is quite a bit of controversy around this and if it's ethical and obviously it's frowned upon by many employees.\n\nIf I were to do this I would prefer to do it the legit way as I would like to keep the great relationship I have with my employer. My current data engineering position usually involves at least 2 zoom meetings a day and the times aren't consistent so if I considered taking a second role it would have to be something with no or minimal meetings. Also my primary position I would keep salaried with the benefits and anything else I would only consider doing on a contractual / hourly basis. \n\nDo such jobs exist where basically you are given a project and a time frame to compete it within but besides that you don't need to be available for calls or meetings at any set hours ? That would be the ideal situation for me if it was something I could work on outside the hours of my primary job and on the weekends.\n\nObviously the money is an important reason to do this but my primary motivation is also keeping a diverse skill set sharp. My job right now is almost entirely based in SQL and PowerShell and the only platforms we are using is Azure, on prem SQL Server and the ETL tools are SSIS or Data Factory. I put a lot of effort into learning Python for Data Science and Data Analyst task and I'm kinda bummed I'm not using it. It would also be nice to take on a second gig that uses a different platform like AWS so I can keep myself relevant and up to date with all the main cloud environments.\n\nIs anyone here doing this successfully ?", "author_fullname": "t2_dfcot0zg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone hold down two DE positions at once ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y3aayl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665695642.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Ever since WFH has become the norm there seems to be a new craze going on called over employment. Essentially people work 2-3 work from home jobs concurrently either with or without the permission of their employers.&lt;/p&gt;\n\n&lt;p&gt;This ranges a whole spectrum of industries and there is a whole sub reddit dedicated to it but I wanted to bring the discussion here because Data Engineering and other data related positions seem like they would be ideal for this type of set up. Specifically because of the automation scripting that are used in so many data related task.&lt;/p&gt;\n\n&lt;p&gt;What I am seeing is people are able to automate the most basic job functions and only require manual intervention in the event that something breaks or when making upgrades or enhancements. It seems there is quite a bit of controversy around this and if it&amp;#39;s ethical and obviously it&amp;#39;s frowned upon by many employees.&lt;/p&gt;\n\n&lt;p&gt;If I were to do this I would prefer to do it the legit way as I would like to keep the great relationship I have with my employer. My current data engineering position usually involves at least 2 zoom meetings a day and the times aren&amp;#39;t consistent so if I considered taking a second role it would have to be something with no or minimal meetings. Also my primary position I would keep salaried with the benefits and anything else I would only consider doing on a contractual / hourly basis. &lt;/p&gt;\n\n&lt;p&gt;Do such jobs exist where basically you are given a project and a time frame to compete it within but besides that you don&amp;#39;t need to be available for calls or meetings at any set hours ? That would be the ideal situation for me if it was something I could work on outside the hours of my primary job and on the weekends.&lt;/p&gt;\n\n&lt;p&gt;Obviously the money is an important reason to do this but my primary motivation is also keeping a diverse skill set sharp. My job right now is almost entirely based in SQL and PowerShell and the only platforms we are using is Azure, on prem SQL Server and the ETL tools are SSIS or Data Factory. I put a lot of effort into learning Python for Data Science and Data Analyst task and I&amp;#39;m kinda bummed I&amp;#39;m not using it. It would also be nice to take on a second gig that uses a different platform like AWS so I can keep myself relevant and up to date with all the main cloud environments.&lt;/p&gt;\n\n&lt;p&gt;Is anyone here doing this successfully ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "y3aayl", "is_robot_indexable": true, "report_reasons": null, "author": "DrRedmondNYC", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y3aayl/anyone_hold_down_two_de_positions_at_once/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y3aayl/anyone_hold_down_two_de_positions_at_once/", "subreddit_subscribers": 76386, "created_utc": 1665695642.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_q9a58hxy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DuckDB - Modern Data Stack in a Box with DuckDB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_y31oid", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/-md-jPF1vRQTud0XCPODyiZjaDMXi7frOPYybhgKFeA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1665675090.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "duckdb.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://duckdb.org/2022/10/12/modern-data-stack-in-a-box.html", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/GctXJNpN2X3nQLnJV4YKiGNicM-bQELTDEHwQJ3tLlo.jpg?auto=webp&amp;s=df4fb13c0741919fd9f695ba304cb6d3a1fb56ed", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/GctXJNpN2X3nQLnJV4YKiGNicM-bQELTDEHwQJ3tLlo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5ac7c3882de773b950cd2e3cd83aba08b84d6fa7", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/GctXJNpN2X3nQLnJV4YKiGNicM-bQELTDEHwQJ3tLlo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e011b38bce0303748d54aed1967329a61ba0bf14", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/GctXJNpN2X3nQLnJV4YKiGNicM-bQELTDEHwQJ3tLlo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=28287676b7e382af057ff233ebabb92eb44395da", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/GctXJNpN2X3nQLnJV4YKiGNicM-bQELTDEHwQJ3tLlo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=17a7e3ab4756e9f324d7dfbf41f4877a51c3a790", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/GctXJNpN2X3nQLnJV4YKiGNicM-bQELTDEHwQJ3tLlo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b38599a9c28c8b8760b7158ed21e418d1d88ff32", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/GctXJNpN2X3nQLnJV4YKiGNicM-bQELTDEHwQJ3tLlo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4eaa0d481f6cb0b5bde29d1b7160f655cc8a2cc8", "width": 1080, "height": 567}], "variants": {}, "id": "jWyiaF4Jb7ULQyU8SCl75THeEbJM9dbSQ9YXdauXufk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "y31oid", "is_robot_indexable": true, "report_reasons": null, "author": "m___ke", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y31oid/duckdb_modern_data_stack_in_a_box_with_duckdb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://duckdb.org/2022/10/12/modern-data-stack-in-a-box.html", "subreddit_subscribers": 76386, "created_utc": 1665675090.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Same as the title. I have heard that many folks store their db creds in excel file or google sheet. What do you guys use ?", "author_fullname": "t2_57e44nxs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where do you store your database creds ? Let assume you have multiple databases (around 20-30) , then how do you manage or store their creds so that they are shared and stored securely", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y2y06x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665665649.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Same as the title. I have heard that many folks store their db creds in excel file or google sheet. What do you guys use ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y2y06x", "is_robot_indexable": true, "report_reasons": null, "author": "RstarPhoneix", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y2y06x/where_do_you_store_your_database_creds_let_assume/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y2y06x/where_do_you_store_your_database_creds_let_assume/", "subreddit_subscribers": 76386, "created_utc": 1665665649.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm downloading a bunch of Economic Indicators from the Federal Reserve Economic Data site.\n\nExamples might be Monthly CPI number, Monthly Unemployment rate, Monthly Average 30 Year Mortgage rates, Quarterly unemployment claims, etc.\n\nSome are released weekly, some monthly, quarterly, annually just depending on the metric.\n\nI have been thinking of how to model this data. Either having a MonthlyEconomicIndicators and QuarterlyEconomic Indicators and any other levels of granularity that we're grouping.\n\nOr...\n\nHaving individual data points for each Indicator.\n\nGrouping things together makes sense because it's semi-similar data and would probably be easy to work with. The primary key would be whatever date field were using.\n\nHaving individual tables makes some sense because different data points have different amounts of history. Some may only go back to 2010 but others go to 2000. Also I don't want the table to get too wide so it's too hard finding what you're looking for. Primary key would still be the date.\n\nOtherwise the third format that doesn't seem appealing is one with a column that says the indicator and a column that says the value.\n\nThe data will mostly be used for data Scientists to do Modeling and Analysis.\n\nThoughts?", "author_fullname": "t2_94m29", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Economic Indicators - One Table or Many?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y32kzh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665677283.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m downloading a bunch of Economic Indicators from the Federal Reserve Economic Data site.&lt;/p&gt;\n\n&lt;p&gt;Examples might be Monthly CPI number, Monthly Unemployment rate, Monthly Average 30 Year Mortgage rates, Quarterly unemployment claims, etc.&lt;/p&gt;\n\n&lt;p&gt;Some are released weekly, some monthly, quarterly, annually just depending on the metric.&lt;/p&gt;\n\n&lt;p&gt;I have been thinking of how to model this data. Either having a MonthlyEconomicIndicators and QuarterlyEconomic Indicators and any other levels of granularity that we&amp;#39;re grouping.&lt;/p&gt;\n\n&lt;p&gt;Or...&lt;/p&gt;\n\n&lt;p&gt;Having individual data points for each Indicator.&lt;/p&gt;\n\n&lt;p&gt;Grouping things together makes sense because it&amp;#39;s semi-similar data and would probably be easy to work with. The primary key would be whatever date field were using.&lt;/p&gt;\n\n&lt;p&gt;Having individual tables makes some sense because different data points have different amounts of history. Some may only go back to 2010 but others go to 2000. Also I don&amp;#39;t want the table to get too wide so it&amp;#39;s too hard finding what you&amp;#39;re looking for. Primary key would still be the date.&lt;/p&gt;\n\n&lt;p&gt;Otherwise the third format that doesn&amp;#39;t seem appealing is one with a column that says the indicator and a column that says the value.&lt;/p&gt;\n\n&lt;p&gt;The data will mostly be used for data Scientists to do Modeling and Analysis.&lt;/p&gt;\n\n&lt;p&gt;Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y32kzh", "is_robot_indexable": true, "report_reasons": null, "author": "bojanderson", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y32kzh/economic_indicators_one_table_or_many/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y32kzh/economic_indicators_one_table_or_many/", "subreddit_subscribers": 76386, "created_utc": 1665677283.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi!\n\nMore of a conceptual question:\n\nLet's say I have a extract and load pipeline that collect data from a API and loads in a raw table in DW like Big Query. \n\nEverytime the pipeline runs it gets the data from the last day and inserts in a table, sometimes the pipeline could run twice in the same day by mistake (Some analyst could run it manually accidentally) and I wold get duplicated rows for the last day.\n\nI'd like to know if it's ok to check if the key already exists before inserting and then delete the old values, OR if it's better to create some sort of datetime column and when it comes to read the table apply a max(datetime) for guarantee I would get the most updated values.\n\nCan someone help me out with this doubt?\n\n&amp;#x200B;\n\nThanks!!", "author_fullname": "t2_3d6ridh2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Extract and Load Strategy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y30uqp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665673031.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;/p&gt;\n\n&lt;p&gt;More of a conceptual question:&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s say I have a extract and load pipeline that collect data from a API and loads in a raw table in DW like Big Query. &lt;/p&gt;\n\n&lt;p&gt;Everytime the pipeline runs it gets the data from the last day and inserts in a table, sometimes the pipeline could run twice in the same day by mistake (Some analyst could run it manually accidentally) and I wold get duplicated rows for the last day.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to know if it&amp;#39;s ok to check if the key already exists before inserting and then delete the old values, OR if it&amp;#39;s better to create some sort of datetime column and when it comes to read the table apply a max(datetime) for guarantee I would get the most updated values.&lt;/p&gt;\n\n&lt;p&gt;Can someone help me out with this doubt?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y30uqp", "is_robot_indexable": true, "report_reasons": null, "author": "PurpleSir6567", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y30uqp/extract_and_load_strategy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y30uqp/extract_and_load_strategy/", "subreddit_subscribers": 76386, "created_utc": 1665673031.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was hired as a data analyst and the company was supposed to be outsourcing the ETL. However, the ETL company they went with isn't working out and I'm being tasked with building the pipeline. I do have a basic understanding, some of the technical skills and what I don't know I can quickly learn. The money that was being spent on the ETL company is being reallocated and there's nothing else in the budget for data. \n\n\nCurrently I have Stitch set up to load some of our data sources in BigQuery and I'm creating views  in BigQuery to transform the data. It's not a great solution but I needed something quick. The plan is to do the transformations in dbt. Stitch doesn't have enough of the connectors we need, most notably Amazon Seller Central, so I'm exploring other options. I tried out AirByte but it's too over normalized and I haven't had success getting the BigQuery denormalized destination to work. I've also used Meltano some. \n\n\nWhat are some other good free options? If you were in my position what pipeline would you set up? It's an ecommerce company so Shopify, Amazon Seller Central, Google Analytics, Google Ads, Facebook Ads, Big Query, NetSuite are some of the connectors I'll need. \n\n\nAre there any good learning resources out there for someone like me. I'm taking python courses and doing as much research as possible, reading Fundamentals of Data Engineering and Data Science on the Google Cloud Platform. But I really need to hit the ground running and would do better if I could learn as I go.", "author_fullname": "t2_2q171de9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data analyst tasked with building data pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y3i3t1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665716240.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was hired as a data analyst and the company was supposed to be outsourcing the ETL. However, the ETL company they went with isn&amp;#39;t working out and I&amp;#39;m being tasked with building the pipeline. I do have a basic understanding, some of the technical skills and what I don&amp;#39;t know I can quickly learn. The money that was being spent on the ETL company is being reallocated and there&amp;#39;s nothing else in the budget for data. &lt;/p&gt;\n\n&lt;p&gt;Currently I have Stitch set up to load some of our data sources in BigQuery and I&amp;#39;m creating views  in BigQuery to transform the data. It&amp;#39;s not a great solution but I needed something quick. The plan is to do the transformations in dbt. Stitch doesn&amp;#39;t have enough of the connectors we need, most notably Amazon Seller Central, so I&amp;#39;m exploring other options. I tried out AirByte but it&amp;#39;s too over normalized and I haven&amp;#39;t had success getting the BigQuery denormalized destination to work. I&amp;#39;ve also used Meltano some. &lt;/p&gt;\n\n&lt;p&gt;What are some other good free options? If you were in my position what pipeline would you set up? It&amp;#39;s an ecommerce company so Shopify, Amazon Seller Central, Google Analytics, Google Ads, Facebook Ads, Big Query, NetSuite are some of the connectors I&amp;#39;ll need. &lt;/p&gt;\n\n&lt;p&gt;Are there any good learning resources out there for someone like me. I&amp;#39;m taking python courses and doing as much research as possible, reading Fundamentals of Data Engineering and Data Science on the Google Cloud Platform. But I really need to hit the ground running and would do better if I could learn as I go.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y3i3t1", "is_robot_indexable": true, "report_reasons": null, "author": "lahma_mama", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y3i3t1/data_analyst_tasked_with_building_data_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y3i3t1/data_analyst_tasked_with_building_data_pipeline/", "subreddit_subscribers": 76386, "created_utc": 1665716240.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any experience with Dremio? Interviewing for a job with a company who uses it, opinions would be helpful.", "author_fullname": "t2_qbiqlkfi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on Dremio...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y34e1f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665681707.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any experience with Dremio? Interviewing for a job with a company who uses it, opinions would be helpful.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y34e1f", "is_robot_indexable": true, "report_reasons": null, "author": "K_D20", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y34e1f/thoughts_on_dremio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y34e1f/thoughts_on_dremio/", "subreddit_subscribers": 76386, "created_utc": 1665681707.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How is this done if you have to permanently delete thousands of records from several core tables? What sort of checks do you implement to ensure you are only getting the relevant rows?", "author_fullname": "t2_1inf5n5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pipelines to delete user data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_y3fxwx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 0, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": "", "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665710097.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How is this done if you have to permanently delete thousands of records from several core tables? What sort of checks do you implement to ensure you are only getting the relevant rows?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "call_to_action": "", "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y3fxwx", "is_robot_indexable": true, "report_reasons": null, "author": "changiairport", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y3fxwx/pipelines_to_delete_user_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y3fxwx/pipelines_to_delete_user_data/", "subreddit_subscribers": 76386, "created_utc": 1665710097.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, since one of the features of Spark is lazy evaluation, so something is executed only when action is called.  \nHow do i log then?", "author_fullname": "t2_sx1wry60", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how do u log when u use pyspark(Spark).", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y37u5x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665689990.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, since one of the features of Spark is lazy evaluation, so something is executed only when action is called.&lt;br/&gt;\nHow do i log then?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y37u5x", "is_robot_indexable": true, "report_reasons": null, "author": "AcceptableProcess772", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y37u5x/how_do_u_log_when_u_use_pysparkspark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y37u5x/how_do_u_log_when_u_use_pysparkspark/", "subreddit_subscribers": 76386, "created_utc": 1665689990.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Say you have a source database like Postgres. Data engineering team pipes that data in to a data warehouse landing location. For purposes of metadata, data catalog, etc who is the owner of those raw tables? Data engineering certainly owns the pipelines, maybe they own the tables, how about the data itself?", "author_fullname": "t2_c6w52", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data that is replicated from a source database to landing in data warehouse. Who is the \u201cowner\u201d?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y367r0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665686168.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Say you have a source database like Postgres. Data engineering team pipes that data in to a data warehouse landing location. For purposes of metadata, data catalog, etc who is the owner of those raw tables? Data engineering certainly owns the pipelines, maybe they own the tables, how about the data itself?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y367r0", "is_robot_indexable": true, "report_reasons": null, "author": "EmergenL", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y367r0/data_that_is_replicated_from_a_source_database_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y367r0/data_that_is_replicated_from_a_source_database_to/", "subreddit_subscribers": 76386, "created_utc": 1665686168.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I applied to a job, a question was do you have experience with Snowflake and SQL? Where I replies yes\n\nSo if I have an interview would it be easy to quickly do some tutorials and wing the interview or not?", "author_fullname": "t2_pll9p2x2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I already have experience in SQL and data warehousing, how difficult will it be learning snowflake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y2zh9h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665669575.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I applied to a job, a question was do you have experience with Snowflake and SQL? Where I replies yes&lt;/p&gt;\n\n&lt;p&gt;So if I have an interview would it be easy to quickly do some tutorials and wing the interview or not?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y2zh9h", "is_robot_indexable": true, "report_reasons": null, "author": "Do_I_know_you_1", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y2zh9h/i_already_have_experience_in_sql_and_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y2zh9h/i_already_have_experience_in_sql_and_data/", "subreddit_subscribers": 76386, "created_utc": 1665669575.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nI have the desire to create an analytics side hustle but do not want to host the data service on my machine. I would ideally use a cloud service so if my computer crashed, it would be no big deal.\n\nSome background information:\n\nI would like to create a system to execute API calls in Python and store the data.\n\nWith this data I would like to perform ML and data mining for analysis.\n\nThese Python scripts should run on a schedule.\n\nThis data would then be displayed in Tableau Cloud for customers to have their analytics.\n\nHow should I go about this? I am trying to minimize costs but if the tool is amazing I would be willing to spend the money.\n\nThank you in advance.", "author_fullname": "t2_5fves3ac", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Service Infrastructure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y3djxw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665703609.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have the desire to create an analytics side hustle but do not want to host the data service on my machine. I would ideally use a cloud service so if my computer crashed, it would be no big deal.&lt;/p&gt;\n\n&lt;p&gt;Some background information:&lt;/p&gt;\n\n&lt;p&gt;I would like to create a system to execute API calls in Python and store the data.&lt;/p&gt;\n\n&lt;p&gt;With this data I would like to perform ML and data mining for analysis.&lt;/p&gt;\n\n&lt;p&gt;These Python scripts should run on a schedule.&lt;/p&gt;\n\n&lt;p&gt;This data would then be displayed in Tableau Cloud for customers to have their analytics.&lt;/p&gt;\n\n&lt;p&gt;How should I go about this? I am trying to minimize costs but if the tool is amazing I would be willing to spend the money.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y3djxw", "is_robot_indexable": true, "report_reasons": null, "author": "TraditionalWorth1436", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y3djxw/data_service_infrastructure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y3djxw/data_service_infrastructure/", "subreddit_subscribers": 76386, "created_utc": 1665703609.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a DE on an executive position, with several years of experience. For many years now I've been leading a reasonably large (60 people) team of applied mathematicians, engineers, software developers, actuaries, etc. in a business-side data engineering function within the Risk department in a large bank in a non-US country.\n\nOur current level of service and NPS is suffering a bit and I've concluded the main problem  is that my team is not really a data engineering team built from the ground up, (with ad hoc job descriptions, people actually matching that job description, adequate compensation reflecting this etc.). Hence, I'm working with HR to remediate this, and the first step is to rewrite our job descriptions for DE.\n\nI have already written some draft JDs but I thought it was a good idea to ask for your opinions on the following matters:\n\n&amp;#x200B;\n\n1. What would you say are the top five **soft skills** (i.e. non-technical) a DE must definitely have?How are you actually assessing those skills in interviews? (it's way easier to apply a technical test than to assess a particular soft skill in such a reduced interview period)\n2. Apart from leadership and team management skills, how would you clearly differentiate a **junior** data engineer vs a **senior** data engineer and a **head** of DE (years of experience, variety of technologies, specific academic background, specific soft skills...)? \n3. Over the years I've sometimes found it better to hire business people (i.e. academically and with actual business experience) specializing in DE stuff, than computer scientists with experience trying to learn the business. **What's your take on this** and how would you **reflect it in the job description**?\n4. What would you say are the specific DE skills that really **up the bar in terms of \"desirability\"** (and, hence, pay range)?\n\n&amp;#x200B;\n\nThank you so much in advance for any pointers or tips regarding this.\n\nBest,", "author_fullname": "t2_1ae5qbb2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help me figure out a good job description for DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y31ch7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665674241.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a DE on an executive position, with several years of experience. For many years now I&amp;#39;ve been leading a reasonably large (60 people) team of applied mathematicians, engineers, software developers, actuaries, etc. in a business-side data engineering function within the Risk department in a large bank in a non-US country.&lt;/p&gt;\n\n&lt;p&gt;Our current level of service and NPS is suffering a bit and I&amp;#39;ve concluded the main problem  is that my team is not really a data engineering team built from the ground up, (with ad hoc job descriptions, people actually matching that job description, adequate compensation reflecting this etc.). Hence, I&amp;#39;m working with HR to remediate this, and the first step is to rewrite our job descriptions for DE.&lt;/p&gt;\n\n&lt;p&gt;I have already written some draft JDs but I thought it was a good idea to ask for your opinions on the following matters:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;What would you say are the top five &lt;strong&gt;soft skills&lt;/strong&gt; (i.e. non-technical) a DE must definitely have?How are you actually assessing those skills in interviews? (it&amp;#39;s way easier to apply a technical test than to assess a particular soft skill in such a reduced interview period)&lt;/li&gt;\n&lt;li&gt;Apart from leadership and team management skills, how would you clearly differentiate a &lt;strong&gt;junior&lt;/strong&gt; data engineer vs a &lt;strong&gt;senior&lt;/strong&gt; data engineer and a &lt;strong&gt;head&lt;/strong&gt; of DE (years of experience, variety of technologies, specific academic background, specific soft skills...)? &lt;/li&gt;\n&lt;li&gt;Over the years I&amp;#39;ve sometimes found it better to hire business people (i.e. academically and with actual business experience) specializing in DE stuff, than computer scientists with experience trying to learn the business. &lt;strong&gt;What&amp;#39;s your take on this&lt;/strong&gt; and how would you &lt;strong&gt;reflect it in the job description&lt;/strong&gt;?&lt;/li&gt;\n&lt;li&gt;What would you say are the specific DE skills that really &lt;strong&gt;up the bar in terms of &amp;quot;desirability&amp;quot;&lt;/strong&gt; (and, hence, pay range)?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you so much in advance for any pointers or tips regarding this.&lt;/p&gt;\n\n&lt;p&gt;Best,&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y31ch7", "is_robot_indexable": true, "report_reasons": null, "author": "biyectivo", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y31ch7/help_me_figure_out_a_good_job_description_for_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y31ch7/help_me_figure_out_a_good_job_description_for_de/", "subreddit_subscribers": 76386, "created_utc": 1665674241.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6qpanfe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introducing Views for metrics management in your data stack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_y315de", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/mav4GN5tebZFWWPjkldO67WzlB5jfXxPerx8UFjJ6bk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1665673757.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "cube.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://cube.dev/blog/introducing-views", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/tOZD8FimYNeaLO2b_46NA3hYXR_fe12WfGyOF6qBIyM.jpg?auto=webp&amp;s=720db075b3f3d651c6582cf248941e81e271ed89", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/tOZD8FimYNeaLO2b_46NA3hYXR_fe12WfGyOF6qBIyM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=04754e8f26ce6584e9f7320d8ae9296c39d8f00a", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/tOZD8FimYNeaLO2b_46NA3hYXR_fe12WfGyOF6qBIyM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=84e24831b702095b74ca46cfc87106f53f562fd7", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/tOZD8FimYNeaLO2b_46NA3hYXR_fe12WfGyOF6qBIyM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=42180b84b31128e1d7d311e1cb71759f17409f68", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/tOZD8FimYNeaLO2b_46NA3hYXR_fe12WfGyOF6qBIyM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d91a2c7ff7148e5c6046c4cc99111be4cc6e5a0e", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/tOZD8FimYNeaLO2b_46NA3hYXR_fe12WfGyOF6qBIyM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b38d3aed37b9694d06acb98c3a6c5e7d812c92cb", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/tOZD8FimYNeaLO2b_46NA3hYXR_fe12WfGyOF6qBIyM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b25948a4c01bdd718dbb2e5c2f1b46f94c493136", "width": 1080, "height": 567}], "variants": {}, "id": "k0-CLnsMWk6ABOwLuc_FkI8Cgzjm-4pFTqEYyd2KSRA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "y315de", "is_robot_indexable": true, "report_reasons": null, "author": "igorlukanin", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y315de/introducing_views_for_metrics_management_in_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://cube.dev/blog/introducing-views", "subreddit_subscribers": 76386, "created_utc": 1665673757.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, \n\nI was thinking of starting a course from Bertosz Konieczny ([http://www.becomedataengineer.com](http://www.becomedataengineer.com)) and I was wondering if anyone here ever attended? Is it worth it? Do you have any other recommendations? I have a bsc in CS and work as a BI Analyst", "author_fullname": "t2_q92vm6kg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE course", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y2ux8h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1665655920.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, &lt;/p&gt;\n\n&lt;p&gt;I was thinking of starting a course from Bertosz Konieczny (&lt;a href=\"http://www.becomedataengineer.com\"&gt;http://www.becomedataengineer.com&lt;/a&gt;) and I was wondering if anyone here ever attended? Is it worth it? Do you have any other recommendations? I have a bsc in CS and work as a BI Analyst&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yslgPJk-szPt97jkswC3Nx8cvM3a11gPRuYDKNj3yWg.jpg?auto=webp&amp;s=1542e8920c80e86e1f3702fefcd58c69b7829606", "width": 1474, "height": 1382}, "resolutions": [{"url": "https://external-preview.redd.it/yslgPJk-szPt97jkswC3Nx8cvM3a11gPRuYDKNj3yWg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ff91bba2b9b8b3a41e8cf5e68a51eed1b893de42", "width": 108, "height": 101}, {"url": "https://external-preview.redd.it/yslgPJk-szPt97jkswC3Nx8cvM3a11gPRuYDKNj3yWg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=25b60bf72a20b20cc3ca903cd4a74efe9e4def04", "width": 216, "height": 202}, {"url": "https://external-preview.redd.it/yslgPJk-szPt97jkswC3Nx8cvM3a11gPRuYDKNj3yWg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cd0bc0e4ffde9bbdd4f20a8a6e095869196eebaa", "width": 320, "height": 300}, {"url": "https://external-preview.redd.it/yslgPJk-szPt97jkswC3Nx8cvM3a11gPRuYDKNj3yWg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=20a9466b6a7c92cd7785c42e1f9465f7e947baec", "width": 640, "height": 600}, {"url": "https://external-preview.redd.it/yslgPJk-szPt97jkswC3Nx8cvM3a11gPRuYDKNj3yWg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=fdb787c49667fd09789ae56baa7e9ee88504b636", "width": 960, "height": 900}, {"url": "https://external-preview.redd.it/yslgPJk-szPt97jkswC3Nx8cvM3a11gPRuYDKNj3yWg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f851b9a33fdf60277729b30c26dbae0f3d8540f7", "width": 1080, "height": 1012}], "variants": {}, "id": "bySzyovL-sih7_Y4SroZ3grkLCHk2pBvj7mf-kkUrh0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "y2ux8h", "is_robot_indexable": true, "report_reasons": null, "author": "tyrion25", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y2ux8h/de_course/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y2ux8h/de_course/", "subreddit_subscribers": 76386, "created_utc": 1665655920.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, as per title I would like to start a streaming project with Kafka. I'm searching for some interesting free data sources but it doesn't seem easy to find one, I'm trying to avoid some inflated ones like Twitter of Facebook API. A project about IoT would be really cool.\n\n I would also like to keep the project as cheap as possible.\n\nThanks!", "author_fullname": "t2_1xbf9q7w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Free Data Streaming Sources for a Personal Project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y2t2e4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665648892.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, as per title I would like to start a streaming project with Kafka. I&amp;#39;m searching for some interesting free data sources but it doesn&amp;#39;t seem easy to find one, I&amp;#39;m trying to avoid some inflated ones like Twitter of Facebook API. A project about IoT would be really cool.&lt;/p&gt;\n\n&lt;p&gt;I would also like to keep the project as cheap as possible.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y2t2e4", "is_robot_indexable": true, "report_reasons": null, "author": "aerdna69", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y2t2e4/free_data_streaming_sources_for_a_personal_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y2t2e4/free_data_streaming_sources_for_a_personal_project/", "subreddit_subscribers": 76386, "created_utc": 1665648892.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_265t3i5h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "46 Best Resources to learn Big Data (YouTube, Books, Courses, &amp; Tutorials)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": true, "name": "t3_y3n2kj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/iVYzb0ZONTnAtIxXFHPb0JsxXMTCzKDky62rfDInoDU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1665732151.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "mltut.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.mltut.com/best-resources-to-learn-big-data/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Zth95306cFBt-OnZ1hAtNCTDJRuihEklulXdwH0vIwI.jpg?auto=webp&amp;s=614384e41816c34adb88a5a6bcc25a4bd09b7e0c", "width": 2240, "height": 1260}, "resolutions": [{"url": "https://external-preview.redd.it/Zth95306cFBt-OnZ1hAtNCTDJRuihEklulXdwH0vIwI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3dc69e201936d4caaf45dd5a2029eb4df50df141", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/Zth95306cFBt-OnZ1hAtNCTDJRuihEklulXdwH0vIwI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bb620cf085f300cfe313947aa09bb4a9e6ad711a", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/Zth95306cFBt-OnZ1hAtNCTDJRuihEklulXdwH0vIwI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ab9c5c73f3d77856d5fddcd988784a6e34b11edb", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/Zth95306cFBt-OnZ1hAtNCTDJRuihEklulXdwH0vIwI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=548473bed1ecf68b1fbfdd93b8006a04a2f75bd7", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/Zth95306cFBt-OnZ1hAtNCTDJRuihEklulXdwH0vIwI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7d42c8d4abefae19bc7abca0c76dd56f57d11e37", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/Zth95306cFBt-OnZ1hAtNCTDJRuihEklulXdwH0vIwI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=31c8ffb1731b385a2807e1d638e9d9f356b4031f", "width": 1080, "height": 607}], "variants": {}, "id": "6H8zHTpMnkqcsEbLwABRmGyofeCjFJsg8wvMe_ttDf4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "y3n2kj", "is_robot_indexable": true, "report_reasons": null, "author": "MlTut", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y3n2kj/46_best_resources_to_learn_big_data_youtube_books/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.mltut.com/best-resources-to-learn-big-data/", "subreddit_subscribers": 76386, "created_utc": 1665732151.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A big part of me joining the company I\u2019m currently at is the ability to learn from the software engineers and bring the software best practices to data.\n\nWith that in mind, the team is constantly referring to Feature Flags - the ability to have a feature turned on in dev but off in prod. It seems like a great approach, allowing is to embrace CI/CD. But\u2026 how does it work in practice in a data warehouse?\n\nWe use dbt. We can enable or disable a model with a config block. That\u2019s easy. But what about a feature that changes an inner join to a left join? Or that adds a join to a new table in the model and pulls in an additional 3 fields?\n\nI\u2019ve not been able to crack it. Does anyone have an answer?", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feature Flags", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y39jvt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665693908.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A big part of me joining the company I\u2019m currently at is the ability to learn from the software engineers and bring the software best practices to data.&lt;/p&gt;\n\n&lt;p&gt;With that in mind, the team is constantly referring to Feature Flags - the ability to have a feature turned on in dev but off in prod. It seems like a great approach, allowing is to embrace CI/CD. But\u2026 how does it work in practice in a data warehouse?&lt;/p&gt;\n\n&lt;p&gt;We use dbt. We can enable or disable a model with a config block. That\u2019s easy. But what about a feature that changes an inner join to a left join? Or that adds a join to a new table in the model and pulls in an additional 3 fields?&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve not been able to crack it. Does anyone have an answer?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y39jvt", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y39jvt/feature_flags/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y39jvt/feature_flags/", "subreddit_subscribers": 76386, "created_utc": 1665693908.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_aehfkmkb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Microsoft Ignite Day 1 | Data Hot News", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_y2xabq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/QSzH9aM-3nM?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Microsoft Ignite Day 1 | Data Hot News\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Microsoft Ignite Day 1 | Data Hot News", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/QSzH9aM-3nM?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Microsoft Ignite Day 1 | Data Hot News\"&gt;&lt;/iframe&gt;", "author_name": "Cloud and Data Science", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/QSzH9aM-3nM/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/c/CloudDataScience"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/QSzH9aM-3nM?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Microsoft Ignite Day 1 | Data Hot News\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/y2xabq", "height": 200}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/3BIOFQqcxkrc8E8xq-bLCK3gpzdl4nLvZr80SWF4R30.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1665663622.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtube.com/watch?v=QSzH9aM-3nM&amp;feature=share", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/TbyA2PmC61LpUWPkU0wwEM2Q_s3kIJSYoq_4NtXWlpA.jpg?auto=webp&amp;s=00641063ce5c84a889670ed59bb5289ec56442bf", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/TbyA2PmC61LpUWPkU0wwEM2Q_s3kIJSYoq_4NtXWlpA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=97cf6b16ef636f5f0a14aa630c84929ccfb4daad", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/TbyA2PmC61LpUWPkU0wwEM2Q_s3kIJSYoq_4NtXWlpA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=63d2076f42f07fb54032cb159c108204f4a9e713", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/TbyA2PmC61LpUWPkU0wwEM2Q_s3kIJSYoq_4NtXWlpA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=dd165898622623333fcb4e6ccf78cf561347c54a", "width": 320, "height": 240}], "variants": {}, "id": "_spbrECWORzSSvZbYGwpsNGn97ynEuvVfRqECJtHjVo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "y2xabq", "is_robot_indexable": true, "report_reasons": null, "author": "Successful-Aide3077", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y2xabq/microsoft_ignite_day_1_data_hot_news/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtube.com/watch?v=QSzH9aM-3nM&amp;feature=share", "subreddit_subscribers": 76386, "created_utc": 1665663622.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Microsoft Ignite Day 1 | Data Hot News", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/QSzH9aM-3nM?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Microsoft Ignite Day 1 | Data Hot News\"&gt;&lt;/iframe&gt;", "author_name": "Cloud and Data Science", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/QSzH9aM-3nM/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/c/CloudDataScience"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What's everyones thoughts on FiveTran recently dropping their support of SQL by 2023?\n\n&amp;#x200B;\n\n[https://www.theregister.com/2022/10/07/fivetran\\_slated\\_for\\_dropping\\_sql/](https://www.theregister.com/2022/10/07/fivetran_slated_for_dropping_sql/)", "author_fullname": "t2_tbon5l5x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "FiveTran dropping SQL support", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y2ws3p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1665662142.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What&amp;#39;s everyones thoughts on FiveTran recently dropping their support of SQL by 2023?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.theregister.com/2022/10/07/fivetran_slated_for_dropping_sql/\"&gt;https://www.theregister.com/2022/10/07/fivetran_slated_for_dropping_sql/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qwcS_bXL03oQEUbZmHVqOqgppszCEEL-uTaxQjGl-RQ.jpg?auto=webp&amp;s=67b07b8615ce875f35bdbc54d158d575abdedb23", "width": 1000, "height": 667}, "resolutions": [{"url": "https://external-preview.redd.it/qwcS_bXL03oQEUbZmHVqOqgppszCEEL-uTaxQjGl-RQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bfc3056a77681bdee9f0170c9c481b6eba336145", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/qwcS_bXL03oQEUbZmHVqOqgppszCEEL-uTaxQjGl-RQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=940a5b37da7a4090f041fcca4444819ee253f38f", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/qwcS_bXL03oQEUbZmHVqOqgppszCEEL-uTaxQjGl-RQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c75e36be4ec7b812c85d91ba2bde18f32e0f0d8b", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/qwcS_bXL03oQEUbZmHVqOqgppszCEEL-uTaxQjGl-RQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7c04503c7a03ffe50b522de476f4b4e5c56a2eae", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/qwcS_bXL03oQEUbZmHVqOqgppszCEEL-uTaxQjGl-RQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=70526f54d25264f5d7d45a1da620660c39da8b74", "width": 960, "height": 640}], "variants": {}, "id": "s3x-aDnoC_mVA4veUg0WuohRXSNHJw1pRXwyhnPYApM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y2ws3p", "is_robot_indexable": true, "report_reasons": null, "author": "EquivalentExpress875", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y2ws3p/fivetran_dropping_sql_support/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y2ws3p/fivetran_dropping_sql_support/", "subreddit_subscribers": 76386, "created_utc": 1665662142.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Given years of experience can you limit your workday to &lt; 3 hours?", "author_fullname": "t2_xgf2i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "As a Data Engineer, how much of my job can I automate away?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y38e6m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665691245.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Given years of experience can you limit your workday to &amp;lt; 3 hours?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "y38e6m", "is_robot_indexable": true, "report_reasons": null, "author": "Ricearoni33", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y38e6m/as_a_data_engineer_how_much_of_my_job_can_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y38e6m/as_a_data_engineer_how_much_of_my_job_can_i/", "subreddit_subscribers": 76386, "created_utc": 1665691245.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is an HR-focused, ATS-based service, including:\n\n1. **Full upgrade** of your resume/cv with achievement-based jobs content, grammar, flow, syntax and keyword optimization for ATS.\n2. Powerful professional **bio-intro** to immediately grab attention on your resume/cv.\n3. Complete resume/cv re-formatting to a clean, **professional design** praised by industry executives and HR managers.\n4. **Dynamic cover letter** created from scratch, tailored to you and easily editable for any job you apply to in the future.\n5. Eye-catching **LinkedIn content** primed to get you noticed and to leave an impression, plus a full multi-point profile inspection.\n\nThe Evidence:\n\nThe service has successfully supported **17,000+ professionals** in securing new jobs in their chosen fields.\n\n[ORDER HERE](https://www.reddit.com/user/mcgill83/comments/y3a9yd/resume_packages)", "author_fullname": "t2_rzhml6zz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\u2714\ufe0fProfessional Resume Writer At Your Service - Over 15 000 Positive Reviews (&lt;5 days delivery)\ud83d\udc47", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y3ai11", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.08, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665696104.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is an HR-focused, ATS-based service, including:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Full upgrade&lt;/strong&gt; of your resume/cv with achievement-based jobs content, grammar, flow, syntax and keyword optimization for ATS.&lt;/li&gt;\n&lt;li&gt;Powerful professional &lt;strong&gt;bio-intro&lt;/strong&gt; to immediately grab attention on your resume/cv.&lt;/li&gt;\n&lt;li&gt;Complete resume/cv re-formatting to a clean, &lt;strong&gt;professional design&lt;/strong&gt; praised by industry executives and HR managers.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Dynamic cover letter&lt;/strong&gt; created from scratch, tailored to you and easily editable for any job you apply to in the future.&lt;/li&gt;\n&lt;li&gt;Eye-catching &lt;strong&gt;LinkedIn content&lt;/strong&gt; primed to get you noticed and to leave an impression, plus a full multi-point profile inspection.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The Evidence:&lt;/p&gt;\n\n&lt;p&gt;The service has successfully supported &lt;strong&gt;17,000+ professionals&lt;/strong&gt; in securing new jobs in their chosen fields.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/user/mcgill83/comments/y3a9yd/resume_packages\"&gt;ORDER HERE&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "y3ai11", "is_robot_indexable": true, "report_reasons": null, "author": "mcgill83", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y3ai11/professional_resume_writer_at_your_service_over/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y3ai11/professional_resume_writer_at_your_service_over/", "subreddit_subscribers": 76386, "created_utc": 1665696104.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}