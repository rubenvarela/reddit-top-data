{"kind": "Listing", "data": {"after": "t3_y8m3ho", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_4tczv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "every time I hear someone say num-pee i die a little bit", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "meta", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_y7ycxz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 473, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meta", "can_mod_post": false, "score": 473, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/8ifUPQbWM946tcFz4Vg7wIPw5tcMaSuMpDdLm9qyyXo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666173070.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/aylc75laiqu91.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/aylc75laiqu91.png?auto=webp&amp;s=811d064f28c698d46d822b83b6b0e59ba36cf0ff", "width": 225, "height": 225}, "resolutions": [{"url": "https://preview.redd.it/aylc75laiqu91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=28c0ec8e54a7859652b0dc689287cd5298e7dec4", "width": 108, "height": 108}, {"url": "https://preview.redd.it/aylc75laiqu91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d9956e566ba76b8eec221428731f7170c360c21e", "width": 216, "height": 216}], "variants": {}, "id": "mXRYaAVfSayNzyW4E87Hes-sLP2gVI-6dqexq2_QSsc"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7ycxz", "is_robot_indexable": true, "report_reasons": null, "author": "MAFiA303", "discussion_type": null, "num_comments": 116, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7ycxz/every_time_i_hear_someone_say_numpee_i_die_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/aylc75laiqu91.png", "subreddit_subscribers": 814439, "created_utc": 1666173070.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Do you link to your Kaggle? Or perhaps your Github, which contains the underlying .ipynb files? I want to make sure I\u2019m communicating my work in a way that aligns with how other data science practitioners do it. \n\nThanks for your input!", "author_fullname": "t2_ceqh7wvy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you present your portfolio on LinkedIn?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y87smb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 38, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 38, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666198209.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you link to your Kaggle? Or perhaps your Github, which contains the underlying .ipynb files? I want to make sure I\u2019m communicating my work in a way that aligns with how other data science practitioners do it. &lt;/p&gt;\n\n&lt;p&gt;Thanks for your input!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "y87smb", "is_robot_indexable": true, "report_reasons": null, "author": "boston_acc", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y87smb/how_do_you_present_your_portfolio_on_linkedin/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y87smb/how_do_you_present_your_portfolio_on_linkedin/", "subreddit_subscribers": 814439, "created_utc": 1666198209.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am confused on how to build my portfolio or even what platforms to use.  I\u2019ve been overwhelmed and trying to find answers about this without much luck. \n\nIf I\u2019m trying to showcase SQL, R, Python, tableau and Microsoft excel, what are the best platforms and strategies for going about this?\n\nEdit: I\u2019m transitioning into data analysis", "author_fullname": "t2_t1en7quk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Structure Portfolio", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7u9ky", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666158466.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am confused on how to build my portfolio or even what platforms to use.  I\u2019ve been overwhelmed and trying to find answers about this without much luck. &lt;/p&gt;\n\n&lt;p&gt;If I\u2019m trying to showcase SQL, R, Python, tableau and Microsoft excel, what are the best platforms and strategies for going about this?&lt;/p&gt;\n\n&lt;p&gt;Edit: I\u2019m transitioning into data analysis&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7u9ky", "is_robot_indexable": true, "report_reasons": null, "author": "SeaRocks10", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7u9ky/how_to_structure_portfolio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7u9ky/how_to_structure_portfolio/", "subreddit_subscribers": 814439, "created_utc": 1666158466.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Dear fellow smart data expert \n\nI\u2019m working on this Ubereats project to measure/determine restaurant\u2019s success through these variables \nI\u2019ve these variables (restaurant ratings 1-6) ,(restaurant ratings count 1-7k) , (food hygiene ratings 1-5) (daily deals %) (spend $ )  (delivery fees $)\n\nWhat confuse me most is some restaurants have high ratings with low ratings counts \n\nCan\u2019t think further from this \n\nHelp \n\nThanks", "author_fullname": "t2_6ku703xx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I determine if a restaurant is doing well through these variables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y87aea", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666197013.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dear fellow smart data expert &lt;/p&gt;\n\n&lt;p&gt;I\u2019m working on this Ubereats project to measure/determine restaurant\u2019s success through these variables \nI\u2019ve these variables (restaurant ratings 1-6) ,(restaurant ratings count 1-7k) , (food hygiene ratings 1-5) (daily deals %) (spend $ )  (delivery fees $)&lt;/p&gt;\n\n&lt;p&gt;What confuse me most is some restaurants have high ratings with low ratings counts &lt;/p&gt;\n\n&lt;p&gt;Can\u2019t think further from this &lt;/p&gt;\n\n&lt;p&gt;Help &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y87aea", "is_robot_indexable": true, "report_reasons": null, "author": "Street-Target9245", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y87aea/how_can_i_determine_if_a_restaurant_is_doing_well/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y87aea/how_can_i_determine_if_a_restaurant_is_doing_well/", "subreddit_subscribers": 814439, "created_utc": 1666197013.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm new to data analysis and excel. I have a question to see how you all might address a problem I'm having. \n\nA group of 20 students take an exam. Some pass and some fail. Students who fail, retake the test a few days later. This continues until all students have passed the exam. \n\nI have data on the student name, pass/fail, date of exam, and exam attempt #. \n\nWhat's the best way to represent this data to show student performance over time? Ideally there would be some indication of exam attempt # on the graph/chart as well. \n\nThanks in advance for help and advice!", "author_fullname": "t2_40s55kmr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the best way to represent this data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y89tsj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666203006.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m new to data analysis and excel. I have a question to see how you all might address a problem I&amp;#39;m having. &lt;/p&gt;\n\n&lt;p&gt;A group of 20 students take an exam. Some pass and some fail. Students who fail, retake the test a few days later. This continues until all students have passed the exam. &lt;/p&gt;\n\n&lt;p&gt;I have data on the student name, pass/fail, date of exam, and exam attempt #. &lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the best way to represent this data to show student performance over time? Ideally there would be some indication of exam attempt # on the graph/chart as well. &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for help and advice!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y89tsj", "is_robot_indexable": true, "report_reasons": null, "author": "guppyguyco", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y89tsj/whats_the_best_way_to_represent_this_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y89tsj/whats_the_best_way_to_represent_this_data/", "subreddit_subscribers": 814439, "created_utc": 1666203006.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Im using the `refresh_token` &gt; `fetch new access_token` &gt; `make request` flow to fetch json data from Xero. \n\nBut for some reason providing the same tokens and credentials to tap-xero's config.json returns `tap_xero.client.XeroNotFoundError: HTTP-error-code: 404, Error: The resource you have specified cannot be found.`\n\nThe command args are: `tap-xero -c config.json -d &gt; cat.json`\n\nSinger's documentation is really lacking for their dedicated taps.", "author_fullname": "t2_n732f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone used Singer's tap-xero to fetch Xero data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y89cok", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666201883.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im using the &lt;code&gt;refresh_token&lt;/code&gt; &amp;gt; &lt;code&gt;fetch new access_token&lt;/code&gt; &amp;gt; &lt;code&gt;make request&lt;/code&gt; flow to fetch json data from Xero. &lt;/p&gt;\n\n&lt;p&gt;But for some reason providing the same tokens and credentials to tap-xero&amp;#39;s config.json returns &lt;code&gt;tap_xero.client.XeroNotFoundError: HTTP-error-code: 404, Error: The resource you have specified cannot be found.&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;The command args are: &lt;code&gt;tap-xero -c config.json -d &amp;gt; cat.json&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;Singer&amp;#39;s documentation is really lacking for their dedicated taps.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y89cok", "is_robot_indexable": true, "report_reasons": null, "author": "buckypimpin", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y89cok/has_anyone_used_singers_tapxero_to_fetch_xero_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y89cok/has_anyone_used_singers_tapxero_to_fetch_xero_data/", "subreddit_subscribers": 814439, "created_utc": 1666201883.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nHi mates\n\nI hope you are doing well.\n\nWould you please tell me the **difference between** the ***Retention*** and the ***Propensity*** models?  \nAs I understand, the propensity model has three types: **Propensity to buy**, **Propensity to churn**, and **Propensity to unsubscribe**.\n\nIs the **retention model** the same as the **propensity to churn**?\n\nThank you in advance", "author_fullname": "t2_8otyl3bx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Difference between Propensity model and Retention model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7ymoz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666173922.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi mates&lt;/p&gt;\n\n&lt;p&gt;I hope you are doing well.&lt;/p&gt;\n\n&lt;p&gt;Would you please tell me the &lt;strong&gt;difference between&lt;/strong&gt; the &lt;strong&gt;&lt;em&gt;Retention&lt;/em&gt;&lt;/strong&gt; and the &lt;strong&gt;&lt;em&gt;Propensity&lt;/em&gt;&lt;/strong&gt; models?&lt;br/&gt;\nAs I understand, the propensity model has three types: &lt;strong&gt;Propensity to buy&lt;/strong&gt;, &lt;strong&gt;Propensity to churn&lt;/strong&gt;, and &lt;strong&gt;Propensity to unsubscribe&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;Is the &lt;strong&gt;retention model&lt;/strong&gt; the same as the &lt;strong&gt;propensity to churn&lt;/strong&gt;?&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7ymoz", "is_robot_indexable": true, "report_reasons": null, "author": "Masoud_mirza", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7ymoz/difference_between_propensity_model_and_retention/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7ymoz/difference_between_propensity_model_and_retention/", "subreddit_subscribers": 814439, "created_utc": 1666173922.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am working on a project where we have users that perform a series of actions in a specific order, every day. I also have the delay between each action\n\nIf I know that at least a know of subset of users do not perform a fraudulent action. What is a possible way to know which users are fraudulent or at least start an investigation.\n\nI have many ideas but I don't know where to start and not sure my ideas make sense. Here they are:\n\n\\- create a markov chain using the historical data and tag users that do a series of action with low probability\n\n\\- create the markov chain and cluster it in one way or another (dont know how yet), then tag users that do not belong to a certain cluster\n\n\\- create a markov chain and use a graph neural network to do some sort of classification (dont know how I will proceed without labels)\n\nCan you please guide me, provide ressources or any kind of feedback or concept that can help me move forward. Thanks", "author_fullname": "t2_4fa0ibvk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Graph classification", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_y8kggy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666229306.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working on a project where we have users that perform a series of actions in a specific order, every day. I also have the delay between each action&lt;/p&gt;\n\n&lt;p&gt;If I know that at least a know of subset of users do not perform a fraudulent action. What is a possible way to know which users are fraudulent or at least start an investigation.&lt;/p&gt;\n\n&lt;p&gt;I have many ideas but I don&amp;#39;t know where to start and not sure my ideas make sense. Here they are:&lt;/p&gt;\n\n&lt;p&gt;- create a markov chain using the historical data and tag users that do a series of action with low probability&lt;/p&gt;\n\n&lt;p&gt;- create the markov chain and cluster it in one way or another (dont know how yet), then tag users that do not belong to a certain cluster&lt;/p&gt;\n\n&lt;p&gt;- create a markov chain and use a graph neural network to do some sort of classification (dont know how I will proceed without labels)&lt;/p&gt;\n\n&lt;p&gt;Can you please guide me, provide ressources or any kind of feedback or concept that can help me move forward. Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y8kggy", "is_robot_indexable": true, "report_reasons": null, "author": "dimem16", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y8kggy/graph_classification/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y8kggy/graph_classification/", "subreddit_subscribers": 814439, "created_utc": 1666229306.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey all, so I have a dataset with 8000 rows and 200+ features, mostly numerical. By looking at summary statistics, I see that a good chunk of these features (100ish) have zeroes for 75%+ of their entries. Seems to me like all these zeroes won't contain any useful info for an eventual model, and it would simplify my process a lot to reduce the dimensionality. Would it be wise to simply remove features like this and continue on my way or would I be missing out on lots of possible info? Maybe take all of these sparse columns and use PCA to hopefully reduce them to one or two principal components?", "author_fullname": "t2_d86jaoff", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Filtering out features?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y8fnsj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666216639.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, so I have a dataset with 8000 rows and 200+ features, mostly numerical. By looking at summary statistics, I see that a good chunk of these features (100ish) have zeroes for 75%+ of their entries. Seems to me like all these zeroes won&amp;#39;t contain any useful info for an eventual model, and it would simplify my process a lot to reduce the dimensionality. Would it be wise to simply remove features like this and continue on my way or would I be missing out on lots of possible info? Maybe take all of these sparse columns and use PCA to hopefully reduce them to one or two principal components?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y8fnsj", "is_robot_indexable": true, "report_reasons": null, "author": "Objective-Simple-836", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y8fnsj/filtering_out_features/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y8fnsj/filtering_out_features/", "subreddit_subscribers": 814439, "created_utc": 1666216639.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "There's a concept in graph theory, in particular when talking about tournaments, known as a median order, which is essentially an ordering of the vertices that maximizes the amount of edges pointing in the increasing direction with respect to the ordering.\n\nThis can be thought of multiplying the adjacency matrix by a permutation matrix on the right and on the left, such that the sum of the upper triangular part of the matrix is maximal.\n\nI've coded it as an integer program [github link here](https://github.com/alonso-cancino/median_orders), but the problem is really slow. I've been thinking if maybe it could be done with some sort of reinforcement learning procedure, where you'd input the adjacency matrix of the graph and it orders the rows/columns in such a way that maximices the upper triangular sum.\n\nIs this a viable strategy or is this one of those places where ML does not apply? Is there any good reference for trying to solve integer optimization problems with ML?", "author_fullname": "t2_8j3x0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this problem \"solvable\" with some ML technique?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y8ctq4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666209996.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There&amp;#39;s a concept in graph theory, in particular when talking about tournaments, known as a median order, which is essentially an ordering of the vertices that maximizes the amount of edges pointing in the increasing direction with respect to the ordering.&lt;/p&gt;\n\n&lt;p&gt;This can be thought of multiplying the adjacency matrix by a permutation matrix on the right and on the left, such that the sum of the upper triangular part of the matrix is maximal.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve coded it as an integer program &lt;a href=\"https://github.com/alonso-cancino/median_orders\"&gt;github link here&lt;/a&gt;, but the problem is really slow. I&amp;#39;ve been thinking if maybe it could be done with some sort of reinforcement learning procedure, where you&amp;#39;d input the adjacency matrix of the graph and it orders the rows/columns in such a way that maximices the upper triangular sum.&lt;/p&gt;\n\n&lt;p&gt;Is this a viable strategy or is this one of those places where ML does not apply? Is there any good reference for trying to solve integer optimization problems with ML?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Ah6w4nBNbPGP36O_njNAtcMATQmVY7Ul5UnwtVOKTm0.jpg?auto=webp&amp;s=a76366a3402c347763a45516a3e596c74737b1ed", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/Ah6w4nBNbPGP36O_njNAtcMATQmVY7Ul5UnwtVOKTm0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3916f66b61f9600c4d90738234d1e0a3e4e4d437", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/Ah6w4nBNbPGP36O_njNAtcMATQmVY7Ul5UnwtVOKTm0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c72f2e956ed5ea858865141458240b1f18146cb8", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/Ah6w4nBNbPGP36O_njNAtcMATQmVY7Ul5UnwtVOKTm0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8dbc48c0818783af329f8dde028dad84f5cb9b11", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/Ah6w4nBNbPGP36O_njNAtcMATQmVY7Ul5UnwtVOKTm0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a0f809d905f8a09e0c37d4b606670734e7cbfb60", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/Ah6w4nBNbPGP36O_njNAtcMATQmVY7Ul5UnwtVOKTm0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1e5361c376e5dcca8eac85bcf0b729a47aaa4aa3", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/Ah6w4nBNbPGP36O_njNAtcMATQmVY7Ul5UnwtVOKTm0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=27e5e2356ab0271b5a7d504c914070696b6e8a7b", "width": 1080, "height": 540}], "variants": {}, "id": "Wq9ag5G5LtLj5Qnn-YA2InyN3z_A52IZbamkEA_wXec"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y8ctq4", "is_robot_indexable": true, "report_reasons": null, "author": "Alozzk", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y8ctq4/is_this_problem_solvable_with_some_ml_technique/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y8ctq4/is_this_problem_solvable_with_some_ml_technique/", "subreddit_subscribers": 814439, "created_utc": 1666209996.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I don't get enough \u201cbad\u201d samples, because it\u2019s almost impossible and challenging for our customers to artificially capture defects (bad samples) in production. Without bad samples, we cannot create or optimize algorithms. \n\n&amp;#x200B;\n\nAny suggestions?", "author_fullname": "t2_t9mt0bic", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need more bad samples in order to create and optimize algorithms", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y8bzin", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666208013.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t get enough \u201cbad\u201d samples, because it\u2019s almost impossible and challenging for our customers to artificially capture defects (bad samples) in production. Without bad samples, we cannot create or optimize algorithms. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y8bzin", "is_robot_indexable": true, "report_reasons": null, "author": "alovna88", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y8bzin/i_need_more_bad_samples_in_order_to_create_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y8bzin/i_need_more_bad_samples_in_order_to_create_and/", "subreddit_subscribers": 814439, "created_utc": 1666208013.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, I have been trying to scrap the school schedule (for obvious reasons, of course). And so far, I saw coursicle claims that they get the data from \"Smith's public listing course\". I've tried to find it but no use, then I found a reddit post from the cofounder of coursicle himself saying that he ping the school gateway ([https://www.reddit.com/r/gatech/comments/r0datq/where\\_does\\_coursicle\\_get\\_its\\_class\\_seats\\_data\\_from/](https://www.reddit.com/r/gatech/comments/r0datq/where_does_coursicle_get_its_class_seats_data_from/)). I'm not sure whether I understand his idea right, but I can't find any way to access my school schedule without actually have to login in, which is a big deal when employ bot to server. So do you have any suggestion, or have any source that has college's courses available publicly, please let me know. Thank you\n\nhttps://preview.redd.it/m23sd3e6ssu91.png?width=907&amp;format=png&amp;auto=webp&amp;s=288959bf76d09287f908b4b019fa0890756c9c51", "author_fullname": "t2_eo1lh8sj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Public College schedule from Coursicle", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 16, "top_awarded_type": null, "hide_score": false, "media_metadata": {"m23sd3e6ssu91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 12, "x": 108, "u": "https://preview.redd.it/m23sd3e6ssu91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6f035c5a7fe36151c0497efd5b4c7266ba7bca5b"}, {"y": 25, "x": 216, "u": "https://preview.redd.it/m23sd3e6ssu91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f49e3225bd5cb82be7a0e1662a497a2cf33116ad"}, {"y": 38, "x": 320, "u": "https://preview.redd.it/m23sd3e6ssu91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=503a99350e3bfa9efeebe99f181cd505f09d7f4a"}, {"y": 76, "x": 640, "u": "https://preview.redd.it/m23sd3e6ssu91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=db7ff2816c4a6a1220dfbba36873020eb55aa599"}], "s": {"y": 109, "x": 907, "u": "https://preview.redd.it/m23sd3e6ssu91.png?width=907&amp;format=png&amp;auto=webp&amp;s=288959bf76d09287f908b4b019fa0890756c9c51"}, "id": "m23sd3e6ssu91"}}, "name": "t3_y88uyt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/-A-f9IFIg2xrA82oOkM5O_ESc1W53HXKOTUR4W59Z2A.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666200713.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I have been trying to scrap the school schedule (for obvious reasons, of course). And so far, I saw coursicle claims that they get the data from &amp;quot;Smith&amp;#39;s public listing course&amp;quot;. I&amp;#39;ve tried to find it but no use, then I found a reddit post from the cofounder of coursicle himself saying that he ping the school gateway (&lt;a href=\"https://www.reddit.com/r/gatech/comments/r0datq/where_does_coursicle_get_its_class_seats_data_from/\"&gt;https://www.reddit.com/r/gatech/comments/r0datq/where_does_coursicle_get_its_class_seats_data_from/&lt;/a&gt;). I&amp;#39;m not sure whether I understand his idea right, but I can&amp;#39;t find any way to access my school schedule without actually have to login in, which is a big deal when employ bot to server. So do you have any suggestion, or have any source that has college&amp;#39;s courses available publicly, please let me know. Thank you&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/m23sd3e6ssu91.png?width=907&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=288959bf76d09287f908b4b019fa0890756c9c51\"&gt;https://preview.redd.it/m23sd3e6ssu91.png?width=907&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=288959bf76d09287f908b4b019fa0890756c9c51&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y88uyt", "is_robot_indexable": true, "report_reasons": null, "author": "PiccoloStreet3002", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y88uyt/public_college_schedule_from_coursicle/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y88uyt/public_college_schedule_from_coursicle/", "subreddit_subscribers": 814439, "created_utc": 1666200713.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello all! \n\nI've been pretty excited reading about all the advancements in LLMs over the years but never took the time to dip my toes in. I'm also a PC gamer and waited until the gpu market dipped a bit to finally buy a RTX3080 and figured might as well get into some hobbyist ML/deep learning experimentation with a new GPU with so many CUDA cores. \n\nI'm aware its still nothing in comparison to an A100 or the like and that I might still be fairly limited working with any LLM, but wondering if anyone has any experience, tips or guidance on what's possible without a multi-gpu at-home setup, like what's the biggest model one could play with on a single 3080, what to expect in terms of process time per token, the biggest feasible model one could or should use to fine tune on a closed domain dataset, etc. \n\nIf I'm being completely unrealistic in even attempting to fine-tune an LLM locally, please also feel free to clear me of any dilusions. \n\nRegardless, it's still so fascinating to see all the developments in the space happening so quickly. This is a super exciting time we're living in, and hopefully these kinds of technologies will be more accessible to hobbyists as they're developed to require less compute and consume less energy.\n\nThanks in advance for any guidance!", "author_fullname": "t2_5z0my9eb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "At-home LLM experimentation questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y87bub", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666197106.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all! &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been pretty excited reading about all the advancements in LLMs over the years but never took the time to dip my toes in. I&amp;#39;m also a PC gamer and waited until the gpu market dipped a bit to finally buy a RTX3080 and figured might as well get into some hobbyist ML/deep learning experimentation with a new GPU with so many CUDA cores. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m aware its still nothing in comparison to an A100 or the like and that I might still be fairly limited working with any LLM, but wondering if anyone has any experience, tips or guidance on what&amp;#39;s possible without a multi-gpu at-home setup, like what&amp;#39;s the biggest model one could play with on a single 3080, what to expect in terms of process time per token, the biggest feasible model one could or should use to fine tune on a closed domain dataset, etc. &lt;/p&gt;\n\n&lt;p&gt;If I&amp;#39;m being completely unrealistic in even attempting to fine-tune an LLM locally, please also feel free to clear me of any dilusions. &lt;/p&gt;\n\n&lt;p&gt;Regardless, it&amp;#39;s still so fascinating to see all the developments in the space happening so quickly. This is a super exciting time we&amp;#39;re living in, and hopefully these kinds of technologies will be more accessible to hobbyists as they&amp;#39;re developed to require less compute and consume less energy.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for any guidance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y87bub", "is_robot_indexable": true, "report_reasons": null, "author": "smarthaiti", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y87bub/athome_llm_experimentation_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y87bub/athome_llm_experimentation_questions/", "subreddit_subscribers": 814439, "created_utc": 1666197106.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I was wondering if anyone can provide me with a roadmap or courses I can take that will give me a good chance of landing a data science job. \n\nI am almost done with my first Machine Learning specialization on Coursera. I found that I already knew a lot of the statistical concepts due to my career in actuarial science which is heavy on stats. However, I did not feel like their was enough practice with python as most of the code was given to you in the assignments. So I wouldn\u2019t feel confident saying I can implement a neural network from start to finish for example. Is that expected?\n\nAny tips are appreciated!", "author_fullname": "t2_1z6uqvx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career switch into data science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_y8m3yw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666233866.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was wondering if anyone can provide me with a roadmap or courses I can take that will give me a good chance of landing a data science job. &lt;/p&gt;\n\n&lt;p&gt;I am almost done with my first Machine Learning specialization on Coursera. I found that I already knew a lot of the statistical concepts due to my career in actuarial science which is heavy on stats. However, I did not feel like their was enough practice with python as most of the code was given to you in the assignments. So I wouldn\u2019t feel confident saying I can implement a neural network from start to finish for example. Is that expected?&lt;/p&gt;\n\n&lt;p&gt;Any tips are appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y8m3yw", "is_robot_indexable": true, "report_reasons": null, "author": "examfml", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y8m3yw/career_switch_into_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y8m3yw/career_switch_into_data_science/", "subreddit_subscribers": 814439, "created_utc": 1666233866.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Business Objective - The company started a LTIP (long term incentive program) to compensate the employees as a replacement of stocks and finance team wants to track the program and **figure out if the plan is effective in keeping the talent at the company.** How do I figure out if this program **caused** the turnover rate to drop?\n\nThis program is very new and the data we have is the performance of each individual. For example, the units assigned to each employee but have never looked/tracked at how they are been distributed as per employee.\n\nHow units are assigned? On the day of January 1st of each year, each employee gets certain LTIP unit (1 unit = 1USD). But the number of units each employee gets is dependent on the manager and number of team members under manager.\n\nAll the units are vested after 3rd year. Price of unit is dependent on how the company grows.\n\nHow the amount is calculated?Let\u2019s say I receive a 1000 units on Jan 1st, 2019 and the company grew 150% across 3 years. On Jan 1st 2022, the amount will be 1500$ compared to 1000$ in 2019.", "author_fullname": "t2_rochx4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to do analysis on this data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_y8lop0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666232671.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Business Objective - The company started a LTIP (long term incentive program) to compensate the employees as a replacement of stocks and finance team wants to track the program and &lt;strong&gt;figure out if the plan is effective in keeping the talent at the company.&lt;/strong&gt; How do I figure out if this program &lt;strong&gt;caused&lt;/strong&gt; the turnover rate to drop?&lt;/p&gt;\n\n&lt;p&gt;This program is very new and the data we have is the performance of each individual. For example, the units assigned to each employee but have never looked/tracked at how they are been distributed as per employee.&lt;/p&gt;\n\n&lt;p&gt;How units are assigned? On the day of January 1st of each year, each employee gets certain LTIP unit (1 unit = 1USD). But the number of units each employee gets is dependent on the manager and number of team members under manager.&lt;/p&gt;\n\n&lt;p&gt;All the units are vested after 3rd year. Price of unit is dependent on how the company grows.&lt;/p&gt;\n\n&lt;p&gt;How the amount is calculated?Let\u2019s say I receive a 1000 units on Jan 1st, 2019 and the company grew 150% across 3 years. On Jan 1st 2022, the amount will be 1500$ compared to 1000$ in 2019.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y8lop0", "is_robot_indexable": true, "report_reasons": null, "author": "yashk1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y8lop0/how_to_do_analysis_on_this_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y8lop0/how_to_do_analysis_on_this_data/", "subreddit_subscribers": 814439, "created_utc": 1666232671.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I want to set up some Python scripts to run automatically on a recurring basis, dump to .csv, upload to a Snowflake database. Pretty simple. In my professional life I\u2019m familiar with Alteryx but it\u2019s way too expensive for me to buy a personal license lol. What lower cost alternatives are out there? I\u2019ve been looking at stuff like Cascade, Stitch, and Tableau Prep, but I\u2019m feeling a little lost so hoped to just get some recommendations from any folks with experience here\u2026 thank you in advance for any insights!", "author_fullname": "t2_535x4dqy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Software recommendations to set up automated Python jobs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_y8lnjn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666232578.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to set up some Python scripts to run automatically on a recurring basis, dump to .csv, upload to a Snowflake database. Pretty simple. In my professional life I\u2019m familiar with Alteryx but it\u2019s way too expensive for me to buy a personal license lol. What lower cost alternatives are out there? I\u2019ve been looking at stuff like Cascade, Stitch, and Tableau Prep, but I\u2019m feeling a little lost so hoped to just get some recommendations from any folks with experience here\u2026 thank you in advance for any insights!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y8lnjn", "is_robot_indexable": true, "report_reasons": null, "author": "vizualbasic", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y8lnjn/software_recommendations_to_set_up_automated/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y8lnjn/software_recommendations_to_set_up_automated/", "subreddit_subscribers": 814439, "created_utc": 1666232578.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Did you work remotely or do you know any data scientist that worked remotely before the pandemic? If so, how common was it?", "author_fullname": "t2_k82la2mu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Were remote jobs common in data science/data analytics before the pandemic?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_y8kxrh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666230596.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Did you work remotely or do you know any data scientist that worked remotely before the pandemic? If so, how common was it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y8kxrh", "is_robot_indexable": true, "report_reasons": null, "author": "benedick2", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y8kxrh/were_remote_jobs_common_in_data_sciencedata/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y8kxrh/were_remote_jobs_common_in_data_sciencedata/", "subreddit_subscribers": 814439, "created_utc": 1666230596.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I want to create signature recognition, they have two input sources, one is the signature in plain paper the other is the signature from ID Card. \n\nCurrently my preprocessing for plain paper is converting to gray, using HSV threshold to remove, remove noise by blurring, cropping with boundingRect\n\nThis has the benefits that all input will have the same format. But Is it too much, or maybe can cause it to unable to generalize?", "author_fullname": "t2_ktg7qk2l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much preprocessing is too much (Image Preprocessing)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_y8kwyb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666230530.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to create signature recognition, they have two input sources, one is the signature in plain paper the other is the signature from ID Card. &lt;/p&gt;\n\n&lt;p&gt;Currently my preprocessing for plain paper is converting to gray, using HSV threshold to remove, remove noise by blurring, cropping with boundingRect&lt;/p&gt;\n\n&lt;p&gt;This has the benefits that all input will have the same format. But Is it too much, or maybe can cause it to unable to generalize?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y8kwyb", "is_robot_indexable": true, "report_reasons": null, "author": "chervilious", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y8kwyb/how_much_preprocessing_is_too_much_image/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y8kwyb/how_much_preprocessing_is_too_much_image/", "subreddit_subscribers": 814439, "created_utc": 1666230530.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a free account and I've made some visualizations to share with my linkedin network. I plan to save it on github. What is the best way to share it ?\n\ni can't embed it, it won't allow me on my free account.", "author_fullname": "t2_13t60b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is a best way to share powerBI reports to Github ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_y8ksmj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666230196.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a free account and I&amp;#39;ve made some visualizations to share with my linkedin network. I plan to save it on github. What is the best way to share it ?&lt;/p&gt;\n\n&lt;p&gt;i can&amp;#39;t embed it, it won&amp;#39;t allow me on my free account.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y8ksmj", "is_robot_indexable": true, "report_reasons": null, "author": "drugsarebadmky", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y8ksmj/what_is_a_best_way_to_share_powerbi_reports_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y8ksmj/what_is_a_best_way_to_share_powerbi_reports_to/", "subreddit_subscribers": 814439, "created_utc": 1666230196.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Pretty unsophisticated data person here. I work in housing/urban planning so mostly work with census/county assessor parcel data to examine neighborhood housing market trends/indicators. Starting to feel like there might be a better tool for doing more sophisticated analysis than excel. Maybe SPSS? Thoughts?", "author_fullname": "t2_r38s8kc8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Next step up from excel for data analysis?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y8azf0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666205709.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Pretty unsophisticated data person here. I work in housing/urban planning so mostly work with census/county assessor parcel data to examine neighborhood housing market trends/indicators. Starting to feel like there might be a better tool for doing more sophisticated analysis than excel. Maybe SPSS? Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y8azf0", "is_robot_indexable": true, "report_reasons": null, "author": "theEarnestUrbanist", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y8azf0/next_step_up_from_excel_for_data_analysis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y8azf0/next_step_up_from_excel_for_data_analysis/", "subreddit_subscribers": 814439, "created_utc": 1666205709.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "*(I apologize in advance if this is the wrong forum for my question. I'm not entirely sure where to direct it.)*\n\n**Background:**  \nI'm a business professor in Boston, and I expect to be awarded tenure this spring. I also expect my teaching and service demands to reduce quite a bit in the next year. I would like to use this sudden flexibility to begin developing my technical and data skills, which are severely lacking. I am fine with a long-term pursuit (2+ years). I teach undergraduate analytics, but in a very applied and simple way (e.g., Google Analytics, SPSS, linear regression, binary logistic regression, cluster analysis, etc.).\n\n**What I'm looking for:**  \nMy priorities in developing a side hustle are as such (in this order):\n\n1. Gain career flexibility. My PhD currently limits me to academia.\n2. Gain some opportunities for freelance consulting.\n3. Improve my capacity to build interesting datasets that could help my research and my students.\n4. Develop a more visible skillset that I can publicly showcase (this is understandably vague). Long-term ambitions are to build more of an online presence oriented around an in-demand skillset.\n\n**Ideas:**  \nSome areas that I am brainstorming:\n\n1. Machine Learning (Not sure what this industry looks like, so may be a naiive idea)\n2. Data engineering (could help me build unique datasets, but would not have access to servers)\n3. Web development\n4. Data visualization\n5. Data science (I understand that some of the topics above fall under this category)\n\nAll of these topics have equal intuitive appeal to me. My problem is that I do not fully understand the dynamics of these industries, as I've been tucked away in my academic bubble plugging away at my personal research projects. I am looking to break out of this bubble a bit, while also holding onto the security it provides (not looking to leave academia anytime soon).\n\nWould love any insights you may have to offer!", "author_fullname": "t2_1ybsrlm1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help me pick a side hustle", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y85i96", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666192813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;em&gt;(I apologize in advance if this is the wrong forum for my question. I&amp;#39;m not entirely sure where to direct it.)&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Background:&lt;/strong&gt;&lt;br/&gt;\nI&amp;#39;m a business professor in Boston, and I expect to be awarded tenure this spring. I also expect my teaching and service demands to reduce quite a bit in the next year. I would like to use this sudden flexibility to begin developing my technical and data skills, which are severely lacking. I am fine with a long-term pursuit (2+ years). I teach undergraduate analytics, but in a very applied and simple way (e.g., Google Analytics, SPSS, linear regression, binary logistic regression, cluster analysis, etc.).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What I&amp;#39;m looking for:&lt;/strong&gt;&lt;br/&gt;\nMy priorities in developing a side hustle are as such (in this order):&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Gain career flexibility. My PhD currently limits me to academia.&lt;/li&gt;\n&lt;li&gt;Gain some opportunities for freelance consulting.&lt;/li&gt;\n&lt;li&gt;Improve my capacity to build interesting datasets that could help my research and my students.&lt;/li&gt;\n&lt;li&gt;Develop a more visible skillset that I can publicly showcase (this is understandably vague). Long-term ambitions are to build more of an online presence oriented around an in-demand skillset.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;Ideas:&lt;/strong&gt;&lt;br/&gt;\nSome areas that I am brainstorming:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Machine Learning (Not sure what this industry looks like, so may be a naiive idea)&lt;/li&gt;\n&lt;li&gt;Data engineering (could help me build unique datasets, but would not have access to servers)&lt;/li&gt;\n&lt;li&gt;Web development&lt;/li&gt;\n&lt;li&gt;Data visualization&lt;/li&gt;\n&lt;li&gt;Data science (I understand that some of the topics above fall under this category)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;All of these topics have equal intuitive appeal to me. My problem is that I do not fully understand the dynamics of these industries, as I&amp;#39;ve been tucked away in my academic bubble plugging away at my personal research projects. I am looking to break out of this bubble a bit, while also holding onto the security it provides (not looking to leave academia anytime soon).&lt;/p&gt;\n\n&lt;p&gt;Would love any insights you may have to offer!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y85i96", "is_robot_indexable": true, "report_reasons": null, "author": "iscurred", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y85i96/help_me_pick_a_side_hustle/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y85i96/help_me_pick_a_side_hustle/", "subreddit_subscribers": 814439, "created_utc": 1666192813.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have some mixed data that I thought I'd first transform into embeddings and then cluster the embedding. However, since I'm clustering embeddings does that mean that I'm going to lose all interpretability of the clusters? I know there's some loss of interpreability when using embeddings but I'm not clear on what the degree of that loss is. Anyone care to clarify?", "author_fullname": "t2_5ox025vb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Clustering embeddings", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y82y0u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666186559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have some mixed data that I thought I&amp;#39;d first transform into embeddings and then cluster the embedding. However, since I&amp;#39;m clustering embeddings does that mean that I&amp;#39;m going to lose all interpretability of the clusters? I know there&amp;#39;s some loss of interpreability when using embeddings but I&amp;#39;m not clear on what the degree of that loss is. Anyone care to clarify?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y82y0u", "is_robot_indexable": true, "report_reasons": null, "author": "SomaDomaBoma", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y82y0u/clustering_embeddings/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y82y0u/clustering_embeddings/", "subreddit_subscribers": 814439, "created_utc": 1666186559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "hello,\n\nI'm planning on using the shortened version of the [schwartz value survey](https://www.framevoicereport.org/media/1093/the-short-schwartzs-value-survey.pdf) (SSVS) in my master's thesis. there are 10 basic human values and participants rate each of them on a likert-scale (0 to 8). I will later relate this survey data to some behavior of the participants *(like \"participants who value conformity behave like this\")* \\-but, I am completely lost on how to analyze the survey data. I guess I need to create a score for each participant, but is it possible? or logical? *(values have a circumplex structure -each value is similar to one other while also being the opposite of another. so yielding just one score per individual seems like it wouldn't make sense? like they would cancel each other out somehow? i don't know)*\n\nusing factor analysis, the 10 values can be reduced into a couple (?) of dimensions (I guess). but would that lead to a score? or a score with two dimensions (like a point coordinate in xy-axis)? \n\ndoes anybody have any clue? help.........please?", "author_fullname": "t2_664rqg0i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "schwartz value survey -analysis", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y800ys", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666178445.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hello,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m planning on using the shortened version of the &lt;a href=\"https://www.framevoicereport.org/media/1093/the-short-schwartzs-value-survey.pdf\"&gt;schwartz value survey&lt;/a&gt; (SSVS) in my master&amp;#39;s thesis. there are 10 basic human values and participants rate each of them on a likert-scale (0 to 8). I will later relate this survey data to some behavior of the participants &lt;em&gt;(like &amp;quot;participants who value conformity behave like this&amp;quot;)&lt;/em&gt; -but, I am completely lost on how to analyze the survey data. I guess I need to create a score for each participant, but is it possible? or logical? &lt;em&gt;(values have a circumplex structure -each value is similar to one other while also being the opposite of another. so yielding just one score per individual seems like it wouldn&amp;#39;t make sense? like they would cancel each other out somehow? i don&amp;#39;t know)&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;using factor analysis, the 10 values can be reduced into a couple (?) of dimensions (I guess). but would that lead to a score? or a score with two dimensions (like a point coordinate in xy-axis)? &lt;/p&gt;\n\n&lt;p&gt;does anybody have any clue? help.........please?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y800ys", "is_robot_indexable": true, "report_reasons": null, "author": "cauliflowingo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y800ys/schwartz_value_survey_analysis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y800ys/schwartz_value_survey_analysis/", "subreddit_subscribers": 814439, "created_utc": 1666178445.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Assumptions before performing tests", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7zsrk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_6wfy9q4l", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "rstats", "selftext": "For example, I want to run an Anova test. \n\nDo I need to check if the data qualifies all assumptions?\n\nWhat do I do when the data does not fulfill any of the assumptions? \n\nWhat is the best way to confirm a normal distribution before such tests? Is a qqplot good enough?", "author_fullname": "t2_6wfy9q4l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Assumptions before performing tests", "link_flair_richtext": [], "subreddit_name_prefixed": "r/rstats", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7ex5k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666117965.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.rstats", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For example, I want to run an Anova test. &lt;/p&gt;\n\n&lt;p&gt;Do I need to check if the data qualifies all assumptions?&lt;/p&gt;\n\n&lt;p&gt;What do I do when the data does not fulfill any of the assumptions? &lt;/p&gt;\n\n&lt;p&gt;What is the best way to confirm a normal distribution before such tests? Is a qqplot good enough?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r8n0", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7ex5k", "is_robot_indexable": true, "report_reasons": null, "author": "1SageK1", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/rstats/comments/y7ex5k/assumptions_before_performing_tests/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/rstats/comments/y7ex5k/assumptions_before_performing_tests/", "subreddit_subscribers": 67769, "created_utc": 1666117965.0, "num_crossposts": 3, "media": null, "is_video": false}], "created": 1666177732.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.rstats", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/rstats/comments/y7ex5k/assumptions_before_performing_tests/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7zsrk", "is_robot_indexable": true, "report_reasons": null, "author": "1SageK1", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_y7ex5k", "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7zsrk/assumptions_before_performing_tests/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/rstats/comments/y7ex5k/assumptions_before_performing_tests/", "subreddit_subscribers": 814439, "created_utc": 1666177732.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I was wondering if anyone can provide me with a roadmap or courses I can take that will give me a good chance of landing a data science job. \n\nI am almost done with my first Machine Learning specialization on Coursera. I found that I already knew a lot of the statistical concepts due to my career in actuarial science which is heavy on stats. However, I did not feel like their was enough practice with python as most of the code was given to you in the assignments. So I wouldn\u2019t feel confident saying I can implement a neural network from start to finish for example. Is that expected?\n\nAny tips are appreciated!", "author_fullname": "t2_1z6uqvx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career switch into data science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_y8m3ho", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666233828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was wondering if anyone can provide me with a roadmap or courses I can take that will give me a good chance of landing a data science job. &lt;/p&gt;\n\n&lt;p&gt;I am almost done with my first Machine Learning specialization on Coursera. I found that I already knew a lot of the statistical concepts due to my career in actuarial science which is heavy on stats. However, I did not feel like their was enough practice with python as most of the code was given to you in the assignments. So I wouldn\u2019t feel confident saying I can implement a neural network from start to finish for example. Is that expected?&lt;/p&gt;\n\n&lt;p&gt;Any tips are appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y8m3ho", "is_robot_indexable": true, "report_reasons": null, "author": "examfml", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y8m3ho/career_switch_into_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y8m3ho/career_switch_into_data_science/", "subreddit_subscribers": 814439, "created_utc": 1666233828.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}