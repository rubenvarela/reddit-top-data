{"kind": "Listing", "data": {"after": "t3_yddind", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6pc6xjl3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "U.K. gov consider this a decent package for a Lead DE\u2026", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_yd28wn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 147, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 147, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/U516ly52f6ctuog4RwKMKHcwzKLaq59pVIaSzphWkM8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666696559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/q5oli442rxv91.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/q5oli442rxv91.jpg?auto=webp&amp;s=5048f997709278782cdf525acddd8c778685669f", "width": 1170, "height": 1337}, "resolutions": [{"url": "https://preview.redd.it/q5oli442rxv91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=88b112df9828dd6038eadc65597be0eee38a4455", "width": 108, "height": 123}, {"url": "https://preview.redd.it/q5oli442rxv91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f50d43f8cfc9f68e9e5cd102f649275b7fbfb3f7", "width": 216, "height": 246}, {"url": "https://preview.redd.it/q5oli442rxv91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b802427eabe8990bd3f15015df75e51b4ec80ca1", "width": 320, "height": 365}, {"url": "https://preview.redd.it/q5oli442rxv91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b84f4f3789e0192286e677da5bf131d67b0d5e51", "width": 640, "height": 731}, {"url": "https://preview.redd.it/q5oli442rxv91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=05d81880dc1199fc8f47e3d8a36bc2c4419d7098", "width": 960, "height": 1097}, {"url": "https://preview.redd.it/q5oli442rxv91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3b4ca6cc6bb1ca75138d504edf61e2e65816e2f9", "width": 1080, "height": 1234}], "variants": {}, "id": "1poI9XFqPqr6oMYqs6Bdh9CVKPR-52T1rRerEOrZsug"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yd28wn", "is_robot_indexable": true, "report_reasons": null, "author": "tawaiii", "discussion_type": null, "num_comments": 76, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yd28wn/uk_gov_consider_this_a_decent_package_for_a_lead/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/q5oli442rxv91.jpg", "subreddit_subscribers": 77750, "created_utc": 1666696559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Terminology wise, one does the load before the transformation and one does it after. \n\nBut this doesn\u2019t make much sense to me and why it\u2019s so important?\n\nDoes order matter? And for which case is what option better?\n\nIn theory, I have a snowflake warehouse. In one I get data and then transform it and then load it somewhere else\n\nConversely, I can get data, load it into a database and then transform it?", "author_fullname": "t2_7ddbtrz1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ELT vs ETL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycqulb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 62, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 62, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666656815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Terminology wise, one does the load before the transformation and one does it after. &lt;/p&gt;\n\n&lt;p&gt;But this doesn\u2019t make much sense to me and why it\u2019s so important?&lt;/p&gt;\n\n&lt;p&gt;Does order matter? And for which case is what option better?&lt;/p&gt;\n\n&lt;p&gt;In theory, I have a snowflake warehouse. In one I get data and then transform it and then load it somewhere else&lt;/p&gt;\n\n&lt;p&gt;Conversely, I can get data, load it into a database and then transform it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ycqulb", "is_robot_indexable": true, "report_reasons": null, "author": "relentless_bull_", "discussion_type": null, "num_comments": 51, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycqulb/elt_vs_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycqulb/elt_vs_etl/", "subreddit_subscribers": 77750, "created_utc": 1666656815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been working with dbt for the last couple of years and I would never go back to the way things were before, idempotent, source controlled code with  CI/CD really changed things. \n\nI was wondering, is there a technology out there that is doing the same thing for Reporting and Dashboarding? Currently I'm using Power BI, and it gets the job done, but afaik, there is no way to have source control, at least without any hacks.", "author_fullname": "t2_9d1jjuxh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "a dbt equivalent for visualization?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycxeq6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666677748.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working with dbt for the last couple of years and I would never go back to the way things were before, idempotent, source controlled code with  CI/CD really changed things. &lt;/p&gt;\n\n&lt;p&gt;I was wondering, is there a technology out there that is doing the same thing for Reporting and Dashboarding? Currently I&amp;#39;m using Power BI, and it gets the job done, but afaik, there is no way to have source control, at least without any hacks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ycxeq6", "is_robot_indexable": true, "report_reasons": null, "author": "boggle_thy_mind", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycxeq6/a_dbt_equivalent_for_visualization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycxeq6/a_dbt_equivalent_for_visualization/", "subreddit_subscribers": 77750, "created_utc": 1666677748.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Or your parents, spouce, sibling, or someone who is just not technical in general", "author_fullname": "t2_c2wij", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you explain SQL at a party?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycz8st", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666685190.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Or your parents, spouce, sibling, or someone who is just not technical in general&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ycz8st", "is_robot_indexable": true, "report_reasons": null, "author": "Wh0_am_1", "discussion_type": null, "num_comments": 71, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycz8st/how_would_you_explain_sql_at_a_party/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycz8st/how_would_you_explain_sql_at_a_party/", "subreddit_subscribers": 77750, "created_utc": 1666685190.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I wrote a blog post on smoke-testing data pipelines: [https://dagster.io/blog/smoke-test-data-pipeline](https://dagster.io/blog/smoke-test-data-pipeline).\n\n&amp;#x200B;\n\nI used this heavily as an ML engineer / DE at Motive (nee KeepTruckin).\n\n&amp;#x200B;\n\nHere's the TLDR:\n\n* The idea of the data pipeline smoke test is to automatically run all your Pandas/PySpark/SQL data transformations on empty or synthetic data.\n* When defining your data pipeline, you include metadata on your data assets - e.g., column schemas - that determines how to mock them in downstream transformations.\n* The advantage of smoke tests is that you write them just once: you don\u2019t need to write a test for every newly derived data asset.\n* If your smoke test can execute quickly, it can become part of your dev loop and help you catch issues much more quickly than you would if you were executing on full data or writing a unit test.", "author_fullname": "t2_1jjs655y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Smoke tests for data pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycq87y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666655018.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wrote a blog post on smoke-testing data pipelines: &lt;a href=\"https://dagster.io/blog/smoke-test-data-pipeline\"&gt;https://dagster.io/blog/smoke-test-data-pipeline&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I used this heavily as an ML engineer / DE at Motive (nee KeepTruckin).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the TLDR:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The idea of the data pipeline smoke test is to automatically run all your Pandas/PySpark/SQL data transformations on empty or synthetic data.&lt;/li&gt;\n&lt;li&gt;When defining your data pipeline, you include metadata on your data assets - e.g., column schemas - that determines how to mock them in downstream transformations.&lt;/li&gt;\n&lt;li&gt;The advantage of smoke tests is that you write them just once: you don\u2019t need to write a test for every newly derived data asset.&lt;/li&gt;\n&lt;li&gt;If your smoke test can execute quickly, it can become part of your dev loop and help you catch issues much more quickly than you would if you were executing on full data or writing a unit test.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/PAOa0yKSko47lIi7At6Qv-MiqN692lWZHS95v4sznB0.jpg?auto=webp&amp;s=e9cc383395dc438c3eea16815fc12f1778b197e5", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/PAOa0yKSko47lIi7At6Qv-MiqN692lWZHS95v4sznB0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4e7616b5ef090ce54cd4d6a3e46f867f90464bdd", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/PAOa0yKSko47lIi7At6Qv-MiqN692lWZHS95v4sznB0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6fe5b1e0dd5a961496d33b297c9ec8b15aff4889", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/PAOa0yKSko47lIi7At6Qv-MiqN692lWZHS95v4sznB0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=511adede696708c58a8a3ddfc673dec17768e988", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/PAOa0yKSko47lIi7At6Qv-MiqN692lWZHS95v4sznB0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=00928a143e6c40ab6ecbf6f4a01568e55c862172", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/PAOa0yKSko47lIi7At6Qv-MiqN692lWZHS95v4sznB0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e5ff4ac52ddb5161e49bc5c4830694960d20fc02", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/PAOa0yKSko47lIi7At6Qv-MiqN692lWZHS95v4sznB0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7774ff0359446b714c3d7e03503648742752c8f5", "width": 1080, "height": 567}], "variants": {}, "id": "M_lWKOkMiwYDXj9qpLLfNIIeEBz7A4nvy6zVzisia-k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "ycq87y", "is_robot_indexable": true, "report_reasons": null, "author": "FrequentAthlete", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycq87y/smoke_tests_for_data_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycq87y/smoke_tests_for_data_pipelines/", "subreddit_subscribers": 77750, "created_utc": 1666655018.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_anyz9dbz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you do when your data pipeline depends on someone else\u2019s pipeline and that upstream pipeline fails?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_ydg0g9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 1200, "fallback_url": "https://v.redd.it/rbl58o15q0w91/DASH_480.mp4?source=fallback", "height": 480, "width": 480, "scrubber_media_url": "https://v.redd.it/rbl58o15q0w91/DASH_96.mp4", "dash_url": "https://v.redd.it/rbl58o15q0w91/DASHPlaylist.mpd?a=1669333664%2COTRmMjkxMzk3MWU3OWMyYzc0YmY0MTg0ZmZiYTQ4ZmFmNjFlODllOGQxYWIyMDI0ZGIyMmNiYWQ3OWJkYzMxYQ%3D%3D&amp;v=1&amp;f=sd", "duration": 9, "hls_url": "https://v.redd.it/rbl58o15q0w91/HLSPlaylist.m3u8?a=1669333664%2CNzRkYzA4YWM3OTY3ZWRkMmU2NDc3Yzc4NjdiODI3MTYxZDAzNGIwOGVjYWQ4YTI1OGRiYmFmMDk2YzFkMzU3Nw%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/QjEC_cURE42AfrncU9uBn8xTfO_V_IBSLGF8bxScrtA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666732599.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/rbl58o15q0w91", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/HV5BVVsGXLrhk-lwml9mvBh3vdK8uEZKxa_f9Mjd1nw.png?format=pjpg&amp;auto=webp&amp;s=fdd6fca210cf305e0bc8ccb860e7a4de59b49fdf", "width": 480, "height": 480}, "resolutions": [{"url": "https://external-preview.redd.it/HV5BVVsGXLrhk-lwml9mvBh3vdK8uEZKxa_f9Mjd1nw.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=a73c83be2768b03b03a1805ca02ab757286832fc", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/HV5BVVsGXLrhk-lwml9mvBh3vdK8uEZKxa_f9Mjd1nw.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=cae283a12c293345ddf62c4e421d20206831846d", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/HV5BVVsGXLrhk-lwml9mvBh3vdK8uEZKxa_f9Mjd1nw.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=c7fe9445e161c6054b92620a744423932669fda9", "width": 320, "height": 320}], "variants": {}, "id": "6PjWrLpAl3G16r_b35yJxv6RyPIPmepaViFCmRXrJ3o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "ydg0g9", "is_robot_indexable": true, "report_reasons": null, "author": "tchungry", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ydg0g9/what_do_you_do_when_your_data_pipeline_depends_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/rbl58o15q0w91", "subreddit_subscribers": 77750, "created_utc": 1666732599.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 1200, "fallback_url": "https://v.redd.it/rbl58o15q0w91/DASH_480.mp4?source=fallback", "height": 480, "width": 480, "scrubber_media_url": "https://v.redd.it/rbl58o15q0w91/DASH_96.mp4", "dash_url": "https://v.redd.it/rbl58o15q0w91/DASHPlaylist.mpd?a=1669333664%2COTRmMjkxMzk3MWU3OWMyYzc0YmY0MTg0ZmZiYTQ4ZmFmNjFlODllOGQxYWIyMDI0ZGIyMmNiYWQ3OWJkYzMxYQ%3D%3D&amp;v=1&amp;f=sd", "duration": 9, "hls_url": "https://v.redd.it/rbl58o15q0w91/HLSPlaylist.m3u8?a=1669333664%2CNzRkYzA4YWM3OTY3ZWRkMmU2NDc3Yzc4NjdiODI3MTYxZDAzNGIwOGVjYWQ4YTI1OGRiYmFmMDk2YzFkMzU3Nw%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do you experience the same thing? I work for an infra team in a data org, and it seems like the researchers don\u2019t understand basic engineering processes like:\n\n- how to use git\n\n- how to modularize their Python code\n\n- how to not perform full table scan\n\netc.", "author_fullname": "t2_4p45n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it just my feelings or many scientists/analysts don\u2019t know proper engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yd8goa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666713893.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you experience the same thing? I work for an infra team in a data org, and it seems like the researchers don\u2019t understand basic engineering processes like:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;how to use git&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;how to modularize their Python code&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;how to not perform full table scan&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yd8goa", "is_robot_indexable": true, "report_reasons": null, "author": "pinpinbo", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yd8goa/is_it_just_my_feelings_or_many_scientistsanalysts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yd8goa/is_it_just_my_feelings_or_many_scientistsanalysts/", "subreddit_subscribers": 77750, "created_utc": 1666713893.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So for the last 3 months, my time has been almost solely dedicated to interviewing, onboarding, and training new people at my work. Throughout the whole process, I\u2019ve been able to identify a couple patterns that I think would be useful to work on before going into interviews or if you are looking to have better chances at getting hired at popular companies.\n\nNeedless to say, these are my opinions alone and should be taken with a grain of salt. I might be a Sr. engineer but I still have much to learn and my experiences might be not a true reflection of the market.\n\n# Things To Consider:\n\n* This is more specific for boot camp grads. An interviewer will see the same \"Airflow pipeline with &lt;insert name of free API  here&gt; data\" project a million times with the same structure, tests, and GitHub readme. A lot of bootcamps (and online courses) tend to steer their students to reuse projects from previous years over and over, which leaves you at a huge disadvantage. If you think this is you, take the time to work on other things.  \n\n* I thought everyone knew this but obviously, some missed the memo. Data engineering is not exempt from TDD practices. If can't talk about testing during the interview, this is a massive red flag.  \n\n* Unwillingness to learn SWE concepts/topics will hurt you in the long run. It will not make it easy to interview at companies where Data Engineers are treated as specialized software engineers, or where you are expected to work with other engineers (Backend, DevOps, Architecture, Networking, etc).   \n\n* Focus on collaboration during technical interviews. Getting to the right answer is great, but a lot of companies will not consider you if you don't communicate with whoever is interviewing you. Being silent during the entire coding session makes it awkward and makes interviewers think you won't be a good fit in a collaborative team.   \n\n* For the love of god, come prepared with questions before an interview. And something else besides \"what is &lt;insert name of company&gt;, what do you do?\".   \n\n* If you are applying to a position but have no experience (internships, coops, freelancing, etc.) or just come straight out of an 18-week boot camp course. Please understand that you must put in 300% more effort in the interview and your portfolio than most candidates. I would love to hire folks like this, mentor them, and see them become great developers (and I have). Unfortunately, for 1 job application I publish, I get \\~170 applicants within a couple days sometimes. It is hard to say no to experience when jobs in the DE space are so popular these days. Maybe get an internship first or find a small startup that is willing to give you a shot.   \n\n* There are sooooo many companies out there misusing the term \"Data Engineering\" in job postings. Some are just glorified BI/DA positions with fancy titles or jobs where you don't code and end up becoming stuck in a career where you will have a hard time making moves to other engineering positions. In my opinion, data engineers shouldn't settle for such jobs. Ask questions to weed out these jobs during the interview process if you really want to become a proper DE (sorry if it sounds a bit harsh, I truly appreciate good BI developers and Data analysts)  \n\n* Finally, weekend projects and open-source contributions are always cool to see. I support those who want to keep their personal time completely separate from doing anything related to development. But you know, it's cool to see folks passionate about learning or contributing to our community. \n\nThese are just a couple things that jumped out at me during the past three months. I think paying attention to some of these points will make you a more well-rounded candidate and possibly give you better chances in the long run.", "author_fullname": "t2_ueuz4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A Few Pointers for Boot Camp Grads and Uni Students From a Sr. Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ydedn2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666728515.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So for the last 3 months, my time has been almost solely dedicated to interviewing, onboarding, and training new people at my work. Throughout the whole process, I\u2019ve been able to identify a couple patterns that I think would be useful to work on before going into interviews or if you are looking to have better chances at getting hired at popular companies.&lt;/p&gt;\n\n&lt;p&gt;Needless to say, these are my opinions alone and should be taken with a grain of salt. I might be a Sr. engineer but I still have much to learn and my experiences might be not a true reflection of the market.&lt;/p&gt;\n\n&lt;h1&gt;Things To Consider:&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;This is more specific for boot camp grads. An interviewer will see the same &amp;quot;Airflow pipeline with &amp;lt;insert name of free API  here&amp;gt; data&amp;quot; project a million times with the same structure, tests, and GitHub readme. A lot of bootcamps (and online courses) tend to steer their students to reuse projects from previous years over and over, which leaves you at a huge disadvantage. If you think this is you, take the time to work on other things.  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I thought everyone knew this but obviously, some missed the memo. Data engineering is not exempt from TDD practices. If can&amp;#39;t talk about testing during the interview, this is a massive red flag.  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Unwillingness to learn SWE concepts/topics will hurt you in the long run. It will not make it easy to interview at companies where Data Engineers are treated as specialized software engineers, or where you are expected to work with other engineers (Backend, DevOps, Architecture, Networking, etc).   &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Focus on collaboration during technical interviews. Getting to the right answer is great, but a lot of companies will not consider you if you don&amp;#39;t communicate with whoever is interviewing you. Being silent during the entire coding session makes it awkward and makes interviewers think you won&amp;#39;t be a good fit in a collaborative team.   &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;For the love of god, come prepared with questions before an interview. And something else besides &amp;quot;what is &amp;lt;insert name of company&amp;gt;, what do you do?&amp;quot;.   &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;If you are applying to a position but have no experience (internships, coops, freelancing, etc.) or just come straight out of an 18-week boot camp course. Please understand that you must put in 300% more effort in the interview and your portfolio than most candidates. I would love to hire folks like this, mentor them, and see them become great developers (and I have). Unfortunately, for 1 job application I publish, I get ~170 applicants within a couple days sometimes. It is hard to say no to experience when jobs in the DE space are so popular these days. Maybe get an internship first or find a small startup that is willing to give you a shot.   &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;There are sooooo many companies out there misusing the term &amp;quot;Data Engineering&amp;quot; in job postings. Some are just glorified BI/DA positions with fancy titles or jobs where you don&amp;#39;t code and end up becoming stuck in a career where you will have a hard time making moves to other engineering positions. In my opinion, data engineers shouldn&amp;#39;t settle for such jobs. Ask questions to weed out these jobs during the interview process if you really want to become a proper DE (sorry if it sounds a bit harsh, I truly appreciate good BI developers and Data analysts)  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Finally, weekend projects and open-source contributions are always cool to see. I support those who want to keep their personal time completely separate from doing anything related to development. But you know, it&amp;#39;s cool to see folks passionate about learning or contributing to our community. &lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;These are just a couple things that jumped out at me during the past three months. I think paying attention to some of these points will make you a more well-rounded candidate and possibly give you better chances in the long run.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ydedn2", "is_robot_indexable": true, "report_reasons": null, "author": "uncomfortablepanda", "discussion_type": null, "num_comments": 10, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ydedn2/a_few_pointers_for_boot_camp_grads_and_uni/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ydedn2/a_few_pointers_for_boot_camp_grads_and_uni/", "subreddit_subscribers": 77750, "created_utc": 1666728515.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been experimenting with moving parts of my data pipeline to Delta Live Tables and have found some limitations:\n\n1. No JVM support - this means no scala, no Py4J and most importantly, no spark-xml;\n2. No pivot support - this isn't a hard rule, but you can't pivot between live tables;\n3. Only 1 supported DLT storage location per pipeline;\n4. No XML support - I mentioned this in #1, but it deserves it's own callout.\n\nI'm wondering who's using this tool considering these limitations. I can see the usefulness for silver/gold, but I see plenty of guidance around using autoloader with DLT, but I struggle to see how that would work if you have xml sources or sources that need to be pivoted.\n\nI would like to hear if you have evaluated DLT and if you're using it, your use case, especially if you're using it with autoloader!", "author_fullname": "t2_41da5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are You Using Databricks Delta Live Tables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yd59hx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666705643.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been experimenting with moving parts of my data pipeline to Delta Live Tables and have found some limitations:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;No JVM support - this means no scala, no Py4J and most importantly, no spark-xml;&lt;/li&gt;\n&lt;li&gt;No pivot support - this isn&amp;#39;t a hard rule, but you can&amp;#39;t pivot between live tables;&lt;/li&gt;\n&lt;li&gt;Only 1 supported DLT storage location per pipeline;&lt;/li&gt;\n&lt;li&gt;No XML support - I mentioned this in #1, but it deserves it&amp;#39;s own callout.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;m wondering who&amp;#39;s using this tool considering these limitations. I can see the usefulness for silver/gold, but I see plenty of guidance around using autoloader with DLT, but I struggle to see how that would work if you have xml sources or sources that need to be pivoted.&lt;/p&gt;\n\n&lt;p&gt;I would like to hear if you have evaluated DLT and if you&amp;#39;re using it, your use case, especially if you&amp;#39;re using it with autoloader!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yd59hx", "is_robot_indexable": true, "report_reasons": null, "author": "dylanberry", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yd59hx/are_you_using_databricks_delta_live_tables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yd59hx/are_you_using_databricks_delta_live_tables/", "subreddit_subscribers": 77750, "created_utc": 1666705643.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the subject says , I'm going to focus more on the SQL from scratch as i see a good future in the SQL . So I'm going to strengthen my skill in SQL in flavour of data engineering . Can someone recommend a good course paid or free to achieve my targets by Dec 2022.\n\ndaily study time is approx. 1.5 hours/day.", "author_fullname": "t2_3sqs3uub", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best SQL course to Solve Hacker Rank atleast Intermediate levels", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycwwwh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666675893.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the subject says , I&amp;#39;m going to focus more on the SQL from scratch as i see a good future in the SQL . So I&amp;#39;m going to strengthen my skill in SQL in flavour of data engineering . Can someone recommend a good course paid or free to achieve my targets by Dec 2022.&lt;/p&gt;\n\n&lt;p&gt;daily study time is approx. 1.5 hours/day.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ycwwwh", "is_robot_indexable": true, "report_reasons": null, "author": "priyasweety1", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycwwwh/best_sql_course_to_solve_hacker_rank_atleast/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycwwwh/best_sql_course_to_solve_hacker_rank_atleast/", "subreddit_subscribers": 77750, "created_utc": 1666675893.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Edit: [have donated](https://imgur.com/K5VDTqu) $50 for the first 5 suggestions, please keep them coming. Thank you.\n\nSay you have a data producer and a data consumer, and changes in the data structure of data produced by the data producer cause a downstream model to break (e.g., business analytics, production ready model, or even customer facing application).\n\n**What are the** ***most common*** **examples of data structure changes that would cause a downstream model to break?** Please feel free to list as many as you can think of, or the \"why\", or context on how they occur, etc.\n\nOne example might be where a column is deleted from a production database by the software engineer that owns the data producing system, so the data consumer loses that column of data (this might be an elementary example just trying to illustrate the idea - looking for ideas other than deletion).\n\n**Thanks so much!**\n\nps - I would offer to donate more but I am just a student", "author_fullname": "t2_rcx1cqyo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[For every real example up to 10 examples I will donate $10 to charity and post proof] What are some examples of data structure changes that cause downstream models that consume that data to break?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycrzmp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666661964.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666660173.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Edit: &lt;a href=\"https://imgur.com/K5VDTqu\"&gt;have donated&lt;/a&gt; $50 for the first 5 suggestions, please keep them coming. Thank you.&lt;/p&gt;\n\n&lt;p&gt;Say you have a data producer and a data consumer, and changes in the data structure of data produced by the data producer cause a downstream model to break (e.g., business analytics, production ready model, or even customer facing application).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What are the&lt;/strong&gt; &lt;strong&gt;&lt;em&gt;most common&lt;/em&gt;&lt;/strong&gt; &lt;strong&gt;examples of data structure changes that would cause a downstream model to break?&lt;/strong&gt; Please feel free to list as many as you can think of, or the &amp;quot;why&amp;quot;, or context on how they occur, etc.&lt;/p&gt;\n\n&lt;p&gt;One example might be where a column is deleted from a production database by the software engineer that owns the data producing system, so the data consumer loses that column of data (this might be an elementary example just trying to illustrate the idea - looking for ideas other than deletion).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Thanks so much!&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;ps - I would offer to donate more but I am just a student&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Wlx-GYAT2Nf1JKYH1vkfAFSUOzl1c3cOGeYrHFEYi5M.jpg?auto=webp&amp;s=80edf78e4dfe295ad9976d00f723addfc40e96ce", "width": 600, "height": 315}, "resolutions": [{"url": "https://external-preview.redd.it/Wlx-GYAT2Nf1JKYH1vkfAFSUOzl1c3cOGeYrHFEYi5M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7f02d32049243461da0ba1c0ebd2425261edc8db", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Wlx-GYAT2Nf1JKYH1vkfAFSUOzl1c3cOGeYrHFEYi5M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=74cbaaac5e44c61682fe74d80b1c3307827710d3", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Wlx-GYAT2Nf1JKYH1vkfAFSUOzl1c3cOGeYrHFEYi5M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=662bd8173fbae193e7c199b6676256a0ea8a374a", "width": 320, "height": 168}], "variants": {}, "id": "K9MXHiDSNYTSbUJeqnGuzFRGz_LCo65_2u1Tz1XYTJY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ycrzmp", "is_robot_indexable": true, "report_reasons": null, "author": "----bubba----", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycrzmp/for_every_real_example_up_to_10_examples_i_will/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycrzmp/for_every_real_example_up_to_10_examples_i_will/", "subreddit_subscribers": 77750, "created_utc": 1666660173.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_dfcot0zg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Had some cool discussions yesterday about Window Functions. Anyone read this book it's updated for 2019. I have his two other T-SQL books so I'm gonna go grab this too.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_yd5nsb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/1NNQk60TYzGmqNHCD0XVV4kNaWqVOGddwH_pWLet_Nc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666706659.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/asn99e8l20w91.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/asn99e8l20w91.png?auto=webp&amp;s=37cbc375dd271c080dbe84af2157546b026ccf8d", "width": 1080, "height": 1502}, "resolutions": [{"url": "https://preview.redd.it/asn99e8l20w91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4c3e3c14ef1e53830822afcab9728ff12e66b8b0", "width": 108, "height": 150}, {"url": "https://preview.redd.it/asn99e8l20w91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6425dfdb6eba99d500975dedb189d736418f99f7", "width": 216, "height": 300}, {"url": "https://preview.redd.it/asn99e8l20w91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7b9d5f57395057030ebd571461836cb5f362f80b", "width": 320, "height": 445}, {"url": "https://preview.redd.it/asn99e8l20w91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=fcad977270500f65adc2e5adc3d457a427535779", "width": 640, "height": 890}, {"url": "https://preview.redd.it/asn99e8l20w91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=c62687b9d1e2596289af98c509f4e67233ea5c18", "width": 960, "height": 1335}, {"url": "https://preview.redd.it/asn99e8l20w91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ab375f1d7f88f41d1cfcec183695bc06147e5aec", "width": 1080, "height": 1502}], "variants": {}, "id": "OWZwHhMLAX1bWwIlVrYXh0B2oj_7n9CnnXmKJDlnpd8"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yd5nsb", "is_robot_indexable": true, "report_reasons": null, "author": "DrRedmondNYC", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yd5nsb/had_some_cool_discussions_yesterday_about_window/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/asn99e8l20w91.png", "subreddit_subscribers": 77750, "created_utc": 1666706659.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work for a software company doing data migrations mostly using T-SQL with occasionally Python scripts to facilitate something. Been doing this work for several years but I don\u2019t have a lot of the breadth I really need to be considered a data engineer, I don\u2019t think. I have a lot of flexibility in my role (as long as I can get the work done) and we may be migrating to Azure at some point I\u2019m the future, so I am thinking of doing a few Azure Crete including the DE one. Along the way I\u2019d like to be able to have my own Azure environment to build pipelines, intent data, etc.\n\nI know the cost can vary, but I\u2019m curious how much I\u2019d be realistically looking to spend per month. Just a ballpark will do. I think having this sort of environment will be necessary in order to really start progressing my skill set, but as I\u2019ll be paying out of pocket I want to keep it as economic as possible.", "author_fullname": "t2_ay2nitaj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much would I realistically need to spend on Azure to get some good DE experience?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ydgiem", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666733881.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work for a software company doing data migrations mostly using T-SQL with occasionally Python scripts to facilitate something. Been doing this work for several years but I don\u2019t have a lot of the breadth I really need to be considered a data engineer, I don\u2019t think. I have a lot of flexibility in my role (as long as I can get the work done) and we may be migrating to Azure at some point I\u2019m the future, so I am thinking of doing a few Azure Crete including the DE one. Along the way I\u2019d like to be able to have my own Azure environment to build pipelines, intent data, etc.&lt;/p&gt;\n\n&lt;p&gt;I know the cost can vary, but I\u2019m curious how much I\u2019d be realistically looking to spend per month. Just a ballpark will do. I think having this sort of environment will be necessary in order to really start progressing my skill set, but as I\u2019ll be paying out of pocket I want to keep it as economic as possible.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ydgiem", "is_robot_indexable": true, "report_reasons": null, "author": "theloons", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ydgiem/how_much_would_i_realistically_need_to_spend_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ydgiem/how_much_would_i_realistically_need_to_spend_on/", "subreddit_subscribers": 77750, "created_utc": 1666733881.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all! After a technical assessment, I had a technical interview with a senior data engineer. He asked me a couple of questions and it was tough for me, let me share the questions that I can remember.\n\n&gt;\\-What is the difference between renting a virtual machine and installing a mysql server and using bigquery directly? why do we use bigquery?  \n&gt;  \n&gt;\\-What is HDFS? (then what is hadoop)  \n&gt;  \n&gt;\\-What is Kafka? Why should we use Kafka instead of writing code and transferring data elsewhere?  \n&gt;  \n&gt;\\-(Suppose it is more cost-effective). What difference does it make for us if I merge the tables under a single table instead of separating them with join functions in relational databases?  \n&gt;  \n&gt;\\-What does \"this service is serverless\" mean?\n\nThis was not all of them but that's all I can remember. So I wonder,(also I'm not a ceng student, I'm studying ba but learning deng and data) isn't it too unmerciful for a 20 yo intern candidate? He also asked different detailed things but I already forgot. So guys that's all and I can add more detail below if I can remember. Write your suggestions and we can chat from dm if you want to say special. Thank you!", "author_fullname": "t2_366ahhed", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Questions that asked to me in DEng intern program technical interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ydfedx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666731062.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all! After a technical assessment, I had a technical interview with a senior data engineer. He asked me a couple of questions and it was tough for me, let me share the questions that I can remember.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;-What is the difference between renting a virtual machine and installing a mysql server and using bigquery directly? why do we use bigquery?  &lt;/p&gt;\n\n&lt;p&gt;-What is HDFS? (then what is hadoop)  &lt;/p&gt;\n\n&lt;p&gt;-What is Kafka? Why should we use Kafka instead of writing code and transferring data elsewhere?  &lt;/p&gt;\n\n&lt;p&gt;-(Suppose it is more cost-effective). What difference does it make for us if I merge the tables under a single table instead of separating them with join functions in relational databases?  &lt;/p&gt;\n\n&lt;p&gt;-What does &amp;quot;this service is serverless&amp;quot; mean?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;This was not all of them but that&amp;#39;s all I can remember. So I wonder,(also I&amp;#39;m not a ceng student, I&amp;#39;m studying ba but learning deng and data) isn&amp;#39;t it too unmerciful for a 20 yo intern candidate? He also asked different detailed things but I already forgot. So guys that&amp;#39;s all and I can add more detail below if I can remember. Write your suggestions and we can chat from dm if you want to say special. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "ydfedx", "is_robot_indexable": true, "report_reasons": null, "author": "erngkky", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ydfedx/questions_that_asked_to_me_in_deng_intern_program/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ydfedx/questions_that_asked_to_me_in_deng_intern_program/", "subreddit_subscribers": 77750, "created_utc": 1666731062.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A two-day virtual event packed with demos, AMAs, and hands-on labs created by builders, for builders. Immerse yourself in improving your apps, data pipelines, machine learning workflows, and much more. Join here - [https://www.snowflake.com/build/?utm\\_source=dataops.live&amp;utm\\_medium=partner&amp;utm\\_campaign=na-us-en-&amp;utm\\_content=-evv-build-virtual-](https://www.snowflake.com/build/?utm_source=dataops.live&amp;utm_medium=partner&amp;utm_campaign=na-us-en-&amp;utm_content=-evv-build-virtual-)\n\n[Snowflake Build - DataOps.live](https://preview.redd.it/6m4yb5wv50w91.png?width=1200&amp;format=png&amp;auto=webp&amp;s=8c74b932a764b6b86b4f4b83c959240cb29562ca)", "author_fullname": "t2_12li6zgs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake BUILD '22 - The Data Cloud Dev Virtual Summit (NOV 15-16)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "media_metadata": {"6m4yb5wv50w91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 56, "x": 108, "u": "https://preview.redd.it/6m4yb5wv50w91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a0d5524019ff358784c4cb1f4ea59106dc489f48"}, {"y": 113, "x": 216, "u": "https://preview.redd.it/6m4yb5wv50w91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ba5cf3ba73b6d773ca774af56c88ffa5346a5f70"}, {"y": 167, "x": 320, "u": "https://preview.redd.it/6m4yb5wv50w91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=22c33b96e783f6e96d3013f6bfafb7a605dfac3c"}, {"y": 334, "x": 640, "u": "https://preview.redd.it/6m4yb5wv50w91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=38a42e8c9dc9f43e5502c030939e0cd8d4ef64e5"}, {"y": 502, "x": 960, "u": "https://preview.redd.it/6m4yb5wv50w91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=47b306bd0d19f5da0ec24344212e2d5ad7a24da8"}, {"y": 565, "x": 1080, "u": "https://preview.redd.it/6m4yb5wv50w91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9b405677af2146b6f9eb37d624987ac4b062f900"}], "s": {"y": 628, "x": 1200, "u": "https://preview.redd.it/6m4yb5wv50w91.png?width=1200&amp;format=png&amp;auto=webp&amp;s=8c74b932a764b6b86b4f4b83c959240cb29562ca"}, "id": "6m4yb5wv50w91"}}, "name": "t3_yddpbm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/2Ze2TDkBmRn-wnSD6yb_CEI7u-Y4m7KOqOacZRkVfao.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666726832.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A two-day virtual event packed with demos, AMAs, and hands-on labs created by builders, for builders. Immerse yourself in improving your apps, data pipelines, machine learning workflows, and much more. Join here - &lt;a href=\"https://www.snowflake.com/build/?utm_source=dataops.live&amp;amp;utm_medium=partner&amp;amp;utm_campaign=na-us-en-&amp;amp;utm_content=-evv-build-virtual-\"&gt;https://www.snowflake.com/build/?utm_source=dataops.live&amp;amp;utm_medium=partner&amp;amp;utm_campaign=na-us-en-&amp;amp;utm_content=-evv-build-virtual-&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/6m4yb5wv50w91.png?width=1200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8c74b932a764b6b86b4f4b83c959240cb29562ca\"&gt;Snowflake Build - DataOps.live&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yddpbm", "is_robot_indexable": true, "report_reasons": null, "author": "Dkreig", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yddpbm/snowflake_build_22_the_data_cloud_dev_virtual/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yddpbm/snowflake_build_22_the_data_cloud_dev_virtual/", "subreddit_subscribers": 77750, "created_utc": 1666726832.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi fellow members. I hope you have a great start to the day.  \n\n\nI am beginning my Data Engineering journey and I wanted to let you guys know that this subreddit has been of great help to me.  \n\n\nI wanted your opinion as there are experienced and newbies in this field regarding a project that I have started for self-learning. Also, let me know if it is good enough for building my portfolio.  \n\n\nSo here it goes.  \n\n\nI have elevated twitter access. I am fetching tweets using Tweepy.   \nI fetch 10 tweets and I save the last tweet's ID in a text file. I have created a scheduler that gets the last tweet's ID from the text file and fetches a batch of the next 10 tweets. Moving forward, I parse the JSON response and filter out a few columns.   \n\n\n(Below is the part that I am about to build)  \nI would use a Postgres DB (docker image) for Data Warehousing. Furthermore, I am thinking of using Apache Airflow for data pipeline management.   \n\n\nI would love your opinions in guiding me toward a better understanding of the pathway I am following.", "author_fullname": "t2_ecv06uk8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this a good approach for starters?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ydajxs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666718928.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi fellow members. I hope you have a great start to the day.  &lt;/p&gt;\n\n&lt;p&gt;I am beginning my Data Engineering journey and I wanted to let you guys know that this subreddit has been of great help to me.  &lt;/p&gt;\n\n&lt;p&gt;I wanted your opinion as there are experienced and newbies in this field regarding a project that I have started for self-learning. Also, let me know if it is good enough for building my portfolio.  &lt;/p&gt;\n\n&lt;p&gt;So here it goes.  &lt;/p&gt;\n\n&lt;p&gt;I have elevated twitter access. I am fetching tweets using Tweepy.&lt;br/&gt;\nI fetch 10 tweets and I save the last tweet&amp;#39;s ID in a text file. I have created a scheduler that gets the last tweet&amp;#39;s ID from the text file and fetches a batch of the next 10 tweets. Moving forward, I parse the JSON response and filter out a few columns.   &lt;/p&gt;\n\n&lt;p&gt;(Below is the part that I am about to build)&lt;br/&gt;\nI would use a Postgres DB (docker image) for Data Warehousing. Furthermore, I am thinking of using Apache Airflow for data pipeline management.   &lt;/p&gt;\n\n&lt;p&gt;I would love your opinions in guiding me toward a better understanding of the pathway I am following.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ydajxs", "is_robot_indexable": true, "report_reasons": null, "author": "ShahSawari", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ydajxs/is_this_a_good_approach_for_starters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ydajxs/is_this_a_good_approach_for_starters/", "subreddit_subscribers": 77750, "created_utc": 1666718928.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys!\n\nSo i started to work on a personal project with the purpose of learning as many as possible about data engineering.\n\nThe goal is to have as less costs as possible, cause I wont make any $$ out of it, I just want to learn.\n\nTill now: \nI started on render.com (not sure if was the right option) by creating a postgreSQL DB.\n\nI've  wrote a python script that retrieves data from an API source and then stores the data in the DB.\n\nThen some data retrieved from the 1st API source, I am using it as input to a 2nd API source, from which I retrieve data and then again I am storing in the DB.\n\nNow I would like to ask for advice regarding how I should proceed and if is possible to keep going on render.com or if I should shift.\n\nNow I want to:\n\n- run that script daily and append new data to the postgreSQL tables (I have experience with airflow DAGs and tasks but not sure how i can integrate it)\n\n- i guess i need a repo and a VM instance that will run that (but again not sure about the steps in here)\n\n- I want to build also an API that will access the data (I would know how to do that with FastAPI, but not sure how i can make it in the same Repo with the whole thing)\n\n\nBasically I have parts of knowledge from these processes,but I've eve understood how I can have the together with a production &amp; staging environment, how I am actually hosting it, how thea real combination of everything happens.\n\nIf you have any sources I can learn from or advice to give, I would be really thankful.\n\nThank you for your time!", "author_fullname": "t2_b4ypm8ew", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Next steps for an 'app'", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ydab3i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666718343.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys!&lt;/p&gt;\n\n&lt;p&gt;So i started to work on a personal project with the purpose of learning as many as possible about data engineering.&lt;/p&gt;\n\n&lt;p&gt;The goal is to have as less costs as possible, cause I wont make any $$ out of it, I just want to learn.&lt;/p&gt;\n\n&lt;p&gt;Till now: \nI started on render.com (not sure if was the right option) by creating a postgreSQL DB.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve  wrote a python script that retrieves data from an API source and then stores the data in the DB.&lt;/p&gt;\n\n&lt;p&gt;Then some data retrieved from the 1st API source, I am using it as input to a 2nd API source, from which I retrieve data and then again I am storing in the DB.&lt;/p&gt;\n\n&lt;p&gt;Now I would like to ask for advice regarding how I should proceed and if is possible to keep going on render.com or if I should shift.&lt;/p&gt;\n\n&lt;p&gt;Now I want to:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;run that script daily and append new data to the postgreSQL tables (I have experience with airflow DAGs and tasks but not sure how i can integrate it)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;i guess i need a repo and a VM instance that will run that (but again not sure about the steps in here)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I want to build also an API that will access the data (I would know how to do that with FastAPI, but not sure how i can make it in the same Repo with the whole thing)&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Basically I have parts of knowledge from these processes,but I&amp;#39;ve eve understood how I can have the together with a production &amp;amp; staging environment, how I am actually hosting it, how thea real combination of everything happens.&lt;/p&gt;\n\n&lt;p&gt;If you have any sources I can learn from or advice to give, I would be really thankful.&lt;/p&gt;\n\n&lt;p&gt;Thank you for your time!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ydab3i", "is_robot_indexable": true, "report_reasons": null, "author": "Koxinfster", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ydab3i/next_steps_for_an_app/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ydab3i/next_steps_for_an_app/", "subreddit_subscribers": 77750, "created_utc": 1666718343.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I taught myself SQL on my Linux machine, beginner stuff. I'm taking Python at Data Camp...\n\nAm I likely to get a job in DE if my BS and MS are in speech therapy? \n\nAny advice to up my chances? Phrasing in my cover letter and resume? Please and thanks", "author_fullname": "t2_s05lz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE job outlooks without CS degree? (I have other degrees)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yd8zm9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666715160.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I taught myself SQL on my Linux machine, beginner stuff. I&amp;#39;m taking Python at Data Camp...&lt;/p&gt;\n\n&lt;p&gt;Am I likely to get a job in DE if my BS and MS are in speech therapy? &lt;/p&gt;\n\n&lt;p&gt;Any advice to up my chances? Phrasing in my cover letter and resume? Please and thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yd8zm9", "is_robot_indexable": true, "report_reasons": null, "author": "Easygoing_E", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yd8zm9/de_job_outlooks_without_cs_degree_i_have_other/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yd8zm9/de_job_outlooks_without_cs_degree_i_have_other/", "subreddit_subscribers": 77750, "created_utc": 1666715160.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_40ihn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Build a poor man\u2019s data lake from scratch with DuckDB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_yd8ek2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/j19A4gjER4Fhwr0vY1pNx396M63K__MPvGuoQzeyk80.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666713745.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dagster.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://dagster.io/blog/duckdb-data-lake", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9RGWtZ4-Z8omJHxqjou-b1AKtNA-JVZnZc0ds4kNLgE.jpg?auto=webp&amp;s=2e6c2f96643c1dcfc7cc7764de763ca0dd95b1f2", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/9RGWtZ4-Z8omJHxqjou-b1AKtNA-JVZnZc0ds4kNLgE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3033e0f7e8f632ae74930d6dadb1239e520aa9d0", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/9RGWtZ4-Z8omJHxqjou-b1AKtNA-JVZnZc0ds4kNLgE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fde9f0a8a50a6af8a5bdaeaaced07a68b713ab4e", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/9RGWtZ4-Z8omJHxqjou-b1AKtNA-JVZnZc0ds4kNLgE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fe1fc403c19dced88afe11bb301296d719c46aaf", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/9RGWtZ4-Z8omJHxqjou-b1AKtNA-JVZnZc0ds4kNLgE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3e3a43c984c9a9e94d1749cd3f658ae173bc369c", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/9RGWtZ4-Z8omJHxqjou-b1AKtNA-JVZnZc0ds4kNLgE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c96c60ee4bf81a32138efdb5dbec178cf4cf191f", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/9RGWtZ4-Z8omJHxqjou-b1AKtNA-JVZnZc0ds4kNLgE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=04be9cd82ad6ddea129eddc97844a60ae37d26b0", "width": 1080, "height": 607}], "variants": {}, "id": "8jnj5t96vjt3Yjp7iltc9A9N4DlNne1k-U36rzPAqto"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yd8ek2", "is_robot_indexable": true, "report_reasons": null, "author": "floydophone", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yd8ek2/build_a_poor_mans_data_lake_from_scratch_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dagster.io/blog/duckdb-data-lake", "subreddit_subscribers": 77750, "created_utc": 1666713745.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone built an address validation/standardization pipeline or have any advice for my thoughts here? The tools our pipelines are using are FiveTran, Databricks and DBT. \n\nMy basic idea for this pipeline is hit either anyone of the various APIs, SmartyStreets, Melissa, Loqate etc using their respective python SDKs, nightly in a batch process as apart of the cleansing/cleaning process of our loads. \n\nWhen the data is cleaned, we will add a new column for the validated/standardized address. \n\n1. Ingest new records into our raw tables daily (for now twice daily, in the future more frequently)\n2. Create a dataframe from the raw table, but filter on where the standardized address column is null\n3. Create a dictionary with the primary key and the associated address\n4. Send the info to the API in batches\n5. Join the cleaned data back to the dataframe\n6. Join the dataframe back to the table, adding the new cleaned address column\n\nAm I thinking about this correctly? My biggest fear is how long this might take to hit the API several times. Is this something that could be overcome with spark and parallelizing the API call (I haven't looked into this yet)?", "author_fullname": "t2_19klta65", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Address Validation Pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yd58yu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666705604.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone built an address validation/standardization pipeline or have any advice for my thoughts here? The tools our pipelines are using are FiveTran, Databricks and DBT. &lt;/p&gt;\n\n&lt;p&gt;My basic idea for this pipeline is hit either anyone of the various APIs, SmartyStreets, Melissa, Loqate etc using their respective python SDKs, nightly in a batch process as apart of the cleansing/cleaning process of our loads. &lt;/p&gt;\n\n&lt;p&gt;When the data is cleaned, we will add a new column for the validated/standardized address. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Ingest new records into our raw tables daily (for now twice daily, in the future more frequently)&lt;/li&gt;\n&lt;li&gt;Create a dataframe from the raw table, but filter on where the standardized address column is null&lt;/li&gt;\n&lt;li&gt;Create a dictionary with the primary key and the associated address&lt;/li&gt;\n&lt;li&gt;Send the info to the API in batches&lt;/li&gt;\n&lt;li&gt;Join the cleaned data back to the dataframe&lt;/li&gt;\n&lt;li&gt;Join the dataframe back to the table, adding the new cleaned address column&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Am I thinking about this correctly? My biggest fear is how long this might take to hit the API several times. Is this something that could be overcome with spark and parallelizing the API call (I haven&amp;#39;t looked into this yet)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yd58yu", "is_robot_indexable": true, "report_reasons": null, "author": "DRUKSTOP", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yd58yu/address_validation_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yd58yu/address_validation_pipeline/", "subreddit_subscribers": 77750, "created_utc": 1666705604.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey All, \n\nMy team needs data from different systems (HubSpot, Salesforce, Oracle NetSuite etc) into Redshift. I will then use SQL to create specific views and use it in power BI for visualization.\n\nI searched online for companies who provide software to achieve this (Mulesoft, Segment etc) and they charge very high license fees, which my team doesn't have the budget for.\n\nIt's there any other way to achieve my end goal? What should I learn / build in order to get this done?", "author_fullname": "t2_8hvqqklw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to pull data from SaaS into Data Warehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycq2xu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666654586.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey All, &lt;/p&gt;\n\n&lt;p&gt;My team needs data from different systems (HubSpot, Salesforce, Oracle NetSuite etc) into Redshift. I will then use SQL to create specific views and use it in power BI for visualization.&lt;/p&gt;\n\n&lt;p&gt;I searched online for companies who provide software to achieve this (Mulesoft, Segment etc) and they charge very high license fees, which my team doesn&amp;#39;t have the budget for.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s there any other way to achieve my end goal? What should I learn / build in order to get this done?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ycq2xu", "is_robot_indexable": true, "report_reasons": null, "author": "Embarrassed-Yoghurt8", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycq2xu/how_to_pull_data_from_saas_into_data_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycq2xu/how_to_pull_data_from_saas_into_data_warehouse/", "subreddit_subscribers": 77750, "created_utc": 1666654586.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In previous jobs, I used to spend a lot of time writing transformations in spark and python, loading the final results to Redshift or S3.  During that time, I got to become very familiar with using many different AWS tools, and I feel like I gained a lot of system design knowledge along the way.\n\n\n\n\nNow, with ELT becoming a big thing, it seems like all data engineers are working in DBT now.  Since a lot of data transformations nowadays are now being done in SQL, I think it will allow a data/product analyst to do data engineering work for less than what we are paid.\n\n\n\n\nIs anyone else worried about that?", "author_fullname": "t2_3v6ob2bf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "With tech stacks becoming \"easier\", how do you envision data engineering job security in the future?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_ydhtyq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666737398.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In previous jobs, I used to spend a lot of time writing transformations in spark and python, loading the final results to Redshift or S3.  During that time, I got to become very familiar with using many different AWS tools, and I feel like I gained a lot of system design knowledge along the way.&lt;/p&gt;\n\n&lt;p&gt;Now, with ELT becoming a big thing, it seems like all data engineers are working in DBT now.  Since a lot of data transformations nowadays are now being done in SQL, I think it will allow a data/product analyst to do data engineering work for less than what we are paid.&lt;/p&gt;\n\n&lt;p&gt;Is anyone else worried about that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ydhtyq", "is_robot_indexable": true, "report_reasons": null, "author": "data_preprocessing", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ydhtyq/with_tech_stacks_becoming_easier_how_do_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ydhtyq/with_tech_stacks_becoming_easier_how_do_you/", "subreddit_subscribers": 77750, "created_utc": 1666737398.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm an analytics engineer and I've been asked to bring some high level metrics of our clients into Salesforce to attach to the accounts (reverse ETL / data activation). This might be total revenue to date, last 6 months etc.\n\nWhen I asked what this would be used for or what actions the sales team would do off the back of this, they said that sales could notify operations of lower than expected revenue.\n\nTo me, these metrics did not seem relevant to the sales team's operations. It feels as though this could lead to more metric requests in Salesforce when we already have a self serve bi platform the whole company can access.\n\nAre my concerns of Salesforce becoming a BI Platform legitimate or do I just need to get the task done?\n\nI do see the benefit of some metrics in Salesforce but I'm thinking along the lines around indicators of Churn, score cards etc.", "author_fullname": "t2_2x2iij2a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Salesforce as a BI Platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ydf9su", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666730734.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m an analytics engineer and I&amp;#39;ve been asked to bring some high level metrics of our clients into Salesforce to attach to the accounts (reverse ETL / data activation). This might be total revenue to date, last 6 months etc.&lt;/p&gt;\n\n&lt;p&gt;When I asked what this would be used for or what actions the sales team would do off the back of this, they said that sales could notify operations of lower than expected revenue.&lt;/p&gt;\n\n&lt;p&gt;To me, these metrics did not seem relevant to the sales team&amp;#39;s operations. It feels as though this could lead to more metric requests in Salesforce when we already have a self serve bi platform the whole company can access.&lt;/p&gt;\n\n&lt;p&gt;Are my concerns of Salesforce becoming a BI Platform legitimate or do I just need to get the task done?&lt;/p&gt;\n\n&lt;p&gt;I do see the benefit of some metrics in Salesforce but I&amp;#39;m thinking along the lines around indicators of Churn, score cards etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ydf9su", "is_robot_indexable": true, "report_reasons": null, "author": "ChickenChowMean", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ydf9su/salesforce_as_a_bi_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ydf9su/salesforce_as_a_bi_platform/", "subreddit_subscribers": 77750, "created_utc": 1666730734.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My team manages two dbt projects in redshift and currently the entire code base runs multiple times a day. This is carried out by a series of docker commands, all of which are triggered at certain intervals by cron. \n\nI am wondering what other options exist out there for job scheduling that might give us more granularity in our commands. For example, maybe I want to run certain models only once a day compared to others which I want to run every time. Or maybe in the event of some sort of process interruption it would be nice to disable a certain model on successive runs without some sort of code change. I know that dbt's tag selectors could achieve the interval separation option, but I am wondering if there are some tools out there that can do both of these and more.", "author_fullname": "t2_6nf2i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trying to understand what scheduling options exist for more granular control of dbt runs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yde071", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666727591.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My team manages two dbt projects in redshift and currently the entire code base runs multiple times a day. This is carried out by a series of docker commands, all of which are triggered at certain intervals by cron. &lt;/p&gt;\n\n&lt;p&gt;I am wondering what other options exist out there for job scheduling that might give us more granularity in our commands. For example, maybe I want to run certain models only once a day compared to others which I want to run every time. Or maybe in the event of some sort of process interruption it would be nice to disable a certain model on successive runs without some sort of code change. I know that dbt&amp;#39;s tag selectors could achieve the interval separation option, but I am wondering if there are some tools out there that can do both of these and more.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yde071", "is_robot_indexable": true, "report_reasons": null, "author": "radil", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yde071/trying_to_understand_what_scheduling_options/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yde071/trying_to_understand_what_scheduling_options/", "subreddit_subscribers": 77750, "created_utc": 1666727591.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How can I save the output of a variable (one specific value i.e. sql query used to get the latest BatchID) to use and reference in another variable, variable B?\n\nCurrently, I am trying to do just that - reference variable A in variable B - I just want the output of variable A (the latest BatchID) to use in the WHERE clause of variable B.\n\nHowever, when I evaluate the expression - it's showing the whole query used to obtain the output of variable A as well as variable B (so it looks like two queries, when in reality, I just want the value of variable A to reference in variable B).\n\nDoes that make sense? Does this sound right? Or what am I doing wrong?", "author_fullname": "t2_gsch4oaq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SSIS Variables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yddind", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666726360.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How can I save the output of a variable (one specific value i.e. sql query used to get the latest BatchID) to use and reference in another variable, variable B?&lt;/p&gt;\n\n&lt;p&gt;Currently, I am trying to do just that - reference variable A in variable B - I just want the output of variable A (the latest BatchID) to use in the WHERE clause of variable B.&lt;/p&gt;\n\n&lt;p&gt;However, when I evaluate the expression - it&amp;#39;s showing the whole query used to obtain the output of variable A as well as variable B (so it looks like two queries, when in reality, I just want the value of variable A to reference in variable B).&lt;/p&gt;\n\n&lt;p&gt;Does that make sense? Does this sound right? Or what am I doing wrong?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yddind", "is_robot_indexable": true, "report_reasons": null, "author": "xxEiGhTyxx", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yddind/ssis_variables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yddind/ssis_variables/", "subreddit_subscribers": 77750, "created_utc": 1666726360.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}