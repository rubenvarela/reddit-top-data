{"kind": "Listing", "data": {"after": "t3_yd2gen", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6pc6xjl3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "U.K. gov consider this a decent package for a Lead DE\u2026", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_yd28wn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "ups": 68, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 68, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/U516ly52f6ctuog4RwKMKHcwzKLaq59pVIaSzphWkM8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666696559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/q5oli442rxv91.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/q5oli442rxv91.jpg?auto=webp&amp;s=5048f997709278782cdf525acddd8c778685669f", "width": 1170, "height": 1337}, "resolutions": [{"url": "https://preview.redd.it/q5oli442rxv91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=88b112df9828dd6038eadc65597be0eee38a4455", "width": 108, "height": 123}, {"url": "https://preview.redd.it/q5oli442rxv91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f50d43f8cfc9f68e9e5cd102f649275b7fbfb3f7", "width": 216, "height": 246}, {"url": "https://preview.redd.it/q5oli442rxv91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b802427eabe8990bd3f15015df75e51b4ec80ca1", "width": 320, "height": 365}, {"url": "https://preview.redd.it/q5oli442rxv91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b84f4f3789e0192286e677da5bf131d67b0d5e51", "width": 640, "height": 731}, {"url": "https://preview.redd.it/q5oli442rxv91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=05d81880dc1199fc8f47e3d8a36bc2c4419d7098", "width": 960, "height": 1097}, {"url": "https://preview.redd.it/q5oli442rxv91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3b4ca6cc6bb1ca75138d504edf61e2e65816e2f9", "width": 1080, "height": 1234}], "variants": {}, "id": "1poI9XFqPqr6oMYqs6Bdh9CVKPR-52T1rRerEOrZsug"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yd28wn", "is_robot_indexable": true, "report_reasons": null, "author": "tawaiii", "discussion_type": null, "num_comments": 52, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yd28wn/uk_gov_consider_this_a_decent_package_for_a_lead/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/q5oli442rxv91.jpg", "subreddit_subscribers": 77693, "created_utc": 1666696559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Terminology wise, one does the load before the transformation and one does it after. \n\nBut this doesn\u2019t make much sense to me and why it\u2019s so important?\n\nDoes order matter? And for which case is what option better?\n\nIn theory, I have a snowflake warehouse. In one I get data and then transform it and then load it somewhere else\n\nConversely, I can get data, load it into a database and then transform it?", "author_fullname": "t2_7ddbtrz1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ELT vs ETL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycqulb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 57, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 57, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666656815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Terminology wise, one does the load before the transformation and one does it after. &lt;/p&gt;\n\n&lt;p&gt;But this doesn\u2019t make much sense to me and why it\u2019s so important?&lt;/p&gt;\n\n&lt;p&gt;Does order matter? And for which case is what option better?&lt;/p&gt;\n\n&lt;p&gt;In theory, I have a snowflake warehouse. In one I get data and then transform it and then load it somewhere else&lt;/p&gt;\n\n&lt;p&gt;Conversely, I can get data, load it into a database and then transform it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ycqulb", "is_robot_indexable": true, "report_reasons": null, "author": "relentless_bull_", "discussion_type": null, "num_comments": 50, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycqulb/elt_vs_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycqulb/elt_vs_etl/", "subreddit_subscribers": 77693, "created_utc": 1666656815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I wrote a blog post on smoke-testing data pipelines: [https://dagster.io/blog/smoke-test-data-pipeline](https://dagster.io/blog/smoke-test-data-pipeline).\n\n&amp;#x200B;\n\nI used this heavily as an ML engineer / DE at Motive (nee KeepTruckin).\n\n&amp;#x200B;\n\nHere's the TLDR:\n\n* The idea of the data pipeline smoke test is to automatically run all your Pandas/PySpark/SQL data transformations on empty or synthetic data.\n* When defining your data pipeline, you include metadata on your data assets - e.g., column schemas - that determines how to mock them in downstream transformations.\n* The advantage of smoke tests is that you write them just once: you don\u2019t need to write a test for every newly derived data asset.\n* If your smoke test can execute quickly, it can become part of your dev loop and help you catch issues much more quickly than you would if you were executing on full data or writing a unit test.", "author_fullname": "t2_1jjs655y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Smoke tests for data pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycq87y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666655018.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wrote a blog post on smoke-testing data pipelines: &lt;a href=\"https://dagster.io/blog/smoke-test-data-pipeline\"&gt;https://dagster.io/blog/smoke-test-data-pipeline&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I used this heavily as an ML engineer / DE at Motive (nee KeepTruckin).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the TLDR:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The idea of the data pipeline smoke test is to automatically run all your Pandas/PySpark/SQL data transformations on empty or synthetic data.&lt;/li&gt;\n&lt;li&gt;When defining your data pipeline, you include metadata on your data assets - e.g., column schemas - that determines how to mock them in downstream transformations.&lt;/li&gt;\n&lt;li&gt;The advantage of smoke tests is that you write them just once: you don\u2019t need to write a test for every newly derived data asset.&lt;/li&gt;\n&lt;li&gt;If your smoke test can execute quickly, it can become part of your dev loop and help you catch issues much more quickly than you would if you were executing on full data or writing a unit test.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/PAOa0yKSko47lIi7At6Qv-MiqN692lWZHS95v4sznB0.jpg?auto=webp&amp;s=e9cc383395dc438c3eea16815fc12f1778b197e5", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/PAOa0yKSko47lIi7At6Qv-MiqN692lWZHS95v4sznB0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4e7616b5ef090ce54cd4d6a3e46f867f90464bdd", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/PAOa0yKSko47lIi7At6Qv-MiqN692lWZHS95v4sznB0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6fe5b1e0dd5a961496d33b297c9ec8b15aff4889", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/PAOa0yKSko47lIi7At6Qv-MiqN692lWZHS95v4sznB0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=511adede696708c58a8a3ddfc673dec17768e988", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/PAOa0yKSko47lIi7At6Qv-MiqN692lWZHS95v4sznB0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=00928a143e6c40ab6ecbf6f4a01568e55c862172", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/PAOa0yKSko47lIi7At6Qv-MiqN692lWZHS95v4sznB0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e5ff4ac52ddb5161e49bc5c4830694960d20fc02", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/PAOa0yKSko47lIi7At6Qv-MiqN692lWZHS95v4sznB0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7774ff0359446b714c3d7e03503648742752c8f5", "width": 1080, "height": 567}], "variants": {}, "id": "M_lWKOkMiwYDXj9qpLLfNIIeEBz7A4nvy6zVzisia-k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "ycq87y", "is_robot_indexable": true, "report_reasons": null, "author": "FrequentAthlete", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycq87y/smoke_tests_for_data_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycq87y/smoke_tests_for_data_pipelines/", "subreddit_subscribers": 77693, "created_utc": 1666655018.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been working with dbt for the last couple of years and I would never go back to the way things were before, idempotent, source controlled code with  CI/CD really changed things. \n\nI was wondering, is there a technology out there that is doing the same thing for Reporting and Dashboarding? Currently I'm using Power BI, and it gets the job done, but afaik, there is no way to have source control, at least without any hacks.", "author_fullname": "t2_9d1jjuxh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "a dbt equivalent for visualization?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycxeq6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666677748.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working with dbt for the last couple of years and I would never go back to the way things were before, idempotent, source controlled code with  CI/CD really changed things. &lt;/p&gt;\n\n&lt;p&gt;I was wondering, is there a technology out there that is doing the same thing for Reporting and Dashboarding? Currently I&amp;#39;m using Power BI, and it gets the job done, but afaik, there is no way to have source control, at least without any hacks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ycxeq6", "is_robot_indexable": true, "report_reasons": null, "author": "boggle_thy_mind", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycxeq6/a_dbt_equivalent_for_visualization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycxeq6/a_dbt_equivalent_for_visualization/", "subreddit_subscribers": 77693, "created_utc": 1666677748.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A comical yet, very accurate take on the current state of the modern Data stack.  What a joke and a massive mess.  I feel like I will be making a lot of money cleaning up and shutting off a lot of garbage in the next 3 years.\n\nhttps://medium.com/@laurengreerbalik/the-modern-data-stack-through-the-gervais-principle-bfd4b4e33ac7", "author_fullname": "t2_59fd6989", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Modern Data Stack is a joke", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycnabu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666647083.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A comical yet, very accurate take on the current state of the modern Data stack.  What a joke and a massive mess.  I feel like I will be making a lot of money cleaning up and shutting off a lot of garbage in the next 3 years.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@laurengreerbalik/the-modern-data-stack-through-the-gervais-principle-bfd4b4e33ac7\"&gt;https://medium.com/@laurengreerbalik/the-modern-data-stack-through-the-gervais-principle-bfd4b4e33ac7&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/gH0xucWP8l6GHZbp8Et6MFGSzwyHs1e1KZValrao2OM.jpg?auto=webp&amp;s=f8b243613670076e36e033a718bad78408a4100a", "width": 1088, "height": 698}, "resolutions": [{"url": "https://external-preview.redd.it/gH0xucWP8l6GHZbp8Et6MFGSzwyHs1e1KZValrao2OM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=67837b0012d4612507c8e668f22223ffc9542f3d", "width": 108, "height": 69}, {"url": "https://external-preview.redd.it/gH0xucWP8l6GHZbp8Et6MFGSzwyHs1e1KZValrao2OM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8e505160e1d9192b3ce2c0cea26202b74c649153", "width": 216, "height": 138}, {"url": "https://external-preview.redd.it/gH0xucWP8l6GHZbp8Et6MFGSzwyHs1e1KZValrao2OM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=91cdb2fd3fbef5b36708fd76cdc719ec83bfa9ab", "width": 320, "height": 205}, {"url": "https://external-preview.redd.it/gH0xucWP8l6GHZbp8Et6MFGSzwyHs1e1KZValrao2OM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2f2e0503114bb23fed9d75d924cf30bac3fad7e8", "width": 640, "height": 410}, {"url": "https://external-preview.redd.it/gH0xucWP8l6GHZbp8Et6MFGSzwyHs1e1KZValrao2OM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b1453c6bd21d8e454f7c99e958d15aa1e7985de1", "width": 960, "height": 615}, {"url": "https://external-preview.redd.it/gH0xucWP8l6GHZbp8Et6MFGSzwyHs1e1KZValrao2OM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a38b9f5271e087af88194476e74e3e17fc0b960e", "width": 1080, "height": 692}], "variants": {}, "id": "_YvsMCd7jSlheVNi0GHad-4zcCtcx35qbnquSZUEAZQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ycnabu", "is_robot_indexable": true, "report_reasons": null, "author": "dongdesk", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycnabu/modern_data_stack_is_a_joke/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycnabu/modern_data_stack_is_a_joke/", "subreddit_subscribers": 77693, "created_utc": 1666647083.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Or your parents, spouce, sibling, or someone who is just not technical in general", "author_fullname": "t2_c2wij", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you explain SQL at a party?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycz8st", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666685190.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Or your parents, spouce, sibling, or someone who is just not technical in general&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ycz8st", "is_robot_indexable": true, "report_reasons": null, "author": "Wh0_am_1", "discussion_type": null, "num_comments": 42, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycz8st/how_would_you_explain_sql_at_a_party/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycz8st/how_would_you_explain_sql_at_a_party/", "subreddit_subscribers": 77693, "created_utc": 1666685190.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently a data engineer. Interviewing for a Senior Analytics Engineering role that pays 60% more than my current job. \n\nI'm at a growing startup and I'm happy where I'm at. The WLB is good, my team as nice, and I also get a lot of autonomy to work with different teams, further my technical skills with different technologies, and infrastructure. \n\nThe Senior Analytics Engineer role would be at a well known second tier tech company, like salesforce or Atlassian. My major concern is related to the future outlook of analytics engineering vs data engineering. I feel like data engineering is more versatile, getting to work on a variety of data pipelines and tech stacks, also generating more demand overall in the job market. While Analytics Engineering is primarily SQL, dbt, and Airflow. \n\nI was reached out to by a recruiter so I'm not actively looking at the moment, but I'm wondering if an opportunity to get a name brand company, and increase my comp by 60% is too good of an opportunity to pass up. \n\nAny feedback would be appreciated!", "author_fullname": "t2_8x16rrzg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career Advice, Senior Analytics Engineer or Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycnbdp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 7, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666647157.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently a data engineer. Interviewing for a Senior Analytics Engineering role that pays 60% more than my current job. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m at a growing startup and I&amp;#39;m happy where I&amp;#39;m at. The WLB is good, my team as nice, and I also get a lot of autonomy to work with different teams, further my technical skills with different technologies, and infrastructure. &lt;/p&gt;\n\n&lt;p&gt;The Senior Analytics Engineer role would be at a well known second tier tech company, like salesforce or Atlassian. My major concern is related to the future outlook of analytics engineering vs data engineering. I feel like data engineering is more versatile, getting to work on a variety of data pipelines and tech stacks, also generating more demand overall in the job market. While Analytics Engineering is primarily SQL, dbt, and Airflow. &lt;/p&gt;\n\n&lt;p&gt;I was reached out to by a recruiter so I&amp;#39;m not actively looking at the moment, but I&amp;#39;m wondering if an opportunity to get a name brand company, and increase my comp by 60% is too good of an opportunity to pass up. &lt;/p&gt;\n\n&lt;p&gt;Any feedback would be appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 150, "id": "award_f44611f1-b89e-46dc-97fe-892280b13b82", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Thank you stranger. Shows the award.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Helpful", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ycnbdp", "is_robot_indexable": true, "report_reasons": null, "author": "Justanotherguy2022", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/ycnbdp/career_advice_senior_analytics_engineer_or_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycnbdp/career_advice_senior_analytics_engineer_or_data/", "subreddit_subscribers": 77693, "created_utc": 1666647157.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the subject says , I'm going to focus more on the SQL from scratch as i see a good future in the SQL . So I'm going to strengthen my skill in SQL in flavour of data engineering . Can someone recommend a good course paid or free to achieve my targets by Dec 2022.\n\ndaily study time is approx. 1.5 hours/day.", "author_fullname": "t2_3sqs3uub", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best SQL course to Solve Hacker Rank atleast Intermediate levels", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycwwwh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666675893.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the subject says , I&amp;#39;m going to focus more on the SQL from scratch as i see a good future in the SQL . So I&amp;#39;m going to strengthen my skill in SQL in flavour of data engineering . Can someone recommend a good course paid or free to achieve my targets by Dec 2022.&lt;/p&gt;\n\n&lt;p&gt;daily study time is approx. 1.5 hours/day.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ycwwwh", "is_robot_indexable": true, "report_reasons": null, "author": "priyasweety1", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycwwwh/best_sql_course_to_solve_hacker_rank_atleast/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycwwwh/best_sql_course_to_solve_hacker_rank_atleast/", "subreddit_subscribers": 77693, "created_utc": 1666675893.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Edit: [have donated](https://imgur.com/K5VDTqu) $50 for the first 5 suggestions, please keep them coming. Thank you.\n\nSay you have a data producer and a data consumer, and changes in the data structure of data produced by the data producer cause a downstream model to break (e.g., business analytics, production ready model, or even customer facing application).\n\n**What are the** ***most common*** **examples of data structure changes that would cause a downstream model to break?** Please feel free to list as many as you can think of, or the \"why\", or context on how they occur, etc.\n\nOne example might be where a column is deleted from a production database by the software engineer that owns the data producing system, so the data consumer loses that column of data (this might be an elementary example just trying to illustrate the idea - looking for ideas other than deletion).\n\n**Thanks so much!**\n\nps - I would offer to donate more but I am just a student", "author_fullname": "t2_rcx1cqyo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[For every real example up to 10 examples I will donate $10 to charity and post proof] What are some examples of data structure changes that cause downstream models that consume that data to break?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycrzmp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666661964.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666660173.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Edit: &lt;a href=\"https://imgur.com/K5VDTqu\"&gt;have donated&lt;/a&gt; $50 for the first 5 suggestions, please keep them coming. Thank you.&lt;/p&gt;\n\n&lt;p&gt;Say you have a data producer and a data consumer, and changes in the data structure of data produced by the data producer cause a downstream model to break (e.g., business analytics, production ready model, or even customer facing application).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What are the&lt;/strong&gt; &lt;strong&gt;&lt;em&gt;most common&lt;/em&gt;&lt;/strong&gt; &lt;strong&gt;examples of data structure changes that would cause a downstream model to break?&lt;/strong&gt; Please feel free to list as many as you can think of, or the &amp;quot;why&amp;quot;, or context on how they occur, etc.&lt;/p&gt;\n\n&lt;p&gt;One example might be where a column is deleted from a production database by the software engineer that owns the data producing system, so the data consumer loses that column of data (this might be an elementary example just trying to illustrate the idea - looking for ideas other than deletion).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Thanks so much!&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;ps - I would offer to donate more but I am just a student&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Wlx-GYAT2Nf1JKYH1vkfAFSUOzl1c3cOGeYrHFEYi5M.jpg?auto=webp&amp;s=80edf78e4dfe295ad9976d00f723addfc40e96ce", "width": 600, "height": 315}, "resolutions": [{"url": "https://external-preview.redd.it/Wlx-GYAT2Nf1JKYH1vkfAFSUOzl1c3cOGeYrHFEYi5M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7f02d32049243461da0ba1c0ebd2425261edc8db", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Wlx-GYAT2Nf1JKYH1vkfAFSUOzl1c3cOGeYrHFEYi5M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=74cbaaac5e44c61682fe74d80b1c3307827710d3", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Wlx-GYAT2Nf1JKYH1vkfAFSUOzl1c3cOGeYrHFEYi5M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=662bd8173fbae193e7c199b6676256a0ea8a374a", "width": 320, "height": 168}], "variants": {}, "id": "K9MXHiDSNYTSbUJeqnGuzFRGz_LCo65_2u1Tz1XYTJY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ycrzmp", "is_robot_indexable": true, "report_reasons": null, "author": "----bubba----", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycrzmp/for_every_real_example_up_to_10_examples_i_will/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycrzmp/for_every_real_example_up_to_10_examples_i_will/", "subreddit_subscribers": 77693, "created_utc": 1666660173.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been experimenting with moving parts of my data pipeline to Delta Live Tables and have found some limitations:\n\n1. No JVM support - this means no scala, no Py4J and most importantly, no spark-xml;\n2. No pivot support - this isn't a hard rule, but you can't pivot between live tables;\n3. Only 1 supported DLT storage location per pipeline;\n4. No XML support - I mentioned this in #1, but it deserves it's own callout.\n\nI'm wondering who's using this tool considering these limitations. I can see the usefulness for silver/gold, but I see plenty of guidance around using autoloader with DLT, but I struggle to see how that would work if you have xml sources or sources that need to be pivoted.\n\nI would like to hear if you have evaluated DLT and if you're using it, your use case, especially if you're using it with autoloader!", "author_fullname": "t2_41da5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are You Using Databricks Delta Live Tables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yd59hx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666705643.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been experimenting with moving parts of my data pipeline to Delta Live Tables and have found some limitations:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;No JVM support - this means no scala, no Py4J and most importantly, no spark-xml;&lt;/li&gt;\n&lt;li&gt;No pivot support - this isn&amp;#39;t a hard rule, but you can&amp;#39;t pivot between live tables;&lt;/li&gt;\n&lt;li&gt;Only 1 supported DLT storage location per pipeline;&lt;/li&gt;\n&lt;li&gt;No XML support - I mentioned this in #1, but it deserves it&amp;#39;s own callout.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;m wondering who&amp;#39;s using this tool considering these limitations. I can see the usefulness for silver/gold, but I see plenty of guidance around using autoloader with DLT, but I struggle to see how that would work if you have xml sources or sources that need to be pivoted.&lt;/p&gt;\n\n&lt;p&gt;I would like to hear if you have evaluated DLT and if you&amp;#39;re using it, your use case, especially if you&amp;#39;re using it with autoloader!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yd59hx", "is_robot_indexable": true, "report_reasons": null, "author": "dylanberry", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yd59hx/are_you_using_databricks_delta_live_tables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yd59hx/are_you_using_databricks_delta_live_tables/", "subreddit_subscribers": 77693, "created_utc": 1666705643.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://www.youtube.com/watch?v=72W\\_VvFRqc0](https://www.youtube.com/watch?v=72W_VvFRqc0)", "author_fullname": "t2_82dwrpz7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kleppmann - Thinking in Events: From Databases to Distributed Collaboration Software", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycp4ll", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666651927.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=72W_VvFRqc0\"&gt;https://www.youtube.com/watch?v=72W_VvFRqc0&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/dxgW-GycjOCKTApgOE6zjuezYYtJHUhCXoiVUEhxuzY.jpg?auto=webp&amp;s=ed654259a482bd39a59877b52db2881f8bd664e7", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/dxgW-GycjOCKTApgOE6zjuezYYtJHUhCXoiVUEhxuzY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c99f64e85a11d1e5ffa0be0e6a8dc342557f5e90", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/dxgW-GycjOCKTApgOE6zjuezYYtJHUhCXoiVUEhxuzY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=366971b8154d1640c014938a56b8bfa7361d4499", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/dxgW-GycjOCKTApgOE6zjuezYYtJHUhCXoiVUEhxuzY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5c2bc5eac035007f1f1e7fb5094d2a33541eff92", "width": 320, "height": 240}], "variants": {}, "id": "Rjv08LfIHTjeTNbRC5GBeA7-UtfZEG8kb-b_rElzhuU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "ycp4ll", "is_robot_indexable": true, "report_reasons": null, "author": "Upstairs-Ad-8440", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycp4ll/kleppmann_thinking_in_events_from_databases_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycp4ll/kleppmann_thinking_in_events_from_databases_to/", "subreddit_subscribers": 77693, "created_utc": 1666651927.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Need some quick help if possible, I\u2019m migrating data from datastage and one of the conversions used is a decimal to string (name, \u201csuppress_zero\u201d). \n\nThe data i have right now has single 0\u2019s in some rows. Is it possible to retain these single 0\u2019s but also removing leading/trailing 0s in other rows? \n\nEx:\nRetain - 0 into 0\n\nTransform - 0509300 into 5093\n\nSorry btw I\u2019m not exactly familiar with datastage this is my first time using it for school lol thanks!", "author_fullname": "t2_8ohhoreb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anybody here knows about \u2018suppress zeros\u2019 in DataStage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycggg0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666630649.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Need some quick help if possible, I\u2019m migrating data from datastage and one of the conversions used is a decimal to string (name, \u201csuppress_zero\u201d). &lt;/p&gt;\n\n&lt;p&gt;The data i have right now has single 0\u2019s in some rows. Is it possible to retain these single 0\u2019s but also removing leading/trailing 0s in other rows? &lt;/p&gt;\n\n&lt;p&gt;Ex:\nRetain - 0 into 0&lt;/p&gt;\n\n&lt;p&gt;Transform - 0509300 into 5093&lt;/p&gt;\n\n&lt;p&gt;Sorry btw I\u2019m not exactly familiar with datastage this is my first time using it for school lol thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ycggg0", "is_robot_indexable": true, "report_reasons": null, "author": "Specific_Onion2659", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycggg0/anybody_here_knows_about_suppress_zeros_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycggg0/anybody_here_knows_about_suppress_zeros_in/", "subreddit_subscribers": 77693, "created_utc": 1666630649.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I would love to keep up on the data industry to grow my career. What are some good sources of industry news around the the data field? \n\nHacker News seems to be a good source. Would love to know if there good ones I am missing.", "author_fullname": "t2_4utvtop9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Industry News", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycg19r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666629649.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would love to keep up on the data industry to grow my career. What are some good sources of industry news around the the data field? &lt;/p&gt;\n\n&lt;p&gt;Hacker News seems to be a good source. Would love to know if there good ones I am missing.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ycg19r", "is_robot_indexable": true, "report_reasons": null, "author": "mixedmanofsteel", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycg19r/data_industry_news/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycg19r/data_industry_news/", "subreddit_subscribers": 77693, "created_utc": 1666629649.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Let's say I have a production-live DB or clickstream data source, and I am extracting data from those data sources into my cloud data warehouse. \n\nIf I were to \"look\" into the data source and the destination at the same time, could I get a sense of time? Like, could I peer into my Snowflake instance and say, ok, my data is from time 0 through time 1. And then you go take a look in your production DB and say, ok, I've got data here from time 1 through 2. So now you are able to figure out temporally where one ends and the other begins.\n\n&amp;#x200B;\n\nIs this possible?", "author_fullname": "t2_rcx1cqyo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can you tell time inside databases or cloud data warehouses?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycek1g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666626169.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s say I have a production-live DB or clickstream data source, and I am extracting data from those data sources into my cloud data warehouse. &lt;/p&gt;\n\n&lt;p&gt;If I were to &amp;quot;look&amp;quot; into the data source and the destination at the same time, could I get a sense of time? Like, could I peer into my Snowflake instance and say, ok, my data is from time 0 through time 1. And then you go take a look in your production DB and say, ok, I&amp;#39;ve got data here from time 1 through 2. So now you are able to figure out temporally where one ends and the other begins.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Is this possible?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ycek1g", "is_robot_indexable": true, "report_reasons": null, "author": "----bubba----", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycek1g/can_you_tell_time_inside_databases_or_cloud_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycek1g/can_you_tell_time_inside_databases_or_cloud_data/", "subreddit_subscribers": 77693, "created_utc": 1666626169.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey All, \n\nMy team needs data from different systems (HubSpot, Salesforce, Oracle NetSuite etc) into Redshift. I will then use SQL to create specific views and use it in power BI for visualization.\n\nI searched online for companies who provide software to achieve this (Mulesoft, Segment etc) and they charge very high license fees, which my team doesn't have the budget for.\n\nIt's there any other way to achieve my end goal? What should I learn / build in order to get this done?", "author_fullname": "t2_8hvqqklw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to pull data from SaaS into Data Warehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycq2xu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666654586.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey All, &lt;/p&gt;\n\n&lt;p&gt;My team needs data from different systems (HubSpot, Salesforce, Oracle NetSuite etc) into Redshift. I will then use SQL to create specific views and use it in power BI for visualization.&lt;/p&gt;\n\n&lt;p&gt;I searched online for companies who provide software to achieve this (Mulesoft, Segment etc) and they charge very high license fees, which my team doesn&amp;#39;t have the budget for.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s there any other way to achieve my end goal? What should I learn / build in order to get this done?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ycq2xu", "is_robot_indexable": true, "report_reasons": null, "author": "Embarrassed-Yoghurt8", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycq2xu/how_to_pull_data_from_saas_into_data_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycq2xu/how_to_pull_data_from_saas_into_data_warehouse/", "subreddit_subscribers": 77693, "created_utc": 1666654586.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently hired on a 3 months trial contract in a current company. I have 2 years of experience in data space, but this is the first company where I have a legit title of \"data engineer\" (although my scope in previous jobs was definitely focused on data engineering - just under different names), on a mid-level position. Salary-wise it's good, and the project I am on is big and actually pretty well organized and documented (especially compared to some of s*itshow I experienced in a past). The company has its product sold to a big client, which they constantly develop &amp; maintain. This is actually the first project where a testing process is thoroughly planned and implemented on various stages and I think I can learn a lot on how I should do data engineering properly. And where more senior developers are actually skilled &amp; knowledgeable.\n\nI'm in a DataOps team that develops data pipelines and commits data operations, such as migrations. The data are actual big data, reaching TBs of volume per a pipeline. Technology stack is based on AWS, Apache Spark &amp; Trino, and we are migrating a lot into Snowflake which I was advised to learn. There is some DevOps stuff like Kubernetes and Jenkins, which I haven't worked with yet and I'd love to learn these properly. We also use Git in a proper way (I mention it because, laughably, it wasn't implemented in my previous project and it was a pain to deal with other developers).\n\n\nThe only problem is that I am doing almost no coding as for now. Most of my job so far, technically-wise, has been writing SQL queries and JSON config files to properly implement a data pipeline, and manage it via APIs of microservices of my company's application. The app is written in Java/Scala, but I don't touch the development layer. We have some Python utility scripts, but I didn't develop them either. Most of our repositories content are SQL &amp; JSON files, so I expect that it won't change much, unless we'll have more time for other projects. In a previous job, I was doing a lot of Python, as we used Airflow as a main tool, and I hoped to continue on that track.\n\nThis is actually the only reason I am considering not extending this contract. I am afraid that lack of coding will hurt my prospects, as my coding skills would rust over time.\n\nI've wanted to ask you two simple questions:\n1. Should I extend?\n2. Is little/no coding a big deal if I can develop myself in other branches of DE?\n\nTo add a little more of context. I already did some job hopping, having worked 10, 9 &amp; 6 months for 3 respective companies before. Although each change was completely justified, I would like to stick with some company for at least 1 year, to retain some stability, and also to lose the label of a potential infamous 'job-hopper'. I'm on a last year of master's degree, and upon finishing it in ~September, I would like to look for either some good foreign remote contract (I'm Eastern Europe based) or big tech company, treating my company as a \"safe haven\" while trying to fulfill my ambitions.", "author_fullname": "t2_9e7m1qmr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this company a good place for me to spend the next year? I'm afraid of little coding so far.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycnu5w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666648501.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently hired on a 3 months trial contract in a current company. I have 2 years of experience in data space, but this is the first company where I have a legit title of &amp;quot;data engineer&amp;quot; (although my scope in previous jobs was definitely focused on data engineering - just under different names), on a mid-level position. Salary-wise it&amp;#39;s good, and the project I am on is big and actually pretty well organized and documented (especially compared to some of s*itshow I experienced in a past). The company has its product sold to a big client, which they constantly develop &amp;amp; maintain. This is actually the first project where a testing process is thoroughly planned and implemented on various stages and I think I can learn a lot on how I should do data engineering properly. And where more senior developers are actually skilled &amp;amp; knowledgeable.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m in a DataOps team that develops data pipelines and commits data operations, such as migrations. The data are actual big data, reaching TBs of volume per a pipeline. Technology stack is based on AWS, Apache Spark &amp;amp; Trino, and we are migrating a lot into Snowflake which I was advised to learn. There is some DevOps stuff like Kubernetes and Jenkins, which I haven&amp;#39;t worked with yet and I&amp;#39;d love to learn these properly. We also use Git in a proper way (I mention it because, laughably, it wasn&amp;#39;t implemented in my previous project and it was a pain to deal with other developers).&lt;/p&gt;\n\n&lt;p&gt;The only problem is that I am doing almost no coding as for now. Most of my job so far, technically-wise, has been writing SQL queries and JSON config files to properly implement a data pipeline, and manage it via APIs of microservices of my company&amp;#39;s application. The app is written in Java/Scala, but I don&amp;#39;t touch the development layer. We have some Python utility scripts, but I didn&amp;#39;t develop them either. Most of our repositories content are SQL &amp;amp; JSON files, so I expect that it won&amp;#39;t change much, unless we&amp;#39;ll have more time for other projects. In a previous job, I was doing a lot of Python, as we used Airflow as a main tool, and I hoped to continue on that track.&lt;/p&gt;\n\n&lt;p&gt;This is actually the only reason I am considering not extending this contract. I am afraid that lack of coding will hurt my prospects, as my coding skills would rust over time.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve wanted to ask you two simple questions:\n1. Should I extend?\n2. Is little/no coding a big deal if I can develop myself in other branches of DE?&lt;/p&gt;\n\n&lt;p&gt;To add a little more of context. I already did some job hopping, having worked 10, 9 &amp;amp; 6 months for 3 respective companies before. Although each change was completely justified, I would like to stick with some company for at least 1 year, to retain some stability, and also to lose the label of a potential infamous &amp;#39;job-hopper&amp;#39;. I&amp;#39;m on a last year of master&amp;#39;s degree, and upon finishing it in ~September, I would like to look for either some good foreign remote contract (I&amp;#39;m Eastern Europe based) or big tech company, treating my company as a &amp;quot;safe haven&amp;quot; while trying to fulfill my ambitions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ycnu5w", "is_robot_indexable": true, "report_reasons": null, "author": "LewWariat", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycnu5w/is_this_company_a_good_place_for_me_to_spend_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycnu5w/is_this_company_a_good_place_for_me_to_spend_the/", "subreddit_subscribers": 77693, "created_utc": 1666648501.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'd like to hear other people's experiences with MySQL Heatwave.\n\nSeems pretty cool to be able to run analytical queries from the same database. Less effort than building and maintaining an ETL and using something like clickhouse or snowflake.\n\nhttps://docs.oracle.com/en-us/iaas/mysql-database/doc/heatwave.html", "author_fullname": "t2_2tsz5r0r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MySQL Heatwave Experiences", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycml8g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666645383.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;d like to hear other people&amp;#39;s experiences with MySQL Heatwave.&lt;/p&gt;\n\n&lt;p&gt;Seems pretty cool to be able to run analytical queries from the same database. Less effort than building and maintaining an ETL and using something like clickhouse or snowflake.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://docs.oracle.com/en-us/iaas/mysql-database/doc/heatwave.html\"&gt;https://docs.oracle.com/en-us/iaas/mysql-database/doc/heatwave.html&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ycml8g", "is_robot_indexable": true, "report_reasons": null, "author": "nathan026", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycml8g/mysql_heatwave_experiences/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycml8g/mysql_heatwave_experiences/", "subreddit_subscribers": 77693, "created_utc": 1666645383.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_dfcot0zg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Had some cool discussions yesterday about Window Functions. Anyone read this book it's updated for 2019. I have his two other T-SQL books so I'm gonna go grab this too.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_yd5nsb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/1NNQk60TYzGmqNHCD0XVV4kNaWqVOGddwH_pWLet_Nc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666706659.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/asn99e8l20w91.png", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/asn99e8l20w91.png?auto=webp&amp;s=37cbc375dd271c080dbe84af2157546b026ccf8d", "width": 1080, "height": 1502}, "resolutions": [{"url": "https://preview.redd.it/asn99e8l20w91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4c3e3c14ef1e53830822afcab9728ff12e66b8b0", "width": 108, "height": 150}, {"url": "https://preview.redd.it/asn99e8l20w91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6425dfdb6eba99d500975dedb189d736418f99f7", "width": 216, "height": 300}, {"url": "https://preview.redd.it/asn99e8l20w91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7b9d5f57395057030ebd571461836cb5f362f80b", "width": 320, "height": 445}, {"url": "https://preview.redd.it/asn99e8l20w91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=fcad977270500f65adc2e5adc3d457a427535779", "width": 640, "height": 890}, {"url": "https://preview.redd.it/asn99e8l20w91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=c62687b9d1e2596289af98c509f4e67233ea5c18", "width": 960, "height": 1335}, {"url": "https://preview.redd.it/asn99e8l20w91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ab375f1d7f88f41d1cfcec183695bc06147e5aec", "width": 1080, "height": 1502}], "variants": {}, "id": "OWZwHhMLAX1bWwIlVrYXh0B2oj_7n9CnnXmKJDlnpd8"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yd5nsb", "is_robot_indexable": true, "report_reasons": null, "author": "DrRedmondNYC", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yd5nsb/had_some_cool_discussions_yesterday_about_window/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/asn99e8l20w91.png", "subreddit_subscribers": 77693, "created_utc": 1666706659.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone built an address validation/standardization pipeline or have any advice for my thoughts here? The tools our pipelines are using are FiveTran, Databricks and DBT. \n\nMy basic idea for this pipeline is hit either anyone of the various APIs, SmartyStreets, Melissa, Loqate etc using their respective python SDKs, nightly in a batch process as apart of the cleansing/cleaning process of our loads. \n\nWhen the data is cleaned, we will add a new column for the validated/standardized address. \n\n1. Ingest new records into our raw tables daily (for now twice daily, in the future more frequently)\n2. Create a dataframe from the raw table, but filter on where the standardized address column is null\n3. Create a dictionary with the primary key and the associated address\n4. Send the info to the API in batches\n5. Join the cleaned data back to the dataframe\n6. Join the dataframe back to the table, adding the new cleaned address column\n\nAm I thinking about this correctly? My biggest fear is how long this might take to hit the API several times. Is this something that could be overcome with spark and parallelizing the API call (I haven't looked into this yet)?", "author_fullname": "t2_19klta65", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Address Validation Pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yd58yu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666705604.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone built an address validation/standardization pipeline or have any advice for my thoughts here? The tools our pipelines are using are FiveTran, Databricks and DBT. &lt;/p&gt;\n\n&lt;p&gt;My basic idea for this pipeline is hit either anyone of the various APIs, SmartyStreets, Melissa, Loqate etc using their respective python SDKs, nightly in a batch process as apart of the cleansing/cleaning process of our loads. &lt;/p&gt;\n\n&lt;p&gt;When the data is cleaned, we will add a new column for the validated/standardized address. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Ingest new records into our raw tables daily (for now twice daily, in the future more frequently)&lt;/li&gt;\n&lt;li&gt;Create a dataframe from the raw table, but filter on where the standardized address column is null&lt;/li&gt;\n&lt;li&gt;Create a dictionary with the primary key and the associated address&lt;/li&gt;\n&lt;li&gt;Send the info to the API in batches&lt;/li&gt;\n&lt;li&gt;Join the cleaned data back to the dataframe&lt;/li&gt;\n&lt;li&gt;Join the dataframe back to the table, adding the new cleaned address column&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Am I thinking about this correctly? My biggest fear is how long this might take to hit the API several times. Is this something that could be overcome with spark and parallelizing the API call (I haven&amp;#39;t looked into this yet)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yd58yu", "is_robot_indexable": true, "report_reasons": null, "author": "DRUKSTOP", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yd58yu/address_validation_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yd58yu/address_validation_pipeline/", "subreddit_subscribers": 77693, "created_utc": 1666705604.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "UPDATE - \n\n15 min later I found the solution.\n\n```sql\nCREATE TEMP VIEW tmp\nSELECT\np.*,\nl.*,\nST_Distance(p.geom, l.geom) dist\nFROM prev p, last l;\n\nSELECT\nd.*\nFROM tmp d\nJOIN (SELECT t.Id ids, MIN(t.dist) dist FROM dist t GROUP BY t.Id) p\nON d.Id = p.ids\n```\nMight not be the best but its good enough and super fast\n\n-----------------------------------\n\n\nSo I have been looking all over the internet and GeoPandas is the only thing I have found that has a nearest point join.\n\nBut - I have a requirement that I have to use spark - in this case GeoSpark. I have gotten the KNNQuery.SpatialKnnQuery to work, but that is not a join based on the shortest distance. Just to clarify, joining two different sized dataframes with the shortest distance to each other. I know there is a distance join but that is based on a hard coded distance value.\n\nThe geopandas function that is the exact thing I am looking for is sjoin\\_nearest - does anyone have experience in doing this.", "author_fullname": "t2_112dgq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Geospark nearest point join", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yd38md", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666700923.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666699708.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;UPDATE - &lt;/p&gt;\n\n&lt;p&gt;15 min later I found the solution.&lt;/p&gt;\n\n&lt;p&gt;```sql\nCREATE TEMP VIEW tmp\nSELECT\np.&lt;em&gt;,\nl.&lt;/em&gt;,\nST_Distance(p.geom, l.geom) dist\nFROM prev p, last l;&lt;/p&gt;\n\n&lt;p&gt;SELECT\nd.*\nFROM tmp d\nJOIN (SELECT t.Id ids, MIN(t.dist) dist FROM dist t GROUP BY t.Id) p\nON d.Id = p.ids\n```\nMight not be the best but its good enough and super fast&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;So I have been looking all over the internet and GeoPandas is the only thing I have found that has a nearest point join.&lt;/p&gt;\n\n&lt;p&gt;But - I have a requirement that I have to use spark - in this case GeoSpark. I have gotten the KNNQuery.SpatialKnnQuery to work, but that is not a join based on the shortest distance. Just to clarify, joining two different sized dataframes with the shortest distance to each other. I know there is a distance join but that is based on a hard coded distance value.&lt;/p&gt;\n\n&lt;p&gt;The geopandas function that is the exact thing I am looking for is sjoin_nearest - does anyone have experience in doing this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yd38md", "is_robot_indexable": true, "report_reasons": null, "author": "psychEcon", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yd38md/geospark_nearest_point_join/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yd38md/geospark_nearest_point_join/", "subreddit_subscribers": 77693, "created_utc": 1666699708.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_maoat3jj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[CV Review] Looking for new grad positions at FAANG. Am I worthy?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_ycjz5z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/5ZD0MrUb-KWZKAb17tNDrdJEBecw0YmUQHTBmCQ4GCo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666639084.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/k3ivqmx40tv91.jpg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/k3ivqmx40tv91.jpg?auto=webp&amp;s=8933c3625758e90530e1cb040993b0fa712dba05", "width": 1125, "height": 1459}, "resolutions": [{"url": "https://preview.redd.it/k3ivqmx40tv91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=75e7b8a9aa9a794448a769abe16d125313e4902b", "width": 108, "height": 140}, {"url": "https://preview.redd.it/k3ivqmx40tv91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=905bbeb15f5c359b291f2e59fae970d208dd7603", "width": 216, "height": 280}, {"url": "https://preview.redd.it/k3ivqmx40tv91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9873030272e593083c37bf80fdf60d67f87aaa9d", "width": 320, "height": 415}, {"url": "https://preview.redd.it/k3ivqmx40tv91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ccc98a307ec9d18de1c65fc0049c607f5dc50edb", "width": 640, "height": 830}, {"url": "https://preview.redd.it/k3ivqmx40tv91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=27a72ec76e2c70b876c1dd1609120f5326ab161f", "width": 960, "height": 1245}, {"url": "https://preview.redd.it/k3ivqmx40tv91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ad35cc99f0c9433aa4af8eb9a93c06ce0db76159", "width": 1080, "height": 1400}], "variants": {}, "id": "KuFtzBZodBb5d2LP3fmIV1_b_6f5qm5e1qD-CA1W3Hw"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "ycjz5z", "is_robot_indexable": true, "report_reasons": null, "author": "cr34th0r", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycjz5z/cv_review_looking_for_new_grad_positions_at_faang/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/k3ivqmx40tv91.jpg", "subreddit_subscribers": 77693, "created_utc": 1666639084.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi!\n\nI'm implementing a simple workflow in which I have three different data sources (API, parquet file and PostgreSQL database). The goal is to gather the data from all the different sources and store it in a PostgreSQL warehouse.\n\nThe task flow I projected goes like:\n\n*Create PostrgreSQL DW* ***&gt;&gt;*** *\\[Get data from source 1, Get data from source 2, Get data from source 3\\]* ***&gt;&gt;*** *Insert data into PostrgreSQL DW*\n\nIn order for this to work, I would have to share the data from the \"Get Data\" tasks to the \"Insert Data\" task.\t\n\nMy questions are: \n\n* Is sharing data between tasks a bad/wrong thing to do? \n* Should I approach this any other way? \n* If I implement a task to get the data from the source and then insert it to another database, wouldn't it not be idempotent? \n\nAppreciate any help. Thanks!", "author_fullname": "t2_3pu26izy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[QUESTION] Airflow best practices - How to correctly approach a workflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycfbj6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666627976.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m implementing a simple workflow in which I have three different data sources (API, parquet file and PostgreSQL database). The goal is to gather the data from all the different sources and store it in a PostgreSQL warehouse.&lt;/p&gt;\n\n&lt;p&gt;The task flow I projected goes like:&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Create PostrgreSQL DW&lt;/em&gt; &lt;strong&gt;&lt;em&gt;&amp;gt;&amp;gt;&lt;/em&gt;&lt;/strong&gt; &lt;em&gt;[Get data from source 1, Get data from source 2, Get data from source 3]&lt;/em&gt; &lt;strong&gt;&lt;em&gt;&amp;gt;&amp;gt;&lt;/em&gt;&lt;/strong&gt; &lt;em&gt;Insert data into PostrgreSQL DW&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;In order for this to work, I would have to share the data from the &amp;quot;Get Data&amp;quot; tasks to the &amp;quot;Insert Data&amp;quot; task.  &lt;/p&gt;\n\n&lt;p&gt;My questions are: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Is sharing data between tasks a bad/wrong thing to do? &lt;/li&gt;\n&lt;li&gt;Should I approach this any other way? &lt;/li&gt;\n&lt;li&gt;If I implement a task to get the data from the source and then insert it to another database, wouldn&amp;#39;t it not be idempotent? &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Appreciate any help. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ycfbj6", "is_robot_indexable": true, "report_reasons": null, "author": "menegat", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycfbj6/question_airflow_best_practices_how_to_correctly/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycfbj6/question_airflow_best_practices_how_to_correctly/", "subreddit_subscribers": 77693, "created_utc": 1666627976.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\nI am looking into getting the meta db engineer certificate but I was wondering if they are good enough to get a job or if they still want experience with these certificates? I work some with db now but not to that level and experience. Usually in Access and some SSMS so it would be a career change for me.\nThanks for any advice!", "author_fullname": "t2_g805ba5u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Database Engineer Career Switch", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycf7t2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666627733.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,\nI am looking into getting the meta db engineer certificate but I was wondering if they are good enough to get a job or if they still want experience with these certificates? I work some with db now but not to that level and experience. Usually in Access and some SSMS so it would be a career change for me.\nThanks for any advice!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ycf7t2", "is_robot_indexable": true, "report_reasons": null, "author": "Advanced-End-620", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycf7t2/database_engineer_career_switch/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycf7t2/database_engineer_career_switch/", "subreddit_subscribers": 77693, "created_utc": 1666627733.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "# Goal\n\nI  would like to create a docker swam implementation:\n\n1.) IMAGE\n\n\\- Rebuilds a new image based on the Dockerfile\n\n\\- if we make any changes to the Dockerfile\n\n\\- (If it fails I should be able to check out the error log)\n\n2.) CONTAINER\n\n\\- Just starts ad replaces the old running docker container with the new docker container\n\n\\- (Airflow Docker docker-compose.yml file )\n\n\\- (If it fails I should be able to check out the error log)\n\n\\- 1 node, no other special requirements\n\n# My Progress\n\n\\- I have run thru the docker documentation but I can not find any simple solution for this\n\n# My Progress\n\n\\- I have run thru the docker documentation but I can not find any simple solution for this", "author_fullname": "t2_qrm5o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Docker Swam - Airflow Docker - Updating", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yd1wlg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666696522.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666695456.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;Goal&lt;/h1&gt;\n\n&lt;p&gt;I  would like to create a docker swam implementation:&lt;/p&gt;\n\n&lt;p&gt;1.) IMAGE&lt;/p&gt;\n\n&lt;p&gt;- Rebuilds a new image based on the Dockerfile&lt;/p&gt;\n\n&lt;p&gt;- if we make any changes to the Dockerfile&lt;/p&gt;\n\n&lt;p&gt;- (If it fails I should be able to check out the error log)&lt;/p&gt;\n\n&lt;p&gt;2.) CONTAINER&lt;/p&gt;\n\n&lt;p&gt;- Just starts ad replaces the old running docker container with the new docker container&lt;/p&gt;\n\n&lt;p&gt;- (Airflow Docker docker-compose.yml file )&lt;/p&gt;\n\n&lt;p&gt;- (If it fails I should be able to check out the error log)&lt;/p&gt;\n\n&lt;p&gt;- 1 node, no other special requirements&lt;/p&gt;\n\n&lt;h1&gt;My Progress&lt;/h1&gt;\n\n&lt;p&gt;- I have run thru the docker documentation but I can not find any simple solution for this&lt;/p&gt;\n\n&lt;h1&gt;My Progress&lt;/h1&gt;\n\n&lt;p&gt;- I have run thru the docker documentation but I can not find any simple solution for this&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yd1wlg", "is_robot_indexable": true, "report_reasons": null, "author": "glassAlloy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yd1wlg/docker_swam_airflow_docker_updating/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yd1wlg/docker_swam_airflow_docker_updating/", "subreddit_subscribers": 77693, "created_utc": 1666695456.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I just got a job as a data engineer working mainly with informatica doing ETL and data warehousing for banks mostly (How I got there is a bit complicated as I mostly wanted something more like Data analysis or data science) and some BI using OBIEE. I am now learning data engineering with python on the side as the concept I am learning rn are nearly the same theoretically as legit DE and I am actually exploring how I am feeling actually about Data engineering in general as I wasn\u2019t really thinking about it at first", "author_fullname": "t2_73wy3wzm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I move forward?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yd2gen", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666697236.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I just got a job as a data engineer working mainly with informatica doing ETL and data warehousing for banks mostly (How I got there is a bit complicated as I mostly wanted something more like Data analysis or data science) and some BI using OBIEE. I am now learning data engineering with python on the side as the concept I am learning rn are nearly the same theoretically as legit DE and I am actually exploring how I am feeling actually about Data engineering in general as I wasn\u2019t really thinking about it at first&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yd2gen", "is_robot_indexable": true, "report_reasons": null, "author": "AliMamdouhs", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yd2gen/how_can_i_move_forward/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yd2gen/how_can_i_move_forward/", "subreddit_subscribers": 77693, "created_utc": 1666697236.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}