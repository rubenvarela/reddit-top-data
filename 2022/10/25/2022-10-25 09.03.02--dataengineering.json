{"kind": "Listing", "data": {"after": null, "dist": 22, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Well it's Monday morning back to work. I'm finishing up some QA queries from last week. In my opinion QA is one of the most tedious parts of Data Engineering because it's rather time consuming and many times it seems like your ETLs or Pipelines are working just fine but they might be missing a key data element.\n\nIn an attempt to automate some of this I am creating stored procedures that can dynamically iterate through tables and check for specific data points (record count, columns with null values where there should be something, ratio of nulls to non nulls).\n\nGot a little bit of everything in there, temp tables, variables, a while loop, dynamic SQL. The only thing missing is a cursor or any XML functions.\n\nAt what point do you consider SQL transitioning from basic to advanced. For me I consider that line when you start using the programmability features like making stored procedures or functions that accept parameters for inputs or can store result sets into variables. However some people still consider this basic SQL and don't think of it as being advanced until you start getting down and dirty with some of the features like CURSORS, Dynamic SQL, and all of that XML PATH stuff.\n\nPersonally I've only used the XML functions for string concatenation and manipulation but I've seen entire queries written with those XML commands and they are pretty complex. I am sure if I had a better understanding of XML they would appear much more simple but I never use XML for anything. Especially with JSON being widely used now.\n\n Anyway where does everyone draw the line on what they considered advanced SQL. I expect the responses to vary widely.", "author_fullname": "t2_dfcot0zg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you consider \"advanced\" SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycbwv0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 90, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 90, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666619736.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Well it&amp;#39;s Monday morning back to work. I&amp;#39;m finishing up some QA queries from last week. In my opinion QA is one of the most tedious parts of Data Engineering because it&amp;#39;s rather time consuming and many times it seems like your ETLs or Pipelines are working just fine but they might be missing a key data element.&lt;/p&gt;\n\n&lt;p&gt;In an attempt to automate some of this I am creating stored procedures that can dynamically iterate through tables and check for specific data points (record count, columns with null values where there should be something, ratio of nulls to non nulls).&lt;/p&gt;\n\n&lt;p&gt;Got a little bit of everything in there, temp tables, variables, a while loop, dynamic SQL. The only thing missing is a cursor or any XML functions.&lt;/p&gt;\n\n&lt;p&gt;At what point do you consider SQL transitioning from basic to advanced. For me I consider that line when you start using the programmability features like making stored procedures or functions that accept parameters for inputs or can store result sets into variables. However some people still consider this basic SQL and don&amp;#39;t think of it as being advanced until you start getting down and dirty with some of the features like CURSORS, Dynamic SQL, and all of that XML PATH stuff.&lt;/p&gt;\n\n&lt;p&gt;Personally I&amp;#39;ve only used the XML functions for string concatenation and manipulation but I&amp;#39;ve seen entire queries written with those XML commands and they are pretty complex. I am sure if I had a better understanding of XML they would appear much more simple but I never use XML for anything. Especially with JSON being widely used now.&lt;/p&gt;\n\n&lt;p&gt;Anyway where does everyone draw the line on what they considered advanced SQL. I expect the responses to vary widely.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ycbwv0", "is_robot_indexable": true, "report_reasons": null, "author": "DrRedmondNYC", "discussion_type": null, "num_comments": 82, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycbwv0/what_do_you_consider_advanced_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycbwv0/what_do_you_consider_advanced_sql/", "subreddit_subscribers": 77666, "created_utc": 1666619736.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Terminology wise, one does the load before the transformation and one does it after. \n\nBut this doesn\u2019t make much sense to me and why it\u2019s so important?\n\nDoes order matter? And for which case is what option better?\n\nIn theory, I have a snowflake warehouse. In one I get data and then transform it and then load it somewhere else\n\nConversely, I can get data, load it into a database and then transform it?", "author_fullname": "t2_7ddbtrz1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ELT vs ETL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycqulb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 38, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 38, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666656815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Terminology wise, one does the load before the transformation and one does it after. &lt;/p&gt;\n\n&lt;p&gt;But this doesn\u2019t make much sense to me and why it\u2019s so important?&lt;/p&gt;\n\n&lt;p&gt;Does order matter? And for which case is what option better?&lt;/p&gt;\n\n&lt;p&gt;In theory, I have a snowflake warehouse. In one I get data and then transform it and then load it somewhere else&lt;/p&gt;\n\n&lt;p&gt;Conversely, I can get data, load it into a database and then transform it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ycqulb", "is_robot_indexable": true, "report_reasons": null, "author": "relentless_bull_", "discussion_type": null, "num_comments": 44, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycqulb/elt_vs_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycqulb/elt_vs_etl/", "subreddit_subscribers": 77666, "created_utc": 1666656815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3hhpxtkh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "EtLT for improved GDPR compliance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 77, "top_awarded_type": null, "hide_score": false, "name": "t3_ycczvd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Z9670lQeGFG-sYpX87tbzNlNQG83m-uG2amf6zPBEZU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666622416.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "airbyte.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://airbyte.com/blog/etlt-gdpr-compliance", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/SnXJzSptZteFGJ27yucwGeVH6XxuKJlIfS0-1djnQ7k.jpg?auto=webp&amp;s=d438cbaa61d80a0464f4647fd242486cfcca7abf", "width": 1200, "height": 665}, "resolutions": [{"url": "https://external-preview.redd.it/SnXJzSptZteFGJ27yucwGeVH6XxuKJlIfS0-1djnQ7k.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=633a008e748072a1bc3727f8136c5ff33aa80966", "width": 108, "height": 59}, {"url": "https://external-preview.redd.it/SnXJzSptZteFGJ27yucwGeVH6XxuKJlIfS0-1djnQ7k.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=55688d1a2a0eeeeb3b906b1ef238124d63679cf2", "width": 216, "height": 119}, {"url": "https://external-preview.redd.it/SnXJzSptZteFGJ27yucwGeVH6XxuKJlIfS0-1djnQ7k.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6499f92e02a1b1f2c280fbf5dc6ca76f3364526b", "width": 320, "height": 177}, {"url": "https://external-preview.redd.it/SnXJzSptZteFGJ27yucwGeVH6XxuKJlIfS0-1djnQ7k.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a333fbab8955e9fa58c2ad56868faaa15f0b5712", "width": 640, "height": 354}, {"url": "https://external-preview.redd.it/SnXJzSptZteFGJ27yucwGeVH6XxuKJlIfS0-1djnQ7k.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3527ee1bd4a8648944a306c09ec13cb1a38fccbf", "width": 960, "height": 532}, {"url": "https://external-preview.redd.it/SnXJzSptZteFGJ27yucwGeVH6XxuKJlIfS0-1djnQ7k.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b55247612155ddddbc21e04733c639b472be619b", "width": 1080, "height": 598}], "variants": {}, "id": "L7RloCVZ0wp6hQ-JuaHveJa4aTa3nIOSd8NSR5W8aAE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "ycczvd", "is_robot_indexable": true, "report_reasons": null, "author": "alexmarquardt", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycczvd/etlt_for_improved_gdpr_compliance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://airbyte.com/blog/etlt-gdpr-compliance", "subreddit_subscribers": 77666, "created_utc": 1666622416.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A comical yet, very accurate take on the current state of the modern Data stack.  What a joke and a massive mess.  I feel like I will be making a lot of money cleaning up and shutting off a lot of garbage in the next 3 years.\n\nhttps://medium.com/@laurengreerbalik/the-modern-data-stack-through-the-gervais-principle-bfd4b4e33ac7", "author_fullname": "t2_59fd6989", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Modern Data Stack is a joke", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycnabu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666647083.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A comical yet, very accurate take on the current state of the modern Data stack.  What a joke and a massive mess.  I feel like I will be making a lot of money cleaning up and shutting off a lot of garbage in the next 3 years.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@laurengreerbalik/the-modern-data-stack-through-the-gervais-principle-bfd4b4e33ac7\"&gt;https://medium.com/@laurengreerbalik/the-modern-data-stack-through-the-gervais-principle-bfd4b4e33ac7&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/gH0xucWP8l6GHZbp8Et6MFGSzwyHs1e1KZValrao2OM.jpg?auto=webp&amp;s=f8b243613670076e36e033a718bad78408a4100a", "width": 1088, "height": 698}, "resolutions": [{"url": "https://external-preview.redd.it/gH0xucWP8l6GHZbp8Et6MFGSzwyHs1e1KZValrao2OM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=67837b0012d4612507c8e668f22223ffc9542f3d", "width": 108, "height": 69}, {"url": "https://external-preview.redd.it/gH0xucWP8l6GHZbp8Et6MFGSzwyHs1e1KZValrao2OM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8e505160e1d9192b3ce2c0cea26202b74c649153", "width": 216, "height": 138}, {"url": "https://external-preview.redd.it/gH0xucWP8l6GHZbp8Et6MFGSzwyHs1e1KZValrao2OM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=91cdb2fd3fbef5b36708fd76cdc719ec83bfa9ab", "width": 320, "height": 205}, {"url": "https://external-preview.redd.it/gH0xucWP8l6GHZbp8Et6MFGSzwyHs1e1KZValrao2OM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2f2e0503114bb23fed9d75d924cf30bac3fad7e8", "width": 640, "height": 410}, {"url": "https://external-preview.redd.it/gH0xucWP8l6GHZbp8Et6MFGSzwyHs1e1KZValrao2OM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b1453c6bd21d8e454f7c99e958d15aa1e7985de1", "width": 960, "height": 615}, {"url": "https://external-preview.redd.it/gH0xucWP8l6GHZbp8Et6MFGSzwyHs1e1KZValrao2OM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a38b9f5271e087af88194476e74e3e17fc0b960e", "width": 1080, "height": 692}], "variants": {}, "id": "_YvsMCd7jSlheVNi0GHad-4zcCtcx35qbnquSZUEAZQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ycnabu", "is_robot_indexable": true, "report_reasons": null, "author": "dongdesk", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycnabu/modern_data_stack_is_a_joke/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycnabu/modern_data_stack_is_a_joke/", "subreddit_subscribers": 77666, "created_utc": 1666647083.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I wrote a blog post on smoke-testing data pipelines: [https://dagster.io/blog/smoke-test-data-pipeline](https://dagster.io/blog/smoke-test-data-pipeline).\n\n&amp;#x200B;\n\nI used this heavily as an ML engineer / DE at Motive (nee KeepTruckin).\n\n&amp;#x200B;\n\nHere's the TLDR:\n\n* The idea of the data pipeline smoke test is to automatically run all your Pandas/PySpark/SQL data transformations on empty or synthetic data.\n* When defining your data pipeline, you include metadata on your data assets - e.g., column schemas - that determines how to mock them in downstream transformations.\n* The advantage of smoke tests is that you write them just once: you don\u2019t need to write a test for every newly derived data asset.\n* If your smoke test can execute quickly, it can become part of your dev loop and help you catch issues much more quickly than you would if you were executing on full data or writing a unit test.", "author_fullname": "t2_1jjs655y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Smoke tests for data pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycq87y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666655018.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wrote a blog post on smoke-testing data pipelines: &lt;a href=\"https://dagster.io/blog/smoke-test-data-pipeline\"&gt;https://dagster.io/blog/smoke-test-data-pipeline&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I used this heavily as an ML engineer / DE at Motive (nee KeepTruckin).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the TLDR:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The idea of the data pipeline smoke test is to automatically run all your Pandas/PySpark/SQL data transformations on empty or synthetic data.&lt;/li&gt;\n&lt;li&gt;When defining your data pipeline, you include metadata on your data assets - e.g., column schemas - that determines how to mock them in downstream transformations.&lt;/li&gt;\n&lt;li&gt;The advantage of smoke tests is that you write them just once: you don\u2019t need to write a test for every newly derived data asset.&lt;/li&gt;\n&lt;li&gt;If your smoke test can execute quickly, it can become part of your dev loop and help you catch issues much more quickly than you would if you were executing on full data or writing a unit test.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/PAOa0yKSko47lIi7At6Qv-MiqN692lWZHS95v4sznB0.jpg?auto=webp&amp;s=e9cc383395dc438c3eea16815fc12f1778b197e5", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/PAOa0yKSko47lIi7At6Qv-MiqN692lWZHS95v4sznB0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4e7616b5ef090ce54cd4d6a3e46f867f90464bdd", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/PAOa0yKSko47lIi7At6Qv-MiqN692lWZHS95v4sznB0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6fe5b1e0dd5a961496d33b297c9ec8b15aff4889", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/PAOa0yKSko47lIi7At6Qv-MiqN692lWZHS95v4sznB0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=511adede696708c58a8a3ddfc673dec17768e988", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/PAOa0yKSko47lIi7At6Qv-MiqN692lWZHS95v4sznB0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=00928a143e6c40ab6ecbf6f4a01568e55c862172", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/PAOa0yKSko47lIi7At6Qv-MiqN692lWZHS95v4sznB0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e5ff4ac52ddb5161e49bc5c4830694960d20fc02", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/PAOa0yKSko47lIi7At6Qv-MiqN692lWZHS95v4sznB0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7774ff0359446b714c3d7e03503648742752c8f5", "width": 1080, "height": 567}], "variants": {}, "id": "M_lWKOkMiwYDXj9qpLLfNIIeEBz7A4nvy6zVzisia-k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "ycq87y", "is_robot_indexable": true, "report_reasons": null, "author": "FrequentAthlete", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycq87y/smoke_tests_for_data_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycq87y/smoke_tests_for_data_pipelines/", "subreddit_subscribers": 77666, "created_utc": 1666655018.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_49cfbl1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Versatile Data Kit data engineering framework for dbt users", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_yc6c7t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/75GvkHr6KM-lgd9W_k9qXlMyYsyVZFB6AkGBA6KJH_A.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666602093.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/versatile-data-kit/versatile-data-kit-data-engineering-framework-for-dbt-users-46df614e7dcb", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XsAbQ5cmlN8TYFSih9b15cGz2EADpFWYYZAbA3D-FMA.jpg?auto=webp&amp;s=c491d4ae1d3bab9df639cd981c8f5fc1949cab2c", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/XsAbQ5cmlN8TYFSih9b15cGz2EADpFWYYZAbA3D-FMA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cb9d673db3b4eb0345569a0b831dea5870e8ebeb", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/XsAbQ5cmlN8TYFSih9b15cGz2EADpFWYYZAbA3D-FMA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=96bbabd61f385046baeba2d738772c378f993579", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/XsAbQ5cmlN8TYFSih9b15cGz2EADpFWYYZAbA3D-FMA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8d9af352cf76382cb3829511f59b2669340320bc", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/XsAbQ5cmlN8TYFSih9b15cGz2EADpFWYYZAbA3D-FMA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a1a843b0af7c6e14034fb8400c4f508ca310a312", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/XsAbQ5cmlN8TYFSih9b15cGz2EADpFWYYZAbA3D-FMA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8ff719f020511b8e33cecc2c50cef7e41b5d4a86", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/XsAbQ5cmlN8TYFSih9b15cGz2EADpFWYYZAbA3D-FMA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=795ac4e76f8cbc8e6ba8e5540d0996f060bd1309", "width": 1080, "height": 720}], "variants": {}, "id": "3RFPyVD2sTNaJoXILFrD5o2mwj7ovN1w34QVY4MslCo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yc6c7t", "is_robot_indexable": true, "report_reasons": null, "author": "zverulacis", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yc6c7t/versatile_data_kit_data_engineering_framework_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/versatile-data-kit/versatile-data-kit-data-engineering-framework-for-dbt-users-46df614e7dcb", "subreddit_subscribers": 77666, "created_utc": 1666602093.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been working with dbt for the last couple of years and I would never go back to the way things were before, idempotent, source controlled code with  CI/CD really changed things. \n\nI was wondering, is there a technology out there that is doing the same thing for Reporting and Dashboarding? Currently I'm using Power BI, and it gets the job done, but afaik, there is no way to have source control, at least without any hacks.", "author_fullname": "t2_9d1jjuxh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "a dbt equivalent for visualization?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycxeq6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666677748.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working with dbt for the last couple of years and I would never go back to the way things were before, idempotent, source controlled code with  CI/CD really changed things. &lt;/p&gt;\n\n&lt;p&gt;I was wondering, is there a technology out there that is doing the same thing for Reporting and Dashboarding? Currently I&amp;#39;m using Power BI, and it gets the job done, but afaik, there is no way to have source control, at least without any hacks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ycxeq6", "is_robot_indexable": true, "report_reasons": null, "author": "boggle_thy_mind", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycxeq6/a_dbt_equivalent_for_visualization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycxeq6/a_dbt_equivalent_for_visualization/", "subreddit_subscribers": 77666, "created_utc": 1666677748.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Edit: [have donated](https://imgur.com/K5VDTqu) $50 for the first 5 suggestions, please keep them coming. Thank you.\n\nSay you have a data producer and a data consumer, and changes in the data structure of data produced by the data producer cause a downstream model to break (e.g., business analytics, production ready model, or even customer facing application).\n\n**What are the** ***most common*** **examples of data structure changes that would cause a downstream model to break?** Please feel free to list as many as you can think of, or the \"why\", or context on how they occur, etc.\n\nOne example might be where a column is deleted from a production database by the software engineer that owns the data producing system, so the data consumer loses that column of data (this might be an elementary example just trying to illustrate the idea - looking for ideas other than deletion).\n\n**Thanks so much!**\n\nps - I would offer to donate more but I am just a student", "author_fullname": "t2_rcx1cqyo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[For every real example up to 10 examples I will donate $10 to charity and post proof] What are some examples of data structure changes that cause downstream models that consume that data to break?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycrzmp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666661964.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666660173.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Edit: &lt;a href=\"https://imgur.com/K5VDTqu\"&gt;have donated&lt;/a&gt; $50 for the first 5 suggestions, please keep them coming. Thank you.&lt;/p&gt;\n\n&lt;p&gt;Say you have a data producer and a data consumer, and changes in the data structure of data produced by the data producer cause a downstream model to break (e.g., business analytics, production ready model, or even customer facing application).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What are the&lt;/strong&gt; &lt;strong&gt;&lt;em&gt;most common&lt;/em&gt;&lt;/strong&gt; &lt;strong&gt;examples of data structure changes that would cause a downstream model to break?&lt;/strong&gt; Please feel free to list as many as you can think of, or the &amp;quot;why&amp;quot;, or context on how they occur, etc.&lt;/p&gt;\n\n&lt;p&gt;One example might be where a column is deleted from a production database by the software engineer that owns the data producing system, so the data consumer loses that column of data (this might be an elementary example just trying to illustrate the idea - looking for ideas other than deletion).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Thanks so much!&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;ps - I would offer to donate more but I am just a student&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Wlx-GYAT2Nf1JKYH1vkfAFSUOzl1c3cOGeYrHFEYi5M.jpg?auto=webp&amp;s=80edf78e4dfe295ad9976d00f723addfc40e96ce", "width": 600, "height": 315}, "resolutions": [{"url": "https://external-preview.redd.it/Wlx-GYAT2Nf1JKYH1vkfAFSUOzl1c3cOGeYrHFEYi5M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7f02d32049243461da0ba1c0ebd2425261edc8db", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Wlx-GYAT2Nf1JKYH1vkfAFSUOzl1c3cOGeYrHFEYi5M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=74cbaaac5e44c61682fe74d80b1c3307827710d3", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Wlx-GYAT2Nf1JKYH1vkfAFSUOzl1c3cOGeYrHFEYi5M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=662bd8173fbae193e7c199b6676256a0ea8a374a", "width": 320, "height": 168}], "variants": {}, "id": "K9MXHiDSNYTSbUJeqnGuzFRGz_LCo65_2u1Tz1XYTJY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ycrzmp", "is_robot_indexable": true, "report_reasons": null, "author": "----bubba----", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycrzmp/for_every_real_example_up_to_10_examples_i_will/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycrzmp/for_every_real_example_up_to_10_examples_i_will/", "subreddit_subscribers": 77666, "created_utc": 1666660173.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently a data engineer. Interviewing for a Senior Analytics Engineering role that pays 60% more than my current job. \n\nI'm at a growing startup and I'm happy where I'm at. The WLB is good, my team as nice, and I also get a lot of autonomy to work with different teams, further my technical skills with different technologies, and infrastructure. \n\nThe Senior Analytics Engineer role would be at a well known second tier tech company, like salesforce or Atlassian. My major concern is related to the future outlook of analytics engineering vs data engineering. I feel like data engineering is more versatile, getting to work on a variety of data pipelines and tech stacks, also generating more demand overall in the job market. While Analytics Engineering is primarily SQL, dbt, and Airflow. \n\nI was reached out to by a recruiter so I'm not actively looking at the moment, but I'm wondering if an opportunity to get a name brand company, and increase my comp by 60% is too good of an opportunity to pass up. \n\nAny feedback would be appreciated!", "author_fullname": "t2_8x16rrzg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career Advice, Senior Analytics Engineer or Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycnbdp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666647157.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently a data engineer. Interviewing for a Senior Analytics Engineering role that pays 60% more than my current job. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m at a growing startup and I&amp;#39;m happy where I&amp;#39;m at. The WLB is good, my team as nice, and I also get a lot of autonomy to work with different teams, further my technical skills with different technologies, and infrastructure. &lt;/p&gt;\n\n&lt;p&gt;The Senior Analytics Engineer role would be at a well known second tier tech company, like salesforce or Atlassian. My major concern is related to the future outlook of analytics engineering vs data engineering. I feel like data engineering is more versatile, getting to work on a variety of data pipelines and tech stacks, also generating more demand overall in the job market. While Analytics Engineering is primarily SQL, dbt, and Airflow. &lt;/p&gt;\n\n&lt;p&gt;I was reached out to by a recruiter so I&amp;#39;m not actively looking at the moment, but I&amp;#39;m wondering if an opportunity to get a name brand company, and increase my comp by 60% is too good of an opportunity to pass up. &lt;/p&gt;\n\n&lt;p&gt;Any feedback would be appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ycnbdp", "is_robot_indexable": true, "report_reasons": null, "author": "Justanotherguy2022", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/ycnbdp/career_advice_senior_analytics_engineer_or_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycnbdp/career_advice_senior_analytics_engineer_or_data/", "subreddit_subscribers": 77666, "created_utc": 1666647157.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Need some quick help if possible, I\u2019m migrating data from datastage and one of the conversions used is a decimal to string (name, \u201csuppress_zero\u201d). \n\nThe data i have right now has single 0\u2019s in some rows. Is it possible to retain these single 0\u2019s but also removing leading/trailing 0s in other rows? \n\nEx:\nRetain - 0 into 0\n\nTransform - 0509300 into 5093\n\nSorry btw I\u2019m not exactly familiar with datastage this is my first time using it for school lol thanks!", "author_fullname": "t2_8ohhoreb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anybody here knows about \u2018suppress zeros\u2019 in DataStage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycggg0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666630649.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Need some quick help if possible, I\u2019m migrating data from datastage and one of the conversions used is a decimal to string (name, \u201csuppress_zero\u201d). &lt;/p&gt;\n\n&lt;p&gt;The data i have right now has single 0\u2019s in some rows. Is it possible to retain these single 0\u2019s but also removing leading/trailing 0s in other rows? &lt;/p&gt;\n\n&lt;p&gt;Ex:\nRetain - 0 into 0&lt;/p&gt;\n\n&lt;p&gt;Transform - 0509300 into 5093&lt;/p&gt;\n\n&lt;p&gt;Sorry btw I\u2019m not exactly familiar with datastage this is my first time using it for school lol thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ycggg0", "is_robot_indexable": true, "report_reasons": null, "author": "Specific_Onion2659", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycggg0/anybody_here_knows_about_suppress_zeros_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycggg0/anybody_here_knows_about_suppress_zeros_in/", "subreddit_subscribers": 77666, "created_utc": 1666630649.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the subject says , I'm going to focus more on the SQL from scratch as i see a good future in the SQL . So I'm going to strengthen my skill in SQL in flavour of data engineering . Can someone recommend a good course paid or free to achieve my targets by Dec 2022.\n\ndaily study time is approx. 1.5 hours/day.", "author_fullname": "t2_3sqs3uub", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best SQL course to Solve Hacker Rank atleast Intermediate levels", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycwwwh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666675893.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the subject says , I&amp;#39;m going to focus more on the SQL from scratch as i see a good future in the SQL . So I&amp;#39;m going to strengthen my skill in SQL in flavour of data engineering . Can someone recommend a good course paid or free to achieve my targets by Dec 2022.&lt;/p&gt;\n\n&lt;p&gt;daily study time is approx. 1.5 hours/day.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ycwwwh", "is_robot_indexable": true, "report_reasons": null, "author": "priyasweety1", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycwwwh/best_sql_course_to_solve_hacker_rank_atleast/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycwwwh/best_sql_course_to_solve_hacker_rank_atleast/", "subreddit_subscribers": 77666, "created_utc": 1666675893.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey All, \n\nMy team needs data from different systems (HubSpot, Salesforce, Oracle NetSuite etc) into Redshift. I will then use SQL to create specific views and use it in power BI for visualization.\n\nI searched online for companies who provide software to achieve this (Mulesoft, Segment etc) and they charge very high license fees, which my team doesn't have the budget for.\n\nIt's there any other way to achieve my end goal? What should I learn / build in order to get this done?", "author_fullname": "t2_8hvqqklw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to pull data from SaaS into Data Warehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycq2xu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666654586.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey All, &lt;/p&gt;\n\n&lt;p&gt;My team needs data from different systems (HubSpot, Salesforce, Oracle NetSuite etc) into Redshift. I will then use SQL to create specific views and use it in power BI for visualization.&lt;/p&gt;\n\n&lt;p&gt;I searched online for companies who provide software to achieve this (Mulesoft, Segment etc) and they charge very high license fees, which my team doesn&amp;#39;t have the budget for.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s there any other way to achieve my end goal? What should I learn / build in order to get this done?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ycq2xu", "is_robot_indexable": true, "report_reasons": null, "author": "Embarrassed-Yoghurt8", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycq2xu/how_to_pull_data_from_saas_into_data_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycq2xu/how_to_pull_data_from_saas_into_data_warehouse/", "subreddit_subscribers": 77666, "created_utc": 1666654586.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://www.youtube.com/watch?v=72W\\_VvFRqc0](https://www.youtube.com/watch?v=72W_VvFRqc0)", "author_fullname": "t2_82dwrpz7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kleppmann - Thinking in Events: From Databases to Distributed Collaboration Software", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycp4ll", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666651927.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=72W_VvFRqc0\"&gt;https://www.youtube.com/watch?v=72W_VvFRqc0&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/dxgW-GycjOCKTApgOE6zjuezYYtJHUhCXoiVUEhxuzY.jpg?auto=webp&amp;s=ed654259a482bd39a59877b52db2881f8bd664e7", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/dxgW-GycjOCKTApgOE6zjuezYYtJHUhCXoiVUEhxuzY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c99f64e85a11d1e5ffa0be0e6a8dc342557f5e90", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/dxgW-GycjOCKTApgOE6zjuezYYtJHUhCXoiVUEhxuzY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=366971b8154d1640c014938a56b8bfa7361d4499", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/dxgW-GycjOCKTApgOE6zjuezYYtJHUhCXoiVUEhxuzY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5c2bc5eac035007f1f1e7fb5094d2a33541eff92", "width": 320, "height": 240}], "variants": {}, "id": "Rjv08LfIHTjeTNbRC5GBeA7-UtfZEG8kb-b_rElzhuU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "ycp4ll", "is_robot_indexable": true, "report_reasons": null, "author": "Upstairs-Ad-8440", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycp4ll/kleppmann_thinking_in_events_from_databases_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycp4ll/kleppmann_thinking_in_events_from_databases_to/", "subreddit_subscribers": 77666, "created_utc": 1666651927.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I would love to keep up on the data industry to grow my career. What are some good sources of industry news around the the data field? \n\nHacker News seems to be a good source. Would love to know if there good ones I am missing.", "author_fullname": "t2_4utvtop9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Industry News", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycg19r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666629649.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would love to keep up on the data industry to grow my career. What are some good sources of industry news around the the data field? &lt;/p&gt;\n\n&lt;p&gt;Hacker News seems to be a good source. Would love to know if there good ones I am missing.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ycg19r", "is_robot_indexable": true, "report_reasons": null, "author": "mixedmanofsteel", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycg19r/data_industry_news/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycg19r/data_industry_news/", "subreddit_subscribers": 77666, "created_utc": 1666629649.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Let's say I have a production-live DB or clickstream data source, and I am extracting data from those data sources into my cloud data warehouse. \n\nIf I were to \"look\" into the data source and the destination at the same time, could I get a sense of time? Like, could I peer into my Snowflake instance and say, ok, my data is from time 0 through time 1. And then you go take a look in your production DB and say, ok, I've got data here from time 1 through 2. So now you are able to figure out temporally where one ends and the other begins.\n\n&amp;#x200B;\n\nIs this possible?", "author_fullname": "t2_rcx1cqyo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can you tell time inside databases or cloud data warehouses?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycek1g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666626169.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s say I have a production-live DB or clickstream data source, and I am extracting data from those data sources into my cloud data warehouse. &lt;/p&gt;\n\n&lt;p&gt;If I were to &amp;quot;look&amp;quot; into the data source and the destination at the same time, could I get a sense of time? Like, could I peer into my Snowflake instance and say, ok, my data is from time 0 through time 1. And then you go take a look in your production DB and say, ok, I&amp;#39;ve got data here from time 1 through 2. So now you are able to figure out temporally where one ends and the other begins.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Is this possible?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ycek1g", "is_robot_indexable": true, "report_reasons": null, "author": "----bubba----", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycek1g/can_you_tell_time_inside_databases_or_cloud_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycek1g/can_you_tell_time_inside_databases_or_cloud_data/", "subreddit_subscribers": 77666, "created_utc": 1666626169.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently hired on a 3 months trial contract in a current company. I have 2 years of experience in data space, but this is the first company where I have a legit title of \"data engineer\" (although my scope in previous jobs was definitely focused on data engineering - just under different names), on a mid-level position. Salary-wise it's good, and the project I am on is big and actually pretty well organized and documented (especially compared to some of s*itshow I experienced in a past). The company has its product sold to a big client, which they constantly develop &amp; maintain. This is actually the first project where a testing process is thoroughly planned and implemented on various stages and I think I can learn a lot on how I should do data engineering properly. And where more senior developers are actually skilled &amp; knowledgeable.\n\nI'm in a DataOps team that develops data pipelines and commits data operations, such as migrations. The data are actual big data, reaching TBs of volume per a pipeline. Technology stack is based on AWS, Apache Spark &amp; Trino, and we are migrating a lot into Snowflake which I was advised to learn. There is some DevOps stuff like Kubernetes and Jenkins, which I haven't worked with yet and I'd love to learn these properly. We also use Git in a proper way (I mention it because, laughably, it wasn't implemented in my previous project and it was a pain to deal with other developers).\n\n\nThe only problem is that I am doing almost no coding as for now. Most of my job so far, technically-wise, has been writing SQL queries and JSON config files to properly implement a data pipeline, and manage it via APIs of microservices of my company's application. The app is written in Java/Scala, but I don't touch the development layer. We have some Python utility scripts, but I didn't develop them either. Most of our repositories content are SQL &amp; JSON files, so I expect that it won't change much, unless we'll have more time for other projects. In a previous job, I was doing a lot of Python, as we used Airflow as a main tool, and I hoped to continue on that track.\n\nThis is actually the only reason I am considering not extending this contract. I am afraid that lack of coding will hurt my prospects, as my coding skills would rust over time.\n\nI've wanted to ask you two simple questions:\n1. Should I extend?\n2. Is little/no coding a big deal if I can develop myself in other branches of DE?\n\nTo add a little more of context. I already did some job hopping, having worked 10, 9 &amp; 6 months for 3 respective companies before. Although each change was completely justified, I would like to stick with some company for at least 1 year, to retain some stability, and also to lose the label of a potential infamous 'job-hopper'. I'm on a last year of master's degree, and upon finishing it in ~September, I would like to look for either some good foreign remote contract (I'm Eastern Europe based) or big tech company, treating my company as a \"safe haven\" while trying to fulfill my ambitions.", "author_fullname": "t2_9e7m1qmr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this company a good place for me to spend the next year? I'm afraid of little coding so far.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycnu5w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666648501.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently hired on a 3 months trial contract in a current company. I have 2 years of experience in data space, but this is the first company where I have a legit title of &amp;quot;data engineer&amp;quot; (although my scope in previous jobs was definitely focused on data engineering - just under different names), on a mid-level position. Salary-wise it&amp;#39;s good, and the project I am on is big and actually pretty well organized and documented (especially compared to some of s*itshow I experienced in a past). The company has its product sold to a big client, which they constantly develop &amp;amp; maintain. This is actually the first project where a testing process is thoroughly planned and implemented on various stages and I think I can learn a lot on how I should do data engineering properly. And where more senior developers are actually skilled &amp;amp; knowledgeable.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m in a DataOps team that develops data pipelines and commits data operations, such as migrations. The data are actual big data, reaching TBs of volume per a pipeline. Technology stack is based on AWS, Apache Spark &amp;amp; Trino, and we are migrating a lot into Snowflake which I was advised to learn. There is some DevOps stuff like Kubernetes and Jenkins, which I haven&amp;#39;t worked with yet and I&amp;#39;d love to learn these properly. We also use Git in a proper way (I mention it because, laughably, it wasn&amp;#39;t implemented in my previous project and it was a pain to deal with other developers).&lt;/p&gt;\n\n&lt;p&gt;The only problem is that I am doing almost no coding as for now. Most of my job so far, technically-wise, has been writing SQL queries and JSON config files to properly implement a data pipeline, and manage it via APIs of microservices of my company&amp;#39;s application. The app is written in Java/Scala, but I don&amp;#39;t touch the development layer. We have some Python utility scripts, but I didn&amp;#39;t develop them either. Most of our repositories content are SQL &amp;amp; JSON files, so I expect that it won&amp;#39;t change much, unless we&amp;#39;ll have more time for other projects. In a previous job, I was doing a lot of Python, as we used Airflow as a main tool, and I hoped to continue on that track.&lt;/p&gt;\n\n&lt;p&gt;This is actually the only reason I am considering not extending this contract. I am afraid that lack of coding will hurt my prospects, as my coding skills would rust over time.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve wanted to ask you two simple questions:\n1. Should I extend?\n2. Is little/no coding a big deal if I can develop myself in other branches of DE?&lt;/p&gt;\n\n&lt;p&gt;To add a little more of context. I already did some job hopping, having worked 10, 9 &amp;amp; 6 months for 3 respective companies before. Although each change was completely justified, I would like to stick with some company for at least 1 year, to retain some stability, and also to lose the label of a potential infamous &amp;#39;job-hopper&amp;#39;. I&amp;#39;m on a last year of master&amp;#39;s degree, and upon finishing it in ~September, I would like to look for either some good foreign remote contract (I&amp;#39;m Eastern Europe based) or big tech company, treating my company as a &amp;quot;safe haven&amp;quot; while trying to fulfill my ambitions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ycnu5w", "is_robot_indexable": true, "report_reasons": null, "author": "LewWariat", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycnu5w/is_this_company_a_good_place_for_me_to_spend_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycnu5w/is_this_company_a_good_place_for_me_to_spend_the/", "subreddit_subscribers": 77666, "created_utc": 1666648501.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'd like to hear other people's experiences with MySQL Heatwave.\n\nSeems pretty cool to be able to run analytical queries from the same database. Less effort than building and maintaining an ETL and using something like clickhouse or snowflake.\n\nhttps://docs.oracle.com/en-us/iaas/mysql-database/doc/heatwave.html", "author_fullname": "t2_2tsz5r0r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MySQL Heatwave Experiences", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycml8g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666645383.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;d like to hear other people&amp;#39;s experiences with MySQL Heatwave.&lt;/p&gt;\n\n&lt;p&gt;Seems pretty cool to be able to run analytical queries from the same database. Less effort than building and maintaining an ETL and using something like clickhouse or snowflake.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://docs.oracle.com/en-us/iaas/mysql-database/doc/heatwave.html\"&gt;https://docs.oracle.com/en-us/iaas/mysql-database/doc/heatwave.html&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ycml8g", "is_robot_indexable": true, "report_reasons": null, "author": "nathan026", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycml8g/mysql_heatwave_experiences/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycml8g/mysql_heatwave_experiences/", "subreddit_subscribers": 77666, "created_utc": 1666645383.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'im trying to build this simple dockerfile file..\n\n    FROM docker.io/apache/airflow:2.0.1\n    USER root\n    RUN apt-get update &amp;&amp; \\\n        apt install -y python-lxml &amp;&amp; \\\n        apt clean all\n    USER airflow\n\n[Docker Build Screenshot](https://pastebin.com/dV6A8DUQ)\n\n[System Specs Screenshot](https://i.imgur.com/64QFJ8P.png)\n\nThis can't be normal. I've built docker images in the past (last year, the last time I remembered) and it's never been this slow.\nIt's been close to an hour now to build this simple docker image. Anyone know what the possible cause is? \n\nThanks", "author_fullname": "t2_yex15", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building a docker image is slow af....", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_ycyjbg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666682242.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;im trying to build this simple dockerfile file..&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;FROM docker.io/apache/airflow:2.0.1\nUSER root\nRUN apt-get update &amp;amp;&amp;amp; \\\n    apt install -y python-lxml &amp;amp;&amp;amp; \\\n    apt clean all\nUSER airflow\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;a href=\"https://pastebin.com/dV6A8DUQ\"&gt;Docker Build Screenshot&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://i.imgur.com/64QFJ8P.png\"&gt;System Specs Screenshot&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This can&amp;#39;t be normal. I&amp;#39;ve built docker images in the past (last year, the last time I remembered) and it&amp;#39;s never been this slow.\nIt&amp;#39;s been close to an hour now to build this simple docker image. Anyone know what the possible cause is? &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Co-VbBktDrvy4If8KeTClrUaMl8jNsrFKEFkbct8Aps.png?auto=webp&amp;s=fce8fbc9185c8efde427deb0a8b072f42a43f06b", "width": 968, "height": 469}, "resolutions": [{"url": "https://external-preview.redd.it/Co-VbBktDrvy4If8KeTClrUaMl8jNsrFKEFkbct8Aps.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d2612d903751821b4a6fd5a8fe65fa7d7d12d3cb", "width": 108, "height": 52}, {"url": "https://external-preview.redd.it/Co-VbBktDrvy4If8KeTClrUaMl8jNsrFKEFkbct8Aps.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f91534c5d5d3636891aab899cc60c05483522877", "width": 216, "height": 104}, {"url": "https://external-preview.redd.it/Co-VbBktDrvy4If8KeTClrUaMl8jNsrFKEFkbct8Aps.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c7907f2ff1b0e9ef4e86cfb286075435a2cb9933", "width": 320, "height": 155}, {"url": "https://external-preview.redd.it/Co-VbBktDrvy4If8KeTClrUaMl8jNsrFKEFkbct8Aps.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ef163c72be2fbd72ba60f5183637b4153fbaf103", "width": 640, "height": 310}, {"url": "https://external-preview.redd.it/Co-VbBktDrvy4If8KeTClrUaMl8jNsrFKEFkbct8Aps.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=7d4e63c4c0442a862bee6073904742a41ec63301", "width": 960, "height": 465}], "variants": {}, "id": "nAjNfj8IfFLheMes63RJ7eY0BouT10Q-8c-44Q9QQcY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ycyjbg", "is_robot_indexable": true, "report_reasons": null, "author": "desperate-1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycyjbg/building_a_docker_image_is_slow_af/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycyjbg/building_a_docker_image_is_slow_af/", "subreddit_subscribers": 77666, "created_utc": 1666682242.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_maoat3jj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[CV Review] Looking for new grad positions at FAANG. Am I worthy?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_ycjz5z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/5ZD0MrUb-KWZKAb17tNDrdJEBecw0YmUQHTBmCQ4GCo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666639084.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/k3ivqmx40tv91.jpg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/k3ivqmx40tv91.jpg?auto=webp&amp;s=8933c3625758e90530e1cb040993b0fa712dba05", "width": 1125, "height": 1459}, "resolutions": [{"url": "https://preview.redd.it/k3ivqmx40tv91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=75e7b8a9aa9a794448a769abe16d125313e4902b", "width": 108, "height": 140}, {"url": "https://preview.redd.it/k3ivqmx40tv91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=905bbeb15f5c359b291f2e59fae970d208dd7603", "width": 216, "height": 280}, {"url": "https://preview.redd.it/k3ivqmx40tv91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9873030272e593083c37bf80fdf60d67f87aaa9d", "width": 320, "height": 415}, {"url": "https://preview.redd.it/k3ivqmx40tv91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ccc98a307ec9d18de1c65fc0049c607f5dc50edb", "width": 640, "height": 830}, {"url": "https://preview.redd.it/k3ivqmx40tv91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=27a72ec76e2c70b876c1dd1609120f5326ab161f", "width": 960, "height": 1245}, {"url": "https://preview.redd.it/k3ivqmx40tv91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ad35cc99f0c9433aa4af8eb9a93c06ce0db76159", "width": 1080, "height": 1400}], "variants": {}, "id": "KuFtzBZodBb5d2LP3fmIV1_b_6f5qm5e1qD-CA1W3Hw"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "ycjz5z", "is_robot_indexable": true, "report_reasons": null, "author": "cr34th0r", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycjz5z/cv_review_looking_for_new_grad_positions_at_faang/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/k3ivqmx40tv91.jpg", "subreddit_subscribers": 77666, "created_utc": 1666639084.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi!\n\nI'm implementing a simple workflow in which I have three different data sources (API, parquet file and PostgreSQL database). The goal is to gather the data from all the different sources and store it in a PostgreSQL warehouse.\n\nThe task flow I projected goes like:\n\n*Create PostrgreSQL DW* ***&gt;&gt;*** *\\[Get data from source 1, Get data from source 2, Get data from source 3\\]* ***&gt;&gt;*** *Insert data into PostrgreSQL DW*\n\nIn order for this to work, I would have to share the data from the \"Get Data\" tasks to the \"Insert Data\" task.\t\n\nMy questions are: \n\n* Is sharing data between tasks a bad/wrong thing to do? \n* Should I approach this any other way? \n* If I implement a task to get the data from the source and then insert it to another database, wouldn't it not be idempotent? \n\nAppreciate any help. Thanks!", "author_fullname": "t2_3pu26izy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[QUESTION] Airflow best practices - How to correctly approach a workflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycfbj6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666627976.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m implementing a simple workflow in which I have three different data sources (API, parquet file and PostgreSQL database). The goal is to gather the data from all the different sources and store it in a PostgreSQL warehouse.&lt;/p&gt;\n\n&lt;p&gt;The task flow I projected goes like:&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Create PostrgreSQL DW&lt;/em&gt; &lt;strong&gt;&lt;em&gt;&amp;gt;&amp;gt;&lt;/em&gt;&lt;/strong&gt; &lt;em&gt;[Get data from source 1, Get data from source 2, Get data from source 3]&lt;/em&gt; &lt;strong&gt;&lt;em&gt;&amp;gt;&amp;gt;&lt;/em&gt;&lt;/strong&gt; &lt;em&gt;Insert data into PostrgreSQL DW&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;In order for this to work, I would have to share the data from the &amp;quot;Get Data&amp;quot; tasks to the &amp;quot;Insert Data&amp;quot; task.  &lt;/p&gt;\n\n&lt;p&gt;My questions are: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Is sharing data between tasks a bad/wrong thing to do? &lt;/li&gt;\n&lt;li&gt;Should I approach this any other way? &lt;/li&gt;\n&lt;li&gt;If I implement a task to get the data from the source and then insert it to another database, wouldn&amp;#39;t it not be idempotent? &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Appreciate any help. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ycfbj6", "is_robot_indexable": true, "report_reasons": null, "author": "menegat", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycfbj6/question_airflow_best_practices_how_to_correctly/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycfbj6/question_airflow_best_practices_how_to_correctly/", "subreddit_subscribers": 77666, "created_utc": 1666627976.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\nI am looking into getting the meta db engineer certificate but I was wondering if they are good enough to get a job or if they still want experience with these certificates? I work some with db now but not to that level and experience. Usually in Access and some SSMS so it would be a career change for me.\nThanks for any advice!", "author_fullname": "t2_g805ba5u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Database Engineer Career Switch", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycf7t2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666627733.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,\nI am looking into getting the meta db engineer certificate but I was wondering if they are good enough to get a job or if they still want experience with these certificates? I work some with db now but not to that level and experience. Usually in Access and some SSMS so it would be a career change for me.\nThanks for any advice!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ycf7t2", "is_robot_indexable": true, "report_reasons": null, "author": "Advanced-End-620", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycf7t2/database_engineer_career_switch/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycf7t2/database_engineer_career_switch/", "subreddit_subscribers": 77666, "created_utc": 1666627733.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone, our data warehouse rebuilds every night from airflow and we have 2 schemas, public and data warehouse.  The public schema retains permissions and rebuilds fine, but our all of our dags to create data warehouse tables (built from public tables) fail due to \u201crelation (table name) doesn\u2019t exist\u201d.  To fix it we currently manually run a \u201cGrant all privileges\u201d sql script for that user. But every night the user loses the permissions again. Any advice on how I can make the user retain permissions through the rebuild and have our dags complete?", "author_fullname": "t2_dqlps", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Database user losing permissions on DW rebuild", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycdchp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666623268.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, our data warehouse rebuilds every night from airflow and we have 2 schemas, public and data warehouse.  The public schema retains permissions and rebuilds fine, but our all of our dags to create data warehouse tables (built from public tables) fail due to \u201crelation (table name) doesn\u2019t exist\u201d.  To fix it we currently manually run a \u201cGrant all privileges\u201d sql script for that user. But every night the user loses the permissions again. Any advice on how I can make the user retain permissions through the rebuild and have our dags complete?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ycdchp", "is_robot_indexable": true, "report_reasons": null, "author": "dynamex1097", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycdchp/database_user_losing_permissions_on_dw_rebuild/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycdchp/database_user_losing_permissions_on_dw_rebuild/", "subreddit_subscribers": 77666, "created_utc": 1666623268.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}