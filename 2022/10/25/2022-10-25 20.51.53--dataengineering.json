{"kind": "Listing", "data": {"after": "t3_ydc5cr", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6pc6xjl3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "U.K. gov consider this a decent package for a Lead DE\u2026", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_yd28wn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 129, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 129, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/U516ly52f6ctuog4RwKMKHcwzKLaq59pVIaSzphWkM8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666696559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/q5oli442rxv91.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/q5oli442rxv91.jpg?auto=webp&amp;s=5048f997709278782cdf525acddd8c778685669f", "width": 1170, "height": 1337}, "resolutions": [{"url": "https://preview.redd.it/q5oli442rxv91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=88b112df9828dd6038eadc65597be0eee38a4455", "width": 108, "height": 123}, {"url": "https://preview.redd.it/q5oli442rxv91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f50d43f8cfc9f68e9e5cd102f649275b7fbfb3f7", "width": 216, "height": 246}, {"url": "https://preview.redd.it/q5oli442rxv91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b802427eabe8990bd3f15015df75e51b4ec80ca1", "width": 320, "height": 365}, {"url": "https://preview.redd.it/q5oli442rxv91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b84f4f3789e0192286e677da5bf131d67b0d5e51", "width": 640, "height": 731}, {"url": "https://preview.redd.it/q5oli442rxv91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=05d81880dc1199fc8f47e3d8a36bc2c4419d7098", "width": 960, "height": 1097}, {"url": "https://preview.redd.it/q5oli442rxv91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3b4ca6cc6bb1ca75138d504edf61e2e65816e2f9", "width": 1080, "height": 1234}], "variants": {}, "id": "1poI9XFqPqr6oMYqs6Bdh9CVKPR-52T1rRerEOrZsug"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yd28wn", "is_robot_indexable": true, "report_reasons": null, "author": "tawaiii", "discussion_type": null, "num_comments": 70, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yd28wn/uk_gov_consider_this_a_decent_package_for_a_lead/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/q5oli442rxv91.jpg", "subreddit_subscribers": 77730, "created_utc": 1666696559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Terminology wise, one does the load before the transformation and one does it after. \n\nBut this doesn\u2019t make much sense to me and why it\u2019s so important?\n\nDoes order matter? And for which case is what option better?\n\nIn theory, I have a snowflake warehouse. In one I get data and then transform it and then load it somewhere else\n\nConversely, I can get data, load it into a database and then transform it?", "author_fullname": "t2_7ddbtrz1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ELT vs ETL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycqulb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 60, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 60, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666656815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Terminology wise, one does the load before the transformation and one does it after. &lt;/p&gt;\n\n&lt;p&gt;But this doesn\u2019t make much sense to me and why it\u2019s so important?&lt;/p&gt;\n\n&lt;p&gt;Does order matter? And for which case is what option better?&lt;/p&gt;\n\n&lt;p&gt;In theory, I have a snowflake warehouse. In one I get data and then transform it and then load it somewhere else&lt;/p&gt;\n\n&lt;p&gt;Conversely, I can get data, load it into a database and then transform it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ycqulb", "is_robot_indexable": true, "report_reasons": null, "author": "relentless_bull_", "discussion_type": null, "num_comments": 51, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycqulb/elt_vs_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycqulb/elt_vs_etl/", "subreddit_subscribers": 77730, "created_utc": 1666656815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been working with dbt for the last couple of years and I would never go back to the way things were before, idempotent, source controlled code with  CI/CD really changed things. \n\nI was wondering, is there a technology out there that is doing the same thing for Reporting and Dashboarding? Currently I'm using Power BI, and it gets the job done, but afaik, there is no way to have source control, at least without any hacks.", "author_fullname": "t2_9d1jjuxh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "a dbt equivalent for visualization?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycxeq6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666677748.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working with dbt for the last couple of years and I would never go back to the way things were before, idempotent, source controlled code with  CI/CD really changed things. &lt;/p&gt;\n\n&lt;p&gt;I was wondering, is there a technology out there that is doing the same thing for Reporting and Dashboarding? Currently I&amp;#39;m using Power BI, and it gets the job done, but afaik, there is no way to have source control, at least without any hacks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ycxeq6", "is_robot_indexable": true, "report_reasons": null, "author": "boggle_thy_mind", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycxeq6/a_dbt_equivalent_for_visualization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycxeq6/a_dbt_equivalent_for_visualization/", "subreddit_subscribers": 77730, "created_utc": 1666677748.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Or your parents, spouce, sibling, or someone who is just not technical in general", "author_fullname": "t2_c2wij", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you explain SQL at a party?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycz8st", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666685190.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Or your parents, spouce, sibling, or someone who is just not technical in general&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ycz8st", "is_robot_indexable": true, "report_reasons": null, "author": "Wh0_am_1", "discussion_type": null, "num_comments": 59, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycz8st/how_would_you_explain_sql_at_a_party/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycz8st/how_would_you_explain_sql_at_a_party/", "subreddit_subscribers": 77730, "created_utc": 1666685190.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I wrote a blog post on smoke-testing data pipelines: [https://dagster.io/blog/smoke-test-data-pipeline](https://dagster.io/blog/smoke-test-data-pipeline).\n\n&amp;#x200B;\n\nI used this heavily as an ML engineer / DE at Motive (nee KeepTruckin).\n\n&amp;#x200B;\n\nHere's the TLDR:\n\n* The idea of the data pipeline smoke test is to automatically run all your Pandas/PySpark/SQL data transformations on empty or synthetic data.\n* When defining your data pipeline, you include metadata on your data assets - e.g., column schemas - that determines how to mock them in downstream transformations.\n* The advantage of smoke tests is that you write them just once: you don\u2019t need to write a test for every newly derived data asset.\n* If your smoke test can execute quickly, it can become part of your dev loop and help you catch issues much more quickly than you would if you were executing on full data or writing a unit test.", "author_fullname": "t2_1jjs655y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Smoke tests for data pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycq87y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666655018.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wrote a blog post on smoke-testing data pipelines: &lt;a href=\"https://dagster.io/blog/smoke-test-data-pipeline\"&gt;https://dagster.io/blog/smoke-test-data-pipeline&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I used this heavily as an ML engineer / DE at Motive (nee KeepTruckin).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the TLDR:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The idea of the data pipeline smoke test is to automatically run all your Pandas/PySpark/SQL data transformations on empty or synthetic data.&lt;/li&gt;\n&lt;li&gt;When defining your data pipeline, you include metadata on your data assets - e.g., column schemas - that determines how to mock them in downstream transformations.&lt;/li&gt;\n&lt;li&gt;The advantage of smoke tests is that you write them just once: you don\u2019t need to write a test for every newly derived data asset.&lt;/li&gt;\n&lt;li&gt;If your smoke test can execute quickly, it can become part of your dev loop and help you catch issues much more quickly than you would if you were executing on full data or writing a unit test.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/PAOa0yKSko47lIi7At6Qv-MiqN692lWZHS95v4sznB0.jpg?auto=webp&amp;s=e9cc383395dc438c3eea16815fc12f1778b197e5", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/PAOa0yKSko47lIi7At6Qv-MiqN692lWZHS95v4sznB0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4e7616b5ef090ce54cd4d6a3e46f867f90464bdd", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/PAOa0yKSko47lIi7At6Qv-MiqN692lWZHS95v4sznB0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6fe5b1e0dd5a961496d33b297c9ec8b15aff4889", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/PAOa0yKSko47lIi7At6Qv-MiqN692lWZHS95v4sznB0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=511adede696708c58a8a3ddfc673dec17768e988", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/PAOa0yKSko47lIi7At6Qv-MiqN692lWZHS95v4sznB0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=00928a143e6c40ab6ecbf6f4a01568e55c862172", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/PAOa0yKSko47lIi7At6Qv-MiqN692lWZHS95v4sznB0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e5ff4ac52ddb5161e49bc5c4830694960d20fc02", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/PAOa0yKSko47lIi7At6Qv-MiqN692lWZHS95v4sznB0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7774ff0359446b714c3d7e03503648742752c8f5", "width": 1080, "height": 567}], "variants": {}, "id": "M_lWKOkMiwYDXj9qpLLfNIIeEBz7A4nvy6zVzisia-k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "ycq87y", "is_robot_indexable": true, "report_reasons": null, "author": "FrequentAthlete", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycq87y/smoke_tests_for_data_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycq87y/smoke_tests_for_data_pipelines/", "subreddit_subscribers": 77730, "created_utc": 1666655018.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A comical yet, very accurate take on the current state of the modern Data stack.  What a joke and a massive mess.  I feel like I will be making a lot of money cleaning up and shutting off a lot of garbage in the next 3 years.\n\nhttps://medium.com/@laurengreerbalik/the-modern-data-stack-through-the-gervais-principle-bfd4b4e33ac7", "author_fullname": "t2_59fd6989", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Modern Data Stack is a joke", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycnabu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666647083.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A comical yet, very accurate take on the current state of the modern Data stack.  What a joke and a massive mess.  I feel like I will be making a lot of money cleaning up and shutting off a lot of garbage in the next 3 years.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@laurengreerbalik/the-modern-data-stack-through-the-gervais-principle-bfd4b4e33ac7\"&gt;https://medium.com/@laurengreerbalik/the-modern-data-stack-through-the-gervais-principle-bfd4b4e33ac7&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/gH0xucWP8l6GHZbp8Et6MFGSzwyHs1e1KZValrao2OM.jpg?auto=webp&amp;s=f8b243613670076e36e033a718bad78408a4100a", "width": 1088, "height": 698}, "resolutions": [{"url": "https://external-preview.redd.it/gH0xucWP8l6GHZbp8Et6MFGSzwyHs1e1KZValrao2OM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=67837b0012d4612507c8e668f22223ffc9542f3d", "width": 108, "height": 69}, {"url": "https://external-preview.redd.it/gH0xucWP8l6GHZbp8Et6MFGSzwyHs1e1KZValrao2OM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8e505160e1d9192b3ce2c0cea26202b74c649153", "width": 216, "height": 138}, {"url": "https://external-preview.redd.it/gH0xucWP8l6GHZbp8Et6MFGSzwyHs1e1KZValrao2OM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=91cdb2fd3fbef5b36708fd76cdc719ec83bfa9ab", "width": 320, "height": 205}, {"url": "https://external-preview.redd.it/gH0xucWP8l6GHZbp8Et6MFGSzwyHs1e1KZValrao2OM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2f2e0503114bb23fed9d75d924cf30bac3fad7e8", "width": 640, "height": 410}, {"url": "https://external-preview.redd.it/gH0xucWP8l6GHZbp8Et6MFGSzwyHs1e1KZValrao2OM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b1453c6bd21d8e454f7c99e958d15aa1e7985de1", "width": 960, "height": 615}, {"url": "https://external-preview.redd.it/gH0xucWP8l6GHZbp8Et6MFGSzwyHs1e1KZValrao2OM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a38b9f5271e087af88194476e74e3e17fc0b960e", "width": 1080, "height": 692}], "variants": {}, "id": "_YvsMCd7jSlheVNi0GHad-4zcCtcx35qbnquSZUEAZQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ycnabu", "is_robot_indexable": true, "report_reasons": null, "author": "dongdesk", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycnabu/modern_data_stack_is_a_joke/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycnabu/modern_data_stack_is_a_joke/", "subreddit_subscribers": 77730, "created_utc": 1666647083.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do you experience the same thing? I work for an infra team in a data org, and it seems like the researchers don\u2019t understand basic engineering processes like:\n\n- how to use git\n\n- how to modularize their Python code\n\n- how to not perform full table scan\n\netc.", "author_fullname": "t2_4p45n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it just my feelings or many scientists/analysts don\u2019t know proper engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yd8goa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666713893.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you experience the same thing? I work for an infra team in a data org, and it seems like the researchers don\u2019t understand basic engineering processes like:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;how to use git&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;how to modularize their Python code&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;how to not perform full table scan&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yd8goa", "is_robot_indexable": true, "report_reasons": null, "author": "pinpinbo", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yd8goa/is_it_just_my_feelings_or_many_scientistsanalysts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yd8goa/is_it_just_my_feelings_or_many_scientistsanalysts/", "subreddit_subscribers": 77730, "created_utc": 1666713893.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently a data engineer. Interviewing for a Senior Analytics Engineering role that pays 60% more than my current job. \n\nI'm at a growing startup and I'm happy where I'm at. The WLB is good, my team as nice, and I also get a lot of autonomy to work with different teams, further my technical skills with different technologies, and infrastructure. \n\nThe Senior Analytics Engineer role would be at a well known second tier tech company, like salesforce or Atlassian. My major concern is related to the future outlook of analytics engineering vs data engineering. I feel like data engineering is more versatile, getting to work on a variety of data pipelines and tech stacks, also generating more demand overall in the job market. While Analytics Engineering is primarily SQL, dbt, and Airflow. \n\nI was reached out to by a recruiter so I'm not actively looking at the moment, but I'm wondering if an opportunity to get a name brand company, and increase my comp by 60% is too good of an opportunity to pass up. \n\nAny feedback would be appreciated!", "author_fullname": "t2_8x16rrzg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career Advice, Senior Analytics Engineer or Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycnbdp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 7, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666647157.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently a data engineer. Interviewing for a Senior Analytics Engineering role that pays 60% more than my current job. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m at a growing startup and I&amp;#39;m happy where I&amp;#39;m at. The WLB is good, my team as nice, and I also get a lot of autonomy to work with different teams, further my technical skills with different technologies, and infrastructure. &lt;/p&gt;\n\n&lt;p&gt;The Senior Analytics Engineer role would be at a well known second tier tech company, like salesforce or Atlassian. My major concern is related to the future outlook of analytics engineering vs data engineering. I feel like data engineering is more versatile, getting to work on a variety of data pipelines and tech stacks, also generating more demand overall in the job market. While Analytics Engineering is primarily SQL, dbt, and Airflow. &lt;/p&gt;\n\n&lt;p&gt;I was reached out to by a recruiter so I&amp;#39;m not actively looking at the moment, but I&amp;#39;m wondering if an opportunity to get a name brand company, and increase my comp by 60% is too good of an opportunity to pass up. &lt;/p&gt;\n\n&lt;p&gt;Any feedback would be appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 150, "id": "award_f44611f1-b89e-46dc-97fe-892280b13b82", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Thank you stranger. Shows the award.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Helpful", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ycnbdp", "is_robot_indexable": true, "report_reasons": null, "author": "Justanotherguy2022", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/ycnbdp/career_advice_senior_analytics_engineer_or_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycnbdp/career_advice_senior_analytics_engineer_or_data/", "subreddit_subscribers": 77730, "created_utc": 1666647157.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been experimenting with moving parts of my data pipeline to Delta Live Tables and have found some limitations:\n\n1. No JVM support - this means no scala, no Py4J and most importantly, no spark-xml;\n2. No pivot support - this isn't a hard rule, but you can't pivot between live tables;\n3. Only 1 supported DLT storage location per pipeline;\n4. No XML support - I mentioned this in #1, but it deserves it's own callout.\n\nI'm wondering who's using this tool considering these limitations. I can see the usefulness for silver/gold, but I see plenty of guidance around using autoloader with DLT, but I struggle to see how that would work if you have xml sources or sources that need to be pivoted.\n\nI would like to hear if you have evaluated DLT and if you're using it, your use case, especially if you're using it with autoloader!", "author_fullname": "t2_41da5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are You Using Databricks Delta Live Tables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yd59hx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666705643.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been experimenting with moving parts of my data pipeline to Delta Live Tables and have found some limitations:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;No JVM support - this means no scala, no Py4J and most importantly, no spark-xml;&lt;/li&gt;\n&lt;li&gt;No pivot support - this isn&amp;#39;t a hard rule, but you can&amp;#39;t pivot between live tables;&lt;/li&gt;\n&lt;li&gt;Only 1 supported DLT storage location per pipeline;&lt;/li&gt;\n&lt;li&gt;No XML support - I mentioned this in #1, but it deserves it&amp;#39;s own callout.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;m wondering who&amp;#39;s using this tool considering these limitations. I can see the usefulness for silver/gold, but I see plenty of guidance around using autoloader with DLT, but I struggle to see how that would work if you have xml sources or sources that need to be pivoted.&lt;/p&gt;\n\n&lt;p&gt;I would like to hear if you have evaluated DLT and if you&amp;#39;re using it, your use case, especially if you&amp;#39;re using it with autoloader!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yd59hx", "is_robot_indexable": true, "report_reasons": null, "author": "dylanberry", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yd59hx/are_you_using_databricks_delta_live_tables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yd59hx/are_you_using_databricks_delta_live_tables/", "subreddit_subscribers": 77730, "created_utc": 1666705643.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the subject says , I'm going to focus more on the SQL from scratch as i see a good future in the SQL . So I'm going to strengthen my skill in SQL in flavour of data engineering . Can someone recommend a good course paid or free to achieve my targets by Dec 2022.\n\ndaily study time is approx. 1.5 hours/day.", "author_fullname": "t2_3sqs3uub", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best SQL course to Solve Hacker Rank atleast Intermediate levels", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycwwwh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666675893.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the subject says , I&amp;#39;m going to focus more on the SQL from scratch as i see a good future in the SQL . So I&amp;#39;m going to strengthen my skill in SQL in flavour of data engineering . Can someone recommend a good course paid or free to achieve my targets by Dec 2022.&lt;/p&gt;\n\n&lt;p&gt;daily study time is approx. 1.5 hours/day.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ycwwwh", "is_robot_indexable": true, "report_reasons": null, "author": "priyasweety1", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycwwwh/best_sql_course_to_solve_hacker_rank_atleast/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycwwwh/best_sql_course_to_solve_hacker_rank_atleast/", "subreddit_subscribers": 77730, "created_utc": 1666675893.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Edit: [have donated](https://imgur.com/K5VDTqu) $50 for the first 5 suggestions, please keep them coming. Thank you.\n\nSay you have a data producer and a data consumer, and changes in the data structure of data produced by the data producer cause a downstream model to break (e.g., business analytics, production ready model, or even customer facing application).\n\n**What are the** ***most common*** **examples of data structure changes that would cause a downstream model to break?** Please feel free to list as many as you can think of, or the \"why\", or context on how they occur, etc.\n\nOne example might be where a column is deleted from a production database by the software engineer that owns the data producing system, so the data consumer loses that column of data (this might be an elementary example just trying to illustrate the idea - looking for ideas other than deletion).\n\n**Thanks so much!**\n\nps - I would offer to donate more but I am just a student", "author_fullname": "t2_rcx1cqyo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[For every real example up to 10 examples I will donate $10 to charity and post proof] What are some examples of data structure changes that cause downstream models that consume that data to break?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycrzmp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666661964.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666660173.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Edit: &lt;a href=\"https://imgur.com/K5VDTqu\"&gt;have donated&lt;/a&gt; $50 for the first 5 suggestions, please keep them coming. Thank you.&lt;/p&gt;\n\n&lt;p&gt;Say you have a data producer and a data consumer, and changes in the data structure of data produced by the data producer cause a downstream model to break (e.g., business analytics, production ready model, or even customer facing application).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What are the&lt;/strong&gt; &lt;strong&gt;&lt;em&gt;most common&lt;/em&gt;&lt;/strong&gt; &lt;strong&gt;examples of data structure changes that would cause a downstream model to break?&lt;/strong&gt; Please feel free to list as many as you can think of, or the &amp;quot;why&amp;quot;, or context on how they occur, etc.&lt;/p&gt;\n\n&lt;p&gt;One example might be where a column is deleted from a production database by the software engineer that owns the data producing system, so the data consumer loses that column of data (this might be an elementary example just trying to illustrate the idea - looking for ideas other than deletion).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Thanks so much!&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;ps - I would offer to donate more but I am just a student&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Wlx-GYAT2Nf1JKYH1vkfAFSUOzl1c3cOGeYrHFEYi5M.jpg?auto=webp&amp;s=80edf78e4dfe295ad9976d00f723addfc40e96ce", "width": 600, "height": 315}, "resolutions": [{"url": "https://external-preview.redd.it/Wlx-GYAT2Nf1JKYH1vkfAFSUOzl1c3cOGeYrHFEYi5M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7f02d32049243461da0ba1c0ebd2425261edc8db", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Wlx-GYAT2Nf1JKYH1vkfAFSUOzl1c3cOGeYrHFEYi5M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=74cbaaac5e44c61682fe74d80b1c3307827710d3", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Wlx-GYAT2Nf1JKYH1vkfAFSUOzl1c3cOGeYrHFEYi5M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=662bd8173fbae193e7c199b6676256a0ea8a374a", "width": 320, "height": 168}], "variants": {}, "id": "K9MXHiDSNYTSbUJeqnGuzFRGz_LCo65_2u1Tz1XYTJY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ycrzmp", "is_robot_indexable": true, "report_reasons": null, "author": "----bubba----", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycrzmp/for_every_real_example_up_to_10_examples_i_will/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycrzmp/for_every_real_example_up_to_10_examples_i_will/", "subreddit_subscribers": 77730, "created_utc": 1666660173.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://www.youtube.com/watch?v=72W\\_VvFRqc0](https://www.youtube.com/watch?v=72W_VvFRqc0)", "author_fullname": "t2_82dwrpz7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kleppmann - Thinking in Events: From Databases to Distributed Collaboration Software", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycp4ll", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666651927.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=72W_VvFRqc0\"&gt;https://www.youtube.com/watch?v=72W_VvFRqc0&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/dxgW-GycjOCKTApgOE6zjuezYYtJHUhCXoiVUEhxuzY.jpg?auto=webp&amp;s=ed654259a482bd39a59877b52db2881f8bd664e7", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/dxgW-GycjOCKTApgOE6zjuezYYtJHUhCXoiVUEhxuzY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c99f64e85a11d1e5ffa0be0e6a8dc342557f5e90", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/dxgW-GycjOCKTApgOE6zjuezYYtJHUhCXoiVUEhxuzY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=366971b8154d1640c014938a56b8bfa7361d4499", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/dxgW-GycjOCKTApgOE6zjuezYYtJHUhCXoiVUEhxuzY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5c2bc5eac035007f1f1e7fb5094d2a33541eff92", "width": 320, "height": 240}], "variants": {}, "id": "Rjv08LfIHTjeTNbRC5GBeA7-UtfZEG8kb-b_rElzhuU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "ycp4ll", "is_robot_indexable": true, "report_reasons": null, "author": "Upstairs-Ad-8440", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycp4ll/kleppmann_thinking_in_events_from_databases_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycp4ll/kleppmann_thinking_in_events_from_databases_to/", "subreddit_subscribers": 77730, "created_utc": 1666651927.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_dfcot0zg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Had some cool discussions yesterday about Window Functions. Anyone read this book it's updated for 2019. I have his two other T-SQL books so I'm gonna go grab this too.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_yd5nsb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/1NNQk60TYzGmqNHCD0XVV4kNaWqVOGddwH_pWLet_Nc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666706659.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/asn99e8l20w91.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/asn99e8l20w91.png?auto=webp&amp;s=37cbc375dd271c080dbe84af2157546b026ccf8d", "width": 1080, "height": 1502}, "resolutions": [{"url": "https://preview.redd.it/asn99e8l20w91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4c3e3c14ef1e53830822afcab9728ff12e66b8b0", "width": 108, "height": 150}, {"url": "https://preview.redd.it/asn99e8l20w91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6425dfdb6eba99d500975dedb189d736418f99f7", "width": 216, "height": 300}, {"url": "https://preview.redd.it/asn99e8l20w91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7b9d5f57395057030ebd571461836cb5f362f80b", "width": 320, "height": 445}, {"url": "https://preview.redd.it/asn99e8l20w91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=fcad977270500f65adc2e5adc3d457a427535779", "width": 640, "height": 890}, {"url": "https://preview.redd.it/asn99e8l20w91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=c62687b9d1e2596289af98c509f4e67233ea5c18", "width": 960, "height": 1335}, {"url": "https://preview.redd.it/asn99e8l20w91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ab375f1d7f88f41d1cfcec183695bc06147e5aec", "width": 1080, "height": 1502}], "variants": {}, "id": "OWZwHhMLAX1bWwIlVrYXh0B2oj_7n9CnnXmKJDlnpd8"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yd5nsb", "is_robot_indexable": true, "report_reasons": null, "author": "DrRedmondNYC", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yd5nsb/had_some_cool_discussions_yesterday_about_window/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/asn99e8l20w91.png", "subreddit_subscribers": 77730, "created_utc": 1666706659.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi fellow members. I hope you have a great start to the day.  \n\n\nI am beginning my Data Engineering journey and I wanted to let you guys know that this subreddit has been of great help to me.  \n\n\nI wanted your opinion as there are experienced and newbies in this field regarding a project that I have started for self-learning. Also, let me know if it is good enough for building my portfolio.  \n\n\nSo here it goes.  \n\n\nI have elevated twitter access. I am fetching tweets using Tweepy.   \nI fetch 10 tweets and I save the last tweet's ID in a text file. I have created a scheduler that gets the last tweet's ID from the text file and fetches a batch of the next 10 tweets. Moving forward, I parse the JSON response and filter out a few columns.   \n\n\n(Below is the part that I am about to build)  \nI would use a Postgres DB (docker image) for Data Warehousing. Furthermore, I am thinking of using Apache Airflow for data pipeline management.   \n\n\nI would love your opinions in guiding me toward a better understanding of the pathway I am following.", "author_fullname": "t2_ecv06uk8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this a good approach for starters?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ydajxs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666718928.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi fellow members. I hope you have a great start to the day.  &lt;/p&gt;\n\n&lt;p&gt;I am beginning my Data Engineering journey and I wanted to let you guys know that this subreddit has been of great help to me.  &lt;/p&gt;\n\n&lt;p&gt;I wanted your opinion as there are experienced and newbies in this field regarding a project that I have started for self-learning. Also, let me know if it is good enough for building my portfolio.  &lt;/p&gt;\n\n&lt;p&gt;So here it goes.  &lt;/p&gt;\n\n&lt;p&gt;I have elevated twitter access. I am fetching tweets using Tweepy.&lt;br/&gt;\nI fetch 10 tweets and I save the last tweet&amp;#39;s ID in a text file. I have created a scheduler that gets the last tweet&amp;#39;s ID from the text file and fetches a batch of the next 10 tweets. Moving forward, I parse the JSON response and filter out a few columns.   &lt;/p&gt;\n\n&lt;p&gt;(Below is the part that I am about to build)&lt;br/&gt;\nI would use a Postgres DB (docker image) for Data Warehousing. Furthermore, I am thinking of using Apache Airflow for data pipeline management.   &lt;/p&gt;\n\n&lt;p&gt;I would love your opinions in guiding me toward a better understanding of the pathway I am following.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ydajxs", "is_robot_indexable": true, "report_reasons": null, "author": "ShahSawari", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ydajxs/is_this_a_good_approach_for_starters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ydajxs/is_this_a_good_approach_for_starters/", "subreddit_subscribers": 77730, "created_utc": 1666718928.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys!\n\nSo i started to work on a personal project with the purpose of learning as many as possible about data engineering.\n\nThe goal is to have as less costs as possible, cause I wont make any $$ out of it, I just want to learn.\n\nTill now: \nI started on render.com (not sure if was the right option) by creating a postgreSQL DB.\n\nI've  wrote a python script that retrieves data from an API source and then stores the data in the DB.\n\nThen some data retrieved from the 1st API source, I am using it as input to a 2nd API source, from which I retrieve data and then again I am storing in the DB.\n\nNow I would like to ask for advice regarding how I should proceed and if is possible to keep going on render.com or if I should shift.\n\nNow I want to:\n\n- run that script daily and append new data to the postgreSQL tables (I have experience with airflow DAGs and tasks but not sure how i can integrate it)\n\n- i guess i need a repo and a VM instance that will run that (but again not sure about the steps in here)\n\n- I want to build also an API that will access the data (I would know how to do that with FastAPI, but not sure how i can make it in the same Repo with the whole thing)\n\n\nBasically I have parts of knowledge from these processes,but I've eve understood how I can have the together with a production &amp; staging environment, how I am actually hosting it, how thea real combination of everything happens.\n\nIf you have any sources I can learn from or advice to give, I would be really thankful.\n\nThank you for your time!", "author_fullname": "t2_b4ypm8ew", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Next steps for an 'app'", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ydab3i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666718343.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys!&lt;/p&gt;\n\n&lt;p&gt;So i started to work on a personal project with the purpose of learning as many as possible about data engineering.&lt;/p&gt;\n\n&lt;p&gt;The goal is to have as less costs as possible, cause I wont make any $$ out of it, I just want to learn.&lt;/p&gt;\n\n&lt;p&gt;Till now: \nI started on render.com (not sure if was the right option) by creating a postgreSQL DB.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve  wrote a python script that retrieves data from an API source and then stores the data in the DB.&lt;/p&gt;\n\n&lt;p&gt;Then some data retrieved from the 1st API source, I am using it as input to a 2nd API source, from which I retrieve data and then again I am storing in the DB.&lt;/p&gt;\n\n&lt;p&gt;Now I would like to ask for advice regarding how I should proceed and if is possible to keep going on render.com or if I should shift.&lt;/p&gt;\n\n&lt;p&gt;Now I want to:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;run that script daily and append new data to the postgreSQL tables (I have experience with airflow DAGs and tasks but not sure how i can integrate it)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;i guess i need a repo and a VM instance that will run that (but again not sure about the steps in here)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I want to build also an API that will access the data (I would know how to do that with FastAPI, but not sure how i can make it in the same Repo with the whole thing)&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Basically I have parts of knowledge from these processes,but I&amp;#39;ve eve understood how I can have the together with a production &amp;amp; staging environment, how I am actually hosting it, how thea real combination of everything happens.&lt;/p&gt;\n\n&lt;p&gt;If you have any sources I can learn from or advice to give, I would be really thankful.&lt;/p&gt;\n\n&lt;p&gt;Thank you for your time!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ydab3i", "is_robot_indexable": true, "report_reasons": null, "author": "Koxinfster", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ydab3i/next_steps_for_an_app/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ydab3i/next_steps_for_an_app/", "subreddit_subscribers": 77730, "created_utc": 1666718343.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I taught myself SQL on my Linux machine, beginner stuff. I'm taking Python at Data Camp...\n\nAm I likely to get a job in DE if my BS and MS are in speech therapy? \n\nAny advice to up my chances? Phrasing in my cover letter and resume? Please and thanks", "author_fullname": "t2_s05lz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE job outlooks without CS degree? (I have other degrees)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yd8zm9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666715160.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I taught myself SQL on my Linux machine, beginner stuff. I&amp;#39;m taking Python at Data Camp...&lt;/p&gt;\n\n&lt;p&gt;Am I likely to get a job in DE if my BS and MS are in speech therapy? &lt;/p&gt;\n\n&lt;p&gt;Any advice to up my chances? Phrasing in my cover letter and resume? Please and thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yd8zm9", "is_robot_indexable": true, "report_reasons": null, "author": "Easygoing_E", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yd8zm9/de_job_outlooks_without_cs_degree_i_have_other/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yd8zm9/de_job_outlooks_without_cs_degree_i_have_other/", "subreddit_subscribers": 77730, "created_utc": 1666715160.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_40ihn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Build a poor man\u2019s data lake from scratch with DuckDB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_yd8ek2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/j19A4gjER4Fhwr0vY1pNx396M63K__MPvGuoQzeyk80.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666713745.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dagster.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://dagster.io/blog/duckdb-data-lake", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9RGWtZ4-Z8omJHxqjou-b1AKtNA-JVZnZc0ds4kNLgE.jpg?auto=webp&amp;s=2e6c2f96643c1dcfc7cc7764de763ca0dd95b1f2", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/9RGWtZ4-Z8omJHxqjou-b1AKtNA-JVZnZc0ds4kNLgE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3033e0f7e8f632ae74930d6dadb1239e520aa9d0", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/9RGWtZ4-Z8omJHxqjou-b1AKtNA-JVZnZc0ds4kNLgE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fde9f0a8a50a6af8a5bdaeaaced07a68b713ab4e", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/9RGWtZ4-Z8omJHxqjou-b1AKtNA-JVZnZc0ds4kNLgE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fe1fc403c19dced88afe11bb301296d719c46aaf", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/9RGWtZ4-Z8omJHxqjou-b1AKtNA-JVZnZc0ds4kNLgE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3e3a43c984c9a9e94d1749cd3f658ae173bc369c", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/9RGWtZ4-Z8omJHxqjou-b1AKtNA-JVZnZc0ds4kNLgE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c96c60ee4bf81a32138efdb5dbec178cf4cf191f", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/9RGWtZ4-Z8omJHxqjou-b1AKtNA-JVZnZc0ds4kNLgE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=04be9cd82ad6ddea129eddc97844a60ae37d26b0", "width": 1080, "height": 607}], "variants": {}, "id": "8jnj5t96vjt3Yjp7iltc9A9N4DlNne1k-U36rzPAqto"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yd8ek2", "is_robot_indexable": true, "report_reasons": null, "author": "floydophone", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yd8ek2/build_a_poor_mans_data_lake_from_scratch_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dagster.io/blog/duckdb-data-lake", "subreddit_subscribers": 77730, "created_utc": 1666713745.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone built an address validation/standardization pipeline or have any advice for my thoughts here? The tools our pipelines are using are FiveTran, Databricks and DBT. \n\nMy basic idea for this pipeline is hit either anyone of the various APIs, SmartyStreets, Melissa, Loqate etc using their respective python SDKs, nightly in a batch process as apart of the cleansing/cleaning process of our loads. \n\nWhen the data is cleaned, we will add a new column for the validated/standardized address. \n\n1. Ingest new records into our raw tables daily (for now twice daily, in the future more frequently)\n2. Create a dataframe from the raw table, but filter on where the standardized address column is null\n3. Create a dictionary with the primary key and the associated address\n4. Send the info to the API in batches\n5. Join the cleaned data back to the dataframe\n6. Join the dataframe back to the table, adding the new cleaned address column\n\nAm I thinking about this correctly? My biggest fear is how long this might take to hit the API several times. Is this something that could be overcome with spark and parallelizing the API call (I haven't looked into this yet)?", "author_fullname": "t2_19klta65", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Address Validation Pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yd58yu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666705604.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone built an address validation/standardization pipeline or have any advice for my thoughts here? The tools our pipelines are using are FiveTran, Databricks and DBT. &lt;/p&gt;\n\n&lt;p&gt;My basic idea for this pipeline is hit either anyone of the various APIs, SmartyStreets, Melissa, Loqate etc using their respective python SDKs, nightly in a batch process as apart of the cleansing/cleaning process of our loads. &lt;/p&gt;\n\n&lt;p&gt;When the data is cleaned, we will add a new column for the validated/standardized address. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Ingest new records into our raw tables daily (for now twice daily, in the future more frequently)&lt;/li&gt;\n&lt;li&gt;Create a dataframe from the raw table, but filter on where the standardized address column is null&lt;/li&gt;\n&lt;li&gt;Create a dictionary with the primary key and the associated address&lt;/li&gt;\n&lt;li&gt;Send the info to the API in batches&lt;/li&gt;\n&lt;li&gt;Join the cleaned data back to the dataframe&lt;/li&gt;\n&lt;li&gt;Join the dataframe back to the table, adding the new cleaned address column&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Am I thinking about this correctly? My biggest fear is how long this might take to hit the API several times. Is this something that could be overcome with spark and parallelizing the API call (I haven&amp;#39;t looked into this yet)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yd58yu", "is_robot_indexable": true, "report_reasons": null, "author": "DRUKSTOP", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yd58yu/address_validation_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yd58yu/address_validation_pipeline/", "subreddit_subscribers": 77730, "created_utc": 1666705604.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey All, \n\nMy team needs data from different systems (HubSpot, Salesforce, Oracle NetSuite etc) into Redshift. I will then use SQL to create specific views and use it in power BI for visualization.\n\nI searched online for companies who provide software to achieve this (Mulesoft, Segment etc) and they charge very high license fees, which my team doesn't have the budget for.\n\nIt's there any other way to achieve my end goal? What should I learn / build in order to get this done?", "author_fullname": "t2_8hvqqklw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to pull data from SaaS into Data Warehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycq2xu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666654586.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey All, &lt;/p&gt;\n\n&lt;p&gt;My team needs data from different systems (HubSpot, Salesforce, Oracle NetSuite etc) into Redshift. I will then use SQL to create specific views and use it in power BI for visualization.&lt;/p&gt;\n\n&lt;p&gt;I searched online for companies who provide software to achieve this (Mulesoft, Segment etc) and they charge very high license fees, which my team doesn&amp;#39;t have the budget for.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s there any other way to achieve my end goal? What should I learn / build in order to get this done?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ycq2xu", "is_robot_indexable": true, "report_reasons": null, "author": "Embarrassed-Yoghurt8", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycq2xu/how_to_pull_data_from_saas_into_data_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycq2xu/how_to_pull_data_from_saas_into_data_warehouse/", "subreddit_subscribers": 77730, "created_utc": 1666654586.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently hired on a 3 months trial contract in a current company. I have 2 years of experience in data space, but this is the first company where I have a legit title of \"data engineer\" (although my scope in previous jobs was definitely focused on data engineering - just under different names), on a mid-level position. Salary-wise it's good, and the project I am on is big and actually pretty well organized and documented (especially compared to some of s*itshow I experienced in a past). The company has its product sold to a big client, which they constantly develop &amp; maintain. This is actually the first project where a testing process is thoroughly planned and implemented on various stages and I think I can learn a lot on how I should do data engineering properly. And where more senior developers are actually skilled &amp; knowledgeable.\n\nI'm in a DataOps team that develops data pipelines and commits data operations, such as migrations. The data are actual big data, reaching TBs of volume per a pipeline. Technology stack is based on AWS, Apache Spark &amp; Trino, and we are migrating a lot into Snowflake which I was advised to learn. There is some DevOps stuff like Kubernetes and Jenkins, which I haven't worked with yet and I'd love to learn these properly. We also use Git in a proper way (I mention it because, laughably, it wasn't implemented in my previous project and it was a pain to deal with other developers).\n\n\nThe only problem is that I am doing almost no coding as for now. Most of my job so far, technically-wise, has been writing SQL queries and JSON config files to properly implement a data pipeline, and manage it via APIs of microservices of my company's application. The app is written in Java/Scala, but I don't touch the development layer. We have some Python utility scripts, but I didn't develop them either. Most of our repositories content are SQL &amp; JSON files, so I expect that it won't change much, unless we'll have more time for other projects. In a previous job, I was doing a lot of Python, as we used Airflow as a main tool, and I hoped to continue on that track.\n\nThis is actually the only reason I am considering not extending this contract. I am afraid that lack of coding will hurt my prospects, as my coding skills would rust over time.\n\nI've wanted to ask you two simple questions:\n1. Should I extend?\n2. Is little/no coding a big deal if I can develop myself in other branches of DE?\n\nTo add a little more of context. I already did some job hopping, having worked 10, 9 &amp; 6 months for 3 respective companies before. Although each change was completely justified, I would like to stick with some company for at least 1 year, to retain some stability, and also to lose the label of a potential infamous 'job-hopper'. I'm on a last year of master's degree, and upon finishing it in ~September, I would like to look for either some good foreign remote contract (I'm Eastern Europe based) or big tech company, treating my company as a \"safe haven\" while trying to fulfill my ambitions.", "author_fullname": "t2_9e7m1qmr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this company a good place for me to spend the next year? I'm afraid of little coding so far.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycnu5w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666648501.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently hired on a 3 months trial contract in a current company. I have 2 years of experience in data space, but this is the first company where I have a legit title of &amp;quot;data engineer&amp;quot; (although my scope in previous jobs was definitely focused on data engineering - just under different names), on a mid-level position. Salary-wise it&amp;#39;s good, and the project I am on is big and actually pretty well organized and documented (especially compared to some of s*itshow I experienced in a past). The company has its product sold to a big client, which they constantly develop &amp;amp; maintain. This is actually the first project where a testing process is thoroughly planned and implemented on various stages and I think I can learn a lot on how I should do data engineering properly. And where more senior developers are actually skilled &amp;amp; knowledgeable.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m in a DataOps team that develops data pipelines and commits data operations, such as migrations. The data are actual big data, reaching TBs of volume per a pipeline. Technology stack is based on AWS, Apache Spark &amp;amp; Trino, and we are migrating a lot into Snowflake which I was advised to learn. There is some DevOps stuff like Kubernetes and Jenkins, which I haven&amp;#39;t worked with yet and I&amp;#39;d love to learn these properly. We also use Git in a proper way (I mention it because, laughably, it wasn&amp;#39;t implemented in my previous project and it was a pain to deal with other developers).&lt;/p&gt;\n\n&lt;p&gt;The only problem is that I am doing almost no coding as for now. Most of my job so far, technically-wise, has been writing SQL queries and JSON config files to properly implement a data pipeline, and manage it via APIs of microservices of my company&amp;#39;s application. The app is written in Java/Scala, but I don&amp;#39;t touch the development layer. We have some Python utility scripts, but I didn&amp;#39;t develop them either. Most of our repositories content are SQL &amp;amp; JSON files, so I expect that it won&amp;#39;t change much, unless we&amp;#39;ll have more time for other projects. In a previous job, I was doing a lot of Python, as we used Airflow as a main tool, and I hoped to continue on that track.&lt;/p&gt;\n\n&lt;p&gt;This is actually the only reason I am considering not extending this contract. I am afraid that lack of coding will hurt my prospects, as my coding skills would rust over time.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve wanted to ask you two simple questions:\n1. Should I extend?\n2. Is little/no coding a big deal if I can develop myself in other branches of DE?&lt;/p&gt;\n\n&lt;p&gt;To add a little more of context. I already did some job hopping, having worked 10, 9 &amp;amp; 6 months for 3 respective companies before. Although each change was completely justified, I would like to stick with some company for at least 1 year, to retain some stability, and also to lose the label of a potential infamous &amp;#39;job-hopper&amp;#39;. I&amp;#39;m on a last year of master&amp;#39;s degree, and upon finishing it in ~September, I would like to look for either some good foreign remote contract (I&amp;#39;m Eastern Europe based) or big tech company, treating my company as a &amp;quot;safe haven&amp;quot; while trying to fulfill my ambitions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ycnu5w", "is_robot_indexable": true, "report_reasons": null, "author": "LewWariat", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycnu5w/is_this_company_a_good_place_for_me_to_spend_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycnu5w/is_this_company_a_good_place_for_me_to_spend_the/", "subreddit_subscribers": 77730, "created_utc": 1666648501.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'd like to hear other people's experiences with MySQL Heatwave.\n\nSeems pretty cool to be able to run analytical queries from the same database. Less effort than building and maintaining an ETL and using something like clickhouse or snowflake.\n\nhttps://docs.oracle.com/en-us/iaas/mysql-database/doc/heatwave.html", "author_fullname": "t2_2tsz5r0r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MySQL Heatwave Experiences", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycml8g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666645383.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;d like to hear other people&amp;#39;s experiences with MySQL Heatwave.&lt;/p&gt;\n\n&lt;p&gt;Seems pretty cool to be able to run analytical queries from the same database. Less effort than building and maintaining an ETL and using something like clickhouse or snowflake.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://docs.oracle.com/en-us/iaas/mysql-database/doc/heatwave.html\"&gt;https://docs.oracle.com/en-us/iaas/mysql-database/doc/heatwave.html&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ycml8g", "is_robot_indexable": true, "report_reasons": null, "author": "nathan026", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ycml8g/mysql_heatwave_experiences/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ycml8g/mysql_heatwave_experiences/", "subreddit_subscribers": 77730, "created_utc": 1666645383.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My team manages two dbt projects in redshift and currently the entire code base runs multiple times a day. This is carried out by a series of docker commands, all of which are triggered at certain intervals by cron. \n\nI am wondering what other options exist out there for job scheduling that might give us more granularity in our commands. For example, maybe I want to run certain models only once a day compared to others which I want to run every time. Or maybe in the event of some sort of process interruption it would be nice to disable a certain model on successive runs without some sort of code change. I know that dbt's tag selectors could achieve the interval separation option, but I am wondering if there are some tools out there that can do both of these and more.", "author_fullname": "t2_6nf2i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trying to understand what scheduling options exist for more granular control of dbt runs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yde071", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666727591.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My team manages two dbt projects in redshift and currently the entire code base runs multiple times a day. This is carried out by a series of docker commands, all of which are triggered at certain intervals by cron. &lt;/p&gt;\n\n&lt;p&gt;I am wondering what other options exist out there for job scheduling that might give us more granularity in our commands. For example, maybe I want to run certain models only once a day compared to others which I want to run every time. Or maybe in the event of some sort of process interruption it would be nice to disable a certain model on successive runs without some sort of code change. I know that dbt&amp;#39;s tag selectors could achieve the interval separation option, but I am wondering if there are some tools out there that can do both of these and more.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yde071", "is_robot_indexable": true, "report_reasons": null, "author": "radil", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yde071/trying_to_understand_what_scheduling_options/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yde071/trying_to_understand_what_scheduling_options/", "subreddit_subscribers": 77730, "created_utc": 1666727591.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A two-day virtual event packed with demos, AMAs, and hands-on labs created by builders, for builders. Immerse yourself in improving your apps, data pipelines, machine learning workflows, and much more. Join here - [https://www.snowflake.com/build/?utm\\_source=dataops.live&amp;utm\\_medium=partner&amp;utm\\_campaign=na-us-en-&amp;utm\\_content=-evv-build-virtual-](https://www.snowflake.com/build/?utm_source=dataops.live&amp;utm_medium=partner&amp;utm_campaign=na-us-en-&amp;utm_content=-evv-build-virtual-)\n\n[Snowflake Build - DataOps.live](https://preview.redd.it/6m4yb5wv50w91.png?width=1200&amp;format=png&amp;auto=webp&amp;s=8c74b932a764b6b86b4f4b83c959240cb29562ca)", "author_fullname": "t2_12li6zgs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake BUILD '22 - The Data Cloud Dev Virtual Summit (NOV 15-16)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": true, "media_metadata": {"6m4yb5wv50w91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 56, "x": 108, "u": "https://preview.redd.it/6m4yb5wv50w91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a0d5524019ff358784c4cb1f4ea59106dc489f48"}, {"y": 113, "x": 216, "u": "https://preview.redd.it/6m4yb5wv50w91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ba5cf3ba73b6d773ca774af56c88ffa5346a5f70"}, {"y": 167, "x": 320, "u": "https://preview.redd.it/6m4yb5wv50w91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=22c33b96e783f6e96d3013f6bfafb7a605dfac3c"}, {"y": 334, "x": 640, "u": "https://preview.redd.it/6m4yb5wv50w91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=38a42e8c9dc9f43e5502c030939e0cd8d4ef64e5"}, {"y": 502, "x": 960, "u": "https://preview.redd.it/6m4yb5wv50w91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=47b306bd0d19f5da0ec24344212e2d5ad7a24da8"}, {"y": 565, "x": 1080, "u": "https://preview.redd.it/6m4yb5wv50w91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9b405677af2146b6f9eb37d624987ac4b062f900"}], "s": {"y": 628, "x": 1200, "u": "https://preview.redd.it/6m4yb5wv50w91.png?width=1200&amp;format=png&amp;auto=webp&amp;s=8c74b932a764b6b86b4f4b83c959240cb29562ca"}, "id": "6m4yb5wv50w91"}}, "name": "t3_yddpbm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/2Ze2TDkBmRn-wnSD6yb_CEI7u-Y4m7KOqOacZRkVfao.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666726832.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A two-day virtual event packed with demos, AMAs, and hands-on labs created by builders, for builders. Immerse yourself in improving your apps, data pipelines, machine learning workflows, and much more. Join here - &lt;a href=\"https://www.snowflake.com/build/?utm_source=dataops.live&amp;amp;utm_medium=partner&amp;amp;utm_campaign=na-us-en-&amp;amp;utm_content=-evv-build-virtual-\"&gt;https://www.snowflake.com/build/?utm_source=dataops.live&amp;amp;utm_medium=partner&amp;amp;utm_campaign=na-us-en-&amp;amp;utm_content=-evv-build-virtual-&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/6m4yb5wv50w91.png?width=1200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8c74b932a764b6b86b4f4b83c959240cb29562ca\"&gt;Snowflake Build - DataOps.live&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yddpbm", "is_robot_indexable": true, "report_reasons": null, "author": "Dkreig", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yddpbm/snowflake_build_22_the_data_cloud_dev_virtual/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yddpbm/snowflake_build_22_the_data_cloud_dev_virtual/", "subreddit_subscribers": 77730, "created_utc": 1666726832.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How can I save the output of a variable (one specific value i.e. sql query used to get the latest BatchID) to use and reference in another variable, variable B?\n\nCurrently, I am trying to do just that - reference variable A in variable B - I just want the output of variable A (the latest BatchID) to use in the WHERE clause of variable B.\n\nHowever, when I evaluate the expression - it's showing the whole query used to obtain the output of variable A as well as variable B (so it looks like two queries, when in reality, I just want the value of variable A to reference in variable B).\n\nDoes that make sense? Does this sound right? Or what am I doing wrong?", "author_fullname": "t2_gsch4oaq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SSIS Variables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yddind", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666726360.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How can I save the output of a variable (one specific value i.e. sql query used to get the latest BatchID) to use and reference in another variable, variable B?&lt;/p&gt;\n\n&lt;p&gt;Currently, I am trying to do just that - reference variable A in variable B - I just want the output of variable A (the latest BatchID) to use in the WHERE clause of variable B.&lt;/p&gt;\n\n&lt;p&gt;However, when I evaluate the expression - it&amp;#39;s showing the whole query used to obtain the output of variable A as well as variable B (so it looks like two queries, when in reality, I just want the value of variable A to reference in variable B).&lt;/p&gt;\n\n&lt;p&gt;Does that make sense? Does this sound right? Or what am I doing wrong?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yddind", "is_robot_indexable": true, "report_reasons": null, "author": "xxEiGhTyxx", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yddind/ssis_variables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yddind/ssis_variables/", "subreddit_subscribers": 77730, "created_utc": 1666726360.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "With all the discussion of OBT/Wide Tables, I having a devil of a time finding **actual examples**.  I thought I might be crazy for asking, but [another post](https://www.reddit.com/r/dataengineering/comments/oy8b2x/does_obt_one_big_table_really_mean_one_big_table/) convinced me I'm not.\n\n**Can a few of you please show an example of wide tables that actually gets used in production?**\n\nI have 15GB of data in Bigquery (not that much).  It doesn't change often (annually).  But, the data is not typical business transactional data, but education data (e.g. enrollment, student performance, staffing, finances).  I need to ask questions across these domains and am finding NO examples of how we might do it with wide tables in practice.\n\nI have an example galaxy schema set up for an intermediate step, but it seems like lots of work to ultimately turn it into wide tables for analysis anyway.", "author_fullname": "t2_4d8caxd5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need example of OBT or Wide Tables for data warehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ydc5cr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666722900.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With all the discussion of OBT/Wide Tables, I having a devil of a time finding &lt;strong&gt;actual examples&lt;/strong&gt;.  I thought I might be crazy for asking, but &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/oy8b2x/does_obt_one_big_table_really_mean_one_big_table/\"&gt;another post&lt;/a&gt; convinced me I&amp;#39;m not.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Can a few of you please show an example of wide tables that actually gets used in production?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I have 15GB of data in Bigquery (not that much).  It doesn&amp;#39;t change often (annually).  But, the data is not typical business transactional data, but education data (e.g. enrollment, student performance, staffing, finances).  I need to ask questions across these domains and am finding NO examples of how we might do it with wide tables in practice.&lt;/p&gt;\n\n&lt;p&gt;I have an example galaxy schema set up for an intermediate step, but it seems like lots of work to ultimately turn it into wide tables for analysis anyway.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ydc5cr", "is_robot_indexable": true, "report_reasons": null, "author": "realistdreamer69", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ydc5cr/need_example_of_obt_or_wide_tables_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ydc5cr/need_example_of_obt_or_wide_tables_for_data/", "subreddit_subscribers": 77730, "created_utc": 1666722900.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}