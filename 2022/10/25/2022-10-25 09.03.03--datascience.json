{"kind": "Listing", "data": {"after": "t3_ycju7g", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_pgekz9xq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data = Oil", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_ycgmbu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 983, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 983, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/K5J_BSCyRQDJoMsr8nhxvy8-ESblRMi-HxMECAJgVN0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666631018.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/d8xfyn96csv91.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/d8xfyn96csv91.jpg?auto=webp&amp;s=48f01d982fa426511e57b10798d7705da3b4a886", "width": 852, "height": 480}, "resolutions": [{"url": "https://preview.redd.it/d8xfyn96csv91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=62965aa586841884add9045ed1559c8be7ddd049", "width": 108, "height": 60}, {"url": "https://preview.redd.it/d8xfyn96csv91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=792fb45f3dac2f5311553f196c676c124e219815", "width": 216, "height": 121}, {"url": "https://preview.redd.it/d8xfyn96csv91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f09daae077ef3533990ee367cf101abcab8c2dfa", "width": 320, "height": 180}, {"url": "https://preview.redd.it/d8xfyn96csv91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=255e3964c59f6cd1f31ab87a73a64d1e2c0ca279", "width": 640, "height": 360}], "variants": {}, "id": "Q-HjxdQz5vk91t1DpeWTRa9kV7vg_lCn2_8fEDG1cU8"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycgmbu", "is_robot_indexable": true, "report_reasons": null, "author": "realbigflavor", "discussion_type": null, "num_comments": 63, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ycgmbu/data_oil/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/d8xfyn96csv91.jpg", "subreddit_subscribers": 815258, "created_utc": 1666631018.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_5hgh94wf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I made a website to practice for DS interviews", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_ycmt6a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 182, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 182, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/qxbhMbs5kLBOXOsYO64L5-d-oE7E7mEQVbgjIaolv9I.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666645915.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/yat3ccovjtv91.gif", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/yat3ccovjtv91.gif?format=png8&amp;s=fef8022ab37793433352c42e2d5b2507d5b78832", "width": 886, "height": 1920}, "resolutions": [{"url": "https://preview.redd.it/yat3ccovjtv91.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=0598ee1817fd103310dc2ed86e90bbf24f905a24", "width": 108, "height": 216}, {"url": "https://preview.redd.it/yat3ccovjtv91.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=4ae42f420b71b1b05aaec22270ff2f76fe47b89e", "width": 216, "height": 432}, {"url": "https://preview.redd.it/yat3ccovjtv91.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=4415010166ee4736d841ae28cadb1323953a4683", "width": 320, "height": 640}, {"url": "https://preview.redd.it/yat3ccovjtv91.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=6a75b70884969f3c356f64b11637ae6960d70dac", "width": 640, "height": 1280}], "variants": {"gif": {"source": {"url": "https://preview.redd.it/yat3ccovjtv91.gif?s=6b5aabf78d7ac7e10dbafb5d2a2a8718f626ddce", "width": 886, "height": 1920}, "resolutions": [{"url": "https://preview.redd.it/yat3ccovjtv91.gif?width=108&amp;crop=smart&amp;s=a62d539652b7bab8d5b49c45925850c87b32a7f0", "width": 108, "height": 216}, {"url": "https://preview.redd.it/yat3ccovjtv91.gif?width=216&amp;crop=smart&amp;s=a692e1086d6ff024412c218e26b72b15815aea17", "width": 216, "height": 432}, {"url": "https://preview.redd.it/yat3ccovjtv91.gif?width=320&amp;crop=smart&amp;s=3421990e252d8a7e9116c5e17f8d9eabe13a844a", "width": 320, "height": 640}, {"url": "https://preview.redd.it/yat3ccovjtv91.gif?width=640&amp;crop=smart&amp;s=381238f8102b4ac742ade662c9db813efb578cb4", "width": 640, "height": 1280}]}, "mp4": {"source": {"url": "https://preview.redd.it/yat3ccovjtv91.gif?format=mp4&amp;s=53d91ef1068d058930eb3112cbe7d59efaa0993c", "width": 886, "height": 1920}, "resolutions": [{"url": "https://preview.redd.it/yat3ccovjtv91.gif?width=108&amp;format=mp4&amp;s=308b2d75d79832ce1b76929c4ef98819b5482ad3", "width": 108, "height": 216}, {"url": "https://preview.redd.it/yat3ccovjtv91.gif?width=216&amp;format=mp4&amp;s=9bdac4851da0510226be2298105b0a196d6bf0fb", "width": 216, "height": 432}, {"url": "https://preview.redd.it/yat3ccovjtv91.gif?width=320&amp;format=mp4&amp;s=d6c10e321666bccc59e50fefd4ba951923a3f787", "width": 320, "height": 640}, {"url": "https://preview.redd.it/yat3ccovjtv91.gif?width=640&amp;format=mp4&amp;s=821209e734ebd499ee30de420f44b2e49cf0691e", "width": 640, "height": 1280}]}}, "id": "fmy6tnvJInWKk4R2Yq378FjgAmvJUz-qZOTOs-d81Wo"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycmt6a", "is_robot_indexable": true, "report_reasons": null, "author": "santiviquez", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ycmt6a/i_made_a_website_to_practice_for_ds_interviews/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/yat3ccovjtv91.gif", "subreddit_subscribers": 815258, "created_utc": 1666645915.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So our company \"bought\" databricks and now they want us to use it for everything :D I understand that it's a very good platform for data engineering but is anyone using it for ML? \nIt always spins up a spark cluster so simply using it as a notebook to train tensorflow model looks like a waste of reasources. It has MLflow but other than that it looks like a poor platform for ML.  Or am I wrong here?", "author_fullname": "t2_sl11q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks as ML platform?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycb20j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 47, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 47, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666617530.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So our company &amp;quot;bought&amp;quot; databricks and now they want us to use it for everything :D I understand that it&amp;#39;s a very good platform for data engineering but is anyone using it for ML? \nIt always spins up a spark cluster so simply using it as a notebook to train tensorflow model looks like a waste of reasources. It has MLflow but other than that it looks like a poor platform for ML.  Or am I wrong here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycb20j", "is_robot_indexable": true, "report_reasons": null, "author": "07Zulrah", "discussion_type": null, "num_comments": 46, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ycb20j/databricks_as_ml_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ycb20j/databricks_as_ml_platform/", "subreddit_subscribers": 815258, "created_utc": 1666617530.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have 4.5 years of work experience in the data analytics/science domain, of which I spent:\n- 2 years at one company as Data Analyst, where I was mostly building dashboards visualising predictions from sklearn models (\"classical ML\")\n- 1.5 years at another company as a Data Scientist, where I was building PoC apps using deep learning algorithms, mostly computer vision, but a couple of NLP projects as well\n- and the last 1 year at my current company as an AI consultant, where I'm building PoC models by creating simulated datasets, as it's a startup and we don't have any real-world data yet.\n\nSo, as you can see, I have not done any real heavy-duty deployment work at any of my roles, as I was never required to. **What I do have is data science experience** - I can do ETL jobs, I can explain the math of most of the classical ML stuff, and some of the \"beginner-level\" deep learning stuff like CNNs, make APIs out of them, and I've done simple deployments in Heroku for my personal projects. **I'm giving you this long-ish backdrop so that you understand how hard the take-home assignment was for the interview I gave last week, which was for an ML Engineer role.** The task was to take a Huggingface transformer model, fine-tune it on their data, deploy it with Kuberbetes, and make it consumable via an API. ***I had absolutely no idea about any of these*** (except making API endpoints) ***before, and I was given 1 week to compete it.*** So, here goes my journey.\n\nDue to my actual work occupying much of the workday, I was not able to give much time to the assignment for the first couple of days. So I had to work extra hard to learn all that stuff within 4-5 days, which I did by working late into the night. The last 2 days I was working deep into the night, trying to get the deployment right and the k8s cluster to function as expected, until 4:30 am.\n\nSo anyway, I submitted the assignment, satisfied and happy that I was able to get the thing working. The recruiter informed me that the company would like to interview me for the next round, hurray. In the interview, I explained to them how I built the model, how I deployed it, how it would take care of variable loads, etc. **Then they asked me, how do you do model versioning and retraining?** Honestly, I've never done it using any formal tooling purpose-built for this task. I just rename my models with a timestamp, if at all I need to, which like I mentioned before is for PoC projects, which is what my roles have entailed so far, and not for productionizing and deployment. So I said as much and also that I use Git for versioning. Well, they said Git is good for versioning code, but it's not sufficient for models.\n\nAnyway, got the news from the recruiter that I didn't pass the interview. I looked up (Googled) \"model versioning\" after the interview, it seems I needed to reply with \"ML Flow\" as the answer. If only I could blabber, \"I use MLflow and Jenkins for model versioning and CICD/orchestration\", I think I would have gotten through to the next round in the interview process. But alas, getting through to 90-95% of the way - **starting from zero mind you** - isn't enough anymore. Because if it was, they could have known or understood that if this guy can learn docker and kuberbetes and GKE within 4-5 days and build a working prototype of an app, compete with a UI and everything, as a full-fledged product with a deep-learning model that he fine-tuned on custom data, then he can definitely learn f**kin MLflow and Jenkins within another week. \n\nOh and, by the way, they never even proposed to reimburse me for the ~ US$ 22 that I spent on building and running the cluster for a week. Not that $22 matters a lot to me - in fact I'm glad I learnt how to use GKE within 3-4 days with that $22, so it's money well spent imo - but it is a matter of principles, honour, ethics and just plain old manners.\n\nSo, do you think my frustration and hurt is justified? Or do you think they're right in having rejected me instead of seeing my potential? Personally, I feel like if a company is only gonna employ people that fulfil 100% of their requirements, where is the scope of growth in it?", "author_fullname": "t2_79v29l8u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Got rejected from ML Engineer role despite completing a tough take-home assignment, because of not knowing about specific tool(s) used for model versioning and retraining. Do you think it's fair or unfair?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycgxzf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666643804.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666631802.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 4.5 years of work experience in the data analytics/science domain, of which I spent:\n- 2 years at one company as Data Analyst, where I was mostly building dashboards visualising predictions from sklearn models (&amp;quot;classical ML&amp;quot;)\n- 1.5 years at another company as a Data Scientist, where I was building PoC apps using deep learning algorithms, mostly computer vision, but a couple of NLP projects as well\n- and the last 1 year at my current company as an AI consultant, where I&amp;#39;m building PoC models by creating simulated datasets, as it&amp;#39;s a startup and we don&amp;#39;t have any real-world data yet.&lt;/p&gt;\n\n&lt;p&gt;So, as you can see, I have not done any real heavy-duty deployment work at any of my roles, as I was never required to. &lt;strong&gt;What I do have is data science experience&lt;/strong&gt; - I can do ETL jobs, I can explain the math of most of the classical ML stuff, and some of the &amp;quot;beginner-level&amp;quot; deep learning stuff like CNNs, make APIs out of them, and I&amp;#39;ve done simple deployments in Heroku for my personal projects. &lt;strong&gt;I&amp;#39;m giving you this long-ish backdrop so that you understand how hard the take-home assignment was for the interview I gave last week, which was for an ML Engineer role.&lt;/strong&gt; The task was to take a Huggingface transformer model, fine-tune it on their data, deploy it with Kuberbetes, and make it consumable via an API. &lt;strong&gt;&lt;em&gt;I had absolutely no idea about any of these&lt;/em&gt;&lt;/strong&gt; (except making API endpoints) &lt;strong&gt;&lt;em&gt;before, and I was given 1 week to compete it.&lt;/em&gt;&lt;/strong&gt; So, here goes my journey.&lt;/p&gt;\n\n&lt;p&gt;Due to my actual work occupying much of the workday, I was not able to give much time to the assignment for the first couple of days. So I had to work extra hard to learn all that stuff within 4-5 days, which I did by working late into the night. The last 2 days I was working deep into the night, trying to get the deployment right and the k8s cluster to function as expected, until 4:30 am.&lt;/p&gt;\n\n&lt;p&gt;So anyway, I submitted the assignment, satisfied and happy that I was able to get the thing working. The recruiter informed me that the company would like to interview me for the next round, hurray. In the interview, I explained to them how I built the model, how I deployed it, how it would take care of variable loads, etc. &lt;strong&gt;Then they asked me, how do you do model versioning and retraining?&lt;/strong&gt; Honestly, I&amp;#39;ve never done it using any formal tooling purpose-built for this task. I just rename my models with a timestamp, if at all I need to, which like I mentioned before is for PoC projects, which is what my roles have entailed so far, and not for productionizing and deployment. So I said as much and also that I use Git for versioning. Well, they said Git is good for versioning code, but it&amp;#39;s not sufficient for models.&lt;/p&gt;\n\n&lt;p&gt;Anyway, got the news from the recruiter that I didn&amp;#39;t pass the interview. I looked up (Googled) &amp;quot;model versioning&amp;quot; after the interview, it seems I needed to reply with &amp;quot;ML Flow&amp;quot; as the answer. If only I could blabber, &amp;quot;I use MLflow and Jenkins for model versioning and CICD/orchestration&amp;quot;, I think I would have gotten through to the next round in the interview process. But alas, getting through to 90-95% of the way - &lt;strong&gt;starting from zero mind you&lt;/strong&gt; - isn&amp;#39;t enough anymore. Because if it was, they could have known or understood that if this guy can learn docker and kuberbetes and GKE within 4-5 days and build a working prototype of an app, compete with a UI and everything, as a full-fledged product with a deep-learning model that he fine-tuned on custom data, then he can definitely learn f**kin MLflow and Jenkins within another week. &lt;/p&gt;\n\n&lt;p&gt;Oh and, by the way, they never even proposed to reimburse me for the ~ US$ 22 that I spent on building and running the cluster for a week. Not that $22 matters a lot to me - in fact I&amp;#39;m glad I learnt how to use GKE within 3-4 days with that $22, so it&amp;#39;s money well spent imo - but it is a matter of principles, honour, ethics and just plain old manners.&lt;/p&gt;\n\n&lt;p&gt;So, do you think my frustration and hurt is justified? Or do you think they&amp;#39;re right in having rejected me instead of seeing my potential? Personally, I feel like if a company is only gonna employ people that fulfil 100% of their requirements, where is the scope of growth in it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycgxzf", "is_robot_indexable": true, "report_reasons": null, "author": "ResearcherNo4728", "discussion_type": null, "num_comments": 59, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ycgxzf/got_rejected_from_ml_engineer_role_despite/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ycgxzf/got_rejected_from_ml_engineer_role_despite/", "subreddit_subscribers": 815258, "created_utc": 1666631802.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "It seems like a significant amount of that for me is used on doing \"nothing productive\".", "author_fullname": "t2_amfdjuba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[PRODUCTIVITY-RELATED] If you work 8 hours a day, how many of those hours are productive hours?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycxcw3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666677572.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It seems like a significant amount of that for me is used on doing &amp;quot;nothing productive&amp;quot;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycxcw3", "is_robot_indexable": true, "report_reasons": null, "author": "limedove", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ycxcw3/productivityrelated_if_you_work_8_hours_a_day_how/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ycxcw3/productivityrelated_if_you_work_8_hours_a_day_how/", "subreddit_subscribers": 815258, "created_utc": 1666677572.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "We would like to make a small collection of essential or interesting data science/ML books at our department. Might be any related field, also business oriented titles are welcome. Could you please suggest 4-5 books published no earlier than 2019? Thanks a lot!", "author_fullname": "t2_ndl92", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Books worth having at hand?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycjcyk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666637623.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We would like to make a small collection of essential or interesting data science/ML books at our department. Might be any related field, also business oriented titles are welcome. Could you please suggest 4-5 books published no earlier than 2019? Thanks a lot!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycjcyk", "is_robot_indexable": true, "report_reasons": null, "author": "cv_be", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ycjcyk/books_worth_having_at_hand/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ycjcyk/books_worth_having_at_hand/", "subreddit_subscribers": 815258, "created_utc": 1666637623.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone! \n\nI\u2019m currently a bit confused career-wise and would like to ask your opinion and advice on improving my skills. \n\nMy goal professionally is to work in data science in a finance related company (although I\u2019m open to other ideas too). I have a bachelors degree in economics and I\u2019m now finishing my master in data science and economics. Putting a lot of effort over the last two years, I\u2019ve managed to achieve a solid intermediate level in Python, R, Tableau and PostgreSQL. I also work part time as a tech freelancer in a startup (but more on the data collection side). \n\nLately I\u2019ve been asking a couple of professors and co-workers about data science career options and skills to improve. Some of them directly say that I need a degree in computer science. What is your opinion? After my master I would like to get a full time job, but I can\u2019t help but think that I\u2019m lacking skills. Is a computer science degree in my situation necessary, or are there other certificates/tools I can carry out to improve? Lately I\u2019ve considered undertaking the professional data engineer certification for Google cloud to broaden my skills. What do you think?", "author_fullname": "t2_3s1pvyko", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting my foot on the door with a data science master? Tips on improving my skills?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycgdv5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666630479.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone! &lt;/p&gt;\n\n&lt;p&gt;I\u2019m currently a bit confused career-wise and would like to ask your opinion and advice on improving my skills. &lt;/p&gt;\n\n&lt;p&gt;My goal professionally is to work in data science in a finance related company (although I\u2019m open to other ideas too). I have a bachelors degree in economics and I\u2019m now finishing my master in data science and economics. Putting a lot of effort over the last two years, I\u2019ve managed to achieve a solid intermediate level in Python, R, Tableau and PostgreSQL. I also work part time as a tech freelancer in a startup (but more on the data collection side). &lt;/p&gt;\n\n&lt;p&gt;Lately I\u2019ve been asking a couple of professors and co-workers about data science career options and skills to improve. Some of them directly say that I need a degree in computer science. What is your opinion? After my master I would like to get a full time job, but I can\u2019t help but think that I\u2019m lacking skills. Is a computer science degree in my situation necessary, or are there other certificates/tools I can carry out to improve? Lately I\u2019ve considered undertaking the professional data engineer certification for Google cloud to broaden my skills. What do you think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycgdv5", "is_robot_indexable": true, "report_reasons": null, "author": "Tiffanys_Coma", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ycgdv5/getting_my_foot_on_the_door_with_a_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ycgdv5/getting_my_foot_on_the_door_with_a_data_science/", "subreddit_subscribers": 815258, "created_utc": 1666630479.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In almost all the learning material and tutorials i've observed that the training of the model is done everytime the application is executed. I understand that training would be required everytime if the type of data changes but for a real world application do we have to teach it how to run everytime?\n\ne.g. in an application that forecasts some values based on a dataset that grows with time, do i have to train my model each time i request a forecast?", "author_fullname": "t2_n732f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Newbie here. Do people train their models everytime an app runs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycxtn8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666679395.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In almost all the learning material and tutorials i&amp;#39;ve observed that the training of the model is done everytime the application is executed. I understand that training would be required everytime if the type of data changes but for a real world application do we have to teach it how to run everytime?&lt;/p&gt;\n\n&lt;p&gt;e.g. in an application that forecasts some values based on a dataset that grows with time, do i have to train my model each time i request a forecast?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycxtn8", "is_robot_indexable": true, "report_reasons": null, "author": "buckypimpin", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ycxtn8/newbie_here_do_people_train_their_models/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ycxtn8/newbie_here_do_people_train_their_models/", "subreddit_subscribers": 815258, "created_utc": 1666679395.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Context: I oversee marketing analytics team for a large organization that owns many smaller companies. The company is currently transitioning into an enterprise mindset and is trying to uniform the SFDB for each of these companies. Holistically, it's not ready for deep analytics and we spend a lot of time building/hacking together BI reports and working to automate a slew of marketing data connections into a central DB. Busy + working on foundations on the fly is the key take away here. Not a ton of analytics actually going on.\n\nOne of these companies has the data volume, internal resources, and data framework that would be needed to double down into actual analytic investigation. After showing them how it is impossible to find actionable insights on marketing strategy with our current ecosystem, they caught the vision that we need to design proper modeling/testing vs eyeballing - and that the upside is enormous.\n\nThere is appetite to start designing marketing tests to optimize for revenue and diminishing return. However, we need someone who can embed with this group and navigate what type of data environment they need to answer the questions we want to ask, educate leadership and developers in building the data environment, and then lead them in building test arms. Finally, assessing results + iterating.\n\nI recently got the buy-in to add headcount to our team. I'm not sure what resource to add though. We have 2 data analysts who are eager to lean and apply more data science. I don't know if we should come in with a net new data science 'heavy hitter' to establish enterprise standards, a data engineer, or let my team learn to navigate this on top of their other responsibilities.  \n\n\nHelp me Obi-wan", "author_fullname": "t2_8sgcfxe3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice: Should I add a Data Scientist to my Marketing Analytics team", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycj3ns", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666637011.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Context: I oversee marketing analytics team for a large organization that owns many smaller companies. The company is currently transitioning into an enterprise mindset and is trying to uniform the SFDB for each of these companies. Holistically, it&amp;#39;s not ready for deep analytics and we spend a lot of time building/hacking together BI reports and working to automate a slew of marketing data connections into a central DB. Busy + working on foundations on the fly is the key take away here. Not a ton of analytics actually going on.&lt;/p&gt;\n\n&lt;p&gt;One of these companies has the data volume, internal resources, and data framework that would be needed to double down into actual analytic investigation. After showing them how it is impossible to find actionable insights on marketing strategy with our current ecosystem, they caught the vision that we need to design proper modeling/testing vs eyeballing - and that the upside is enormous.&lt;/p&gt;\n\n&lt;p&gt;There is appetite to start designing marketing tests to optimize for revenue and diminishing return. However, we need someone who can embed with this group and navigate what type of data environment they need to answer the questions we want to ask, educate leadership and developers in building the data environment, and then lead them in building test arms. Finally, assessing results + iterating.&lt;/p&gt;\n\n&lt;p&gt;I recently got the buy-in to add headcount to our team. I&amp;#39;m not sure what resource to add though. We have 2 data analysts who are eager to lean and apply more data science. I don&amp;#39;t know if we should come in with a net new data science &amp;#39;heavy hitter&amp;#39; to establish enterprise standards, a data engineer, or let my team learn to navigate this on top of their other responsibilities.  &lt;/p&gt;\n\n&lt;p&gt;Help me Obi-wan&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycj3ns", "is_robot_indexable": true, "report_reasons": null, "author": "mistermmk", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ycj3ns/advice_should_i_add_a_data_scientist_to_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ycj3ns/advice_should_i_add_a_data_scientist_to_my/", "subreddit_subscribers": 815258, "created_utc": 1666637011.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As an aspiring data scientist what programming languages are useful? And do I have to learn the whole python or some specific libraries.", "author_fullname": "t2_js9frbnm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do I have to learn the whole of python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycttu7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666665720.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As an aspiring data scientist what programming languages are useful? And do I have to learn the whole python or some specific libraries.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycttu7", "is_robot_indexable": true, "report_reasons": null, "author": "Cute-Egg9301", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ycttu7/do_i_have_to_learn_the_whole_of_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ycttu7/do_i_have_to_learn_the_whole_of_python/", "subreddit_subscribers": 815258, "created_utc": 1666665720.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Many of you will likely find this useful -- our open-source team has spent the last few years building out the much-needed standard python framework for all things DCAI.\n\nToday we launched Out-of-Distribution Detection to help you automatically find and remove outliers in your datasets so you can train models and perform analytics on reliable data.\n\n[Our algorithms detect out-of-distribution data like this \\\\\"3\\\\\" included in a clothing dataset](https://preview.redd.it/xt6dmet7jsv91.png?width=720&amp;format=png&amp;auto=webp&amp;s=db13b96df1b2ba4e14bcae87568388769f800aca)\n\nWhat makes this different from existing OOD methods?\n\nMany complex OOD detection algorithms exist but they are only applicable to specific data types. Our research shows that our package works as effectively as these complex methods, but also works with **any type of data** for which either a feature embedding or trained classifier is available.\n\n[Published Research](https://arxiv.org/abs/2207.03061)", "author_fullname": "t2_s0qucgfk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Detecting Out-of-Distribution Datapoints via Embeddings or Predictions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 55, "top_awarded_type": null, "hide_score": false, "media_metadata": {"xt6dmet7jsv91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 42, "x": 108, "u": "https://preview.redd.it/xt6dmet7jsv91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1e45728c48c37c6194789cabf0eb7863911859e1"}, {"y": 85, "x": 216, "u": "https://preview.redd.it/xt6dmet7jsv91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1169dcf4c725cd1dd851d5a056bade118bb536e9"}, {"y": 127, "x": 320, "u": "https://preview.redd.it/xt6dmet7jsv91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=82ca19cafaf7ca836686880a93bb229a9e0545ab"}, {"y": 254, "x": 640, "u": "https://preview.redd.it/xt6dmet7jsv91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=16214183a461596a2c5cb55dc5772558e1a0bcd0"}], "s": {"y": 286, "x": 720, "u": "https://preview.redd.it/xt6dmet7jsv91.png?width=720&amp;format=png&amp;auto=webp&amp;s=db13b96df1b2ba4e14bcae87568388769f800aca"}, "id": "xt6dmet7jsv91"}}, "name": "t3_yci2hl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/hsBEOARi4Ttyd6rSvW32jIifTybS6Cjnvymw0jcCMR0.jpg", "edited": 1666639619.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666634533.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Many of you will likely find this useful -- our open-source team has spent the last few years building out the much-needed standard python framework for all things DCAI.&lt;/p&gt;\n\n&lt;p&gt;Today we launched Out-of-Distribution Detection to help you automatically find and remove outliers in your datasets so you can train models and perform analytics on reliable data.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/xt6dmet7jsv91.png?width=720&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=db13b96df1b2ba4e14bcae87568388769f800aca\"&gt;Our algorithms detect out-of-distribution data like this \\&amp;quot;3\\&amp;quot; included in a clothing dataset&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;What makes this different from existing OOD methods?&lt;/p&gt;\n\n&lt;p&gt;Many complex OOD detection algorithms exist but they are only applicable to specific data types. Our research shows that our package works as effectively as these complex methods, but also works with &lt;strong&gt;any type of data&lt;/strong&gt; for which either a feature embedding or trained classifier is available.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://arxiv.org/abs/2207.03061\"&gt;Published Research&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yci2hl", "is_robot_indexable": true, "report_reasons": null, "author": "cmauck10", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yci2hl/detecting_outofdistribution_datapoints_via/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yci2hl/detecting_outofdistribution_datapoints_via/", "subreddit_subscribers": 815258, "created_utc": 1666634533.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently a Computer Science undergraduate student working as a \"Data Science Intern\" for my university. I work with the Oracle Database, using Python (PySpark, Pandas, Numpy) and SQL to handle and analyze big student data. \n\nAre there even Data Scientist who work at Universities and if so what do you do? Do you make Prediction models, or any Machine Learning at all?", "author_fullname": "t2_705udfmb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Scientists who work at Universities", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_ycyt72", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666683385.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently a Computer Science undergraduate student working as a &amp;quot;Data Science Intern&amp;quot; for my university. I work with the Oracle Database, using Python (PySpark, Pandas, Numpy) and SQL to handle and analyze big student data. &lt;/p&gt;\n\n&lt;p&gt;Are there even Data Scientist who work at Universities and if so what do you do? Do you make Prediction models, or any Machine Learning at all?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycyt72", "is_robot_indexable": true, "report_reasons": null, "author": "Huitzilin_760", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ycyt72/data_scientists_who_work_at_universities/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ycyt72/data_scientists_who_work_at_universities/", "subreddit_subscribers": 815258, "created_utc": 1666683385.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "TLDR: Colab is taking longer to connect to Redshift than Jupyter, and I want to know why\n\nI am a Product Analyst, and I work with several PM's to get them the data that they need- nothing fancy, they really just want csv's that they can load into pivot tables. For reasons not in my control, we are not doing  dashboards (not my call), and I need to get multiple PM's multiple files on a regular basis. \n\nI am using Jupyter notebook hooked up directly to our Redshift database. I figured I could save myself some work by uploading the notebooks to Google Colab (the company is already on G-Suite), and then the PM's can just run the script, which will automatically pull the data, do the manipulations, and download the CSV for them to use. \n\nWhen I tried this, notebooks that ran in 2 minutes or less in Jupyter resulted in run times so long in Colab that the connection to Redshift was shut down.\n\nAny ideas on why Colab is taking so much longer to connect to Redshift?", "author_fullname": "t2_13b1f3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Jupyter Notebook vs Google Colab Performance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycxxnz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666679837.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TLDR: Colab is taking longer to connect to Redshift than Jupyter, and I want to know why&lt;/p&gt;\n\n&lt;p&gt;I am a Product Analyst, and I work with several PM&amp;#39;s to get them the data that they need- nothing fancy, they really just want csv&amp;#39;s that they can load into pivot tables. For reasons not in my control, we are not doing  dashboards (not my call), and I need to get multiple PM&amp;#39;s multiple files on a regular basis. &lt;/p&gt;\n\n&lt;p&gt;I am using Jupyter notebook hooked up directly to our Redshift database. I figured I could save myself some work by uploading the notebooks to Google Colab (the company is already on G-Suite), and then the PM&amp;#39;s can just run the script, which will automatically pull the data, do the manipulations, and download the CSV for them to use. &lt;/p&gt;\n\n&lt;p&gt;When I tried this, notebooks that ran in 2 minutes or less in Jupyter resulted in run times so long in Colab that the connection to Redshift was shut down.&lt;/p&gt;\n\n&lt;p&gt;Any ideas on why Colab is taking so much longer to connect to Redshift?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycxxnz", "is_robot_indexable": true, "report_reasons": null, "author": "aaquad", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ycxxnz/jupyter_notebook_vs_google_colab_performance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ycxxnz/jupyter_notebook_vs_google_colab_performance/", "subreddit_subscribers": 815258, "created_utc": 1666679837.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Apologies if this is a dumb question, but I've been doing a lot of searching and have found nothing on this topic.\n\nI am trying to put together a logistic regression model to predict the outcome of MMA fights (win or loss). (I know sorry for the sports regression).\n\nHow do I run my model without using data from future fights that have not happened yet? E.g. if the fight occurs on 1/1/22, any info on the fighters in fights that occurred after that date should not be included and every fight up to that date is included?\n\nI am working in python if there are any specific solutions I should be aware of.\n\nAppreciate any input.", "author_fullname": "t2_4ndy3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Logistic Regression Model - How to include only data from events that already occurred?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycrs1j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666659576.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Apologies if this is a dumb question, but I&amp;#39;ve been doing a lot of searching and have found nothing on this topic.&lt;/p&gt;\n\n&lt;p&gt;I am trying to put together a logistic regression model to predict the outcome of MMA fights (win or loss). (I know sorry for the sports regression).&lt;/p&gt;\n\n&lt;p&gt;How do I run my model without using data from future fights that have not happened yet? E.g. if the fight occurs on 1/1/22, any info on the fighters in fights that occurred after that date should not be included and every fight up to that date is included?&lt;/p&gt;\n\n&lt;p&gt;I am working in python if there are any specific solutions I should be aware of.&lt;/p&gt;\n\n&lt;p&gt;Appreciate any input.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycrs1j", "is_robot_indexable": true, "report_reasons": null, "author": "tookie22", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ycrs1j/logistic_regression_model_how_to_include_only/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ycrs1j/logistic_regression_model_how_to_include_only/", "subreddit_subscribers": 815258, "created_utc": 1666659576.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Just trying to gauge how you all determine your sample sizes. I\u2019ve always just kinda rule-of-thumb gone with minimum sample of 100 but no more than 1000, and aimed for maybe 10% of the population count. \n\nAdditionally, how do you all determine iterations for calculating the means of sample means? Here I just pull a number out of my butt that\u2019s kinda big\u2026\n\nWhat I\u2019m finding on a toy data set (from real data) is that if my sample sizes are kinda big, like 1000, then my distribution of sample means is basically a single bar around some number that is very different than my population mean. If I reduce my sample size to 30-50 ish, my mean of sample means is closer to my population mean and the distribution is more \u201cnormal\u201d in a sense. \n\nMy population is in the 1,000,000 range for counts of observations.", "author_fullname": "t2_d5gr1nxb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sample size and iterations for Mean of Sample Means", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycrfd5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666658533.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just trying to gauge how you all determine your sample sizes. I\u2019ve always just kinda rule-of-thumb gone with minimum sample of 100 but no more than 1000, and aimed for maybe 10% of the population count. &lt;/p&gt;\n\n&lt;p&gt;Additionally, how do you all determine iterations for calculating the means of sample means? Here I just pull a number out of my butt that\u2019s kinda big\u2026&lt;/p&gt;\n\n&lt;p&gt;What I\u2019m finding on a toy data set (from real data) is that if my sample sizes are kinda big, like 1000, then my distribution of sample means is basically a single bar around some number that is very different than my population mean. If I reduce my sample size to 30-50 ish, my mean of sample means is closer to my population mean and the distribution is more \u201cnormal\u201d in a sense. &lt;/p&gt;\n\n&lt;p&gt;My population is in the 1,000,000 range for counts of observations.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycrfd5", "is_robot_indexable": true, "report_reasons": null, "author": "renok_archnmy", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ycrfd5/sample_size_and_iterations_for_mean_of_sample/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ycrfd5/sample_size_and_iterations_for_mean_of_sample/", "subreddit_subscribers": 815258, "created_utc": 1666658533.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Used the free Patterns platform to build out a quick dash of my last 4 years of rides- got a bunch of my questions answered around consistency, improvement, and rider preference.  Would love to continue to update the template if folks have other things they'd like to track.\n\n&amp;#x200B;\n\n[https://studio.patterns.app/graph/tsieb96q00h2sjeml9jb/peloton-workouts-graph](https://studio.patterns.app/graph/tsieb96q00h2sjeml9jb/peloton-workouts-graph)", "author_fullname": "t2_a18h7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Xpost since Peloton doesn't let me post links- here's a dashboard for any riders out there!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycqz6r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666657200.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Used the free Patterns platform to build out a quick dash of my last 4 years of rides- got a bunch of my questions answered around consistency, improvement, and rider preference.  Would love to continue to update the template if folks have other things they&amp;#39;d like to track.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://studio.patterns.app/graph/tsieb96q00h2sjeml9jb/peloton-workouts-graph\"&gt;https://studio.patterns.app/graph/tsieb96q00h2sjeml9jb/peloton-workouts-graph&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/aq7-u90eP-joGrrV1XER018jKZtGHB8k7n_DJlyhwKM.jpg?auto=webp&amp;s=4450ecf05438a74ad9bb10b2f8bf2b6c96469975", "width": 624, "height": 397}, "resolutions": [{"url": "https://external-preview.redd.it/aq7-u90eP-joGrrV1XER018jKZtGHB8k7n_DJlyhwKM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f5c66dfb13bb8526f460623124de3dbafd7debc5", "width": 108, "height": 68}, {"url": "https://external-preview.redd.it/aq7-u90eP-joGrrV1XER018jKZtGHB8k7n_DJlyhwKM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2f5cf8cc0c1fdf35e5fab625e72e181fb935bb0f", "width": 216, "height": 137}, {"url": "https://external-preview.redd.it/aq7-u90eP-joGrrV1XER018jKZtGHB8k7n_DJlyhwKM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=052e2a62e5738804604b8cc77b10fe4260abe788", "width": 320, "height": 203}], "variants": {}, "id": "6S6oLVtHfZd86syY_UNvLm4jmi-0Ytd53HAjgpG91X8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycqz6r", "is_robot_indexable": true, "report_reasons": null, "author": "AjaxGreyshadow", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ycqz6r/xpost_since_peloton_doesnt_let_me_post_links/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ycqz6r/xpost_since_peloton_doesnt_let_me_post_links/", "subreddit_subscribers": 815258, "created_utc": 1666657200.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My friends and I are students working on a machine learning framework that allows devs to train models on other peoples GPUs. Does anyone have any experience working with similar tech (Model/data parallelism, differential privacy, edge computing) or even any feedback on the idea in general.", "author_fullname": "t2_tg5fewzz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Distributed Machine Learning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycoll6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666650471.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My friends and I are students working on a machine learning framework that allows devs to train models on other peoples GPUs. Does anyone have any experience working with similar tech (Model/data parallelism, differential privacy, edge computing) or even any feedback on the idea in general.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycoll6", "is_robot_indexable": true, "report_reasons": null, "author": "avnertothemoon", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ycoll6/distributed_machine_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ycoll6/distributed_machine_learning/", "subreddit_subscribers": 815258, "created_utc": 1666650471.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Currently debating the way we're going to implement an algorithm change for an opinion ranking tool. Would really appreciate any opinions on the scenarios below!\n\n\\---\n\nImagine 100 people participated in a simple ranking exercise where they were asked to rank 10 options from 1st (most important) to 10th (least important). Participants were allowed to submit incompletes as long as they included 2 or more of the 10 options. Would you expect the scoring algorithm to:\n\n1. Calculate the score for each option based only on the total number of participants who \\*included\\* that option in their personal ranking.\n2. Assume that any non-inclusions were the equivalent of a last-place rank, giving 0 points in those cases and therefore using the total 100 participants when calculating the overall score for each option.\n\nWe currently use Glicko-2 to score ranking options. Due to Glicko-2's comparative format, we often see researchers include new ranking options mid-project, adding additional participants until the ratings deviation reaches a similar level to the original ranking options. While we can replicate this format with a Borda Count using method 1 above, I would imagine the majority of researchers would expect the survey to use method 2.\n\nAn optional third method would be to combine the two approaches -- to rank newly-added options based on all participants that saw it, ie. only using a total count of 60 participants if the new option was added after the 40th participant completed their ranking.\n\nInterested to hear what you think? We've found that Glicko-2 is a black box for researchers and therefore they can't ensure their findings will be adopted and trusted when people disagree with the results.", "author_fullname": "t2_4ifru9mi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Borda Count Calculation Question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yckxj7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666641408.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently debating the way we&amp;#39;re going to implement an algorithm change for an opinion ranking tool. Would really appreciate any opinions on the scenarios below!&lt;/p&gt;\n\n&lt;p&gt;---&lt;/p&gt;\n\n&lt;p&gt;Imagine 100 people participated in a simple ranking exercise where they were asked to rank 10 options from 1st (most important) to 10th (least important). Participants were allowed to submit incompletes as long as they included 2 or more of the 10 options. Would you expect the scoring algorithm to:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Calculate the score for each option based only on the total number of participants who *included* that option in their personal ranking.&lt;/li&gt;\n&lt;li&gt;Assume that any non-inclusions were the equivalent of a last-place rank, giving 0 points in those cases and therefore using the total 100 participants when calculating the overall score for each option.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;We currently use Glicko-2 to score ranking options. Due to Glicko-2&amp;#39;s comparative format, we often see researchers include new ranking options mid-project, adding additional participants until the ratings deviation reaches a similar level to the original ranking options. While we can replicate this format with a Borda Count using method 1 above, I would imagine the majority of researchers would expect the survey to use method 2.&lt;/p&gt;\n\n&lt;p&gt;An optional third method would be to combine the two approaches -- to rank newly-added options based on all participants that saw it, ie. only using a total count of 60 participants if the new option was added after the 40th participant completed their ranking.&lt;/p&gt;\n\n&lt;p&gt;Interested to hear what you think? We&amp;#39;ve found that Glicko-2 is a black box for researchers and therefore they can&amp;#39;t ensure their findings will be adopted and trusted when people disagree with the results.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yckxj7", "is_robot_indexable": true, "report_reasons": null, "author": "danielkyne", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yckxj7/borda_count_calculation_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yckxj7/borda_count_calculation_question/", "subreddit_subscribers": 815258, "created_utc": 1666641408.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_s47x31rw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What books have had the most impact on your career/skillset?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycip69", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666636061.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycip69", "is_robot_indexable": true, "report_reasons": null, "author": "Western-Elevator-456", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ycip69/what_books_have_had_the_most_impact_on_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ycip69/what_books_have_had_the_most_impact_on_your/", "subreddit_subscribers": 815258, "created_utc": 1666636061.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Data science isn't a new practice at my company but it is maturing, to say the least. One area that hasn't been well standardized is how we level data scientists between different orgs. \n\nBasically, a **Senior Data Scientist** in the business, marketing, customer-facing orgs will be the equivalent of Meta E4, Google L4, Amazon L5.\n\nHowever, the **Senior Data Scientist** title in my org (R&amp;D, ML, modeling), is one level up.\n\nOne might argue that the inconsistency is appropriate since the DS in the latter group will be more quant-heavy. But at the same time, this is a nuanced distinction that may be overlooked in the labor market when recruiters are scanning profiles/resumes. I also get that \"senior\" is super arbitrary from place to place.\n\nCurious to know what others have experienced.", "author_fullname": "t2_3iok1byg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Inconsistent DS leveling depending on org?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycgnex", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": "", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666631091.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data science isn&amp;#39;t a new practice at my company but it is maturing, to say the least. One area that hasn&amp;#39;t been well standardized is how we level data scientists between different orgs. &lt;/p&gt;\n\n&lt;p&gt;Basically, a &lt;strong&gt;Senior Data Scientist&lt;/strong&gt; in the business, marketing, customer-facing orgs will be the equivalent of Meta E4, Google L4, Amazon L5.&lt;/p&gt;\n\n&lt;p&gt;However, the &lt;strong&gt;Senior Data Scientist&lt;/strong&gt; title in my org (R&amp;amp;D, ML, modeling), is one level up.&lt;/p&gt;\n\n&lt;p&gt;One might argue that the inconsistency is appropriate since the DS in the latter group will be more quant-heavy. But at the same time, this is a nuanced distinction that may be overlooked in the labor market when recruiters are scanning profiles/resumes. I also get that &amp;quot;senior&amp;quot; is super arbitrary from place to place.&lt;/p&gt;\n\n&lt;p&gt;Curious to know what others have experienced.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "MS|Data Scientist|Software", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycgnex", "is_robot_indexable": true, "report_reasons": null, "author": "dantzigismyhero", "discussion_type": null, "num_comments": 4, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/datascience/comments/ycgnex/inconsistent_ds_leveling_depending_on_org/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ycgnex/inconsistent_ds_leveling_depending_on_org/", "subreddit_subscribers": 815258, "created_utc": 1666631091.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Unable to categorize if the below datasets as tidy and Untidy. Wondering if anyone can lead me through this.\n\n [https://data.ny.gov/Energy-Environment/Gasoline-Retail-Prices-Weekly-Average-by-Region-Be/nqur-w4p7/data](https://data.ny.gov/Energy-Environment/Gasoline-Retail-Prices-Weekly-Average-by-Region-Be/nqur-w4p7/data) (Seems to be a tidy dataset)\n\n[https://data.cityofnewyork.us/api/views/jb7j-dtam/rows.csv?accessType=DOWNLOAD](https://data.cityofnewyork.us/api/views/jb7j-dtam/rows.csv?accessType=DOWNLOAD)(Race and ethnicity are present under the same column so can we conclude it to be untidy?, and how to correct them using python)\n\n[https://www.briandunning.com/sample-data/us-500.zip](https://www.briandunning.com/sample-data/us-500.zip)(Seems like a tidy dataset,, do the name fields be combined into one)\n\n[https://data.ny.gov/api/views/2fni-raj8/rows.csv?accessType=DOWNLOAD&amp;sorting=true](https://data.ny.gov/api/views/2fni-raj8/rows.csv?accessType=DOWNLOAD&amp;sorting=true)(Untidy data, since the georeference and location address convey same details, further should this be corrected further)", "author_fullname": "t2_jyoz4xrr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Identify if the following are tidy or Untidy data and how to correct them?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycgih7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666630786.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Unable to categorize if the below datasets as tidy and Untidy. Wondering if anyone can lead me through this.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://data.ny.gov/Energy-Environment/Gasoline-Retail-Prices-Weekly-Average-by-Region-Be/nqur-w4p7/data\"&gt;https://data.ny.gov/Energy-Environment/Gasoline-Retail-Prices-Weekly-Average-by-Region-Be/nqur-w4p7/data&lt;/a&gt; (Seems to be a tidy dataset)&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://data.cityofnewyork.us/api/views/jb7j-dtam/rows.csv?accessType=DOWNLOAD\"&gt;https://data.cityofnewyork.us/api/views/jb7j-dtam/rows.csv?accessType=DOWNLOAD&lt;/a&gt;(Race and ethnicity are present under the same column so can we conclude it to be untidy?, and how to correct them using python)&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.briandunning.com/sample-data/us-500.zip\"&gt;https://www.briandunning.com/sample-data/us-500.zip&lt;/a&gt;(Seems like a tidy dataset,, do the name fields be combined into one)&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://data.ny.gov/api/views/2fni-raj8/rows.csv?accessType=DOWNLOAD&amp;amp;sorting=true\"&gt;https://data.ny.gov/api/views/2fni-raj8/rows.csv?accessType=DOWNLOAD&amp;amp;sorting=true&lt;/a&gt;(Untidy data, since the georeference and location address convey same details, further should this be corrected further)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DdLEAiOakPGsL0_MUaOap7TeNDnBBfrXBXE9wgK6ykM.jpg?auto=webp&amp;s=2c8a844f6c929e32b32078514ac46a605eea100f", "width": 32, "height": 16}, "resolutions": [], "variants": {}, "id": "kpsfwl2fmtqAdgcAXJh8Nf4dEw9J-7jkAONPOviFNmg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycgih7", "is_robot_indexable": true, "report_reasons": null, "author": "Scary-Government-352", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ycgih7/identify_if_the_following_are_tidy_or_untidy_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ycgih7/identify_if_the_following_are_tidy_or_untidy_data/", "subreddit_subscribers": 815258, "created_utc": 1666630786.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone a doubt about Association Rules (Market Basket Algorithm) i know it is good, to map all the transactions in the database.\n\nBut i'm facing a issue around itens, i had a bunch of itens that i can\\`t process even using GCP clusters.\n\nSo a possible approach it is to use some sampling technique, but how can this affect the result?", "author_fullname": "t2_768gsz2h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sampling for Association Rules", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycayfd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666617266.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone a doubt about Association Rules (Market Basket Algorithm) i know it is good, to map all the transactions in the database.&lt;/p&gt;\n\n&lt;p&gt;But i&amp;#39;m facing a issue around itens, i had a bunch of itens that i can`t process even using GCP clusters.&lt;/p&gt;\n\n&lt;p&gt;So a possible approach it is to use some sampling technique, but how can this affect the result?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycayfd", "is_robot_indexable": true, "report_reasons": null, "author": "suneirl1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ycayfd/sampling_for_association_rules/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ycayfd/sampling_for_association_rules/", "subreddit_subscribers": 815258, "created_utc": 1666617266.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_rzm8vs2d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "which programming language do you think will be more useful in the future? or that it is already being used more and more", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yct2f3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666663400.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yct2f3", "is_robot_indexable": true, "report_reasons": null, "author": "IlustriousCap", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yct2f3/which_programming_language_do_you_think_will_be/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yct2f3/which_programming_language_do_you_think_will_be/", "subreddit_subscribers": 815258, "created_utc": 1666663400.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently a senior in my undergrad who has a major in Data Analytics and a minor in Statistics. I used to have a major in Data Science, but dropped it for my analytics so I could graduate a year earlier and focus more on actual experiences than classes. At this point, it's too late to switch back, and even if it wasn't, I'm not sure I would want to.\n\nI have almost all of my knowledge in R and SQL. I have had a BI internship and I work with my university's baseball team so I get a lot of very good experience to work on these skills constantly. Without sounding arrogant, I know I am quite advanced in analytics (at least compared to most others at my school), and I worry that I will end up working my way up through a job in analytics to a project manager role or non analytics role where I don't program at all. As I would love to work my way up, I also am more interested in programming and I love the idea of learning more and more complex methods as I progress in my career.\n\nWith all that being said, I want to know where to start? I understand the basics of data science, considering I have the programming knowledge from analytics and statistics skills from my minor. I have some baseline knowledge of Python and kinda want to learn more Python now, since I feel that R has a ceiling to its learning at this point.\n\nBut what specifically should I work on? I use DataCamp to teach myself different things and I plan on using this a lot, but I'm not sure what is most beneficial to me. So far, I know pretty advanced data wrangling and visualizations, linear modeling, many different statistical tests, random sampling, and basics of machine learning like random forest a k-means clustering. If I want to upgrade my knowledge into a data scientist, what else will I need to know?\n\n(I know there's thousands of blogs and websites talking about this, but I wanted to know from real data scientists about what they think of my situation in particular)", "author_fullname": "t2_2txzqlc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What should I learn to switch tracks into DS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yck561", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666639469.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently a senior in my undergrad who has a major in Data Analytics and a minor in Statistics. I used to have a major in Data Science, but dropped it for my analytics so I could graduate a year earlier and focus more on actual experiences than classes. At this point, it&amp;#39;s too late to switch back, and even if it wasn&amp;#39;t, I&amp;#39;m not sure I would want to.&lt;/p&gt;\n\n&lt;p&gt;I have almost all of my knowledge in R and SQL. I have had a BI internship and I work with my university&amp;#39;s baseball team so I get a lot of very good experience to work on these skills constantly. Without sounding arrogant, I know I am quite advanced in analytics (at least compared to most others at my school), and I worry that I will end up working my way up through a job in analytics to a project manager role or non analytics role where I don&amp;#39;t program at all. As I would love to work my way up, I also am more interested in programming and I love the idea of learning more and more complex methods as I progress in my career.&lt;/p&gt;\n\n&lt;p&gt;With all that being said, I want to know where to start? I understand the basics of data science, considering I have the programming knowledge from analytics and statistics skills from my minor. I have some baseline knowledge of Python and kinda want to learn more Python now, since I feel that R has a ceiling to its learning at this point.&lt;/p&gt;\n\n&lt;p&gt;But what specifically should I work on? I use DataCamp to teach myself different things and I plan on using this a lot, but I&amp;#39;m not sure what is most beneficial to me. So far, I know pretty advanced data wrangling and visualizations, linear modeling, many different statistical tests, random sampling, and basics of machine learning like random forest a k-means clustering. If I want to upgrade my knowledge into a data scientist, what else will I need to know?&lt;/p&gt;\n\n&lt;p&gt;(I know there&amp;#39;s thousands of blogs and websites talking about this, but I wanted to know from real data scientists about what they think of my situation in particular)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yck561", "is_robot_indexable": true, "report_reasons": null, "author": "tcffff", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yck561/what_should_i_learn_to_switch_tracks_into_ds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yck561/what_should_i_learn_to_switch_tracks_into_ds/", "subreddit_subscribers": 815258, "created_utc": 1666639469.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "There are things my degree (MSc in EE) didn't teach me about, and these are things that might be the most \"valuable\" to a company if I want to go into DS/MLE. Stuff like Recommendation Systems/ Bandits, Time Series, GLMs, etc... These are also things that interest me a lot.\n\nHow should I go about learning these things and show on my CV that I have experience in them? I do have some knowledge of these topics because I took a Machine Learning and a Deep Learning course (among others) but I have to recognize we didn't talk about them that deeply.\n\nI guess one way would be to do Kaggle problems but I feel like Kaggle gets a bad rep sometimes... Are there any books or courses you'd recommend to learn about these topics?", "author_fullname": "t2_h916gqd1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How should I go about learning this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycju7g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666638756.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There are things my degree (MSc in EE) didn&amp;#39;t teach me about, and these are things that might be the most &amp;quot;valuable&amp;quot; to a company if I want to go into DS/MLE. Stuff like Recommendation Systems/ Bandits, Time Series, GLMs, etc... These are also things that interest me a lot.&lt;/p&gt;\n\n&lt;p&gt;How should I go about learning these things and show on my CV that I have experience in them? I do have some knowledge of these topics because I took a Machine Learning and a Deep Learning course (among others) but I have to recognize we didn&amp;#39;t talk about them that deeply.&lt;/p&gt;\n\n&lt;p&gt;I guess one way would be to do Kaggle problems but I feel like Kaggle gets a bad rep sometimes... Are there any books or courses you&amp;#39;d recommend to learn about these topics?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycju7g", "is_robot_indexable": true, "report_reasons": null, "author": "AdministrativeRub484", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ycju7g/how_should_i_go_about_learning_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ycju7g/how_should_i_go_about_learning_this/", "subreddit_subscribers": 815258, "created_utc": 1666638756.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}