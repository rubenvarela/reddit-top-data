{"kind": "Listing", "data": {"after": "t3_yd250j", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_pgekz9xq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data = Oil", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_ycgmbu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 1185, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 1185, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/K5J_BSCyRQDJoMsr8nhxvy8-ESblRMi-HxMECAJgVN0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666631018.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/d8xfyn96csv91.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/d8xfyn96csv91.jpg?auto=webp&amp;s=48f01d982fa426511e57b10798d7705da3b4a886", "width": 852, "height": 480}, "resolutions": [{"url": "https://preview.redd.it/d8xfyn96csv91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=62965aa586841884add9045ed1559c8be7ddd049", "width": 108, "height": 60}, {"url": "https://preview.redd.it/d8xfyn96csv91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=792fb45f3dac2f5311553f196c676c124e219815", "width": 216, "height": 121}, {"url": "https://preview.redd.it/d8xfyn96csv91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f09daae077ef3533990ee367cf101abcab8c2dfa", "width": 320, "height": 180}, {"url": "https://preview.redd.it/d8xfyn96csv91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=255e3964c59f6cd1f31ab87a73a64d1e2c0ca279", "width": 640, "height": 360}], "variants": {}, "id": "Q-HjxdQz5vk91t1DpeWTRa9kV7vg_lCn2_8fEDG1cU8"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycgmbu", "is_robot_indexable": true, "report_reasons": null, "author": "realbigflavor", "discussion_type": null, "num_comments": 75, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ycgmbu/data_oil/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/d8xfyn96csv91.jpg", "subreddit_subscribers": 815311, "created_utc": 1666631018.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_5hgh94wf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I made a website to practice for DS interviews", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_ycmt6a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 269, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 269, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/qxbhMbs5kLBOXOsYO64L5-d-oE7E7mEQVbgjIaolv9I.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666645915.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/yat3ccovjtv91.gif", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/yat3ccovjtv91.gif?format=png8&amp;s=fef8022ab37793433352c42e2d5b2507d5b78832", "width": 886, "height": 1920}, "resolutions": [{"url": "https://preview.redd.it/yat3ccovjtv91.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=0598ee1817fd103310dc2ed86e90bbf24f905a24", "width": 108, "height": 216}, {"url": "https://preview.redd.it/yat3ccovjtv91.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=4ae42f420b71b1b05aaec22270ff2f76fe47b89e", "width": 216, "height": 432}, {"url": "https://preview.redd.it/yat3ccovjtv91.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=4415010166ee4736d841ae28cadb1323953a4683", "width": 320, "height": 640}, {"url": "https://preview.redd.it/yat3ccovjtv91.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=6a75b70884969f3c356f64b11637ae6960d70dac", "width": 640, "height": 1280}], "variants": {"gif": {"source": {"url": "https://preview.redd.it/yat3ccovjtv91.gif?s=6b5aabf78d7ac7e10dbafb5d2a2a8718f626ddce", "width": 886, "height": 1920}, "resolutions": [{"url": "https://preview.redd.it/yat3ccovjtv91.gif?width=108&amp;crop=smart&amp;s=a62d539652b7bab8d5b49c45925850c87b32a7f0", "width": 108, "height": 216}, {"url": "https://preview.redd.it/yat3ccovjtv91.gif?width=216&amp;crop=smart&amp;s=a692e1086d6ff024412c218e26b72b15815aea17", "width": 216, "height": 432}, {"url": "https://preview.redd.it/yat3ccovjtv91.gif?width=320&amp;crop=smart&amp;s=3421990e252d8a7e9116c5e17f8d9eabe13a844a", "width": 320, "height": 640}, {"url": "https://preview.redd.it/yat3ccovjtv91.gif?width=640&amp;crop=smart&amp;s=381238f8102b4ac742ade662c9db813efb578cb4", "width": 640, "height": 1280}]}, "mp4": {"source": {"url": "https://preview.redd.it/yat3ccovjtv91.gif?format=mp4&amp;s=53d91ef1068d058930eb3112cbe7d59efaa0993c", "width": 886, "height": 1920}, "resolutions": [{"url": "https://preview.redd.it/yat3ccovjtv91.gif?width=108&amp;format=mp4&amp;s=308b2d75d79832ce1b76929c4ef98819b5482ad3", "width": 108, "height": 216}, {"url": "https://preview.redd.it/yat3ccovjtv91.gif?width=216&amp;format=mp4&amp;s=9bdac4851da0510226be2298105b0a196d6bf0fb", "width": 216, "height": 432}, {"url": "https://preview.redd.it/yat3ccovjtv91.gif?width=320&amp;format=mp4&amp;s=d6c10e321666bccc59e50fefd4ba951923a3f787", "width": 320, "height": 640}, {"url": "https://preview.redd.it/yat3ccovjtv91.gif?width=640&amp;format=mp4&amp;s=821209e734ebd499ee30de420f44b2e49cf0691e", "width": 640, "height": 1280}]}}, "id": "fmy6tnvJInWKk4R2Yq378FjgAmvJUz-qZOTOs-d81Wo"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycmt6a", "is_robot_indexable": true, "report_reasons": null, "author": "santiviquez", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ycmt6a/i_made_a_website_to_practice_for_ds_interviews/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/yat3ccovjtv91.gif", "subreddit_subscribers": 815311, "created_utc": 1666645915.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have 4.5 years of work experience in the data analytics/science domain, of which I spent:\n- 2 years at one company as Data Analyst, where I was mostly building dashboards visualising predictions from sklearn models (\"classical ML\")\n- 1.5 years at another company as a Data Scientist, where I was building PoC apps using deep learning algorithms, mostly computer vision, but a couple of NLP projects as well\n- and the last 1 year at my current company as an AI consultant, where I'm building PoC models by creating simulated datasets, as it's a startup and we don't have any real-world data yet.\n\nSo, as you can see, I have not done any real heavy-duty deployment work at any of my roles, as I was never required to. **What I do have is data science experience** - I can do ETL jobs, I can explain the math of most of the classical ML stuff, and some of the \"beginner-level\" deep learning stuff like CNNs, make APIs out of them, and I've done simple deployments in Heroku for my personal projects. **I'm giving you this long-ish backdrop so that you understand how hard the take-home assignment was for the interview I gave last week, which was for an ML Engineer role.** The task was to take a Huggingface transformer model, fine-tune it on their data, deploy it with Kuberbetes, and make it consumable via an API. ***I had absolutely no idea about any of these*** (except making API endpoints) ***before, and I was given 1 week to compete it.*** So, here goes my journey.\n\nDue to my actual work occupying much of the workday, I was not able to give much time to the assignment for the first couple of days. So I had to work extra hard to learn all that stuff within 4-5 days, which I did by working late into the night. The last 2 days I was working deep into the night, trying to get the deployment right and the k8s cluster to function as expected, until 4:30 am.\n\nSo anyway, I submitted the assignment, satisfied and happy that I was able to get the thing working. The recruiter informed me that the company would like to interview me for the next round, hurray. In the interview, I explained to them how I built the model, how I deployed it, how it would take care of variable loads, etc. **Then they asked me, how do you do model versioning and retraining?** Honestly, I've never done it using any formal tooling purpose-built for this task. I just rename my models with a timestamp, if at all I need to, which like I mentioned before is for PoC projects, which is what my roles have entailed so far, and not for productionizing and deployment. So I said as much and also that I use Git for versioning. Well, they said Git is good for versioning code, but it's not sufficient for models.\n\nAnyway, got the news from the recruiter that I didn't pass the interview. I looked up (Googled) \"model versioning\" after the interview, it seems I needed to reply with \"ML Flow\" as the answer. If only I could blabber, \"I use MLflow and Jenkins for model versioning and CICD/orchestration\", I think I would have gotten through to the next round in the interview process. But alas, getting through to 90-95% of the way - **starting from zero mind you** - isn't enough anymore. Because if it was, they could have known or understood that if this guy can learn docker and kuberbetes and GKE within 4-5 days and build a working prototype of an app, compete with a UI and everything, as a full-fledged product with a deep-learning model that he fine-tuned on custom data, then he can definitely learn f**kin MLflow and Jenkins within another week. \n\nOh and, by the way, they never even proposed to reimburse me for the ~ US$ 22 that I spent on building and running the cluster for a week. Not that $22 matters a lot to me - in fact I'm glad I learnt how to use GKE within 3-4 days with that $22, so it's money well spent imo - but it is a matter of principles, honour, ethics and just plain old manners.\n\nSo, do you think my frustration and hurt is justified? Or do you think they're right in having rejected me instead of seeing my potential? Personally, I feel like if a company is only gonna employ people that fulfil 100% of their requirements, where is the scope of growth in it?", "author_fullname": "t2_79v29l8u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Got rejected from ML Engineer role despite completing a tough take-home assignment, because of not knowing about specific tool(s) used for model versioning and retraining. Do you think it's fair or unfair?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycgxzf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666643804.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666631802.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 4.5 years of work experience in the data analytics/science domain, of which I spent:\n- 2 years at one company as Data Analyst, where I was mostly building dashboards visualising predictions from sklearn models (&amp;quot;classical ML&amp;quot;)\n- 1.5 years at another company as a Data Scientist, where I was building PoC apps using deep learning algorithms, mostly computer vision, but a couple of NLP projects as well\n- and the last 1 year at my current company as an AI consultant, where I&amp;#39;m building PoC models by creating simulated datasets, as it&amp;#39;s a startup and we don&amp;#39;t have any real-world data yet.&lt;/p&gt;\n\n&lt;p&gt;So, as you can see, I have not done any real heavy-duty deployment work at any of my roles, as I was never required to. &lt;strong&gt;What I do have is data science experience&lt;/strong&gt; - I can do ETL jobs, I can explain the math of most of the classical ML stuff, and some of the &amp;quot;beginner-level&amp;quot; deep learning stuff like CNNs, make APIs out of them, and I&amp;#39;ve done simple deployments in Heroku for my personal projects. &lt;strong&gt;I&amp;#39;m giving you this long-ish backdrop so that you understand how hard the take-home assignment was for the interview I gave last week, which was for an ML Engineer role.&lt;/strong&gt; The task was to take a Huggingface transformer model, fine-tune it on their data, deploy it with Kuberbetes, and make it consumable via an API. &lt;strong&gt;&lt;em&gt;I had absolutely no idea about any of these&lt;/em&gt;&lt;/strong&gt; (except making API endpoints) &lt;strong&gt;&lt;em&gt;before, and I was given 1 week to compete it.&lt;/em&gt;&lt;/strong&gt; So, here goes my journey.&lt;/p&gt;\n\n&lt;p&gt;Due to my actual work occupying much of the workday, I was not able to give much time to the assignment for the first couple of days. So I had to work extra hard to learn all that stuff within 4-5 days, which I did by working late into the night. The last 2 days I was working deep into the night, trying to get the deployment right and the k8s cluster to function as expected, until 4:30 am.&lt;/p&gt;\n\n&lt;p&gt;So anyway, I submitted the assignment, satisfied and happy that I was able to get the thing working. The recruiter informed me that the company would like to interview me for the next round, hurray. In the interview, I explained to them how I built the model, how I deployed it, how it would take care of variable loads, etc. &lt;strong&gt;Then they asked me, how do you do model versioning and retraining?&lt;/strong&gt; Honestly, I&amp;#39;ve never done it using any formal tooling purpose-built for this task. I just rename my models with a timestamp, if at all I need to, which like I mentioned before is for PoC projects, which is what my roles have entailed so far, and not for productionizing and deployment. So I said as much and also that I use Git for versioning. Well, they said Git is good for versioning code, but it&amp;#39;s not sufficient for models.&lt;/p&gt;\n\n&lt;p&gt;Anyway, got the news from the recruiter that I didn&amp;#39;t pass the interview. I looked up (Googled) &amp;quot;model versioning&amp;quot; after the interview, it seems I needed to reply with &amp;quot;ML Flow&amp;quot; as the answer. If only I could blabber, &amp;quot;I use MLflow and Jenkins for model versioning and CICD/orchestration&amp;quot;, I think I would have gotten through to the next round in the interview process. But alas, getting through to 90-95% of the way - &lt;strong&gt;starting from zero mind you&lt;/strong&gt; - isn&amp;#39;t enough anymore. Because if it was, they could have known or understood that if this guy can learn docker and kuberbetes and GKE within 4-5 days and build a working prototype of an app, compete with a UI and everything, as a full-fledged product with a deep-learning model that he fine-tuned on custom data, then he can definitely learn f**kin MLflow and Jenkins within another week. &lt;/p&gt;\n\n&lt;p&gt;Oh and, by the way, they never even proposed to reimburse me for the ~ US$ 22 that I spent on building and running the cluster for a week. Not that $22 matters a lot to me - in fact I&amp;#39;m glad I learnt how to use GKE within 3-4 days with that $22, so it&amp;#39;s money well spent imo - but it is a matter of principles, honour, ethics and just plain old manners.&lt;/p&gt;\n\n&lt;p&gt;So, do you think my frustration and hurt is justified? Or do you think they&amp;#39;re right in having rejected me instead of seeing my potential? Personally, I feel like if a company is only gonna employ people that fulfil 100% of their requirements, where is the scope of growth in it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycgxzf", "is_robot_indexable": true, "report_reasons": null, "author": "ResearcherNo4728", "discussion_type": null, "num_comments": 63, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ycgxzf/got_rejected_from_ml_engineer_role_despite/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ycgxzf/got_rejected_from_ml_engineer_role_despite/", "subreddit_subscribers": 815311, "created_utc": 1666631802.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_36hvab2o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[OC] Data scientists use PowerPoint?! \ud83d\ude2f\ud83e\udd2f", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_yd3jcf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "ups": 47, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 47, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/YcMcac75q9gENMhopNqJpTt5CyWCN9u7dcfk84R-5EA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666700602.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/0r7jptcx2yv91.gif", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/0r7jptcx2yv91.gif?format=png8&amp;s=dbc30a02cb7fbafca6b093e153b68bd76a954a98", "width": 1280, "height": 720}, "resolutions": [{"url": "https://preview.redd.it/0r7jptcx2yv91.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=ed3becdab5a3b7f8281b7ae05c68db95a4ede1bf", "width": 108, "height": 60}, {"url": "https://preview.redd.it/0r7jptcx2yv91.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=1f024a91d7e635d56e68c9462fab8974434a4d59", "width": 216, "height": 121}, {"url": "https://preview.redd.it/0r7jptcx2yv91.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=b1325a738237fca7956c1cfde2a967d46f708851", "width": 320, "height": 180}, {"url": "https://preview.redd.it/0r7jptcx2yv91.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=e961cb623fb8bdb2403c0d607177d7d990393139", "width": 640, "height": 360}, {"url": "https://preview.redd.it/0r7jptcx2yv91.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=145d617194bbed579cac95f1adbc45c0e19f17ca", "width": 960, "height": 540}, {"url": "https://preview.redd.it/0r7jptcx2yv91.gif?width=1080&amp;crop=smart&amp;format=png8&amp;s=f0b886a096c676924684eed6ba9cb340e6ac6ac4", "width": 1080, "height": 607}], "variants": {"gif": {"source": {"url": "https://preview.redd.it/0r7jptcx2yv91.gif?s=ee1aaeebce2a8811f51875ba07bf01430cbe1f66", "width": 1280, "height": 720}, "resolutions": [{"url": "https://preview.redd.it/0r7jptcx2yv91.gif?width=108&amp;crop=smart&amp;s=60e5b72435dd9aa1ef77fcc77f701428975090ce", "width": 108, "height": 60}, {"url": "https://preview.redd.it/0r7jptcx2yv91.gif?width=216&amp;crop=smart&amp;s=f9618631fabf3f103417e38fb5ef6bc0f1e2d6d8", "width": 216, "height": 121}, {"url": "https://preview.redd.it/0r7jptcx2yv91.gif?width=320&amp;crop=smart&amp;s=ee83384579632a652cff90365401b65c5fdf5e02", "width": 320, "height": 180}, {"url": "https://preview.redd.it/0r7jptcx2yv91.gif?width=640&amp;crop=smart&amp;s=59cf25f87542dfa7e5d32305a9ec064d935a3b0c", "width": 640, "height": 360}, {"url": "https://preview.redd.it/0r7jptcx2yv91.gif?width=960&amp;crop=smart&amp;s=36281282252fc11a2a36e09dc6c507db091a9a9d", "width": 960, "height": 540}, {"url": "https://preview.redd.it/0r7jptcx2yv91.gif?width=1080&amp;crop=smart&amp;s=c23638ba57f7a8c27b922ff43f51977c16eecd11", "width": 1080, "height": 607}]}, "mp4": {"source": {"url": "https://preview.redd.it/0r7jptcx2yv91.gif?format=mp4&amp;s=e13178305c7ed61e4bfd120a369f8f2b7c320dd1", "width": 1280, "height": 720}, "resolutions": [{"url": "https://preview.redd.it/0r7jptcx2yv91.gif?width=108&amp;format=mp4&amp;s=283d13e9d3b635db84a0979f31451926d90e4149", "width": 108, "height": 60}, {"url": "https://preview.redd.it/0r7jptcx2yv91.gif?width=216&amp;format=mp4&amp;s=bdde31a7531f2f2aafe59a35c52dcdb10d8e2cdb", "width": 216, "height": 121}, {"url": "https://preview.redd.it/0r7jptcx2yv91.gif?width=320&amp;format=mp4&amp;s=6fe26e6432b511c839bb28f12343af5abb6e38ff", "width": 320, "height": 180}, {"url": "https://preview.redd.it/0r7jptcx2yv91.gif?width=640&amp;format=mp4&amp;s=e63f69955344e7b2b76eb2f6ff8dcb19fa9ee1e0", "width": 640, "height": 360}, {"url": "https://preview.redd.it/0r7jptcx2yv91.gif?width=960&amp;format=mp4&amp;s=6936daacc1b805755fc8e5953e8fc0222e17175b", "width": 960, "height": 540}, {"url": "https://preview.redd.it/0r7jptcx2yv91.gif?width=1080&amp;format=mp4&amp;s=7c2a311c567a45c83ce512c5ce6852c1166658b5", "width": 1080, "height": 607}]}}, "id": "-jnGx0liD-4qNfBt2a2qjpKUFTClBNg1H8Jf9fwMo44"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "yd3jcf", "is_robot_indexable": true, "report_reasons": null, "author": "VizzuHQ", "discussion_type": null, "num_comments": 36, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yd3jcf/oc_data_scientists_use_powerpoint/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/0r7jptcx2yv91.gif", "subreddit_subscribers": 815311, "created_utc": 1666700602.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "It seems like a significant amount of that for me is used on doing \"nothing productive\".", "author_fullname": "t2_amfdjuba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[PRODUCTIVITY-RELATED] If you work 8 hours a day, how many of those hours are productive hours?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycxcw3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666677572.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It seems like a significant amount of that for me is used on doing &amp;quot;nothing productive&amp;quot;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycxcw3", "is_robot_indexable": true, "report_reasons": null, "author": "limedove", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ycxcw3/productivityrelated_if_you_work_8_hours_a_day_how/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ycxcw3/productivityrelated_if_you_work_8_hours_a_day_how/", "subreddit_subscribers": 815311, "created_utc": 1666677572.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "We would like to make a small collection of essential or interesting data science/ML books at our department. Might be any related field, also business oriented titles are welcome. Could you please suggest 4-5 books published no earlier than 2019? Thanks a lot!", "author_fullname": "t2_ndl92", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Books worth having at hand?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycjcyk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666637623.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We would like to make a small collection of essential or interesting data science/ML books at our department. Might be any related field, also business oriented titles are welcome. Could you please suggest 4-5 books published no earlier than 2019? Thanks a lot!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycjcyk", "is_robot_indexable": true, "report_reasons": null, "author": "cv_be", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ycjcyk/books_worth_having_at_hand/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ycjcyk/books_worth_having_at_hand/", "subreddit_subscribers": 815311, "created_utc": 1666637623.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Which storage option is better to store data for analysis?", "author_fullname": "t2_pwxlrv27", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you prefer OneDrive, Google Drive, or Dropbox?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yd34mn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666699362.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Which storage option is better to store data for analysis?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yd34mn", "is_robot_indexable": true, "report_reasons": null, "author": "Fast-Group-8501", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yd34mn/do_you_prefer_onedrive_google_drive_or_dropbox/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yd34mn/do_you_prefer_onedrive_google_drive_or_dropbox/", "subreddit_subscribers": 815311, "created_utc": 1666699362.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently a Computer Science undergraduate student working as a \"Data Science Intern\" for my university. I work with the Oracle Database, using Python (PySpark, Pandas, Numpy) and SQL to handle and analyze big student data. \n\nAre there even Data Scientist who work at Universities and if so what do you do? Do you make Prediction models, or any Machine Learning at all?", "author_fullname": "t2_705udfmb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Scientists who work at Universities", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycyt72", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666683385.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently a Computer Science undergraduate student working as a &amp;quot;Data Science Intern&amp;quot; for my university. I work with the Oracle Database, using Python (PySpark, Pandas, Numpy) and SQL to handle and analyze big student data. &lt;/p&gt;\n\n&lt;p&gt;Are there even Data Scientist who work at Universities and if so what do you do? Do you make Prediction models, or any Machine Learning at all?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycyt72", "is_robot_indexable": true, "report_reasons": null, "author": "Huitzilin_760", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ycyt72/data_scientists_who_work_at_universities/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ycyt72/data_scientists_who_work_at_universities/", "subreddit_subscribers": 815311, "created_utc": 1666683385.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone! \n\nI\u2019m currently a bit confused career-wise and would like to ask your opinion and advice on improving my skills. \n\nMy goal professionally is to work in data science in a finance related company (although I\u2019m open to other ideas too). I have a bachelors degree in economics and I\u2019m now finishing my master in data science and economics. Putting a lot of effort over the last two years, I\u2019ve managed to achieve a solid intermediate level in Python, R, Tableau and PostgreSQL. I also work part time as a tech freelancer in a startup (but more on the data collection side). \n\nLately I\u2019ve been asking a couple of professors and co-workers about data science career options and skills to improve. Some of them directly say that I need a degree in computer science. What is your opinion? After my master I would like to get a full time job, but I can\u2019t help but think that I\u2019m lacking skills. Is a computer science degree in my situation necessary, or are there other certificates/tools I can carry out to improve? Lately I\u2019ve considered undertaking the professional data engineer certification for Google cloud to broaden my skills. What do you think?", "author_fullname": "t2_3s1pvyko", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting my foot on the door with a data science master? Tips on improving my skills?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycgdv5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666630479.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone! &lt;/p&gt;\n\n&lt;p&gt;I\u2019m currently a bit confused career-wise and would like to ask your opinion and advice on improving my skills. &lt;/p&gt;\n\n&lt;p&gt;My goal professionally is to work in data science in a finance related company (although I\u2019m open to other ideas too). I have a bachelors degree in economics and I\u2019m now finishing my master in data science and economics. Putting a lot of effort over the last two years, I\u2019ve managed to achieve a solid intermediate level in Python, R, Tableau and PostgreSQL. I also work part time as a tech freelancer in a startup (but more on the data collection side). &lt;/p&gt;\n\n&lt;p&gt;Lately I\u2019ve been asking a couple of professors and co-workers about data science career options and skills to improve. Some of them directly say that I need a degree in computer science. What is your opinion? After my master I would like to get a full time job, but I can\u2019t help but think that I\u2019m lacking skills. Is a computer science degree in my situation necessary, or are there other certificates/tools I can carry out to improve? Lately I\u2019ve considered undertaking the professional data engineer certification for Google cloud to broaden my skills. What do you think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycgdv5", "is_robot_indexable": true, "report_reasons": null, "author": "Tiffanys_Coma", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ycgdv5/getting_my_foot_on_the_door_with_a_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ycgdv5/getting_my_foot_on_the_door_with_a_data_science/", "subreddit_subscribers": 815311, "created_utc": 1666630479.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As an aspiring data scientist what programming languages are useful? And do I have to learn the whole python or some specific libraries.", "author_fullname": "t2_js9frbnm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do I have to learn the whole of python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycttu7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666665720.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As an aspiring data scientist what programming languages are useful? And do I have to learn the whole python or some specific libraries.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycttu7", "is_robot_indexable": true, "report_reasons": null, "author": "Cute-Egg9301", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ycttu7/do_i_have_to_learn_the_whole_of_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ycttu7/do_i_have_to_learn_the_whole_of_python/", "subreddit_subscribers": 815311, "created_utc": 1666665720.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Context: I oversee marketing analytics team for a large organization that owns many smaller companies. The company is currently transitioning into an enterprise mindset and is trying to uniform the SFDB for each of these companies. Holistically, it's not ready for deep analytics and we spend a lot of time building/hacking together BI reports and working to automate a slew of marketing data connections into a central DB. Busy + working on foundations on the fly is the key take away here. Not a ton of analytics actually going on.\n\nOne of these companies has the data volume, internal resources, and data framework that would be needed to double down into actual analytic investigation. After showing them how it is impossible to find actionable insights on marketing strategy with our current ecosystem, they caught the vision that we need to design proper modeling/testing vs eyeballing - and that the upside is enormous.\n\nThere is appetite to start designing marketing tests to optimize for revenue and diminishing return. However, we need someone who can embed with this group and navigate what type of data environment they need to answer the questions we want to ask, educate leadership and developers in building the data environment, and then lead them in building test arms. Finally, assessing results + iterating.\n\nI recently got the buy-in to add headcount to our team. I'm not sure what resource to add though. We have 2 data analysts who are eager to lean and apply more data science. I don't know if we should come in with a net new data science 'heavy hitter' to establish enterprise standards, a data engineer, or let my team learn to navigate this on top of their other responsibilities.  \n\n\nHelp me Obi-wan", "author_fullname": "t2_8sgcfxe3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice: Should I add a Data Scientist to my Marketing Analytics team", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycj3ns", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666637011.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Context: I oversee marketing analytics team for a large organization that owns many smaller companies. The company is currently transitioning into an enterprise mindset and is trying to uniform the SFDB for each of these companies. Holistically, it&amp;#39;s not ready for deep analytics and we spend a lot of time building/hacking together BI reports and working to automate a slew of marketing data connections into a central DB. Busy + working on foundations on the fly is the key take away here. Not a ton of analytics actually going on.&lt;/p&gt;\n\n&lt;p&gt;One of these companies has the data volume, internal resources, and data framework that would be needed to double down into actual analytic investigation. After showing them how it is impossible to find actionable insights on marketing strategy with our current ecosystem, they caught the vision that we need to design proper modeling/testing vs eyeballing - and that the upside is enormous.&lt;/p&gt;\n\n&lt;p&gt;There is appetite to start designing marketing tests to optimize for revenue and diminishing return. However, we need someone who can embed with this group and navigate what type of data environment they need to answer the questions we want to ask, educate leadership and developers in building the data environment, and then lead them in building test arms. Finally, assessing results + iterating.&lt;/p&gt;\n\n&lt;p&gt;I recently got the buy-in to add headcount to our team. I&amp;#39;m not sure what resource to add though. We have 2 data analysts who are eager to lean and apply more data science. I don&amp;#39;t know if we should come in with a net new data science &amp;#39;heavy hitter&amp;#39; to establish enterprise standards, a data engineer, or let my team learn to navigate this on top of their other responsibilities.  &lt;/p&gt;\n\n&lt;p&gt;Help me Obi-wan&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycj3ns", "is_robot_indexable": true, "report_reasons": null, "author": "mistermmk", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ycj3ns/advice_should_i_add_a_data_scientist_to_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ycj3ns/advice_should_i_add_a_data_scientist_to_my/", "subreddit_subscribers": 815311, "created_utc": 1666637011.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In almost all the learning material and tutorials i've observed that the training of the model is done everytime the application is executed. I understand that training would be required everytime if the type of data changes but for a real world application do we have to teach it how to run everytime?\n\ne.g. in an application that forecasts some values based on a dataset that grows with time, do i have to train my model each time i request a forecast?", "author_fullname": "t2_n732f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Newbie here. Do people train their models everytime an app runs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycxtn8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666679395.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In almost all the learning material and tutorials i&amp;#39;ve observed that the training of the model is done everytime the application is executed. I understand that training would be required everytime if the type of data changes but for a real world application do we have to teach it how to run everytime?&lt;/p&gt;\n\n&lt;p&gt;e.g. in an application that forecasts some values based on a dataset that grows with time, do i have to train my model each time i request a forecast?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycxtn8", "is_robot_indexable": true, "report_reasons": null, "author": "buckypimpin", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ycxtn8/newbie_here_do_people_train_their_models/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ycxtn8/newbie_here_do_people_train_their_models/", "subreddit_subscribers": 815311, "created_utc": 1666679395.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_s47x31rw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What books have had the most impact on your career/skillset?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycip69", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666636061.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycip69", "is_robot_indexable": true, "report_reasons": null, "author": "Western-Elevator-456", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ycip69/what_books_have_had_the_most_impact_on_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ycip69/what_books_have_had_the_most_impact_on_your/", "subreddit_subscribers": 815311, "created_utc": 1666636061.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Many of you will likely find this useful -- our open-source team has spent the last few years building out the much-needed standard python framework for all things DCAI.\n\nToday we launched Out-of-Distribution Detection to help you automatically find and remove outliers in your datasets so you can train models and perform analytics on reliable data.\n\n[Our algorithms detect out-of-distribution data like this \\\\\"3\\\\\" included in a clothing dataset](https://preview.redd.it/xt6dmet7jsv91.png?width=720&amp;format=png&amp;auto=webp&amp;s=db13b96df1b2ba4e14bcae87568388769f800aca)\n\nWhat makes this different from existing OOD methods?\n\nMany complex OOD detection algorithms exist but they are only applicable to specific data types. Our research shows that our package works as effectively as these complex methods, but also works with **any type of data** for which either a feature embedding or trained classifier is available.\n\n[Published Research](https://arxiv.org/abs/2207.03061)", "author_fullname": "t2_s0qucgfk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Detecting Out-of-Distribution Datapoints via Embeddings or Predictions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 55, "top_awarded_type": null, "hide_score": false, "media_metadata": {"xt6dmet7jsv91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 42, "x": 108, "u": "https://preview.redd.it/xt6dmet7jsv91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1e45728c48c37c6194789cabf0eb7863911859e1"}, {"y": 85, "x": 216, "u": "https://preview.redd.it/xt6dmet7jsv91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1169dcf4c725cd1dd851d5a056bade118bb536e9"}, {"y": 127, "x": 320, "u": "https://preview.redd.it/xt6dmet7jsv91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=82ca19cafaf7ca836686880a93bb229a9e0545ab"}, {"y": 254, "x": 640, "u": "https://preview.redd.it/xt6dmet7jsv91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=16214183a461596a2c5cb55dc5772558e1a0bcd0"}], "s": {"y": 286, "x": 720, "u": "https://preview.redd.it/xt6dmet7jsv91.png?width=720&amp;format=png&amp;auto=webp&amp;s=db13b96df1b2ba4e14bcae87568388769f800aca"}, "id": "xt6dmet7jsv91"}}, "name": "t3_yci2hl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/hsBEOARi4Ttyd6rSvW32jIifTybS6Cjnvymw0jcCMR0.jpg", "edited": 1666639619.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666634533.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Many of you will likely find this useful -- our open-source team has spent the last few years building out the much-needed standard python framework for all things DCAI.&lt;/p&gt;\n\n&lt;p&gt;Today we launched Out-of-Distribution Detection to help you automatically find and remove outliers in your datasets so you can train models and perform analytics on reliable data.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/xt6dmet7jsv91.png?width=720&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=db13b96df1b2ba4e14bcae87568388769f800aca\"&gt;Our algorithms detect out-of-distribution data like this \\&amp;quot;3\\&amp;quot; included in a clothing dataset&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;What makes this different from existing OOD methods?&lt;/p&gt;\n\n&lt;p&gt;Many complex OOD detection algorithms exist but they are only applicable to specific data types. Our research shows that our package works as effectively as these complex methods, but also works with &lt;strong&gt;any type of data&lt;/strong&gt; for which either a feature embedding or trained classifier is available.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://arxiv.org/abs/2207.03061\"&gt;Published Research&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yci2hl", "is_robot_indexable": true, "report_reasons": null, "author": "cmauck10", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yci2hl/detecting_outofdistribution_datapoints_via/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yci2hl/detecting_outofdistribution_datapoints_via/", "subreddit_subscribers": 815311, "created_utc": 1666634533.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Labeling and AI companies", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yd5hbc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_rsdl04ak", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "ArtificialInteligence", "selftext": "Hello folks,\n\nCan you explain please how AI companies chose to what data labeling company they should outsource their data set for labeling?  \n\nWhat metrics or things they search in data labeling companies before they pick one?\n\nplease share with your experience,\n\nThank you in advance", "author_fullname": "t2_rsdl04ak", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Labeling and AI companies", "link_flair_richtext": [], "subreddit_name_prefixed": "r/ArtificialInteligence", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yd5fmj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666706090.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.ArtificialInteligence", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello folks,&lt;/p&gt;\n\n&lt;p&gt;Can you explain please how AI companies chose to what data labeling company they should outsource their data set for labeling?  &lt;/p&gt;\n\n&lt;p&gt;What metrics or things they search in data labeling companies before they pick one?&lt;/p&gt;\n\n&lt;p&gt;please share with your experience,&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_3crzr", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yd5fmj", "is_robot_indexable": true, "report_reasons": null, "author": "PayVolt", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/ArtificialInteligence/comments/yd5fmj/data_labeling_and_ai_companies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/ArtificialInteligence/comments/yd5fmj/data_labeling_and_ai_companies/", "subreddit_subscribers": 87125, "created_utc": 1666706090.0, "num_crossposts": 4, "media": null, "is_video": false}], "created": 1666706212.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.ArtificialInteligence", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/ArtificialInteligence/comments/yd5fmj/data_labeling_and_ai_companies/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yd5hbc", "is_robot_indexable": true, "report_reasons": null, "author": "PayVolt", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_yd5fmj", "author_flair_text_color": null, "permalink": "/r/datascience/comments/yd5hbc/data_labeling_and_ai_companies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/ArtificialInteligence/comments/yd5fmj/data_labeling_and_ai_companies/", "subreddit_subscribers": 815311, "created_utc": 1666706212.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "How i can create  gauge chart in tableau....any easy method", "author_fullname": "t2_tm2org8c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Gauge chart in tableau", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yd1ot4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666694732.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How i can create  gauge chart in tableau....any easy method&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yd1ot4", "is_robot_indexable": true, "report_reasons": null, "author": "vaibhav7888", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yd1ot4/gauge_chart_in_tableau/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yd1ot4/gauge_chart_in_tableau/", "subreddit_subscribers": 815311, "created_utc": 1666694732.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "TLDR: Colab is taking longer to connect to Redshift than Jupyter, and I want to know why\n\nI am a Product Analyst, and I work with several PM's to get them the data that they need- nothing fancy, they really just want csv's that they can load into pivot tables. For reasons not in my control, we are not doing  dashboards (not my call), and I need to get multiple PM's multiple files on a regular basis. \n\nI am using Jupyter notebook hooked up directly to our Redshift database. I figured I could save myself some work by uploading the notebooks to Google Colab (the company is already on G-Suite), and then the PM's can just run the script, which will automatically pull the data, do the manipulations, and download the CSV for them to use. \n\nWhen I tried this, notebooks that ran in 2 minutes or less in Jupyter resulted in run times so long in Colab that the connection to Redshift was shut down.\n\nAny ideas on why Colab is taking so much longer to connect to Redshift?", "author_fullname": "t2_13b1f3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Jupyter Notebook vs Google Colab Performance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycxxnz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666679837.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TLDR: Colab is taking longer to connect to Redshift than Jupyter, and I want to know why&lt;/p&gt;\n\n&lt;p&gt;I am a Product Analyst, and I work with several PM&amp;#39;s to get them the data that they need- nothing fancy, they really just want csv&amp;#39;s that they can load into pivot tables. For reasons not in my control, we are not doing  dashboards (not my call), and I need to get multiple PM&amp;#39;s multiple files on a regular basis. &lt;/p&gt;\n\n&lt;p&gt;I am using Jupyter notebook hooked up directly to our Redshift database. I figured I could save myself some work by uploading the notebooks to Google Colab (the company is already on G-Suite), and then the PM&amp;#39;s can just run the script, which will automatically pull the data, do the manipulations, and download the CSV for them to use. &lt;/p&gt;\n\n&lt;p&gt;When I tried this, notebooks that ran in 2 minutes or less in Jupyter resulted in run times so long in Colab that the connection to Redshift was shut down.&lt;/p&gt;\n\n&lt;p&gt;Any ideas on why Colab is taking so much longer to connect to Redshift?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycxxnz", "is_robot_indexable": true, "report_reasons": null, "author": "aaquad", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ycxxnz/jupyter_notebook_vs_google_colab_performance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ycxxnz/jupyter_notebook_vs_google_colab_performance/", "subreddit_subscribers": 815311, "created_utc": 1666679837.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Apologies if this is a dumb question, but I've been doing a lot of searching and have found nothing on this topic.\n\nI am trying to put together a logistic regression model to predict the outcome of MMA fights (win or loss). (I know sorry for the sports regression).\n\nHow do I run my model without using data from future fights that have not happened yet? E.g. if the fight occurs on 1/1/22, any info on the fighters in fights that occurred after that date should not be included and every fight up to that date is included?\n\nI am working in python if there are any specific solutions I should be aware of.\n\nAppreciate any input.", "author_fullname": "t2_4ndy3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Logistic Regression Model - How to include only data from events that already occurred?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycrs1j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666659576.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Apologies if this is a dumb question, but I&amp;#39;ve been doing a lot of searching and have found nothing on this topic.&lt;/p&gt;\n\n&lt;p&gt;I am trying to put together a logistic regression model to predict the outcome of MMA fights (win or loss). (I know sorry for the sports regression).&lt;/p&gt;\n\n&lt;p&gt;How do I run my model without using data from future fights that have not happened yet? E.g. if the fight occurs on 1/1/22, any info on the fighters in fights that occurred after that date should not be included and every fight up to that date is included?&lt;/p&gt;\n\n&lt;p&gt;I am working in python if there are any specific solutions I should be aware of.&lt;/p&gt;\n\n&lt;p&gt;Appreciate any input.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycrs1j", "is_robot_indexable": true, "report_reasons": null, "author": "tookie22", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ycrs1j/logistic_regression_model_how_to_include_only/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ycrs1j/logistic_regression_model_how_to_include_only/", "subreddit_subscribers": 815311, "created_utc": 1666659576.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Just trying to gauge how you all determine your sample sizes. I\u2019ve always just kinda rule-of-thumb gone with minimum sample of 100 but no more than 1000, and aimed for maybe 10% of the population count. \n\nAdditionally, how do you all determine iterations for calculating the means of sample means? Here I just pull a number out of my butt that\u2019s kinda big\u2026\n\nWhat I\u2019m finding on a toy data set (from real data) is that if my sample sizes are kinda big, like 1000, then my distribution of sample means is basically a single bar around some number that is very different than my population mean. If I reduce my sample size to 30-50 ish, my mean of sample means is closer to my population mean and the distribution is more \u201cnormal\u201d in a sense. \n\nMy population is in the 1,000,000 range for counts of observations.", "author_fullname": "t2_d5gr1nxb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sample size and iterations for Mean of Sample Means", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycrfd5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666658533.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just trying to gauge how you all determine your sample sizes. I\u2019ve always just kinda rule-of-thumb gone with minimum sample of 100 but no more than 1000, and aimed for maybe 10% of the population count. &lt;/p&gt;\n\n&lt;p&gt;Additionally, how do you all determine iterations for calculating the means of sample means? Here I just pull a number out of my butt that\u2019s kinda big\u2026&lt;/p&gt;\n\n&lt;p&gt;What I\u2019m finding on a toy data set (from real data) is that if my sample sizes are kinda big, like 1000, then my distribution of sample means is basically a single bar around some number that is very different than my population mean. If I reduce my sample size to 30-50 ish, my mean of sample means is closer to my population mean and the distribution is more \u201cnormal\u201d in a sense. &lt;/p&gt;\n\n&lt;p&gt;My population is in the 1,000,000 range for counts of observations.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycrfd5", "is_robot_indexable": true, "report_reasons": null, "author": "renok_archnmy", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ycrfd5/sample_size_and_iterations_for_mean_of_sample/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ycrfd5/sample_size_and_iterations_for_mean_of_sample/", "subreddit_subscribers": 815311, "created_utc": 1666658533.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My friends and I are students working on a machine learning framework that allows devs to train models on other peoples GPUs. Does anyone have any experience working with similar tech (Model/data parallelism, differential privacy, edge computing) or even any feedback on the idea in general.", "author_fullname": "t2_tg5fewzz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Distributed Machine Learning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycoll6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666650471.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My friends and I are students working on a machine learning framework that allows devs to train models on other peoples GPUs. Does anyone have any experience working with similar tech (Model/data parallelism, differential privacy, edge computing) or even any feedback on the idea in general.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycoll6", "is_robot_indexable": true, "report_reasons": null, "author": "avnertothemoon", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ycoll6/distributed_machine_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ycoll6/distributed_machine_learning/", "subreddit_subscribers": 815311, "created_utc": 1666650471.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Data science isn't a new practice at my company but it is maturing, to say the least. One area that hasn't been well standardized is how we level data scientists between different orgs. \n\nBasically, a **Senior Data Scientist** in the business, marketing, customer-facing orgs will be the equivalent of Meta E4, Google L4, Amazon L5.\n\nHowever, the **Senior Data Scientist** title in my org (R&amp;D, ML, modeling), is one level up.\n\nOne might argue that the inconsistency is appropriate since the DS in the latter group will be more quant-heavy. But at the same time, this is a nuanced distinction that may be overlooked in the labor market when recruiters are scanning profiles/resumes. I also get that \"senior\" is super arbitrary from place to place.\n\nCurious to know what others have experienced.", "author_fullname": "t2_3iok1byg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Inconsistent DS leveling depending on org?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycgnex", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": "", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666631091.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data science isn&amp;#39;t a new practice at my company but it is maturing, to say the least. One area that hasn&amp;#39;t been well standardized is how we level data scientists between different orgs. &lt;/p&gt;\n\n&lt;p&gt;Basically, a &lt;strong&gt;Senior Data Scientist&lt;/strong&gt; in the business, marketing, customer-facing orgs will be the equivalent of Meta E4, Google L4, Amazon L5.&lt;/p&gt;\n\n&lt;p&gt;However, the &lt;strong&gt;Senior Data Scientist&lt;/strong&gt; title in my org (R&amp;amp;D, ML, modeling), is one level up.&lt;/p&gt;\n\n&lt;p&gt;One might argue that the inconsistency is appropriate since the DS in the latter group will be more quant-heavy. But at the same time, this is a nuanced distinction that may be overlooked in the labor market when recruiters are scanning profiles/resumes. I also get that &amp;quot;senior&amp;quot; is super arbitrary from place to place.&lt;/p&gt;\n\n&lt;p&gt;Curious to know what others have experienced.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "MS|Data Scientist|Software", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycgnex", "is_robot_indexable": true, "report_reasons": null, "author": "dantzigismyhero", "discussion_type": null, "num_comments": 4, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/datascience/comments/ycgnex/inconsistent_ds_leveling_depending_on_org/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ycgnex/inconsistent_ds_leveling_depending_on_org/", "subreddit_subscribers": 815311, "created_utc": 1666631091.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Unable to categorize if the below datasets as tidy and Untidy. Wondering if anyone can lead me through this.\n\n [https://data.ny.gov/Energy-Environment/Gasoline-Retail-Prices-Weekly-Average-by-Region-Be/nqur-w4p7/data](https://data.ny.gov/Energy-Environment/Gasoline-Retail-Prices-Weekly-Average-by-Region-Be/nqur-w4p7/data) (Seems to be a tidy dataset)\n\n[https://data.cityofnewyork.us/api/views/jb7j-dtam/rows.csv?accessType=DOWNLOAD](https://data.cityofnewyork.us/api/views/jb7j-dtam/rows.csv?accessType=DOWNLOAD)(Race and ethnicity are present under the same column so can we conclude it to be untidy?, and how to correct them using python)\n\n[https://www.briandunning.com/sample-data/us-500.zip](https://www.briandunning.com/sample-data/us-500.zip)(Seems like a tidy dataset,, do the name fields be combined into one)\n\n[https://data.ny.gov/api/views/2fni-raj8/rows.csv?accessType=DOWNLOAD&amp;sorting=true](https://data.ny.gov/api/views/2fni-raj8/rows.csv?accessType=DOWNLOAD&amp;sorting=true)(Untidy data, since the georeference and location address convey same details, further should this be corrected further)", "author_fullname": "t2_jyoz4xrr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Identify if the following are tidy or Untidy data and how to correct them?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ycgih7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666630786.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Unable to categorize if the below datasets as tidy and Untidy. Wondering if anyone can lead me through this.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://data.ny.gov/Energy-Environment/Gasoline-Retail-Prices-Weekly-Average-by-Region-Be/nqur-w4p7/data\"&gt;https://data.ny.gov/Energy-Environment/Gasoline-Retail-Prices-Weekly-Average-by-Region-Be/nqur-w4p7/data&lt;/a&gt; (Seems to be a tidy dataset)&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://data.cityofnewyork.us/api/views/jb7j-dtam/rows.csv?accessType=DOWNLOAD\"&gt;https://data.cityofnewyork.us/api/views/jb7j-dtam/rows.csv?accessType=DOWNLOAD&lt;/a&gt;(Race and ethnicity are present under the same column so can we conclude it to be untidy?, and how to correct them using python)&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.briandunning.com/sample-data/us-500.zip\"&gt;https://www.briandunning.com/sample-data/us-500.zip&lt;/a&gt;(Seems like a tidy dataset,, do the name fields be combined into one)&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://data.ny.gov/api/views/2fni-raj8/rows.csv?accessType=DOWNLOAD&amp;amp;sorting=true\"&gt;https://data.ny.gov/api/views/2fni-raj8/rows.csv?accessType=DOWNLOAD&amp;amp;sorting=true&lt;/a&gt;(Untidy data, since the georeference and location address convey same details, further should this be corrected further)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DdLEAiOakPGsL0_MUaOap7TeNDnBBfrXBXE9wgK6ykM.jpg?auto=webp&amp;s=2c8a844f6c929e32b32078514ac46a605eea100f", "width": 32, "height": 16}, "resolutions": [], "variants": {}, "id": "kpsfwl2fmtqAdgcAXJh8Nf4dEw9J-7jkAONPOviFNmg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ycgih7", "is_robot_indexable": true, "report_reasons": null, "author": "Scary-Government-352", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ycgih7/identify_if_the_following_are_tidy_or_untidy_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ycgih7/identify_if_the_following_are_tidy_or_untidy_data/", "subreddit_subscribers": 815311, "created_utc": 1666630786.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi!\n\n&amp;#x200B;\n\nCan someone help me figure out how can I readjust my pytesseract-ocr script to work directly with a PDF file, rather than a path to it.", "author_fullname": "t2_fmamadvj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "pytesseract work with PDF file, not path to it", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yd52g8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666705112.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Can someone help me figure out how can I readjust my pytesseract-ocr script to work directly with a PDF file, rather than a path to it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yd52g8", "is_robot_indexable": true, "report_reasons": null, "author": "FoxSinofSloth", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yd52g8/pytesseract_work_with_pdf_file_not_path_to_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yd52g8/pytesseract_work_with_pdf_file_not_path_to_it/", "subreddit_subscribers": 815311, "created_utc": 1666705112.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi guys, I'm new here, and basically in the data science field in general. So I thought to myself it'd be a good idea to create a blog where I can document my journey and share what I learn with folks in the same field. Anyway, here's the link if anyone wants to take a look, and hopefully give some feedback. Cheers\n\n[https://techtyro.hashnode.dev/getting-started-in-data-science](https://techtyro.hashnode.dev/getting-started-in-data-science)", "author_fullname": "t2_2fnbkl6e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science Newbie", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yd4020", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666702057.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, I&amp;#39;m new here, and basically in the data science field in general. So I thought to myself it&amp;#39;d be a good idea to create a blog where I can document my journey and share what I learn with folks in the same field. Anyway, here&amp;#39;s the link if anyone wants to take a look, and hopefully give some feedback. Cheers&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://techtyro.hashnode.dev/getting-started-in-data-science\"&gt;https://techtyro.hashnode.dev/getting-started-in-data-science&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/TDrvPYfcVpbrBLCiTtChV8SKv3I-o4aFfPugIWrPdnE.jpg?auto=webp&amp;s=ed944a2f67ba6980eb02fcf868c2b4747259dc3b", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/TDrvPYfcVpbrBLCiTtChV8SKv3I-o4aFfPugIWrPdnE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4ce613749c63ae81bb9f670d7d69efe2ea143c12", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/TDrvPYfcVpbrBLCiTtChV8SKv3I-o4aFfPugIWrPdnE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a02826cd68611448d74bf914ba82153a81c3ab71", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/TDrvPYfcVpbrBLCiTtChV8SKv3I-o4aFfPugIWrPdnE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bcd24abcb29966c3d496e26e8758fa465c524ab2", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/TDrvPYfcVpbrBLCiTtChV8SKv3I-o4aFfPugIWrPdnE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e6f816d2913f949f27664efa5d6117be15a37b60", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/TDrvPYfcVpbrBLCiTtChV8SKv3I-o4aFfPugIWrPdnE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=326eb0dd350cd7e0b4aff871bfb5c4050d52cfdc", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/TDrvPYfcVpbrBLCiTtChV8SKv3I-o4aFfPugIWrPdnE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dd30b326c22272eedc9f8c003f587db34989d6ec", "width": 1080, "height": 607}], "variants": {}, "id": "3mEPJaIghl7ph9KNJ5vhNbX1EotbhGR46F_YwFXY5oE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yd4020", "is_robot_indexable": true, "report_reasons": null, "author": "postnutdisgust", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yd4020/data_science_newbie/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yd4020/data_science_newbie/", "subreddit_subscribers": 815311, "created_utc": 1666702057.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "You can know someone works in user-centric-design is if their concept pitch includes the phrase \"it somehow [does X]\". And this irritates me more than it should.", "author_fullname": "t2_1wm8goh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "It somehow does magic", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yd250j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666696201.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;You can know someone works in user-centric-design is if their concept pitch includes the phrase &amp;quot;it somehow [does X]&amp;quot;. And this irritates me more than it should.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yd250j", "is_robot_indexable": true, "report_reasons": null, "author": "yourmamaman", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yd250j/it_somehow_does_magic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yd250j/it_somehow_does_magic/", "subreddit_subscribers": 815311, "created_utc": 1666696201.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}