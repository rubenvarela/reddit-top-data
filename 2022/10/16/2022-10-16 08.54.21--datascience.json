{"kind": "Listing", "data": {"after": null, "dist": 20, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m interested in learning more about Bayesian Models, and am trying to decide if it would be beneficial to implement them at my work (I work in retail). In what situations do you all use Bayesian models over frequentists models?", "author_fullname": "t2_fjll57b4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "In what situations would a Bayesian model work better than frequentist model?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4obe5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 181, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 181, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665841364.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m interested in learning more about Bayesian Models, and am trying to decide if it would be beneficial to implement them at my work (I work in retail). In what situations do you all use Bayesian models over frequentists models?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4obe5", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Resort-4196", "discussion_type": null, "num_comments": 76, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4obe5/in_what_situations_would_a_bayesian_model_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4obe5/in_what_situations_would_a_bayesian_model_work/", "subreddit_subscribers": 813798, "created_utc": 1665841364.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_b7z7a6t4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can we interprate this box plot in regards to outliers? Is it every value above the upper fence? In that case, about 1/6 of the total values are outliers.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 63, "top_awarded_type": null, "hide_score": false, "name": "t3_y4s8cy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "ups": 92, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 92, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/UWHyL0uAC086_fianjiO7-5pLIEDNayzi2NR-f-4BMQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1665851355.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/huwywux7xzt91.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/huwywux7xzt91.png?auto=webp&amp;s=cc6f6317e6afdb86edfa0a0697abc5389db52959", "width": 1235, "height": 558}, "resolutions": [{"url": "https://preview.redd.it/huwywux7xzt91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=354cbccb19304de12debc55cc8d33a43903f0154", "width": 108, "height": 48}, {"url": "https://preview.redd.it/huwywux7xzt91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9d755cc7e5fb2ad51cfd84900f23a0f24d9946fb", "width": 216, "height": 97}, {"url": "https://preview.redd.it/huwywux7xzt91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c2c5d8040432cfe013af7cb7ac4129eeb1323ea4", "width": 320, "height": 144}, {"url": "https://preview.redd.it/huwywux7xzt91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b4aecf1ee052431c08f937a5bf6970d4df7345ab", "width": 640, "height": 289}, {"url": "https://preview.redd.it/huwywux7xzt91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=4f7b19fb35ff96c01378537c995f150394dfee9b", "width": 960, "height": 433}, {"url": "https://preview.redd.it/huwywux7xzt91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=aed86c9be16cb475c3ef613a845f2ca16d8440b6", "width": 1080, "height": 487}], "variants": {}, "id": "6kbHq0P-iIt0cbMHwt0Gx-R_gKWvfSEj9XwDcGdZ6AA"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4s8cy", "is_robot_indexable": true, "report_reasons": null, "author": "Outside-Werewolf-983", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4s8cy/how_can_we_interprate_this_box_plot_in_regards_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/huwywux7xzt91.png", "subreddit_subscribers": 813798, "created_utc": 1665851355.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\n\n1. What are some of the steps for data wrangling and data cleaning before applying machine learning algorithms?\n\n2. How to deal with unbalanced binary classification?\n\n3. What is the difference between a box plot and a histogram?\n\n4. Describe different regularization methods, such as L1 and L2 regularization?\n\n5. What are Neural Networks\n\n6. What is cross-validation?\n\n7. How to define/select metrics?\n\n8. Explain what precision and recall are\n\n9. Explain what a false positive and a false negative are. Why is it important these from each other?\n\n10.Provide examples when false positives are more important than false negatives, false negatives are more important than false positives and when these two types of errors are equally important\n\n11. What is the difference between supervised learning and unsupervised learning? Give concrete examples\n\n12.Assume you need to generate a predictive model using multiple regression. Explain how you intend to validate this model\n\n13.What does NLP stand for?\n14. When would you use random forests Vs SVM and why? 15. Why is dimension reduction important?\n\n16. What is principal component analysis? Explain the sort of problems you would use PCA for.\n\n17. Why is Naive Bayes so bad? How would you improve a spam detection algorithm that uses naive Bayes?\n\n18. What are the drawbacks of a linear model?\n\n19. Do you think 50 small decision trees are better than a large one? Why?\n\n20. Why is mean square error a bad measure of model performance? What would you suggest instead?\n\n21. What are the assumptions required for linear regression? What if some of these assumptions are violated?\n\n22. What is collinearity and what to do with it? How to remove multicollinearity?\n\n23. How to check if the regression model fits the data well?\n\n24. What is a decision tree?\n\n25. What is a random forest? Why is it good?\n\n26. What is a kernel? Explain the kernel trick\n\n27. What is the Central Limit Theorem? Explain it. Why is it important?\n\n28. What is the statistical power?\n29. Is it beneficial to perform dimensionality reduction before fitting an SVM? Why or why not?\n\n30. What is overfitting? 31. What is boosting?\n\n32. The probability that item an item at location A is 0.6, and 0.8 at location B. What is the probability that item would be found on Amazon website?\n\n33. You randomly draw a coin from 100 coins-1 unfair coin (head-head), 99 fair coins (head-tail) and roll it 10 times. If the result is 10 heads, what is the probability that the coin is unfair?\n\n34. Difference between convex and non-convex cost function; what does it mean when a cost function is non-convex?\n\n35. Walk through the probability fundamentals 36. Describe Markov chains?\n\n37. A box has 12 red cards and 12 black cards. Another box has 24 red cards and 24 black cards. You want to draw two cards at random from one of the two boxes, one card at a time. Which box has a higher probability of getting cards of the same color and why?\n\n38. You are at a Casino and have two dices to play with. You win $10 every time you roll a 5. If you play till you win and then stop, what is the expected payout?\n39. How can you tell if a given coin is biased?\n\n40. Make an unfair coin fair\n\n41. You are about to get on a plane to London, you want to know whether you have to bring an umbrella or not. You call three of your random friends and ask each one of them if it's raining. The probability that your friend is telling the truth is 2/3 and the probability that they are playing a prank on you by lying is 1/3. If all 3 of them tell that it is raining, then what is the probability that it is actually raining in London.\n\n42. You are given 40 cards with four different colors- 10 Green\n\ncards, 10 Red Cards, 10 Blue cards, and 10 Yellow cards. The\n\ncards of each color are numbered from one to ten. Two cards\n\nare picked at random. Find out the probability that the cards\n\npicked are not of the same number and same color.\n\n43. How do you assess the statistical significance of an insight?\n\n44. Explain what a long-tailed distribution is and provide three examples of relevant phenomena that have long tails. Why are they important in classification and regression problems?\n\n45. Explain selection bias (with regard to a dataset, not variable selection). Why is it important? How can data management procedures such as missing data handling make it worse?\n\n46. Provide a simple example of how an experimental design can help answer a question about behavior. How does experimental data contrast with observational data?\n\n47. Is mean imputation of missing data acceptable practice? Why or why not?\n\n48. What is an outlier? Explain how you might screen for outliers and what would you do if you found them in your dataset. Also, explain what an inlier is and how you might screen for them and what would you do if you found them in your dataset.\n\n49. How do you handle missing data? What imputation techniques do you recommend?\n\n50. You have data on the duration of calls to a call center. Generate a plan for how you would code and analyze these data. Explain a plausible scenario for what the distribution of these durations might look like. How could you test, even graphically, whether your expectations are borne out?\n\n51. Explain likely differences between administrative datasets and datasets gathered from experimental studies. What are likely problems encountered with administrative data? How do experimental methods help alleviate these problems? What problem do they bring?\n52. You are compiling a report for user content uploaded every month and notice a spike in uploads in October. In particular, a spike in picture uploads. What might you think is the cause of this, and how would you test it?\n\n53. Give examples of data that does not have a Gaussian distribution, nor log normal.\n\n54. What is root cause analysis? How to identify a cause vs. a correlation? Give examples\n\n55. Give an example where the median is a better measure than the mean\n\n56. Given two fair dices, what is the probability of getting scores that sum to 4? to 8?\n\n57. What is the Law of Large Numbers?\n\n58. How do you calculate the needed sample size?\n\n59. When you sample, what bias are you inflicting?\n\n60. How do you control for biases?\n\n61. What are confounding variables?\n\n62. What is A/B testing?\n\n63. How do you prove that males are on average taller than females by knowing just gender height?\n\n64. Infection rates at a hospital above a 1 infection per 100 person-days at risk are considered high. A hospital had 10 infections over the last 1787 person days at risk. Give the p-value of the correct one-sided test of whether the hospital is below the standard.\n\n65. You roll a biased coin (p(head)=0.8) five times. What's the probability of getting three or more heads?\n66. A random variable X is normal with mean 1020 and a standard deviation 50. Calculate P(X&gt;1200)\n\n67. Consider the number of people that show up at a bus station is Poisson with mean 2.5/h. What is the probability that at most three people show up in a four hour period?\n\n68. An HIV test has a sensitivity of 99.7% and a specificity of 98.5%. A subject from a population of prevalence 0.1% receives a positive test result. What is the precision of the test (i.e the probability he is HIV positive)?\n\n69. You are running for office and your pollster polled hundred people. Sixty of them claimed they will vote for you. Can you relax?\n\n70. Geiger counter records 100 radioactive decays in 5 minutes. Find an approximate 95% interval for the number of decays per hour.\n\n71. The homicide rate in Scotland fell last year to 99 from 115 the year before. Is this reported change really noteworthy?\n\n72. Consider influenza epidemics for two-parent heterosexual families. Suppose that the probability is 17% that at least one of the parents has contracted the disease. The probability that the father has contracted influenza is 12% while the probability that both the mother and father have contracted the disease is 6%. What is the probability that the mother has contracted influenza?\n\n73. Suppose that diastolic blood pressures (DBPs) for men aged 35-44 are normally distributed with a mean of 80 (mm Hg) and a standard deviation of 10. About what is the probability that a random 35-44 year old has a DBP less than 70?\n\n74. In a population of interest, a sample of 9 men yielded a sample average brain volume of 1,100cc and a standard deviation of 30cc. What is a 95% Student's T confidence interval for the mean brain volume in this new population?\n\n75. A diet pill is given to 9 subjects over six weeks. The average difference in weight (follow up baseline) is -2 pounds. What would the standard - deviation of the difference in weight have to be for the upper endpoint of the 95% T confidence interval to touch 0?\n76. In a study of emergency room waiting times, investigators consider a new and the standard triage systems. To test the systems, administrators selected 20 nights and randomly assigned the new triage system to be used on 10 nights and the standard system on the remaining 10 nights. They calculated the nightly median waiting time (MWT) to see a physician. The average MWT for the new system was 3 hours with a variance of 0.60 while the average MWT for the old system was 5 hours with a variance of 0.68. Consider the 95% confidence interval estimate for the differences of the mean MWT associated with the new system. Assume a constant variance. What is the interval? Subtract in this order (New System - Old System).\n\n77. To further test the hospital triage system, administrators selected 200 nights and randomly assigned a new triage system to be used on 100 nights and a standard system on the remaining 100 nights. They calculated the nightly median waiting time (MWT) to see a physician. The average MWT for the new system was 4 hours with a standard deviation of 0.5 hours while the average MWT for the old system was 6 hours with a standard deviation of 2 hours. Consider the hypothesis of a decrease in the mean MWT associated with the new treatment. What does the 95% independent group confidence interval with unequal variances suggest vis a vis this hypothesis? (Because there's so many observations per group, just use the Z quantile instead of the T.)", "author_fullname": "t2_82p2xt8o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "75+ data science interview questions : most asked interview questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y57j0o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 83, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 83, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665894369.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;What are some of the steps for data wrangling and data cleaning before applying machine learning algorithms?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How to deal with unbalanced binary classification?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;What is the difference between a box plot and a histogram?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Describe different regularization methods, such as L1 and L2 regularization?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;What are Neural Networks&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;What is cross-validation?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How to define/select metrics?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Explain what precision and recall are&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Explain what a false positive and a false negative are. Why is it important these from each other?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;10.Provide examples when false positives are more important than false negatives, false negatives are more important than false positives and when these two types of errors are equally important&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;What is the difference between supervised learning and unsupervised learning? Give concrete examples&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;12.Assume you need to generate a predictive model using multiple regression. Explain how you intend to validate this model&lt;/p&gt;\n\n&lt;p&gt;13.What does NLP stand for?\n14. When would you use random forests Vs SVM and why? 15. Why is dimension reduction important?&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;What is principal component analysis? Explain the sort of problems you would use PCA for.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Why is Naive Bayes so bad? How would you improve a spam detection algorithm that uses naive Bayes?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;What are the drawbacks of a linear model?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Do you think 50 small decision trees are better than a large one? Why?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Why is mean square error a bad measure of model performance? What would you suggest instead?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;What are the assumptions required for linear regression? What if some of these assumptions are violated?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;What is collinearity and what to do with it? How to remove multicollinearity?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How to check if the regression model fits the data well?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;What is a decision tree?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;What is a random forest? Why is it good?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;What is a kernel? Explain the kernel trick&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;What is the Central Limit Theorem? Explain it. Why is it important?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;What is the statistical power?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Is it beneficial to perform dimensionality reduction before fitting an SVM? Why or why not?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;What is overfitting? 31. What is boosting?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;The probability that item an item at location A is 0.6, and 0.8 at location B. What is the probability that item would be found on Amazon website?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;You randomly draw a coin from 100 coins-1 unfair coin (head-head), 99 fair coins (head-tail) and roll it 10 times. If the result is 10 heads, what is the probability that the coin is unfair?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Difference between convex and non-convex cost function; what does it mean when a cost function is non-convex?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Walk through the probability fundamentals 36. Describe Markov chains?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;A box has 12 red cards and 12 black cards. Another box has 24 red cards and 24 black cards. You want to draw two cards at random from one of the two boxes, one card at a time. Which box has a higher probability of getting cards of the same color and why?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;You are at a Casino and have two dices to play with. You win $10 every time you roll a 5. If you play till you win and then stop, what is the expected payout?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How can you tell if a given coin is biased?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Make an unfair coin fair&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;You are about to get on a plane to London, you want to know whether you have to bring an umbrella or not. You call three of your random friends and ask each one of them if it&amp;#39;s raining. The probability that your friend is telling the truth is 2/3 and the probability that they are playing a prank on you by lying is 1/3. If all 3 of them tell that it is raining, then what is the probability that it is actually raining in London.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;You are given 40 cards with four different colors- 10 Green&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;cards, 10 Red Cards, 10 Blue cards, and 10 Yellow cards. The&lt;/p&gt;\n\n&lt;p&gt;cards of each color are numbered from one to ten. Two cards&lt;/p&gt;\n\n&lt;p&gt;are picked at random. Find out the probability that the cards&lt;/p&gt;\n\n&lt;p&gt;picked are not of the same number and same color.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;How do you assess the statistical significance of an insight?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Explain what a long-tailed distribution is and provide three examples of relevant phenomena that have long tails. Why are they important in classification and regression problems?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Explain selection bias (with regard to a dataset, not variable selection). Why is it important? How can data management procedures such as missing data handling make it worse?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Provide a simple example of how an experimental design can help answer a question about behavior. How does experimental data contrast with observational data?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Is mean imputation of missing data acceptable practice? Why or why not?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;What is an outlier? Explain how you might screen for outliers and what would you do if you found them in your dataset. Also, explain what an inlier is and how you might screen for them and what would you do if you found them in your dataset.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How do you handle missing data? What imputation techniques do you recommend?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;You have data on the duration of calls to a call center. Generate a plan for how you would code and analyze these data. Explain a plausible scenario for what the distribution of these durations might look like. How could you test, even graphically, whether your expectations are borne out?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Explain likely differences between administrative datasets and datasets gathered from experimental studies. What are likely problems encountered with administrative data? How do experimental methods help alleviate these problems? What problem do they bring?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;You are compiling a report for user content uploaded every month and notice a spike in uploads in October. In particular, a spike in picture uploads. What might you think is the cause of this, and how would you test it?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Give examples of data that does not have a Gaussian distribution, nor log normal.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;What is root cause analysis? How to identify a cause vs. a correlation? Give examples&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Give an example where the median is a better measure than the mean&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Given two fair dices, what is the probability of getting scores that sum to 4? to 8?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;What is the Law of Large Numbers?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How do you calculate the needed sample size?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;When you sample, what bias are you inflicting?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How do you control for biases?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;What are confounding variables?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;What is A/B testing?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How do you prove that males are on average taller than females by knowing just gender height?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Infection rates at a hospital above a 1 infection per 100 person-days at risk are considered high. A hospital had 10 infections over the last 1787 person days at risk. Give the p-value of the correct one-sided test of whether the hospital is below the standard.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;You roll a biased coin (p(head)=0.8) five times. What&amp;#39;s the probability of getting three or more heads?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;A random variable X is normal with mean 1020 and a standard deviation 50. Calculate P(X&amp;gt;1200)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Consider the number of people that show up at a bus station is Poisson with mean 2.5/h. What is the probability that at most three people show up in a four hour period?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;An HIV test has a sensitivity of 99.7% and a specificity of 98.5%. A subject from a population of prevalence 0.1% receives a positive test result. What is the precision of the test (i.e the probability he is HIV positive)?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;You are running for office and your pollster polled hundred people. Sixty of them claimed they will vote for you. Can you relax?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Geiger counter records 100 radioactive decays in 5 minutes. Find an approximate 95% interval for the number of decays per hour.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;The homicide rate in Scotland fell last year to 99 from 115 the year before. Is this reported change really noteworthy?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Consider influenza epidemics for two-parent heterosexual families. Suppose that the probability is 17% that at least one of the parents has contracted the disease. The probability that the father has contracted influenza is 12% while the probability that both the mother and father have contracted the disease is 6%. What is the probability that the mother has contracted influenza?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Suppose that diastolic blood pressures (DBPs) for men aged 35-44 are normally distributed with a mean of 80 (mm Hg) and a standard deviation of 10. About what is the probability that a random 35-44 year old has a DBP less than 70?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;In a population of interest, a sample of 9 men yielded a sample average brain volume of 1,100cc and a standard deviation of 30cc. What is a 95% Student&amp;#39;s T confidence interval for the mean brain volume in this new population?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;A diet pill is given to 9 subjects over six weeks. The average difference in weight (follow up baseline) is -2 pounds. What would the standard - deviation of the difference in weight have to be for the upper endpoint of the 95% T confidence interval to touch 0?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;In a study of emergency room waiting times, investigators consider a new and the standard triage systems. To test the systems, administrators selected 20 nights and randomly assigned the new triage system to be used on 10 nights and the standard system on the remaining 10 nights. They calculated the nightly median waiting time (MWT) to see a physician. The average MWT for the new system was 3 hours with a variance of 0.60 while the average MWT for the old system was 5 hours with a variance of 0.68. Consider the 95% confidence interval estimate for the differences of the mean MWT associated with the new system. Assume a constant variance. What is the interval? Subtract in this order (New System - Old System).&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;To further test the hospital triage system, administrators selected 200 nights and randomly assigned a new triage system to be used on 100 nights and a standard system on the remaining 100 nights. They calculated the nightly median waiting time (MWT) to see a physician. The average MWT for the new system was 4 hours with a standard deviation of 0.5 hours while the average MWT for the old system was 6 hours with a standard deviation of 2 hours. Consider the hypothesis of a decrease in the mean MWT associated with the new treatment. What does the 95% independent group confidence interval with unequal variances suggest vis a vis this hypothesis? (Because there&amp;#39;s so many observations per group, just use the Z quantile instead of the T.)&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y57j0o", "is_robot_indexable": true, "report_reasons": null, "author": "unknowtopic", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y57j0o/75_data_science_interview_questions_most_asked/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y57j0o/75_data_science_interview_questions_most_asked/", "subreddit_subscribers": 813798, "created_utc": 1665894369.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,\n\nLong history short: the analytics director of my non-tech company, who is a DS illiterate, has hired a Data Science Lead that has considerably fewer qualifications, and just 2 years more work experience than me (senior DS). In our first interaction, he bragged about how he created a segmentation model using a random forest with an accuracy of 94% in his previous role ...\n\nI was previously leading our team of 3 DS and 2 DE. It is quite blurred how we will collaborate and divide the roles, management responsibilities, and workload.\n\nIt is still early days, but I wanted to get insights and advice from the community, from people who have been in a similar situation. I've done a few google searches on this topic and haven't found anything. Maybe everyone out there has competent and knowledgeable data science leads/managers? It could be the case, as I guess you can't fake being a data science lead and get away with it, can you?\n\n* How do senior data scientists learn and are mentored by lead data scientists in your organizations? Is there a way to check informally if this guy has knowledge/skills that I can really pick up and learn from him?\n* Should I transfer to him all my management responsibilities and the projects I own?\n* Any advice about how to cope with this situation, especially during his first 100 days would be gold. I guess working patterns and assumptions that solidify at the beginning will stay there. Thank you!", "author_fullname": "t2_5phwwjob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Have you ever been under a Data Science Lead/Manager who knew less than you? How did you cope?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4pxoe", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 47, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 47, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665845545.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;Long history short: the analytics director of my non-tech company, who is a DS illiterate, has hired a Data Science Lead that has considerably fewer qualifications, and just 2 years more work experience than me (senior DS). In our first interaction, he bragged about how he created a segmentation model using a random forest with an accuracy of 94% in his previous role ...&lt;/p&gt;\n\n&lt;p&gt;I was previously leading our team of 3 DS and 2 DE. It is quite blurred how we will collaborate and divide the roles, management responsibilities, and workload.&lt;/p&gt;\n\n&lt;p&gt;It is still early days, but I wanted to get insights and advice from the community, from people who have been in a similar situation. I&amp;#39;ve done a few google searches on this topic and haven&amp;#39;t found anything. Maybe everyone out there has competent and knowledgeable data science leads/managers? It could be the case, as I guess you can&amp;#39;t fake being a data science lead and get away with it, can you?&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;How do senior data scientists learn and are mentored by lead data scientists in your organizations? Is there a way to check informally if this guy has knowledge/skills that I can really pick up and learn from him?&lt;/li&gt;\n&lt;li&gt;Should I transfer to him all my management responsibilities and the projects I own?&lt;/li&gt;\n&lt;li&gt;Any advice about how to cope with this situation, especially during his first 100 days would be gold. I guess working patterns and assumptions that solidify at the beginning will stay there. Thank you!&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4pxoe", "is_robot_indexable": true, "report_reasons": null, "author": "werthobakew", "discussion_type": null, "num_comments": 56, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4pxoe/have_you_ever_been_under_a_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4pxoe/have_you_ever_been_under_a_data_science/", "subreddit_subscribers": 813798, "created_utc": 1665845545.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey all,\n\nAs a meager software engineer mortal, I've always been curious about how concepts/algorithms work in machine learning. I am starting a series of posts, documenting my understanding of these concepts.\n\nHere's my first attempt; it's on Gini impurity, a core concept fundamental in how decision trees are built.\n\n[https://gradiently.io/gini-impurity/](https://gradiently.io/gini-impurity/)", "author_fullname": "t2_6dnrwg8t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "An Explanation of Gini Impurity", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y50l0u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665873125.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;As a meager software engineer mortal, I&amp;#39;ve always been curious about how concepts/algorithms work in machine learning. I am starting a series of posts, documenting my understanding of these concepts.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s my first attempt; it&amp;#39;s on Gini impurity, a core concept fundamental in how decision trees are built.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://gradiently.io/gini-impurity/\"&gt;https://gradiently.io/gini-impurity/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y50l0u", "is_robot_indexable": true, "report_reasons": null, "author": "Ill-Tomato-8400", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y50l0u/an_explanation_of_gini_impurity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y50l0u/an_explanation_of_gini_impurity/", "subreddit_subscribers": 813798, "created_utc": 1665873125.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My goal is to have a place to ask question regarding Data Analyst stuff (like eigendecomposition, matrix reconstruction, eigenvector centrality) and next month regarding Data Science stuff.\n\nI've tried to ask question regarding eigendecomposition in StackOverflow and datascience.StackExchange.com, but to no avail. No one answered the question. I guess, Data Analyst and Data Scientist rarely use these forum.", "author_fullname": "t2_5yye765o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where do Data Analyst and Data Science ask question most of the time (except StackOverflow and StackExchange)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4o199", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665840608.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My goal is to have a place to ask question regarding Data Analyst stuff (like eigendecomposition, matrix reconstruction, eigenvector centrality) and next month regarding Data Science stuff.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried to ask question regarding eigendecomposition in StackOverflow and datascience.StackExchange.com, but to no avail. No one answered the question. I guess, Data Analyst and Data Scientist rarely use these forum.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4o199", "is_robot_indexable": true, "report_reasons": null, "author": "kidfromtheast", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4o199/where_do_data_analyst_and_data_science_ask/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4o199/where_do_data_analyst_and_data_science_ask/", "subreddit_subscribers": 813798, "created_utc": 1665840608.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I know there are a lot of posts about resources, but I don't recall seeing this specifically. \n\nI'm looking for for resources for Bayes statistics.   Everything I've found is either simple examples meant to introduce a concept... or very theoretical without many examples. \n\nI need something in the middle, examples that are complex and varied enough to get into details.  Maybe even something that progresses in difficult.  Currently going over MCMC, but I actually thing it's more basic Bayes stuff that I'm getting hung up on. \n\nI might be a bit weird... i'm good at math, but not strong.   What i mean is: I went up through Calc II in college and didn't have issues with it, but between a lack of application or practice, I've been struggling with the stats/math side of DS classes. \n\nIn honestly considering dropping this class, just so I can study and retake it next term.  Any assistance is appreciated!", "author_fullname": "t2_7t6en9d2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bayes examples and study help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y55z3b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665889307.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know there are a lot of posts about resources, but I don&amp;#39;t recall seeing this specifically. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for for resources for Bayes statistics.   Everything I&amp;#39;ve found is either simple examples meant to introduce a concept... or very theoretical without many examples. &lt;/p&gt;\n\n&lt;p&gt;I need something in the middle, examples that are complex and varied enough to get into details.  Maybe even something that progresses in difficult.  Currently going over MCMC, but I actually thing it&amp;#39;s more basic Bayes stuff that I&amp;#39;m getting hung up on. &lt;/p&gt;\n\n&lt;p&gt;I might be a bit weird... i&amp;#39;m good at math, but not strong.   What i mean is: I went up through Calc II in college and didn&amp;#39;t have issues with it, but between a lack of application or practice, I&amp;#39;ve been struggling with the stats/math side of DS classes. &lt;/p&gt;\n\n&lt;p&gt;In honestly considering dropping this class, just so I can study and retake it next term.  Any assistance is appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y55z3b", "is_robot_indexable": true, "report_reasons": null, "author": "Cryptic-Squid", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y55z3b/bayes_examples_and_study_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y55z3b/bayes_examples_and_study_help/", "subreddit_subscribers": 813798, "created_utc": 1665889307.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,  I am wondering about about some recent trends I have been experienced at work with younger or less experienced data scientists.\n\nPeople are fitting these large multivariate, nonlinear models that come directly from python libraries, for example PyOD outlier detection.   They just compare results from all the built in ML algos.   They don't think about any simple methods what so ever for detecting outliers.   However, the end user always drills down to univariate to see if the features are significant anyway.     So I don't see the purpose in testing the advanced algos without a baseline.\n\nSo instead of starting with a basic statistical outlier method, or univariate or linear method,like PCA, all of this is skipped and considered irrelevant or \"dinosaur\".  \n\nMy argument is that if you don't have a baseline simple method, you will never understand the benefit the ML algo brings .    Basically if they cant can't find a benefit over univariate ,  they shouldn't promote the advanced methods yet.\n\nWhat are your thoughts on this?\n\nHow do I convince these people to slow down and take baby steps to see the benefits without insulting them?  \n\nHow do I stop ignorant management from listening to these trendy individuals? Its quite frustrating when a simple method beats a complex desired method, but someone won't listen because they want to look smart.", "author_fullname": "t2_3qgvuco6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Simpler Methods over Advanced Algos", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4npv5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665839731.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,  I am wondering about about some recent trends I have been experienced at work with younger or less experienced data scientists.&lt;/p&gt;\n\n&lt;p&gt;People are fitting these large multivariate, nonlinear models that come directly from python libraries, for example PyOD outlier detection.   They just compare results from all the built in ML algos.   They don&amp;#39;t think about any simple methods what so ever for detecting outliers.   However, the end user always drills down to univariate to see if the features are significant anyway.     So I don&amp;#39;t see the purpose in testing the advanced algos without a baseline.&lt;/p&gt;\n\n&lt;p&gt;So instead of starting with a basic statistical outlier method, or univariate or linear method,like PCA, all of this is skipped and considered irrelevant or &amp;quot;dinosaur&amp;quot;.  &lt;/p&gt;\n\n&lt;p&gt;My argument is that if you don&amp;#39;t have a baseline simple method, you will never understand the benefit the ML algo brings .    Basically if they cant can&amp;#39;t find a benefit over univariate ,  they shouldn&amp;#39;t promote the advanced methods yet.&lt;/p&gt;\n\n&lt;p&gt;What are your thoughts on this?&lt;/p&gt;\n\n&lt;p&gt;How do I convince these people to slow down and take baby steps to see the benefits without insulting them?  &lt;/p&gt;\n\n&lt;p&gt;How do I stop ignorant management from listening to these trendy individuals? Its quite frustrating when a simple method beats a complex desired method, but someone won&amp;#39;t listen because they want to look smart.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4npv5", "is_robot_indexable": true, "report_reasons": null, "author": "Atxaquariguy", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4npv5/simpler_methods_over_advanced_algos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4npv5/simpler_methods_over_advanced_algos/", "subreddit_subscribers": 813798, "created_utc": 1665839731.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey Guys &amp; Gals!!!\n\nSo, I'm currently running some regressions and similar, in order to create a trading algorithm. I've collected and cleaned daily price data for each currency pair, and I have organised relevant variables. I'm looking to build an algorithm in order to best determine future price changes, based on a few variable. Some are dummy, some are percentage values. \n\nI've ran simple OLS regressions to see I have a strong and statistically significant (at 0.001% level) between my dummy and price data, although I'm struggling to work out how to incorporate more variables into this. I also don't think OLS is the best way to do this, should I be using MA(?) Or EMA(?)? I've done an economics degree with econometrics moudles so I know a bit about what I'm doing, although not enough to do what I want to.  (clearly \ud83d\ude02!)\n\nAny advice would be massively appreciated! I'm currency learning to use python, would NumPy or similar be satisfactory? \n\nThanks again!", "author_fullname": "t2_cj4nfibx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What tools should I run to determine the best predictive power?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4mshz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665837182.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Guys &amp;amp; Gals!!!&lt;/p&gt;\n\n&lt;p&gt;So, I&amp;#39;m currently running some regressions and similar, in order to create a trading algorithm. I&amp;#39;ve collected and cleaned daily price data for each currency pair, and I have organised relevant variables. I&amp;#39;m looking to build an algorithm in order to best determine future price changes, based on a few variable. Some are dummy, some are percentage values. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve ran simple OLS regressions to see I have a strong and statistically significant (at 0.001% level) between my dummy and price data, although I&amp;#39;m struggling to work out how to incorporate more variables into this. I also don&amp;#39;t think OLS is the best way to do this, should I be using MA(?) Or EMA(?)? I&amp;#39;ve done an economics degree with econometrics moudles so I know a bit about what I&amp;#39;m doing, although not enough to do what I want to.  (clearly \ud83d\ude02!)&lt;/p&gt;\n\n&lt;p&gt;Any advice would be massively appreciated! I&amp;#39;m currency learning to use python, would NumPy or similar be satisfactory? &lt;/p&gt;\n\n&lt;p&gt;Thanks again!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4mshz", "is_robot_indexable": true, "report_reasons": null, "author": "ChoccyRoccy", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4mshz/what_tools_should_i_run_to_determine_the_best/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4mshz/what_tools_should_i_run_to_determine_the_best/", "subreddit_subscribers": 813798, "created_utc": 1665837182.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I understand that you need to do Power analysis in order to figure out what sample size you need for your AB test, but something that I have difficulty coming up with is \u201cwhat MDE should we use?\u201d  Researching online hasn\u2019t been much help because all I see are examples of where they just give an MDE to use but don\u2019t explain the process of getting there. \n\nFor my company, a lot of our tests have very low operational costs, so in almost all cases any positive performance is worth rolling out. Basically, even if we saw only a 0.05% lift, if it was statistically significant, we\u2019d probably implement the change. This has led me down a path where I basically just check to see what MDE we can reasonably detect given the number of users coming into the platform INSTEAD of determining what MDE is actually valuable. I feel like this is the wrong approach, but I\u2019m unsure what else to do given that our \u201cgoal\u201d MDE is basically anything above 0. This especially makes it difficult for me to determine when I should stop the tests as well, other than picking a somewhat arbitrary end point of 3-4 weeks and then seeing if there is any directional value from the data. \n\nWhat would you do in this situation? How do you determine the MDE for your AB tests? \n\nThanks!", "author_fullname": "t2_3dbxxd6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to determine what value is good for minimum detectable effect (MDE) for AB testing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4t1y1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665853411.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I understand that you need to do Power analysis in order to figure out what sample size you need for your AB test, but something that I have difficulty coming up with is \u201cwhat MDE should we use?\u201d  Researching online hasn\u2019t been much help because all I see are examples of where they just give an MDE to use but don\u2019t explain the process of getting there. &lt;/p&gt;\n\n&lt;p&gt;For my company, a lot of our tests have very low operational costs, so in almost all cases any positive performance is worth rolling out. Basically, even if we saw only a 0.05% lift, if it was statistically significant, we\u2019d probably implement the change. This has led me down a path where I basically just check to see what MDE we can reasonably detect given the number of users coming into the platform INSTEAD of determining what MDE is actually valuable. I feel like this is the wrong approach, but I\u2019m unsure what else to do given that our \u201cgoal\u201d MDE is basically anything above 0. This especially makes it difficult for me to determine when I should stop the tests as well, other than picking a somewhat arbitrary end point of 3-4 weeks and then seeing if there is any directional value from the data. &lt;/p&gt;\n\n&lt;p&gt;What would you do in this situation? How do you determine the MDE for your AB tests? &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4t1y1", "is_robot_indexable": true, "report_reasons": null, "author": "matt22022", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4t1y1/how_to_determine_what_value_is_good_for_minimum/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4t1y1/how_to_determine_what_value_is_good_for_minimum/", "subreddit_subscribers": 813798, "created_utc": 1665853411.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am on track to get into [this](https://soic.iupui.edu/degrees/undergraduate/data-info-science/) program, and I\u2019m still not sure what I want to do with myself. I have very little knowledge of the tech world other than what I\u2019ve learned in school. Based on your professional opinions, is this degree *really* going to open doors, or should I take the classes to move towards something different such as computer science?", "author_fullname": "t2_dv5bxf49", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about my college degree major", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y57x1j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1665895729.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am on track to get into &lt;a href=\"https://soic.iupui.edu/degrees/undergraduate/data-info-science/\"&gt;this&lt;/a&gt; program, and I\u2019m still not sure what I want to do with myself. I have very little knowledge of the tech world other than what I\u2019ve learned in school. Based on your professional opinions, is this degree &lt;em&gt;really&lt;/em&gt; going to open doors, or should I take the classes to move towards something different such as computer science?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1ZcUXlQa5aFZ5WQjr5s0Fp6PiNHr5VMGTg1XYtdl8Bo.jpg?auto=webp&amp;s=4695bd046175d0f7f85682da6306dfd304734ff0", "width": 965, "height": 667}, "resolutions": [{"url": "https://external-preview.redd.it/1ZcUXlQa5aFZ5WQjr5s0Fp6PiNHr5VMGTg1XYtdl8Bo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0865ddc0111789b9cf80503ff3b89a2c65f395f2", "width": 108, "height": 74}, {"url": "https://external-preview.redd.it/1ZcUXlQa5aFZ5WQjr5s0Fp6PiNHr5VMGTg1XYtdl8Bo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0608cd8eabfaa996a8b1b65b6ce9a7c3752ccd1c", "width": 216, "height": 149}, {"url": "https://external-preview.redd.it/1ZcUXlQa5aFZ5WQjr5s0Fp6PiNHr5VMGTg1XYtdl8Bo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d7e52de9018d7220d1b654807ff102e0d55d25ca", "width": 320, "height": 221}, {"url": "https://external-preview.redd.it/1ZcUXlQa5aFZ5WQjr5s0Fp6PiNHr5VMGTg1XYtdl8Bo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=33de40b23135f48a848d9cb90bd5d6ba27e9a65f", "width": 640, "height": 442}, {"url": "https://external-preview.redd.it/1ZcUXlQa5aFZ5WQjr5s0Fp6PiNHr5VMGTg1XYtdl8Bo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ecb63204909d75086e2046b9df5be2f87897165e", "width": 960, "height": 663}], "variants": {}, "id": "q_836bpWaFOPf5QRp_upv_xcDKRLwic5N4AYZuRlqos"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y57x1j", "is_robot_indexable": true, "report_reasons": null, "author": "hoosiercrisis", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y57x1j/question_about_my_college_degree_major/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y57x1j/question_about_my_college_degree_major/", "subreddit_subscribers": 813798, "created_utc": 1665895729.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "TL;DR: Has industry demand on experts in Bayesian-ML for Control Engineering?\n\n&amp;#x200B;\n\nHey,\n\nI'm a CS student right before my master thesis and I have to take a decision between two career topics:\n\n1. Becoming an NLP expert.\n2. Becoming an expert on Bayesian-ML for Control Engineering.\n\nThe path I want to take is Master-Thesis --&gt; PhD --&gt; Industry. There are many pros and cons for me to take any of these two. I'm here because I doubt the demand of the industry on additional experts in *Bayesian-ML for Control Engineering*. The doubts originate from the following reason.\n\nPeople are working on Bayesian methods since decades and engineering also does respectively. So it might be, that experts from these decades are already spread through the industry.\n\nNLP in comparison is pretty new and on high demand without a doubt.\n\nDoes someone has insights for me on the demand of the industry on Bayesian-ML in Control Engineering? More specifically I could also ask, if Kalman Filters and Gaussian Processes are of interest?\n\n&amp;#x200B;\n\nI'm thanking every reader for his/her/&lt;other pronouns&gt; attention and even more for answers :)\n\nLinks to informative threads are also appreciated (I only found average useful ones)!", "author_fullname": "t2_kmck7zwg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Demand on Bayesian-ML in Control Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4q6rh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665846168.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TL;DR: Has industry demand on experts in Bayesian-ML for Control Engineering?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Hey,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a CS student right before my master thesis and I have to take a decision between two career topics:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Becoming an NLP expert.&lt;/li&gt;\n&lt;li&gt;Becoming an expert on Bayesian-ML for Control Engineering.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The path I want to take is Master-Thesis --&amp;gt; PhD --&amp;gt; Industry. There are many pros and cons for me to take any of these two. I&amp;#39;m here because I doubt the demand of the industry on additional experts in &lt;em&gt;Bayesian-ML for Control Engineering&lt;/em&gt;. The doubts originate from the following reason.&lt;/p&gt;\n\n&lt;p&gt;People are working on Bayesian methods since decades and engineering also does respectively. So it might be, that experts from these decades are already spread through the industry.&lt;/p&gt;\n\n&lt;p&gt;NLP in comparison is pretty new and on high demand without a doubt.&lt;/p&gt;\n\n&lt;p&gt;Does someone has insights for me on the demand of the industry on Bayesian-ML in Control Engineering? More specifically I could also ask, if Kalman Filters and Gaussian Processes are of interest?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thanking every reader for his/her/&amp;lt;other pronouns&amp;gt; attention and even more for answers :)&lt;/p&gt;\n\n&lt;p&gt;Links to informative threads are also appreciated (I only found average useful ones)!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4q6rh", "is_robot_indexable": true, "report_reasons": null, "author": "Michael_Skowronek", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4q6rh/demand_on_bayesianml_in_control_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4q6rh/demand_on_bayesianml_in_control_engineering/", "subreddit_subscribers": 813798, "created_utc": 1665846168.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "A chart is displayed with precision and recall scores. The table underneath calculated the scores so they were double format 1, 0 .67 etc and it grouped by certain fields such as week.\n\nThe chart then converted these doubles to % and displayed by month using SUM(precision)\n\nI was requested to also include additional field, hour (24 hr clock) as they wanted to be able to filter on the charts by the hour.\n\nI did this, and obviously when we added this to the GROUP BY the sum(precision) values increased in number, and the chart range now goes up to 900%.\n\nWhat can I do to make this range display accurate %s between 0 - 100?\n\nor is this a bogus calculation? THanks!", "author_fullname": "t2_eejku9w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "calculating with group by", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4nmur", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665839501.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A chart is displayed with precision and recall scores. The table underneath calculated the scores so they were double format 1, 0 .67 etc and it grouped by certain fields such as week.&lt;/p&gt;\n\n&lt;p&gt;The chart then converted these doubles to % and displayed by month using SUM(precision)&lt;/p&gt;\n\n&lt;p&gt;I was requested to also include additional field, hour (24 hr clock) as they wanted to be able to filter on the charts by the hour.&lt;/p&gt;\n\n&lt;p&gt;I did this, and obviously when we added this to the GROUP BY the sum(precision) values increased in number, and the chart range now goes up to 900%.&lt;/p&gt;\n\n&lt;p&gt;What can I do to make this range display accurate %s between 0 - 100?&lt;/p&gt;\n\n&lt;p&gt;or is this a bogus calculation? THanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4nmur", "is_robot_indexable": true, "report_reasons": null, "author": "panadol64", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4nmur/calculating_with_group_by/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4nmur/calculating_with_group_by/", "subreddit_subscribers": 813798, "created_utc": 1665839501.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi guys,\n\nJunior analyst here and I was hoping I can pick your brains on a challenge. I have an ecommerce dataset for customer purchases and the challenge is to measure the share of customers who purchased from multiple categories in a month and continue to purchase in multiple categories in succeeding months.\n\nHas anyone done a similar project before through Python? It would be great to hear your thoughts on how I might approach this in the code.\n\nThank you!\n\n[sample ecommerce dataset](https://preview.redd.it/7xzu56eauyt91.png?width=1452&amp;format=png&amp;auto=webp&amp;s=8e8469cfd113fd52c0d16be4a5db47d6412c264f)", "author_fullname": "t2_87cwramh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Measuring customers who purchased from multiple categories", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 137, "top_awarded_type": null, "hide_score": false, "media_metadata": {"7xzu56eauyt91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 105, "x": 108, "u": "https://preview.redd.it/7xzu56eauyt91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1bbf710f77e92a4d1d1ac5d440a08ea23416246b"}, {"y": 211, "x": 216, "u": "https://preview.redd.it/7xzu56eauyt91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0633909f195b1ac7a26ece125fb3ff4aacbc5748"}, {"y": 313, "x": 320, "u": "https://preview.redd.it/7xzu56eauyt91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=1f0409b5e4736caadd2427b86f5d313d45b305c0"}, {"y": 627, "x": 640, "u": "https://preview.redd.it/7xzu56eauyt91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=fc06bf96cb5ed05ccf630904e60ba8a0292074d6"}, {"y": 941, "x": 960, "u": "https://preview.redd.it/7xzu56eauyt91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=fef8ce00b11eb07251d0861ad5ea36cbb6fe0018"}, {"y": 1059, "x": 1080, "u": "https://preview.redd.it/7xzu56eauyt91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f11702db91c6ea0717063d23c7ba8e2baa32939a"}], "s": {"y": 1424, "x": 1452, "u": "https://preview.redd.it/7xzu56eauyt91.png?width=1452&amp;format=png&amp;auto=webp&amp;s=8e8469cfd113fd52c0d16be4a5db47d6412c264f"}, "id": "7xzu56eauyt91"}}, "name": "t3_y4n33g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/8nl7snpB-ohbPTVE_qFBJA8OFTPVjP5t0Vksq4QvjBw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665838019.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;Junior analyst here and I was hoping I can pick your brains on a challenge. I have an ecommerce dataset for customer purchases and the challenge is to measure the share of customers who purchased from multiple categories in a month and continue to purchase in multiple categories in succeeding months.&lt;/p&gt;\n\n&lt;p&gt;Has anyone done a similar project before through Python? It would be great to hear your thoughts on how I might approach this in the code.&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/7xzu56eauyt91.png?width=1452&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8e8469cfd113fd52c0d16be4a5db47d6412c264f\"&gt;sample ecommerce dataset&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4n33g", "is_robot_indexable": true, "report_reasons": null, "author": "Shirt_Reasonable", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4n33g/measuring_customers_who_purchased_from_multiple/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4n33g/measuring_customers_who_purchased_from_multiple/", "subreddit_subscribers": 813798, "created_utc": 1665838019.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "A few months ago I started a data science focused blog. I\u2019ve posted a few tutorials but I\u2019ve mostly posted data stories about things that interest me. I try to make an interactive element that is usually a small web app that lets you interact with the data. I\u2019ve had some moderate success with about 10 thousand unique visitors in September. \n\nMy question is, do y\u2019all care about these data stories? I would prefer to make things people want, and I\u2019m not sure I\u2019m doing that. A few ideas I had that y\u2019all might like:\n\n- Live streams of doing data science projects. Scraping, cleaning, and modeling in one chunk of time. \n- Technical posts. Do a project and walk  through the code. Basically blog post with code. Not a tutorial exactly though. \n- Mini data products with all code attached to remake/remix yourself. \n\nI\u2019m open to ideas. So, what kind of content would you like more of?\n\nThe blog is [datafantic.com](https://datafantic.com). My goal here is not to get clicks but to understand y\u2019all better. My target audience is other data scientists, and I would like to create content y\u2019all like.", "author_fullname": "t2_a0kcgwo4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you want in a data science publication (blog)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4jlh7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1665826689.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A few months ago I started a data science focused blog. I\u2019ve posted a few tutorials but I\u2019ve mostly posted data stories about things that interest me. I try to make an interactive element that is usually a small web app that lets you interact with the data. I\u2019ve had some moderate success with about 10 thousand unique visitors in September. &lt;/p&gt;\n\n&lt;p&gt;My question is, do y\u2019all care about these data stories? I would prefer to make things people want, and I\u2019m not sure I\u2019m doing that. A few ideas I had that y\u2019all might like:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Live streams of doing data science projects. Scraping, cleaning, and modeling in one chunk of time. &lt;/li&gt;\n&lt;li&gt;Technical posts. Do a project and walk  through the code. Basically blog post with code. Not a tutorial exactly though. &lt;/li&gt;\n&lt;li&gt;Mini data products with all code attached to remake/remix yourself. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I\u2019m open to ideas. So, what kind of content would you like more of?&lt;/p&gt;\n\n&lt;p&gt;The blog is &lt;a href=\"https://datafantic.com\"&gt;datafantic.com&lt;/a&gt;. My goal here is not to get clicks but to understand y\u2019all better. My target audience is other data scientists, and I would like to create content y\u2019all like.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jK_Rae0h1ebDEMtfUdLFkxTifROb_wRsOUsOXOyoYdQ.jpg?auto=webp&amp;s=24573f8cb91746901ee7305d63ee2cd574f44ed6", "width": 950, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/jK_Rae0h1ebDEMtfUdLFkxTifROb_wRsOUsOXOyoYdQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e632d1dfa8e6ae10a550016f4832af44f791cd64", "width": 108, "height": 68}, {"url": "https://external-preview.redd.it/jK_Rae0h1ebDEMtfUdLFkxTifROb_wRsOUsOXOyoYdQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0b32276b51d8974c4fd7c9486b6f80143396a5bb", "width": 216, "height": 136}, {"url": "https://external-preview.redd.it/jK_Rae0h1ebDEMtfUdLFkxTifROb_wRsOUsOXOyoYdQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c0135baa377781ee5db9898c61eb0aae9d724ef4", "width": 320, "height": 202}, {"url": "https://external-preview.redd.it/jK_Rae0h1ebDEMtfUdLFkxTifROb_wRsOUsOXOyoYdQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a5c4fedefb2f0b1f2cad8c65898887bf23e8dfc5", "width": 640, "height": 404}], "variants": {}, "id": "4ThJ0-MX4f9TGEZ0W5hZ8TGZk7Hp7jMc1Hwr4rtRwpc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4jlh7", "is_robot_indexable": true, "report_reasons": null, "author": "robert_ritz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4jlh7/what_do_you_want_in_a_data_science_publication/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4jlh7/what_do_you_want_in_a_data_science_publication/", "subreddit_subscribers": 813798, "created_utc": 1665826689.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello Data Enthusiasts,\n\nWhat kind of projects should i be focusing on or doing more of from a entry level job perspective? Also, what do recruiters mostly look for entry level graduates in data science field?\n\nAny projects ideas would be helpful?", "author_fullname": "t2_bsfosv4r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Projects relating to DS/ML?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y58scn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665898781.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Data Enthusiasts,&lt;/p&gt;\n\n&lt;p&gt;What kind of projects should i be focusing on or doing more of from a entry level job perspective? Also, what do recruiters mostly look for entry level graduates in data science field?&lt;/p&gt;\n\n&lt;p&gt;Any projects ideas would be helpful?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y58scn", "is_robot_indexable": true, "report_reasons": null, "author": "Adventurous-Grab-20", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y58scn/projects_relating_to_dsml/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y58scn/projects_relating_to_dsml/", "subreddit_subscribers": 813798, "created_utc": 1665898781.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I understand the difference between ML and DL ,which one is used mostly in your day to day jobs. As a  Data Science Beginner which area should i be focusing more ML or DL from a job perspective?", "author_fullname": "t2_bsfosv4r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is widely used ML or DL in your day to day jobs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4s3sr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665851026.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I understand the difference between ML and DL ,which one is used mostly in your day to day jobs. As a  Data Science Beginner which area should i be focusing more ML or DL from a job perspective?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4s3sr", "is_robot_indexable": true, "report_reasons": null, "author": "Adventurous-Grab-20", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4s3sr/what_is_widely_used_ml_or_dl_in_your_day_to_day/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4s3sr/what_is_widely_used_ml_or_dl_in_your_day_to_day/", "subreddit_subscribers": 813798, "created_utc": 1665851026.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've learnt concepts like linear, logistic regression, SVM, decision tree, gaussian mixture model, k means clustering. \n\nHow I want to use this to analyze selfdriving car dataset but not sure how do I use these principles on images ? most of the data from self driving cars are images from cameras. \n\nCan someone point me to an example notebook ?", "author_fullname": "t2_13t60b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I've recently completed a post graduate certification in ML and analytics. How to apply learning and principles using kaggle dataset?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4rktl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.2, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665849707.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve learnt concepts like linear, logistic regression, SVM, decision tree, gaussian mixture model, k means clustering. &lt;/p&gt;\n\n&lt;p&gt;How I want to use this to analyze selfdriving car dataset but not sure how do I use these principles on images ? most of the data from self driving cars are images from cameras. &lt;/p&gt;\n\n&lt;p&gt;Can someone point me to an example notebook ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4rktl", "is_robot_indexable": true, "report_reasons": null, "author": "drugsarebadmky", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4rktl/ive_recently_completed_a_post_graduate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4rktl/ive_recently_completed_a_post_graduate/", "subreddit_subscribers": 813798, "created_utc": 1665849707.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am Japanese, so please forgive me if my grammar may be incorrect.  \n\n\nI would like to know how to reward DAOs not on a task basis, but by calculating their contribution through data analysis.  \nIf we can create that method with high quality, I believe we can create a new system of economy that will be upward compatible with capitalism.  \nWe call it freeism.  \n\n\nAbout freeism\n\nWe came up with the \"freeism\" system as an alternative economic mechanism to capitalism.\n\nIt gives a new alternative to economic mechanisms that have had only limited choices, such as capitalism and socialism.\n\nI know that many people are already thinking about this kind of thing, but I would like to implement it as a part of the social structure, not as a theoretical theory, and eventually create a society in which the entire economy revolves around freeism instead of capitalism.\n\n&amp;#x200B;\n\nBasic Mechanism of Freeism\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nThe following is an explanation of the basic mechanism of FREELISM.\n\n&amp;#x200B;\n\nThe supplier is asked to provide all types of goods and services for free, and non-transferable points (SBT?) (called contribution points) are given to those who provide them.\n\nThere will be multiple ways to calculate contribution points, and we will also create a mechanism to provide them.\n\nThe mechanism is described below.\n\nFor products or services that are not available to all who want them (hereinafter referred to as \"limited edition products\"), the points (hereinafter referred to as \"quota\") will be set as the square root of contribution points, and those who offer to use the most quota will be given priority in using them.\n\nInstead of consuming contribution points as compensation for obtaining goods or services, they should only be accounted for so that they cannot be used to obtain other limited items.\n\nTherefore, contribution points do not decrease even if a limited item is obtained but accumulate (exceptions apply. See below)\n\nNecessity\n\nThe necessity of the quota is described below.\n\nThe method of calculating the quota is also described below.\n\nThis type of economic mechanism is called \"freeism.\n\nFreeism is an economic model that can be finally established by using technologies such as data analysis, blockchain, web apps, etc.\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nDig a little deeper into the mechanism of FREESISM\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nThis section explains each of the mechanisms that make up FREESISM.\n\n&amp;#x200B;\n\nContribution rules\n\nThe rules of contribution are the laws that govern life in a freeism society.\n\nOr the country in which the law is located.\n\nAt first, only one rule exists, but just as there are multiple countries, multiple rules of contribution can be created.\n\nThe contribution rules should be easy for anyone to create.\n\nI want the rules of contribution to be divided by ideology and taste (only some people emigrate based on taxation, culture, and taste, but for the most part, the current country is determined by birth and upbringing, and there are people with different tastes, values, and ideology in the same country, which creates conflict).\n\nThat is why we create the right of non-interference as the right not to interfere with others.\n\nEach contribution rule has an end goal.\n\nThe end goal is discussed below.\n\n&amp;#x200B;\n\nThe FREEISM Platform\n\nThe freeism platform is a mechanism to manage the rules of contribution.\n\nThe rules of contribution play a legal role.\n\nThe freeism platform becomes a higher-level entity like the Constitution OR the UN OR the federal government.\n\nThe freeism platform also has rules, and within the scope of those rules, they get to make the rules of contribution.\n\nThere will be multiple freeism platforms, and people will be able to join any freeism platform they want.\n\nA freeism platform may also have an end goal.\n\nThe end goal is described below.\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nFinal Goal\n\nThe end goal is the goal that each freeism platform, each contribution rule, and each project (like a company) is aiming for.\n\nIt can be set by vote, decided at the establishment stage, or left to the decision-makers to set.\n\nSet goals that you want to achieve, not goals or KPIs to achieve subdivided goals.\n\nFor example, \"increase in happiness,\" \"degree of health,\" \"increase in productivity,\" \"increase in the number of rational decisions made,\" and \"crime rate.\"\n\nIt is unclear if we would set \"lower crime rate\" as a goal since even \"lower crime rate\" might be a goal to achieve higher levels of happiness. We want to set a goal that we are ultimately aiming for.\n\nFor FREEISM, we should set a final goal for the FREEISM platform, a final goal for the contribution rule, and a final goal for the project, and then calculate the contributions based on how much they have helped to bring us closer to or achieve that final goal.\n\nExamples of final goals\n\nIncrease in productivity (working hours required to obtain goods and services) within the limits of the law\n\nIncrease in happiness within the limits of the law\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nContribution points\n\nRefers to points required to obtain priority for limited items.\n\nContribution points are non-transferable.\n\nHowever, loans are possible under some contribution rules.\n\nCan I use SBT as contribution points?\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nHow to Calculate Contribution Points\n\nContribution points earned are calculated based on \"the degree of contribution to the final goal\" \u2716\ufe0e \"market principle\" \u2716\ufe0e \"different weighting/rules for each contribution rule.\"\n\nUntil now, it was \"market principles\" \u2716\ufe0e \"different weighting/rules for each country or region rule\", but we will add \"degree of contribution to the final goal\" to it.\n\nI think the market principle is encapsulated in the degree of contribution to the final goal. However, if you still want to make further use of the market principle, you can give contribution points based on \"market principle x degree of contribution to the final goal\" or \"market principle only\".\n\nThe degree of contribution to the final goal could be calculated using multiple regression analysis or other data analysis methods or methods to visualize DAO's task-based contribution.\n\nSee below.\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nQuota\n\nThe quota is a mechanism to avoid monopolizing the service, and if the service can be provided to everyone, the quota is not used.\n\nEach contribution rule has a different way of calculating the quota, and each person is given a quota weighted by contribution points (contribution points \u2716\ufe0f0.9 = amount of quota, etc.) or the square root of contribution points.\n\nThe amount of quota used will be the price.\n\nThere is a negative correlation: the lower the winning rate of a product or service, the more quota it occupies, and the closer the winning rate is to 100%, the less quota it occupies.\n\nIn FREESISM, the quota is always used while the limited item is in use, and the amount used always reflects the market value, not the amount used when it was acquired.\n\nThe structure of the quota differs for each contribution rule.\n\nThe period you occupy a quota should be the period you own that limited edition item.\n\nIf you give it away or throw it away, you can apply for it on the FREEMISM platform, or the service will automatically detect it and release the use of the quota.\n\nTo prevent \"false applications\" where people apply to give it away when they own it, make it necessary to give it away or throw it away at a predetermined location or app.\n\nCreate an incentive to have it detected through the app, since it should be detected from each app and if not through the app, it will occupy the frame all the time.\n\nMake it impossible for people to report that they have given it up on their own, other than by having the app automatically detect it.\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nFREEISM\n\nIn freeism, if other people refer to the products, services, source code, or other deliverables developed by each person, or to know-how and other things such as research findings, they will receive only a portion of the contribution points earned by the person they refer to, such as 0.5 times the contribution points earned by the person they refer to.\n\nThereby.\n\nIf someone only submits an idea and others implement it, the person who submitted the idea will also receive a portion of the contribution points earned by the person who implemented it.\n\nIf another company started a business and failed but was successful in running it by avoiding the strategies of the failed company, then allow the people who worked in the failed company to receive a portion of the contribution points earned by the successful company.\n\nThat way, where it was 0-1 to succeed or fail, maybe we could make it so that even if it fails, it is not 0-1 financially, but there is some benefit.\n\nSince points are just points, unlike the currency, they don't have to be distributed and can be offered to both.\n\nBut it's hard to determine if that's what I was referring to.\n\nI will discuss this later.\n\nWe want a society where everything is open source.\n\nI want to create a society where every no-how, patent, and other thing is open source, by weighting the contribution points that can be earned if others use the no-how, and by weighting the contribution points that can be earned just by making it open source, such as 1.2 times the contribution points that can be earned by making it open source.\n\nEveryone gets it without having to distribute, and being open source could lead to more compensation for sharing without monopolizing rather than monopolizing and competing.\n\nBut if the relative position without distribution determines whether you get a limited product, is it the same as when profits were shared?\n\nIt's more mentally stable because you don't have to fight for a piece of the pie.\n\nThe basic idea is to think in terms of rules of contribution, where the only rule is the degree of contribution to the liberal end goal, but when considering various rules of contribution, we can make a law that regulates each of them in a way that is characteristic to the sound of each rule of contribution.\n\nEven if any action is the wrong action or not, we will stipulate that only actions that have a bad impact on the final goal contribution level are bad.\n\nEven theft would not be a crime if it did not negatively impact anyone.\n\nSomewhere the idea is like a woman who says it's not cheating if she doesn't get caught in a love story about whether or not she qualifies as cheating.\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nThe position of each\n\nIn freeism, the system is divided into a freeism platform, contribution rules, projects, and other mechanisms.\n\nThe freeism platform is the role of the federal government, the contribution rule is the role of the state government, and the project is the role of the company.\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nProject\n\nThe role of the company.\n\nThe idea of freeism is to make everything open, so all the data of companies that are currently hidden will be shared and made available to everyone so that the contribution points earned will be weighted 1.1 times more than before.\n\nOr, by being more open, make the service more technical and reliable, so that it is seen as contributing to the well-being and other end goals.\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nPrice\n\nThe lower the winning rate (the percentage of people who apply who win), the more quota is occupied and the more the beneficiary pays.\n\nThe amount of quota used becomes the price, so if the winning rate increases, the price becomes \"completely free\" with zero quota use of zero yen.\n\nIn capitalism, even for products with high demand and high supply, the price is close to the cost, but the beneficiaries bear the burden.\n\nIn FREEMISM, the overall goods and services are cheaper because they are negatively correlated with the winning rate, regardless of cost.\n\nFurthermore, since the added value cannot be added to the price, the price becomes cheaper by that amount, and the beneficiary burden of freeism is better than the beneficiary burden of capitalism.\n\nThe provider of goods and services receives nothing from the beneficiary for providing goods and services, and the beneficiary pays nothing to the provider for acquiring goods and services, which only increases the amount that occupies the quota managed by the freeism platform.\n\nThe provider can offer goods and services to those who cannot afford to pay for them, and if they do, the business will be compensated.\n\n  \nLife of FREEISM\n\nLet's imagine and write about what society would be like in a society where FREESISM is realized.\n\n&amp;#x200B;\n\nDownload or use any of the web apps, native apps, VR or AR apps of the freeism app (which also serves as the freeism platform) that manages all the functions of freeism, from a web app, native app, VR, or AR app, or a browser.\n\nIn the freeism app, choose the contribution rule to which you want to belong.\n\nEnter various information about yourself and link it to the contribution rule you have chosen, and generate an account with the data for that contribution rule.\n\nYou can put the date of the contribution rule you belong to as a property in your wallet for Web3, or in your Google account for Web2, etc.\n\nWith the account containing that data, data is acquired from various applications and the contribution rules are calculated using that data.\n\nFurthermore, according to each contribution rule, you can display 00 content on Twitter, but not 00. If the content is prohibited by each rule of each contribution level, such as \"00 content is allowed to be displayed on Twitter, but 00 is prohibited,\" each rule of each contribution level will be detected from the account and automatically hidden.\n\nWhen you want to get a product or service on each platform of freeism services or existing services (Amazon, Spotify, etc.), you can get the person's contribution points from the API that can get the contribution points of each person managed by that freeism platform, and Then, we can set up an input field in the platform, such as Amazon, where people can input how many quotas they want to offer, and those who offer the highest amount will be given priority to receive?\n\nIs it faster to create a new one?\n\nThose who offer limited items in the above process will receive contribution points for the contribution rules to which they belong.\n\nThere is no such thing as an exchange rate between multiple contribution points, so the more contribution rules that contribute to the ultimate goal of the freeism platform, the larger the percentage to be offered (tentative idea).\n\nCompatibility between freeism platforms is discussed below.", "author_fullname": "t2_dy46uwx1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "freeism\u30fcCapitalism upwardly compatible\u30fc", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y539db", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.2, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665880895.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am Japanese, so please forgive me if my grammar may be incorrect.  &lt;/p&gt;\n\n&lt;p&gt;I would like to know how to reward DAOs not on a task basis, but by calculating their contribution through data analysis.&lt;br/&gt;\nIf we can create that method with high quality, I believe we can create a new system of economy that will be upward compatible with capitalism.&lt;br/&gt;\nWe call it freeism.  &lt;/p&gt;\n\n&lt;p&gt;About freeism&lt;/p&gt;\n\n&lt;p&gt;We came up with the &amp;quot;freeism&amp;quot; system as an alternative economic mechanism to capitalism.&lt;/p&gt;\n\n&lt;p&gt;It gives a new alternative to economic mechanisms that have had only limited choices, such as capitalism and socialism.&lt;/p&gt;\n\n&lt;p&gt;I know that many people are already thinking about this kind of thing, but I would like to implement it as a part of the social structure, not as a theoretical theory, and eventually create a society in which the entire economy revolves around freeism instead of capitalism.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Basic Mechanism of Freeism&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The following is an explanation of the basic mechanism of FREELISM.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The supplier is asked to provide all types of goods and services for free, and non-transferable points (SBT?) (called contribution points) are given to those who provide them.&lt;/p&gt;\n\n&lt;p&gt;There will be multiple ways to calculate contribution points, and we will also create a mechanism to provide them.&lt;/p&gt;\n\n&lt;p&gt;The mechanism is described below.&lt;/p&gt;\n\n&lt;p&gt;For products or services that are not available to all who want them (hereinafter referred to as &amp;quot;limited edition products&amp;quot;), the points (hereinafter referred to as &amp;quot;quota&amp;quot;) will be set as the square root of contribution points, and those who offer to use the most quota will be given priority in using them.&lt;/p&gt;\n\n&lt;p&gt;Instead of consuming contribution points as compensation for obtaining goods or services, they should only be accounted for so that they cannot be used to obtain other limited items.&lt;/p&gt;\n\n&lt;p&gt;Therefore, contribution points do not decrease even if a limited item is obtained but accumulate (exceptions apply. See below)&lt;/p&gt;\n\n&lt;p&gt;Necessity&lt;/p&gt;\n\n&lt;p&gt;The necessity of the quota is described below.&lt;/p&gt;\n\n&lt;p&gt;The method of calculating the quota is also described below.&lt;/p&gt;\n\n&lt;p&gt;This type of economic mechanism is called &amp;quot;freeism.&lt;/p&gt;\n\n&lt;p&gt;Freeism is an economic model that can be finally established by using technologies such as data analysis, blockchain, web apps, etc.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Dig a little deeper into the mechanism of FREESISM&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;This section explains each of the mechanisms that make up FREESISM.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Contribution rules&lt;/p&gt;\n\n&lt;p&gt;The rules of contribution are the laws that govern life in a freeism society.&lt;/p&gt;\n\n&lt;p&gt;Or the country in which the law is located.&lt;/p&gt;\n\n&lt;p&gt;At first, only one rule exists, but just as there are multiple countries, multiple rules of contribution can be created.&lt;/p&gt;\n\n&lt;p&gt;The contribution rules should be easy for anyone to create.&lt;/p&gt;\n\n&lt;p&gt;I want the rules of contribution to be divided by ideology and taste (only some people emigrate based on taxation, culture, and taste, but for the most part, the current country is determined by birth and upbringing, and there are people with different tastes, values, and ideology in the same country, which creates conflict).&lt;/p&gt;\n\n&lt;p&gt;That is why we create the right of non-interference as the right not to interfere with others.&lt;/p&gt;\n\n&lt;p&gt;Each contribution rule has an end goal.&lt;/p&gt;\n\n&lt;p&gt;The end goal is discussed below.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The FREEISM Platform&lt;/p&gt;\n\n&lt;p&gt;The freeism platform is a mechanism to manage the rules of contribution.&lt;/p&gt;\n\n&lt;p&gt;The rules of contribution play a legal role.&lt;/p&gt;\n\n&lt;p&gt;The freeism platform becomes a higher-level entity like the Constitution OR the UN OR the federal government.&lt;/p&gt;\n\n&lt;p&gt;The freeism platform also has rules, and within the scope of those rules, they get to make the rules of contribution.&lt;/p&gt;\n\n&lt;p&gt;There will be multiple freeism platforms, and people will be able to join any freeism platform they want.&lt;/p&gt;\n\n&lt;p&gt;A freeism platform may also have an end goal.&lt;/p&gt;\n\n&lt;p&gt;The end goal is described below.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Final Goal&lt;/p&gt;\n\n&lt;p&gt;The end goal is the goal that each freeism platform, each contribution rule, and each project (like a company) is aiming for.&lt;/p&gt;\n\n&lt;p&gt;It can be set by vote, decided at the establishment stage, or left to the decision-makers to set.&lt;/p&gt;\n\n&lt;p&gt;Set goals that you want to achieve, not goals or KPIs to achieve subdivided goals.&lt;/p&gt;\n\n&lt;p&gt;For example, &amp;quot;increase in happiness,&amp;quot; &amp;quot;degree of health,&amp;quot; &amp;quot;increase in productivity,&amp;quot; &amp;quot;increase in the number of rational decisions made,&amp;quot; and &amp;quot;crime rate.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;It is unclear if we would set &amp;quot;lower crime rate&amp;quot; as a goal since even &amp;quot;lower crime rate&amp;quot; might be a goal to achieve higher levels of happiness. We want to set a goal that we are ultimately aiming for.&lt;/p&gt;\n\n&lt;p&gt;For FREEISM, we should set a final goal for the FREEISM platform, a final goal for the contribution rule, and a final goal for the project, and then calculate the contributions based on how much they have helped to bring us closer to or achieve that final goal.&lt;/p&gt;\n\n&lt;p&gt;Examples of final goals&lt;/p&gt;\n\n&lt;p&gt;Increase in productivity (working hours required to obtain goods and services) within the limits of the law&lt;/p&gt;\n\n&lt;p&gt;Increase in happiness within the limits of the law&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Contribution points&lt;/p&gt;\n\n&lt;p&gt;Refers to points required to obtain priority for limited items.&lt;/p&gt;\n\n&lt;p&gt;Contribution points are non-transferable.&lt;/p&gt;\n\n&lt;p&gt;However, loans are possible under some contribution rules.&lt;/p&gt;\n\n&lt;p&gt;Can I use SBT as contribution points?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;How to Calculate Contribution Points&lt;/p&gt;\n\n&lt;p&gt;Contribution points earned are calculated based on &amp;quot;the degree of contribution to the final goal&amp;quot; \u2716\ufe0e &amp;quot;market principle&amp;quot; \u2716\ufe0e &amp;quot;different weighting/rules for each contribution rule.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Until now, it was &amp;quot;market principles&amp;quot; \u2716\ufe0e &amp;quot;different weighting/rules for each country or region rule&amp;quot;, but we will add &amp;quot;degree of contribution to the final goal&amp;quot; to it.&lt;/p&gt;\n\n&lt;p&gt;I think the market principle is encapsulated in the degree of contribution to the final goal. However, if you still want to make further use of the market principle, you can give contribution points based on &amp;quot;market principle x degree of contribution to the final goal&amp;quot; or &amp;quot;market principle only&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;The degree of contribution to the final goal could be calculated using multiple regression analysis or other data analysis methods or methods to visualize DAO&amp;#39;s task-based contribution.&lt;/p&gt;\n\n&lt;p&gt;See below.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Quota&lt;/p&gt;\n\n&lt;p&gt;The quota is a mechanism to avoid monopolizing the service, and if the service can be provided to everyone, the quota is not used.&lt;/p&gt;\n\n&lt;p&gt;Each contribution rule has a different way of calculating the quota, and each person is given a quota weighted by contribution points (contribution points \u2716\ufe0f0.9 = amount of quota, etc.) or the square root of contribution points.&lt;/p&gt;\n\n&lt;p&gt;The amount of quota used will be the price.&lt;/p&gt;\n\n&lt;p&gt;There is a negative correlation: the lower the winning rate of a product or service, the more quota it occupies, and the closer the winning rate is to 100%, the less quota it occupies.&lt;/p&gt;\n\n&lt;p&gt;In FREESISM, the quota is always used while the limited item is in use, and the amount used always reflects the market value, not the amount used when it was acquired.&lt;/p&gt;\n\n&lt;p&gt;The structure of the quota differs for each contribution rule.&lt;/p&gt;\n\n&lt;p&gt;The period you occupy a quota should be the period you own that limited edition item.&lt;/p&gt;\n\n&lt;p&gt;If you give it away or throw it away, you can apply for it on the FREEMISM platform, or the service will automatically detect it and release the use of the quota.&lt;/p&gt;\n\n&lt;p&gt;To prevent &amp;quot;false applications&amp;quot; where people apply to give it away when they own it, make it necessary to give it away or throw it away at a predetermined location or app.&lt;/p&gt;\n\n&lt;p&gt;Create an incentive to have it detected through the app, since it should be detected from each app and if not through the app, it will occupy the frame all the time.&lt;/p&gt;\n\n&lt;p&gt;Make it impossible for people to report that they have given it up on their own, other than by having the app automatically detect it.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;FREEISM&lt;/p&gt;\n\n&lt;p&gt;In freeism, if other people refer to the products, services, source code, or other deliverables developed by each person, or to know-how and other things such as research findings, they will receive only a portion of the contribution points earned by the person they refer to, such as 0.5 times the contribution points earned by the person they refer to.&lt;/p&gt;\n\n&lt;p&gt;Thereby.&lt;/p&gt;\n\n&lt;p&gt;If someone only submits an idea and others implement it, the person who submitted the idea will also receive a portion of the contribution points earned by the person who implemented it.&lt;/p&gt;\n\n&lt;p&gt;If another company started a business and failed but was successful in running it by avoiding the strategies of the failed company, then allow the people who worked in the failed company to receive a portion of the contribution points earned by the successful company.&lt;/p&gt;\n\n&lt;p&gt;That way, where it was 0-1 to succeed or fail, maybe we could make it so that even if it fails, it is not 0-1 financially, but there is some benefit.&lt;/p&gt;\n\n&lt;p&gt;Since points are just points, unlike the currency, they don&amp;#39;t have to be distributed and can be offered to both.&lt;/p&gt;\n\n&lt;p&gt;But it&amp;#39;s hard to determine if that&amp;#39;s what I was referring to.&lt;/p&gt;\n\n&lt;p&gt;I will discuss this later.&lt;/p&gt;\n\n&lt;p&gt;We want a society where everything is open source.&lt;/p&gt;\n\n&lt;p&gt;I want to create a society where every no-how, patent, and other thing is open source, by weighting the contribution points that can be earned if others use the no-how, and by weighting the contribution points that can be earned just by making it open source, such as 1.2 times the contribution points that can be earned by making it open source.&lt;/p&gt;\n\n&lt;p&gt;Everyone gets it without having to distribute, and being open source could lead to more compensation for sharing without monopolizing rather than monopolizing and competing.&lt;/p&gt;\n\n&lt;p&gt;But if the relative position without distribution determines whether you get a limited product, is it the same as when profits were shared?&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s more mentally stable because you don&amp;#39;t have to fight for a piece of the pie.&lt;/p&gt;\n\n&lt;p&gt;The basic idea is to think in terms of rules of contribution, where the only rule is the degree of contribution to the liberal end goal, but when considering various rules of contribution, we can make a law that regulates each of them in a way that is characteristic to the sound of each rule of contribution.&lt;/p&gt;\n\n&lt;p&gt;Even if any action is the wrong action or not, we will stipulate that only actions that have a bad impact on the final goal contribution level are bad.&lt;/p&gt;\n\n&lt;p&gt;Even theft would not be a crime if it did not negatively impact anyone.&lt;/p&gt;\n\n&lt;p&gt;Somewhere the idea is like a woman who says it&amp;#39;s not cheating if she doesn&amp;#39;t get caught in a love story about whether or not she qualifies as cheating.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The position of each&lt;/p&gt;\n\n&lt;p&gt;In freeism, the system is divided into a freeism platform, contribution rules, projects, and other mechanisms.&lt;/p&gt;\n\n&lt;p&gt;The freeism platform is the role of the federal government, the contribution rule is the role of the state government, and the project is the role of the company.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Project&lt;/p&gt;\n\n&lt;p&gt;The role of the company.&lt;/p&gt;\n\n&lt;p&gt;The idea of freeism is to make everything open, so all the data of companies that are currently hidden will be shared and made available to everyone so that the contribution points earned will be weighted 1.1 times more than before.&lt;/p&gt;\n\n&lt;p&gt;Or, by being more open, make the service more technical and reliable, so that it is seen as contributing to the well-being and other end goals.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Price&lt;/p&gt;\n\n&lt;p&gt;The lower the winning rate (the percentage of people who apply who win), the more quota is occupied and the more the beneficiary pays.&lt;/p&gt;\n\n&lt;p&gt;The amount of quota used becomes the price, so if the winning rate increases, the price becomes &amp;quot;completely free&amp;quot; with zero quota use of zero yen.&lt;/p&gt;\n\n&lt;p&gt;In capitalism, even for products with high demand and high supply, the price is close to the cost, but the beneficiaries bear the burden.&lt;/p&gt;\n\n&lt;p&gt;In FREEMISM, the overall goods and services are cheaper because they are negatively correlated with the winning rate, regardless of cost.&lt;/p&gt;\n\n&lt;p&gt;Furthermore, since the added value cannot be added to the price, the price becomes cheaper by that amount, and the beneficiary burden of freeism is better than the beneficiary burden of capitalism.&lt;/p&gt;\n\n&lt;p&gt;The provider of goods and services receives nothing from the beneficiary for providing goods and services, and the beneficiary pays nothing to the provider for acquiring goods and services, which only increases the amount that occupies the quota managed by the freeism platform.&lt;/p&gt;\n\n&lt;p&gt;The provider can offer goods and services to those who cannot afford to pay for them, and if they do, the business will be compensated.&lt;/p&gt;\n\n&lt;p&gt;Life of FREEISM&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s imagine and write about what society would be like in a society where FREESISM is realized.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Download or use any of the web apps, native apps, VR or AR apps of the freeism app (which also serves as the freeism platform) that manages all the functions of freeism, from a web app, native app, VR, or AR app, or a browser.&lt;/p&gt;\n\n&lt;p&gt;In the freeism app, choose the contribution rule to which you want to belong.&lt;/p&gt;\n\n&lt;p&gt;Enter various information about yourself and link it to the contribution rule you have chosen, and generate an account with the data for that contribution rule.&lt;/p&gt;\n\n&lt;p&gt;You can put the date of the contribution rule you belong to as a property in your wallet for Web3, or in your Google account for Web2, etc.&lt;/p&gt;\n\n&lt;p&gt;With the account containing that data, data is acquired from various applications and the contribution rules are calculated using that data.&lt;/p&gt;\n\n&lt;p&gt;Furthermore, according to each contribution rule, you can display 00 content on Twitter, but not 00. If the content is prohibited by each rule of each contribution level, such as &amp;quot;00 content is allowed to be displayed on Twitter, but 00 is prohibited,&amp;quot; each rule of each contribution level will be detected from the account and automatically hidden.&lt;/p&gt;\n\n&lt;p&gt;When you want to get a product or service on each platform of freeism services or existing services (Amazon, Spotify, etc.), you can get the person&amp;#39;s contribution points from the API that can get the contribution points of each person managed by that freeism platform, and Then, we can set up an input field in the platform, such as Amazon, where people can input how many quotas they want to offer, and those who offer the highest amount will be given priority to receive?&lt;/p&gt;\n\n&lt;p&gt;Is it faster to create a new one?&lt;/p&gt;\n\n&lt;p&gt;Those who offer limited items in the above process will receive contribution points for the contribution rules to which they belong.&lt;/p&gt;\n\n&lt;p&gt;There is no such thing as an exchange rate between multiple contribution points, so the more contribution rules that contribute to the ultimate goal of the freeism platform, the larger the percentage to be offered (tentative idea).&lt;/p&gt;\n\n&lt;p&gt;Compatibility between freeism platforms is discussed below.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y539db", "is_robot_indexable": true, "report_reasons": null, "author": "Traditional-Self1986", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y539db/freeism\u30fccapitalism_upwardly_compatible\u30fc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y539db/freeism\u30fccapitalism_upwardly_compatible\u30fc/", "subreddit_subscribers": 813798, "created_utc": 1665880895.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been lurking on this sub for a while now and all too often I see posts from people claiming they feel inadequate and then they go on to describe their stupid impressive background and experience. That's great and all but I'd like to move the spotlight to the rest of us for just a minute. Cheers to my fellow mediocre data scientists who don't work at FAANG companies, aren't pursing a PhD, don't publish papers, haven't won Kaggle competitions, and don't spend every waking hour improving their portfolio. Even though we're nothing special, we still deserve some appreciation every once in a while.\n\n/rant I'll hand it back over to the smart people now", "author_fullname": "t2_rv2brc3u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Shout Out to All the Mediocre Data Scientists Out There", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4zh44", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.36, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665870141.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been lurking on this sub for a while now and all too often I see posts from people claiming they feel inadequate and then they go on to describe their stupid impressive background and experience. That&amp;#39;s great and all but I&amp;#39;d like to move the spotlight to the rest of us for just a minute. Cheers to my fellow mediocre data scientists who don&amp;#39;t work at FAANG companies, aren&amp;#39;t pursing a PhD, don&amp;#39;t publish papers, haven&amp;#39;t won Kaggle competitions, and don&amp;#39;t spend every waking hour improving their portfolio. Even though we&amp;#39;re nothing special, we still deserve some appreciation every once in a while.&lt;/p&gt;\n\n&lt;p&gt;/rant I&amp;#39;ll hand it back over to the smart people now&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4zh44", "is_robot_indexable": true, "report_reasons": null, "author": "Dull_Adagio4038", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4zh44/shout_out_to_all_the_mediocre_data_scientists_out/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4zh44/shout_out_to_all_the_mediocre_data_scientists_out/", "subreddit_subscribers": 813798, "created_utc": 1665870141.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}