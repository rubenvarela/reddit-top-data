{"kind": "Listing", "data": {"after": null, "dist": 22, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m interested in learning more about Bayesian Models, and am trying to decide if it would be beneficial to implement them at my work (I work in retail). In what situations do you all use Bayesian models over frequentists models?", "author_fullname": "t2_fjll57b4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "In what situations would a Bayesian model work better than frequentist model?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4obe5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 165, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 165, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665841364.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m interested in learning more about Bayesian Models, and am trying to decide if it would be beneficial to implement them at my work (I work in retail). In what situations do you all use Bayesian models over frequentists models?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4obe5", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Resort-4196", "discussion_type": null, "num_comments": 72, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4obe5/in_what_situations_would_a_bayesian_model_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4obe5/in_what_situations_would_a_bayesian_model_work/", "subreddit_subscribers": 813764, "created_utc": 1665841364.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_b7z7a6t4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can we interprate this box plot in regards to outliers? Is it every value above the upper fence? In that case, about 1/6 of the total values are outliers.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 63, "top_awarded_type": null, "hide_score": false, "name": "t3_y4s8cy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "ups": 76, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 76, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/UWHyL0uAC086_fianjiO7-5pLIEDNayzi2NR-f-4BMQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1665851355.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/huwywux7xzt91.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/huwywux7xzt91.png?auto=webp&amp;s=cc6f6317e6afdb86edfa0a0697abc5389db52959", "width": 1235, "height": 558}, "resolutions": [{"url": "https://preview.redd.it/huwywux7xzt91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=354cbccb19304de12debc55cc8d33a43903f0154", "width": 108, "height": 48}, {"url": "https://preview.redd.it/huwywux7xzt91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9d755cc7e5fb2ad51cfd84900f23a0f24d9946fb", "width": 216, "height": 97}, {"url": "https://preview.redd.it/huwywux7xzt91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c2c5d8040432cfe013af7cb7ac4129eeb1323ea4", "width": 320, "height": 144}, {"url": "https://preview.redd.it/huwywux7xzt91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b4aecf1ee052431c08f937a5bf6970d4df7345ab", "width": 640, "height": 289}, {"url": "https://preview.redd.it/huwywux7xzt91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=4f7b19fb35ff96c01378537c995f150394dfee9b", "width": 960, "height": 433}, {"url": "https://preview.redd.it/huwywux7xzt91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=aed86c9be16cb475c3ef613a845f2ca16d8440b6", "width": 1080, "height": 487}], "variants": {}, "id": "6kbHq0P-iIt0cbMHwt0Gx-R_gKWvfSEj9XwDcGdZ6AA"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4s8cy", "is_robot_indexable": true, "report_reasons": null, "author": "Outside-Werewolf-983", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4s8cy/how_can_we_interprate_this_box_plot_in_regards_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/huwywux7xzt91.png", "subreddit_subscribers": 813764, "created_utc": 1665851355.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,\n\nLong history short: the analytics director of my non-tech company, who is a DS illiterate, has hired a Data Science Lead that has considerably fewer qualifications, and just 2 years more work experience than me (senior DS). In our first interaction, he bragged about how he created a segmentation model using a random forest with an accuracy of 94% in his previous role ...\n\nI was previously leading our team of 3 DS and 2 DE. It is quite blurred how we will collaborate and divide the roles, management responsibilities, and workload.\n\nIt is still early days, but I wanted to get insights and advice from the community, from people who have been in a similar situation. I've done a few google searches on this topic and haven't found anything. Maybe everyone out there has competent and knowledgeable data science leads/managers? It could be the case, as I guess you can't fake being a data science lead and get away with it, can you?\n\n* How do senior data scientists learn and are mentored by lead data scientists in your organizations? Is there a way to check informally if this guy has knowledge/skills that I can really pick up and learn from him?\n* Should I transfer to him all my management responsibilities and the projects I own?\n* Any advice about how to cope with this situation, especially during his first 100 days would be gold. I guess working patterns and assumptions that solidify at the beginning will stay there. Thank you!", "author_fullname": "t2_5phwwjob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Have you ever been under a Data Science Lead/Manager who knew less than you? How did you cope?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4pxoe", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 41, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665845545.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;Long history short: the analytics director of my non-tech company, who is a DS illiterate, has hired a Data Science Lead that has considerably fewer qualifications, and just 2 years more work experience than me (senior DS). In our first interaction, he bragged about how he created a segmentation model using a random forest with an accuracy of 94% in his previous role ...&lt;/p&gt;\n\n&lt;p&gt;I was previously leading our team of 3 DS and 2 DE. It is quite blurred how we will collaborate and divide the roles, management responsibilities, and workload.&lt;/p&gt;\n\n&lt;p&gt;It is still early days, but I wanted to get insights and advice from the community, from people who have been in a similar situation. I&amp;#39;ve done a few google searches on this topic and haven&amp;#39;t found anything. Maybe everyone out there has competent and knowledgeable data science leads/managers? It could be the case, as I guess you can&amp;#39;t fake being a data science lead and get away with it, can you?&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;How do senior data scientists learn and are mentored by lead data scientists in your organizations? Is there a way to check informally if this guy has knowledge/skills that I can really pick up and learn from him?&lt;/li&gt;\n&lt;li&gt;Should I transfer to him all my management responsibilities and the projects I own?&lt;/li&gt;\n&lt;li&gt;Any advice about how to cope with this situation, especially during his first 100 days would be gold. I guess working patterns and assumptions that solidify at the beginning will stay there. Thank you!&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4pxoe", "is_robot_indexable": true, "report_reasons": null, "author": "werthobakew", "discussion_type": null, "num_comments": 54, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4pxoe/have_you_ever_been_under_a_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4pxoe/have_you_ever_been_under_a_data_science/", "subreddit_subscribers": 813764, "created_utc": 1665845545.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey all,\n\nAs a meager software engineer mortal, I've always been curious about how concepts/algorithms work in machine learning. I am starting a series of posts, documenting my understanding of these concepts.\n\nHere's my first attempt; it's on Gini impurity, a core concept fundamental in how decision trees are built.\n\n[https://gradiently.io/gini-impurity/](https://gradiently.io/gini-impurity/)", "author_fullname": "t2_6dnrwg8t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "An Explanation of Gini Impurity", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y50l0u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665873125.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;As a meager software engineer mortal, I&amp;#39;ve always been curious about how concepts/algorithms work in machine learning. I am starting a series of posts, documenting my understanding of these concepts.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s my first attempt; it&amp;#39;s on Gini impurity, a core concept fundamental in how decision trees are built.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://gradiently.io/gini-impurity/\"&gt;https://gradiently.io/gini-impurity/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y50l0u", "is_robot_indexable": true, "report_reasons": null, "author": "Ill-Tomato-8400", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y50l0u/an_explanation_of_gini_impurity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y50l0u/an_explanation_of_gini_impurity/", "subreddit_subscribers": 813764, "created_utc": 1665873125.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My goal is to have a place to ask question regarding Data Analyst stuff (like eigendecomposition, matrix reconstruction, eigenvector centrality) and next month regarding Data Science stuff.\n\nI've tried to ask question regarding eigendecomposition in StackOverflow and datascience.StackExchange.com, but to no avail. No one answered the question. I guess, Data Analyst and Data Scientist rarely use these forum.", "author_fullname": "t2_5yye765o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where do Data Analyst and Data Science ask question most of the time (except StackOverflow and StackExchange)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4o199", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665840608.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My goal is to have a place to ask question regarding Data Analyst stuff (like eigendecomposition, matrix reconstruction, eigenvector centrality) and next month regarding Data Science stuff.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried to ask question regarding eigendecomposition in StackOverflow and datascience.StackExchange.com, but to no avail. No one answered the question. I guess, Data Analyst and Data Scientist rarely use these forum.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4o199", "is_robot_indexable": true, "report_reasons": null, "author": "kidfromtheast", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4o199/where_do_data_analyst_and_data_science_ask/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4o199/where_do_data_analyst_and_data_science_ask/", "subreddit_subscribers": 813764, "created_utc": 1665840608.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Mini intro: I'm currently into my 3rd year of bachelor's in mathematics with a minor in data sciences. I decided on this path 2 years ago when I decided to venture out of my current field of engineering. So I have no experience in the tech field yet. \n\nI'm studying part time and I'm not sure if I have the case of imposter syndrome or I really do feel inadequate. In classes, I think I do okay, as I help others with their codes. Please don't take me for boasting or flexing, I had a full time software engineer seeking help from me and praising me as well, and this further adds to my confusion because I can't think that I'm actually bad. \n\nWhen I'm browsing LinkedIn, I see people at my level with very good portfolios, like reducing man-hours by 70% by implementing this-that algorithm etc in their internships. I'm applying for an apprenticeship that has a second assessment coming up and I just feel stressed even though I got past their first assessment. \n\nHas anyone experienced this and how do I go about solving this?", "author_fullname": "t2_vezlk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I know where I stand?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_y4h2re", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 0, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": "", "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665817320.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Mini intro: I&amp;#39;m currently into my 3rd year of bachelor&amp;#39;s in mathematics with a minor in data sciences. I decided on this path 2 years ago when I decided to venture out of my current field of engineering. So I have no experience in the tech field yet. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m studying part time and I&amp;#39;m not sure if I have the case of imposter syndrome or I really do feel inadequate. In classes, I think I do okay, as I help others with their codes. Please don&amp;#39;t take me for boasting or flexing, I had a full time software engineer seeking help from me and praising me as well, and this further adds to my confusion because I can&amp;#39;t think that I&amp;#39;m actually bad. &lt;/p&gt;\n\n&lt;p&gt;When I&amp;#39;m browsing LinkedIn, I see people at my level with very good portfolios, like reducing man-hours by 70% by implementing this-that algorithm etc in their internships. I&amp;#39;m applying for an apprenticeship that has a second assessment coming up and I just feel stressed even though I got past their first assessment. &lt;/p&gt;\n\n&lt;p&gt;Has anyone experienced this and how do I go about solving this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "call_to_action": "", "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4h2re", "is_robot_indexable": true, "report_reasons": null, "author": "Wheynelau", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4h2re/how_do_i_know_where_i_stand/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4h2re/how_do_i_know_where_i_stand/", "subreddit_subscribers": 813764, "created_utc": 1665817320.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I know there are a lot of posts about resources, but I don't recall seeing this specifically. \n\nI'm looking for for resources for Bayes statistics.   Everything I've found is either simple examples meant to introduce a concept... or very theoretical without many examples. \n\nI need something in the middle, examples that are complex and varied enough to get into details.  Maybe even something that progresses in difficult.  Currently going over MCMC, but I actually thing it's more basic Bayes stuff that I'm getting hung up on. \n\nI might be a bit weird... i'm good at math, but not strong.   What i mean is: I went up through Calc II in college and didn't have issues with it, but between a lack of application or practice, I've been struggling with the stats/math side of DS classes. \n\nIn honestly considering dropping this class, just so I can study and retake it next term.  Any assistance is appreciated!", "author_fullname": "t2_7t6en9d2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bayes examples and study help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_y55z3b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665889307.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know there are a lot of posts about resources, but I don&amp;#39;t recall seeing this specifically. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for for resources for Bayes statistics.   Everything I&amp;#39;ve found is either simple examples meant to introduce a concept... or very theoretical without many examples. &lt;/p&gt;\n\n&lt;p&gt;I need something in the middle, examples that are complex and varied enough to get into details.  Maybe even something that progresses in difficult.  Currently going over MCMC, but I actually thing it&amp;#39;s more basic Bayes stuff that I&amp;#39;m getting hung up on. &lt;/p&gt;\n\n&lt;p&gt;I might be a bit weird... i&amp;#39;m good at math, but not strong.   What i mean is: I went up through Calc II in college and didn&amp;#39;t have issues with it, but between a lack of application or practice, I&amp;#39;ve been struggling with the stats/math side of DS classes. &lt;/p&gt;\n\n&lt;p&gt;In honestly considering dropping this class, just so I can study and retake it next term.  Any assistance is appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y55z3b", "is_robot_indexable": true, "report_reasons": null, "author": "Cryptic-Squid", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y55z3b/bayes_examples_and_study_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y55z3b/bayes_examples_and_study_help/", "subreddit_subscribers": 813764, "created_utc": 1665889307.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello Everyone,\n\nUp until now I have extensively worked on computer vision problems for the past 3-4 years but did not get a lot of opportunity to work on NLP problems. Therefore, I want to get an overview of the current research status and its applications in the NLP domain. Can anyone suggest some good papers to read in the NLP domain to get a brief of the current research status there?\n\nThanks a lot!", "author_fullname": "t2_59mwk2ku", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NLP research status", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4i1jz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665820973.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone,&lt;/p&gt;\n\n&lt;p&gt;Up until now I have extensively worked on computer vision problems for the past 3-4 years but did not get a lot of opportunity to work on NLP problems. Therefore, I want to get an overview of the current research status and its applications in the NLP domain. Can anyone suggest some good papers to read in the NLP domain to get a brief of the current research status there?&lt;/p&gt;\n\n&lt;p&gt;Thanks a lot!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4i1jz", "is_robot_indexable": true, "report_reasons": null, "author": "Eve26th", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4i1jz/nlp_research_status/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4i1jz/nlp_research_status/", "subreddit_subscribers": 813764, "created_utc": 1665820973.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,  I am wondering about about some recent trends I have been experienced at work with younger or less experienced data scientists.\n\nPeople are fitting these large multivariate, nonlinear models that come directly from python libraries, for example PyOD outlier detection.   They just compare results from all the built in ML algos.   They don't think about any simple methods what so ever for detecting outliers.   However, the end user always drills down to univariate to see if the features are significant anyway.     So I don't see the purpose in testing the advanced algos without a baseline.\n\nSo instead of starting with a basic statistical outlier method, or univariate or linear method,like PCA, all of this is skipped and considered irrelevant or \"dinosaur\".  \n\nMy argument is that if you don't have a baseline simple method, you will never understand the benefit the ML algo brings .    Basically if they cant can't find a benefit over univariate ,  they shouldn't promote the advanced methods yet.\n\nWhat are your thoughts on this?\n\nHow do I convince these people to slow down and take baby steps to see the benefits without insulting them?  \n\nHow do I stop ignorant management from listening to these trendy individuals? Its quite frustrating when a simple method beats a complex desired method, but someone won't listen because they want to look smart.", "author_fullname": "t2_3qgvuco6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Simpler Methods over Advanced Algos", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4npv5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665839731.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,  I am wondering about about some recent trends I have been experienced at work with younger or less experienced data scientists.&lt;/p&gt;\n\n&lt;p&gt;People are fitting these large multivariate, nonlinear models that come directly from python libraries, for example PyOD outlier detection.   They just compare results from all the built in ML algos.   They don&amp;#39;t think about any simple methods what so ever for detecting outliers.   However, the end user always drills down to univariate to see if the features are significant anyway.     So I don&amp;#39;t see the purpose in testing the advanced algos without a baseline.&lt;/p&gt;\n\n&lt;p&gt;So instead of starting with a basic statistical outlier method, or univariate or linear method,like PCA, all of this is skipped and considered irrelevant or &amp;quot;dinosaur&amp;quot;.  &lt;/p&gt;\n\n&lt;p&gt;My argument is that if you don&amp;#39;t have a baseline simple method, you will never understand the benefit the ML algo brings .    Basically if they cant can&amp;#39;t find a benefit over univariate ,  they shouldn&amp;#39;t promote the advanced methods yet.&lt;/p&gt;\n\n&lt;p&gt;What are your thoughts on this?&lt;/p&gt;\n\n&lt;p&gt;How do I convince these people to slow down and take baby steps to see the benefits without insulting them?  &lt;/p&gt;\n\n&lt;p&gt;How do I stop ignorant management from listening to these trendy individuals? Its quite frustrating when a simple method beats a complex desired method, but someone won&amp;#39;t listen because they want to look smart.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4npv5", "is_robot_indexable": true, "report_reasons": null, "author": "Atxaquariguy", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4npv5/simpler_methods_over_advanced_algos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4npv5/simpler_methods_over_advanced_algos/", "subreddit_subscribers": 813764, "created_utc": 1665839731.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey Guys &amp; Gals!!!\n\nSo, I'm currently running some regressions and similar, in order to create a trading algorithm. I've collected and cleaned daily price data for each currency pair, and I have organised relevant variables. I'm looking to build an algorithm in order to best determine future price changes, based on a few variable. Some are dummy, some are percentage values. \n\nI've ran simple OLS regressions to see I have a strong and statistically significant (at 0.001% level) between my dummy and price data, although I'm struggling to work out how to incorporate more variables into this. I also don't think OLS is the best way to do this, should I be using MA(?) Or EMA(?)? I've done an economics degree with econometrics moudles so I know a bit about what I'm doing, although not enough to do what I want to.  (clearly \ud83d\ude02!)\n\nAny advice would be massively appreciated! I'm currency learning to use python, would NumPy or similar be satisfactory? \n\nThanks again!", "author_fullname": "t2_cj4nfibx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What tools should I run to determine the best predictive power?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4mshz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665837182.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Guys &amp;amp; Gals!!!&lt;/p&gt;\n\n&lt;p&gt;So, I&amp;#39;m currently running some regressions and similar, in order to create a trading algorithm. I&amp;#39;ve collected and cleaned daily price data for each currency pair, and I have organised relevant variables. I&amp;#39;m looking to build an algorithm in order to best determine future price changes, based on a few variable. Some are dummy, some are percentage values. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve ran simple OLS regressions to see I have a strong and statistically significant (at 0.001% level) between my dummy and price data, although I&amp;#39;m struggling to work out how to incorporate more variables into this. I also don&amp;#39;t think OLS is the best way to do this, should I be using MA(?) Or EMA(?)? I&amp;#39;ve done an economics degree with econometrics moudles so I know a bit about what I&amp;#39;m doing, although not enough to do what I want to.  (clearly \ud83d\ude02!)&lt;/p&gt;\n\n&lt;p&gt;Any advice would be massively appreciated! I&amp;#39;m currency learning to use python, would NumPy or similar be satisfactory? &lt;/p&gt;\n\n&lt;p&gt;Thanks again!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4mshz", "is_robot_indexable": true, "report_reasons": null, "author": "ChoccyRoccy", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4mshz/what_tools_should_i_run_to_determine_the_best/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4mshz/what_tools_should_i_run_to_determine_the_best/", "subreddit_subscribers": 813764, "created_utc": 1665837182.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I understand that you need to do Power analysis in order to figure out what sample size you need for your AB test, but something that I have difficulty coming up with is \u201cwhat MDE should we use?\u201d  Researching online hasn\u2019t been much help because all I see are examples of where they just give an MDE to use but don\u2019t explain the process of getting there. \n\nFor my company, a lot of our tests have very low operational costs, so in almost all cases any positive performance is worth rolling out. Basically, even if we saw only a 0.05% lift, if it was statistically significant, we\u2019d probably implement the change. This has led me down a path where I basically just check to see what MDE we can reasonably detect given the number of users coming into the platform INSTEAD of determining what MDE is actually valuable. I feel like this is the wrong approach, but I\u2019m unsure what else to do given that our \u201cgoal\u201d MDE is basically anything above 0. This especially makes it difficult for me to determine when I should stop the tests as well, other than picking a somewhat arbitrary end point of 3-4 weeks and then seeing if there is any directional value from the data. \n\nWhat would you do in this situation? How do you determine the MDE for your AB tests? \n\nThanks!", "author_fullname": "t2_3dbxxd6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to determine what value is good for minimum detectable effect (MDE) for AB testing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4t1y1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665853411.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I understand that you need to do Power analysis in order to figure out what sample size you need for your AB test, but something that I have difficulty coming up with is \u201cwhat MDE should we use?\u201d  Researching online hasn\u2019t been much help because all I see are examples of where they just give an MDE to use but don\u2019t explain the process of getting there. &lt;/p&gt;\n\n&lt;p&gt;For my company, a lot of our tests have very low operational costs, so in almost all cases any positive performance is worth rolling out. Basically, even if we saw only a 0.05% lift, if it was statistically significant, we\u2019d probably implement the change. This has led me down a path where I basically just check to see what MDE we can reasonably detect given the number of users coming into the platform INSTEAD of determining what MDE is actually valuable. I feel like this is the wrong approach, but I\u2019m unsure what else to do given that our \u201cgoal\u201d MDE is basically anything above 0. This especially makes it difficult for me to determine when I should stop the tests as well, other than picking a somewhat arbitrary end point of 3-4 weeks and then seeing if there is any directional value from the data. &lt;/p&gt;\n\n&lt;p&gt;What would you do in this situation? How do you determine the MDE for your AB tests? &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4t1y1", "is_robot_indexable": true, "report_reasons": null, "author": "matt22022", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4t1y1/how_to_determine_what_value_is_good_for_minimum/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4t1y1/how_to_determine_what_value_is_good_for_minimum/", "subreddit_subscribers": 813764, "created_utc": 1665853411.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello data fellows,\n\nDo you think that it generally makes sense to develop and invest a lot of time in improving technical skills in DL, as a generalist data scientist? Meaning, as someone that is not in research scientist/ML engineer position and/or doesn\u2019t work in big-tech?\n\nI am not talking about being able to build a simple sequential model with Keras and feeding np arrays, but rather going much deeper with Functional/Subclassing APIs and then use tf.Datasets and generators to feed Tensorflow data pipelines.\n\nThe reason why I am asking is that I love this stuff, but I don\u2019t know how many firms outside of big tech use these technologies out there. If in the end all they expect/understand/value is knowing SQL and some basic Python, is it worth going down the more technical path? Will it give me an edge in the long run?\n\nThanks for your feedback!\n\nA nice weekend everyone", "author_fullname": "t2_538mr0fs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Focus on Deep Learning: does it make generally sense?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4hbw4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665818276.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello data fellows,&lt;/p&gt;\n\n&lt;p&gt;Do you think that it generally makes sense to develop and invest a lot of time in improving technical skills in DL, as a generalist data scientist? Meaning, as someone that is not in research scientist/ML engineer position and/or doesn\u2019t work in big-tech?&lt;/p&gt;\n\n&lt;p&gt;I am not talking about being able to build a simple sequential model with Keras and feeding np arrays, but rather going much deeper with Functional/Subclassing APIs and then use tf.Datasets and generators to feed Tensorflow data pipelines.&lt;/p&gt;\n\n&lt;p&gt;The reason why I am asking is that I love this stuff, but I don\u2019t know how many firms outside of big tech use these technologies out there. If in the end all they expect/understand/value is knowing SQL and some basic Python, is it worth going down the more technical path? Will it give me an edge in the long run?&lt;/p&gt;\n\n&lt;p&gt;Thanks for your feedback!&lt;/p&gt;\n\n&lt;p&gt;A nice weekend everyone&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4hbw4", "is_robot_indexable": true, "report_reasons": null, "author": "funkyhog", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4hbw4/focus_on_deep_learning_does_it_make_generally/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4hbw4/focus_on_deep_learning_does_it_make_generally/", "subreddit_subscribers": 813764, "created_utc": 1665818276.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "TL;DR: Has industry demand on experts in Bayesian-ML for Control Engineering?\n\n&amp;#x200B;\n\nHey,\n\nI'm a CS student right before my master thesis and I have to take a decision between two career topics:\n\n1. Becoming an NLP expert.\n2. Becoming an expert on Bayesian-ML for Control Engineering.\n\nThe path I want to take is Master-Thesis --&gt; PhD --&gt; Industry. There are many pros and cons for me to take any of these two. I'm here because I doubt the demand of the industry on additional experts in *Bayesian-ML for Control Engineering*. The doubts originate from the following reason.\n\nPeople are working on Bayesian methods since decades and engineering also does respectively. So it might be, that experts from these decades are already spread through the industry.\n\nNLP in comparison is pretty new and on high demand without a doubt.\n\nDoes someone has insights for me on the demand of the industry on Bayesian-ML in Control Engineering? More specifically I could also ask, if Kalman Filters and Gaussian Processes are of interest?\n\n&amp;#x200B;\n\nI'm thanking every reader for his/her/&lt;other pronouns&gt; attention and even more for answers :)\n\nLinks to informative threads are also appreciated (I only found average useful ones)!", "author_fullname": "t2_kmck7zwg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Demand on Bayesian-ML in Control Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4q6rh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665846168.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TL;DR: Has industry demand on experts in Bayesian-ML for Control Engineering?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Hey,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a CS student right before my master thesis and I have to take a decision between two career topics:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Becoming an NLP expert.&lt;/li&gt;\n&lt;li&gt;Becoming an expert on Bayesian-ML for Control Engineering.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The path I want to take is Master-Thesis --&amp;gt; PhD --&amp;gt; Industry. There are many pros and cons for me to take any of these two. I&amp;#39;m here because I doubt the demand of the industry on additional experts in &lt;em&gt;Bayesian-ML for Control Engineering&lt;/em&gt;. The doubts originate from the following reason.&lt;/p&gt;\n\n&lt;p&gt;People are working on Bayesian methods since decades and engineering also does respectively. So it might be, that experts from these decades are already spread through the industry.&lt;/p&gt;\n\n&lt;p&gt;NLP in comparison is pretty new and on high demand without a doubt.&lt;/p&gt;\n\n&lt;p&gt;Does someone has insights for me on the demand of the industry on Bayesian-ML in Control Engineering? More specifically I could also ask, if Kalman Filters and Gaussian Processes are of interest?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thanking every reader for his/her/&amp;lt;other pronouns&amp;gt; attention and even more for answers :)&lt;/p&gt;\n\n&lt;p&gt;Links to informative threads are also appreciated (I only found average useful ones)!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4q6rh", "is_robot_indexable": true, "report_reasons": null, "author": "Michael_Skowronek", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4q6rh/demand_on_bayesianml_in_control_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4q6rh/demand_on_bayesianml_in_control_engineering/", "subreddit_subscribers": 813764, "created_utc": 1665846168.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "A chart is displayed with precision and recall scores. The table underneath calculated the scores so they were double format 1, 0 .67 etc and it grouped by certain fields such as week.\n\nThe chart then converted these doubles to % and displayed by month using SUM(precision)\n\nI was requested to also include additional field, hour (24 hr clock) as they wanted to be able to filter on the charts by the hour.\n\nI did this, and obviously when we added this to the GROUP BY the sum(precision) values increased in number, and the chart range now goes up to 900%.\n\nWhat can I do to make this range display accurate %s between 0 - 100?\n\nor is this a bogus calculation? THanks!", "author_fullname": "t2_eejku9w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "calculating with group by", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4nmur", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665839501.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A chart is displayed with precision and recall scores. The table underneath calculated the scores so they were double format 1, 0 .67 etc and it grouped by certain fields such as week.&lt;/p&gt;\n\n&lt;p&gt;The chart then converted these doubles to % and displayed by month using SUM(precision)&lt;/p&gt;\n\n&lt;p&gt;I was requested to also include additional field, hour (24 hr clock) as they wanted to be able to filter on the charts by the hour.&lt;/p&gt;\n\n&lt;p&gt;I did this, and obviously when we added this to the GROUP BY the sum(precision) values increased in number, and the chart range now goes up to 900%.&lt;/p&gt;\n\n&lt;p&gt;What can I do to make this range display accurate %s between 0 - 100?&lt;/p&gt;\n\n&lt;p&gt;or is this a bogus calculation? THanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4nmur", "is_robot_indexable": true, "report_reasons": null, "author": "panadol64", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4nmur/calculating_with_group_by/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4nmur/calculating_with_group_by/", "subreddit_subscribers": 813764, "created_utc": 1665839501.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi guys,\n\nJunior analyst here and I was hoping I can pick your brains on a challenge. I have an ecommerce dataset for customer purchases and the challenge is to measure the share of customers who purchased from multiple categories in a month and continue to purchase in multiple categories in succeeding months.\n\nHas anyone done a similar project before through Python? It would be great to hear your thoughts on how I might approach this in the code.\n\nThank you!\n\n[sample ecommerce dataset](https://preview.redd.it/7xzu56eauyt91.png?width=1452&amp;format=png&amp;auto=webp&amp;s=8e8469cfd113fd52c0d16be4a5db47d6412c264f)", "author_fullname": "t2_87cwramh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Measuring customers who purchased from multiple categories", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 137, "top_awarded_type": null, "hide_score": false, "media_metadata": {"7xzu56eauyt91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 105, "x": 108, "u": "https://preview.redd.it/7xzu56eauyt91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1bbf710f77e92a4d1d1ac5d440a08ea23416246b"}, {"y": 211, "x": 216, "u": "https://preview.redd.it/7xzu56eauyt91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0633909f195b1ac7a26ece125fb3ff4aacbc5748"}, {"y": 313, "x": 320, "u": "https://preview.redd.it/7xzu56eauyt91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=1f0409b5e4736caadd2427b86f5d313d45b305c0"}, {"y": 627, "x": 640, "u": "https://preview.redd.it/7xzu56eauyt91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=fc06bf96cb5ed05ccf630904e60ba8a0292074d6"}, {"y": 941, "x": 960, "u": "https://preview.redd.it/7xzu56eauyt91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=fef8ce00b11eb07251d0861ad5ea36cbb6fe0018"}, {"y": 1059, "x": 1080, "u": "https://preview.redd.it/7xzu56eauyt91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f11702db91c6ea0717063d23c7ba8e2baa32939a"}], "s": {"y": 1424, "x": 1452, "u": "https://preview.redd.it/7xzu56eauyt91.png?width=1452&amp;format=png&amp;auto=webp&amp;s=8e8469cfd113fd52c0d16be4a5db47d6412c264f"}, "id": "7xzu56eauyt91"}}, "name": "t3_y4n33g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/8nl7snpB-ohbPTVE_qFBJA8OFTPVjP5t0Vksq4QvjBw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665838019.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;Junior analyst here and I was hoping I can pick your brains on a challenge. I have an ecommerce dataset for customer purchases and the challenge is to measure the share of customers who purchased from multiple categories in a month and continue to purchase in multiple categories in succeeding months.&lt;/p&gt;\n\n&lt;p&gt;Has anyone done a similar project before through Python? It would be great to hear your thoughts on how I might approach this in the code.&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/7xzu56eauyt91.png?width=1452&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8e8469cfd113fd52c0d16be4a5db47d6412c264f\"&gt;sample ecommerce dataset&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4n33g", "is_robot_indexable": true, "report_reasons": null, "author": "Shirt_Reasonable", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4n33g/measuring_customers_who_purchased_from_multiple/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4n33g/measuring_customers_who_purchased_from_multiple/", "subreddit_subscribers": 813764, "created_utc": 1665838019.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "A few months ago I started a data science focused blog. I\u2019ve posted a few tutorials but I\u2019ve mostly posted data stories about things that interest me. I try to make an interactive element that is usually a small web app that lets you interact with the data. I\u2019ve had some moderate success with about 10 thousand unique visitors in September. \n\nMy question is, do y\u2019all care about these data stories? I would prefer to make things people want, and I\u2019m not sure I\u2019m doing that. A few ideas I had that y\u2019all might like:\n\n- Live streams of doing data science projects. Scraping, cleaning, and modeling in one chunk of time. \n- Technical posts. Do a project and walk  through the code. Basically blog post with code. Not a tutorial exactly though. \n- Mini data products with all code attached to remake/remix yourself. \n\nI\u2019m open to ideas. So, what kind of content would you like more of?\n\nThe blog is [datafantic.com](https://datafantic.com). My goal here is not to get clicks but to understand y\u2019all better. My target audience is other data scientists, and I would like to create content y\u2019all like.", "author_fullname": "t2_a0kcgwo4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you want in a data science publication (blog)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4jlh7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1665826689.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A few months ago I started a data science focused blog. I\u2019ve posted a few tutorials but I\u2019ve mostly posted data stories about things that interest me. I try to make an interactive element that is usually a small web app that lets you interact with the data. I\u2019ve had some moderate success with about 10 thousand unique visitors in September. &lt;/p&gt;\n\n&lt;p&gt;My question is, do y\u2019all care about these data stories? I would prefer to make things people want, and I\u2019m not sure I\u2019m doing that. A few ideas I had that y\u2019all might like:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Live streams of doing data science projects. Scraping, cleaning, and modeling in one chunk of time. &lt;/li&gt;\n&lt;li&gt;Technical posts. Do a project and walk  through the code. Basically blog post with code. Not a tutorial exactly though. &lt;/li&gt;\n&lt;li&gt;Mini data products with all code attached to remake/remix yourself. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I\u2019m open to ideas. So, what kind of content would you like more of?&lt;/p&gt;\n\n&lt;p&gt;The blog is &lt;a href=\"https://datafantic.com\"&gt;datafantic.com&lt;/a&gt;. My goal here is not to get clicks but to understand y\u2019all better. My target audience is other data scientists, and I would like to create content y\u2019all like.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jK_Rae0h1ebDEMtfUdLFkxTifROb_wRsOUsOXOyoYdQ.jpg?auto=webp&amp;s=24573f8cb91746901ee7305d63ee2cd574f44ed6", "width": 950, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/jK_Rae0h1ebDEMtfUdLFkxTifROb_wRsOUsOXOyoYdQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e632d1dfa8e6ae10a550016f4832af44f791cd64", "width": 108, "height": 68}, {"url": "https://external-preview.redd.it/jK_Rae0h1ebDEMtfUdLFkxTifROb_wRsOUsOXOyoYdQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0b32276b51d8974c4fd7c9486b6f80143396a5bb", "width": 216, "height": 136}, {"url": "https://external-preview.redd.it/jK_Rae0h1ebDEMtfUdLFkxTifROb_wRsOUsOXOyoYdQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c0135baa377781ee5db9898c61eb0aae9d724ef4", "width": 320, "height": 202}, {"url": "https://external-preview.redd.it/jK_Rae0h1ebDEMtfUdLFkxTifROb_wRsOUsOXOyoYdQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a5c4fedefb2f0b1f2cad8c65898887bf23e8dfc5", "width": 640, "height": 404}], "variants": {}, "id": "4ThJ0-MX4f9TGEZ0W5hZ8TGZk7Hp7jMc1Hwr4rtRwpc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4jlh7", "is_robot_indexable": true, "report_reasons": null, "author": "robert_ritz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4jlh7/what_do_you_want_in_a_data_science_publication/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4jlh7/what_do_you_want_in_a_data_science_publication/", "subreddit_subscribers": 813764, "created_utc": 1665826689.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "same as title", "author_fullname": "t2_bsfosv4r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the most important machine learning algorithms? What are the most commonly applied algorithms when attacking a problem?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4h2m7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665817309.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;same as title&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4h2m7", "is_robot_indexable": true, "report_reasons": null, "author": "Adventurous-Grab-20", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4h2m7/what_are_the_most_important_machine_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4h2m7/what_are_the_most_important_machine_learning/", "subreddit_subscribers": 813764, "created_utc": 1665817309.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "There are lot's of algorithm explanations out there like [this](https://blog.acolyer.org/2015/04/22/distributed-snapshots-determining-global-states-of-distributed-systems/) one, but i can't fine real code examples. Without those i really don't get it.", "author_fullname": "t2_ehomo9o8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hey guys, can you share code examples of Distributed Snapshot implementation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4h2pt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1665817318.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There are lot&amp;#39;s of algorithm explanations out there like &lt;a href=\"https://blog.acolyer.org/2015/04/22/distributed-snapshots-determining-global-states-of-distributed-systems/\"&gt;this&lt;/a&gt; one, but i can&amp;#39;t fine real code examples. Without those i really don&amp;#39;t get it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/BT3kbNfcl3kI2H2nl1QXFawJd0TfjkBzRyYw0Hrp8rU.jpg?auto=webp&amp;s=f8886d1524cf7796ae19a1569105de6973edb193", "width": 2020, "height": 1210}, "resolutions": [{"url": "https://external-preview.redd.it/BT3kbNfcl3kI2H2nl1QXFawJd0TfjkBzRyYw0Hrp8rU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b62351658eeffe4d8ff6fec079a3aa9116878956", "width": 108, "height": 64}, {"url": "https://external-preview.redd.it/BT3kbNfcl3kI2H2nl1QXFawJd0TfjkBzRyYw0Hrp8rU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d27934942280f2711b7e1813c40ff721b183922f", "width": 216, "height": 129}, {"url": "https://external-preview.redd.it/BT3kbNfcl3kI2H2nl1QXFawJd0TfjkBzRyYw0Hrp8rU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8f479db9832afd78b03b6f8126500c72ccf22eb0", "width": 320, "height": 191}, {"url": "https://external-preview.redd.it/BT3kbNfcl3kI2H2nl1QXFawJd0TfjkBzRyYw0Hrp8rU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=655e06a6d32ba60f061cfce11448d3f403e9e846", "width": 640, "height": 383}, {"url": "https://external-preview.redd.it/BT3kbNfcl3kI2H2nl1QXFawJd0TfjkBzRyYw0Hrp8rU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e8697ab8a7cdf53755d083352e271584d4cd904a", "width": 960, "height": 575}, {"url": "https://external-preview.redd.it/BT3kbNfcl3kI2H2nl1QXFawJd0TfjkBzRyYw0Hrp8rU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=53697970008a9daf145eaf0dccb5f9d311f5ad02", "width": 1080, "height": 646}], "variants": {}, "id": "JIJ5n3_5EsXlCbpR6FAYDGRDfZKADDwAEmi50TblsFU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4h2pt", "is_robot_indexable": true, "report_reasons": null, "author": "nevermindever42", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4h2pt/hey_guys_can_you_share_code_examples_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4h2pt/hey_guys_can_you_share_code_examples_of/", "subreddit_subscribers": 813764, "created_utc": 1665817318.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I understand the difference between ML and DL ,which one is used mostly in your day to day jobs. As a  Data Science Beginner which area should i be focusing more ML or DL from a job perspective?", "author_fullname": "t2_bsfosv4r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is widely used ML or DL in your day to day jobs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4s3sr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665851026.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I understand the difference between ML and DL ,which one is used mostly in your day to day jobs. As a  Data Science Beginner which area should i be focusing more ML or DL from a job perspective?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4s3sr", "is_robot_indexable": true, "report_reasons": null, "author": "Adventurous-Grab-20", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4s3sr/what_is_widely_used_ml_or_dl_in_your_day_to_day/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4s3sr/what_is_widely_used_ml_or_dl_in_your_day_to_day/", "subreddit_subscribers": 813764, "created_utc": 1665851026.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've learnt concepts like linear, logistic regression, SVM, decision tree, gaussian mixture model, k means clustering. \n\nHow I want to use this to analyze selfdriving car dataset but not sure how do I use these principles on images ? most of the data from self driving cars are images from cameras. \n\nCan someone point me to an example notebook ?", "author_fullname": "t2_13t60b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I've recently completed a post graduate certification in ML and analytics. How to apply learning and principles using kaggle dataset?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4rktl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665849707.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve learnt concepts like linear, logistic regression, SVM, decision tree, gaussian mixture model, k means clustering. &lt;/p&gt;\n\n&lt;p&gt;How I want to use this to analyze selfdriving car dataset but not sure how do I use these principles on images ? most of the data from self driving cars are images from cameras. &lt;/p&gt;\n\n&lt;p&gt;Can someone point me to an example notebook ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4rktl", "is_robot_indexable": true, "report_reasons": null, "author": "drugsarebadmky", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4rktl/ive_recently_completed_a_post_graduate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4rktl/ive_recently_completed_a_post_graduate/", "subreddit_subscribers": 813764, "created_utc": 1665849707.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am Japanese, so please forgive me if my grammar may be incorrect.  \n\n\nI would like to know how to reward DAOs not on a task basis, but by calculating their contribution through data analysis.  \nIf we can create that method with high quality, I believe we can create a new system of economy that will be upward compatible with capitalism.  \nWe call it freeism.  \n\n\nAbout freeism\n\nWe came up with the \"freeism\" system as an alternative economic mechanism to capitalism.\n\nIt gives a new alternative to economic mechanisms that have had only limited choices, such as capitalism and socialism.\n\nI know that many people are already thinking about this kind of thing, but I would like to implement it as a part of the social structure, not as a theoretical theory, and eventually create a society in which the entire economy revolves around freeism instead of capitalism.\n\n&amp;#x200B;\n\nBasic Mechanism of Freeism\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nThe following is an explanation of the basic mechanism of FREELISM.\n\n&amp;#x200B;\n\nThe supplier is asked to provide all types of goods and services for free, and non-transferable points (SBT?) (called contribution points) are given to those who provide them.\n\nThere will be multiple ways to calculate contribution points, and we will also create a mechanism to provide them.\n\nThe mechanism is described below.\n\nFor products or services that are not available to all who want them (hereinafter referred to as \"limited edition products\"), the points (hereinafter referred to as \"quota\") will be set as the square root of contribution points, and those who offer to use the most quota will be given priority in using them.\n\nInstead of consuming contribution points as compensation for obtaining goods or services, they should only be accounted for so that they cannot be used to obtain other limited items.\n\nTherefore, contribution points do not decrease even if a limited item is obtained but accumulate (exceptions apply. See below)\n\nNecessity\n\nThe necessity of the quota is described below.\n\nThe method of calculating the quota is also described below.\n\nThis type of economic mechanism is called \"freeism.\n\nFreeism is an economic model that can be finally established by using technologies such as data analysis, blockchain, web apps, etc.\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nDig a little deeper into the mechanism of FREESISM\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nThis section explains each of the mechanisms that make up FREESISM.\n\n&amp;#x200B;\n\nContribution rules\n\nThe rules of contribution are the laws that govern life in a freeism society.\n\nOr the country in which the law is located.\n\nAt first, only one rule exists, but just as there are multiple countries, multiple rules of contribution can be created.\n\nThe contribution rules should be easy for anyone to create.\n\nI want the rules of contribution to be divided by ideology and taste (only some people emigrate based on taxation, culture, and taste, but for the most part, the current country is determined by birth and upbringing, and there are people with different tastes, values, and ideology in the same country, which creates conflict).\n\nThat is why we create the right of non-interference as the right not to interfere with others.\n\nEach contribution rule has an end goal.\n\nThe end goal is discussed below.\n\n&amp;#x200B;\n\nThe FREEISM Platform\n\nThe freeism platform is a mechanism to manage the rules of contribution.\n\nThe rules of contribution play a legal role.\n\nThe freeism platform becomes a higher-level entity like the Constitution OR the UN OR the federal government.\n\nThe freeism platform also has rules, and within the scope of those rules, they get to make the rules of contribution.\n\nThere will be multiple freeism platforms, and people will be able to join any freeism platform they want.\n\nA freeism platform may also have an end goal.\n\nThe end goal is described below.\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nFinal Goal\n\nThe end goal is the goal that each freeism platform, each contribution rule, and each project (like a company) is aiming for.\n\nIt can be set by vote, decided at the establishment stage, or left to the decision-makers to set.\n\nSet goals that you want to achieve, not goals or KPIs to achieve subdivided goals.\n\nFor example, \"increase in happiness,\" \"degree of health,\" \"increase in productivity,\" \"increase in the number of rational decisions made,\" and \"crime rate.\"\n\nIt is unclear if we would set \"lower crime rate\" as a goal since even \"lower crime rate\" might be a goal to achieve higher levels of happiness. We want to set a goal that we are ultimately aiming for.\n\nFor FREEISM, we should set a final goal for the FREEISM platform, a final goal for the contribution rule, and a final goal for the project, and then calculate the contributions based on how much they have helped to bring us closer to or achieve that final goal.\n\nExamples of final goals\n\nIncrease in productivity (working hours required to obtain goods and services) within the limits of the law\n\nIncrease in happiness within the limits of the law\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nContribution points\n\nRefers to points required to obtain priority for limited items.\n\nContribution points are non-transferable.\n\nHowever, loans are possible under some contribution rules.\n\nCan I use SBT as contribution points?\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nHow to Calculate Contribution Points\n\nContribution points earned are calculated based on \"the degree of contribution to the final goal\" \u2716\ufe0e \"market principle\" \u2716\ufe0e \"different weighting/rules for each contribution rule.\"\n\nUntil now, it was \"market principles\" \u2716\ufe0e \"different weighting/rules for each country or region rule\", but we will add \"degree of contribution to the final goal\" to it.\n\nI think the market principle is encapsulated in the degree of contribution to the final goal. However, if you still want to make further use of the market principle, you can give contribution points based on \"market principle x degree of contribution to the final goal\" or \"market principle only\".\n\nThe degree of contribution to the final goal could be calculated using multiple regression analysis or other data analysis methods or methods to visualize DAO's task-based contribution.\n\nSee below.\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nQuota\n\nThe quota is a mechanism to avoid monopolizing the service, and if the service can be provided to everyone, the quota is not used.\n\nEach contribution rule has a different way of calculating the quota, and each person is given a quota weighted by contribution points (contribution points \u2716\ufe0f0.9 = amount of quota, etc.) or the square root of contribution points.\n\nThe amount of quota used will be the price.\n\nThere is a negative correlation: the lower the winning rate of a product or service, the more quota it occupies, and the closer the winning rate is to 100%, the less quota it occupies.\n\nIn FREESISM, the quota is always used while the limited item is in use, and the amount used always reflects the market value, not the amount used when it was acquired.\n\nThe structure of the quota differs for each contribution rule.\n\nThe period you occupy a quota should be the period you own that limited edition item.\n\nIf you give it away or throw it away, you can apply for it on the FREEMISM platform, or the service will automatically detect it and release the use of the quota.\n\nTo prevent \"false applications\" where people apply to give it away when they own it, make it necessary to give it away or throw it away at a predetermined location or app.\n\nCreate an incentive to have it detected through the app, since it should be detected from each app and if not through the app, it will occupy the frame all the time.\n\nMake it impossible for people to report that they have given it up on their own, other than by having the app automatically detect it.\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nFREEISM\n\nIn freeism, if other people refer to the products, services, source code, or other deliverables developed by each person, or to know-how and other things such as research findings, they will receive only a portion of the contribution points earned by the person they refer to, such as 0.5 times the contribution points earned by the person they refer to.\n\nThereby.\n\nIf someone only submits an idea and others implement it, the person who submitted the idea will also receive a portion of the contribution points earned by the person who implemented it.\n\nIf another company started a business and failed but was successful in running it by avoiding the strategies of the failed company, then allow the people who worked in the failed company to receive a portion of the contribution points earned by the successful company.\n\nThat way, where it was 0-1 to succeed or fail, maybe we could make it so that even if it fails, it is not 0-1 financially, but there is some benefit.\n\nSince points are just points, unlike the currency, they don't have to be distributed and can be offered to both.\n\nBut it's hard to determine if that's what I was referring to.\n\nI will discuss this later.\n\nWe want a society where everything is open source.\n\nI want to create a society where every no-how, patent, and other thing is open source, by weighting the contribution points that can be earned if others use the no-how, and by weighting the contribution points that can be earned just by making it open source, such as 1.2 times the contribution points that can be earned by making it open source.\n\nEveryone gets it without having to distribute, and being open source could lead to more compensation for sharing without monopolizing rather than monopolizing and competing.\n\nBut if the relative position without distribution determines whether you get a limited product, is it the same as when profits were shared?\n\nIt's more mentally stable because you don't have to fight for a piece of the pie.\n\nThe basic idea is to think in terms of rules of contribution, where the only rule is the degree of contribution to the liberal end goal, but when considering various rules of contribution, we can make a law that regulates each of them in a way that is characteristic to the sound of each rule of contribution.\n\nEven if any action is the wrong action or not, we will stipulate that only actions that have a bad impact on the final goal contribution level are bad.\n\nEven theft would not be a crime if it did not negatively impact anyone.\n\nSomewhere the idea is like a woman who says it's not cheating if she doesn't get caught in a love story about whether or not she qualifies as cheating.\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nThe position of each\n\nIn freeism, the system is divided into a freeism platform, contribution rules, projects, and other mechanisms.\n\nThe freeism platform is the role of the federal government, the contribution rule is the role of the state government, and the project is the role of the company.\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nProject\n\nThe role of the company.\n\nThe idea of freeism is to make everything open, so all the data of companies that are currently hidden will be shared and made available to everyone so that the contribution points earned will be weighted 1.1 times more than before.\n\nOr, by being more open, make the service more technical and reliable, so that it is seen as contributing to the well-being and other end goals.\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nPrice\n\nThe lower the winning rate (the percentage of people who apply who win), the more quota is occupied and the more the beneficiary pays.\n\nThe amount of quota used becomes the price, so if the winning rate increases, the price becomes \"completely free\" with zero quota use of zero yen.\n\nIn capitalism, even for products with high demand and high supply, the price is close to the cost, but the beneficiaries bear the burden.\n\nIn FREEMISM, the overall goods and services are cheaper because they are negatively correlated with the winning rate, regardless of cost.\n\nFurthermore, since the added value cannot be added to the price, the price becomes cheaper by that amount, and the beneficiary burden of freeism is better than the beneficiary burden of capitalism.\n\nThe provider of goods and services receives nothing from the beneficiary for providing goods and services, and the beneficiary pays nothing to the provider for acquiring goods and services, which only increases the amount that occupies the quota managed by the freeism platform.\n\nThe provider can offer goods and services to those who cannot afford to pay for them, and if they do, the business will be compensated.\n\n  \nLife of FREEISM\n\nLet's imagine and write about what society would be like in a society where FREESISM is realized.\n\n&amp;#x200B;\n\nDownload or use any of the web apps, native apps, VR or AR apps of the freeism app (which also serves as the freeism platform) that manages all the functions of freeism, from a web app, native app, VR, or AR app, or a browser.\n\nIn the freeism app, choose the contribution rule to which you want to belong.\n\nEnter various information about yourself and link it to the contribution rule you have chosen, and generate an account with the data for that contribution rule.\n\nYou can put the date of the contribution rule you belong to as a property in your wallet for Web3, or in your Google account for Web2, etc.\n\nWith the account containing that data, data is acquired from various applications and the contribution rules are calculated using that data.\n\nFurthermore, according to each contribution rule, you can display 00 content on Twitter, but not 00. If the content is prohibited by each rule of each contribution level, such as \"00 content is allowed to be displayed on Twitter, but 00 is prohibited,\" each rule of each contribution level will be detected from the account and automatically hidden.\n\nWhen you want to get a product or service on each platform of freeism services or existing services (Amazon, Spotify, etc.), you can get the person's contribution points from the API that can get the contribution points of each person managed by that freeism platform, and Then, we can set up an input field in the platform, such as Amazon, where people can input how many quotas they want to offer, and those who offer the highest amount will be given priority to receive?\n\nIs it faster to create a new one?\n\nThose who offer limited items in the above process will receive contribution points for the contribution rules to which they belong.\n\nThere is no such thing as an exchange rate between multiple contribution points, so the more contribution rules that contribute to the ultimate goal of the freeism platform, the larger the percentage to be offered (tentative idea).\n\nCompatibility between freeism platforms is discussed below.", "author_fullname": "t2_dy46uwx1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "freeism\u30fcCapitalism upwardly compatible\u30fc", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y539db", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.2, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665880895.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am Japanese, so please forgive me if my grammar may be incorrect.  &lt;/p&gt;\n\n&lt;p&gt;I would like to know how to reward DAOs not on a task basis, but by calculating their contribution through data analysis.&lt;br/&gt;\nIf we can create that method with high quality, I believe we can create a new system of economy that will be upward compatible with capitalism.&lt;br/&gt;\nWe call it freeism.  &lt;/p&gt;\n\n&lt;p&gt;About freeism&lt;/p&gt;\n\n&lt;p&gt;We came up with the &amp;quot;freeism&amp;quot; system as an alternative economic mechanism to capitalism.&lt;/p&gt;\n\n&lt;p&gt;It gives a new alternative to economic mechanisms that have had only limited choices, such as capitalism and socialism.&lt;/p&gt;\n\n&lt;p&gt;I know that many people are already thinking about this kind of thing, but I would like to implement it as a part of the social structure, not as a theoretical theory, and eventually create a society in which the entire economy revolves around freeism instead of capitalism.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Basic Mechanism of Freeism&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The following is an explanation of the basic mechanism of FREELISM.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The supplier is asked to provide all types of goods and services for free, and non-transferable points (SBT?) (called contribution points) are given to those who provide them.&lt;/p&gt;\n\n&lt;p&gt;There will be multiple ways to calculate contribution points, and we will also create a mechanism to provide them.&lt;/p&gt;\n\n&lt;p&gt;The mechanism is described below.&lt;/p&gt;\n\n&lt;p&gt;For products or services that are not available to all who want them (hereinafter referred to as &amp;quot;limited edition products&amp;quot;), the points (hereinafter referred to as &amp;quot;quota&amp;quot;) will be set as the square root of contribution points, and those who offer to use the most quota will be given priority in using them.&lt;/p&gt;\n\n&lt;p&gt;Instead of consuming contribution points as compensation for obtaining goods or services, they should only be accounted for so that they cannot be used to obtain other limited items.&lt;/p&gt;\n\n&lt;p&gt;Therefore, contribution points do not decrease even if a limited item is obtained but accumulate (exceptions apply. See below)&lt;/p&gt;\n\n&lt;p&gt;Necessity&lt;/p&gt;\n\n&lt;p&gt;The necessity of the quota is described below.&lt;/p&gt;\n\n&lt;p&gt;The method of calculating the quota is also described below.&lt;/p&gt;\n\n&lt;p&gt;This type of economic mechanism is called &amp;quot;freeism.&lt;/p&gt;\n\n&lt;p&gt;Freeism is an economic model that can be finally established by using technologies such as data analysis, blockchain, web apps, etc.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Dig a little deeper into the mechanism of FREESISM&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;This section explains each of the mechanisms that make up FREESISM.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Contribution rules&lt;/p&gt;\n\n&lt;p&gt;The rules of contribution are the laws that govern life in a freeism society.&lt;/p&gt;\n\n&lt;p&gt;Or the country in which the law is located.&lt;/p&gt;\n\n&lt;p&gt;At first, only one rule exists, but just as there are multiple countries, multiple rules of contribution can be created.&lt;/p&gt;\n\n&lt;p&gt;The contribution rules should be easy for anyone to create.&lt;/p&gt;\n\n&lt;p&gt;I want the rules of contribution to be divided by ideology and taste (only some people emigrate based on taxation, culture, and taste, but for the most part, the current country is determined by birth and upbringing, and there are people with different tastes, values, and ideology in the same country, which creates conflict).&lt;/p&gt;\n\n&lt;p&gt;That is why we create the right of non-interference as the right not to interfere with others.&lt;/p&gt;\n\n&lt;p&gt;Each contribution rule has an end goal.&lt;/p&gt;\n\n&lt;p&gt;The end goal is discussed below.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The FREEISM Platform&lt;/p&gt;\n\n&lt;p&gt;The freeism platform is a mechanism to manage the rules of contribution.&lt;/p&gt;\n\n&lt;p&gt;The rules of contribution play a legal role.&lt;/p&gt;\n\n&lt;p&gt;The freeism platform becomes a higher-level entity like the Constitution OR the UN OR the federal government.&lt;/p&gt;\n\n&lt;p&gt;The freeism platform also has rules, and within the scope of those rules, they get to make the rules of contribution.&lt;/p&gt;\n\n&lt;p&gt;There will be multiple freeism platforms, and people will be able to join any freeism platform they want.&lt;/p&gt;\n\n&lt;p&gt;A freeism platform may also have an end goal.&lt;/p&gt;\n\n&lt;p&gt;The end goal is described below.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Final Goal&lt;/p&gt;\n\n&lt;p&gt;The end goal is the goal that each freeism platform, each contribution rule, and each project (like a company) is aiming for.&lt;/p&gt;\n\n&lt;p&gt;It can be set by vote, decided at the establishment stage, or left to the decision-makers to set.&lt;/p&gt;\n\n&lt;p&gt;Set goals that you want to achieve, not goals or KPIs to achieve subdivided goals.&lt;/p&gt;\n\n&lt;p&gt;For example, &amp;quot;increase in happiness,&amp;quot; &amp;quot;degree of health,&amp;quot; &amp;quot;increase in productivity,&amp;quot; &amp;quot;increase in the number of rational decisions made,&amp;quot; and &amp;quot;crime rate.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;It is unclear if we would set &amp;quot;lower crime rate&amp;quot; as a goal since even &amp;quot;lower crime rate&amp;quot; might be a goal to achieve higher levels of happiness. We want to set a goal that we are ultimately aiming for.&lt;/p&gt;\n\n&lt;p&gt;For FREEISM, we should set a final goal for the FREEISM platform, a final goal for the contribution rule, and a final goal for the project, and then calculate the contributions based on how much they have helped to bring us closer to or achieve that final goal.&lt;/p&gt;\n\n&lt;p&gt;Examples of final goals&lt;/p&gt;\n\n&lt;p&gt;Increase in productivity (working hours required to obtain goods and services) within the limits of the law&lt;/p&gt;\n\n&lt;p&gt;Increase in happiness within the limits of the law&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Contribution points&lt;/p&gt;\n\n&lt;p&gt;Refers to points required to obtain priority for limited items.&lt;/p&gt;\n\n&lt;p&gt;Contribution points are non-transferable.&lt;/p&gt;\n\n&lt;p&gt;However, loans are possible under some contribution rules.&lt;/p&gt;\n\n&lt;p&gt;Can I use SBT as contribution points?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;How to Calculate Contribution Points&lt;/p&gt;\n\n&lt;p&gt;Contribution points earned are calculated based on &amp;quot;the degree of contribution to the final goal&amp;quot; \u2716\ufe0e &amp;quot;market principle&amp;quot; \u2716\ufe0e &amp;quot;different weighting/rules for each contribution rule.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Until now, it was &amp;quot;market principles&amp;quot; \u2716\ufe0e &amp;quot;different weighting/rules for each country or region rule&amp;quot;, but we will add &amp;quot;degree of contribution to the final goal&amp;quot; to it.&lt;/p&gt;\n\n&lt;p&gt;I think the market principle is encapsulated in the degree of contribution to the final goal. However, if you still want to make further use of the market principle, you can give contribution points based on &amp;quot;market principle x degree of contribution to the final goal&amp;quot; or &amp;quot;market principle only&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;The degree of contribution to the final goal could be calculated using multiple regression analysis or other data analysis methods or methods to visualize DAO&amp;#39;s task-based contribution.&lt;/p&gt;\n\n&lt;p&gt;See below.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Quota&lt;/p&gt;\n\n&lt;p&gt;The quota is a mechanism to avoid monopolizing the service, and if the service can be provided to everyone, the quota is not used.&lt;/p&gt;\n\n&lt;p&gt;Each contribution rule has a different way of calculating the quota, and each person is given a quota weighted by contribution points (contribution points \u2716\ufe0f0.9 = amount of quota, etc.) or the square root of contribution points.&lt;/p&gt;\n\n&lt;p&gt;The amount of quota used will be the price.&lt;/p&gt;\n\n&lt;p&gt;There is a negative correlation: the lower the winning rate of a product or service, the more quota it occupies, and the closer the winning rate is to 100%, the less quota it occupies.&lt;/p&gt;\n\n&lt;p&gt;In FREESISM, the quota is always used while the limited item is in use, and the amount used always reflects the market value, not the amount used when it was acquired.&lt;/p&gt;\n\n&lt;p&gt;The structure of the quota differs for each contribution rule.&lt;/p&gt;\n\n&lt;p&gt;The period you occupy a quota should be the period you own that limited edition item.&lt;/p&gt;\n\n&lt;p&gt;If you give it away or throw it away, you can apply for it on the FREEMISM platform, or the service will automatically detect it and release the use of the quota.&lt;/p&gt;\n\n&lt;p&gt;To prevent &amp;quot;false applications&amp;quot; where people apply to give it away when they own it, make it necessary to give it away or throw it away at a predetermined location or app.&lt;/p&gt;\n\n&lt;p&gt;Create an incentive to have it detected through the app, since it should be detected from each app and if not through the app, it will occupy the frame all the time.&lt;/p&gt;\n\n&lt;p&gt;Make it impossible for people to report that they have given it up on their own, other than by having the app automatically detect it.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;FREEISM&lt;/p&gt;\n\n&lt;p&gt;In freeism, if other people refer to the products, services, source code, or other deliverables developed by each person, or to know-how and other things such as research findings, they will receive only a portion of the contribution points earned by the person they refer to, such as 0.5 times the contribution points earned by the person they refer to.&lt;/p&gt;\n\n&lt;p&gt;Thereby.&lt;/p&gt;\n\n&lt;p&gt;If someone only submits an idea and others implement it, the person who submitted the idea will also receive a portion of the contribution points earned by the person who implemented it.&lt;/p&gt;\n\n&lt;p&gt;If another company started a business and failed but was successful in running it by avoiding the strategies of the failed company, then allow the people who worked in the failed company to receive a portion of the contribution points earned by the successful company.&lt;/p&gt;\n\n&lt;p&gt;That way, where it was 0-1 to succeed or fail, maybe we could make it so that even if it fails, it is not 0-1 financially, but there is some benefit.&lt;/p&gt;\n\n&lt;p&gt;Since points are just points, unlike the currency, they don&amp;#39;t have to be distributed and can be offered to both.&lt;/p&gt;\n\n&lt;p&gt;But it&amp;#39;s hard to determine if that&amp;#39;s what I was referring to.&lt;/p&gt;\n\n&lt;p&gt;I will discuss this later.&lt;/p&gt;\n\n&lt;p&gt;We want a society where everything is open source.&lt;/p&gt;\n\n&lt;p&gt;I want to create a society where every no-how, patent, and other thing is open source, by weighting the contribution points that can be earned if others use the no-how, and by weighting the contribution points that can be earned just by making it open source, such as 1.2 times the contribution points that can be earned by making it open source.&lt;/p&gt;\n\n&lt;p&gt;Everyone gets it without having to distribute, and being open source could lead to more compensation for sharing without monopolizing rather than monopolizing and competing.&lt;/p&gt;\n\n&lt;p&gt;But if the relative position without distribution determines whether you get a limited product, is it the same as when profits were shared?&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s more mentally stable because you don&amp;#39;t have to fight for a piece of the pie.&lt;/p&gt;\n\n&lt;p&gt;The basic idea is to think in terms of rules of contribution, where the only rule is the degree of contribution to the liberal end goal, but when considering various rules of contribution, we can make a law that regulates each of them in a way that is characteristic to the sound of each rule of contribution.&lt;/p&gt;\n\n&lt;p&gt;Even if any action is the wrong action or not, we will stipulate that only actions that have a bad impact on the final goal contribution level are bad.&lt;/p&gt;\n\n&lt;p&gt;Even theft would not be a crime if it did not negatively impact anyone.&lt;/p&gt;\n\n&lt;p&gt;Somewhere the idea is like a woman who says it&amp;#39;s not cheating if she doesn&amp;#39;t get caught in a love story about whether or not she qualifies as cheating.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The position of each&lt;/p&gt;\n\n&lt;p&gt;In freeism, the system is divided into a freeism platform, contribution rules, projects, and other mechanisms.&lt;/p&gt;\n\n&lt;p&gt;The freeism platform is the role of the federal government, the contribution rule is the role of the state government, and the project is the role of the company.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Project&lt;/p&gt;\n\n&lt;p&gt;The role of the company.&lt;/p&gt;\n\n&lt;p&gt;The idea of freeism is to make everything open, so all the data of companies that are currently hidden will be shared and made available to everyone so that the contribution points earned will be weighted 1.1 times more than before.&lt;/p&gt;\n\n&lt;p&gt;Or, by being more open, make the service more technical and reliable, so that it is seen as contributing to the well-being and other end goals.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Price&lt;/p&gt;\n\n&lt;p&gt;The lower the winning rate (the percentage of people who apply who win), the more quota is occupied and the more the beneficiary pays.&lt;/p&gt;\n\n&lt;p&gt;The amount of quota used becomes the price, so if the winning rate increases, the price becomes &amp;quot;completely free&amp;quot; with zero quota use of zero yen.&lt;/p&gt;\n\n&lt;p&gt;In capitalism, even for products with high demand and high supply, the price is close to the cost, but the beneficiaries bear the burden.&lt;/p&gt;\n\n&lt;p&gt;In FREEMISM, the overall goods and services are cheaper because they are negatively correlated with the winning rate, regardless of cost.&lt;/p&gt;\n\n&lt;p&gt;Furthermore, since the added value cannot be added to the price, the price becomes cheaper by that amount, and the beneficiary burden of freeism is better than the beneficiary burden of capitalism.&lt;/p&gt;\n\n&lt;p&gt;The provider of goods and services receives nothing from the beneficiary for providing goods and services, and the beneficiary pays nothing to the provider for acquiring goods and services, which only increases the amount that occupies the quota managed by the freeism platform.&lt;/p&gt;\n\n&lt;p&gt;The provider can offer goods and services to those who cannot afford to pay for them, and if they do, the business will be compensated.&lt;/p&gt;\n\n&lt;p&gt;Life of FREEISM&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s imagine and write about what society would be like in a society where FREESISM is realized.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Download or use any of the web apps, native apps, VR or AR apps of the freeism app (which also serves as the freeism platform) that manages all the functions of freeism, from a web app, native app, VR, or AR app, or a browser.&lt;/p&gt;\n\n&lt;p&gt;In the freeism app, choose the contribution rule to which you want to belong.&lt;/p&gt;\n\n&lt;p&gt;Enter various information about yourself and link it to the contribution rule you have chosen, and generate an account with the data for that contribution rule.&lt;/p&gt;\n\n&lt;p&gt;You can put the date of the contribution rule you belong to as a property in your wallet for Web3, or in your Google account for Web2, etc.&lt;/p&gt;\n\n&lt;p&gt;With the account containing that data, data is acquired from various applications and the contribution rules are calculated using that data.&lt;/p&gt;\n\n&lt;p&gt;Furthermore, according to each contribution rule, you can display 00 content on Twitter, but not 00. If the content is prohibited by each rule of each contribution level, such as &amp;quot;00 content is allowed to be displayed on Twitter, but 00 is prohibited,&amp;quot; each rule of each contribution level will be detected from the account and automatically hidden.&lt;/p&gt;\n\n&lt;p&gt;When you want to get a product or service on each platform of freeism services or existing services (Amazon, Spotify, etc.), you can get the person&amp;#39;s contribution points from the API that can get the contribution points of each person managed by that freeism platform, and Then, we can set up an input field in the platform, such as Amazon, where people can input how many quotas they want to offer, and those who offer the highest amount will be given priority to receive?&lt;/p&gt;\n\n&lt;p&gt;Is it faster to create a new one?&lt;/p&gt;\n\n&lt;p&gt;Those who offer limited items in the above process will receive contribution points for the contribution rules to which they belong.&lt;/p&gt;\n\n&lt;p&gt;There is no such thing as an exchange rate between multiple contribution points, so the more contribution rules that contribute to the ultimate goal of the freeism platform, the larger the percentage to be offered (tentative idea).&lt;/p&gt;\n\n&lt;p&gt;Compatibility between freeism platforms is discussed below.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y539db", "is_robot_indexable": true, "report_reasons": null, "author": "Traditional-Self1986", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y539db/freeism\u30fccapitalism_upwardly_compatible\u30fc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y539db/freeism\u30fccapitalism_upwardly_compatible\u30fc/", "subreddit_subscribers": 813764, "created_utc": 1665880895.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been lurking on this sub for a while now and all too often I see posts from people claiming they feel inadequate and then they go on to describe their stupid impressive background and experience. That's great and all but I'd like to move the spotlight to the rest of us for just a minute. Cheers to my fellow mediocre data scientists who don't work at FAANG companies, aren't pursing a PhD, don't publish papers, haven't won Kaggle competitions, and don't spend every waking hour improving their portfolio. Even though we're nothing special, we still deserve some appreciation every once in a while.\n\n/rant I'll hand it back over to the smart people now", "author_fullname": "t2_rv2brc3u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Shout Out to All the Mediocre Data Scientists Out There", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4zh44", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665870141.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been lurking on this sub for a while now and all too often I see posts from people claiming they feel inadequate and then they go on to describe their stupid impressive background and experience. That&amp;#39;s great and all but I&amp;#39;d like to move the spotlight to the rest of us for just a minute. Cheers to my fellow mediocre data scientists who don&amp;#39;t work at FAANG companies, aren&amp;#39;t pursing a PhD, don&amp;#39;t publish papers, haven&amp;#39;t won Kaggle competitions, and don&amp;#39;t spend every waking hour improving their portfolio. Even though we&amp;#39;re nothing special, we still deserve some appreciation every once in a while.&lt;/p&gt;\n\n&lt;p&gt;/rant I&amp;#39;ll hand it back over to the smart people now&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4zh44", "is_robot_indexable": true, "report_reasons": null, "author": "Dull_Adagio4038", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4zh44/shout_out_to_all_the_mediocre_data_scientists_out/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4zh44/shout_out_to_all_the_mediocre_data_scientists_out/", "subreddit_subscribers": 813764, "created_utc": 1665870141.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}