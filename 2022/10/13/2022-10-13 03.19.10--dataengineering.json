{"kind": "Listing", "data": {"after": null, "dist": 21, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_h30vc65", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What\u2019s your process for deploying a data pipeline from a notebook, running it, and managing it in production?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_y2bl65", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 173, "domain": "i.redd.it", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 173, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/RroEsmI7CJi1Jay3z_IgPGAUtA7a54WP5JTv3MRwsP0.jpg", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1665599540.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/pq04w47z4ft91.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/pq04w47z4ft91.jpg?auto=webp&amp;s=60c30264e541d7e8eebe102734a42bb4264850b2", "width": 500, "height": 585}, "resolutions": [{"url": "https://preview.redd.it/pq04w47z4ft91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d83cc0f1f5a4e715ab30e00387bf6d1db27e0e5d", "width": 108, "height": 126}, {"url": "https://preview.redd.it/pq04w47z4ft91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2c38d6c3bbbc2e8e3f20a4525872acba72a16c01", "width": 216, "height": 252}, {"url": "https://preview.redd.it/pq04w47z4ft91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4e0ce26b863772d37918629d7050bcabe32cc416", "width": 320, "height": 374}], "variants": {}, "id": "pqAyKsDleORYu-ooOQsVqG1tMO87jQIXYM7Is2K6-3w"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y2bl65", "is_robot_indexable": true, "report_reasons": null, "author": "jnkwok", "discussion_type": null, "num_comments": 56, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y2bl65/whats_your_process_for_deploying_a_data_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/pq04w47z4ft91.jpg", "subreddit_subscribers": 76250, "created_utc": 1665599540.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am organising an evening workshop aimed at last year university students (mostly technical profiles). The goal is to make them warm for a career in data engineering. Or at least give them a taste of what it is (not) about. \n\nIf you have organised or joined such a similar event, what topics/tools/platform worked or did not work? Any suggestions?  \n\n\nWhat I had in mind: create a small story where they are part of a data team under time pressure to deliver: introduce them to Pyspark (core concepts),  let them play in Databricks, provide bad quality data, let them schedule a job on it. During this, other persona's would pop up (architects, product owners, data scientists) that will alter the scope slightly and let them reflect on how they did it.", "author_fullname": "t2_cnfdjk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ideas for 2-3h workshop for students on data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y1xia7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 55, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 55, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665560609.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am organising an evening workshop aimed at last year university students (mostly technical profiles). The goal is to make them warm for a career in data engineering. Or at least give them a taste of what it is (not) about. &lt;/p&gt;\n\n&lt;p&gt;If you have organised or joined such a similar event, what topics/tools/platform worked or did not work? Any suggestions?  &lt;/p&gt;\n\n&lt;p&gt;What I had in mind: create a small story where they are part of a data team under time pressure to deliver: introduce them to Pyspark (core concepts),  let them play in Databricks, provide bad quality data, let them schedule a job on it. During this, other persona&amp;#39;s would pop up (architects, product owners, data scientists) that will alter the scope slightly and let them reflect on how they did it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "y1xia7", "is_robot_indexable": true, "report_reasons": null, "author": "brunocou", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y1xia7/ideas_for_23h_workshop_for_students_on_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y1xia7/ideas_for_23h_workshop_for_students_on_data/", "subreddit_subscribers": 76250, "created_utc": 1665560609.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nMy company uses Flyway and we currently keep track of data and schema changes. Here's my simple question: could this be done differently? What do you guys use at your company? Do you just take regular dumps/snapshots? Do you use other tools? Do you keep track of both data and schema?\n\nMany thanks", "author_fullname": "t2_17f8xf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Database version control: how do you do it at your company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y26s3q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665588159.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;My company uses Flyway and we currently keep track of data and schema changes. Here&amp;#39;s my simple question: could this be done differently? What do you guys use at your company? Do you just take regular dumps/snapshots? Do you use other tools? Do you keep track of both data and schema?&lt;/p&gt;\n\n&lt;p&gt;Many thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y26s3q", "is_robot_indexable": true, "report_reasons": null, "author": "goglobal01", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y26s3q/database_version_control_how_do_you_do_it_at_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y26s3q/database_version_control_how_do_you_do_it_at_your/", "subreddit_subscribers": 76250, "created_utc": 1665588159.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I would say I am still in the early years of being a data engineer and there is so much to learn. But lurking in this subreddit has helped me learn new tools, techniques, best practices, and so much more. So thanks to everyone that contributes in this subreddit. To those that give helpful advice to someone that may have asked the same question 100x. This subreddit has been like a free mentoring program at times!", "author_fullname": "t2_awlj3rif", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thanks to everyone here that contributes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_y2mdxi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665626547.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would say I am still in the early years of being a data engineer and there is so much to learn. But lurking in this subreddit has helped me learn new tools, techniques, best practices, and so much more. So thanks to everyone that contributes in this subreddit. To those that give helpful advice to someone that may have asked the same question 100x. This subreddit has been like a free mentoring program at times!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y2mdxi", "is_robot_indexable": true, "report_reasons": null, "author": "darthsatoshious", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y2mdxi/thanks_to_everyone_here_that_contributes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y2mdxi/thanks_to_everyone_here_that_contributes/", "subreddit_subscribers": 76250, "created_utc": 1665626547.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi I'm looking for interesting Data architecture/engineering writers/YouTubers/Twitter profiles to follow and learn from/ could you please share with who are your favorite ones to follow?", "author_fullname": "t2_bqjrmnud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data influencers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y1zeve", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665567496.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi I&amp;#39;m looking for interesting Data architecture/engineering writers/YouTubers/Twitter profiles to follow and learn from/ could you please share with who are your favorite ones to follow?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y1zeve", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering_Bug105", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y1zeve/data_influencers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y1zeve/data_influencers/", "subreddit_subscribers": 76250, "created_utc": 1665567496.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "From what I see (at least in my city), most of the \"data engineer\" offers that I see are in fact data scientist / analyst jobs, and I really enjoy coding and dont want to do DS. I'm afraid to waste my time trying DE just to realize that I dont code as much as I want. Am I wrong ?", "author_fullname": "t2_qexqkrk6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I get into DE if I enjoy coding ? (DE ~= data science ?)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y2cr28", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665602301.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;From what I see (at least in my city), most of the &amp;quot;data engineer&amp;quot; offers that I see are in fact data scientist / analyst jobs, and I really enjoy coding and dont want to do DS. I&amp;#39;m afraid to waste my time trying DE just to realize that I dont code as much as I want. Am I wrong ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "y2cr28", "is_robot_indexable": true, "report_reasons": null, "author": "165817566995", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y2cr28/should_i_get_into_de_if_i_enjoy_coding_de_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y2cr28/should_i_get_into_de_if_i_enjoy_coding_de_data/", "subreddit_subscribers": 76250, "created_utc": 1665602301.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Planning to build a whole bunch of data pipelines for a new project, which would all be in Python. This is a first for me, as I'm used to creating a simple script or using some GUI based tool. \n\nHow would you structure a Git repo of data pipelines that are all written in Python? Let's say I'm pulling data from 3 different sources, `Apple`, `Banana`, and `Cherry`. Would you have 3 different python files like `apple.py`, `banana.py`, and `cherry.py` all called by `main.py`?\n\nDo you all recommend having a `data` folder as well? I wouldn't publish any data online but for the sake of the repo, should I create a folder?\n\nAny other tips in terms of repo structure and management for data engineering? Would love any and all suggestions!", "author_fullname": "t2_2pyy4c8f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you structure a data pipeline repo?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y22iyt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665577450.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Planning to build a whole bunch of data pipelines for a new project, which would all be in Python. This is a first for me, as I&amp;#39;m used to creating a simple script or using some GUI based tool. &lt;/p&gt;\n\n&lt;p&gt;How would you structure a Git repo of data pipelines that are all written in Python? Let&amp;#39;s say I&amp;#39;m pulling data from 3 different sources, &lt;code&gt;Apple&lt;/code&gt;, &lt;code&gt;Banana&lt;/code&gt;, and &lt;code&gt;Cherry&lt;/code&gt;. Would you have 3 different python files like &lt;code&gt;apple.py&lt;/code&gt;, &lt;code&gt;banana.py&lt;/code&gt;, and &lt;code&gt;cherry.py&lt;/code&gt; all called by &lt;code&gt;main.py&lt;/code&gt;?&lt;/p&gt;\n\n&lt;p&gt;Do you all recommend having a &lt;code&gt;data&lt;/code&gt; folder as well? I wouldn&amp;#39;t publish any data online but for the sake of the repo, should I create a folder?&lt;/p&gt;\n\n&lt;p&gt;Any other tips in terms of repo structure and management for data engineering? Would love any and all suggestions!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y22iyt", "is_robot_indexable": true, "report_reasons": null, "author": "opabm", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y22iyt/how_would_you_structure_a_data_pipeline_repo/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y22iyt/how_would_you_structure_a_data_pipeline_repo/", "subreddit_subscribers": 76250, "created_utc": 1665577450.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm in Azure Databricks and I'm trying to increase the frequency at which an ADF pipeline can be run from daily to hourly.  This ADF pipeline has a Databricks connector as part of it because it accepts values from a control table and runs both dynamically and in parallel.  This can take around 20 minutes to run using a single cluster.  \n\nThe step I'm trying to overcome right now is the spin up time for said cluster, so I found pools.  But, being really honest, not quite sure how these work and no matter what I've tried, the execution time barely improves.\n\nWhat I've tried and questions:\n\n* I've created the linked service which calls the pool rather than the cluster.  This seems to be working fine.  I'm using the Standard_f8 compute optimised, 16GB, 8 cores instance.\n\n* Created a Databricks pool and attached clusters to it.  For some strange reason, when the ADF pipeline begins adding jobs, the clusters don't spin up and remain in a terminated state.  Is this expected behaviour?\n\n* For the pool, I have set the min idle to be 0.  Ideally, I'd have this pool kick off, have the clusters be ready to go for 8 hours per day, and then spin itself down overnight.\n\n* I have tried both on demand and spot with no decrease in spin up time.  \n\nFrom what I understand, a pool works by distributing workloads across different clusters based on what is and is not available.  I get the feeling there is something I am fundamentally not getting with how pools work.  \n\nShould I be seeing these clusters not spin up at all when a pool is called despite being attached to a pool?\n\nIs this the right approach to decreasing cluster spin up time in Databricks?\n\nThank you!", "author_fullname": "t2_2gp1vrnw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks pools - attached clusters not spinning up. Is this expected behaviour?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y1zkau", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665568040.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in Azure Databricks and I&amp;#39;m trying to increase the frequency at which an ADF pipeline can be run from daily to hourly.  This ADF pipeline has a Databricks connector as part of it because it accepts values from a control table and runs both dynamically and in parallel.  This can take around 20 minutes to run using a single cluster.  &lt;/p&gt;\n\n&lt;p&gt;The step I&amp;#39;m trying to overcome right now is the spin up time for said cluster, so I found pools.  But, being really honest, not quite sure how these work and no matter what I&amp;#39;ve tried, the execution time barely improves.&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;ve tried and questions:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;I&amp;#39;ve created the linked service which calls the pool rather than the cluster.  This seems to be working fine.  I&amp;#39;m using the Standard_f8 compute optimised, 16GB, 8 cores instance.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Created a Databricks pool and attached clusters to it.  For some strange reason, when the ADF pipeline begins adding jobs, the clusters don&amp;#39;t spin up and remain in a terminated state.  Is this expected behaviour?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;For the pool, I have set the min idle to be 0.  Ideally, I&amp;#39;d have this pool kick off, have the clusters be ready to go for 8 hours per day, and then spin itself down overnight.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I have tried both on demand and spot with no decrease in spin up time.  &lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;From what I understand, a pool works by distributing workloads across different clusters based on what is and is not available.  I get the feeling there is something I am fundamentally not getting with how pools work.  &lt;/p&gt;\n\n&lt;p&gt;Should I be seeing these clusters not spin up at all when a pool is called despite being attached to a pool?&lt;/p&gt;\n\n&lt;p&gt;Is this the right approach to decreasing cluster spin up time in Databricks?&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Shitty Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y1zkau", "is_robot_indexable": true, "report_reasons": null, "author": "MikeDoesEverything", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/y1zkau/databricks_pools_attached_clusters_not_spinning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y1zkau/databricks_pools_attached_clusters_not_spinning/", "subreddit_subscribers": 76250, "created_utc": 1665568040.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone. I am working on linking SalesForce to one of my Data Factories. I followed all the Microsoft guidelines and after clearing up a few error messages when I go to test the connection it spins for a few minutes and throws a timeout error with no other details. Has anyone had something similar happen? This doesn\u2019t appear to be an Azure side issue and my credentials are correct for SalesForce. I can\u2019t help but think there\u2019s a permission somewhere I missed but I\u2019m drawing blanks. Let me know if anyone has any ideas.", "author_fullname": "t2_326jvb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Factory SalesForce Linked Service Integration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y2kmzo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665621675.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone. I am working on linking SalesForce to one of my Data Factories. I followed all the Microsoft guidelines and after clearing up a few error messages when I go to test the connection it spins for a few minutes and throws a timeout error with no other details. Has anyone had something similar happen? This doesn\u2019t appear to be an Azure side issue and my credentials are correct for SalesForce. I can\u2019t help but think there\u2019s a permission somewhere I missed but I\u2019m drawing blanks. Let me know if anyone has any ideas.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y2kmzo", "is_robot_indexable": true, "report_reasons": null, "author": "ShouldHaveWentBio", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y2kmzo/data_factory_salesforce_linked_service_integration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y2kmzo/data_factory_salesforce_linked_service_integration/", "subreddit_subscribers": 76250, "created_utc": 1665621675.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey y\u2019all! \n\nMy team and I are working on building a pipeline to migrate data from an Oracle database residing on a non-AWS cloud to AWS RDS. \n\nAny tool recommendations? We have already looked into AWS RDS, but I\u2019m wondering if there\u2019s a native tool that\u2019ll work better than that.", "author_fullname": "t2_78dddb58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ideas on cloud Oracle migration tools to AWS RDS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y2691z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665586897.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey y\u2019all! &lt;/p&gt;\n\n&lt;p&gt;My team and I are working on building a pipeline to migrate data from an Oracle database residing on a non-AWS cloud to AWS RDS. &lt;/p&gt;\n\n&lt;p&gt;Any tool recommendations? We have already looked into AWS RDS, but I\u2019m wondering if there\u2019s a native tool that\u2019ll work better than that.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y2691z", "is_robot_indexable": true, "report_reasons": null, "author": "Both-Trainer-1308", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y2691z/ideas_on_cloud_oracle_migration_tools_to_aws_rds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y2691z/ideas_on_cloud_oracle_migration_tools_to_aws_rds/", "subreddit_subscribers": 76250, "created_utc": 1665586897.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**TL;DR:** Open discussion on the dbt semantic/metrics layer.\n\nLast year Drew Banin, co-founder of dbt labs, [gave a talk on the metrics layer and dbt](https://www.getdbt.com/coalesce-2021/keynote-the-metrics-system/).  \nThat got me curious, thinking where dbt will take this. As time went by they released more information and their view on the topic.  \n\n\nDrew recently wrote [another post](https://www.getdbt.com/blog/dbt-semantic-layer/) on the metrics layer. This time the blog included a lot more details. I found that the fact that dbt are adding an additional server is interesting. It seems like this is the first time that dbt forces users to use dbt-cloud to use this feature. The server is meant to translate \"dbt-sql\" on the fly. I.e the server will be a gateway between applications and the data warehouse.\n\n    select *\n    from {{ metrics.calculate(\n        metric('dbt_cloud_weekly_active_users'),\n        dimensions=['country'],\n        grain='day' ) }}\n\nI believe that this approach will be problematic. There are quite a few companies that use dbt-core with other infrastructure (e.g AirFlow/dbt/BigQuery). These companies will either have to avoid the dbt metrics feature or migrate to dbt cloud.\n\nI would love to hear your thoughts on this subject. Do you think this direction makes sense for dbt? \n\n  \nFor reference the following companies are also working on similar solutions (not dbt bound though):  \n\\- [https://cube.dev/](https://cube.dev/)  \n\\- [https://transform.co/](https://transform.co/)  \nI'm sure there are more, feel free to comment with more companies if relevant.\n\nAnother interesting note is that AirBnB Minerva 2.0 is another metrics layer solution that [is expected to be open sourced soon](https://www.youtube.com/watch?v=ksWwdYwXhh0&amp;ab_channel=Databricks).", "author_fullname": "t2_ayp5oyir", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on dbt semantic layer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y21vbv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1665575578.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;TL;DR:&lt;/strong&gt; Open discussion on the dbt semantic/metrics layer.&lt;/p&gt;\n\n&lt;p&gt;Last year Drew Banin, co-founder of dbt labs, &lt;a href=\"https://www.getdbt.com/coalesce-2021/keynote-the-metrics-system/\"&gt;gave a talk on the metrics layer and dbt&lt;/a&gt;.&lt;br/&gt;\nThat got me curious, thinking where dbt will take this. As time went by they released more information and their view on the topic.  &lt;/p&gt;\n\n&lt;p&gt;Drew recently wrote &lt;a href=\"https://www.getdbt.com/blog/dbt-semantic-layer/\"&gt;another post&lt;/a&gt; on the metrics layer. This time the blog included a lot more details. I found that the fact that dbt are adding an additional server is interesting. It seems like this is the first time that dbt forces users to use dbt-cloud to use this feature. The server is meant to translate &amp;quot;dbt-sql&amp;quot; on the fly. I.e the server will be a gateway between applications and the data warehouse.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;select *\nfrom {{ metrics.calculate(\n    metric(&amp;#39;dbt_cloud_weekly_active_users&amp;#39;),\n    dimensions=[&amp;#39;country&amp;#39;],\n    grain=&amp;#39;day&amp;#39; ) }}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I believe that this approach will be problematic. There are quite a few companies that use dbt-core with other infrastructure (e.g AirFlow/dbt/BigQuery). These companies will either have to avoid the dbt metrics feature or migrate to dbt cloud.&lt;/p&gt;\n\n&lt;p&gt;I would love to hear your thoughts on this subject. Do you think this direction makes sense for dbt? &lt;/p&gt;\n\n&lt;p&gt;For reference the following companies are also working on similar solutions (not dbt bound though):&lt;br/&gt;\n- &lt;a href=\"https://cube.dev/\"&gt;https://cube.dev/&lt;/a&gt;&lt;br/&gt;\n- &lt;a href=\"https://transform.co/\"&gt;https://transform.co/&lt;/a&gt;&lt;br/&gt;\nI&amp;#39;m sure there are more, feel free to comment with more companies if relevant.&lt;/p&gt;\n\n&lt;p&gt;Another interesting note is that AirBnB Minerva 2.0 is another metrics layer solution that &lt;a href=\"https://www.youtube.com/watch?v=ksWwdYwXhh0&amp;amp;ab_channel=Databricks\"&gt;is expected to be open sourced soon&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZtXtwr-MU0uJMWStzwnNfFnNqpbDZIEYEcSS42tJrRQ.jpg?auto=webp&amp;s=dfc29c57589489096a4172be53a7237f8e720649", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/ZtXtwr-MU0uJMWStzwnNfFnNqpbDZIEYEcSS42tJrRQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=83e6030b4172723c3902545e997edee3e930e50b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/ZtXtwr-MU0uJMWStzwnNfFnNqpbDZIEYEcSS42tJrRQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a44afdb7aed4b0db8a8ecc89b53fd218ea9da9b9", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/ZtXtwr-MU0uJMWStzwnNfFnNqpbDZIEYEcSS42tJrRQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a8d6d3f9ace8a844df49ae9ff0a4ff1f41fef6e4", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/ZtXtwr-MU0uJMWStzwnNfFnNqpbDZIEYEcSS42tJrRQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f07025ee9435d59b059999381d5064c5c9a9a698", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/ZtXtwr-MU0uJMWStzwnNfFnNqpbDZIEYEcSS42tJrRQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6fb6989c7570cf2ccbd01ccf6f06e4c0d967750f", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/ZtXtwr-MU0uJMWStzwnNfFnNqpbDZIEYEcSS42tJrRQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c83abae37378fe05150706ae68c21dc8d194e4bc", "width": 1080, "height": 565}], "variants": {}, "id": "jVsOAHLBrwfbtrK38DWITA6Aj8-KgJYuBOuRaB8V9Z8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y21vbv", "is_robot_indexable": true, "report_reasons": null, "author": "Puzzleheaded_Dog_614", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y21vbv/thoughts_on_dbt_semantic_layer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y21vbv/thoughts_on_dbt_semantic_layer/", "subreddit_subscribers": 76250, "created_utc": 1665575578.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Starting a project with GCS, Bigquery and Looker Studio (hate the new name) and wondering thoughts on switching plans from dbt to dataform. Haven't started transforms yet.\n\nUsing contractors.", "author_fullname": "t2_4d8caxd5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dataform re-released - reconsider dbt?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y1t5oi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665546061.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Starting a project with GCS, Bigquery and Looker Studio (hate the new name) and wondering thoughts on switching plans from dbt to dataform. Haven&amp;#39;t started transforms yet.&lt;/p&gt;\n\n&lt;p&gt;Using contractors.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y1t5oi", "is_robot_indexable": true, "report_reasons": null, "author": "realistdreamer69", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y1t5oi/dataform_rereleased_reconsider_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y1t5oi/dataform_rereleased_reconsider_dbt/", "subreddit_subscribers": 76250, "created_utc": 1665546061.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hi, so I graduated last year with a bs in finance and pretty much worked retail since and never had an internship in finance. I had a job offer as analyst at a bulge bracket bank this year and completely turned it down and realized traditional finance is not what I wanted to do. After researching roles and such I really liked BI &amp; data engineering. Thinking data engineering may be the better path to pursue for job growth.\n\nJust wondering what I would need to do to be successful in a switch. I may plan on going back to school next year to pursue an MSCS or MS in data science. But really focused on being a self learner at the moment and building my own knowledge and experience. \n\nI want to create a data engineering portfolio and work on my own projects by 2023 as well. I know SQL and plan to pick up python starting this week.\n\nAny project tips/portfolio help? Where do you recommend I keep my online portfolio?\n\nBest way to learn python as a newbie?\n\nBooks, YouTube channels, &amp; any other free resources you would like to recommend?\n\nSo far using datacamp\u2019s path to becoming a data engineer \n\nThank you", "author_fullname": "t2_k9d12ch2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "career change help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y2f6df", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1665611531.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665607982.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hi, so I graduated last year with a bs in finance and pretty much worked retail since and never had an internship in finance. I had a job offer as analyst at a bulge bracket bank this year and completely turned it down and realized traditional finance is not what I wanted to do. After researching roles and such I really liked BI &amp;amp; data engineering. Thinking data engineering may be the better path to pursue for job growth.&lt;/p&gt;\n\n&lt;p&gt;Just wondering what I would need to do to be successful in a switch. I may plan on going back to school next year to pursue an MSCS or MS in data science. But really focused on being a self learner at the moment and building my own knowledge and experience. &lt;/p&gt;\n\n&lt;p&gt;I want to create a data engineering portfolio and work on my own projects by 2023 as well. I know SQL and plan to pick up python starting this week.&lt;/p&gt;\n\n&lt;p&gt;Any project tips/portfolio help? Where do you recommend I keep my online portfolio?&lt;/p&gt;\n\n&lt;p&gt;Best way to learn python as a newbie?&lt;/p&gt;\n\n&lt;p&gt;Books, YouTube channels, &amp;amp; any other free resources you would like to recommend?&lt;/p&gt;\n\n&lt;p&gt;So far using datacamp\u2019s path to becoming a data engineer &lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "y2f6df", "is_robot_indexable": true, "report_reasons": null, "author": "uaintgotnoyzy", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y2f6df/career_change_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y2f6df/career_change_help/", "subreddit_subscribers": 76250, "created_utc": 1665607982.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I currently part of data team on a retail company on migration, and I want to focus on a dataops roll that cover some technical areas but idk where start\n\nActually this is my first experience on IT so I need the basic to pro stuff or roadmap to start\n\nI reading some books like fundamental of data Engineer  and some blogs like dataops cookbook from data kitchen's  is my next read\n\n\nAny resources to learn dataops?? Or specific tools \nSorry for my bad ingles", "author_fullname": "t2_9pzeqq4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dataops from pm", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y27odn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665590318.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently part of data team on a retail company on migration, and I want to focus on a dataops roll that cover some technical areas but idk where start&lt;/p&gt;\n\n&lt;p&gt;Actually this is my first experience on IT so I need the basic to pro stuff or roadmap to start&lt;/p&gt;\n\n&lt;p&gt;I reading some books like fundamental of data Engineer  and some blogs like dataops cookbook from data kitchen&amp;#39;s  is my next read&lt;/p&gt;\n\n&lt;p&gt;Any resources to learn dataops?? Or specific tools \nSorry for my bad ingles&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "y27odn", "is_robot_indexable": true, "report_reasons": null, "author": "Icy_Cricket_779", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y27odn/dataops_from_pm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y27odn/dataops_from_pm/", "subreddit_subscribers": 76250, "created_utc": 1665590318.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Databases implement materialized views differently. My understanding of how Postgres implements a materialized view is that it builds a cached version of the view results and then refreshes them when the \"refresh materialized view\" statement is used.\n\nGiven that, what advantages does this provide over a drop/create table?\n\nHere's what I can think of, are there others?\n\n* Dependancies retain relationships. This wouldn't be possible with drop/create.\n* Data is always available. There's no moment in time where you may be referencing the view and the data isn't there like there is with a drop/create.", "author_fullname": "t2_roqmtvoh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any Advantage to Using Postgres Materialized Views vs Tables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y24bym", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665582171.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Databases implement materialized views differently. My understanding of how Postgres implements a materialized view is that it builds a cached version of the view results and then refreshes them when the &amp;quot;refresh materialized view&amp;quot; statement is used.&lt;/p&gt;\n\n&lt;p&gt;Given that, what advantages does this provide over a drop/create table?&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s what I can think of, are there others?&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Dependancies retain relationships. This wouldn&amp;#39;t be possible with drop/create.&lt;/li&gt;\n&lt;li&gt;Data is always available. There&amp;#39;s no moment in time where you may be referencing the view and the data isn&amp;#39;t there like there is with a drop/create.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y24bym", "is_robot_indexable": true, "report_reasons": null, "author": "goatslikelawns", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y24bym/any_advantage_to_using_postgres_materialized/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y24bym/any_advantage_to_using_postgres_materialized/", "subreddit_subscribers": 76250, "created_utc": 1665582171.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How can I clean up city and postcode/zipcodes in a db. We have pretty shit unclean cities/postcodes and would like to clean using sql. We would this be a macros etc. recommendations please.", "author_fullname": "t2_t1crgsxs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to clean up City and Zipcode/Postcode?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y2cxkv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665602724.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How can I clean up city and postcode/zipcodes in a db. We have pretty shit unclean cities/postcodes and would like to clean using sql. We would this be a macros etc. recommendations please.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y2cxkv", "is_robot_indexable": true, "report_reasons": null, "author": "throwme-ariver", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y2cxkv/how_to_clean_up_city_and_zipcodepostcode/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y2cxkv/how_to_clean_up_city_and_zipcodepostcode/", "subreddit_subscribers": 76250, "created_utc": 1665602724.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello my name is Kevin and I am researching DataOps requirements for long established companies in my master thesis .\n\nIt would be highly appreciated if you could take a few minutes to answer the following survey.\n\n[https://www.survio.com/survey/d/C8E2A1E8Z8A8F7Q6J](https://www.survio.com/survey/d/C8E2A1E8Z8A8F7Q6J)\n\nFor every participant who completes the survey, I will donate 1 USD (up to 250 USD total) to non-profit orginasations!\n\nThank you very much!\n\nAnd sorry for reposting it in several channels :/ :)\n\nPS: The data will of course be collected anonymously and made open source available.\n\nPPS: Feel free to send feedback via email to: kevin.haferkamp001\\[at\\]stud.fh-dortmund.de", "author_fullname": "t2_5x4osqvy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Survey for my master thesis researching requirements for DataOps", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y26z6a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1665588628.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello my name is Kevin and I am researching DataOps requirements for long established companies in my master thesis .&lt;/p&gt;\n\n&lt;p&gt;It would be highly appreciated if you could take a few minutes to answer the following survey.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.survio.com/survey/d/C8E2A1E8Z8A8F7Q6J\"&gt;https://www.survio.com/survey/d/C8E2A1E8Z8A8F7Q6J&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;For every participant who completes the survey, I will donate 1 USD (up to 250 USD total) to non-profit orginasations!&lt;/p&gt;\n\n&lt;p&gt;Thank you very much!&lt;/p&gt;\n\n&lt;p&gt;And sorry for reposting it in several channels :/ :)&lt;/p&gt;\n\n&lt;p&gt;PS: The data will of course be collected anonymously and made open source available.&lt;/p&gt;\n\n&lt;p&gt;PPS: Feel free to send feedback via email to: kevin.haferkamp001[at]stud.fh-dortmund.de&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZyqcBI8AbuLGZanb_6IB7MAlXzV91s2nG4HXUJtUv7o.jpg?auto=webp&amp;s=1e087b87112002c59b1ebd8c0eb159786d0df0c6", "width": 1080, "height": 568}, "resolutions": [{"url": "https://external-preview.redd.it/ZyqcBI8AbuLGZanb_6IB7MAlXzV91s2nG4HXUJtUv7o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=020413bf8b4e8e9797ef349a4f34bae4fb3c8810", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/ZyqcBI8AbuLGZanb_6IB7MAlXzV91s2nG4HXUJtUv7o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d4ef4b280d22eda5f07b71ae61a9a3621587e7c5", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/ZyqcBI8AbuLGZanb_6IB7MAlXzV91s2nG4HXUJtUv7o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e135a5f19a6434878d48639dc191b6b0c76ab9f4", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/ZyqcBI8AbuLGZanb_6IB7MAlXzV91s2nG4HXUJtUv7o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=dfc11c5f3b8c851d06f497858db799c74e2e7825", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/ZyqcBI8AbuLGZanb_6IB7MAlXzV91s2nG4HXUJtUv7o.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ee18e1089cda68d44ffcd9293bd0d1128e5f25e8", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/ZyqcBI8AbuLGZanb_6IB7MAlXzV91s2nG4HXUJtUv7o.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8717d4d176d398ad9ce10f65d3298b3fc1a427d1", "width": 1080, "height": 568}], "variants": {}, "id": "SLrlrRC8ZiSJm8LQFtEyZBxll7XimBa4aHiYcbWt7pI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y26z6a", "is_robot_indexable": true, "report_reasons": null, "author": "khaferkamp", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y26z6a/survey_for_my_master_thesis_researching/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y26z6a/survey_for_my_master_thesis_researching/", "subreddit_subscribers": 76250, "created_utc": 1665588628.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We're starting to move our applications from SSIS to ADF and Databricks. I'm going to end up doing most of the work and so the first thing that I want to do is setup our environment variables.\n\nWe use the environment variables in SSIS to store our connection information. That way the Dev environment only has the connection information to the Dev resources. Then when the SSIS package is run, it points to the Dev DB, Dev FTP, etc. Likewise for PPR and PRD. The variables can include an address, username, PW, token, private key, etc.\n\nMy question is, are there best practices about doing this in Azure? My first thought was to use the Data Vault, and to connect from each application to get the login info. But is it appropriate to use the Data Vault for this? Also, is it possible to have the Data Vault have the same name in each environment? Otherwise, our code would have to be in each environment to know which vault to call, right?", "author_fullname": "t2_8u4k0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practices for ADF and Databricks for Environment variables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y255cl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665584246.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;re starting to move our applications from SSIS to ADF and Databricks. I&amp;#39;m going to end up doing most of the work and so the first thing that I want to do is setup our environment variables.&lt;/p&gt;\n\n&lt;p&gt;We use the environment variables in SSIS to store our connection information. That way the Dev environment only has the connection information to the Dev resources. Then when the SSIS package is run, it points to the Dev DB, Dev FTP, etc. Likewise for PPR and PRD. The variables can include an address, username, PW, token, private key, etc.&lt;/p&gt;\n\n&lt;p&gt;My question is, are there best practices about doing this in Azure? My first thought was to use the Data Vault, and to connect from each application to get the login info. But is it appropriate to use the Data Vault for this? Also, is it possible to have the Data Vault have the same name in each environment? Otherwise, our code would have to be in each environment to know which vault to call, right?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y255cl", "is_robot_indexable": true, "report_reasons": null, "author": "yoelbenyossef", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y255cl/best_practices_for_adf_and_databricks_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y255cl/best_practices_for_adf_and_databricks_for/", "subreddit_subscribers": 76250, "created_utc": 1665584246.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have an extremely large Hive table that stores e-commerce data for multiple stores.\n\nThis table has one row per sale. Each row included the store Id, the buyer Id and information about the order such as the order amount and date. \n\nI\u2019d like to run a pipeline that uses this order data to create cohort groups out of these customers. \n\nI think the most useful way for this data to be represented is one row per storeId, buyerId combination with a column that has an array of all of the orders between that buyer and store (order history).  \n\nThen I\u2019d like to run 12 different cohorting jobs that each query this table for the same data. \n\nI\u2019m wondering what query pattern I can use so this can be done efficiently because each of these jobs takes 2 hours and I\u2019d like to complete all 12 within a few hours and preferably in parallel.", "author_fullname": "t2_9n9rgzkc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help solve this challenge for ingesting big data from massive table", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y1vpru", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665554252.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an extremely large Hive table that stores e-commerce data for multiple stores.&lt;/p&gt;\n\n&lt;p&gt;This table has one row per sale. Each row included the store Id, the buyer Id and information about the order such as the order amount and date. &lt;/p&gt;\n\n&lt;p&gt;I\u2019d like to run a pipeline that uses this order data to create cohort groups out of these customers. &lt;/p&gt;\n\n&lt;p&gt;I think the most useful way for this data to be represented is one row per storeId, buyerId combination with a column that has an array of all of the orders between that buyer and store (order history).  &lt;/p&gt;\n\n&lt;p&gt;Then I\u2019d like to run 12 different cohorting jobs that each query this table for the same data. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m wondering what query pattern I can use so this can be done efficiently because each of these jobs takes 2 hours and I\u2019d like to complete all 12 within a few hours and preferably in parallel.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y1vpru", "is_robot_indexable": true, "report_reasons": null, "author": "Agentdoubleo97", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y1vpru/help_solve_this_challenge_for_ingesting_big_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y1vpru/help_solve_this_challenge_for_ingesting_big_data/", "subreddit_subscribers": 76250, "created_utc": 1665554252.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Wondering what the key difference is between the three, I hear a lot from fellow colleagues that its very different but when I do my research on it they seem quite similar in their responsibilities with client side (front end) being design/navigation, writing code and debugging and service side (back end) being more data application development?\n\nWould love some perspective on it and whether they are in fact different ends of the data spectrum!", "author_fullname": "t2_swx1rmld", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question: Difference Between Data Engineers, Developers and UX/UX Designer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_y2n2wa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665628542.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wondering what the key difference is between the three, I hear a lot from fellow colleagues that its very different but when I do my research on it they seem quite similar in their responsibilities with client side (front end) being design/navigation, writing code and debugging and service side (back end) being more data application development?&lt;/p&gt;\n\n&lt;p&gt;Would love some perspective on it and whether they are in fact different ends of the data spectrum!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y2n2wa", "is_robot_indexable": true, "report_reasons": null, "author": "TheOpportunist01", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y2n2wa/question_difference_between_data_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y2n2wa/question_difference_between_data_engineers/", "subreddit_subscribers": 76250, "created_utc": 1665628542.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\nhttps://preview.redd.it/tg7lx0g0ret91.png?width=980&amp;format=png&amp;auto=webp&amp;s=72911ca09809b6a3c194eb4df0e080e4ba55dc2c\n\n&amp;#x200B;\n\nhttps://preview.redd.it/yxskt8k7ret91.png?width=888&amp;format=png&amp;auto=webp&amp;s=be28ac397bd91eafadb8cc318bf2ad9df2b2de8a", "author_fullname": "t2_bvkm0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Schemas &amp; Data Contracts\u2026", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "media_metadata": {"tg7lx0g0ret91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 71, "x": 108, "u": "https://preview.redd.it/tg7lx0g0ret91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=740b642be35fcfbcbfbc7896be3117fe234efa5a"}, {"y": 143, "x": 216, "u": "https://preview.redd.it/tg7lx0g0ret91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6f96dee3c5551d6326129a740f437aac010efbeb"}, {"y": 212, "x": 320, "u": "https://preview.redd.it/tg7lx0g0ret91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=0ed982c8d02435d9fa1917959a3b0d7682ddf914"}, {"y": 425, "x": 640, "u": "https://preview.redd.it/tg7lx0g0ret91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=aeef012f5beb326a2ec0498286c4d33bb329df78"}, {"y": 638, "x": 960, "u": "https://preview.redd.it/tg7lx0g0ret91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=cda17644cdaedb33cbe7dc534ea6707de89fb25a"}], "s": {"y": 652, "x": 980, "u": "https://preview.redd.it/tg7lx0g0ret91.png?width=980&amp;format=png&amp;auto=webp&amp;s=72911ca09809b6a3c194eb4df0e080e4ba55dc2c"}, "id": "tg7lx0g0ret91"}, "yxskt8k7ret91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/yxskt8k7ret91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=302e8a13e98daf0b9e7594d5b62bb655e0294260"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/yxskt8k7ret91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=be040a3c7a55a5642fdc6ba3e7b5eb5ed4c589cc"}, {"y": 179, "x": 320, "u": "https://preview.redd.it/yxskt8k7ret91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=6b936d06b9995ba6c4d84a70189b2c4d358ad255"}, {"y": 359, "x": 640, "u": "https://preview.redd.it/yxskt8k7ret91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d653b28d050324a661d3174c6da8d63e6cc1dc89"}], "s": {"y": 499, "x": 888, "u": "https://preview.redd.it/yxskt8k7ret91.png?width=888&amp;format=png&amp;auto=webp&amp;s=be28ac397bd91eafadb8cc318bf2ad9df2b2de8a"}, "id": "yxskt8k7ret91"}}, "name": "t3_y29nlu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/9AnY0-J2MwRjr9-wiI_Ieq8nnl1AcoeT-0J0PYrbuLs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665594888.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/tg7lx0g0ret91.png?width=980&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=72911ca09809b6a3c194eb4df0e080e4ba55dc2c\"&gt;https://preview.redd.it/tg7lx0g0ret91.png?width=980&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=72911ca09809b6a3c194eb4df0e080e4ba55dc2c&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/yxskt8k7ret91.png?width=888&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=be28ac397bd91eafadb8cc318bf2ad9df2b2de8a\"&gt;https://preview.redd.it/yxskt8k7ret91.png?width=888&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=be28ac397bd91eafadb8cc318bf2ad9df2b2de8a&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "y29nlu", "is_robot_indexable": true, "report_reasons": null, "author": "rmoff", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y29nlu/schemas_data_contracts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y29nlu/schemas_data_contracts/", "subreddit_subscribers": 76250, "created_utc": 1665594888.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}