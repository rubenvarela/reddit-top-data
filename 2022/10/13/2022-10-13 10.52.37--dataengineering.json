{"kind": "Listing", "data": {"after": null, "dist": 20, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_h30vc65", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What\u2019s your process for deploying a data pipeline from a notebook, running it, and managing it in production?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_y2bl65", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "ups": 279, "domain": "i.redd.it", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 279, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/RroEsmI7CJi1Jay3z_IgPGAUtA7a54WP5JTv3MRwsP0.jpg", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1665599540.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/pq04w47z4ft91.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/pq04w47z4ft91.jpg?auto=webp&amp;s=60c30264e541d7e8eebe102734a42bb4264850b2", "width": 500, "height": 585}, "resolutions": [{"url": "https://preview.redd.it/pq04w47z4ft91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d83cc0f1f5a4e715ab30e00387bf6d1db27e0e5d", "width": 108, "height": 126}, {"url": "https://preview.redd.it/pq04w47z4ft91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2c38d6c3bbbc2e8e3f20a4525872acba72a16c01", "width": 216, "height": 252}, {"url": "https://preview.redd.it/pq04w47z4ft91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4e0ce26b863772d37918629d7050bcabe32cc416", "width": 320, "height": 374}], "variants": {}, "id": "pqAyKsDleORYu-ooOQsVqG1tMO87jQIXYM7Is2K6-3w"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y2bl65", "is_robot_indexable": true, "report_reasons": null, "author": "jnkwok", "discussion_type": null, "num_comments": 101, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y2bl65/whats_your_process_for_deploying_a_data_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/pq04w47z4ft91.jpg", "subreddit_subscribers": 76290, "created_utc": 1665599540.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I would say I am still in the early years of being a data engineer and there is so much to learn. But lurking in this subreddit has helped me learn new tools, techniques, best practices, and so much more. So thanks to everyone that contributes in this subreddit. To those that give helpful advice to someone that may have asked the same question 100x. This subreddit has been like a free mentoring program at times!", "author_fullname": "t2_awlj3rif", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thanks to everyone here that contributes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y2mdxi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 69, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 69, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665626547.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would say I am still in the early years of being a data engineer and there is so much to learn. But lurking in this subreddit has helped me learn new tools, techniques, best practices, and so much more. So thanks to everyone that contributes in this subreddit. To those that give helpful advice to someone that may have asked the same question 100x. This subreddit has been like a free mentoring program at times!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 150, "id": "award_c42dc561-0b41-40b6-a23d-ef7e110e739e", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/zc4a9vk5zmc51_BuffDoge.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/zc4a9vk5zmc51_BuffDoge.png?width=16&amp;height=16&amp;auto=webp&amp;s=18383f4034d47b396b314c033c7d5e9be96df785", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/zc4a9vk5zmc51_BuffDoge.png?width=32&amp;height=32&amp;auto=webp&amp;s=3ed8a934f66150002b39c40f1863f101fba5a8bf", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/zc4a9vk5zmc51_BuffDoge.png?width=48&amp;height=48&amp;auto=webp&amp;s=f10a2d3469f32ce0351da34e234a9955f80f7c1d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/zc4a9vk5zmc51_BuffDoge.png?width=64&amp;height=64&amp;auto=webp&amp;s=2e13b802594180e56037df3d51520b43a0462a29", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/zc4a9vk5zmc51_BuffDoge.png?width=128&amp;height=128&amp;auto=webp&amp;s=79d3a9614f27e2d922c52137caeb06f2bdb33cc5", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "So buff, wow", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Buff Doge", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/zc4a9vk5zmc51_BuffDoge.png?width=16&amp;height=16&amp;auto=webp&amp;s=18383f4034d47b396b314c033c7d5e9be96df785", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/zc4a9vk5zmc51_BuffDoge.png?width=32&amp;height=32&amp;auto=webp&amp;s=3ed8a934f66150002b39c40f1863f101fba5a8bf", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/zc4a9vk5zmc51_BuffDoge.png?width=48&amp;height=48&amp;auto=webp&amp;s=f10a2d3469f32ce0351da34e234a9955f80f7c1d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/zc4a9vk5zmc51_BuffDoge.png?width=64&amp;height=64&amp;auto=webp&amp;s=2e13b802594180e56037df3d51520b43a0462a29", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/zc4a9vk5zmc51_BuffDoge.png?width=128&amp;height=128&amp;auto=webp&amp;s=79d3a9614f27e2d922c52137caeb06f2bdb33cc5", "width": 128, "height": 128}], "icon_format": "PNG", "icon_height": 2048, "penny_price": 0, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/zc4a9vk5zmc51_BuffDoge.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y2mdxi", "is_robot_indexable": true, "report_reasons": null, "author": "darthsatoshious", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y2mdxi/thanks_to_everyone_here_that_contributes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y2mdxi/thanks_to_everyone_here_that_contributes/", "subreddit_subscribers": 76290, "created_utc": 1665626547.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nMy company uses Flyway and we currently keep track of data and schema changes. Here's my simple question: could this be done differently? What do you guys use at your company? Do you just take regular dumps/snapshots? Do you use other tools? Do you keep track of both data and schema?\n\nMany thanks", "author_fullname": "t2_17f8xf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Database version control: how do you do it at your company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y26s3q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665588159.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;My company uses Flyway and we currently keep track of data and schema changes. Here&amp;#39;s my simple question: could this be done differently? What do you guys use at your company? Do you just take regular dumps/snapshots? Do you use other tools? Do you keep track of both data and schema?&lt;/p&gt;\n\n&lt;p&gt;Many thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 30, "id": "award_b4ff447e-05a5-42dc-9002-63568807cfe6", "penny_donate": null, "award_sub_type": "PREMIUM", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_512.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_128.png", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "A glowing commendation for all to see", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "All-Seeing Upvote", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=16&amp;height=16&amp;auto=webp&amp;s=978c93744e53b8c9305467a7be792e5c401eac6c", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=32&amp;height=32&amp;auto=webp&amp;s=d2ee343eef5048ad3add75d4a4d4e3922bb9565a", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=48&amp;height=48&amp;auto=webp&amp;s=7d216fd3a05c61d9fb75b27092844c546d958f14", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=64&amp;height=64&amp;auto=webp&amp;s=b76693f84fd19b04d0c0444a9812d812105e2d8f", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=128&amp;height=128&amp;auto=webp&amp;s=5353352ae9f443c353ef0b7725dabcfc1b3829a5", "width": 128, "height": 128}], "icon_format": "APNG", "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y26s3q", "is_robot_indexable": true, "report_reasons": null, "author": "goglobal01", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y26s3q/database_version_control_how_do_you_do_it_at_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y26s3q/database_version_control_how_do_you_do_it_at_your/", "subreddit_subscribers": 76290, "created_utc": 1665588159.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello!\n\nI've been trying to learn about data engineering concepts recently through the help of this subreddit and the data engineering Zoom-Camp. I'm really happy to say I finished putting together my first functioning DE project (really my first project ever :) ) and wanted to share to celebrate/ get feedback!\n\n[Fit-pipe DE Project](https://github.com/rickyriled/data_engineering_project_1)\n\nThe goal of this project was to just get the various technologies I was learning about interconnected, and to pull in/transform some simple data that I found interesting with them -- specifically, my fit-bit heart rate data!\n\nIn short, terraform was used to build a data lake in GCS, and then I scheduled regular batch jobs through a prefect DAG to pull in my fitbit data, transform it with PySpark, and then push the updated data to the cloud. From there I just made a really simple visualization to test if things were working on google data studios.\n\nhttps://preview.redd.it/24wnijf2mit91.png?width=1566&amp;format=png&amp;auto=webp&amp;s=b9b48e19ac442b5070c0fe07e1dd4fb17b20f3d1\n\nUltimately there were a few things I left out due to issues with my local environment/ a lack of computing power; e.g. airflow running in docker was too computationally heavy for my MacBook air, so I switched to prefect; and various python dependency issues held me back from connecting to big query and developing a data warehouse to pull from.\n\nIn the future, I wan't to try and more appropriately use PySpark for data transforming, as I ultimately used very little of what the tool has to offer. Additionally, though I didn't use it, the various difficulties I had setting up my environment taught me the value of docker containers.\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nI wanted to give a shout out to some of the repos that I found help in/ drew inspiration from too:\n\n[MarcosMJD Global Historical Climatology Pipeline](https://github.com/MarcosMJD/ghcn-d)\n\n[ris-tlp adiophile-e2e-pipeline](https://github.com/ris-tlp/audiophile-e2e-pipeline)\n\n[Data Engineering Zoom Camp](https://github.com/DataTalksClub/data-engineering-zoomcamp)\n\n&amp;#x200B;\n\nCheers!", "author_fullname": "t2_80ytrhvd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Celebrating my first Data Engineering Project -- Fitbit data with PySpark, GCP, prefect, and terraform!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "media_metadata": {"24wnijf2mit91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 37, "x": 108, "u": "https://preview.redd.it/24wnijf2mit91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9f5712caf69cf55c9d250ce00a4e197b17435043"}, {"y": 74, "x": 216, "u": "https://preview.redd.it/24wnijf2mit91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=29d38fc531ae4bcb09f80242e0a8ac8dd8e7a16c"}, {"y": 110, "x": 320, "u": "https://preview.redd.it/24wnijf2mit91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ed9358c28552d48d02e73ba04589f7ef2b96e1f3"}, {"y": 220, "x": 640, "u": "https://preview.redd.it/24wnijf2mit91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=fa32f6a2d6bc4253618c69f49e444f5ae0dddb74"}, {"y": 330, "x": 960, "u": "https://preview.redd.it/24wnijf2mit91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=dd9372d2f809a7365cba9ad0bb0efb1d96e45d39"}, {"y": 371, "x": 1080, "u": "https://preview.redd.it/24wnijf2mit91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=804e85bf3317afa8072e5bb08800c6ab8a7fa4e6"}], "s": {"y": 539, "x": 1566, "u": "https://preview.redd.it/24wnijf2mit91.png?width=1566&amp;format=png&amp;auto=webp&amp;s=b9b48e19ac442b5070c0fe07e1dd4fb17b20f3d1"}, "id": "24wnijf2mit91"}}, "name": "t3_y2r6ml", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/jckCG1C4PU8f16IRNFsRSCqF4KQqZ2Nl5Bv4smqe-So.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1665641787.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been trying to learn about data engineering concepts recently through the help of this subreddit and the data engineering Zoom-Camp. I&amp;#39;m really happy to say I finished putting together my first functioning DE project (really my first project ever :) ) and wanted to share to celebrate/ get feedback!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/rickyriled/data_engineering_project_1\"&gt;Fit-pipe DE Project&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The goal of this project was to just get the various technologies I was learning about interconnected, and to pull in/transform some simple data that I found interesting with them -- specifically, my fit-bit heart rate data!&lt;/p&gt;\n\n&lt;p&gt;In short, terraform was used to build a data lake in GCS, and then I scheduled regular batch jobs through a prefect DAG to pull in my fitbit data, transform it with PySpark, and then push the updated data to the cloud. From there I just made a really simple visualization to test if things were working on google data studios.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/24wnijf2mit91.png?width=1566&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b9b48e19ac442b5070c0fe07e1dd4fb17b20f3d1\"&gt;https://preview.redd.it/24wnijf2mit91.png?width=1566&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b9b48e19ac442b5070c0fe07e1dd4fb17b20f3d1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Ultimately there were a few things I left out due to issues with my local environment/ a lack of computing power; e.g. airflow running in docker was too computationally heavy for my MacBook air, so I switched to prefect; and various python dependency issues held me back from connecting to big query and developing a data warehouse to pull from.&lt;/p&gt;\n\n&lt;p&gt;In the future, I wan&amp;#39;t to try and more appropriately use PySpark for data transforming, as I ultimately used very little of what the tool has to offer. Additionally, though I didn&amp;#39;t use it, the various difficulties I had setting up my environment taught me the value of docker containers.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I wanted to give a shout out to some of the repos that I found help in/ drew inspiration from too:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/MarcosMJD/ghcn-d\"&gt;MarcosMJD Global Historical Climatology Pipeline&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/ris-tlp/audiophile-e2e-pipeline\"&gt;ris-tlp adiophile-e2e-pipeline&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/DataTalksClub/data-engineering-zoomcamp\"&gt;Data Engineering Zoom Camp&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Cheers!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JDF6yAYdY4PTWbKQSV-h6q1mraVQLk2JzJ364UN3Osc.jpg?auto=webp&amp;s=528a4416b5ed2c1d6173ff5644fbdb37c02851a7", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/JDF6yAYdY4PTWbKQSV-h6q1mraVQLk2JzJ364UN3Osc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=db19bce53481c83f2bce3cba33fda915e2c95703", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/JDF6yAYdY4PTWbKQSV-h6q1mraVQLk2JzJ364UN3Osc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c3d519c1156551e9c504390c44e3211df2f17188", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/JDF6yAYdY4PTWbKQSV-h6q1mraVQLk2JzJ364UN3Osc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2a5af335508ae13100eebf2b5f3accf03ec5f82a", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/JDF6yAYdY4PTWbKQSV-h6q1mraVQLk2JzJ364UN3Osc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6822f3675a8d93cb733439e683ef4b900f01088e", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/JDF6yAYdY4PTWbKQSV-h6q1mraVQLk2JzJ364UN3Osc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8eaa23731c3f81d927e8a458e87e792574ca9a84", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/JDF6yAYdY4PTWbKQSV-h6q1mraVQLk2JzJ364UN3Osc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=defc5b295ac19762e968551b37ab12a70e8cdda7", "width": 1080, "height": 540}], "variants": {}, "id": "GVQ3ewzXsB4P0x4w8oxxnuiipK13XGHiTzNHkkbrHP4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "y2r6ml", "is_robot_indexable": true, "report_reasons": null, "author": "Particular-Bet-1828", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y2r6ml/celebrating_my_first_data_engineering_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y2r6ml/celebrating_my_first_data_engineering_project/", "subreddit_subscribers": 76290, "created_utc": 1665641787.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "From what I see (at least in my city), most of the \"data engineer\" offers that I see are in fact data scientist / analyst jobs, and I really enjoy coding and dont want to do DS. I'm afraid to waste my time trying DE just to realize that I dont code as much as I want. Am I wrong ?", "author_fullname": "t2_qexqkrk6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I get into DE if I enjoy coding ? (DE ~= data science ?)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y2cr28", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665602301.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;From what I see (at least in my city), most of the &amp;quot;data engineer&amp;quot; offers that I see are in fact data scientist / analyst jobs, and I really enjoy coding and dont want to do DS. I&amp;#39;m afraid to waste my time trying DE just to realize that I dont code as much as I want. Am I wrong ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "y2cr28", "is_robot_indexable": true, "report_reasons": null, "author": "165817566995", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y2cr28/should_i_get_into_de_if_i_enjoy_coding_de_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y2cr28/should_i_get_into_de_if_i_enjoy_coding_de_data/", "subreddit_subscribers": 76290, "created_utc": 1665602301.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Planning to build a whole bunch of data pipelines for a new project, which would all be in Python. This is a first for me, as I'm used to creating a simple script or using some GUI based tool. \n\nHow would you structure a Git repo of data pipelines that are all written in Python? Let's say I'm pulling data from 3 different sources, `Apple`, `Banana`, and `Cherry`. Would you have 3 different python files like `apple.py`, `banana.py`, and `cherry.py` all called by `main.py`?\n\nDo you all recommend having a `data` folder as well? I wouldn't publish any data online but for the sake of the repo, should I create a folder?\n\nAny other tips in terms of repo structure and management for data engineering? Would love any and all suggestions!", "author_fullname": "t2_2pyy4c8f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you structure a data pipeline repo?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y22iyt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665577450.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Planning to build a whole bunch of data pipelines for a new project, which would all be in Python. This is a first for me, as I&amp;#39;m used to creating a simple script or using some GUI based tool. &lt;/p&gt;\n\n&lt;p&gt;How would you structure a Git repo of data pipelines that are all written in Python? Let&amp;#39;s say I&amp;#39;m pulling data from 3 different sources, &lt;code&gt;Apple&lt;/code&gt;, &lt;code&gt;Banana&lt;/code&gt;, and &lt;code&gt;Cherry&lt;/code&gt;. Would you have 3 different python files like &lt;code&gt;apple.py&lt;/code&gt;, &lt;code&gt;banana.py&lt;/code&gt;, and &lt;code&gt;cherry.py&lt;/code&gt; all called by &lt;code&gt;main.py&lt;/code&gt;?&lt;/p&gt;\n\n&lt;p&gt;Do you all recommend having a &lt;code&gt;data&lt;/code&gt; folder as well? I wouldn&amp;#39;t publish any data online but for the sake of the repo, should I create a folder?&lt;/p&gt;\n\n&lt;p&gt;Any other tips in terms of repo structure and management for data engineering? Would love any and all suggestions!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y22iyt", "is_robot_indexable": true, "report_reasons": null, "author": "opabm", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y22iyt/how_would_you_structure_a_data_pipeline_repo/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y22iyt/how_would_you_structure_a_data_pipeline_repo/", "subreddit_subscribers": 76290, "created_utc": 1665577450.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**TL;DR:** Open discussion on the dbt semantic/metrics layer.\n\nLast year Drew Banin, co-founder of dbt labs, [gave a talk on the metrics layer and dbt](https://www.getdbt.com/coalesce-2021/keynote-the-metrics-system/).  \nThat got me curious, thinking where dbt will take this. As time went by they released more information and their view on the topic.  \n\n\nDrew recently wrote [another post](https://www.getdbt.com/blog/dbt-semantic-layer/) on the metrics layer. This time the blog included a lot more details. I found that the fact that dbt are adding an additional server is interesting. It seems like this is the first time that dbt forces users to use dbt-cloud to use this feature. The server is meant to translate \"dbt-sql\" on the fly. I.e the server will be a gateway between applications and the data warehouse.\n\n    select *\n    from {{ metrics.calculate(\n        metric('dbt_cloud_weekly_active_users'),\n        dimensions=['country'],\n        grain='day' ) }}\n\nI believe that this approach will be problematic. There are quite a few companies that use dbt-core with other infrastructure (e.g AirFlow/dbt/BigQuery). These companies will either have to avoid the dbt metrics feature or migrate to dbt cloud.\n\nI would love to hear your thoughts on this subject. Do you think this direction makes sense for dbt? \n\n  \nFor reference the following companies are also working on similar solutions (not dbt bound though):  \n\\- [https://cube.dev/](https://cube.dev/)  \n\\- [https://transform.co/](https://transform.co/)  \nI'm sure there are more, feel free to comment with more companies if relevant.\n\nAnother interesting note is that AirBnB Minerva 2.0 is another metrics layer solution that [is expected to be open sourced soon](https://www.youtube.com/watch?v=ksWwdYwXhh0&amp;ab_channel=Databricks).", "author_fullname": "t2_ayp5oyir", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on dbt semantic layer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y21vbv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1665575578.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;TL;DR:&lt;/strong&gt; Open discussion on the dbt semantic/metrics layer.&lt;/p&gt;\n\n&lt;p&gt;Last year Drew Banin, co-founder of dbt labs, &lt;a href=\"https://www.getdbt.com/coalesce-2021/keynote-the-metrics-system/\"&gt;gave a talk on the metrics layer and dbt&lt;/a&gt;.&lt;br/&gt;\nThat got me curious, thinking where dbt will take this. As time went by they released more information and their view on the topic.  &lt;/p&gt;\n\n&lt;p&gt;Drew recently wrote &lt;a href=\"https://www.getdbt.com/blog/dbt-semantic-layer/\"&gt;another post&lt;/a&gt; on the metrics layer. This time the blog included a lot more details. I found that the fact that dbt are adding an additional server is interesting. It seems like this is the first time that dbt forces users to use dbt-cloud to use this feature. The server is meant to translate &amp;quot;dbt-sql&amp;quot; on the fly. I.e the server will be a gateway between applications and the data warehouse.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;select *\nfrom {{ metrics.calculate(\n    metric(&amp;#39;dbt_cloud_weekly_active_users&amp;#39;),\n    dimensions=[&amp;#39;country&amp;#39;],\n    grain=&amp;#39;day&amp;#39; ) }}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I believe that this approach will be problematic. There are quite a few companies that use dbt-core with other infrastructure (e.g AirFlow/dbt/BigQuery). These companies will either have to avoid the dbt metrics feature or migrate to dbt cloud.&lt;/p&gt;\n\n&lt;p&gt;I would love to hear your thoughts on this subject. Do you think this direction makes sense for dbt? &lt;/p&gt;\n\n&lt;p&gt;For reference the following companies are also working on similar solutions (not dbt bound though):&lt;br/&gt;\n- &lt;a href=\"https://cube.dev/\"&gt;https://cube.dev/&lt;/a&gt;&lt;br/&gt;\n- &lt;a href=\"https://transform.co/\"&gt;https://transform.co/&lt;/a&gt;&lt;br/&gt;\nI&amp;#39;m sure there are more, feel free to comment with more companies if relevant.&lt;/p&gt;\n\n&lt;p&gt;Another interesting note is that AirBnB Minerva 2.0 is another metrics layer solution that &lt;a href=\"https://www.youtube.com/watch?v=ksWwdYwXhh0&amp;amp;ab_channel=Databricks\"&gt;is expected to be open sourced soon&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZtXtwr-MU0uJMWStzwnNfFnNqpbDZIEYEcSS42tJrRQ.jpg?auto=webp&amp;s=dfc29c57589489096a4172be53a7237f8e720649", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/ZtXtwr-MU0uJMWStzwnNfFnNqpbDZIEYEcSS42tJrRQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=83e6030b4172723c3902545e997edee3e930e50b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/ZtXtwr-MU0uJMWStzwnNfFnNqpbDZIEYEcSS42tJrRQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a44afdb7aed4b0db8a8ecc89b53fd218ea9da9b9", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/ZtXtwr-MU0uJMWStzwnNfFnNqpbDZIEYEcSS42tJrRQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a8d6d3f9ace8a844df49ae9ff0a4ff1f41fef6e4", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/ZtXtwr-MU0uJMWStzwnNfFnNqpbDZIEYEcSS42tJrRQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f07025ee9435d59b059999381d5064c5c9a9a698", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/ZtXtwr-MU0uJMWStzwnNfFnNqpbDZIEYEcSS42tJrRQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6fb6989c7570cf2ccbd01ccf6f06e4c0d967750f", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/ZtXtwr-MU0uJMWStzwnNfFnNqpbDZIEYEcSS42tJrRQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c83abae37378fe05150706ae68c21dc8d194e4bc", "width": 1080, "height": 565}], "variants": {}, "id": "jVsOAHLBrwfbtrK38DWITA6Aj8-KgJYuBOuRaB8V9Z8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y21vbv", "is_robot_indexable": true, "report_reasons": null, "author": "Puzzleheaded_Dog_614", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y21vbv/thoughts_on_dbt_semantic_layer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y21vbv/thoughts_on_dbt_semantic_layer/", "subreddit_subscribers": 76290, "created_utc": 1665575578.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I am currently taking a data mining course which asks to use PySpark to implement our assignments. Is anyone an expert in PySpark and  would be willing to tutor me? I live in LA so getting in-person tutoring would be great, but I am happy to  do over zoom as well. Happy to negotiate pay. Thank you!", "author_fullname": "t2_iljnct2d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PySpark Tutor", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y2pllu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665636355.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am currently taking a data mining course which asks to use PySpark to implement our assignments. Is anyone an expert in PySpark and  would be willing to tutor me? I live in LA so getting in-person tutoring would be great, but I am happy to  do over zoom as well. Happy to negotiate pay. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y2pllu", "is_robot_indexable": true, "report_reasons": null, "author": "Relative_Practice_93", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y2pllu/pyspark_tutor/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y2pllu/pyspark_tutor/", "subreddit_subscribers": 76290, "created_utc": 1665636355.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey y\u2019all! \n\nMy team and I are working on building a pipeline to migrate data from an Oracle database residing on a non-AWS cloud to AWS RDS. \n\nAny tool recommendations? We have already looked into AWS RDS, but I\u2019m wondering if there\u2019s a native tool that\u2019ll work better than that.", "author_fullname": "t2_78dddb58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ideas on cloud Oracle migration tools to AWS RDS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y2691z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665586897.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey y\u2019all! &lt;/p&gt;\n\n&lt;p&gt;My team and I are working on building a pipeline to migrate data from an Oracle database residing on a non-AWS cloud to AWS RDS. &lt;/p&gt;\n\n&lt;p&gt;Any tool recommendations? We have already looked into AWS RDS, but I\u2019m wondering if there\u2019s a native tool that\u2019ll work better than that.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y2691z", "is_robot_indexable": true, "report_reasons": null, "author": "Both-Trainer-1308", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y2691z/ideas_on_cloud_oracle_migration_tools_to_aws_rds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y2691z/ideas_on_cloud_oracle_migration_tools_to_aws_rds/", "subreddit_subscribers": 76290, "created_utc": 1665586897.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone. I am working on linking SalesForce to one of my Data Factories. I followed all the Microsoft guidelines and after clearing up a few error messages when I go to test the connection it spins for a few minutes and throws a timeout error with no other details. Has anyone had something similar happen? This doesn\u2019t appear to be an Azure side issue and my credentials are correct for SalesForce. I can\u2019t help but think there\u2019s a permission somewhere I missed but I\u2019m drawing blanks. Let me know if anyone has any ideas.", "author_fullname": "t2_326jvb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Factory SalesForce Linked Service Integration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y2kmzo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665621675.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone. I am working on linking SalesForce to one of my Data Factories. I followed all the Microsoft guidelines and after clearing up a few error messages when I go to test the connection it spins for a few minutes and throws a timeout error with no other details. Has anyone had something similar happen? This doesn\u2019t appear to be an Azure side issue and my credentials are correct for SalesForce. I can\u2019t help but think there\u2019s a permission somewhere I missed but I\u2019m drawing blanks. Let me know if anyone has any ideas.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y2kmzo", "is_robot_indexable": true, "report_reasons": null, "author": "ShouldHaveWentBio", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y2kmzo/data_factory_salesforce_linked_service_integration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y2kmzo/data_factory_salesforce_linked_service_integration/", "subreddit_subscribers": 76290, "created_utc": 1665621675.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hi, so I graduated last year with a bs in finance and pretty much worked retail since and never had an internship in finance. I had a job offer as analyst at a bulge bracket bank this year and completely turned it down and realized traditional finance is not what I wanted to do. After researching roles and such I really liked BI &amp; data engineering. Thinking data engineering may be the better path to pursue for job growth.\n\nJust wondering what I would need to do to be successful in a switch. I may plan on going back to school next year to pursue an MSCS or MS in data science. But really focused on being a self learner at the moment and building my own knowledge and experience. \n\nI want to create a data engineering portfolio and work on my own projects by 2023 as well. I know SQL and plan to pick up python starting this week.\n\nAny project tips/portfolio help? Where do you recommend I keep my online portfolio?\n\nBest way to learn python as a newbie?\n\nBooks, YouTube channels, &amp; any other free resources you would like to recommend?\n\nSo far using datacamp\u2019s path to becoming a data engineer \n\nThank you", "author_fullname": "t2_k9d12ch2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "career change help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y2f6df", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1665611531.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665607982.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hi, so I graduated last year with a bs in finance and pretty much worked retail since and never had an internship in finance. I had a job offer as analyst at a bulge bracket bank this year and completely turned it down and realized traditional finance is not what I wanted to do. After researching roles and such I really liked BI &amp;amp; data engineering. Thinking data engineering may be the better path to pursue for job growth.&lt;/p&gt;\n\n&lt;p&gt;Just wondering what I would need to do to be successful in a switch. I may plan on going back to school next year to pursue an MSCS or MS in data science. But really focused on being a self learner at the moment and building my own knowledge and experience. &lt;/p&gt;\n\n&lt;p&gt;I want to create a data engineering portfolio and work on my own projects by 2023 as well. I know SQL and plan to pick up python starting this week.&lt;/p&gt;\n\n&lt;p&gt;Any project tips/portfolio help? Where do you recommend I keep my online portfolio?&lt;/p&gt;\n\n&lt;p&gt;Best way to learn python as a newbie?&lt;/p&gt;\n\n&lt;p&gt;Books, YouTube channels, &amp;amp; any other free resources you would like to recommend?&lt;/p&gt;\n\n&lt;p&gt;So far using datacamp\u2019s path to becoming a data engineer &lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "y2f6df", "is_robot_indexable": true, "report_reasons": null, "author": "uaintgotnoyzy", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y2f6df/career_change_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y2f6df/career_change_help/", "subreddit_subscribers": 76290, "created_utc": 1665607982.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I currently part of data team on a retail company on migration, and I want to focus on a dataops roll that cover some technical areas but idk where start\n\nActually this is my first experience on IT so I need the basic to pro stuff or roadmap to start\n\nI reading some books like fundamental of data Engineer  and some blogs like dataops cookbook from data kitchen's  is my next read\n\n\nAny resources to learn dataops?? Or specific tools \nSorry for my bad ingles", "author_fullname": "t2_9pzeqq4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dataops from pm", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y27odn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665590318.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently part of data team on a retail company on migration, and I want to focus on a dataops roll that cover some technical areas but idk where start&lt;/p&gt;\n\n&lt;p&gt;Actually this is my first experience on IT so I need the basic to pro stuff or roadmap to start&lt;/p&gt;\n\n&lt;p&gt;I reading some books like fundamental of data Engineer  and some blogs like dataops cookbook from data kitchen&amp;#39;s  is my next read&lt;/p&gt;\n\n&lt;p&gt;Any resources to learn dataops?? Or specific tools \nSorry for my bad ingles&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "y27odn", "is_robot_indexable": true, "report_reasons": null, "author": "Icy_Cricket_779", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y27odn/dataops_from_pm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y27odn/dataops_from_pm/", "subreddit_subscribers": 76290, "created_utc": 1665590318.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Databases implement materialized views differently. My understanding of how Postgres implements a materialized view is that it builds a cached version of the view results and then refreshes them when the \"refresh materialized view\" statement is used.\n\nGiven that, what advantages does this provide over a drop/create table?\n\nHere's what I can think of, are there others?\n\n* Dependancies retain relationships. This wouldn't be possible with drop/create.\n* Data is always available. There's no moment in time where you may be referencing the view and the data isn't there like there is with a drop/create.", "author_fullname": "t2_roqmtvoh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any Advantage to Using Postgres Materialized Views vs Tables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y24bym", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665582171.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Databases implement materialized views differently. My understanding of how Postgres implements a materialized view is that it builds a cached version of the view results and then refreshes them when the &amp;quot;refresh materialized view&amp;quot; statement is used.&lt;/p&gt;\n\n&lt;p&gt;Given that, what advantages does this provide over a drop/create table?&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s what I can think of, are there others?&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Dependancies retain relationships. This wouldn&amp;#39;t be possible with drop/create.&lt;/li&gt;\n&lt;li&gt;Data is always available. There&amp;#39;s no moment in time where you may be referencing the view and the data isn&amp;#39;t there like there is with a drop/create.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y24bym", "is_robot_indexable": true, "report_reasons": null, "author": "goatslikelawns", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y24bym/any_advantage_to_using_postgres_materialized/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y24bym/any_advantage_to_using_postgres_materialized/", "subreddit_subscribers": 76290, "created_utc": 1665582171.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, as per title I would like to start a streaming project with Kafka. I'm searching for some interesting free data sources but it doesn't seem easy to find one, I'm trying to avoid some inflated ones like Twitter of Facebook API. A project about IoT would be really cool.\n\n I would also like to keep the project as cheap as possible.\n\nThanks!", "author_fullname": "t2_1xbf9q7w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Free Data Streaming Sources for a Personal Project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y2t2e4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665648892.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, as per title I would like to start a streaming project with Kafka. I&amp;#39;m searching for some interesting free data sources but it doesn&amp;#39;t seem easy to find one, I&amp;#39;m trying to avoid some inflated ones like Twitter of Facebook API. A project about IoT would be really cool.&lt;/p&gt;\n\n&lt;p&gt;I would also like to keep the project as cheap as possible.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y2t2e4", "is_robot_indexable": true, "report_reasons": null, "author": "aerdna69", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y2t2e4/free_data_streaming_sources_for_a_personal_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y2t2e4/free_data_streaming_sources_for_a_personal_project/", "subreddit_subscribers": 76290, "created_utc": 1665648892.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone know if Oracle Data Pump Export can be used for an Oracle cloud data migration to AWS RDS?", "author_fullname": "t2_78dddb58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using Oracle Data Pump Export", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y2oc4r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665632292.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone know if Oracle Data Pump Export can be used for an Oracle cloud data migration to AWS RDS?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y2oc4r", "is_robot_indexable": true, "report_reasons": null, "author": "Both-Trainer-1308", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y2oc4r/using_oracle_data_pump_export/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y2oc4r/using_oracle_data_pump_export/", "subreddit_subscribers": 76290, "created_utc": 1665632292.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How can I clean up city and postcode/zipcodes in a db. We have pretty shit unclean cities/postcodes and would like to clean using sql. We would this be a macros etc. recommendations please.", "author_fullname": "t2_t1crgsxs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to clean up City and Zipcode/Postcode?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y2cxkv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665602724.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How can I clean up city and postcode/zipcodes in a db. We have pretty shit unclean cities/postcodes and would like to clean using sql. We would this be a macros etc. recommendations please.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y2cxkv", "is_robot_indexable": true, "report_reasons": null, "author": "throwme-ariver", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y2cxkv/how_to_clean_up_city_and_zipcodepostcode/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y2cxkv/how_to_clean_up_city_and_zipcodepostcode/", "subreddit_subscribers": 76290, "created_utc": 1665602724.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello my name is Kevin and I am researching DataOps requirements for long established companies in my master thesis .\n\nIt would be highly appreciated if you could take a few minutes to answer the following survey.\n\n[https://www.survio.com/survey/d/C8E2A1E8Z8A8F7Q6J](https://www.survio.com/survey/d/C8E2A1E8Z8A8F7Q6J)\n\nFor every participant who completes the survey, I will donate 1 USD (up to 250 USD total) to non-profit orginasations!\n\nThank you very much!\n\nAnd sorry for reposting it in several channels :/ :)\n\nPS: The data will of course be collected anonymously and made open source available.\n\nPPS: Feel free to send feedback via email to: kevin.haferkamp001\\[at\\]stud.fh-dortmund.de", "author_fullname": "t2_5x4osqvy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Survey for my master thesis researching requirements for DataOps", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y26z6a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1665588628.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello my name is Kevin and I am researching DataOps requirements for long established companies in my master thesis .&lt;/p&gt;\n\n&lt;p&gt;It would be highly appreciated if you could take a few minutes to answer the following survey.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.survio.com/survey/d/C8E2A1E8Z8A8F7Q6J\"&gt;https://www.survio.com/survey/d/C8E2A1E8Z8A8F7Q6J&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;For every participant who completes the survey, I will donate 1 USD (up to 250 USD total) to non-profit orginasations!&lt;/p&gt;\n\n&lt;p&gt;Thank you very much!&lt;/p&gt;\n\n&lt;p&gt;And sorry for reposting it in several channels :/ :)&lt;/p&gt;\n\n&lt;p&gt;PS: The data will of course be collected anonymously and made open source available.&lt;/p&gt;\n\n&lt;p&gt;PPS: Feel free to send feedback via email to: kevin.haferkamp001[at]stud.fh-dortmund.de&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZyqcBI8AbuLGZanb_6IB7MAlXzV91s2nG4HXUJtUv7o.jpg?auto=webp&amp;s=1e087b87112002c59b1ebd8c0eb159786d0df0c6", "width": 1080, "height": 568}, "resolutions": [{"url": "https://external-preview.redd.it/ZyqcBI8AbuLGZanb_6IB7MAlXzV91s2nG4HXUJtUv7o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=020413bf8b4e8e9797ef349a4f34bae4fb3c8810", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/ZyqcBI8AbuLGZanb_6IB7MAlXzV91s2nG4HXUJtUv7o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d4ef4b280d22eda5f07b71ae61a9a3621587e7c5", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/ZyqcBI8AbuLGZanb_6IB7MAlXzV91s2nG4HXUJtUv7o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e135a5f19a6434878d48639dc191b6b0c76ab9f4", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/ZyqcBI8AbuLGZanb_6IB7MAlXzV91s2nG4HXUJtUv7o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=dfc11c5f3b8c851d06f497858db799c74e2e7825", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/ZyqcBI8AbuLGZanb_6IB7MAlXzV91s2nG4HXUJtUv7o.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ee18e1089cda68d44ffcd9293bd0d1128e5f25e8", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/ZyqcBI8AbuLGZanb_6IB7MAlXzV91s2nG4HXUJtUv7o.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8717d4d176d398ad9ce10f65d3298b3fc1a427d1", "width": 1080, "height": 568}], "variants": {}, "id": "SLrlrRC8ZiSJm8LQFtEyZBxll7XimBa4aHiYcbWt7pI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y26z6a", "is_robot_indexable": true, "report_reasons": null, "author": "khaferkamp", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y26z6a/survey_for_my_master_thesis_researching/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y26z6a/survey_for_my_master_thesis_researching/", "subreddit_subscribers": 76290, "created_utc": 1665588628.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We're starting to move our applications from SSIS to ADF and Databricks. I'm going to end up doing most of the work and so the first thing that I want to do is setup our environment variables.\n\nWe use the environment variables in SSIS to store our connection information. That way the Dev environment only has the connection information to the Dev resources. Then when the SSIS package is run, it points to the Dev DB, Dev FTP, etc. Likewise for PPR and PRD. The variables can include an address, username, PW, token, private key, etc.\n\nMy question is, are there best practices about doing this in Azure? My first thought was to use the Data Vault, and to connect from each application to get the login info. But is it appropriate to use the Data Vault for this? Also, is it possible to have the Data Vault have the same name in each environment? Otherwise, our code would have to be in each environment to know which vault to call, right?", "author_fullname": "t2_8u4k0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practices for ADF and Databricks for Environment variables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y255cl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665584246.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;re starting to move our applications from SSIS to ADF and Databricks. I&amp;#39;m going to end up doing most of the work and so the first thing that I want to do is setup our environment variables.&lt;/p&gt;\n\n&lt;p&gt;We use the environment variables in SSIS to store our connection information. That way the Dev environment only has the connection information to the Dev resources. Then when the SSIS package is run, it points to the Dev DB, Dev FTP, etc. Likewise for PPR and PRD. The variables can include an address, username, PW, token, private key, etc.&lt;/p&gt;\n\n&lt;p&gt;My question is, are there best practices about doing this in Azure? My first thought was to use the Data Vault, and to connect from each application to get the login info. But is it appropriate to use the Data Vault for this? Also, is it possible to have the Data Vault have the same name in each environment? Otherwise, our code would have to be in each environment to know which vault to call, right?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y255cl", "is_robot_indexable": true, "report_reasons": null, "author": "yoelbenyossef", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y255cl/best_practices_for_adf_and_databricks_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y255cl/best_practices_for_adf_and_databricks_for/", "subreddit_subscribers": 76290, "created_utc": 1665584246.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\nhttps://preview.redd.it/tg7lx0g0ret91.png?width=980&amp;format=png&amp;auto=webp&amp;s=72911ca09809b6a3c194eb4df0e080e4ba55dc2c\n\n&amp;#x200B;\n\nhttps://preview.redd.it/yxskt8k7ret91.png?width=888&amp;format=png&amp;auto=webp&amp;s=be28ac397bd91eafadb8cc318bf2ad9df2b2de8a", "author_fullname": "t2_bvkm0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Schemas &amp; Data Contracts\u2026", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "media_metadata": {"tg7lx0g0ret91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 71, "x": 108, "u": "https://preview.redd.it/tg7lx0g0ret91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=740b642be35fcfbcbfbc7896be3117fe234efa5a"}, {"y": 143, "x": 216, "u": "https://preview.redd.it/tg7lx0g0ret91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6f96dee3c5551d6326129a740f437aac010efbeb"}, {"y": 212, "x": 320, "u": "https://preview.redd.it/tg7lx0g0ret91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=0ed982c8d02435d9fa1917959a3b0d7682ddf914"}, {"y": 425, "x": 640, "u": "https://preview.redd.it/tg7lx0g0ret91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=aeef012f5beb326a2ec0498286c4d33bb329df78"}, {"y": 638, "x": 960, "u": "https://preview.redd.it/tg7lx0g0ret91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=cda17644cdaedb33cbe7dc534ea6707de89fb25a"}], "s": {"y": 652, "x": 980, "u": "https://preview.redd.it/tg7lx0g0ret91.png?width=980&amp;format=png&amp;auto=webp&amp;s=72911ca09809b6a3c194eb4df0e080e4ba55dc2c"}, "id": "tg7lx0g0ret91"}, "yxskt8k7ret91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/yxskt8k7ret91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=302e8a13e98daf0b9e7594d5b62bb655e0294260"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/yxskt8k7ret91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=be040a3c7a55a5642fdc6ba3e7b5eb5ed4c589cc"}, {"y": 179, "x": 320, "u": "https://preview.redd.it/yxskt8k7ret91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=6b936d06b9995ba6c4d84a70189b2c4d358ad255"}, {"y": 359, "x": 640, "u": "https://preview.redd.it/yxskt8k7ret91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d653b28d050324a661d3174c6da8d63e6cc1dc89"}], "s": {"y": 499, "x": 888, "u": "https://preview.redd.it/yxskt8k7ret91.png?width=888&amp;format=png&amp;auto=webp&amp;s=be28ac397bd91eafadb8cc318bf2ad9df2b2de8a"}, "id": "yxskt8k7ret91"}}, "name": "t3_y29nlu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/9AnY0-J2MwRjr9-wiI_Ieq8nnl1AcoeT-0J0PYrbuLs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665594888.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/tg7lx0g0ret91.png?width=980&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=72911ca09809b6a3c194eb4df0e080e4ba55dc2c\"&gt;https://preview.redd.it/tg7lx0g0ret91.png?width=980&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=72911ca09809b6a3c194eb4df0e080e4ba55dc2c&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/yxskt8k7ret91.png?width=888&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=be28ac397bd91eafadb8cc318bf2ad9df2b2de8a\"&gt;https://preview.redd.it/yxskt8k7ret91.png?width=888&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=be28ac397bd91eafadb8cc318bf2ad9df2b2de8a&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "y29nlu", "is_robot_indexable": true, "report_reasons": null, "author": "rmoff", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y29nlu/schemas_data_contracts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y29nlu/schemas_data_contracts/", "subreddit_subscribers": 76290, "created_utc": 1665594888.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Wondering what the key difference is between the three, I hear a lot from fellow colleagues that its very different but when I do my research on it they seem quite similar in their responsibilities with client side (front end) being design/navigation, writing code and debugging and service side (back end) being more data application development?\n\nWould love some perspective on it and whether they are in fact different ends of the data spectrum!", "author_fullname": "t2_swx1rmld", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question: Difference Between Data Engineers, Developers and UX/UX Designer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y2n2wa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665628542.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wondering what the key difference is between the three, I hear a lot from fellow colleagues that its very different but when I do my research on it they seem quite similar in their responsibilities with client side (front end) being design/navigation, writing code and debugging and service side (back end) being more data application development?&lt;/p&gt;\n\n&lt;p&gt;Would love some perspective on it and whether they are in fact different ends of the data spectrum!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y2n2wa", "is_robot_indexable": true, "report_reasons": null, "author": "TheOpportunist01", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y2n2wa/question_difference_between_data_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y2n2wa/question_difference_between_data_engineers/", "subreddit_subscribers": 76290, "created_utc": 1665628542.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}