{"kind": "Listing", "data": {"after": "t3_y25ojs", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\nSince a lot of people would like to learn the softer side of data science (based on my previous [post](https://www.reddit.com/r/datascience/comments/xqmj9q/i_started_out_as_an_inhouse_data_scientist_and/?utm_source=share&amp;utm_medium=web2x&amp;context=3)), I am back with another 10 tips. \n\n&amp;#x200B;\n\nIn most professional settings, it is not enough to be right.\n\nYou have to be **helpful**.\n\nThis means that you have to give more than just an answer. \n\nYou have to help your client understand where the answer is coming from.\n\n&amp;#x200B;\n\n_Note: A client can be a manager, colleague, or an actual paying client._ \n\n&amp;#x200B;\n\n## Here are 10 things that I learned:\n\n### 1. The client wants someone that will take away their worries and absorb problems. \nBe that person.\n\n### 2. Help the client **understand why your analysis makes sense**. \nGive them reasons.\n\n### 3. When presenting a recommendation, **change statements into questions**. \n\u201cI would suggest X because of Y. Does this make sense to you?\u201d\n\n### 4. When starting a new project, rephrase your client's problem to make sure you both understand each other. \n\u201cSo you think your customers are leaving because of bad customer service? Is that correct?\u201d\n\n### 5. Before you can help someone, you have to understand what\u2019s on their mind. \nAsk a lot of questions, shut up and listen.\n\n### 6. Don\u2019t assume someone is a mind reader. \nSay what you think, but try to word it in a constructive way. Just saying that something is dumb is not helpful. Explain why the idea will not work, and come up with a new idea that you together can build upon.\n\n### 7. Take notes during meetings and review them before the next meeting.\nThis will make sure there are no surprises.\n\n### 8. If you like working with someone, say it. \nIt builds the relationship which helps in collaboration. Do this only if you mean it though.\n\n### 9. Almost everyone on every level in a serious profession feels imposter syndrome. \nTrust yourself; you know more than you think you do.\n\n### 10. The key to solving problems is curiosity. \nFocus on what you don\u2019t know, instead of what you know and keep asking questions.\n\n&amp;#x200B;\n\nI hope you found this useful and good luck with your projects!\n\nedit: P.S. I post daily stuff like this on my [Twitter](https://twitter.com/thomasvarekamp)", "author_fullname": "t2_6f4y2kr6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to make the business love you (tips from an ex-corporate slave)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y2f682", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 197, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 197, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1665643481.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1665607973.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;Since a lot of people would like to learn the softer side of data science (based on my previous &lt;a href=\"https://www.reddit.com/r/datascience/comments/xqmj9q/i_started_out_as_an_inhouse_data_scientist_and/?utm_source=share&amp;amp;utm_medium=web2x&amp;amp;context=3\"&gt;post&lt;/a&gt;), I am back with another 10 tips. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;In most professional settings, it is not enough to be right.&lt;/p&gt;\n\n&lt;p&gt;You have to be &lt;strong&gt;helpful&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;This means that you have to give more than just an answer. &lt;/p&gt;\n\n&lt;p&gt;You have to help your client understand where the answer is coming from.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Note: A client can be a manager, colleague, or an actual paying client.&lt;/em&gt; &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;h2&gt;Here are 10 things that I learned:&lt;/h2&gt;\n\n&lt;h3&gt;1. The client wants someone that will take away their worries and absorb problems.&lt;/h3&gt;\n\n&lt;p&gt;Be that person.&lt;/p&gt;\n\n&lt;h3&gt;2. Help the client &lt;strong&gt;understand why your analysis makes sense&lt;/strong&gt;.&lt;/h3&gt;\n\n&lt;p&gt;Give them reasons.&lt;/p&gt;\n\n&lt;h3&gt;3. When presenting a recommendation, &lt;strong&gt;change statements into questions&lt;/strong&gt;.&lt;/h3&gt;\n\n&lt;p&gt;\u201cI would suggest X because of Y. Does this make sense to you?\u201d&lt;/p&gt;\n\n&lt;h3&gt;4. When starting a new project, rephrase your client&amp;#39;s problem to make sure you both understand each other.&lt;/h3&gt;\n\n&lt;p&gt;\u201cSo you think your customers are leaving because of bad customer service? Is that correct?\u201d&lt;/p&gt;\n\n&lt;h3&gt;5. Before you can help someone, you have to understand what\u2019s on their mind.&lt;/h3&gt;\n\n&lt;p&gt;Ask a lot of questions, shut up and listen.&lt;/p&gt;\n\n&lt;h3&gt;6. Don\u2019t assume someone is a mind reader.&lt;/h3&gt;\n\n&lt;p&gt;Say what you think, but try to word it in a constructive way. Just saying that something is dumb is not helpful. Explain why the idea will not work, and come up with a new idea that you together can build upon.&lt;/p&gt;\n\n&lt;h3&gt;7. Take notes during meetings and review them before the next meeting.&lt;/h3&gt;\n\n&lt;p&gt;This will make sure there are no surprises.&lt;/p&gt;\n\n&lt;h3&gt;8. If you like working with someone, say it.&lt;/h3&gt;\n\n&lt;p&gt;It builds the relationship which helps in collaboration. Do this only if you mean it though.&lt;/p&gt;\n\n&lt;h3&gt;9. Almost everyone on every level in a serious profession feels imposter syndrome.&lt;/h3&gt;\n\n&lt;p&gt;Trust yourself; you know more than you think you do.&lt;/p&gt;\n\n&lt;h3&gt;10. The key to solving problems is curiosity.&lt;/h3&gt;\n\n&lt;p&gt;Focus on what you don\u2019t know, instead of what you know and keep asking questions.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I hope you found this useful and good luck with your projects!&lt;/p&gt;\n\n&lt;p&gt;edit: P.S. I post daily stuff like this on my &lt;a href=\"https://twitter.com/thomasvarekamp\"&gt;Twitter&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/AIkOwOMNeRxxR5F5J3ODWoegrfem_609m4Kpj-KyuZ8.jpg?auto=webp&amp;s=b2060804cedae26bf98d0151db1e61c6301c019a", "width": 48, "height": 48}, "resolutions": [], "variants": {}, "id": "4nkoyxKj3C7Fh-sRbTpV9aNYeKtYiudQwh7RRB2Y2w8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y2f682", "is_robot_indexable": true, "report_reasons": null, "author": "thomasvarekamp", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y2f682/how_to_make_the_business_love_you_tips_from_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y2f682/how_to_make_the_business_love_you_tips_from_an/", "subreddit_subscribers": 813296, "created_utc": 1665607973.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Graduated college in may, now working as a junior analyst at a luxury retail firm. \n\nLooking to future proof my skills while honing my interests as well. I\u2019m a people person. I like explaining stuff to people and I love presenting. \n\nData Science seems like it\u2019s becoming too saturated while data engineering seems too SWE-focused for me. \n\nNo, I don\u2019t want to go for an MBA or PhD.", "author_fullname": "t2_mie3ucs8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "So how can I future proof myself in this field?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y251k8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 160, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 160, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665583990.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Graduated college in may, now working as a junior analyst at a luxury retail firm. &lt;/p&gt;\n\n&lt;p&gt;Looking to future proof my skills while honing my interests as well. I\u2019m a people person. I like explaining stuff to people and I love presenting. &lt;/p&gt;\n\n&lt;p&gt;Data Science seems like it\u2019s becoming too saturated while data engineering seems too SWE-focused for me. &lt;/p&gt;\n\n&lt;p&gt;No, I don\u2019t want to go for an MBA or PhD.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y251k8", "is_robot_indexable": true, "report_reasons": null, "author": "PonyBeanFord", "discussion_type": null, "num_comments": 107, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y251k8/so_how_can_i_future_proof_myself_in_this_field/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y251k8/so_how_can_i_future_proof_myself_in_this_field/", "subreddit_subscribers": 813296, "created_utc": 1665583990.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi community!\n\nWork in a field with lots of machinery where pumps and compressors reliability has direct impact on the bottomline. See a lot of new companies coming to offer the holy grail in terms of predictive maintenance using \"analytics\", but they are seldom able to live up to expectations or can't simply provide tangible evidence to go for a trial. We also have an internal Data Science team testing published methods, replicating work from other companies, etc and results are more or less the same: when applied to real data, nothing really adds value over properly performed condition monitoring (\\*). Then read plenty of academic articles (like this example [https://www.mdpi.com/1424-8220/22/1/291/pdf?version=1640946584](https://www.mdpi.com/1424-8220/22/1/291/pdf?version=1640946584)) where their conclusions seem to match ours (methods work nicely on perfect synthetic data, but fall sort in real life production).\n\nData-wise, we could always ask for more instruments to be installed, but we have a reasonable amount of history on key performance variables. Vibration sensors are not installed on every pump/compressor, but where we have them (in really critical machines) it doesn't really make a difference.  \n\nSo, not to sound like I'm just whining, anyone out there really succeeding in the subject of applying ML methods to predict equipment failures well in advance?\n\n(\\*) Some companies come showing \"success stories\" where instrumenting and monitoring a key temperature \"helped the operator save millions of dollars\". That's not what I'm referring to; in my book that's not ML-enabled predictive maintenance...that's basic condition monitoring not being done in first place.", "author_fullname": "t2_4q4y9trz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Predictive maintenance in heavy industries using AI/ML.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y28o5k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665592597.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi community!&lt;/p&gt;\n\n&lt;p&gt;Work in a field with lots of machinery where pumps and compressors reliability has direct impact on the bottomline. See a lot of new companies coming to offer the holy grail in terms of predictive maintenance using &amp;quot;analytics&amp;quot;, but they are seldom able to live up to expectations or can&amp;#39;t simply provide tangible evidence to go for a trial. We also have an internal Data Science team testing published methods, replicating work from other companies, etc and results are more or less the same: when applied to real data, nothing really adds value over properly performed condition monitoring (*). Then read plenty of academic articles (like this example &lt;a href=\"https://www.mdpi.com/1424-8220/22/1/291/pdf?version=1640946584\"&gt;https://www.mdpi.com/1424-8220/22/1/291/pdf?version=1640946584&lt;/a&gt;) where their conclusions seem to match ours (methods work nicely on perfect synthetic data, but fall sort in real life production).&lt;/p&gt;\n\n&lt;p&gt;Data-wise, we could always ask for more instruments to be installed, but we have a reasonable amount of history on key performance variables. Vibration sensors are not installed on every pump/compressor, but where we have them (in really critical machines) it doesn&amp;#39;t really make a difference.  &lt;/p&gt;\n\n&lt;p&gt;So, not to sound like I&amp;#39;m just whining, anyone out there really succeeding in the subject of applying ML methods to predict equipment failures well in advance?&lt;/p&gt;\n\n&lt;p&gt;(*) Some companies come showing &amp;quot;success stories&amp;quot; where instrumenting and monitoring a key temperature &amp;quot;helped the operator save millions of dollars&amp;quot;. That&amp;#39;s not what I&amp;#39;m referring to; in my book that&amp;#39;s not ML-enabled predictive maintenance...that&amp;#39;s basic condition monitoring not being done in first place.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y28o5k", "is_robot_indexable": true, "report_reasons": null, "author": "Trostis", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y28o5k/predictive_maintenance_in_heavy_industries_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y28o5k/predictive_maintenance_in_heavy_industries_using/", "subreddit_subscribers": 813296, "created_utc": 1665592597.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Is [Towards Data Science](https://towardsdatascience.com/) a good source to learn?", "author_fullname": "t2_2odo701g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Towards Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y21ws6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1665575699.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is &lt;a href=\"https://towardsdatascience.com/\"&gt;Towards Data Science&lt;/a&gt; a good source to learn?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_glma8teVmCiosaUvoIhyQuhFWRG0RAiTV3QF8ZVCNU.jpg?auto=webp&amp;s=9cc8e6f26ed7e47cf9217209afa69b33467ab049", "width": 1200, "height": 1200}, "resolutions": [{"url": "https://external-preview.redd.it/_glma8teVmCiosaUvoIhyQuhFWRG0RAiTV3QF8ZVCNU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0b00b904f5a7dcfb9788bdefba9b6dc484123ba0", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/_glma8teVmCiosaUvoIhyQuhFWRG0RAiTV3QF8ZVCNU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=168698ac3610b7c2789b4a15371137745458b23b", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/_glma8teVmCiosaUvoIhyQuhFWRG0RAiTV3QF8ZVCNU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=449fabf4c05632e2703c057812835597cfc41eb5", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/_glma8teVmCiosaUvoIhyQuhFWRG0RAiTV3QF8ZVCNU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=600e7b792cdbb6c59f892be934712df731a05d70", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/_glma8teVmCiosaUvoIhyQuhFWRG0RAiTV3QF8ZVCNU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=486c033d6b341c50354160153bf11406676a51b6", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/_glma8teVmCiosaUvoIhyQuhFWRG0RAiTV3QF8ZVCNU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9b32b649e7f801bac1c41befa9fd75c082886b17", "width": 1080, "height": 1080}], "variants": {}, "id": "fXoxRRVUSgnt_VS9eJHuprobrTWvG08BXvCfch-6FiY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y21ws6", "is_robot_indexable": true, "report_reasons": null, "author": "wtfboye", "discussion_type": null, "num_comments": 39, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y21ws6/towards_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y21ws6/towards_data_science/", "subreddit_subscribers": 813296, "created_utc": 1665575699.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi. Right now my organization runs a lot of promotional campaign every month. We send email, SMS and WhatsApp to all customers for each campaign. I am running a project to identity the best channel for a promotional campaign. All the channels have have similar range of CTR. But using all channels for all customers is a cost to company. The aim is to reduce the cost. Is A/B testing frequenist or Bayesian the ideal method. If no what should my approach.", "author_fullname": "t2_tb9jlihf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A/B testing for channel preference", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y2kse3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665622090.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi. Right now my organization runs a lot of promotional campaign every month. We send email, SMS and WhatsApp to all customers for each campaign. I am running a project to identity the best channel for a promotional campaign. All the channels have have similar range of CTR. But using all channels for all customers is a cost to company. The aim is to reduce the cost. Is A/B testing frequenist or Bayesian the ideal method. If no what should my approach.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y2kse3", "is_robot_indexable": true, "report_reasons": null, "author": "Working_Many_1632", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y2kse3/ab_testing_for_channel_preference/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y2kse3/ab_testing_for_channel_preference/", "subreddit_subscribers": 813296, "created_utc": 1665622090.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "The first thing recommended here for a job in data science is getting strong in math and statistics.\n\nWhat does that look like? Where can I find out more? \n\nCalculus, linear algebra, statistics, discrete math - all these are vast areas that you can spend a lifetime learning and exploring. \n\nSo, where do you draw a line? I mean, I understand that it depends on what you do, but if you don't do anything per se and trying to get in the field, what are the minimum standards? From 6-hour online courses and 120p books promising you'll learn \"math for data science\", to people with PhD degrees in statistics and a lifetime of learning, it all seems too vague, as vague as the term data science is. \n\nAnd is anyone here self-thought in this body of knowledge? How did you go about it? What was your path to getting strong?", "author_fullname": "t2_54lytnyf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How did you get 'strong' in math and statistics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_y2nnkv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 0, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": "", "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1665630687.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665630235.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The first thing recommended here for a job in data science is getting strong in math and statistics.&lt;/p&gt;\n\n&lt;p&gt;What does that look like? Where can I find out more? &lt;/p&gt;\n\n&lt;p&gt;Calculus, linear algebra, statistics, discrete math - all these are vast areas that you can spend a lifetime learning and exploring. &lt;/p&gt;\n\n&lt;p&gt;So, where do you draw a line? I mean, I understand that it depends on what you do, but if you don&amp;#39;t do anything per se and trying to get in the field, what are the minimum standards? From 6-hour online courses and 120p books promising you&amp;#39;ll learn &amp;quot;math for data science&amp;quot;, to people with PhD degrees in statistics and a lifetime of learning, it all seems too vague, as vague as the term data science is. &lt;/p&gt;\n\n&lt;p&gt;And is anyone here self-thought in this body of knowledge? How did you go about it? What was your path to getting strong?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "call_to_action": "", "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y2nnkv", "is_robot_indexable": true, "report_reasons": null, "author": "al0678", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y2nnkv/how_did_you_get_strong_in_math_and_statistics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y2nnkv/how_did_you_get_strong_in_math_and_statistics/", "subreddit_subscribers": 813296, "created_utc": 1665630235.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Can someone tell me the original source of this dataset\n\n[https://www.kaggle.com/datasets/pavanbodanki/blood-press](https://www.kaggle.com/datasets/pavanbodanki/blood-press)", "author_fullname": "t2_pxg9ds0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need the sauce", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y2sgu0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1665646594.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can someone tell me the original source of this dataset&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.kaggle.com/datasets/pavanbodanki/blood-press\"&gt;https://www.kaggle.com/datasets/pavanbodanki/blood-press&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/a38FeLHtfAniqHoeQ4zxk3EGzctFA7ox6J8GjOmo1LY.jpg?auto=webp&amp;s=b5509c1b43b316253ab7280ff193deda17fd1865", "width": 600, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/a38FeLHtfAniqHoeQ4zxk3EGzctFA7ox6J8GjOmo1LY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3f5348dd7afd449da39ef6cb8e374dab11fdfbc3", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/a38FeLHtfAniqHoeQ4zxk3EGzctFA7ox6J8GjOmo1LY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a7b80d94aea28ae7e79f46714771f9e586418727", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/a38FeLHtfAniqHoeQ4zxk3EGzctFA7ox6J8GjOmo1LY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bdad3156faa8600cd1c90b2c9df6fd78a9a4ce4d", "width": 320, "height": 320}], "variants": {}, "id": "h8otiX7Ckm6mpqCDjMC9PM-0ftFVGJaxj6mohIL-pHs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y2sgu0", "is_robot_indexable": true, "report_reasons": null, "author": "himelatb", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y2sgu0/i_need_the_sauce/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y2sgu0/i_need_the_sauce/", "subreddit_subscribers": 813296, "created_utc": 1665646594.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Not entirely sure what quant trading is, but I know that they make a lot of money off stocks using (machine learning) algorithms. If the stock market is so unpredictable, how do they make money?", "author_fullname": "t2_clatkkc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Since the stock market is unpredictable, how do quant firms consistently make large amounts of money?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y2exvv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665607416.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not entirely sure what quant trading is, but I know that they make a lot of money off stocks using (machine learning) algorithms. If the stock market is so unpredictable, how do they make money?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y2exvv", "is_robot_indexable": true, "report_reasons": null, "author": "NFeruch", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y2exvv/since_the_stock_market_is_unpredictable_how_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y2exvv/since_the_stock_market_is_unpredictable_how_do/", "subreddit_subscribers": 813296, "created_utc": 1665607416.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys, I need to average 15 min interval electrical price data. I originally thought harmonic mean since electrical pricing is a rate. However, in the state of Texas we have negative pricing as well, which harmonic mean cannot be used for. Would I simply use the arithmetic mean for this?", "author_fullname": "t2_it64cool", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "mean of negative and positive rates", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y2dmck", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665604361.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I need to average 15 min interval electrical price data. I originally thought harmonic mean since electrical pricing is a rate. However, in the state of Texas we have negative pricing as well, which harmonic mean cannot be used for. Would I simply use the arithmetic mean for this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y2dmck", "is_robot_indexable": true, "report_reasons": null, "author": "ricos_ramblings", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y2dmck/mean_of_negative_and_positive_rates/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y2dmck/mean_of_negative_and_positive_rates/", "subreddit_subscribers": 813296, "created_utc": 1665604361.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi community,\n\nWe recently released a small web application attempting to bring data visualization tools to retail investing. Specifically ETFs and Index Funds.  \n\n[ETF Insider](https://www.etfinsider.co/app)\n\nIf anyone here has a general understand of what an ETF is,  it would be great to get some feedback from the data science community. \n\nThanks!", "author_fullname": "t2_juyxttt0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Visualization Product Feedback", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_y2uhvg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665654379.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi community,&lt;/p&gt;\n\n&lt;p&gt;We recently released a small web application attempting to bring data visualization tools to retail investing. Specifically ETFs and Index Funds.  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.etfinsider.co/app\"&gt;ETF Insider&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If anyone here has a general understand of what an ETF is,  it would be great to get some feedback from the data science community. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y2uhvg", "is_robot_indexable": true, "report_reasons": null, "author": "ETFInsider", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y2uhvg/data_visualization_product_feedback/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y2uhvg/data_visualization_product_feedback/", "subreddit_subscribers": 813296, "created_utc": 1665654379.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone, I hope all is well. Tyia for reading my question.\n\n\\[TLDR -- Title sums it up\\]\n\nI'm a 2nd year CS student at a Canadian university. I have aspirations to get into robotics &amp; A.I. in the future.\n\nThough before that time comes, I would like to get some experience working for professors at my school &amp; start to build up my skill set. And I figure that THE way to provide utility to professors and/or researchers is to clean their data (Please correct me wherever I'm erroneous).\n\nI'm motivated, got enough brain to learn new skills &amp; currently have a foundational understanding of Python and Java. With so much information out there, it's very hard to pin point where to start exactly.\n\nPlease offer me some insight as to how I can get started down this path. Ideally, it would be awesome to be able to continue using Python.\n\nThanks again for your time, and have a great day.", "author_fullname": "t2_t8dvb3s3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Beginner Enquiry: How/Where to Start Learning Data Cleaning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y2s90w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665645755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I hope all is well. Tyia for reading my question.&lt;/p&gt;\n\n&lt;p&gt;[TLDR -- Title sums it up]&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a 2nd year CS student at a Canadian university. I have aspirations to get into robotics &amp;amp; A.I. in the future.&lt;/p&gt;\n\n&lt;p&gt;Though before that time comes, I would like to get some experience working for professors at my school &amp;amp; start to build up my skill set. And I figure that THE way to provide utility to professors and/or researchers is to clean their data (Please correct me wherever I&amp;#39;m erroneous).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m motivated, got enough brain to learn new skills &amp;amp; currently have a foundational understanding of Python and Java. With so much information out there, it&amp;#39;s very hard to pin point where to start exactly.&lt;/p&gt;\n\n&lt;p&gt;Please offer me some insight as to how I can get started down this path. Ideally, it would be awesome to be able to continue using Python.&lt;/p&gt;\n\n&lt;p&gt;Thanks again for your time, and have a great day.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y2s90w", "is_robot_indexable": true, "report_reasons": null, "author": "cool_huip_", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y2s90w/beginner_enquiry_howwhere_to_start_learning_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y2s90w/beginner_enquiry_howwhere_to_start_learning_data/", "subreddit_subscribers": 813296, "created_utc": 1665645755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Share the names and stories behind them. I remember a table created and instantly deleted as part of the tests that was named \u201cdelete_naughty_table_daddy_uh_oh\u201d. Well, once things did not work as they should and this table stayed there until an indignant architect noticed it \ud83d\ude05", "author_fullname": "t2_1rxjtfuw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the funniest table name you have ever seen?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_y2v676", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665656794.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Share the names and stories behind them. I remember a table created and instantly deleted as part of the tests that was named \u201cdelete_naughty_table_daddy_uh_oh\u201d. Well, once things did not work as they should and this table stayed there until an indignant architect noticed it \ud83d\ude05&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y2v676", "is_robot_indexable": true, "report_reasons": null, "author": "HYDP", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y2v676/what_is_the_funniest_table_name_you_have_ever_seen/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y2v676/what_is_the_funniest_table_name_you_have_ever_seen/", "subreddit_subscribers": 813296, "created_utc": 1665656794.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Most data science job require to have Strong knowledge of Big Data technology (e.g. Hadoop, interactive SQL on Hadoop, NoSQL, Spark, etc)!\n\nMost tutorial or courses focus on parts like statistics, analysis, modeling, visualization. I don't usually see big data techniques. Also my understanding is that these tools are looked behind a paywall or available on cloud platform like AWS or Azure.\n\nI believe I'm good with basic stuff, now, How do I practice on those?", "author_fullname": "t2_16t67m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you get experience in **BIG DATA** e.g. hadoop, spark without spending money?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_y2utyb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1665656246.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665655579.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Most data science job require to have Strong knowledge of Big Data technology (e.g. Hadoop, interactive SQL on Hadoop, NoSQL, Spark, etc)!&lt;/p&gt;\n\n&lt;p&gt;Most tutorial or courses focus on parts like statistics, analysis, modeling, visualization. I don&amp;#39;t usually see big data techniques. Also my understanding is that these tools are looked behind a paywall or available on cloud platform like AWS or Azure.&lt;/p&gt;\n\n&lt;p&gt;I believe I&amp;#39;m good with basic stuff, now, How do I practice on those?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y2utyb", "is_robot_indexable": true, "report_reasons": null, "author": "Mighty__hammer", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y2utyb/how_do_you_get_experience_in_big_data_eg_hadoop/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y2utyb/how_do_you_get_experience_in_big_data_eg_hadoop/", "subreddit_subscribers": 813296, "created_utc": 1665655579.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "1. I  worked on a data analysis project and uploaded the Jupyter notebook to Kaggle.\n2. I later DOWNLOADED the notebook from Kaggle to my LOCAL DISK.\n3. I  have realized that Visual studio code has issues whenever I try to open this DOWNLOADED JUPYTER NOTEBOOK inside VS CODE(See Image below)\n4. I do not see the same issue with notebooks that  I created within VS CODE.\n5. What might be the Issue? Have you experienced such?\n\n&amp;#x200B;\n\nhttps://preview.redd.it/omzoq6akajt91.png?width=1210&amp;format=png&amp;auto=webp&amp;s=9fc705fea37436b0a2d51267a17b0aea7bc630fb", "author_fullname": "t2_60pa85jj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "VISUAL STUDIO CODE: Why is it not responding when opening downloaded Jupyter notebooks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 63, "top_awarded_type": null, "hide_score": false, "media_metadata": {"omzoq6akajt91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 49, "x": 108, "u": "https://preview.redd.it/omzoq6akajt91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5d0e2162e9fc8484d81cbb73aed789e36b8dc57e"}, {"y": 98, "x": 216, "u": "https://preview.redd.it/omzoq6akajt91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a1d6f29f19c0ccdc4f2bbfbdebbb55f1fc22a324"}, {"y": 145, "x": 320, "u": "https://preview.redd.it/omzoq6akajt91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=79a071690241dcfeb70c1a00c56c10feadf0aa85"}, {"y": 291, "x": 640, "u": "https://preview.redd.it/omzoq6akajt91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0f9407a3f2eb7d9effb5cc884d05940a1fa9c4e3"}, {"y": 437, "x": 960, "u": "https://preview.redd.it/omzoq6akajt91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9e576a2581ae29ddfee20c744e70e92cd157070a"}, {"y": 491, "x": 1080, "u": "https://preview.redd.it/omzoq6akajt91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=78b3b38ea7cd6bb6cff4e0ad52eb6ea527ea25dc"}], "s": {"y": 551, "x": 1210, "u": "https://preview.redd.it/omzoq6akajt91.png?width=1210&amp;format=png&amp;auto=webp&amp;s=9fc705fea37436b0a2d51267a17b0aea7bc630fb"}, "id": "omzoq6akajt91"}}, "name": "t3_y2tci2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/1BtcF-p5kUwyxVZ3YfkVoJfdeTxf_Fp6Pm9duYm4_1Q.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665650026.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;ol&gt;\n&lt;li&gt;I  worked on a data analysis project and uploaded the Jupyter notebook to Kaggle.&lt;/li&gt;\n&lt;li&gt;I later DOWNLOADED the notebook from Kaggle to my LOCAL DISK.&lt;/li&gt;\n&lt;li&gt;I  have realized that Visual studio code has issues whenever I try to open this DOWNLOADED JUPYTER NOTEBOOK inside VS CODE(See Image below)&lt;/li&gt;\n&lt;li&gt;I do not see the same issue with notebooks that  I created within VS CODE.&lt;/li&gt;\n&lt;li&gt;What might be the Issue? Have you experienced such?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/omzoq6akajt91.png?width=1210&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9fc705fea37436b0a2d51267a17b0aea7bc630fb\"&gt;https://preview.redd.it/omzoq6akajt91.png?width=1210&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9fc705fea37436b0a2d51267a17b0aea7bc630fb&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y2tci2", "is_robot_indexable": true, "report_reasons": null, "author": "SOTP_", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y2tci2/visual_studio_code_why_is_it_not_responding_when/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y2tci2/visual_studio_code_why_is_it_not_responding_when/", "subreddit_subscribers": 813296, "created_utc": 1665650026.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Two years ago I created a library for performing Nested Cross Validation for **hyperparameter tuning** and **model evaluation** on classification problems. It's built on top of \\`sklearn\\`, \\`imblearn\\` and \\`skopt\\`. \n\nIt is specially designed for binary or multiclass classification problems where either there is an imbalance problem or probability calibration is very important (or both). \n\nToday I've released a totally new version with better code, documentation and examples that I hope will make it easier to use for practitioners. \n\n[https://github.com/JaimeArboleda/nestedcvtraining](https://github.com/JaimeArboleda/nestedcvtraining)", "author_fullname": "t2_9rpvki99", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Project: Nested Cross Validation Library", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y2r2aq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1665641349.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Two years ago I created a library for performing Nested Cross Validation for &lt;strong&gt;hyperparameter tuning&lt;/strong&gt; and &lt;strong&gt;model evaluation&lt;/strong&gt; on classification problems. It&amp;#39;s built on top of `sklearn`, `imblearn` and `skopt`. &lt;/p&gt;\n\n&lt;p&gt;It is specially designed for binary or multiclass classification problems where either there is an imbalance problem or probability calibration is very important (or both). &lt;/p&gt;\n\n&lt;p&gt;Today I&amp;#39;ve released a totally new version with better code, documentation and examples that I hope will make it easier to use for practitioners. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/JaimeArboleda/nestedcvtraining\"&gt;https://github.com/JaimeArboleda/nestedcvtraining&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9trzTwEGSOcW6ddUW3-KJ3oMQni6RVlQVsTZ2UHcVm8.jpg?auto=webp&amp;s=fca1aea8f44a5201a18e7c243cb178f9b9485a70", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/9trzTwEGSOcW6ddUW3-KJ3oMQni6RVlQVsTZ2UHcVm8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=61d1e2feba7ccaca5e0732d23f134b4d1cce3e21", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/9trzTwEGSOcW6ddUW3-KJ3oMQni6RVlQVsTZ2UHcVm8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4e336b9ba02382f2ede468f1e287e548530836cd", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/9trzTwEGSOcW6ddUW3-KJ3oMQni6RVlQVsTZ2UHcVm8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d5e4970d1a0f0a6f8651e946378944a9447bd870", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/9trzTwEGSOcW6ddUW3-KJ3oMQni6RVlQVsTZ2UHcVm8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=577c841b582d0395970663704601d3d45ab3ea14", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/9trzTwEGSOcW6ddUW3-KJ3oMQni6RVlQVsTZ2UHcVm8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=89a99a6a7201559c78d59bc3bd27a95838e6e76b", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/9trzTwEGSOcW6ddUW3-KJ3oMQni6RVlQVsTZ2UHcVm8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=261b49edbc654a51d6e65188fc8c16994a6b8d32", "width": 1080, "height": 540}], "variants": {}, "id": "NMVcpxXBOH12FlFkcdr1Kc81CGzK5mQ-yO11Eeb97_8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y2r2aq", "is_robot_indexable": true, "report_reasons": null, "author": "fripperML", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y2r2aq/project_nested_cross_validation_library/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y2r2aq/project_nested_cross_validation_library/", "subreddit_subscribers": 813296, "created_utc": 1665641349.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A-Z of Data Analytics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 74, "top_awarded_type": null, "hide_score": false, "name": "t3_y2q8vt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_dt6ya2pz", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/rG9mBjzno0mXAAJA_7fw9y1AL4Qpqm41Q_B06KVDMsc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "u_addlerkuhn", "selftext": "**A is for Artificial Intelligence (AI).** \n\nhttps://preview.redd.it/tp7oekyf9it91.jpg?width=5001&amp;format=pjpg&amp;auto=webp&amp;s=4008d2bad71bc07ddf08779c1d5798887ef98059\n\nIt is a branch of computer science that develops \u201csmart machines\u201d to do human-related tasks, such as self-driving cars (i.e., Tesla cars), smart assistance (i.e., Siri from Apple), and natural language processing (NLP) for AI copywriting.\n\nTo read the full piece on how AI copywriting tools uses NLP to produce original and legible content, click here: [Clash of Content: Human vs. AI](https://www.linkedin.com/pulse/clash-content-human-vs-ai-cubeware-gmbh/)", "author_fullname": "t2_dt6ya2pz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A-Z of Data Analytics", "link_flair_richtext": [], "subreddit_name_prefixed": "u/addlerkuhn", "hidden": false, "pwls": null, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 74, "top_awarded_type": null, "hide_score": false, "media_metadata": {"tp7oekyf9it91": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 57, "x": 108, "u": "https://preview.redd.it/tp7oekyf9it91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2370d1bf70f84ada8d46ae2f9878fdc20341a905"}, {"y": 114, "x": 216, "u": "https://preview.redd.it/tp7oekyf9it91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7a7288550b3f22e54cf82047be12cf8b6321b89c"}, {"y": 169, "x": 320, "u": "https://preview.redd.it/tp7oekyf9it91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=eb4df009946f8bf6933368a0c3fbe7e9d3b7f678"}, {"y": 339, "x": 640, "u": "https://preview.redd.it/tp7oekyf9it91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f761f4d391924b188662e7fdd2ae2b0af6f2e58a"}, {"y": 509, "x": 960, "u": "https://preview.redd.it/tp7oekyf9it91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f6cd7c93e4e5101f5b46fd4194e7bc5873d77629"}, {"y": 573, "x": 1080, "u": "https://preview.redd.it/tp7oekyf9it91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a35dd902546ab724e105bb3a6863244dd322b4f8"}], "s": {"y": 2655, "x": 5001, "u": "https://preview.redd.it/tp7oekyf9it91.jpg?width=5001&amp;format=pjpg&amp;auto=webp&amp;s=4008d2bad71bc07ddf08779c1d5798887ef98059"}, "id": "tp7oekyf9it91"}}, "name": "t3_y2pxis", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "user", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/rG9mBjzno0mXAAJA_7fw9y1AL4Qpqm41Q_B06KVDMsc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1665637440.0, "link_flair_type": "text", "wls": null, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.addlerkuhn", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;A is for Artificial Intelligence (AI).&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/tp7oekyf9it91.jpg?width=5001&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=4008d2bad71bc07ddf08779c1d5798887ef98059\"&gt;https://preview.redd.it/tp7oekyf9it91.jpg?width=5001&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=4008d2bad71bc07ddf08779c1d5798887ef98059&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;It is a branch of computer science that develops \u201csmart machines\u201d to do human-related tasks, such as self-driving cars (i.e., Tesla cars), smart assistance (i.e., Siri from Apple), and natural language processing (NLP) for AI copywriting.&lt;/p&gt;\n\n&lt;p&gt;To read the full piece on how AI copywriting tools uses NLP to produce original and legible content, click here: &lt;a href=\"https://www.linkedin.com/pulse/clash-content-human-vs-ai-cubeware-gmbh/\"&gt;Clash of Content: Human vs. AI&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "qa", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/WOUuQY_r6PBkd44ObUDz9tql-Aq-mCaJPbL88Qzxbyw.jpg?auto=webp&amp;s=9148289366245c5adb68731311d339ebd4847bc7", "width": 1280, "height": 679}, "resolutions": [{"url": "https://external-preview.redd.it/WOUuQY_r6PBkd44ObUDz9tql-Aq-mCaJPbL88Qzxbyw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bb91f9bf0b1f8b9559959dd6ea15e0489a2f91d3", "width": 108, "height": 57}, {"url": "https://external-preview.redd.it/WOUuQY_r6PBkd44ObUDz9tql-Aq-mCaJPbL88Qzxbyw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=92107d4e61b6210b88ff69fe191d3399d8ddfea7", "width": 216, "height": 114}, {"url": "https://external-preview.redd.it/WOUuQY_r6PBkd44ObUDz9tql-Aq-mCaJPbL88Qzxbyw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b2b2ed4ea0da6b276f0508148f301439e93ae92f", "width": 320, "height": 169}, {"url": "https://external-preview.redd.it/WOUuQY_r6PBkd44ObUDz9tql-Aq-mCaJPbL88Qzxbyw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7b5a811ba5d3f6d1262349391eccc904c3e2e238", "width": 640, "height": 339}, {"url": "https://external-preview.redd.it/WOUuQY_r6PBkd44ObUDz9tql-Aq-mCaJPbL88Qzxbyw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=15e3fe767332038ea73735c817986fbd27d5a25c", "width": 960, "height": 509}, {"url": "https://external-preview.redd.it/WOUuQY_r6PBkd44ObUDz9tql-Aq-mCaJPbL88Qzxbyw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d43489ba2d47227f7bf753e3c216a267dfd6fb72", "width": 1080, "height": 572}], "variants": {}, "id": "1bPbJv78juok13xYMcD7XrLVdFjJ2yy005aGRJmejMA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_6uqcib", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y2pxis", "is_robot_indexable": true, "report_reasons": null, "author": "addlerkuhn", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": null, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/u_addlerkuhn/comments/y2pxis/az_of_data_analytics/", "parent_whitelist_status": null, "stickied": false, "url": "https://old.reddit.com/r/u_addlerkuhn/comments/y2pxis/az_of_data_analytics/", "subreddit_subscribers": 0, "created_utc": 1665637440.0, "num_crossposts": 3, "media": null, "is_video": false}], "created": 1665638499.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.addlerkuhn", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/user/addlerkuhn/comments/y2pxis/az_of_data_analytics/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/WOUuQY_r6PBkd44ObUDz9tql-Aq-mCaJPbL88Qzxbyw.jpg?auto=webp&amp;s=9148289366245c5adb68731311d339ebd4847bc7", "width": 1280, "height": 679}, "resolutions": [{"url": "https://external-preview.redd.it/WOUuQY_r6PBkd44ObUDz9tql-Aq-mCaJPbL88Qzxbyw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bb91f9bf0b1f8b9559959dd6ea15e0489a2f91d3", "width": 108, "height": 57}, {"url": "https://external-preview.redd.it/WOUuQY_r6PBkd44ObUDz9tql-Aq-mCaJPbL88Qzxbyw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=92107d4e61b6210b88ff69fe191d3399d8ddfea7", "width": 216, "height": 114}, {"url": "https://external-preview.redd.it/WOUuQY_r6PBkd44ObUDz9tql-Aq-mCaJPbL88Qzxbyw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b2b2ed4ea0da6b276f0508148f301439e93ae92f", "width": 320, "height": 169}, {"url": "https://external-preview.redd.it/WOUuQY_r6PBkd44ObUDz9tql-Aq-mCaJPbL88Qzxbyw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7b5a811ba5d3f6d1262349391eccc904c3e2e238", "width": 640, "height": 339}, {"url": "https://external-preview.redd.it/WOUuQY_r6PBkd44ObUDz9tql-Aq-mCaJPbL88Qzxbyw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=15e3fe767332038ea73735c817986fbd27d5a25c", "width": 960, "height": 509}, {"url": "https://external-preview.redd.it/WOUuQY_r6PBkd44ObUDz9tql-Aq-mCaJPbL88Qzxbyw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d43489ba2d47227f7bf753e3c216a267dfd6fb72", "width": 1080, "height": 572}], "variants": {}, "id": "1bPbJv78juok13xYMcD7XrLVdFjJ2yy005aGRJmejMA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y2q8vt", "is_robot_indexable": true, "report_reasons": null, "author": "addlerkuhn", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_y2pxis", "author_flair_text_color": null, "permalink": "/r/datascience/comments/y2q8vt/az_of_data_analytics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/user/addlerkuhn/comments/y2pxis/az_of_data_analytics/", "subreddit_subscribers": 813296, "created_utc": 1665638499.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I got asked a question by my boss at work and would love your help.\n\n1. How would one design an A/B test to find out which social media platform is best for brand awareness ad campaigns. To give some context, brand awareness ad campaigns are looking to increase awareness and are typically looking to maximum the number of people that view an ad or engage with ads (think brick and mortar shops or pollical ads). The question here is how will be determine which one of Facebook, twitter, Tiktok, etc is better?\n2. What will be the metric to be used to measure brand awareness ad effectiveness ? What data will be needed to determine brand awareness?\n3. What will be the control and treatment groups? Almost feels like there is no control group, will every platform will be its own treatment group?\n4. How will you control for interference or the fact that every social media platform has different user demographics and different ways to engage with ads ? any other related issues ?", "author_fullname": "t2_1l2m1udt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A/B test to determine best social media platform for brand awareness", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y2oum9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665633884.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got asked a question by my boss at work and would love your help.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;How would one design an A/B test to find out which social media platform is best for brand awareness ad campaigns. To give some context, brand awareness ad campaigns are looking to increase awareness and are typically looking to maximum the number of people that view an ad or engage with ads (think brick and mortar shops or pollical ads). The question here is how will be determine which one of Facebook, twitter, Tiktok, etc is better?&lt;/li&gt;\n&lt;li&gt;What will be the metric to be used to measure brand awareness ad effectiveness ? What data will be needed to determine brand awareness?&lt;/li&gt;\n&lt;li&gt;What will be the control and treatment groups? Almost feels like there is no control group, will every platform will be its own treatment group?&lt;/li&gt;\n&lt;li&gt;How will you control for interference or the fact that every social media platform has different user demographics and different ways to engage with ads ? any other related issues ?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y2oum9", "is_robot_indexable": true, "report_reasons": null, "author": "metador777", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y2oum9/ab_test_to_determine_best_social_media_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y2oum9/ab_test_to_determine_best_social_media_platform/", "subreddit_subscribers": 813296, "created_utc": 1665633884.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m applying for a positions of machine learning engineer and the interviewers tell me I will need to take a test, in which maths will be the main content. Can I ask for sample of those test and tips to prepare for such interview?", "author_fullname": "t2_sec9q57a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can I ask for sample math test for a data science/ machine learning interview?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y2nkiv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665630004.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m applying for a positions of machine learning engineer and the interviewers tell me I will need to take a test, in which maths will be the main content. Can I ask for sample of those test and tips to prepare for such interview?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y2nkiv", "is_robot_indexable": true, "report_reasons": null, "author": "AtmosphereWhole4010", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y2nkiv/can_i_ask_for_sample_math_test_for_a_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y2nkiv/can_i_ask_for_sample_math_test_for_a_data_science/", "subreddit_subscribers": 813296, "created_utc": 1665630004.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "To sharpen my stats for my job interviews next month, I'm trying test all kinds of things so it stays fresh in my brain. Video game ranks of myself vs the whole, how can I estimate a number I don't have access to?\n\n&amp;#x200B;\n\n[My own AC130 zombie target practice](https://preview.redd.it/qk99pq4i6ft91.png?width=1290&amp;format=png&amp;auto=webp&amp;s=f2cc72eae4804a0616f68913e9ff4504f01e14ce)\n\nSo I play that game 'Zombie Gunship' where you play the gunner in an AC130 Gunship, where you have the 105mm howitzer, 40mm grenade, and the 25mm gatling gun.\n\nThe stats I want to estimate is if I am ranked 16,363 of 432,369 globally, I have 1107 kills, how can we estimate the top 1%, and how can we estimate the top player... in general.\n\nOk, so I know these variables.\n\nGiven:  \np=population = 432,369\n\ns=sampled rank 16,363 to 11,542\n\nn = 4,821 steps in rank\n\nr1 = 16,353 \\~ 0.0378449889 or top 3.7% \n\nr2 = 11,542 \\~0.0266947908 or top 2.6%\n\nr3 = 1\n\nk1 = 1107\n\nk2 = 1178\n\nThis is a two sample, known population, known proportion, and its ranked... which still doesn't solve for guessing the #1 players zombie kills. If we lowball the guess and say its linear how can we estimate it? Two sample proportion estimation formula here from our class. [https://online.stat.psu.edu/stat800/lesson/5/5.5](https://online.stat.psu.edu/stat800/lesson/5/5.5)\n\n&amp;#x200B;\n\n[two sample formula](https://preview.redd.it/39y29gpw6ft91.png?width=1230&amp;format=png&amp;auto=webp&amp;s=bc337930cc3c7c14e1b9b35ab7607ce7cb21fbbe)\n\nThe formula I'm thinking is phat-p0 divided by sqroot of ( p0(1-p0))/n or 0.037844-0.026694 = 0.01115 which matches the same proportion of 4821/432,369 = 0.0111501.\n\nSo 0.01115/sqrt(0.026694(1-0.026694)) then divide that by 4821 which gives me a z=4.8029. That sort of makes sense it would be four times the std deviation but we don't know what the distribution of total kills are so k1 and k2 are nice to have but useless unless I went into python to code up some linear estimator. So its maybe accurate math but doesn't fit the distribution.\n\nSo what are the other options to estimate this?\n\nI can click the app and have it tell me what the top players stats are but I want to guess.", "author_fullname": "t2_anvxlfvj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Practicing Data Science at Random", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 108, "top_awarded_type": null, "hide_score": false, "media_metadata": {"qk99pq4i6ft91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 83, "x": 108, "u": "https://preview.redd.it/qk99pq4i6ft91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8bfa4bb68d6629c113c350ad1b3ffc1117a48df4"}, {"y": 167, "x": 216, "u": "https://preview.redd.it/qk99pq4i6ft91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=388f9b9459a02fa558f18bb8ab6994d7ce1ab8ce"}, {"y": 248, "x": 320, "u": "https://preview.redd.it/qk99pq4i6ft91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3d4c87f595c249d67e3fa3cc15f48133cd40658d"}, {"y": 497, "x": 640, "u": "https://preview.redd.it/qk99pq4i6ft91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=1fd918768fbdbc5aabd2b81f22289e76f3416769"}, {"y": 745, "x": 960, "u": "https://preview.redd.it/qk99pq4i6ft91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e061095e5fbc19d3994af5a43cfcada2eee0ce04"}, {"y": 838, "x": 1080, "u": "https://preview.redd.it/qk99pq4i6ft91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=bba288966c95180396a598f0e8a5f5f8ea6b9509"}], "s": {"y": 1002, "x": 1290, "u": "https://preview.redd.it/qk99pq4i6ft91.png?width=1290&amp;format=png&amp;auto=webp&amp;s=f2cc72eae4804a0616f68913e9ff4504f01e14ce"}, "id": "qk99pq4i6ft91"}, "39y29gpw6ft91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 90, "x": 108, "u": "https://preview.redd.it/39y29gpw6ft91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2a7d64c5904db270b61979efdd4eff3791d72f9c"}, {"y": 180, "x": 216, "u": "https://preview.redd.it/39y29gpw6ft91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2a10cc70298035058d10dc272607e972f1e7f7d0"}, {"y": 267, "x": 320, "u": "https://preview.redd.it/39y29gpw6ft91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=faf94f4166678d5d2bbd458d936bc08bbdcb426d"}, {"y": 534, "x": 640, "u": "https://preview.redd.it/39y29gpw6ft91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=4bdc53dfb51076257386373fa2b572f3ab2411db"}, {"y": 802, "x": 960, "u": "https://preview.redd.it/39y29gpw6ft91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=66df7c342fa08606b1fabbea33133e3cd86aa515"}, {"y": 902, "x": 1080, "u": "https://preview.redd.it/39y29gpw6ft91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3fb9c433d3bc4292688225110f196fdb30180aa3"}], "s": {"y": 1028, "x": 1230, "u": "https://preview.redd.it/39y29gpw6ft91.png?width=1230&amp;format=png&amp;auto=webp&amp;s=bc337930cc3c7c14e1b9b35ab7607ce7cb21fbbe"}, "id": "39y29gpw6ft91"}}, "name": "t3_y2bvzs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/N-4qBe8BiST1fPqOaQuAmZKar8UkWgw2QOrAHIAYmxI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665600242.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;To sharpen my stats for my job interviews next month, I&amp;#39;m trying test all kinds of things so it stays fresh in my brain. Video game ranks of myself vs the whole, how can I estimate a number I don&amp;#39;t have access to?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/qk99pq4i6ft91.png?width=1290&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f2cc72eae4804a0616f68913e9ff4504f01e14ce\"&gt;My own AC130 zombie target practice&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;So I play that game &amp;#39;Zombie Gunship&amp;#39; where you play the gunner in an AC130 Gunship, where you have the 105mm howitzer, 40mm grenade, and the 25mm gatling gun.&lt;/p&gt;\n\n&lt;p&gt;The stats I want to estimate is if I am ranked 16,363 of 432,369 globally, I have 1107 kills, how can we estimate the top 1%, and how can we estimate the top player... in general.&lt;/p&gt;\n\n&lt;p&gt;Ok, so I know these variables.&lt;/p&gt;\n\n&lt;p&gt;Given:&lt;br/&gt;\np=population = 432,369&lt;/p&gt;\n\n&lt;p&gt;s=sampled rank 16,363 to 11,542&lt;/p&gt;\n\n&lt;p&gt;n = 4,821 steps in rank&lt;/p&gt;\n\n&lt;p&gt;r1 = 16,353 ~ 0.0378449889 or top 3.7% &lt;/p&gt;\n\n&lt;p&gt;r2 = 11,542 ~0.0266947908 or top 2.6%&lt;/p&gt;\n\n&lt;p&gt;r3 = 1&lt;/p&gt;\n\n&lt;p&gt;k1 = 1107&lt;/p&gt;\n\n&lt;p&gt;k2 = 1178&lt;/p&gt;\n\n&lt;p&gt;This is a two sample, known population, known proportion, and its ranked... which still doesn&amp;#39;t solve for guessing the #1 players zombie kills. If we lowball the guess and say its linear how can we estimate it? Two sample proportion estimation formula here from our class. &lt;a href=\"https://online.stat.psu.edu/stat800/lesson/5/5.5\"&gt;https://online.stat.psu.edu/stat800/lesson/5/5.5&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/39y29gpw6ft91.png?width=1230&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=bc337930cc3c7c14e1b9b35ab7607ce7cb21fbbe\"&gt;two sample formula&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The formula I&amp;#39;m thinking is phat-p0 divided by sqroot of ( p0(1-p0))/n or 0.037844-0.026694 = 0.01115 which matches the same proportion of 4821/432,369 = 0.0111501.&lt;/p&gt;\n\n&lt;p&gt;So 0.01115/sqrt(0.026694(1-0.026694)) then divide that by 4821 which gives me a z=4.8029. That sort of makes sense it would be four times the std deviation but we don&amp;#39;t know what the distribution of total kills are so k1 and k2 are nice to have but useless unless I went into python to code up some linear estimator. So its maybe accurate math but doesn&amp;#39;t fit the distribution.&lt;/p&gt;\n\n&lt;p&gt;So what are the other options to estimate this?&lt;/p&gt;\n\n&lt;p&gt;I can click the app and have it tell me what the top players stats are but I want to guess.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y2bvzs", "is_robot_indexable": true, "report_reasons": null, "author": "Your_Data_Talking", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y2bvzs/practicing_data_science_at_random/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y2bvzs/practicing_data_science_at_random/", "subreddit_subscribers": 813296, "created_utc": 1665600242.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Dear fellow travelers,\n\nHope you are all doing well.\n\nI have a platform that brings together freelance data scientists with companies. In order to generate more traffic on the online platform (on the company's side), I am looking for an e-commerce case study. This case should answer questions like:\n\n* How to improve the acquisition of customers with data science?\n* How to improve the retention of customers with data science?\n\nBut companies are kinda scared, of sharing this sort of data. How would you approach this challenge?", "author_fullname": "t2_mahttbq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you approach this challange?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y21teq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665575417.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dear fellow travelers,&lt;/p&gt;\n\n&lt;p&gt;Hope you are all doing well.&lt;/p&gt;\n\n&lt;p&gt;I have a platform that brings together freelance data scientists with companies. In order to generate more traffic on the online platform (on the company&amp;#39;s side), I am looking for an e-commerce case study. This case should answer questions like:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;How to improve the acquisition of customers with data science?&lt;/li&gt;\n&lt;li&gt;How to improve the retention of customers with data science?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;But companies are kinda scared, of sharing this sort of data. How would you approach this challenge?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y21teq", "is_robot_indexable": true, "report_reasons": null, "author": "BafbeerNL", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y21teq/how_would_you_approach_this_challange/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y21teq/how_would_you_approach_this_challange/", "subreddit_subscribers": 813296, "created_utc": 1665575417.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Difficulty understanding how this regression analysis even makes sense - From a Datacamp course", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y2s9wa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_eht7g", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "DataCamp", "selftext": "As someone from a STEM (chemical biology) background when we do analysis between a reaction parameter (pH, temp) to study an effect such as enzyme activity over time. Regression values (R^(2)) anything less than 0.90 is considered a poor linear relationship.\n\nThis definitely does not show an R^(2) above 0.90 (in the plot images below). The data is so scattered and there is a huge chunk of data concentrated around one x-value. How can people deduce a trend of such poor relationships?\n\n[Plots](https://imgur.com/a/TFeU40w) are here.\n\nEdit: In fact many professors will not allow you to go for a publication unless your data is at least 0.98-0.99  \n\n\nEdit2: The code for the two plots are as follows:  \nGraph 1 -\n\n    # Display a regression plot for Tuition\n    sns.regplot(data=df,\n             y='Tuition',\n             x='SAT_AVG_ALL',\n             marker='^',\n             color='g')\n    \n    plt.show()\n    plt.clf()\n\nGraph 2 -\n\n    # Display the residual plot\n    sns.residplot(data=df,\n              y='Tuition',\n              x='SAT_AVG_ALL',\n              color='g')\n    \n    plt.show()\n    plt.clf()\n\n&amp;#x200B;", "author_fullname": "t2_eht7g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I have difficulty understanding how this regression analysis even makes sense", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataCamp", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y2s60l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1665646052.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1665645454.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataCamp", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As someone from a STEM (chemical biology) background when we do analysis between a reaction parameter (pH, temp) to study an effect such as enzyme activity over time. Regression values (R&lt;sup&gt;2&lt;/sup&gt;) anything less than 0.90 is considered a poor linear relationship.&lt;/p&gt;\n\n&lt;p&gt;This definitely does not show an R&lt;sup&gt;2&lt;/sup&gt; above 0.90 (in the plot images below). The data is so scattered and there is a huge chunk of data concentrated around one x-value. How can people deduce a trend of such poor relationships?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://imgur.com/a/TFeU40w\"&gt;Plots&lt;/a&gt; are here.&lt;/p&gt;\n\n&lt;p&gt;Edit: In fact many professors will not allow you to go for a publication unless your data is at least 0.98-0.99  &lt;/p&gt;\n\n&lt;p&gt;Edit2: The code for the two plots are as follows:&lt;br/&gt;\nGraph 1 -&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;# Display a regression plot for Tuition\nsns.regplot(data=df,\n         y=&amp;#39;Tuition&amp;#39;,\n         x=&amp;#39;SAT_AVG_ALL&amp;#39;,\n         marker=&amp;#39;^&amp;#39;,\n         color=&amp;#39;g&amp;#39;)\n\nplt.show()\nplt.clf()\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Graph 2 -&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;# Display the residual plot\nsns.residplot(data=df,\n          y=&amp;#39;Tuition&amp;#39;,\n          x=&amp;#39;SAT_AVG_ALL&amp;#39;,\n          color=&amp;#39;g&amp;#39;)\n\nplt.show()\nplt.clf()\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/kIg517pD726BQBJd0BFaRRFp_lxR4UgcivDnjxQ3eDU.jpg?auto=webp&amp;s=13bb2b6b27523958afe3547ee33472ec6a86eb7b", "width": 853, "height": 853}, "resolutions": [{"url": "https://external-preview.redd.it/kIg517pD726BQBJd0BFaRRFp_lxR4UgcivDnjxQ3eDU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c2b76c8331b8006680ab6d6894a8529660b9cd53", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/kIg517pD726BQBJd0BFaRRFp_lxR4UgcivDnjxQ3eDU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=537df3c91354af78667d89761aeec32bfe3721e3", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/kIg517pD726BQBJd0BFaRRFp_lxR4UgcivDnjxQ3eDU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d0e26b579f377a9e9d42bc546454f61175d0ae43", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/kIg517pD726BQBJd0BFaRRFp_lxR4UgcivDnjxQ3eDU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=02b38a32f7d6cc41949eaf7147c1297d92de8336", "width": 640, "height": 640}], "variants": {}, "id": "qu3d776Cb7FpsGz7qcU2nFbovrgpjkDLjY1Xv9XQUdY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_3fd1q", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y2s60l", "is_robot_indexable": true, "report_reasons": null, "author": "piklu", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataCamp/comments/y2s60l/i_have_difficulty_understanding_how_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataCamp/comments/y2s60l/i_have_difficulty_understanding_how_this/", "subreddit_subscribers": 3039, "created_utc": 1665645454.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1665645851.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataCamp", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/DataCamp/comments/y2s60l/i_have_difficulty_understanding_how_this/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/kIg517pD726BQBJd0BFaRRFp_lxR4UgcivDnjxQ3eDU.jpg?auto=webp&amp;s=13bb2b6b27523958afe3547ee33472ec6a86eb7b", "width": 853, "height": 853}, "resolutions": [{"url": "https://external-preview.redd.it/kIg517pD726BQBJd0BFaRRFp_lxR4UgcivDnjxQ3eDU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c2b76c8331b8006680ab6d6894a8529660b9cd53", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/kIg517pD726BQBJd0BFaRRFp_lxR4UgcivDnjxQ3eDU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=537df3c91354af78667d89761aeec32bfe3721e3", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/kIg517pD726BQBJd0BFaRRFp_lxR4UgcivDnjxQ3eDU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d0e26b579f377a9e9d42bc546454f61175d0ae43", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/kIg517pD726BQBJd0BFaRRFp_lxR4UgcivDnjxQ3eDU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=02b38a32f7d6cc41949eaf7147c1297d92de8336", "width": 640, "height": 640}], "variants": {}, "id": "qu3d776Cb7FpsGz7qcU2nFbovrgpjkDLjY1Xv9XQUdY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y2s9wa", "is_robot_indexable": true, "report_reasons": null, "author": "piklu", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_y2s60l", "author_flair_text_color": null, "permalink": "/r/datascience/comments/y2s9wa/difficulty_understanding_how_this_regression/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/DataCamp/comments/y2s60l/i_have_difficulty_understanding_how_this/", "subreddit_subscribers": 813296, "created_utc": 1665645851.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_jnd0j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Debunking Myths about \"Soft Skills\" - Reaction (Nick Wan)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_y2e95u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/33G7nElnccE?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Debunking Myths about &amp;quot;Soft Skills&amp;quot;\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Debunking Myths about \"Soft Skills\"", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/33G7nElnccE?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Debunking Myths about &amp;quot;Soft Skills&amp;quot;\"&gt;&lt;/iframe&gt;", "author_name": "Nick Wan", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/33G7nElnccE/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/c/NickWan"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/33G7nElnccE?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Debunking Myths about &amp;quot;Soft Skills&amp;quot;\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/y2e95u", "height": 200}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/pbt1xK6UndUvQKRXQCl5v5M2iWdD3yoV_7Ydu-hQrI8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1665605823.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=33G7nElnccE", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/u1ufZmWRkS4t99UJuYNhob-H_rGcRWKSahRNS1fax2g.jpg?auto=webp&amp;s=8f8627a3c94d7fdd0826f33889734591db892e9f", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/u1ufZmWRkS4t99UJuYNhob-H_rGcRWKSahRNS1fax2g.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=66c54be0ab0846d1cdef1d05c473dfaed6805430", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/u1ufZmWRkS4t99UJuYNhob-H_rGcRWKSahRNS1fax2g.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f4f194d546d64875003768ef91b4453aa3cf55f7", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/u1ufZmWRkS4t99UJuYNhob-H_rGcRWKSahRNS1fax2g.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=316ac028b264807fcd1382fe37e85e43f77aebe2", "width": 320, "height": 240}], "variants": {}, "id": "uvvAoJ_nIe71xAsgIu19nNvszOn1_m7TPhcnYAaA8Ow"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "y2e95u", "is_robot_indexable": true, "report_reasons": null, "author": "Creeeeeeeeeeg", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y2e95u/debunking_myths_about_soft_skills_reaction_nick/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=33G7nElnccE", "subreddit_subscribers": 813296, "created_utc": 1665605823.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Debunking Myths about \"Soft Skills\"", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/33G7nElnccE?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Debunking Myths about &amp;quot;Soft Skills&amp;quot;\"&gt;&lt;/iframe&gt;", "author_name": "Nick Wan", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/33G7nElnccE/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/c/NickWan"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_9rx001ie", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a way to find out a companies DTC sales from their e-commerce store/general online sales?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y2d2ny", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665603064.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y2d2ny", "is_robot_indexable": true, "report_reasons": null, "author": "WatchWatcher2021", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y2d2ny/is_there_a_way_to_find_out_a_companies_dtc_sales/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y2d2ny/is_there_a_way_to_find_out_a_companies_dtc_sales/", "subreddit_subscribers": 813296, "created_utc": 1665603064.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I got a call from Microsoft, and had initial conversation about the role and I was told that I would get further details !! Now after a week, when I checked about the update, they told me that due to restructure in the company, hiring process slowed down a bit and it would take a month for the recruitment process to start! \n\nIS this common or my profile got kicked out?", "author_fullname": "t2_d1tbow3z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "IS HIRING REALLY SLOWED DOWN IN MAANG/Microsoft companies?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y2ar5n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665597559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got a call from Microsoft, and had initial conversation about the role and I was told that I would get further details !! Now after a week, when I checked about the update, they told me that due to restructure in the company, hiring process slowed down a bit and it would take a month for the recruitment process to start! &lt;/p&gt;\n\n&lt;p&gt;IS this common or my profile got kicked out?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y2ar5n", "is_robot_indexable": true, "report_reasons": null, "author": "Crypto-boy-hodl", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y2ar5n/is_hiring_really_slowed_down_in_maangmicrosoft/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y2ar5n/is_hiring_really_slowed_down_in_maangmicrosoft/", "subreddit_subscribers": 813296, "created_utc": 1665597559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_h3obmq9f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How far can A.I go when it's even ''creative'' now ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_y25ojs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/zSJt36__HKk?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"&amp;#39;&amp;#39;SB2TS&amp;#39;&amp;#39; but every lyric is an A.I generated image\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "''SB2TS'' but every lyric is an A.I generated image", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/zSJt36__HKk?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"&amp;#39;&amp;#39;SB2TS&amp;#39;&amp;#39; but every lyric is an A.I generated image\"&gt;&lt;/iframe&gt;", "author_name": "L.A Bluez", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/zSJt36__HKk/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/channel/UCPpQwIhqZgy0m9xw1uNZQXw"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/zSJt36__HKk?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"&amp;#39;&amp;#39;SB2TS&amp;#39;&amp;#39; but every lyric is an A.I generated image\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/y25ojs", "height": 200}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/iObPsDEVXDYVhgvdtQGbYuzY2150z8EtU5GPzvOC9MM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1665585539.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://youtube.com/watch?v=zSJt36__HKk&amp;feature=share", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/prW1MBX7NZeCKizUSNUtHSXDzMrkgE0PTPn20clfGw8.jpg?auto=webp&amp;s=f416905b571da44129e4085d0973abd70729e6f9", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/prW1MBX7NZeCKizUSNUtHSXDzMrkgE0PTPn20clfGw8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9b8e526eaedf0c6e5ba1ddf368729986f77c52b4", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/prW1MBX7NZeCKizUSNUtHSXDzMrkgE0PTPn20clfGw8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8c2aad42ea0965e7db2907c90b881d0e63d5a69d", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/prW1MBX7NZeCKizUSNUtHSXDzMrkgE0PTPn20clfGw8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=55bdc46f26e140587b306f142918e3ec6b92fa36", "width": 320, "height": 240}], "variants": {}, "id": "Ft7Ih560sCHpATrL9S6fJcJEgQukXFzcsbp6MboDtzU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "y25ojs", "is_robot_indexable": true, "report_reasons": null, "author": "LABluez17", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y25ojs/how_far_can_ai_go_when_its_even_creative_now/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtube.com/watch?v=zSJt36__HKk&amp;feature=share", "subreddit_subscribers": 813296, "created_utc": 1665585539.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "''SB2TS'' but every lyric is an A.I generated image", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/zSJt36__HKk?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"&amp;#39;&amp;#39;SB2TS&amp;#39;&amp;#39; but every lyric is an A.I generated image\"&gt;&lt;/iframe&gt;", "author_name": "L.A Bluez", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/zSJt36__HKk/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/channel/UCPpQwIhqZgy0m9xw1uNZQXw"}}, "is_video": false}}], "before": null}}