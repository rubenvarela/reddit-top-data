{"kind": "Listing", "data": {"after": "t3_y9dypw", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been an Azure consultant for several years in a mid-sized consulting firm. When we do solutioning and prototyping for our clients we typically exclusively rely on Azure managed services for data and analytics - Synapse, Data Factory, Azure SQL, Databricks, ADLS, etc.\n\nAnd while that's all well and good, I feel like we are really constrained with what types of tools and technology we are allowed to work with. I suggested dbt recently to a client who wanted a way to validate their data automatically as part of their ETL pipeline, and my manager came back to me and slapped me on the wrist and said I shouldn't be suggesting open source tools to a client, because if anything goes wrong it becomes a huge liability and they cannot get support from Microsoft, so we would be on the hook for support. (She had never heard of dbt and had no idea what it does). Instead we should always use the official off the shelf Microsoft-supported tools with SLAs, etc.\n\nAs I learn more about the DE ecosystem of tools I am realizing that there's an entire universe of stuff out there that none of my peers at my company bother to learn or touch, and I feel like it's slowing me down and constraining me. Trino, Airbyte, Dagster, Airflow, Iceberg, Docker, Kubernetes, Terraform. If I mention any of these things to my peers or manager they look at me like I have two heads, and if I suggest using them it gets no traction because nobody wants to learn how to use a command line. It seems like the culture at my shop is just settling with what's easy and what makes the Microsoft partners happy, not with the best tool for the job.\n\nAnyone else experience anything like this?", "author_fullname": "t2_thw4nqfo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Azure] Company is telling me not to use open-source tools because they are \"unreliable\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y979cd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 67, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 67, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666293593.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been an Azure consultant for several years in a mid-sized consulting firm. When we do solutioning and prototyping for our clients we typically exclusively rely on Azure managed services for data and analytics - Synapse, Data Factory, Azure SQL, Databricks, ADLS, etc.&lt;/p&gt;\n\n&lt;p&gt;And while that&amp;#39;s all well and good, I feel like we are really constrained with what types of tools and technology we are allowed to work with. I suggested dbt recently to a client who wanted a way to validate their data automatically as part of their ETL pipeline, and my manager came back to me and slapped me on the wrist and said I shouldn&amp;#39;t be suggesting open source tools to a client, because if anything goes wrong it becomes a huge liability and they cannot get support from Microsoft, so we would be on the hook for support. (She had never heard of dbt and had no idea what it does). Instead we should always use the official off the shelf Microsoft-supported tools with SLAs, etc.&lt;/p&gt;\n\n&lt;p&gt;As I learn more about the DE ecosystem of tools I am realizing that there&amp;#39;s an entire universe of stuff out there that none of my peers at my company bother to learn or touch, and I feel like it&amp;#39;s slowing me down and constraining me. Trino, Airbyte, Dagster, Airflow, Iceberg, Docker, Kubernetes, Terraform. If I mention any of these things to my peers or manager they look at me like I have two heads, and if I suggest using them it gets no traction because nobody wants to learn how to use a command line. It seems like the culture at my shop is just settling with what&amp;#39;s easy and what makes the Microsoft partners happy, not with the best tool for the job.&lt;/p&gt;\n\n&lt;p&gt;Anyone else experience anything like this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y979cd", "is_robot_indexable": true, "report_reasons": null, "author": "BoofThatShit720", "discussion_type": null, "num_comments": 57, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y979cd/azure_company_is_telling_me_not_to_use_opensource/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y979cd/azure_company_is_telling_me_not_to_use_opensource/", "subreddit_subscribers": 77279, "created_utc": 1666293593.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_bvkm0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A good writeup on the newly-announced semantic layer for dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 91, "top_awarded_type": null, "hide_score": false, "name": "t3_y9apc6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 61, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 61, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/2HilXP6CtgR68qUEN8tuTvMkI7Vtfg18iJ_jn07xj_k.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666301688.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.rittmananalytics.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.rittmananalytics.com/the-dbt-semantic-layer-data-orchestration-and-the-modern-enterprise-data-stack-78d9d9ed5c18", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/w_NkvohKFOI1KtF7p-1v5oFuHUelqHNKi48TbFQd0og.jpg?auto=webp&amp;s=34bc622ac70557d40aa0f114919e6aa24e971de9", "width": 1200, "height": 787}, "resolutions": [{"url": "https://external-preview.redd.it/w_NkvohKFOI1KtF7p-1v5oFuHUelqHNKi48TbFQd0og.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=283fe5a6df56b69403262cbf8a07cf2ea8cd95eb", "width": 108, "height": 70}, {"url": "https://external-preview.redd.it/w_NkvohKFOI1KtF7p-1v5oFuHUelqHNKi48TbFQd0og.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c999f27bc2732691c01285ad630f8e66a8f7c95b", "width": 216, "height": 141}, {"url": "https://external-preview.redd.it/w_NkvohKFOI1KtF7p-1v5oFuHUelqHNKi48TbFQd0og.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=05632f2c4043ed981ebe781a53d3e69040e19e80", "width": 320, "height": 209}, {"url": "https://external-preview.redd.it/w_NkvohKFOI1KtF7p-1v5oFuHUelqHNKi48TbFQd0og.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=90a1d8002fc9dbc4b07f8baba205c004de6ac380", "width": 640, "height": 419}, {"url": "https://external-preview.redd.it/w_NkvohKFOI1KtF7p-1v5oFuHUelqHNKi48TbFQd0og.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=058fa4e65d2abeb1100c53ba7856cf55fa713607", "width": 960, "height": 629}, {"url": "https://external-preview.redd.it/w_NkvohKFOI1KtF7p-1v5oFuHUelqHNKi48TbFQd0og.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3a483902f0011e4e89050e4effa8ac4fe295d53f", "width": 1080, "height": 708}], "variants": {}, "id": "oSI4QOB8fz7luHI9CsQYm0tB9nEEfqPVOak7_a0RVkY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "y9apc6", "is_robot_indexable": true, "report_reasons": null, "author": "rmoff", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9apc6/a_good_writeup_on_the_newlyannounced_semantic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.rittmananalytics.com/the-dbt-semantic-layer-data-orchestration-and-the-modern-enterprise-data-stack-78d9d9ed5c18", "subreddit_subscribers": 77279, "created_utc": 1666301688.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_sa3mbz4l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "It is a recession after all, isn't it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_y9xa2k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 70, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 70, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/oKhcYT0kIgJcwFqz5o_KuYTtbuks9ofkJd2gX1UvKRs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666367817.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/i2wm18ghl6v91.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/i2wm18ghl6v91.png?auto=webp&amp;s=ea915027b60d524ac456c1ae90335b5605cd876c", "width": 500, "height": 700}, "resolutions": [{"url": "https://preview.redd.it/i2wm18ghl6v91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=88aea7b9b817bbb1c3cb4c226a7274851c200e12", "width": 108, "height": 151}, {"url": "https://preview.redd.it/i2wm18ghl6v91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=36bfd2db4d1f91e47db03ef656138c63ef3fefee", "width": 216, "height": 302}, {"url": "https://preview.redd.it/i2wm18ghl6v91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8cef543faf1211c6409322b8f1605f7edd5d6fdc", "width": 320, "height": 448}], "variants": {}, "id": "E403cU_KwdNMd3cN_f8qQqaVwWeirvnKva-C1_w0xdw"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "y9xa2k", "is_robot_indexable": true, "report_reasons": null, "author": "MooJerseyCreamery", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9xa2k/it_is_a_recession_after_all_isnt_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/i2wm18ghl6v91.png", "subreddit_subscribers": 77279, "created_utc": 1666367817.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been in the technology space for over 20 years, and I\u2019ve never known how to properly answer this question, especially since transitioning to the data space. Over the course of my career I\u2019ve used terms such as Computer Programmer, Software Developer, Software Engineer, Data Engineer and simply IT with varying degrees of success depending on my audience. \n\nHow do you answer this question?", "author_fullname": "t2_13fc3u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\u201cWhat do you do for a living?\u201d", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9fgqh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666314047.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been in the technology space for over 20 years, and I\u2019ve never known how to properly answer this question, especially since transitioning to the data space. Over the course of my career I\u2019ve used terms such as Computer Programmer, Software Developer, Software Engineer, Data Engineer and simply IT with varying degrees of success depending on my audience. &lt;/p&gt;\n\n&lt;p&gt;How do you answer this question?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "y9fgqh", "is_robot_indexable": true, "report_reasons": null, "author": "crispyTacoTrain", "discussion_type": null, "num_comments": 60, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9fgqh/what_do_you_do_for_a_living/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9fgqh/what_do_you_do_for_a_living/", "subreddit_subscribers": 77279, "created_utc": 1666314047.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys, I am kinda newbie in this field and I want some advice from experts here.\n\nI have an accounting degree and I am shifting my career towards Business intelligence initially and might try data management if I found my passion there, I studied python basics but I keep hearing from others that Data Structures and algorithms are necessary in any CS field and that I have to practice a lot on LeetCode , so is it really a prerequisite to be one of the best talents in the future when I am senior ?", "author_fullname": "t2_77kq9xsm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Structures and algorithms for BI and Data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9e6g8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666310505.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I am kinda newbie in this field and I want some advice from experts here.&lt;/p&gt;\n\n&lt;p&gt;I have an accounting degree and I am shifting my career towards Business intelligence initially and might try data management if I found my passion there, I studied python basics but I keep hearing from others that Data Structures and algorithms are necessary in any CS field and that I have to practice a lot on LeetCode , so is it really a prerequisite to be one of the best talents in the future when I am senior ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "y9e6g8", "is_robot_indexable": true, "report_reasons": null, "author": "Ill-Confidence1806", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9e6g8/data_structures_and_algorithms_for_bi_and_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9e6g8/data_structures_and_algorithms_for_bi_and_data/", "subreddit_subscribers": 77279, "created_utc": 1666310505.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_rcx1cqyo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineers: the Dwight Schrutes and Michael Scotts of the enterprise?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 89, "top_awarded_type": null, "hide_score": false, "name": "t3_y9dk3b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/z6C7y41TuoAWgizcYCQuSxmPNibm6Hr_ureITs7LVz8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666308850.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@laurengreerbalik/the-modern-data-stack-through-the-gervais-principle-bfd4b4e33ac7", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/gH0xucWP8l6GHZbp8Et6MFGSzwyHs1e1KZValrao2OM.jpg?auto=webp&amp;s=f8b243613670076e36e033a718bad78408a4100a", "width": 1088, "height": 698}, "resolutions": [{"url": "https://external-preview.redd.it/gH0xucWP8l6GHZbp8Et6MFGSzwyHs1e1KZValrao2OM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=67837b0012d4612507c8e668f22223ffc9542f3d", "width": 108, "height": 69}, {"url": "https://external-preview.redd.it/gH0xucWP8l6GHZbp8Et6MFGSzwyHs1e1KZValrao2OM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8e505160e1d9192b3ce2c0cea26202b74c649153", "width": 216, "height": 138}, {"url": "https://external-preview.redd.it/gH0xucWP8l6GHZbp8Et6MFGSzwyHs1e1KZValrao2OM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=91cdb2fd3fbef5b36708fd76cdc719ec83bfa9ab", "width": 320, "height": 205}, {"url": "https://external-preview.redd.it/gH0xucWP8l6GHZbp8Et6MFGSzwyHs1e1KZValrao2OM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2f2e0503114bb23fed9d75d924cf30bac3fad7e8", "width": 640, "height": 410}, {"url": "https://external-preview.redd.it/gH0xucWP8l6GHZbp8Et6MFGSzwyHs1e1KZValrao2OM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b1453c6bd21d8e454f7c99e958d15aa1e7985de1", "width": 960, "height": 615}, {"url": "https://external-preview.redd.it/gH0xucWP8l6GHZbp8Et6MFGSzwyHs1e1KZValrao2OM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a38b9f5271e087af88194476e74e3e17fc0b960e", "width": 1080, "height": 692}], "variants": {}, "id": "_YvsMCd7jSlheVNi0GHad-4zcCtcx35qbnquSZUEAZQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y9dk3b", "is_robot_indexable": true, "report_reasons": null, "author": "----bubba----", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9dk3b/data_engineers_the_dwight_schrutes_and_michael/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@laurengreerbalik/the-modern-data-stack-through-the-gervais-principle-bfd4b4e33ac7", "subreddit_subscribers": 77279, "created_utc": 1666308850.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys , I\u2019m a complete noob in this field. So far I\u2019ve worked mostly on Frontend projects. I\u2019ve worked a little with AWS data modelling for a small app and had a course where we covered relational databases and concepts under that umbrella, an example being table normalization. \n\nI\u2019m currently enrolled in a systems analysis and design course , and am reading the following textbooks to learn by myself \n\n-  computer organization and design - David Patterson \n- computer architecture : a quantitative approach - also by Patterson \n- parallel computer architecture - David culler \n\n\nCan I also start reading designing data intensive applications. Am I going about this the right way? Utilizing the right materials? Some guidance from you experienced folks would be lovely. Thank you \ud83d\ude4f\ud83c\udffc", "author_fullname": "t2_k6wgicc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just picked up the book \u201cDesigning Data Intensive Applications\u201d", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9ujpz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666360970.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys , I\u2019m a complete noob in this field. So far I\u2019ve worked mostly on Frontend projects. I\u2019ve worked a little with AWS data modelling for a small app and had a course where we covered relational databases and concepts under that umbrella, an example being table normalization. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m currently enrolled in a systems analysis and design course , and am reading the following textbooks to learn by myself &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt; computer organization and design - David Patterson &lt;/li&gt;\n&lt;li&gt;computer architecture : a quantitative approach - also by Patterson &lt;/li&gt;\n&lt;li&gt;parallel computer architecture - David culler &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Can I also start reading designing data intensive applications. Am I going about this the right way? Utilizing the right materials? Some guidance from you experienced folks would be lovely. Thank you \ud83d\ude4f\ud83c\udffc&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y9ujpz", "is_robot_indexable": true, "report_reasons": null, "author": "arib_kamal", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9ujpz/just_picked_up_the_book_designing_data_intensive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9ujpz/just_picked_up_the_book_designing_data_intensive/", "subreddit_subscribers": 77279, "created_utc": 1666360970.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\n[See https:\\/\\/twitter.com\\/i\\/status\\/1583111543327436800](https://preview.redd.it/bhi47r8de1v91.png?width=892&amp;format=png&amp;auto=webp&amp;s=89ce9cd2c433a6ac7dfc995ff730829ac000dccf)", "author_fullname": "t2_pl4q8ng7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "More of your Snowflake credits at work", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"bhi47r8de1v91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 125, "x": 108, "u": "https://preview.redd.it/bhi47r8de1v91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=cd8c8cdbf7e534fd76a2fd0050f06560a7ab3417"}, {"y": 250, "x": 216, "u": "https://preview.redd.it/bhi47r8de1v91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=91392447ca85a2df4a41c5631229eaa574e1f66c"}, {"y": 370, "x": 320, "u": "https://preview.redd.it/bhi47r8de1v91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d36801bb52ad3bb70edc7e005b2f555afca647ce"}, {"y": 741, "x": 640, "u": "https://preview.redd.it/bhi47r8de1v91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b7fbc64234e596313569726aec3a064e0fd364b2"}], "s": {"y": 1033, "x": 892, "u": "https://preview.redd.it/bhi47r8de1v91.png?width=892&amp;format=png&amp;auto=webp&amp;s=89ce9cd2c433a6ac7dfc995ff730829ac000dccf"}, "id": "bhi47r8de1v91"}}, "name": "t3_y9c0ub", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/KX6uyZ0X7ANaaiYpDszhrjdxih9gAVWHngkVePqOneU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666304899.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/bhi47r8de1v91.png?width=892&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=89ce9cd2c433a6ac7dfc995ff730829ac000dccf\"&gt;See https://twitter.com/i/status/1583111543327436800&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "y9c0ub", "is_robot_indexable": true, "report_reasons": null, "author": "droppedorphan", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9c0ub/more_of_your_snowflake_credits_at_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9c0ub/more_of_your_snowflake_credits_at_work/", "subreddit_subscribers": 77279, "created_utc": 1666304899.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m a DE with 3 YoE in DE and 5 YoE in Software. \n\nI set aside about 4-8 hours a week for upskilling but I\u2019m sort\u2019ve in a rut when it comes to what to learn next. \n\nI\u2019m proficient in all of the usual SQL, Python, AWS, Docker, K8s, Airflow, Kafka, Spark, dbt, Terraform, Golang, etc. just from my jobs (not trying to brag just trying to list out things I know so people have an idea of what to suggest.)\n\nThis year I\u2019ve been upskilling on random stuff, I taught myself some basic cyber security (tryhackme), and frontend webdev in conjunction with Rust to try to write a rudimentary web apps during my upskill hours to pass the time.\n\nWhile I\u2019ve enjoyed just doing random stuff, I haven\u2019t spent much time getting better at DE and feel I will stagnate if I don\u2019t at least put some effort into DE specific things so I figured I would ask what some of the more experienced people think I should add to my arsenal of languages/skills? \n\nI appreciate any suggestions! Thanks!", "author_fullname": "t2_160eq4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Those of you who use other languages/tools for DE (Not SQL or Python) which ones and why? Do you recommend them?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9b276", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666302558.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m a DE with 3 YoE in DE and 5 YoE in Software. &lt;/p&gt;\n\n&lt;p&gt;I set aside about 4-8 hours a week for upskilling but I\u2019m sort\u2019ve in a rut when it comes to what to learn next. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m proficient in all of the usual SQL, Python, AWS, Docker, K8s, Airflow, Kafka, Spark, dbt, Terraform, Golang, etc. just from my jobs (not trying to brag just trying to list out things I know so people have an idea of what to suggest.)&lt;/p&gt;\n\n&lt;p&gt;This year I\u2019ve been upskilling on random stuff, I taught myself some basic cyber security (tryhackme), and frontend webdev in conjunction with Rust to try to write a rudimentary web apps during my upskill hours to pass the time.&lt;/p&gt;\n\n&lt;p&gt;While I\u2019ve enjoyed just doing random stuff, I haven\u2019t spent much time getting better at DE and feel I will stagnate if I don\u2019t at least put some effort into DE specific things so I figured I would ask what some of the more experienced people think I should add to my arsenal of languages/skills? &lt;/p&gt;\n\n&lt;p&gt;I appreciate any suggestions! Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y9b276", "is_robot_indexable": true, "report_reasons": null, "author": "SirAutismx7", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9b276/those_of_you_who_use_other_languagestools_for_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9b276/those_of_you_who_use_other_languagestools_for_de/", "subreddit_subscribers": 77279, "created_utc": 1666302558.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Mainly an analytics engineer, so I live in dbt and almost exclusively use SQL. I do know some python, and can write simple cloud functions on GCP, but I don't know any other languages such as C++ or Java.\n\nI'm asking because it looks like Python and SQL might be enough for most roles, and I'm using that as a basis for which classes to take in the future for a MSCS. Not sure the time spent learning C++ or Java at this point in my life (I'm 37) would have any benefits in DE. I could see the benefits if I wanted to be a software engineer or if I was personally interested in learning those languages, but I'm not for either of those cases.\n\nAm I missing out on anything?", "author_fullname": "t2_3uoce3bn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I missing out on anything by not learning languages like C++ or Java?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9r8cv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666351668.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Mainly an analytics engineer, so I live in dbt and almost exclusively use SQL. I do know some python, and can write simple cloud functions on GCP, but I don&amp;#39;t know any other languages such as C++ or Java.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m asking because it looks like Python and SQL might be enough for most roles, and I&amp;#39;m using that as a basis for which classes to take in the future for a MSCS. Not sure the time spent learning C++ or Java at this point in my life (I&amp;#39;m 37) would have any benefits in DE. I could see the benefits if I wanted to be a software engineer or if I was personally interested in learning those languages, but I&amp;#39;m not for either of those cases.&lt;/p&gt;\n\n&lt;p&gt;Am I missing out on anything?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y9r8cv", "is_robot_indexable": true, "report_reasons": null, "author": "Tender_Figs", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9r8cv/am_i_missing_out_on_anything_by_not_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9r8cv/am_i_missing_out_on_anything_by_not_learning/", "subreddit_subscribers": 77279, "created_utc": 1666351668.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys, on 27th October [Memphis.dev](https://github.com/memphisdev/memphis-broker) is co-hosting  A roundtable around the current trends and challenges of data streaming, design decisions, tech stacks, and use cases. \n\nPure knowledge sharing with the local community of devs and data engineers. \n\n810 7th Ave \u00b7 New York, NY.\n\n&amp;#x200B;\n\nAll data enthusiasts are welcome to join \n\nRSVP \n\n[https://www.meetup.com/developers-and-data-powered-by-memphis-dev-platform/events/288432501/](https://www.meetup.com/developers-and-data-powered-by-memphis-dev-platform/events/288432501/)", "author_fullname": "t2_bqjrmnud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NYC Data Engineering Meetup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9n17i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666337482.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, on 27th October &lt;a href=\"https://github.com/memphisdev/memphis-broker\"&gt;Memphis.dev&lt;/a&gt; is co-hosting  A roundtable around the current trends and challenges of data streaming, design decisions, tech stacks, and use cases. &lt;/p&gt;\n\n&lt;p&gt;Pure knowledge sharing with the local community of devs and data engineers. &lt;/p&gt;\n\n&lt;p&gt;810 7th Ave \u00b7 New York, NY.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;All data enthusiasts are welcome to join &lt;/p&gt;\n\n&lt;p&gt;RSVP &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.meetup.com/developers-and-data-powered-by-memphis-dev-platform/events/288432501/\"&gt;https://www.meetup.com/developers-and-data-powered-by-memphis-dev-platform/events/288432501/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?auto=webp&amp;s=7227dddf662629d580f2e430eeaa2ae7294e47ed", "width": 1280, "height": 720}, "resolutions": [{"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5dcdc025b6b3954b0c2714b519db2547e7ead491", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=902b11284debb4eadeba71f4551344bc40315415", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=53f00cfe89098449638e871f4fd704e82f812323", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2baf0c623ee36336ec2367e3798b342c620f62dc", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=76d99efca5f389a98a9f349d4b1771a36ecdf6dd", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ed456664e401712061ce47dcc47505d0a6c93b34", "width": 1080, "height": 607}], "variants": {}, "id": "hYBYKmUFkskiOV8szz3ckSx7rnZYTEJIAAkPfkZc44g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "y9n17i", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering_Bug105", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9n17i/nyc_data_engineering_meetup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9n17i/nyc_data_engineering_meetup/", "subreddit_subscribers": 77279, "created_utc": 1666337482.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Many of you will likely find this useful -- our open-source team has spent the last few years building out the much-needed standard python framework for all things #datacentricAI.\n\nToday we launched Out-of-Distribution Detection now natively supported in cleanlab 2.1 to help you automatically find and remove outliers in your datasets so you can train models and perform analytics on reliable data -- **it's only one line of code to use.**\n\n[Our algorithms detect out-of-distribution data like this \\\\\"3\\\\\" included in a clothing dataset](https://preview.redd.it/wvrdnaeca6v91.jpg?width=720&amp;format=pjpg&amp;auto=webp&amp;s=d406cbf3cbaf568735e2f0f1e3a1b705e0e52719)\n\nWhat makes our out-of-distribution package different?\n\nMany complex OOD detection algorithms exist but they are only applicable to specific data types. The `cleanlab.outlier`package works as effectively as these complex methods, but also works with any type of data for which either a feature embedding or trained classifier is available.\n\n`cleanlab.outlier`is:\n\n* [Open-source](https://github.com/cleanlab/cleanlab) and free to use\n* [Research published](https://arxiv.org/abs/2207.03061) \\+ few-lines-of-code [tutorials](https://docs.cleanlab.ai/stable/tutorials/outliers.html)\n* [Benchmarked](https://github.com/cleanlab/ood-detection-benchmarks) to show superior performance in the landscape of OOD methods.\n\nHave fun using `cleanlab.outlier`!\n\nBlog: [https://cleanlab.ai/blog/outlier-detection/](https://cleanlab.ai/blog/outlier-detection/)", "author_fullname": "t2_5v7p3x0j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Detecting Out-of-Distribution Datapoints via Embeddings or Predictions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 55, "top_awarded_type": null, "hide_score": false, "media_metadata": {"wvrdnaeca6v91": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 42, "x": 108, "u": "https://preview.redd.it/wvrdnaeca6v91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=25f828eb4762b0a2f6c9a6b6b435957fecb722df"}, {"y": 85, "x": 216, "u": "https://preview.redd.it/wvrdnaeca6v91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9b4db33bc957ca22f5b155f23db507e6e4942b9d"}, {"y": 127, "x": 320, "u": "https://preview.redd.it/wvrdnaeca6v91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=072dec9d0a87cfd85f880d2f5fe3009703c3ccb1"}, {"y": 254, "x": 640, "u": "https://preview.redd.it/wvrdnaeca6v91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=51e5f51a39dbdf934523c16010986d4a36c2ec31"}], "s": {"y": 286, "x": 720, "u": "https://preview.redd.it/wvrdnaeca6v91.jpg?width=720&amp;format=pjpg&amp;auto=webp&amp;s=d406cbf3cbaf568735e2f0f1e3a1b705e0e52719"}, "id": "wvrdnaeca6v91"}}, "name": "t3_y9vu5f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/LTGb2mWFn7620r2Ky06d3e-fFSnjgc9BECIudHN2UL0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666364163.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Many of you will likely find this useful -- our open-source team has spent the last few years building out the much-needed standard python framework for all things #datacentricAI.&lt;/p&gt;\n\n&lt;p&gt;Today we launched Out-of-Distribution Detection now natively supported in cleanlab 2.1 to help you automatically find and remove outliers in your datasets so you can train models and perform analytics on reliable data -- &lt;strong&gt;it&amp;#39;s only one line of code to use.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/wvrdnaeca6v91.jpg?width=720&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=d406cbf3cbaf568735e2f0f1e3a1b705e0e52719\"&gt;Our algorithms detect out-of-distribution data like this \\&amp;quot;3\\&amp;quot; included in a clothing dataset&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;What makes our out-of-distribution package different?&lt;/p&gt;\n\n&lt;p&gt;Many complex OOD detection algorithms exist but they are only applicable to specific data types. The &lt;code&gt;cleanlab.outlier&lt;/code&gt;package works as effectively as these complex methods, but also works with any type of data for which either a feature embedding or trained classifier is available.&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;cleanlab.outlier&lt;/code&gt;is:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/cleanlab/cleanlab\"&gt;Open-source&lt;/a&gt; and free to use&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://arxiv.org/abs/2207.03061\"&gt;Research published&lt;/a&gt; + few-lines-of-code &lt;a href=\"https://docs.cleanlab.ai/stable/tutorials/outliers.html\"&gt;tutorials&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/cleanlab/ood-detection-benchmarks\"&gt;Benchmarked&lt;/a&gt; to show superior performance in the landscape of OOD methods.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Have fun using &lt;code&gt;cleanlab.outlier&lt;/code&gt;!&lt;/p&gt;\n\n&lt;p&gt;Blog: &lt;a href=\"https://cleanlab.ai/blog/outlier-detection/\"&gt;https://cleanlab.ai/blog/outlier-detection/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "y9vu5f", "is_robot_indexable": true, "report_reasons": null, "author": "jonas__m", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9vu5f/detecting_outofdistribution_datapoints_via/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9vu5f/detecting_outofdistribution_datapoints_via/", "subreddit_subscribers": 77279, "created_utc": 1666364163.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_zia33", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DataProfiler: What's in your data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_y9s1xi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.62, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/F8KDao-juHDzXtQClxdta0TEIIU-2KV9y2k-l4Zz5hg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666354073.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/capitalone/DataProfiler", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/HlEdNMV-y2rTFX-aWd6KSkwfZthKlH3wHbOo37OAGhU.jpg?auto=webp&amp;s=327e8583f46a92e6f036839bac1fa10b05b95ccf", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/HlEdNMV-y2rTFX-aWd6KSkwfZthKlH3wHbOo37OAGhU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d6cb43643da4623a7da30465744962cb59af79f2", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/HlEdNMV-y2rTFX-aWd6KSkwfZthKlH3wHbOo37OAGhU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c164acaa39fc7f477204b047d60da0d7993c9fa7", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/HlEdNMV-y2rTFX-aWd6KSkwfZthKlH3wHbOo37OAGhU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a862497065014c055a6e110eea07da17fb897f8d", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/HlEdNMV-y2rTFX-aWd6KSkwfZthKlH3wHbOo37OAGhU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=07e0cf9ec9e34a1afb631903f1e1d173675bb848", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/HlEdNMV-y2rTFX-aWd6KSkwfZthKlH3wHbOo37OAGhU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=cba7e8e8f13df0d85542e07f74bf8d00df89c649", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/HlEdNMV-y2rTFX-aWd6KSkwfZthKlH3wHbOo37OAGhU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=69949c0002fba768f523a591dc2bd7be90efa38f", "width": 1080, "height": 540}], "variants": {}, "id": "7a2QHIt4QoH5Js0QM9-04MSSFPNASZaYeOw6r4hZ9z8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "y9s1xi", "is_robot_indexable": true, "report_reasons": null, "author": "fitz_n_fitz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9s1xi/dataprofiler_whats_in_your_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/capitalone/DataProfiler", "subreddit_subscribers": 77279, "created_utc": 1666354073.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have this large .zip that takes 2 hours to unzip the whole thing. I really only need the .csv files. Is there a way in ADF to only unzip .csv files?", "author_fullname": "t2_sirnldvp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to ONLY unzip .csv files in Azure Data Factory?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9qrty", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666350222.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have this large .zip that takes 2 hours to unzip the whole thing. I really only need the .csv files. Is there a way in ADF to only unzip .csv files?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y9qrty", "is_robot_indexable": true, "report_reasons": null, "author": "powerBIGuy14", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9qrty/is_it_possible_to_only_unzip_csv_files_in_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9qrty/is_it_possible_to_only_unzip_csv_files_in_azure/", "subreddit_subscribers": 77279, "created_utc": 1666350222.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_49cfbl1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A step-by-step tutorial on how to manipulate a table in your data lake by writing a custom plugin with VDK", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 101, "top_awarded_type": null, "hide_score": false, "name": "t3_y9tnx4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/VktSmWAXSaU5490oJOKYByY2EkGyxQyZpFoLXT6JZ28.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666358687.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "towardsdatascience.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://towardsdatascience.com/how-to-create-a-data-formatting-plugin-in-vdk-dc5f1c7d206d", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/HdOer84WK3nZFBIZjKT4tZtNHXM20Dd-gOkrR1gu-w8.jpg?auto=webp&amp;s=9c6ee1cb4d0e111f2fd2b6a740d3818417e2d9bf", "width": 1200, "height": 868}, "resolutions": [{"url": "https://external-preview.redd.it/HdOer84WK3nZFBIZjKT4tZtNHXM20Dd-gOkrR1gu-w8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=78eaacf59b0f26cfe059b3d02ea5c296f966fcfd", "width": 108, "height": 78}, {"url": "https://external-preview.redd.it/HdOer84WK3nZFBIZjKT4tZtNHXM20Dd-gOkrR1gu-w8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4f93d5c28f98253a461a53f3e2ffedd7f1bb2059", "width": 216, "height": 156}, {"url": "https://external-preview.redd.it/HdOer84WK3nZFBIZjKT4tZtNHXM20Dd-gOkrR1gu-w8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cf5d2bfe012cd1bdae16c0e174eb19c00b268082", "width": 320, "height": 231}, {"url": "https://external-preview.redd.it/HdOer84WK3nZFBIZjKT4tZtNHXM20Dd-gOkrR1gu-w8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=802ec9e6f14a0491bbbf05f7026d113fca68a813", "width": 640, "height": 462}, {"url": "https://external-preview.redd.it/HdOer84WK3nZFBIZjKT4tZtNHXM20Dd-gOkrR1gu-w8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1bb47fc5725f7e87ee87bff57c23a07c5a8bb5c5", "width": 960, "height": 694}, {"url": "https://external-preview.redd.it/HdOer84WK3nZFBIZjKT4tZtNHXM20Dd-gOkrR1gu-w8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a43c0e61cbad31f6dd6341a746afd17dd9d9e57b", "width": 1080, "height": 781}], "variants": {}, "id": "tq11CeUSiRIQW_qQxnKqt69H0JFY8X4v98kqRCps8Ko"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "y9tnx4", "is_robot_indexable": true, "report_reasons": null, "author": "zverulacis", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9tnx4/a_stepbystep_tutorial_on_how_to_manipulate_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://towardsdatascience.com/how-to-create-a-data-formatting-plugin-in-vdk-dc5f1c7d206d", "subreddit_subscribers": 77279, "created_utc": 1666358687.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I never heard this terminology until I started working with SQL. When we would have a really gnarly query that we needed to optimize or reverse engineer someone on my team said \"oh yeah this one a real bear\".\n\nSo what exactly does this mean a task that is very tedious and time consuming ? Or is there more to it.", "author_fullname": "t2_dfcot0zg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What does it mean when a DE project (or any SWE) is considered a real \"bear\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9tjl2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666358371.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I never heard this terminology until I started working with SQL. When we would have a really gnarly query that we needed to optimize or reverse engineer someone on my team said &amp;quot;oh yeah this one a real bear&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;So what exactly does this mean a task that is very tedious and time consuming ? Or is there more to it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y9tjl2", "is_robot_indexable": true, "report_reasons": null, "author": "DrRedmondNYC", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9tjl2/what_does_it_mean_when_a_de_project_or_any_swe_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9tjl2/what_does_it_mean_when_a_de_project_or_any_swe_is/", "subreddit_subscribers": 77279, "created_utc": 1666358371.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Everyone, I had some questions around FPGrowth at PySpark, i using a dataset around 20M, but i facing some issues when i tried to visualize some rules (memory errors), probably because they are creating a lot of rules even when i limited the thresholds for support/confidence.\n\n&amp;#x200B;\n\nThere's another ways to optimize this algorithm?", "author_fullname": "t2_768gsz2h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "FPGrowth and PySpark optimization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9tapl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666366020.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666357696.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone, I had some questions around FPGrowth at PySpark, i using a dataset around 20M, but i facing some issues when i tried to visualize some rules (memory errors), probably because they are creating a lot of rules even when i limited the thresholds for support/confidence.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s another ways to optimize this algorithm?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y9tapl", "is_robot_indexable": true, "report_reasons": null, "author": "suneirl1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9tapl/fpgrowth_and_pyspark_optimization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9tapl/fpgrowth_and_pyspark_optimization/", "subreddit_subscribers": 77279, "created_utc": 1666357696.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_bvkm0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Implementing Data Contracts - a Practical Example", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_y9syna", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/sUxnzUmX5-KHSfKI_rEuAPgRyhUKu675HFW7tjuByvs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666356766.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@danthelion/implementing-data-contracts-82800b9186b", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6Mr0mYy8Gg0tPZqsHyY9x5-rUfaIxHEqsxzTI3PJ84E.jpg?auto=webp&amp;s=46aca62508288c55d4151a2b4c79056d669b5f41", "width": 400, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/6Mr0mYy8Gg0tPZqsHyY9x5-rUfaIxHEqsxzTI3PJ84E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f4c6a017cbcaee64ea9102da3b7c415c2f49c1ee", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/6Mr0mYy8Gg0tPZqsHyY9x5-rUfaIxHEqsxzTI3PJ84E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=af1f37d75a8b5aa5733ae45cb3c34ef19be1e5e7", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/6Mr0mYy8Gg0tPZqsHyY9x5-rUfaIxHEqsxzTI3PJ84E.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b6c333d9371ef51b59ae929055e0b6ed99ede1b3", "width": 320, "height": 240}], "variants": {}, "id": "SthwCf5cEOddOPntr6QX8ASnB7BHgI2TWTwV92DR34w"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "y9syna", "is_robot_indexable": true, "report_reasons": null, "author": "rmoff", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9syna/implementing_data_contracts_a_practical_example/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@danthelion/implementing-data-contracts-82800b9186b", "subreddit_subscribers": 77279, "created_utc": 1666356766.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am planning to take this certification since our company offers free vouchers.\n\nTo those who passed this exam, how long did you review? So i can come up with an estimated schedule for me. Also, how's the difficulty of the exam?\n\nThanks in advance!", "author_fullname": "t2_kh03mlzp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google Professional Data Engineer Certificate - how long did you review?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9iaip", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666322217.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am planning to take this certification since our company offers free vouchers.&lt;/p&gt;\n\n&lt;p&gt;To those who passed this exam, how long did you review? So i can come up with an estimated schedule for me. Also, how&amp;#39;s the difficulty of the exam?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y9iaip", "is_robot_indexable": true, "report_reasons": null, "author": "keemi01", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9iaip/google_professional_data_engineer_certificate_how/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9iaip/google_professional_data_engineer_certificate_how/", "subreddit_subscribers": 77279, "created_utc": 1666322217.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I'm studying to become a Data Engineer but I feel insecure about if this is a role that requires previous experience in the development field. \n\nI do know how to program, I know some SQL and I have worked with some Azure tools since my main project in my current job is to make an ETL with Azure Data Factory as a Consultant (so my job isn't always doing this). \n\nThe thing is, I have no previous web development experience, no app development experience, nothing like that aside from the college projects, and I want to move to a Data Engineering role to focus on what I want to specialize. \n\nMy question is, is it necessary to have previous backend development experience?\nShould I give up studying to be a Data Engineer and study to be a backend developed and then change my role?\n\nMy current job is the only one I ever had since I graduated from college.", "author_fullname": "t2_rr47xrn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is is necessary to have previous backend development experience?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y99402", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666297934.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;m studying to become a Data Engineer but I feel insecure about if this is a role that requires previous experience in the development field. &lt;/p&gt;\n\n&lt;p&gt;I do know how to program, I know some SQL and I have worked with some Azure tools since my main project in my current job is to make an ETL with Azure Data Factory as a Consultant (so my job isn&amp;#39;t always doing this). &lt;/p&gt;\n\n&lt;p&gt;The thing is, I have no previous web development experience, no app development experience, nothing like that aside from the college projects, and I want to move to a Data Engineering role to focus on what I want to specialize. &lt;/p&gt;\n\n&lt;p&gt;My question is, is it necessary to have previous backend development experience?\nShould I give up studying to be a Data Engineer and study to be a backend developed and then change my role?&lt;/p&gt;\n\n&lt;p&gt;My current job is the only one I ever had since I graduated from college.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "y99402", "is_robot_indexable": true, "report_reasons": null, "author": "UserName029", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y99402/is_is_necessary_to_have_previous_backend/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y99402/is_is_necessary_to_have_previous_backend/", "subreddit_subscribers": 77279, "created_utc": 1666297934.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm creating a Spark DataFrame from a list of tuples using PySpark. The list can be relatively large. And with larger lists, the time could increase significantly. Most of what I've read on creating DataFrames in spark uses external files like CSV files. So I was wondering if there were any best practices I employ when creating a DataFrames from a list of tuples. \n\nI did some profiling on the various methods I have. And it looks like the majority of the time is spent creating the DataFrame. I've sped up this process somewhat by using a schema when I create the DataFrame. But this is as far as I've been able to take the optimizations.", "author_fullname": "t2_2ntu9i1o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PySpark: Creating a DataFrame from a list of tuples", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_y9yehm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666370634.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m creating a Spark DataFrame from a list of tuples using PySpark. The list can be relatively large. And with larger lists, the time could increase significantly. Most of what I&amp;#39;ve read on creating DataFrames in spark uses external files like CSV files. So I was wondering if there were any best practices I employ when creating a DataFrames from a list of tuples. &lt;/p&gt;\n\n&lt;p&gt;I did some profiling on the various methods I have. And it looks like the majority of the time is spent creating the DataFrame. I&amp;#39;ve sped up this process somewhat by using a schema when I create the DataFrame. But this is as far as I&amp;#39;ve been able to take the optimizations.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y9yehm", "is_robot_indexable": true, "report_reasons": null, "author": "ineffablol", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9yehm/pyspark_creating_a_dataframe_from_a_list_of_tuples/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9yehm/pyspark_creating_a_dataframe_from_a_list_of_tuples/", "subreddit_subscribers": 77279, "created_utc": 1666370634.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Please help\n\nI\u00b4m make docker image whidt this makerfile  \n\n\nFROM golang:1.12.14 AS builder  \n\n\nRUN apt-get update  \nENV GO111MODULE=on \\\\  \nCGO\\_ENABLED=1 \\\\  \nGOOS=linux \\\\  \nGOARCH=amd64  \n   \nWORKDIR /usr/src/app  \nCOPY go.mod .  \nRUN go mod download  \nCOPY . .  \nRUN go install   \nCMD \\[\"./main\"\\]\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nand give me this error\n\n&amp;#x200B;\n\n \n\nStep 6/9 : RUN go mod download\n\n\\---&gt; Running in b848fac6ce2e\n\ngo: finding github.com/stretchr/testify v1.3.0\n\ngo: finding github.com/jinzhu/gorm v0.0.0-20170703134954-2a1463811ee1\n\ngo: finding github.com/gosimple/slug v1.1.0\n\ngo: finding github.com/jinzhu/inflection v0.0.0-20170102125226-1c35d901db3d\n\ngo: finding github.com/denisenkom/go-mssqldb v0.0.0-20191001013358-cfbb681360f0\n\ngo: finding github.com/go-sql-driver/mysql v1.4.1\n\ngo: finding github.com/dgrijalva/jwt-go v0.0.0-20170608005149-a539ee1a749a\n\ngo: finding golang.org/x/crypto v0.0.0-20191010185427-af544f31c8ac\n\ngo: finding google.golang.org/appengine v1.6.5\n\ngo: finding gopkg.in/go-playground/validator.v8 v8.18.2\n\ngo: finding github.com/lib/pq v1.2.0\n\ngo: finding github.com/mattn/go-sqlite3 v0.0.0-20170710140056-47fc4e5e9153\n\ngo: gopkg.in/go-playground/validator.v8@v8.18.2: unknown revision v8.18.2\n\ngo: finding github.com/rainycape/unidecode v0.0.0-20150907023854-cb7f23ec59be\n\ngo: finding github.com/gin-contrib/cors v1.3.0\n\ngo: finding github.com/jinzhu/now v1.0.1\n\ngo: finding github.com/erikstmartin/go-testdb v0.0.0-20160219214506-8d10e4a1bae5\n\ngo: finding github.com/gin-gonic/gin v1.4.0\n\ngo: error loading module requirements\n\nThe command '/bin/sh -c go mod download' returned a non-zero code: 1\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nAny idea?", "author_fullname": "t2_lpw2sx7v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Docker golang make image problem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9vq7r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666363894.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Please help&lt;/p&gt;\n\n&lt;p&gt;I\u00b4m make docker image whidt this makerfile  &lt;/p&gt;\n\n&lt;p&gt;FROM golang:1.12.14 AS builder  &lt;/p&gt;\n\n&lt;p&gt;RUN apt-get update&lt;br/&gt;\nENV GO111MODULE=on \\&lt;br/&gt;\nCGO_ENABLED=1 \\&lt;br/&gt;\nGOOS=linux \\&lt;br/&gt;\nGOARCH=amd64  &lt;/p&gt;\n\n&lt;p&gt;WORKDIR /usr/src/app&lt;br/&gt;\nCOPY go.mod .&lt;br/&gt;\nRUN go mod download&lt;br/&gt;\nCOPY . .&lt;br/&gt;\nRUN go install&lt;br/&gt;\nCMD [&amp;quot;./main&amp;quot;]&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;and give me this error&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Step 6/9 : RUN go mod download&lt;/p&gt;\n\n&lt;p&gt;---&amp;gt; Running in b848fac6ce2e&lt;/p&gt;\n\n&lt;p&gt;go: finding github.com/stretchr/testify v1.3.0&lt;/p&gt;\n\n&lt;p&gt;go: finding github.com/jinzhu/gorm v0.0.0-20170703134954-2a1463811ee1&lt;/p&gt;\n\n&lt;p&gt;go: finding github.com/gosimple/slug v1.1.0&lt;/p&gt;\n\n&lt;p&gt;go: finding github.com/jinzhu/inflection v0.0.0-20170102125226-1c35d901db3d&lt;/p&gt;\n\n&lt;p&gt;go: finding github.com/denisenkom/go-mssqldb v0.0.0-20191001013358-cfbb681360f0&lt;/p&gt;\n\n&lt;p&gt;go: finding github.com/go-sql-driver/mysql v1.4.1&lt;/p&gt;\n\n&lt;p&gt;go: finding github.com/dgrijalva/jwt-go v0.0.0-20170608005149-a539ee1a749a&lt;/p&gt;\n\n&lt;p&gt;go: finding golang.org/x/crypto v0.0.0-20191010185427-af544f31c8ac&lt;/p&gt;\n\n&lt;p&gt;go: finding google.golang.org/appengine v1.6.5&lt;/p&gt;\n\n&lt;p&gt;go: finding gopkg.in/go-playground/validator.v8 v8.18.2&lt;/p&gt;\n\n&lt;p&gt;go: finding github.com/lib/pq v1.2.0&lt;/p&gt;\n\n&lt;p&gt;go: finding github.com/mattn/go-sqlite3 v0.0.0-20170710140056-47fc4e5e9153&lt;/p&gt;\n\n&lt;p&gt;go: gopkg.in/go-playground/&lt;a href=\"mailto:validator.v8@v8.18.2\"&gt;validator.v8@v8.18.2&lt;/a&gt;: unknown revision v8.18.2&lt;/p&gt;\n\n&lt;p&gt;go: finding github.com/rainycape/unidecode v0.0.0-20150907023854-cb7f23ec59be&lt;/p&gt;\n\n&lt;p&gt;go: finding github.com/gin-contrib/cors v1.3.0&lt;/p&gt;\n\n&lt;p&gt;go: finding github.com/jinzhu/now v1.0.1&lt;/p&gt;\n\n&lt;p&gt;go: finding github.com/erikstmartin/go-testdb v0.0.0-20160219214506-8d10e4a1bae5&lt;/p&gt;\n\n&lt;p&gt;go: finding github.com/gin-gonic/gin v1.4.0&lt;/p&gt;\n\n&lt;p&gt;go: error loading module requirements&lt;/p&gt;\n\n&lt;p&gt;The command &amp;#39;/bin/sh -c go mod download&amp;#39; returned a non-zero code: 1&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any idea?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y9vq7r", "is_robot_indexable": true, "report_reasons": null, "author": "Legitimate-Pea-1848", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9vq7r/docker_golang_make_image_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9vq7r/docker_golang_make_image_problem/", "subreddit_subscribers": 77279, "created_utc": 1666363894.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I have an option to do one of these 2 and I was wondering which role would be more beneficial for my data engineering career, Business Analyst or ETL tester role?\n\n&amp;#x200B;\n\nThanks for any insight!", "author_fullname": "t2_tjxw4oe5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is better, Business Analyst or ETL Tester role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9qmaq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666349749.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have an option to do one of these 2 and I was wondering which role would be more beneficial for my data engineering career, Business Analyst or ETL tester role?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks for any insight!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "y9qmaq", "is_robot_indexable": true, "report_reasons": null, "author": "de_juggin95", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9qmaq/what_is_better_business_analyst_or_etl_tester_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9qmaq/what_is_better_business_analyst_or_etl_tester_role/", "subreddit_subscribers": 77279, "created_utc": 1666349749.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So Airbyte creates data pipelines for me in an easy way. There's a cloud option and a self-host open source option.\n\nLet's say I create a pipeline in Airbyte. Let's say that this pipeline requires some CPU compute and RAM. Where is this CPU and RAM coming from? Is it on the same instance as the Airbyte app? Or do I have to create EC2/Lambda functions somewhere else and let Airbyte control them?", "author_fullname": "t2_l5aep", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where does the compute come from when I use Airbyte?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9lbtf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666331611.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So Airbyte creates data pipelines for me in an easy way. There&amp;#39;s a cloud option and a self-host open source option.&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s say I create a pipeline in Airbyte. Let&amp;#39;s say that this pipeline requires some CPU compute and RAM. Where is this CPU and RAM coming from? Is it on the same instance as the Airbyte app? Or do I have to create EC2/Lambda functions somewhere else and let Airbyte control them?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y9lbtf", "is_robot_indexable": true, "report_reasons": null, "author": "joel1234512", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9lbtf/where_does_the_compute_come_from_when_i_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9lbtf/where_does_the_compute_come_from_when_i_use/", "subreddit_subscribers": 77279, "created_utc": 1666331611.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "On Notion, I have a database with 30 employees' names, positions, emails, and phone numbers for one of my clients. I want to sync this database with the contacts section of this client's salesforce page. If an employee leaves my client's company, my client will delete him from the database, and when new employees join he will be added to the database. I hope that I will never have to recheck this database and my Salesforce data will be reliably accurate and up to date. \n\nI suppose an API like Zapier or a reverse ETL service like Hightouch could accomplish this task, but I am certain a cheaper alternative exists. Do you have any suggestions?", "author_fullname": "t2_13126k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Extremely basic bidirectional syncing issue - looking for the least expensive solution.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9dypw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666310131.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666309946.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;On Notion, I have a database with 30 employees&amp;#39; names, positions, emails, and phone numbers for one of my clients. I want to sync this database with the contacts section of this client&amp;#39;s salesforce page. If an employee leaves my client&amp;#39;s company, my client will delete him from the database, and when new employees join he will be added to the database. I hope that I will never have to recheck this database and my Salesforce data will be reliably accurate and up to date. &lt;/p&gt;\n\n&lt;p&gt;I suppose an API like Zapier or a reverse ETL service like Hightouch could accomplish this task, but I am certain a cheaper alternative exists. Do you have any suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y9dypw", "is_robot_indexable": true, "report_reasons": null, "author": "northernmostroasts", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9dypw/extremely_basic_bidirectional_syncing_issue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9dypw/extremely_basic_bidirectional_syncing_issue/", "subreddit_subscribers": 77279, "created_utc": 1666309946.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}