{"kind": "Listing", "data": {"after": "t3_y9dypw", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_sa3mbz4l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "It is a recession after all, isn't it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_y9xa2k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "ups": 158, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 158, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/oKhcYT0kIgJcwFqz5o_KuYTtbuks9ofkJd2gX1UvKRs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666367817.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/i2wm18ghl6v91.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/i2wm18ghl6v91.png?auto=webp&amp;s=ea915027b60d524ac456c1ae90335b5605cd876c", "width": 500, "height": 700}, "resolutions": [{"url": "https://preview.redd.it/i2wm18ghl6v91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=88aea7b9b817bbb1c3cb4c226a7274851c200e12", "width": 108, "height": 151}, {"url": "https://preview.redd.it/i2wm18ghl6v91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=36bfd2db4d1f91e47db03ef656138c63ef3fefee", "width": 216, "height": 302}, {"url": "https://preview.redd.it/i2wm18ghl6v91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8cef543faf1211c6409322b8f1605f7edd5d6fdc", "width": 320, "height": 448}], "variants": {}, "id": "E403cU_KwdNMd3cN_f8qQqaVwWeirvnKva-C1_w0xdw"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "y9xa2k", "is_robot_indexable": true, "report_reasons": null, "author": "MooJerseyCreamery", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9xa2k/it_is_a_recession_after_all_isnt_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/i2wm18ghl6v91.png", "subreddit_subscribers": 77303, "created_utc": 1666367817.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been in the technology space for over 20 years, and I\u2019ve never known how to properly answer this question, especially since transitioning to the data space. Over the course of my career I\u2019ve used terms such as Computer Programmer, Software Developer, Software Engineer, Data Engineer and simply IT with varying degrees of success depending on my audience. \n\nHow do you answer this question?", "author_fullname": "t2_13fc3u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\u201cWhat do you do for a living?\u201d", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9fgqh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666314047.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been in the technology space for over 20 years, and I\u2019ve never known how to properly answer this question, especially since transitioning to the data space. Over the course of my career I\u2019ve used terms such as Computer Programmer, Software Developer, Software Engineer, Data Engineer and simply IT with varying degrees of success depending on my audience. &lt;/p&gt;\n\n&lt;p&gt;How do you answer this question?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "y9fgqh", "is_robot_indexable": true, "report_reasons": null, "author": "crispyTacoTrain", "discussion_type": null, "num_comments": 66, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9fgqh/what_do_you_do_for_a_living/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9fgqh/what_do_you_do_for_a_living/", "subreddit_subscribers": 77303, "created_utc": 1666314047.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys, I am kinda newbie in this field and I want some advice from experts here.\n\nI have an accounting degree and I am shifting my career towards Business intelligence initially and might try data management if I found my passion there, I studied python basics but I keep hearing from others that Data Structures and algorithms are necessary in any CS field and that I have to practice a lot on LeetCode , so is it really a prerequisite to be one of the best talents in the future when I am senior ?", "author_fullname": "t2_77kq9xsm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Structures and algorithms for BI and Data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9e6g8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666310505.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I am kinda newbie in this field and I want some advice from experts here.&lt;/p&gt;\n\n&lt;p&gt;I have an accounting degree and I am shifting my career towards Business intelligence initially and might try data management if I found my passion there, I studied python basics but I keep hearing from others that Data Structures and algorithms are necessary in any CS field and that I have to practice a lot on LeetCode , so is it really a prerequisite to be one of the best talents in the future when I am senior ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "y9e6g8", "is_robot_indexable": true, "report_reasons": null, "author": "Ill-Confidence1806", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9e6g8/data_structures_and_algorithms_for_bi_and_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9e6g8/data_structures_and_algorithms_for_bi_and_data/", "subreddit_subscribers": 77303, "created_utc": 1666310505.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys , I\u2019m a complete noob in this field. So far I\u2019ve worked mostly on Frontend projects. I\u2019ve worked a little with AWS data modelling for a small app and had a course where we covered relational databases and concepts under that umbrella, an example being table normalization. \n\nI\u2019m currently enrolled in a systems analysis and design course , and am reading the following textbooks to learn by myself \n\n-  computer organization and design - David Patterson \n- computer architecture : a quantitative approach - also by Patterson \n- parallel computer architecture - David culler \n\n\nCan I also start reading designing data intensive applications. Am I going about this the right way? Utilizing the right materials? Some guidance from you experienced folks would be lovely. Thank you \ud83d\ude4f\ud83c\udffc", "author_fullname": "t2_k6wgicc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just picked up the book \u201cDesigning Data Intensive Applications\u201d", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9ujpz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666360970.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys , I\u2019m a complete noob in this field. So far I\u2019ve worked mostly on Frontend projects. I\u2019ve worked a little with AWS data modelling for a small app and had a course where we covered relational databases and concepts under that umbrella, an example being table normalization. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m currently enrolled in a systems analysis and design course , and am reading the following textbooks to learn by myself &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt; computer organization and design - David Patterson &lt;/li&gt;\n&lt;li&gt;computer architecture : a quantitative approach - also by Patterson &lt;/li&gt;\n&lt;li&gt;parallel computer architecture - David culler &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Can I also start reading designing data intensive applications. Am I going about this the right way? Utilizing the right materials? Some guidance from you experienced folks would be lovely. Thank you \ud83d\ude4f\ud83c\udffc&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y9ujpz", "is_robot_indexable": true, "report_reasons": null, "author": "arib_kamal", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9ujpz/just_picked_up_the_book_designing_data_intensive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9ujpz/just_picked_up_the_book_designing_data_intensive/", "subreddit_subscribers": 77303, "created_utc": 1666360970.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_rcx1cqyo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineers: the Dwight Schrutes and Michael Scotts of the enterprise?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 89, "top_awarded_type": null, "hide_score": false, "name": "t3_y9dk3b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/z6C7y41TuoAWgizcYCQuSxmPNibm6Hr_ureITs7LVz8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666308850.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@laurengreerbalik/the-modern-data-stack-through-the-gervais-principle-bfd4b4e33ac7", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/gH0xucWP8l6GHZbp8Et6MFGSzwyHs1e1KZValrao2OM.jpg?auto=webp&amp;s=f8b243613670076e36e033a718bad78408a4100a", "width": 1088, "height": 698}, "resolutions": [{"url": "https://external-preview.redd.it/gH0xucWP8l6GHZbp8Et6MFGSzwyHs1e1KZValrao2OM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=67837b0012d4612507c8e668f22223ffc9542f3d", "width": 108, "height": 69}, {"url": "https://external-preview.redd.it/gH0xucWP8l6GHZbp8Et6MFGSzwyHs1e1KZValrao2OM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8e505160e1d9192b3ce2c0cea26202b74c649153", "width": 216, "height": 138}, {"url": "https://external-preview.redd.it/gH0xucWP8l6GHZbp8Et6MFGSzwyHs1e1KZValrao2OM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=91cdb2fd3fbef5b36708fd76cdc719ec83bfa9ab", "width": 320, "height": 205}, {"url": "https://external-preview.redd.it/gH0xucWP8l6GHZbp8Et6MFGSzwyHs1e1KZValrao2OM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2f2e0503114bb23fed9d75d924cf30bac3fad7e8", "width": 640, "height": 410}, {"url": "https://external-preview.redd.it/gH0xucWP8l6GHZbp8Et6MFGSzwyHs1e1KZValrao2OM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b1453c6bd21d8e454f7c99e958d15aa1e7985de1", "width": 960, "height": 615}, {"url": "https://external-preview.redd.it/gH0xucWP8l6GHZbp8Et6MFGSzwyHs1e1KZValrao2OM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a38b9f5271e087af88194476e74e3e17fc0b960e", "width": 1080, "height": 692}], "variants": {}, "id": "_YvsMCd7jSlheVNi0GHad-4zcCtcx35qbnquSZUEAZQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y9dk3b", "is_robot_indexable": true, "report_reasons": null, "author": "----bubba----", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9dk3b/data_engineers_the_dwight_schrutes_and_michael/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@laurengreerbalik/the-modern-data-stack-through-the-gervais-principle-bfd4b4e33ac7", "subreddit_subscribers": 77303, "created_utc": 1666308850.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\n[See https:\\/\\/twitter.com\\/i\\/status\\/1583111543327436800](https://preview.redd.it/bhi47r8de1v91.png?width=892&amp;format=png&amp;auto=webp&amp;s=89ce9cd2c433a6ac7dfc995ff730829ac000dccf)", "author_fullname": "t2_pl4q8ng7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "More of your Snowflake credits at work", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"bhi47r8de1v91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 125, "x": 108, "u": "https://preview.redd.it/bhi47r8de1v91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=cd8c8cdbf7e534fd76a2fd0050f06560a7ab3417"}, {"y": 250, "x": 216, "u": "https://preview.redd.it/bhi47r8de1v91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=91392447ca85a2df4a41c5631229eaa574e1f66c"}, {"y": 370, "x": 320, "u": "https://preview.redd.it/bhi47r8de1v91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d36801bb52ad3bb70edc7e005b2f555afca647ce"}, {"y": 741, "x": 640, "u": "https://preview.redd.it/bhi47r8de1v91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b7fbc64234e596313569726aec3a064e0fd364b2"}], "s": {"y": 1033, "x": 892, "u": "https://preview.redd.it/bhi47r8de1v91.png?width=892&amp;format=png&amp;auto=webp&amp;s=89ce9cd2c433a6ac7dfc995ff730829ac000dccf"}, "id": "bhi47r8de1v91"}}, "name": "t3_y9c0ub", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/KX6uyZ0X7ANaaiYpDszhrjdxih9gAVWHngkVePqOneU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666304899.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/bhi47r8de1v91.png?width=892&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=89ce9cd2c433a6ac7dfc995ff730829ac000dccf\"&gt;See https://twitter.com/i/status/1583111543327436800&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "y9c0ub", "is_robot_indexable": true, "report_reasons": null, "author": "droppedorphan", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9c0ub/more_of_your_snowflake_credits_at_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9c0ub/more_of_your_snowflake_credits_at_work/", "subreddit_subscribers": 77303, "created_utc": 1666304899.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Mainly an analytics engineer, so I live in dbt and almost exclusively use SQL. I do know some python, and can write simple cloud functions on GCP, but I don't know any other languages such as C++ or Java.\n\nI'm asking because it looks like Python and SQL might be enough for most roles, and I'm using that as a basis for which classes to take in the future for a MSCS. Not sure the time spent learning C++ or Java at this point in my life (I'm 37) would have any benefits in DE. I could see the benefits if I wanted to be a software engineer or if I was personally interested in learning those languages, but I'm not for either of those cases.\n\nAm I missing out on anything?", "author_fullname": "t2_3uoce3bn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I missing out on anything by not learning languages like C++ or Java?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9r8cv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666351668.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Mainly an analytics engineer, so I live in dbt and almost exclusively use SQL. I do know some python, and can write simple cloud functions on GCP, but I don&amp;#39;t know any other languages such as C++ or Java.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m asking because it looks like Python and SQL might be enough for most roles, and I&amp;#39;m using that as a basis for which classes to take in the future for a MSCS. Not sure the time spent learning C++ or Java at this point in my life (I&amp;#39;m 37) would have any benefits in DE. I could see the benefits if I wanted to be a software engineer or if I was personally interested in learning those languages, but I&amp;#39;m not for either of those cases.&lt;/p&gt;\n\n&lt;p&gt;Am I missing out on anything?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y9r8cv", "is_robot_indexable": true, "report_reasons": null, "author": "Tender_Figs", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9r8cv/am_i_missing_out_on_anything_by_not_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9r8cv/am_i_missing_out_on_anything_by_not_learning/", "subreddit_subscribers": 77303, "created_utc": 1666351668.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Many of you will likely find this useful -- our open-source team has spent the last few years building out the much-needed standard python framework for all things #datacentricAI.\n\nToday we launched Out-of-Distribution Detection now natively supported in cleanlab 2.1 to help you automatically find and remove outliers in your datasets so you can train models and perform analytics on reliable data -- **it's only one line of code to use.**\n\n[Our algorithms detect out-of-distribution data like this \\\\\"3\\\\\" included in a clothing dataset](https://preview.redd.it/wvrdnaeca6v91.jpg?width=720&amp;format=pjpg&amp;auto=webp&amp;s=d406cbf3cbaf568735e2f0f1e3a1b705e0e52719)\n\nWhat makes our out-of-distribution package different?\n\nMany complex OOD detection algorithms exist but they are only applicable to specific data types. The `cleanlab.outlier`package works as effectively as these complex methods, but also works with any type of data for which either a feature embedding or trained classifier is available.\n\n`cleanlab.outlier`is:\n\n* [Open-source](https://github.com/cleanlab/cleanlab) and free to use\n* [Research published](https://arxiv.org/abs/2207.03061) \\+ few-lines-of-code [tutorials](https://docs.cleanlab.ai/stable/tutorials/outliers.html)\n* [Benchmarked](https://github.com/cleanlab/ood-detection-benchmarks) to show superior performance in the landscape of OOD methods.\n\nHave fun using `cleanlab.outlier`!\n\nBlog: [https://cleanlab.ai/blog/outlier-detection/](https://cleanlab.ai/blog/outlier-detection/)", "author_fullname": "t2_5v7p3x0j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Detecting Out-of-Distribution Datapoints via Embeddings or Predictions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 55, "top_awarded_type": null, "hide_score": false, "media_metadata": {"wvrdnaeca6v91": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 42, "x": 108, "u": "https://preview.redd.it/wvrdnaeca6v91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=25f828eb4762b0a2f6c9a6b6b435957fecb722df"}, {"y": 85, "x": 216, "u": "https://preview.redd.it/wvrdnaeca6v91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9b4db33bc957ca22f5b155f23db507e6e4942b9d"}, {"y": 127, "x": 320, "u": "https://preview.redd.it/wvrdnaeca6v91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=072dec9d0a87cfd85f880d2f5fe3009703c3ccb1"}, {"y": 254, "x": 640, "u": "https://preview.redd.it/wvrdnaeca6v91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=51e5f51a39dbdf934523c16010986d4a36c2ec31"}], "s": {"y": 286, "x": 720, "u": "https://preview.redd.it/wvrdnaeca6v91.jpg?width=720&amp;format=pjpg&amp;auto=webp&amp;s=d406cbf3cbaf568735e2f0f1e3a1b705e0e52719"}, "id": "wvrdnaeca6v91"}}, "name": "t3_y9vu5f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/LTGb2mWFn7620r2Ky06d3e-fFSnjgc9BECIudHN2UL0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666364163.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Many of you will likely find this useful -- our open-source team has spent the last few years building out the much-needed standard python framework for all things #datacentricAI.&lt;/p&gt;\n\n&lt;p&gt;Today we launched Out-of-Distribution Detection now natively supported in cleanlab 2.1 to help you automatically find and remove outliers in your datasets so you can train models and perform analytics on reliable data -- &lt;strong&gt;it&amp;#39;s only one line of code to use.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/wvrdnaeca6v91.jpg?width=720&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=d406cbf3cbaf568735e2f0f1e3a1b705e0e52719\"&gt;Our algorithms detect out-of-distribution data like this \\&amp;quot;3\\&amp;quot; included in a clothing dataset&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;What makes our out-of-distribution package different?&lt;/p&gt;\n\n&lt;p&gt;Many complex OOD detection algorithms exist but they are only applicable to specific data types. The &lt;code&gt;cleanlab.outlier&lt;/code&gt;package works as effectively as these complex methods, but also works with any type of data for which either a feature embedding or trained classifier is available.&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;cleanlab.outlier&lt;/code&gt;is:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/cleanlab/cleanlab\"&gt;Open-source&lt;/a&gt; and free to use&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://arxiv.org/abs/2207.03061\"&gt;Research published&lt;/a&gt; + few-lines-of-code &lt;a href=\"https://docs.cleanlab.ai/stable/tutorials/outliers.html\"&gt;tutorials&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/cleanlab/ood-detection-benchmarks\"&gt;Benchmarked&lt;/a&gt; to show superior performance in the landscape of OOD methods.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Have fun using &lt;code&gt;cleanlab.outlier&lt;/code&gt;!&lt;/p&gt;\n\n&lt;p&gt;Blog: &lt;a href=\"https://cleanlab.ai/blog/outlier-detection/\"&gt;https://cleanlab.ai/blog/outlier-detection/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "y9vu5f", "is_robot_indexable": true, "report_reasons": null, "author": "jonas__m", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9vu5f/detecting_outofdistribution_datapoints_via/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9vu5f/detecting_outofdistribution_datapoints_via/", "subreddit_subscribers": 77303, "created_utc": 1666364163.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys, on 27th October [Memphis.dev](https://github.com/memphisdev/memphis-broker) is co-hosting  A roundtable around the current trends and challenges of data streaming, design decisions, tech stacks, and use cases. \n\nPure knowledge sharing with the local community of devs and data engineers. \n\n810 7th Ave \u00b7 New York, NY.\n\n&amp;#x200B;\n\nAll data enthusiasts are welcome to join \n\nRSVP \n\n[https://www.meetup.com/developers-and-data-powered-by-memphis-dev-platform/events/288432501/](https://www.meetup.com/developers-and-data-powered-by-memphis-dev-platform/events/288432501/)", "author_fullname": "t2_bqjrmnud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NYC Data Engineering Meetup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9n17i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666337482.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, on 27th October &lt;a href=\"https://github.com/memphisdev/memphis-broker\"&gt;Memphis.dev&lt;/a&gt; is co-hosting  A roundtable around the current trends and challenges of data streaming, design decisions, tech stacks, and use cases. &lt;/p&gt;\n\n&lt;p&gt;Pure knowledge sharing with the local community of devs and data engineers. &lt;/p&gt;\n\n&lt;p&gt;810 7th Ave \u00b7 New York, NY.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;All data enthusiasts are welcome to join &lt;/p&gt;\n\n&lt;p&gt;RSVP &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.meetup.com/developers-and-data-powered-by-memphis-dev-platform/events/288432501/\"&gt;https://www.meetup.com/developers-and-data-powered-by-memphis-dev-platform/events/288432501/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?auto=webp&amp;s=7227dddf662629d580f2e430eeaa2ae7294e47ed", "width": 1280, "height": 720}, "resolutions": [{"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5dcdc025b6b3954b0c2714b519db2547e7ead491", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=902b11284debb4eadeba71f4551344bc40315415", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=53f00cfe89098449638e871f4fd704e82f812323", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2baf0c623ee36336ec2367e3798b342c620f62dc", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=76d99efca5f389a98a9f349d4b1771a36ecdf6dd", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ed456664e401712061ce47dcc47505d0a6c93b34", "width": 1080, "height": 607}], "variants": {}, "id": "hYBYKmUFkskiOV8szz3ckSx7rnZYTEJIAAkPfkZc44g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "y9n17i", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering_Bug105", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9n17i/nyc_data_engineering_meetup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9n17i/nyc_data_engineering_meetup/", "subreddit_subscribers": 77303, "created_utc": 1666337482.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_bvkm0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Implementing Data Contracts - a Practical Example", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_y9syna", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/sUxnzUmX5-KHSfKI_rEuAPgRyhUKu675HFW7tjuByvs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666356766.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@danthelion/implementing-data-contracts-82800b9186b", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6Mr0mYy8Gg0tPZqsHyY9x5-rUfaIxHEqsxzTI3PJ84E.jpg?auto=webp&amp;s=46aca62508288c55d4151a2b4c79056d669b5f41", "width": 400, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/6Mr0mYy8Gg0tPZqsHyY9x5-rUfaIxHEqsxzTI3PJ84E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f4c6a017cbcaee64ea9102da3b7c415c2f49c1ee", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/6Mr0mYy8Gg0tPZqsHyY9x5-rUfaIxHEqsxzTI3PJ84E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=af1f37d75a8b5aa5733ae45cb3c34ef19be1e5e7", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/6Mr0mYy8Gg0tPZqsHyY9x5-rUfaIxHEqsxzTI3PJ84E.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b6c333d9371ef51b59ae929055e0b6ed99ede1b3", "width": 320, "height": 240}], "variants": {}, "id": "SthwCf5cEOddOPntr6QX8ASnB7BHgI2TWTwV92DR34w"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "y9syna", "is_robot_indexable": true, "report_reasons": null, "author": "rmoff", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9syna/implementing_data_contracts_a_practical_example/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@danthelion/implementing-data-contracts-82800b9186b", "subreddit_subscribers": 77303, "created_utc": 1666356766.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have this large .zip that takes 2 hours to unzip the whole thing. I really only need the .csv files. Is there a way in ADF to only unzip .csv files?", "author_fullname": "t2_sirnldvp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to ONLY unzip .csv files in Azure Data Factory?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9qrty", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666350222.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have this large .zip that takes 2 hours to unzip the whole thing. I really only need the .csv files. Is there a way in ADF to only unzip .csv files?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y9qrty", "is_robot_indexable": true, "report_reasons": null, "author": "powerBIGuy14", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9qrty/is_it_possible_to_only_unzip_csv_files_in_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9qrty/is_it_possible_to_only_unzip_csv_files_in_azure/", "subreddit_subscribers": 77303, "created_utc": 1666350222.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_49cfbl1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A step-by-step tutorial on how to manipulate a table in your data lake by writing a custom plugin with VDK", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 101, "top_awarded_type": null, "hide_score": false, "name": "t3_y9tnx4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/VktSmWAXSaU5490oJOKYByY2EkGyxQyZpFoLXT6JZ28.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666358687.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "towardsdatascience.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://towardsdatascience.com/how-to-create-a-data-formatting-plugin-in-vdk-dc5f1c7d206d", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/HdOer84WK3nZFBIZjKT4tZtNHXM20Dd-gOkrR1gu-w8.jpg?auto=webp&amp;s=9c6ee1cb4d0e111f2fd2b6a740d3818417e2d9bf", "width": 1200, "height": 868}, "resolutions": [{"url": "https://external-preview.redd.it/HdOer84WK3nZFBIZjKT4tZtNHXM20Dd-gOkrR1gu-w8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=78eaacf59b0f26cfe059b3d02ea5c296f966fcfd", "width": 108, "height": 78}, {"url": "https://external-preview.redd.it/HdOer84WK3nZFBIZjKT4tZtNHXM20Dd-gOkrR1gu-w8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4f93d5c28f98253a461a53f3e2ffedd7f1bb2059", "width": 216, "height": 156}, {"url": "https://external-preview.redd.it/HdOer84WK3nZFBIZjKT4tZtNHXM20Dd-gOkrR1gu-w8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cf5d2bfe012cd1bdae16c0e174eb19c00b268082", "width": 320, "height": 231}, {"url": "https://external-preview.redd.it/HdOer84WK3nZFBIZjKT4tZtNHXM20Dd-gOkrR1gu-w8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=802ec9e6f14a0491bbbf05f7026d113fca68a813", "width": 640, "height": 462}, {"url": "https://external-preview.redd.it/HdOer84WK3nZFBIZjKT4tZtNHXM20Dd-gOkrR1gu-w8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1bb47fc5725f7e87ee87bff57c23a07c5a8bb5c5", "width": 960, "height": 694}, {"url": "https://external-preview.redd.it/HdOer84WK3nZFBIZjKT4tZtNHXM20Dd-gOkrR1gu-w8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a43c0e61cbad31f6dd6341a746afd17dd9d9e57b", "width": 1080, "height": 781}], "variants": {}, "id": "tq11CeUSiRIQW_qQxnKqt69H0JFY8X4v98kqRCps8Ko"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "y9tnx4", "is_robot_indexable": true, "report_reasons": null, "author": "zverulacis", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9tnx4/a_stepbystep_tutorial_on_how_to_manipulate_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://towardsdatascience.com/how-to-create-a-data-formatting-plugin-in-vdk-dc5f1c7d206d", "subreddit_subscribers": 77303, "created_utc": 1666358687.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I never heard this terminology until I started working with SQL. When we would have a really gnarly query that we needed to optimize or reverse engineer someone on my team said \"oh yeah this one a real bear\".\n\nSo what exactly does this mean a task that is very tedious and time consuming ? Or is there more to it.", "author_fullname": "t2_dfcot0zg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What does it mean when a DE project (or any SWE) is considered a real \"bear\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9tjl2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666358371.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I never heard this terminology until I started working with SQL. When we would have a really gnarly query that we needed to optimize or reverse engineer someone on my team said &amp;quot;oh yeah this one a real bear&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;So what exactly does this mean a task that is very tedious and time consuming ? Or is there more to it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y9tjl2", "is_robot_indexable": true, "report_reasons": null, "author": "DrRedmondNYC", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9tjl2/what_does_it_mean_when_a_de_project_or_any_swe_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9tjl2/what_does_it_mean_when_a_de_project_or_any_swe_is/", "subreddit_subscribers": 77303, "created_utc": 1666358371.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_zia33", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DataProfiler: What's in your data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_y9s1xi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/F8KDao-juHDzXtQClxdta0TEIIU-2KV9y2k-l4Zz5hg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666354073.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/capitalone/DataProfiler", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/HlEdNMV-y2rTFX-aWd6KSkwfZthKlH3wHbOo37OAGhU.jpg?auto=webp&amp;s=327e8583f46a92e6f036839bac1fa10b05b95ccf", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/HlEdNMV-y2rTFX-aWd6KSkwfZthKlH3wHbOo37OAGhU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d6cb43643da4623a7da30465744962cb59af79f2", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/HlEdNMV-y2rTFX-aWd6KSkwfZthKlH3wHbOo37OAGhU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c164acaa39fc7f477204b047d60da0d7993c9fa7", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/HlEdNMV-y2rTFX-aWd6KSkwfZthKlH3wHbOo37OAGhU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a862497065014c055a6e110eea07da17fb897f8d", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/HlEdNMV-y2rTFX-aWd6KSkwfZthKlH3wHbOo37OAGhU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=07e0cf9ec9e34a1afb631903f1e1d173675bb848", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/HlEdNMV-y2rTFX-aWd6KSkwfZthKlH3wHbOo37OAGhU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=cba7e8e8f13df0d85542e07f74bf8d00df89c649", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/HlEdNMV-y2rTFX-aWd6KSkwfZthKlH3wHbOo37OAGhU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=69949c0002fba768f523a591dc2bd7be90efa38f", "width": 1080, "height": 540}], "variants": {}, "id": "7a2QHIt4QoH5Js0QM9-04MSSFPNASZaYeOw6r4hZ9z8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "y9s1xi", "is_robot_indexable": true, "report_reasons": null, "author": "fitz_n_fitz", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9s1xi/dataprofiler_whats_in_your_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/capitalone/DataProfiler", "subreddit_subscribers": 77303, "created_utc": 1666354073.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Everyone, I had some questions around FPGrowth at PySpark, i using a dataset around 20M, but i facing some issues when i tried to visualize some rules (memory errors), probably because they are creating a lot of rules even when i limited the thresholds for support/confidence.\n\n&amp;#x200B;\n\nThere's another ways to optimize this algorithm?", "author_fullname": "t2_768gsz2h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "FPGrowth and PySpark optimization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9tapl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666366020.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666357696.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone, I had some questions around FPGrowth at PySpark, i using a dataset around 20M, but i facing some issues when i tried to visualize some rules (memory errors), probably because they are creating a lot of rules even when i limited the thresholds for support/confidence.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s another ways to optimize this algorithm?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y9tapl", "is_robot_indexable": true, "report_reasons": null, "author": "suneirl1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9tapl/fpgrowth_and_pyspark_optimization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9tapl/fpgrowth_and_pyspark_optimization/", "subreddit_subscribers": 77303, "created_utc": 1666357696.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am planning to take this certification since our company offers free vouchers.\n\nTo those who passed this exam, how long did you review? So i can come up with an estimated schedule for me. Also, how's the difficulty of the exam?\n\nThanks in advance!", "author_fullname": "t2_kh03mlzp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google Professional Data Engineer Certificate - how long did you review?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9iaip", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666322217.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am planning to take this certification since our company offers free vouchers.&lt;/p&gt;\n\n&lt;p&gt;To those who passed this exam, how long did you review? So i can come up with an estimated schedule for me. Also, how&amp;#39;s the difficulty of the exam?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y9iaip", "is_robot_indexable": true, "report_reasons": null, "author": "keemi01", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9iaip/google_professional_data_engineer_certificate_how/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9iaip/google_professional_data_engineer_certificate_how/", "subreddit_subscribers": 77303, "created_utc": 1666322217.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\nEdilitics is a turnkey Data &amp; Analytics solution with an aim to optimise business practices and decision making throughout the value chain. \nWe have developed the solution with a focus on reducing the work load of the code literate and enabling those without code literacy to perform data analytics with ease. \n\n\nThe Problem:\n\n- Eliminate dependency on multiple teams, tools and programming languages to effectively perform data analytics.\n- Provide access to analytics ready data without the need to create and maintain lengthy scripts.\n- Build a one-stop solution to connect the entire organisation to a single source of truth.\n\n\n\n\nThe Solution:\n\n- Integration : an end-to-end data pipeline that enables you to easily pull data from all your sources to the warehouse.\n- Transformation : to better organise your data and make it useable by both humans and systems. \n- Visualisation : graphically represent patterns in data and share with internal as well as external stakeholders. \n- Machine Learning : to analyse and make data-driven recommendations and decisions based on historical data.", "author_fullname": "t2_9o1sdswe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feed back: app.edilitics.com", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_ya5wn0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666389282.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Edilitics is a turnkey Data &amp;amp; Analytics solution with an aim to optimise business practices and decision making throughout the value chain. \nWe have developed the solution with a focus on reducing the work load of the code literate and enabling those without code literacy to perform data analytics with ease. &lt;/p&gt;\n\n&lt;p&gt;The Problem:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Eliminate dependency on multiple teams, tools and programming languages to effectively perform data analytics.&lt;/li&gt;\n&lt;li&gt;Provide access to analytics ready data without the need to create and maintain lengthy scripts.&lt;/li&gt;\n&lt;li&gt;Build a one-stop solution to connect the entire organisation to a single source of truth.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The Solution:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Integration : an end-to-end data pipeline that enables you to easily pull data from all your sources to the warehouse.&lt;/li&gt;\n&lt;li&gt;Transformation : to better organise your data and make it useable by both humans and systems. &lt;/li&gt;\n&lt;li&gt;Visualisation : graphically represent patterns in data and share with internal as well as external stakeholders. &lt;/li&gt;\n&lt;li&gt;Machine Learning : to analyse and make data-driven recommendations and decisions based on historical data.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ya5wn0", "is_robot_indexable": true, "report_reasons": null, "author": "New_Name_6954", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ya5wn0/feed_back_appediliticscom/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ya5wn0/feed_back_appediliticscom/", "subreddit_subscribers": 77303, "created_utc": 1666389282.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do you know what it usually is in a company?", "author_fullname": "t2_82dwrpz7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ratio data / software engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_ya4rew", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666386399.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you know what it usually is in a company?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ya4rew", "is_robot_indexable": true, "report_reasons": null, "author": "Upstairs-Ad-8440", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ya4rew/ratio_data_software_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ya4rew/ratio_data_software_engineer/", "subreddit_subscribers": 77303, "created_utc": 1666386399.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work as part of a small data team that consists of mainly non-technical folks. A lot of my work for the past year has been around automating our internal process and a few external data reliability and validation needs for our platform. \n\nI\u2019m responsible for most of the code and pipelines that the data team uses which run on Azure DevOps as well as some automated month end reporting for other teams and our clients. Main programming language is Python (Libraries commonly used are Pandas, numpy, selenium,openpyxl, simple_salesforce and a few select api to access data stored on third party provisioned services), SQL, Salesforce queries, Power Query for Power BI manipulation. \n\nRecently I have been integrating a lot more Azure services into our workflow, the goal around this is to reduce the dependence of the team on excel and the need to constantly pull large amounts of the same data from the db during pipeline runs. The main services I have included are Azure Storage (blobs), Azure functions, Key Valult and Azure Api management.\n\nI have two certifications: Azure Data Engineer (Dp203) and Azure Adminstrator (Az104). Also prepping for Azure Devops Cert (Az 400).\n\nMy current title is Data Analyst, however I feel like it does not really capture all the things that I do. It\u2019s not something I am overly hang up on however I would like to know based on the above info what would the appropriate title be?", "author_fullname": "t2_dkq68c2f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the title of my role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ya45g8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666384885.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work as part of a small data team that consists of mainly non-technical folks. A lot of my work for the past year has been around automating our internal process and a few external data reliability and validation needs for our platform. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m responsible for most of the code and pipelines that the data team uses which run on Azure DevOps as well as some automated month end reporting for other teams and our clients. Main programming language is Python (Libraries commonly used are Pandas, numpy, selenium,openpyxl, simple_salesforce and a few select api to access data stored on third party provisioned services), SQL, Salesforce queries, Power Query for Power BI manipulation. &lt;/p&gt;\n\n&lt;p&gt;Recently I have been integrating a lot more Azure services into our workflow, the goal around this is to reduce the dependence of the team on excel and the need to constantly pull large amounts of the same data from the db during pipeline runs. The main services I have included are Azure Storage (blobs), Azure functions, Key Valult and Azure Api management.&lt;/p&gt;\n\n&lt;p&gt;I have two certifications: Azure Data Engineer (Dp203) and Azure Adminstrator (Az104). Also prepping for Azure Devops Cert (Az 400).&lt;/p&gt;\n\n&lt;p&gt;My current title is Data Analyst, however I feel like it does not really capture all the things that I do. It\u2019s not something I am overly hang up on however I would like to know based on the above info what would the appropriate title be?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ya45g8", "is_robot_indexable": true, "report_reasons": null, "author": "MajiYaKuoshaVyombo", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ya45g8/what_is_the_title_of_my_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ya45g8/what_is_the_title_of_my_role/", "subreddit_subscribers": 77303, "created_utc": 1666384885.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Have fun task of trying to centralize several disparate systems that I\u2019ve inherited and was trying to explain the problem to several business users. One of the \u201cveterans\u201d insists we should just pass SSN\u2019s across systems (in part because it is stored in several of these systems already).\n\nMy initial and gut stance is this is a horrible idea fraught with compliance issues but my background isn\u2019t super deep in regulatory.\n\nAm I wrong on this stance and does anyone have recommendations/laws/regulations to leverage to make my case", "author_fullname": "t2_ao7u40a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using PII (SSN) as link between several systems\u2019 data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ya3c8x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666382912.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have fun task of trying to centralize several disparate systems that I\u2019ve inherited and was trying to explain the problem to several business users. One of the \u201cveterans\u201d insists we should just pass SSN\u2019s across systems (in part because it is stored in several of these systems already).&lt;/p&gt;\n\n&lt;p&gt;My initial and gut stance is this is a horrible idea fraught with compliance issues but my background isn\u2019t super deep in regulatory.&lt;/p&gt;\n\n&lt;p&gt;Am I wrong on this stance and does anyone have recommendations/laws/regulations to leverage to make my case&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ya3c8x", "is_robot_indexable": true, "report_reasons": null, "author": "minormisgnomer", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ya3c8x/using_pii_ssn_as_link_between_several_systems_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ya3c8x/using_pii_ssn_as_link_between_several_systems_data/", "subreddit_subscribers": 77303, "created_utc": 1666382912.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all, is there anyone here who is, works with, or knows a good amount about the role of an Ontology Specialist? I\u2019m currently in a bit of a dilema, in a good way. I\u2019m a recent software engineering bootcamp graduate who has received two separate job offers over the past week. One is Django/AWS developer at a start-up company and the other is an Ontology Specialist at a company that works closely with a big tech company that I won\u2019t name here. I think it\u2019s worth mentioning more of my background that seems to align with the Ontology Specialist role. Before pursuing software engineering, I got an undergrad in Linguistics and took many Philosophy courses while in college. As a part of the bootcamp, I built two full-stack capstone projects that incorporated NLP with Python\u2019s NLTK library to extract Sentiment Analysis data and insights from news stories and artist lyrics. Although I genuinely enjoy software development, working on the data portion of these projects definitely the most enjoyable part of my entire experience during the bootcamp. \n\nAfter speaking with the company and googling a bit, I now know a little bit more about what the role of an Ontology Specialist entails, but there\u2019s still a lot that remains ambiguous to me. The interviewer did say that the Ontology Specialist position could work just fine for someone trying to get into the field of software engineering, but they did warn me that I wouldn\u2019t be writing too much actual code. Honestly, the position sounds very interesting and like it could open doors to certain areas that I frankly think are more interesting than software engineering, such as NLP and Machine Learning. \n\nI\u2019m just worried that if I don\u2019t like this sort of work after a year and want to go back to mainly software engineering, that it would be almost equally as hard for me to get a job as a software engineer as it is right now, as I wouldn\u2019t have gained really any hands on experience in software engineering. Is this a valid fear? And a few more questions:\n\n1. Is the opportunity for remote work as well as promotions and raises just as good for an Ontology Specialist as it is for a software engineer? \n2. What fields would it be possibly to transition into if I find I don\u2019t really enjoy the Ontology Specialist position? For instance, would this open up some opportunities to work in Machine Learning down the road?\n3. Lastly, if anyone here is or has worked with Ontology Specialists and could explain to me a little more about their experience, or even grant me a 10-15 minute informational interview, that\u2019d be fantastic. During my interview with the company I was able to learn a bit, but we didn\u2019t get too much time and I was still left with a lot of questions. \n\nThanks everyone.", "author_fullname": "t2_6bdkgnq2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recent SWE Bootcamp grad offered job as Ontology Specialist. Could use some guidance and clarification.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9z49y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666372488.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, is there anyone here who is, works with, or knows a good amount about the role of an Ontology Specialist? I\u2019m currently in a bit of a dilema, in a good way. I\u2019m a recent software engineering bootcamp graduate who has received two separate job offers over the past week. One is Django/AWS developer at a start-up company and the other is an Ontology Specialist at a company that works closely with a big tech company that I won\u2019t name here. I think it\u2019s worth mentioning more of my background that seems to align with the Ontology Specialist role. Before pursuing software engineering, I got an undergrad in Linguistics and took many Philosophy courses while in college. As a part of the bootcamp, I built two full-stack capstone projects that incorporated NLP with Python\u2019s NLTK library to extract Sentiment Analysis data and insights from news stories and artist lyrics. Although I genuinely enjoy software development, working on the data portion of these projects definitely the most enjoyable part of my entire experience during the bootcamp. &lt;/p&gt;\n\n&lt;p&gt;After speaking with the company and googling a bit, I now know a little bit more about what the role of an Ontology Specialist entails, but there\u2019s still a lot that remains ambiguous to me. The interviewer did say that the Ontology Specialist position could work just fine for someone trying to get into the field of software engineering, but they did warn me that I wouldn\u2019t be writing too much actual code. Honestly, the position sounds very interesting and like it could open doors to certain areas that I frankly think are more interesting than software engineering, such as NLP and Machine Learning. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m just worried that if I don\u2019t like this sort of work after a year and want to go back to mainly software engineering, that it would be almost equally as hard for me to get a job as a software engineer as it is right now, as I wouldn\u2019t have gained really any hands on experience in software engineering. Is this a valid fear? And a few more questions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Is the opportunity for remote work as well as promotions and raises just as good for an Ontology Specialist as it is for a software engineer? &lt;/li&gt;\n&lt;li&gt;What fields would it be possibly to transition into if I find I don\u2019t really enjoy the Ontology Specialist position? For instance, would this open up some opportunities to work in Machine Learning down the road?&lt;/li&gt;\n&lt;li&gt;Lastly, if anyone here is or has worked with Ontology Specialists and could explain to me a little more about their experience, or even grant me a 10-15 minute informational interview, that\u2019d be fantastic. During my interview with the company I was able to learn a bit, but we didn\u2019t get too much time and I was still left with a lot of questions. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thanks everyone.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "y9z49y", "is_robot_indexable": true, "report_reasons": null, "author": "sammyhats", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9z49y/recent_swe_bootcamp_grad_offered_job_as_ontology/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9z49y/recent_swe_bootcamp_grad_offered_job_as_ontology/", "subreddit_subscribers": 77303, "created_utc": 1666372488.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm creating a Spark DataFrame from a list of tuples using PySpark. The list can be relatively large. And with larger lists, the time could increase significantly. Most of what I've read on creating DataFrames in spark uses external files like CSV files. So I was wondering if there were any best practices I employ when creating a DataFrames from a list of tuples. \n\nI did some profiling on the various methods I have. And it looks like the majority of the time is spent creating the DataFrame. I've sped up this process somewhat by using a schema when I create the DataFrame. But this is as far as I've been able to take the optimizations.", "author_fullname": "t2_2ntu9i1o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PySpark: Creating a DataFrame from a list of tuples", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9yehm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666370634.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m creating a Spark DataFrame from a list of tuples using PySpark. The list can be relatively large. And with larger lists, the time could increase significantly. Most of what I&amp;#39;ve read on creating DataFrames in spark uses external files like CSV files. So I was wondering if there were any best practices I employ when creating a DataFrames from a list of tuples. &lt;/p&gt;\n\n&lt;p&gt;I did some profiling on the various methods I have. And it looks like the majority of the time is spent creating the DataFrame. I&amp;#39;ve sped up this process somewhat by using a schema when I create the DataFrame. But this is as far as I&amp;#39;ve been able to take the optimizations.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y9yehm", "is_robot_indexable": true, "report_reasons": null, "author": "ineffablol", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9yehm/pyspark_creating_a_dataframe_from_a_list_of_tuples/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9yehm/pyspark_creating_a_dataframe_from_a_list_of_tuples/", "subreddit_subscribers": 77303, "created_utc": 1666370634.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I have an option to do one of these 2 and I was wondering which role would be more beneficial for my data engineering career, Business Analyst or ETL tester role?\n\n&amp;#x200B;\n\nThanks for any insight!", "author_fullname": "t2_tjxw4oe5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is better, Business Analyst or ETL Tester role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9qmaq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666349749.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have an option to do one of these 2 and I was wondering which role would be more beneficial for my data engineering career, Business Analyst or ETL tester role?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks for any insight!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "y9qmaq", "is_robot_indexable": true, "report_reasons": null, "author": "de_juggin95", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9qmaq/what_is_better_business_analyst_or_etl_tester_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9qmaq/what_is_better_business_analyst_or_etl_tester_role/", "subreddit_subscribers": 77303, "created_utc": 1666349749.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So Airbyte creates data pipelines for me in an easy way. There's a cloud option and a self-host open source option.\n\nLet's say I create a pipeline in Airbyte. Let's say that this pipeline requires some CPU compute and RAM. Where is this CPU and RAM coming from? Is it on the same instance as the Airbyte app? Or do I have to create EC2/Lambda functions somewhere else and let Airbyte control them?", "author_fullname": "t2_l5aep", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where does the compute come from when I use Airbyte?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9lbtf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666331611.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So Airbyte creates data pipelines for me in an easy way. There&amp;#39;s a cloud option and a self-host open source option.&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s say I create a pipeline in Airbyte. Let&amp;#39;s say that this pipeline requires some CPU compute and RAM. Where is this CPU and RAM coming from? Is it on the same instance as the Airbyte app? Or do I have to create EC2/Lambda functions somewhere else and let Airbyte control them?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y9lbtf", "is_robot_indexable": true, "report_reasons": null, "author": "joel1234512", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9lbtf/where_does_the_compute_come_from_when_i_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9lbtf/where_does_the_compute_come_from_when_i_use/", "subreddit_subscribers": 77303, "created_utc": 1666331611.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "On Notion, I have a database with 30 employees' names, positions, emails, and phone numbers for one of my clients. I want to sync this database with the contacts section of this client's salesforce page. If an employee leaves my client's company, my client will delete him from the database, and when new employees join he will be added to the database. I hope that I will never have to recheck this database and my Salesforce data will be reliably accurate and up to date. \n\nI suppose an API like Zapier or a reverse ETL service like Hightouch could accomplish this task, but I am certain a cheaper alternative exists. Do you have any suggestions?", "author_fullname": "t2_13126k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Extremely basic bidirectional syncing issue - looking for the least expensive solution.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9dypw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666310131.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666309946.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;On Notion, I have a database with 30 employees&amp;#39; names, positions, emails, and phone numbers for one of my clients. I want to sync this database with the contacts section of this client&amp;#39;s salesforce page. If an employee leaves my client&amp;#39;s company, my client will delete him from the database, and when new employees join he will be added to the database. I hope that I will never have to recheck this database and my Salesforce data will be reliably accurate and up to date. &lt;/p&gt;\n\n&lt;p&gt;I suppose an API like Zapier or a reverse ETL service like Hightouch could accomplish this task, but I am certain a cheaper alternative exists. Do you have any suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y9dypw", "is_robot_indexable": true, "report_reasons": null, "author": "northernmostroasts", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9dypw/extremely_basic_bidirectional_syncing_issue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9dypw/extremely_basic_bidirectional_syncing_issue/", "subreddit_subscribers": 77303, "created_utc": 1666309946.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}