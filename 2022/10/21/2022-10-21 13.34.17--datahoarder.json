{"kind": "Listing", "data": {"after": "t3_y9f3r4", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_6kz4z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Only took a few years and 16 drives, but I finally hit 100TB! Still loving the Enthoo Pro 2!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 126, "top_awarded_type": null, "hide_score": false, "name": "t3_y995fv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 607, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe class=\"embedly-embed\" src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fimgur.com%2Fa%2FOEBw1vd%2Fembed%3Fpub%3Dtrue%26ref%3Dhttps%253A%252F%252Fembed.ly%26w%3D900&amp;display_name=Imgur&amp;url=https%3A%2F%2Fimgur.com%2Fa%2FOEBw1vd&amp;image=https%3A%2F%2Fi.imgur.com%2FxVZSyZA.jpg%3Ffb&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=imgur\" width=\"600\" height=\"582\" scrolling=\"no\" title=\"Imgur embed\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen=\"true\"&gt;&lt;/iframe&gt;", "width": 600, "scrolling": false, "height": 582}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": {"type": "imgur.com", "oembed": {"provider_url": "http://imgur.com", "description": "Post with 0 views. 1/10 PB", "title": "1/10 PB", "url": "https://imgur.com/a/OEBw1vd", "type": "rich", "thumbnail_width": 600, "height": 582, "width": 600, "html": "&lt;iframe class=\"embedly-embed\" src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fimgur.com%2Fa%2FOEBw1vd%2Fembed%3Fpub%3Dtrue%26ref%3Dhttps%253A%252F%252Fembed.ly%26w%3D900&amp;display_name=Imgur&amp;url=https%3A%2F%2Fimgur.com%2Fa%2FOEBw1vd&amp;image=https%3A%2F%2Fi.imgur.com%2FxVZSyZA.jpg%3Ffb&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=imgur\" width=\"600\" height=\"582\" scrolling=\"no\" title=\"Imgur embed\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen=\"true\"&gt;&lt;/iframe&gt;", "version": "1.0", "provider_name": "Imgur", "thumbnail_url": "https://i.imgur.com/xVZSyZA.jpg?fb", "thumbnail_height": 315}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe class=\"embedly-embed\" src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fimgur.com%2Fa%2FOEBw1vd%2Fembed%3Fpub%3Dtrue%26ref%3Dhttps%253A%252F%252Fembed.ly%26w%3D900&amp;display_name=Imgur&amp;url=https%3A%2F%2Fimgur.com%2Fa%2FOEBw1vd&amp;image=https%3A%2F%2Fi.imgur.com%2FxVZSyZA.jpg%3Ffb&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=imgur\" width=\"600\" height=\"582\" scrolling=\"no\" title=\"Imgur embed\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen=\"true\"&gt;&lt;/iframe&gt;", "width": 600, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/y995fv", "height": 582}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 607, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/50L0T6F6RKWdTMcD9iRR-DkArsHE5aYMqAGa3cFEL6Q.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666298028.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "imgur.com", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://imgur.com/a/OEBw1vd", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/2S5D9ZXRBmgFuC8KEot9pKoJLiuFS7rOQ9LIWchVXFY.jpg?auto=webp&amp;s=4c7e0a613580505c5a2c0e1baa2a66d5d04dbfb0", "width": 3195, "height": 2885}, "resolutions": [{"url": "https://external-preview.redd.it/2S5D9ZXRBmgFuC8KEot9pKoJLiuFS7rOQ9LIWchVXFY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a17f077d4c963bc8462628a49f8575a8e62a3e42", "width": 108, "height": 97}, {"url": "https://external-preview.redd.it/2S5D9ZXRBmgFuC8KEot9pKoJLiuFS7rOQ9LIWchVXFY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6c67673c78d4875e902e1544ab35471ade3c152f", "width": 216, "height": 195}, {"url": "https://external-preview.redd.it/2S5D9ZXRBmgFuC8KEot9pKoJLiuFS7rOQ9LIWchVXFY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9313014ee6310e4ab8d85f0fefcd0dc024cb1f40", "width": 320, "height": 288}, {"url": "https://external-preview.redd.it/2S5D9ZXRBmgFuC8KEot9pKoJLiuFS7rOQ9LIWchVXFY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=415159719934cb03edffbcd5a6194c3c9d88f7e2", "width": 640, "height": 577}, {"url": "https://external-preview.redd.it/2S5D9ZXRBmgFuC8KEot9pKoJLiuFS7rOQ9LIWchVXFY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=81fda808bbb4c49cc435f7108023c2091076a53f", "width": 960, "height": 866}, {"url": "https://external-preview.redd.it/2S5D9ZXRBmgFuC8KEot9pKoJLiuFS7rOQ9LIWchVXFY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4699b4317e2ebfa06b4c9c9c962c5718bd69f833", "width": 1080, "height": 975}], "variants": {}, "id": "ZQgRCdfpWnKHXJDYiHnq5K3E-R3nIc12MuFnNYFmmiI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "1/10 PB", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y995fv", "is_robot_indexable": true, "report_reasons": null, "author": "mrtramplefoot", "discussion_type": null, "num_comments": 80, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/y995fv/only_took_a_few_years_and_16_drives_but_i_finally/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://imgur.com/a/OEBw1vd", "subreddit_subscribers": 648474, "created_utc": 1666298028.0, "num_crossposts": 0, "media": {"type": "imgur.com", "oembed": {"provider_url": "http://imgur.com", "description": "Post with 0 views. 1/10 PB", "title": "1/10 PB", "url": "https://imgur.com/a/OEBw1vd", "type": "rich", "thumbnail_width": 600, "height": 582, "width": 600, "html": "&lt;iframe class=\"embedly-embed\" src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fimgur.com%2Fa%2FOEBw1vd%2Fembed%3Fpub%3Dtrue%26ref%3Dhttps%253A%252F%252Fembed.ly%26w%3D900&amp;display_name=Imgur&amp;url=https%3A%2F%2Fimgur.com%2Fa%2FOEBw1vd&amp;image=https%3A%2F%2Fi.imgur.com%2FxVZSyZA.jpg%3Ffb&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=imgur\" width=\"600\" height=\"582\" scrolling=\"no\" title=\"Imgur embed\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen=\"true\"&gt;&lt;/iframe&gt;", "version": "1.0", "provider_name": "Imgur", "thumbnail_url": "https://i.imgur.com/xVZSyZA.jpg?fb", "thumbnail_height": 315}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am assuming that mechanical HDDs are simply impossible due to the operating environment, and I'm limited to SSDs. Obviously it won't be that hot most of the time, but if my vehicle is getting direct sun exposure all day in the summer, I can't have things crash. My Pepwave routers (formerly ubr lte, now br2 max pro) handle the conditions fine.\n\nSo then the game is about finding the cheapest SSDs. Ruling out the stuff the stuff that's obviously fraud, the best deal seems to be 2.5\" NVME U.2 drives, with several 7.68 tb models in the $400 range.\n\nFrom what I can tell, u.2 and m.2 are electronically compatible, and you \"simply\" need the appropriate cabling / adapters to go between the two. So rather than run some massive (and power hungry) server which natively runs u.2 drives, I can put the drives in dumb enclosures, get some U2 to M2 adapters, and connect them to something like the QNAP m.2 \"nasbook\" with the adapters.\n\nThis would get me 32TB of SSD storage right around $2000, with a device that I can power directly off my DC electrical system. Am I missing anything? Is there a better / cheaper way to accomplish this?\n\nNo, I don't care about performance - not in any meaningful sense. As long as I can get 100 megabytes per second I'll be fine - no plans for anything faster than gbe. It's all about reliability in a hot moving vehicle.", "author_fullname": "t2_rwjf88po", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Setting up a 30TB or larger NAS for my bugout vehicle - needs to operate in ambient temperatures above 60C and with extreme vibrations. Thoughts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y91m1a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 150, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 150, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666280504.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am assuming that mechanical HDDs are simply impossible due to the operating environment, and I&amp;#39;m limited to SSDs. Obviously it won&amp;#39;t be that hot most of the time, but if my vehicle is getting direct sun exposure all day in the summer, I can&amp;#39;t have things crash. My Pepwave routers (formerly ubr lte, now br2 max pro) handle the conditions fine.&lt;/p&gt;\n\n&lt;p&gt;So then the game is about finding the cheapest SSDs. Ruling out the stuff the stuff that&amp;#39;s obviously fraud, the best deal seems to be 2.5&amp;quot; NVME U.2 drives, with several 7.68 tb models in the $400 range.&lt;/p&gt;\n\n&lt;p&gt;From what I can tell, u.2 and m.2 are electronically compatible, and you &amp;quot;simply&amp;quot; need the appropriate cabling / adapters to go between the two. So rather than run some massive (and power hungry) server which natively runs u.2 drives, I can put the drives in dumb enclosures, get some U2 to M2 adapters, and connect them to something like the QNAP m.2 &amp;quot;nasbook&amp;quot; with the adapters.&lt;/p&gt;\n\n&lt;p&gt;This would get me 32TB of SSD storage right around $2000, with a device that I can power directly off my DC electrical system. Am I missing anything? Is there a better / cheaper way to accomplish this?&lt;/p&gt;\n\n&lt;p&gt;No, I don&amp;#39;t care about performance - not in any meaningful sense. As long as I can get 100 megabytes per second I&amp;#39;ll be fine - no plans for anything faster than gbe. It&amp;#39;s all about reliability in a hot moving vehicle.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y91m1a", "is_robot_indexable": true, "report_reasons": null, "author": "ImFuckinUrDadTonight", "discussion_type": null, "num_comments": 130, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y91m1a/setting_up_a_30tb_or_larger_nas_for_my_bugout/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y91m1a/setting_up_a_30tb_or_larger_nas_for_my_bugout/", "subreddit_subscribers": 648474, "created_utc": 1666280504.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_brup0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My NAS, waiting for HDD's", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_y9do6r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "ups": 84, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 84, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/6AG6MjjfYuiZfsFWsJ_Vq-40DvMBfv5y1gKiy4ZsQhw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666309155.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/umdzth52r1v91.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/umdzth52r1v91.jpg?auto=webp&amp;s=2afe86a2e47f464b209ee8fe2220628827883b7b", "width": 4080, "height": 3072}, "resolutions": [{"url": "https://preview.redd.it/umdzth52r1v91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=da53c920c12c125400e9ebaf1b3d883c4158bde8", "width": 108, "height": 81}, {"url": "https://preview.redd.it/umdzth52r1v91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e727667a729c61ab5932bbe5c7a37f7339c4b8e1", "width": 216, "height": 162}, {"url": "https://preview.redd.it/umdzth52r1v91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=da0bbbea375f8e9580c9b6f475abee528e2ab400", "width": 320, "height": 240}, {"url": "https://preview.redd.it/umdzth52r1v91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=30ec57e6c9aea04db8688affc7b2dec8a19a6c2f", "width": 640, "height": 481}, {"url": "https://preview.redd.it/umdzth52r1v91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2a8731dab308c6dc1b8f2a71a2f860ece6cba986", "width": 960, "height": 722}, {"url": "https://preview.redd.it/umdzth52r1v91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=948fb4de4f9c5560a87c83c9754f4d2fa8f42eda", "width": 1080, "height": 813}], "variants": {}, "id": "vmzNJVobOAm7TlaiUXiur7RZnZX9k_LIcou02IH7udY"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y9do6r", "is_robot_indexable": true, "report_reasons": null, "author": "ronmfnjeremy", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y9do6r/my_nas_waiting_for_hdds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/umdzth52r1v91.jpg", "subreddit_subscribers": 648474, "created_utc": 1666309155.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've got two identical Seagate Barracuda ST1000DM003-1ER162 internal hard drives. They were bought together, and now I'm worried that they're going to die together as well. I took a look at the SMART info today and it got me concerned. I have backups of everything on both of them and my OS is installed on an SSD so I wouldn't lose any data if they did die, but of course I want to extend their life as much as possible. Hard drives don't grow on trees. \n\nThe drives are pretty old, the temperatures are okay and I do not have older SMART data to compare and see if the number of uncorrect/able and pending sectors is increasing or not. Here's the SMART info for both of them:\n\n[Disk 1](https://preview.redd.it/ug60strhvyu91.png?width=742&amp;format=png&amp;auto=webp&amp;s=84d600814d5595a1533398dc35273eec46469951)\n\n[Disk 2](https://preview.redd.it/rgrb23ljvyu91.png?width=745&amp;format=png&amp;auto=webp&amp;s=5ec58be2ac7516b774c300ad2cb59c1154f9fae4)\n\nThere was also a bunch of errors:\n\n[Errors](https://preview.redd.it/qrdswytmvyu91.png?width=920&amp;format=png&amp;auto=webp&amp;s=0da395a230a205b365e77070631ba1486636ffc0)\n\nI am also very concerned about all the \"prefailure warning\" flags NOT on the attributes marked as problematic. \n\nBut oddly, with all this wrong, I still get the following message:\n\n&gt;=== START OF READ SMART DATA SECTION ===   \n&gt;  \n&gt;SMART overall-health self-assessment test result: PASSED\n\nSo, my questions to you fine people are: \n\n1. I know there's a big margin of error, but how long should I expect these drives to last? \n2. Why does SMART say \"passed\" with all those errors? \n3. What immediate action would you take in my shoes? I'd like to avoid replacing them but if the risk is too big, that's what I'll have to do.\n\nPlease and thank you for your time.", "author_fullname": "t2_i0lhuvu5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Worried about \"Reported_Uncorrect\" and \"Offline_Uncorrectable\" - how much longer can I expect my drives to last?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 115, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ug60strhvyu91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 89, "x": 108, "u": "https://preview.redd.it/ug60strhvyu91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=34acf450e468f5e83471dca6ac29f9d77924d565"}, {"y": 178, "x": 216, "u": "https://preview.redd.it/ug60strhvyu91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5dd622f8e1cac5d4cf92e88f682b537986518b74"}, {"y": 264, "x": 320, "u": "https://preview.redd.it/ug60strhvyu91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2485ca590e9eb8f67c6069296c1dda3cd2a8f0f6"}, {"y": 529, "x": 640, "u": "https://preview.redd.it/ug60strhvyu91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0dbb5abbb9f74e536595e40f406be0fb14da559b"}], "s": {"y": 614, "x": 742, "u": "https://preview.redd.it/ug60strhvyu91.png?width=742&amp;format=png&amp;auto=webp&amp;s=84d600814d5595a1533398dc35273eec46469951"}, "id": "ug60strhvyu91"}, "rgrb23ljvyu91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 89, "x": 108, "u": "https://preview.redd.it/rgrb23ljvyu91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6dc86c8354e91afc7de14838bf746507e6bcafb4"}, {"y": 178, "x": 216, "u": "https://preview.redd.it/rgrb23ljvyu91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b4696215559fb92b087e55efb1f6cd9fea1c7e96"}, {"y": 264, "x": 320, "u": "https://preview.redd.it/rgrb23ljvyu91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e5aa344e789d2d85ff3c300c6cac3deef8641677"}, {"y": 529, "x": 640, "u": "https://preview.redd.it/rgrb23ljvyu91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=594f562388fc8a77274d632c9192462498b36f19"}], "s": {"y": 616, "x": 745, "u": "https://preview.redd.it/rgrb23ljvyu91.png?width=745&amp;format=png&amp;auto=webp&amp;s=5ec58be2ac7516b774c300ad2cb59c1154f9fae4"}, "id": "rgrb23ljvyu91"}, "qrdswytmvyu91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 216, "x": 108, "u": "https://preview.redd.it/qrdswytmvyu91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e3bbaefb7e11338f6b03d44d694be10e4ef7628b"}, {"y": 432, "x": 216, "u": "https://preview.redd.it/qrdswytmvyu91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f9c724651663ade23035ad5f01940e5f6eb0fc1d"}, {"y": 640, "x": 320, "u": "https://preview.redd.it/qrdswytmvyu91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f17c4b8b8a74d5fe6fe07863b14d58d602ebec8a"}, {"y": 1280, "x": 640, "u": "https://preview.redd.it/qrdswytmvyu91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ceeee3e467254e95bcc98557335d490138d5f185"}], "s": {"y": 2457, "x": 920, "u": "https://preview.redd.it/qrdswytmvyu91.png?width=920&amp;format=png&amp;auto=webp&amp;s=0da395a230a205b365e77070631ba1486636ffc0"}, "id": "qrdswytmvyu91"}}, "name": "t3_y8zbbv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/a7eoDtbku1c-9DENzEsiUmtjbhd6msRfCABsJcwEkGY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666275027.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got two identical Seagate Barracuda ST1000DM003-1ER162 internal hard drives. They were bought together, and now I&amp;#39;m worried that they&amp;#39;re going to die together as well. I took a look at the SMART info today and it got me concerned. I have backups of everything on both of them and my OS is installed on an SSD so I wouldn&amp;#39;t lose any data if they did die, but of course I want to extend their life as much as possible. Hard drives don&amp;#39;t grow on trees. &lt;/p&gt;\n\n&lt;p&gt;The drives are pretty old, the temperatures are okay and I do not have older SMART data to compare and see if the number of uncorrect/able and pending sectors is increasing or not. Here&amp;#39;s the SMART info for both of them:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ug60strhvyu91.png?width=742&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=84d600814d5595a1533398dc35273eec46469951\"&gt;Disk 1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/rgrb23ljvyu91.png?width=745&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5ec58be2ac7516b774c300ad2cb59c1154f9fae4\"&gt;Disk 2&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;There was also a bunch of errors:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/qrdswytmvyu91.png?width=920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0da395a230a205b365e77070631ba1486636ffc0\"&gt;Errors&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I am also very concerned about all the &amp;quot;prefailure warning&amp;quot; flags NOT on the attributes marked as problematic. &lt;/p&gt;\n\n&lt;p&gt;But oddly, with all this wrong, I still get the following message:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;=== START OF READ SMART DATA SECTION ===   &lt;/p&gt;\n\n&lt;p&gt;SMART overall-health self-assessment test result: PASSED&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;So, my questions to you fine people are: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I know there&amp;#39;s a big margin of error, but how long should I expect these drives to last? &lt;/li&gt;\n&lt;li&gt;Why does SMART say &amp;quot;passed&amp;quot; with all those errors? &lt;/li&gt;\n&lt;li&gt;What immediate action would you take in my shoes? I&amp;#39;d like to avoid replacing them but if the risk is too big, that&amp;#39;s what I&amp;#39;ll have to do.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Please and thank you for your time.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y8zbbv", "is_robot_indexable": true, "report_reasons": null, "author": "Peruvian_Skies", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y8zbbv/worried_about_reported_uncorrect_and_offline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y8zbbv/worried_about_reported_uncorrect_and_offline/", "subreddit_subscribers": 648474, "created_utc": 1666275027.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Well, that is it. After getting my 8th hard drive, I finally feel like trying MergerFS. My current setup is just a mess, I mount all 8 drives as different devices, different SMB shares. That is getting out of hand.\n\nI installed the MergerFS plug-in for OpenMediavault (my server's operating system), selected all my drives (except the system drive and the backup drive) and let it do it's thing.\n\nIn no time, I got a single volume mounted with all my previous data! That is... awesome! No need to search all the drives to find a single file anymore!\n\nQuestions:\n\n* Say I buy new drives. Can I just add them to the virtual disk? Or will I have to recreate it from scratch?\n* Say I remove a disk, or one of them fails. Will that corrupt all my files, like RAID does? If not, what happens, and what can I do in this situation?\n* Will that meaningfully increase resource consumption or Disk I/O?", "author_fullname": "t2_h1i5h1th", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First time using MergerFS. Anything I should know?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y98r62", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666297108.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Well, that is it. After getting my 8th hard drive, I finally feel like trying MergerFS. My current setup is just a mess, I mount all 8 drives as different devices, different SMB shares. That is getting out of hand.&lt;/p&gt;\n\n&lt;p&gt;I installed the MergerFS plug-in for OpenMediavault (my server&amp;#39;s operating system), selected all my drives (except the system drive and the backup drive) and let it do it&amp;#39;s thing.&lt;/p&gt;\n\n&lt;p&gt;In no time, I got a single volume mounted with all my previous data! That is... awesome! No need to search all the drives to find a single file anymore!&lt;/p&gt;\n\n&lt;p&gt;Questions:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Say I buy new drives. Can I just add them to the virtual disk? Or will I have to recreate it from scratch?&lt;/li&gt;\n&lt;li&gt;Say I remove a disk, or one of them fails. Will that corrupt all my files, like RAID does? If not, what happens, and what can I do in this situation?&lt;/li&gt;\n&lt;li&gt;Will that meaningfully increase resource consumption or Disk I/O?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "10.5TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y98r62", "is_robot_indexable": true, "report_reasons": null, "author": "OliveEar", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/y98r62/first_time_using_mergerfs_anything_i_should_know/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y98r62/first_time_using_mergerfs_anything_i_should_know/", "subreddit_subscribers": 648474, "created_utc": 1666297108.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm considering making some kind of time capsule of some of my digital photos and videos. I'd like it to be something like a \"permanent backup\": I write the data once, put it on a shelf and then read multiple times later without the ability to accidentally overwrite the data.\n\nAre there any common storage devices that offer such functionality? The only ones I know of are write-once CD and DVD drives, CD-R, DVD-R and possibly their `+R` variants. Are there any other options?\n\nI could use write-protection features of various file systems and simply store stuff on a hard drive, but it seems like there's no way to prevent formatting the drive and flashing a new empty file system. However, I'd like to have a storage medium that physically can't be formatted or overwritten after the initial write. Is there anything like this that's fairly common and not too exotic?", "author_fullname": "t2_vqc6b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Write-once durable storage medium?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y999ol", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.59, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666299060.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666298303.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m considering making some kind of time capsule of some of my digital photos and videos. I&amp;#39;d like it to be something like a &amp;quot;permanent backup&amp;quot;: I write the data once, put it on a shelf and then read multiple times later without the ability to accidentally overwrite the data.&lt;/p&gt;\n\n&lt;p&gt;Are there any common storage devices that offer such functionality? The only ones I know of are write-once CD and DVD drives, CD-R, DVD-R and possibly their &lt;code&gt;+R&lt;/code&gt; variants. Are there any other options?&lt;/p&gt;\n\n&lt;p&gt;I could use write-protection features of various file systems and simply store stuff on a hard drive, but it seems like there&amp;#39;s no way to prevent formatting the drive and flashing a new empty file system. However, I&amp;#39;d like to have a storage medium that physically can&amp;#39;t be formatted or overwritten after the initial write. Is there anything like this that&amp;#39;s fairly common and not too exotic?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y999ol", "is_robot_indexable": true, "report_reasons": null, "author": "ForceBru", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y999ol/writeonce_durable_storage_medium/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y999ol/writeonce_durable_storage_medium/", "subreddit_subscribers": 648474, "created_utc": 1666298303.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Im doing some research on the early web and such a list of URLs would be a great help. Ive Googled but nothing like that seems to exist. Surely some data hoarder in 1994 mustve pinged every domain on the net, right?", "author_fullname": "t2_8k6dsg1t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "List of every subdomain existing on the internet in 1994?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9moud", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.58, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666336256.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im doing some research on the early web and such a list of URLs would be a great help. Ive Googled but nothing like that seems to exist. Surely some data hoarder in 1994 mustve pinged every domain on the net, right?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y9moud", "is_robot_indexable": true, "report_reasons": null, "author": "icemelter4K", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y9moud/list_of_every_subdomain_existing_on_the_internet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y9moud/list_of_every_subdomain_existing_on_the_internet/", "subreddit_subscribers": 648474, "created_utc": 1666336256.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So someone online sent me this link [https://www.ioi-xd.net/trollface.png/](https://www.ioi-xd.net/trollface.png/), its a 8 exabyte file of a troll face, i asked him if he actually had a server with 8 exabytes of storage hosting the site, he said no, and he wont tell me how he did it, the only hint ive gotten is \" your hint is a command that's not avaliable on windows \", Can someone  help me?", "author_fullname": "t2_8laseudw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How are people able to host really really really big files on servers without it taking space?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9koki", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666329434.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So someone online sent me this link &lt;a href=\"https://www.ioi-xd.net/trollface.png/\"&gt;https://www.ioi-xd.net/trollface.png/&lt;/a&gt;, its a 8 exabyte file of a troll face, i asked him if he actually had a server with 8 exabytes of storage hosting the site, he said no, and he wont tell me how he did it, the only hint ive gotten is &amp;quot; your hint is a command that&amp;#39;s not avaliable on windows &amp;quot;, Can someone  help me?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y9koki", "is_robot_indexable": true, "report_reasons": null, "author": "Agitated-Farmer-4082", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y9koki/how_are_people_able_to_host_really_really_really/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y9koki/how_are_people_able_to_host_really_really_really/", "subreddit_subscribers": 648474, "created_utc": 1666329434.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've spent quite alot of money on a desktop but don't really do much apart from encoding and downloading stuff. I have a Lenovo Z50 laptop sitting there doing nothing and I was thinking of maybe selling the desktop and just using the laptop but would a laptop be OK for the type of stuff I'm doing?", "author_fullname": "t2_5dkgegkg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Laptop for downloading overnight?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y8yk58", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.53, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666273160.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve spent quite alot of money on a desktop but don&amp;#39;t really do much apart from encoding and downloading stuff. I have a Lenovo Z50 laptop sitting there doing nothing and I was thinking of maybe selling the desktop and just using the laptop but would a laptop be OK for the type of stuff I&amp;#39;m doing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y8yk58", "is_robot_indexable": true, "report_reasons": null, "author": "craftywizard1983", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y8yk58/laptop_for_downloading_overnight/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y8yk58/laptop_for_downloading_overnight/", "subreddit_subscribers": 648474, "created_utc": 1666273160.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_76pgn19", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When it's only 1080p on disc, but 4K on streaming.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "friday", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_y9t3l3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Free-Post Friday!", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://a.thumbs.redditmedia.com/hmtFByBvc07MmU4gQdPdSvn_xt2oSiiWPTIPCYiuho4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666357167.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/4fudk82qp5v91.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/4fudk82qp5v91.jpg?auto=webp&amp;s=800b8ffe7a528a12451385f1b3915c24bb1b85e7", "width": 500, "height": 756}, "resolutions": [{"url": "https://preview.redd.it/4fudk82qp5v91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c894a75fc6599e888a97c66a37b60646aaab9c8e", "width": 108, "height": 163}, {"url": "https://preview.redd.it/4fudk82qp5v91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ad6ac5f484d76451f9357abab8adf8cdd82c94e7", "width": 216, "height": 326}, {"url": "https://preview.redd.it/4fudk82qp5v91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=577944cc5488b7d25e8d5b869546ab346a20dc70", "width": 320, "height": 483}], "variants": {}, "id": "Ru1-kE76dgnsAUF9cLPGLH_-efOnk2T9hhwrH_zYNhk"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82f515be-b94e-11eb-9f8a-0e1030dba663", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y9t3l3", "is_robot_indexable": true, "report_reasons": null, "author": "AshleyUncia", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y9t3l3/when_its_only_1080p_on_disc_but_4k_on_streaming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/4fudk82qp5v91.jpg", "subreddit_subscribers": 648474, "created_utc": 1666357167.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "On my machine, I can use \"properties\" to check exactly how many files and bytes are in my folders. However, when I look at my files on dropbox's or google drive's site, I only get a very vague total used space amount, like \"6.3 GB of 15 GB used\".\n\nI want to get an exact byte count so that I can compare it to what I have on my machine and be assured that everything is being copied over correctly. Is there a way of doing that?", "author_fullname": "t2_11vuwl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to ensure that Google Drive and Dropbox has correctly uploaded everything?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9pu2g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666347150.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;On my machine, I can use &amp;quot;properties&amp;quot; to check exactly how many files and bytes are in my folders. However, when I look at my files on dropbox&amp;#39;s or google drive&amp;#39;s site, I only get a very vague total used space amount, like &amp;quot;6.3 GB of 15 GB used&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;I want to get an exact byte count so that I can compare it to what I have on my machine and be assured that everything is being copied over correctly. Is there a way of doing that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y9pu2g", "is_robot_indexable": true, "report_reasons": null, "author": "Skwigle", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y9pu2g/how_to_ensure_that_google_drive_and_dropbox_has/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y9pu2g/how_to_ensure_that_google_drive_and_dropbox_has/", "subreddit_subscribers": 648474, "created_utc": 1666347150.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I have a collection of an old Webcast (HQ Export by me) that I would like to export to the archive but the files are in a directory with subfolders. Is there a way to bulk upload to the archive (preferably with a UI)?", "author_fullname": "t2_1to1h5z2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to bulk upload a directory to Archive.org?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9p4yz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666344881.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I have a collection of an old Webcast (HQ Export by me) that I would like to export to the archive but the files are in a directory with subfolders. Is there a way to bulk upload to the archive (preferably with a UI)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y9p4yz", "is_robot_indexable": true, "report_reasons": null, "author": "WillTDP", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y9p4yz/how_to_bulk_upload_a_directory_to_archiveorg/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y9p4yz/how_to_bulk_upload_a_directory_to_archiveorg/", "subreddit_subscribers": 648474, "created_utc": 1666344881.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_h6kxy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "StackOverflow is going Kiwix: Introducing the Overflow Offline project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_y9q9rm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/l14XyUJ4D0fXDXyDk0pPvBpXeuo4-EhbJF523beuAMk.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666348586.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "stackoverflow.blog", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://stackoverflow.blog/2022/10/20/introducing-the-overflow-offline-project/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4XNCMGYIcyKvr0bbV5HIoGHIb4fDYVNlK7sL1Kv7nG8.jpg?auto=webp&amp;s=fe3fd44282b495eb8502a7f89c0417a4f0d01ed4", "width": 2400, "height": 1260}, "resolutions": [{"url": "https://external-preview.redd.it/4XNCMGYIcyKvr0bbV5HIoGHIb4fDYVNlK7sL1Kv7nG8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5b415abf9c250af511690f8963433a292d4535d8", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/4XNCMGYIcyKvr0bbV5HIoGHIb4fDYVNlK7sL1Kv7nG8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5455916c5e872315bfee3b152594636fc327ed50", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/4XNCMGYIcyKvr0bbV5HIoGHIb4fDYVNlK7sL1Kv7nG8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6850955ae390520fa53916fa9737cc020d53fbda", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/4XNCMGYIcyKvr0bbV5HIoGHIb4fDYVNlK7sL1Kv7nG8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8deb5415054a41ae431dffd4e9cab0717af87254", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/4XNCMGYIcyKvr0bbV5HIoGHIb4fDYVNlK7sL1Kv7nG8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2b356141b347a4729ec8a4dfa6be931395bbb27f", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/4XNCMGYIcyKvr0bbV5HIoGHIb4fDYVNlK7sL1Kv7nG8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f1f8de49727f18be1ccfb670504dbbe697170353", "width": 1080, "height": 567}], "variants": {}, "id": "erL8kaetB-pPKQmluviS4rFGCUQW2_AEXM_uyKHo1dU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "400TB raw", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y9q9rm", "is_robot_indexable": true, "report_reasons": null, "author": "It_Is1-24PM", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/y9q9rm/stackoverflow_is_going_kiwix_introducing_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://stackoverflow.blog/2022/10/20/introducing-the-overflow-offline-project/", "subreddit_subscribers": 648474, "created_utc": 1666348586.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is there a site out there that archives news stories of a particular day in history?\n\nIm trying to find some UK news stories and using the wayback machine is completely useless for anything outside of the US as it redirects to the US versions of those news sites showing a 301, or a 307 error regardless of your locale and im finding it impossible to get to some of the UK news sites because of that.", "author_fullname": "t2_eq196", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Daily news archives for non-US news sources?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9q1kl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666347829.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a site out there that archives news stories of a particular day in history?&lt;/p&gt;\n\n&lt;p&gt;Im trying to find some UK news stories and using the wayback machine is completely useless for anything outside of the US as it redirects to the US versions of those news sites showing a 301, or a 307 error regardless of your locale and im finding it impossible to get to some of the UK news sites because of that.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y9q1kl", "is_robot_indexable": true, "report_reasons": null, "author": "jpjapers", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y9q1kl/daily_news_archives_for_nonus_news_sources/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y9q1kl/daily_news_archives_for_nonus_news_sources/", "subreddit_subscribers": 648474, "created_utc": 1666347829.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Does anyone remember this defunct clould storage site Firedrop.com which had a lot of ROMs from The ISO Zone?", "author_fullname": "t2_lru1al2t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Defunct cloud storage site Firedrop?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9nbt5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666338836.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666338599.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone remember this defunct clould storage site Firedrop.com which had a lot of ROMs from The ISO Zone?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y9nbt5", "is_robot_indexable": true, "report_reasons": null, "author": "miller11568", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y9nbt5/defunct_cloud_storage_site_firedrop/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y9nbt5/defunct_cloud_storage_site_firedrop/", "subreddit_subscribers": 648474, "created_utc": 1666338599.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've tried Twitch Downloader and 4K Video Downloader and they work fine with public VODs, but doesn't work with subscriber locked ones, I'm a sub btw. I've also tried  Video DownloadHelper extension HLS streaming, it works fine until 80-90%, then it crashes and all its left is a PART file that is useless. Please help me!!", "author_fullname": "t2_11su7o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I download Sub-only Twitch VODs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9kdoz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666328494.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve tried Twitch Downloader and 4K Video Downloader and they work fine with public VODs, but doesn&amp;#39;t work with subscriber locked ones, I&amp;#39;m a sub btw. I&amp;#39;ve also tried  Video DownloadHelper extension HLS streaming, it works fine until 80-90%, then it crashes and all its left is a PART file that is useless. Please help me!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y9kdoz", "is_robot_indexable": true, "report_reasons": null, "author": "afwk2", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y9kdoz/how_can_i_download_subonly_twitch_vods/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y9kdoz/how_can_i_download_subonly_twitch_vods/", "subreddit_subscribers": 648474, "created_utc": 1666328494.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey Y'all. I've never doone RAID arrays, proper backups, or the like before and was looing for some advice. I've currently got a couple 4TB drives in RAID1 on OpenMediaVault, but it's filling up fast. After some research, I was planning on making an offsite NAS for redundancy.\n\nI figured a RAID6 of like 16TB  each Seagate Exos drives would be okay for offsite redundancy, it has two drives that can fail, and can hold a lot of data on a smaller number of drives  (was going to start with four, and possibly go to as many as six, depending on my usage. Since it's offsite, I wanted it to be as low-maintenance as possible)\n\nI was then going to set up my home NAS in a raid 5 of some smaller size also on OMV (6TB a drive, for example.) I figure it's less safe, but will still have a drive failure supported, as well as faster reads for the same amount of storage as compared to a larger drive.\n\nWith the offsite redundancy, I'm not sure if that would count as a backup, or if I should have a tertiary option somewhere. I've only ever done cold storage for single disk backups, I'm not sure how that would work with say 25+TB of data.\n\nIs my proposed implementation stable? Are there any things I've overengineered, or should do differently within the limitations of only having 8 bays in my local system? I don't plan on filling them all at once, I figured the 3 drives minimum for a raid 5 and 4 minimum of a raid six should hold me over for maybe a year, unless it's better to create the max size array at once, to cut down on syncing?", "author_fullname": "t2_12lnoa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First time Hoarder questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y96uo0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666292878.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666292623.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Y&amp;#39;all. I&amp;#39;ve never doone RAID arrays, proper backups, or the like before and was looing for some advice. I&amp;#39;ve currently got a couple 4TB drives in RAID1 on OpenMediaVault, but it&amp;#39;s filling up fast. After some research, I was planning on making an offsite NAS for redundancy.&lt;/p&gt;\n\n&lt;p&gt;I figured a RAID6 of like 16TB  each Seagate Exos drives would be okay for offsite redundancy, it has two drives that can fail, and can hold a lot of data on a smaller number of drives  (was going to start with four, and possibly go to as many as six, depending on my usage. Since it&amp;#39;s offsite, I wanted it to be as low-maintenance as possible)&lt;/p&gt;\n\n&lt;p&gt;I was then going to set up my home NAS in a raid 5 of some smaller size also on OMV (6TB a drive, for example.) I figure it&amp;#39;s less safe, but will still have a drive failure supported, as well as faster reads for the same amount of storage as compared to a larger drive.&lt;/p&gt;\n\n&lt;p&gt;With the offsite redundancy, I&amp;#39;m not sure if that would count as a backup, or if I should have a tertiary option somewhere. I&amp;#39;ve only ever done cold storage for single disk backups, I&amp;#39;m not sure how that would work with say 25+TB of data.&lt;/p&gt;\n\n&lt;p&gt;Is my proposed implementation stable? Are there any things I&amp;#39;ve overengineered, or should do differently within the limitations of only having 8 bays in my local system? I don&amp;#39;t plan on filling them all at once, I figured the 3 drives minimum for a raid 5 and 4 minimum of a raid six should hold me over for maybe a year, unless it&amp;#39;s better to create the max size array at once, to cut down on syncing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y96uo0", "is_robot_indexable": true, "report_reasons": null, "author": "thextallxdude", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y96uo0/first_time_hoarder_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y96uo0/first_time_hoarder_questions/", "subreddit_subscribers": 648474, "created_utc": 1666292623.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi guys,\n\nI've acquired a Synology NAS which is leaps and bounds better than the Seagate Personal Cloud I've had for a while, especially so because the thing is actually supported (unlike the Seagate).\n\nIn my attempts to move the data across, I have both the Seagate and Synology on the network, and on my computer I can see each of them as a network drive in the file explorer. I've essentially highlighted all the folders on the Seagate and copy/pasted them over to the Synology through the network folders, but what I've now realised is this is taking the data from the Seagate and sending it through my computer, which then passes it to the Synology - not exactly the most efficient way of doing things and is taking its sweet time.\n\nI don't suppose there's a way to do this in a more direct manner, through the interfaces of each NAS instead so that they can just talk to one another directly on the network rather than using the computer as an intermediary? I did have a look around, but couldn't find a solution. I also don't have the option to connect them to each other via USB as the Seagate does not support this.\n\nThanks in advance.", "author_fullname": "t2_c0wzv9f0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Copying from Seagate Personal Cloud to Synology efficiently?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y96bn2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666291399.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve acquired a Synology NAS which is leaps and bounds better than the Seagate Personal Cloud I&amp;#39;ve had for a while, especially so because the thing is actually supported (unlike the Seagate).&lt;/p&gt;\n\n&lt;p&gt;In my attempts to move the data across, I have both the Seagate and Synology on the network, and on my computer I can see each of them as a network drive in the file explorer. I&amp;#39;ve essentially highlighted all the folders on the Seagate and copy/pasted them over to the Synology through the network folders, but what I&amp;#39;ve now realised is this is taking the data from the Seagate and sending it through my computer, which then passes it to the Synology - not exactly the most efficient way of doing things and is taking its sweet time.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t suppose there&amp;#39;s a way to do this in a more direct manner, through the interfaces of each NAS instead so that they can just talk to one another directly on the network rather than using the computer as an intermediary? I did have a look around, but couldn&amp;#39;t find a solution. I also don&amp;#39;t have the option to connect them to each other via USB as the Seagate does not support this.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y96bn2", "is_robot_indexable": true, "report_reasons": null, "author": "FlyingNipplez", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y96bn2/copying_from_seagate_personal_cloud_to_synology/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y96bn2/copying_from_seagate_personal_cloud_to_synology/", "subreddit_subscribers": 648474, "created_utc": 1666291399.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Testing used hard drives. Right now both units are doing S.M.A.R.T Long scan. About 90% complete (aprox 20hrs so far). Assuming both pass SMART test. \n\nQuestion: Should I run Bad Sector Scan? Or is SMART scan enough to feel used drive is ok to add in raid?", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Used Exos 16TB drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9432f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": "", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666286176.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Testing used hard drives. Right now both units are doing S.M.A.R.T Long scan. About 90% complete (aprox 20hrs so far). Assuming both pass SMART test. &lt;/p&gt;\n\n&lt;p&gt;Question: Should I run Bad Sector Scan? Or is SMART scan enough to feel used drive is ok to add in raid?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y9432f", "is_robot_indexable": true, "report_reasons": null, "author": "[deleted]", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/y9432f/used_exos_16tb_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y9432f/used_exos_16tb_drives/", "subreddit_subscribers": 648474, "created_utc": 1666286176.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Looking at the SMART data I can't seem to decide which pair of HD to replace. The pool is permanently connected as NAS in a network and it's only used when torrenting and/or playing films. So I don't know what's the best strategy to balance long term hardware and money (by maybe selling HD). SMART summary:\n* 1 HD without raw read errors relatively new.\n* 4 HD without raw read errors but maybe getting old.\n* 1 HD with raw read errors but SMART still OK. Self-test passed without errors too. Same age than previous 4.\n\nI have freshly new 2x10TB and I don't know which pair of HD to choose to replace in the pool.\n* Replace the pair where the HD with errors is or leave it until it dies if it does? Sell the other one second hand? Sell both in eBay with the SMART warning?\n* Replace 2 normal ones and sell them? Keep error one?\n* Maybe replace 2 normal ones, replace the error one when it breaks in the future and sell only 1?\n\nHelp is appreciated.", "author_fullname": "t2_kyrj9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Replacing 2\u00d74TB with 2\u00d710TB in a 6\u00d74TB zfs pool of stripped mirrors. But don't know which pair is best looking at SMART.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y91qs3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666280814.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking at the SMART data I can&amp;#39;t seem to decide which pair of HD to replace. The pool is permanently connected as NAS in a network and it&amp;#39;s only used when torrenting and/or playing films. So I don&amp;#39;t know what&amp;#39;s the best strategy to balance long term hardware and money (by maybe selling HD). SMART summary:\n* 1 HD without raw read errors relatively new.\n* 4 HD without raw read errors but maybe getting old.\n* 1 HD with raw read errors but SMART still OK. Self-test passed without errors too. Same age than previous 4.&lt;/p&gt;\n\n&lt;p&gt;I have freshly new 2x10TB and I don&amp;#39;t know which pair of HD to choose to replace in the pool.\n* Replace the pair where the HD with errors is or leave it until it dies if it does? Sell the other one second hand? Sell both in eBay with the SMART warning?\n* Replace 2 normal ones and sell them? Keep error one?\n* Maybe replace 2 normal ones, replace the error one when it breaks in the future and sell only 1?&lt;/p&gt;\n\n&lt;p&gt;Help is appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y91qs3", "is_robot_indexable": true, "report_reasons": null, "author": "Bloodsucker_", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y91qs3/replacing_24tb_with_210tb_in_a_64tb_zfs_pool_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y91qs3/replacing_24tb_with_210tb_in_a_64tb_zfs_pool_of/", "subreddit_subscribers": 648474, "created_utc": 1666280814.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "when i am copying 1 large 20gig 4k movie from my laptop nvme to external ssd, why is speed dropping sometimes?", "author_fullname": "t2_q1as0vo8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SSD speed drops", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9mzg9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666337311.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;when i am copying 1 large 20gig 4k movie from my laptop nvme to external ssd, why is speed dropping sometimes?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y9mzg9", "is_robot_indexable": true, "report_reasons": null, "author": "Illustrious-Band-715", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y9mzg9/ssd_speed_drops/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y9mzg9/ssd_speed_drops/", "subreddit_subscribers": 648474, "created_utc": 1666337311.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been rocking a Seagate NAS 4-Bay 8TB (STCU8000100) since 2016. It is definitely showing its age and no longer is receiving updates. It has a whopping ARM 1.2 GHz Processor and 512MB DDR3 Memory. I have 4x8TB WD Reds in a RAID 6 that I upgraded about a year ago. I'm down to 2TB free and it is whining at me.\n\nI'm looking for something that either has several bays so I can keep my 8TB drives or something that can support larger drives so I can maintain redundancy.\n\nPrice range is \\~$500. I mostly use it as a Plex server and some backup. Any advice would be helpful and welcome!", "author_fullname": "t2_imy4xp2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need advice on new NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9ikkc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666323030.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been rocking a Seagate NAS 4-Bay 8TB (STCU8000100) since 2016. It is definitely showing its age and no longer is receiving updates. It has a whopping ARM 1.2 GHz Processor and 512MB DDR3 Memory. I have 4x8TB WD Reds in a RAID 6 that I upgraded about a year ago. I&amp;#39;m down to 2TB free and it is whining at me.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for something that either has several bays so I can keep my 8TB drives or something that can support larger drives so I can maintain redundancy.&lt;/p&gt;\n\n&lt;p&gt;Price range is ~$500. I mostly use it as a Plex server and some backup. Any advice would be helpful and welcome!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y9ikkc", "is_robot_indexable": true, "report_reasons": null, "author": "AggressiveBaby", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y9ikkc/need_advice_on_new_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y9ikkc/need_advice_on_new_nas/", "subreddit_subscribers": 648474, "created_utc": 1666323030.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Long time ago I uploaded a big folder with many files properly organized under a few subfolders. Now I want to have each file or set of files in a separate IA item with proper metadata and description in order for it to be easier to access in a search. I've learned to use their [cli (python)](https://archive.org/developers/internetarchive/cli.html) and specifically the `ia copy` command (could use `move` but will delete only after all is sorted out) but I can't seem to find out how to use with wildcards or a subdirectory (or even a full mirror of an item for that matter). Can not this be done with this command? (i can probably duct-tape some solution with `list` files and paths but that'd be a bit inneficient; I also don't want to download it all to upload them again individually, not now after seeing how fast a copy or move is).", "author_fullname": "t2_dxhc7fu8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "On internetarchive, how can I copy multiple files from one item to another item?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9938q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666297889.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Long time ago I uploaded a big folder with many files properly organized under a few subfolders. Now I want to have each file or set of files in a separate IA item with proper metadata and description in order for it to be easier to access in a search. I&amp;#39;ve learned to use their &lt;a href=\"https://archive.org/developers/internetarchive/cli.html\"&gt;cli (python)&lt;/a&gt; and specifically the &lt;code&gt;ia copy&lt;/code&gt; command (could use &lt;code&gt;move&lt;/code&gt; but will delete only after all is sorted out) but I can&amp;#39;t seem to find out how to use with wildcards or a subdirectory (or even a full mirror of an item for that matter). Can not this be done with this command? (i can probably duct-tape some solution with &lt;code&gt;list&lt;/code&gt; files and paths but that&amp;#39;d be a bit inneficient; I also don&amp;#39;t want to download it all to upload them again individually, not now after seeing how fast a copy or move is).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y9938q", "is_robot_indexable": true, "report_reasons": null, "author": "mata-caes", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y9938q/on_internetarchive_how_can_i_copy_multiple_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y9938q/on_internetarchive_how_can_i_copy_multiple_files/", "subreddit_subscribers": 648474, "created_utc": 1666297889.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " I have three Lenovo NAS units on my network, one IX2, and two PX4 all running the original EMC software, latest update, not the one with a known security issue. The IX2 has been up nonstop for about 7 years, the other two something like 1.5 and 2 years.  \n\n\n06/15/2022 9:41 pmSystem (svcd)1509\ud83d\udcf7  \n Invalid attempt to log in as user 'badcred'.\n\n07/15/2022 6:38 pmSystem (svcd)1509\ud83d\udcf7  \n Invalid attempt to log in as user 'badcred'.\n\n05/25/2022 6:53 pmSystem (svcd)1509\ud83d\udcf7  \n Invalid attempt to log in as user 'badcred'.\n\nAbove is the first entry on each NAS of hundreds, groups of three a few minutes apart, each group hours apart, same on all three within a minute of same time. Nothing else has happened, Pen testing shows no external vulnerabilities, but it does eat away at my sanity. Nothing obvious is jumping out at me to reveal more details. I don't see any changes to network hardware around the start time, but since then both the switch and router have changed.  \n\n\nAny ideas?", "author_fullname": "t2_3pmrpb4f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NAS event log full of \"badcred\" entries.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9gn2h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666317492.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have three Lenovo NAS units on my network, one IX2, and two PX4 all running the original EMC software, latest update, not the one with a known security issue. The IX2 has been up nonstop for about 7 years, the other two something like 1.5 and 2 years.  &lt;/p&gt;\n\n&lt;p&gt;06/15/2022 9:41 pmSystem (svcd)1509\ud83d\udcf7&lt;br/&gt;\n Invalid attempt to log in as user &amp;#39;badcred&amp;#39;.&lt;/p&gt;\n\n&lt;p&gt;07/15/2022 6:38 pmSystem (svcd)1509\ud83d\udcf7&lt;br/&gt;\n Invalid attempt to log in as user &amp;#39;badcred&amp;#39;.&lt;/p&gt;\n\n&lt;p&gt;05/25/2022 6:53 pmSystem (svcd)1509\ud83d\udcf7&lt;br/&gt;\n Invalid attempt to log in as user &amp;#39;badcred&amp;#39;.&lt;/p&gt;\n\n&lt;p&gt;Above is the first entry on each NAS of hundreds, groups of three a few minutes apart, each group hours apart, same on all three within a minute of same time. Nothing else has happened, Pen testing shows no external vulnerabilities, but it does eat away at my sanity. Nothing obvious is jumping out at me to reveal more details. I don&amp;#39;t see any changes to network hardware around the start time, but since then both the switch and router have changed.  &lt;/p&gt;\n\n&lt;p&gt;Any ideas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y9gn2h", "is_robot_indexable": true, "report_reasons": null, "author": "Mike6f", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y9gn2h/nas_event_log_full_of_badcred_entries/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y9gn2h/nas_event_log_full_of_badcred_entries/", "subreddit_subscribers": 648474, "created_utc": 1666317492.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_kz913", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone got rsync with tor to work for the Russian NRA dump?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9f3r4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "265b199a-b98c-11e2-8300-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": "cloud", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1666313032.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "kyivpost.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.kyivpost.com/russias-war/nra-releases-full-trove-of-data-critical-to-russias-national-security.html", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "88TB useable, Debian, IPv6!!!", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y9f3r4", "is_robot_indexable": true, "report_reasons": null, "author": "gidoBOSSftw5731", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/y9f3r4/anyone_got_rsync_with_tor_to_work_for_the_russian/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.kyivpost.com/russias-war/nra-releases-full-trove-of-data-critical-to-russias-national-security.html", "subreddit_subscribers": 648474, "created_utc": 1666313032.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}