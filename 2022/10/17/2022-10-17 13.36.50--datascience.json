{"kind": "Listing", "data": {"after": "t3_y5ydbx", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "It looks like these jobs are very rare and they require a great amount of experience and do not pay well.\n\nI'm commencing a degree in data science but I'm also of a strong anti-capitalist mindset and could not care less about most of what data science seems to be about when it comes to job opportunities, i.e.  \"maximising profit\", often without any ethical considerations and to the detriment of many people. In fact, know I would be fired quickly in any job of that type.\n\nI wonder if I should reconsider my degree and maybe study something else.", "author_fullname": "t2_54lytnyf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What does data science look like in the not-for-profit sector and are there any opportunities really?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_y5w2bp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 119, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": 0, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": "", "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 119, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1665966743.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665965239.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It looks like these jobs are very rare and they require a great amount of experience and do not pay well.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m commencing a degree in data science but I&amp;#39;m also of a strong anti-capitalist mindset and could not care less about most of what data science seems to be about when it comes to job opportunities, i.e.  &amp;quot;maximising profit&amp;quot;, often without any ethical considerations and to the detriment of many people. In fact, know I would be fired quickly in any job of that type.&lt;/p&gt;\n\n&lt;p&gt;I wonder if I should reconsider my degree and maybe study something else.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 125, "id": "award_5f123e3d-4f48-42f4-9c11-e98b566d5897", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "When you come across a feel-good thing.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Wholesome", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "call_to_action": "", "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y5w2bp", "is_robot_indexable": true, "report_reasons": null, "author": "al0678", "discussion_type": null, "num_comments": 77, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y5w2bp/what_does_data_science_look_like_in_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y5w2bp/what_does_data_science_look_like_in_the/", "subreddit_subscribers": 813959, "created_utc": 1665965239.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "the youtube video for the  How to Win a Data Science Competition Learn from Top Kagglers has been taken down as the youtube channel was also deleted, i assume that one of the reasons is due to them being russian which is why their course was also taken down from coursera. I was at the part wherein they talked about their solutions in past competitions which is the final hour i'd say and then the channel got deleted. So if it is ok and if it is possible please give a link of the video as i'd like to finish it\n\nEDIT: i know that the videos are also in bilibili but they don't have english subtitles like in youtube and i'm having a hard time understanding some of the words they're saying due to their accent", "author_fullname": "t2_7bstgl3u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "does anyone have a copy of the How to Win a Data Science Competition Learn from Top Kagglers video from youtube", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y5g0hh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 102, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 102, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665924515.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;the youtube video for the  How to Win a Data Science Competition Learn from Top Kagglers has been taken down as the youtube channel was also deleted, i assume that one of the reasons is due to them being russian which is why their course was also taken down from coursera. I was at the part wherein they talked about their solutions in past competitions which is the final hour i&amp;#39;d say and then the channel got deleted. So if it is ok and if it is possible please give a link of the video as i&amp;#39;d like to finish it&lt;/p&gt;\n\n&lt;p&gt;EDIT: i know that the videos are also in bilibili but they don&amp;#39;t have english subtitles like in youtube and i&amp;#39;m having a hard time understanding some of the words they&amp;#39;re saying due to their accent&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y5g0hh", "is_robot_indexable": true, "report_reasons": null, "author": "Impossible_Squirrel5", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y5g0hh/does_anyone_have_a_copy_of_the_how_to_win_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y5g0hh/does_anyone_have_a_copy_of_the_how_to_win_a_data/", "subreddit_subscribers": 813959, "created_utc": 1665924515.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have recently been offered a high level position at a startup that is very AI focused. They are focused on mainly defense projects (which is great for me as it is my domain). Most of their funding has come from SIBR projects. I am worried as they are not well known and reading over their website is like a buzzword bingo for AI/ML. What are some questions I should be asking before I make a decision? Thanks", "author_fullname": "t2_xihvg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some red flags for a start up", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y5yf52", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 60, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 60, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665971990.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have recently been offered a high level position at a startup that is very AI focused. They are focused on mainly defense projects (which is great for me as it is my domain). Most of their funding has come from SIBR projects. I am worried as they are not well known and reading over their website is like a buzzword bingo for AI/ML. What are some questions I should be asking before I make a decision? Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y5yf52", "is_robot_indexable": true, "report_reasons": null, "author": "elways_love_child", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y5yf52/what_are_some_red_flags_for_a_start_up/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y5yf52/what_are_some_red_flags_for_a_start_up/", "subreddit_subscribers": 813959, "created_utc": 1665971990.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_t4qvtgt7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science in 2022\u2193\u2193\u2193\u2193", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_y68bbl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "ups": 79, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 79, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/b3iGBsgpOLpzFRFivu_79yQ2XzrHT5oXe1cW-GJLCjE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666005227.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.imgur.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.imgur.com/60Vnj0X.png?sRXhOHyk", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/tUS31Q94dNKyDtKMgMN1nlJGK8-o4YVqhtzSLAB__rk.png?auto=webp&amp;s=97f6dbf8ccc61c05a297481462c17a7658335f7d", "width": 438, "height": 481}, "resolutions": [{"url": "https://external-preview.redd.it/tUS31Q94dNKyDtKMgMN1nlJGK8-o4YVqhtzSLAB__rk.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=512aad3c6dddd9dc357e649626e4d7d6764d6130", "width": 108, "height": 118}, {"url": "https://external-preview.redd.it/tUS31Q94dNKyDtKMgMN1nlJGK8-o4YVqhtzSLAB__rk.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=80ed265b8385115d67396f4b17639df240dd7dee", "width": 216, "height": 237}, {"url": "https://external-preview.redd.it/tUS31Q94dNKyDtKMgMN1nlJGK8-o4YVqhtzSLAB__rk.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=42b23af23a5031ea4ba9c17b573ef69b39b2d7e9", "width": 320, "height": 351}], "variants": {}, "id": "ZdyUde2_J7uaDi9CtM2TytYQG9xl8waPmzKneBqT_XE"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "y68bbl", "is_robot_indexable": true, "report_reasons": null, "author": "hiopacin", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y68bbl/data_science_in_2022/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.imgur.com/60Vnj0X.png?sRXhOHyk", "subreddit_subscribers": 813959, "created_utc": 1666005227.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Id assume that if you wanted to predict on certain features, youd train the model using only those - however the instructions are explicit. Is there a standard way of dealing with missing features like this? \n\nEg: features for model trained on x1, x2, x3, x4, x5\nFeatures for data to be predicted on: x1, x2, x3", "author_fullname": "t2_gm8b3iu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I have an assignment to train a model with specific features, then use it to predict on a dataset containing a subset of the features, is this normal?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y5lodf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665939210.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Id assume that if you wanted to predict on certain features, youd train the model using only those - however the instructions are explicit. Is there a standard way of dealing with missing features like this? &lt;/p&gt;\n\n&lt;p&gt;Eg: features for model trained on x1, x2, x3, x4, x5\nFeatures for data to be predicted on: x1, x2, x3&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y5lodf", "is_robot_indexable": true, "report_reasons": null, "author": "poppycocknbalderdash", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y5lodf/i_have_an_assignment_to_train_a_model_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y5lodf/i_have_an_assignment_to_train_a_model_with/", "subreddit_subscribers": 813959, "created_utc": 1665939210.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "?", "author_fullname": "t2_4xhvqofl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If you have ever experienced imposter syndrome, what's something that happened recently that made you feel like a data scientist?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y5u010", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665959678.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y5u010", "is_robot_indexable": true, "report_reasons": null, "author": "gengarvibes", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y5u010/if_you_have_ever_experienced_imposter_syndrome/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y5u010/if_you_have_ever_experienced_imposter_syndrome/", "subreddit_subscribers": 813959, "created_utc": 1665959678.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm missing something\n\nThe graph below has been used to show the increase in # of deaths in 2022.\n\nAccording to the bottom line \"Excess is calculated by subtracting deaths from the baseline (...) which is calculated as pre pandemic average of 2015-2019 adjusted for the linear trend\", so shouldn't be meaning that deaths are decreasing and not increasing?\n\nIf I take the baseline and subtract the number of deahts, and deaths are decreasing the number should increase, doesn't it?\n\nHowever, the points on the graph, are indicated as \"excess mortality: x deaths/100k\"\n\nWhat am I missing?\n\nhttps://preview.redd.it/mxkd8uwe98u91.png?width=2344&amp;format=png&amp;auto=webp&amp;s=a1c9f3df777c82e0cb429164eea867ef4e21e96f", "author_fullname": "t2_tf2wdkgw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I am missing something, can you help?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 82, "top_awarded_type": null, "hide_score": false, "media_metadata": {"mxkd8uwe98u91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 63, "x": 108, "u": "https://preview.redd.it/mxkd8uwe98u91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=46b6741bb7d7ff8de7b33cec3692aaec229e741a"}, {"y": 126, "x": 216, "u": "https://preview.redd.it/mxkd8uwe98u91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=3506915f02bde4e4754fb55903c0e3b6d9917278"}, {"y": 188, "x": 320, "u": "https://preview.redd.it/mxkd8uwe98u91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b2c0aada9923cc58b9709b40e72f88dc39f87d98"}, {"y": 376, "x": 640, "u": "https://preview.redd.it/mxkd8uwe98u91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=15c970f2dd6c1c46fb9f7b76ce56284fca34d578"}, {"y": 564, "x": 960, "u": "https://preview.redd.it/mxkd8uwe98u91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=2267478557105d11c8ba79dd9027250313656d38"}, {"y": 634, "x": 1080, "u": "https://preview.redd.it/mxkd8uwe98u91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=543f8de4ca23392a81d7fd8897a643575e9b5577"}], "s": {"y": 1378, "x": 2344, "u": "https://preview.redd.it/mxkd8uwe98u91.png?width=2344&amp;format=png&amp;auto=webp&amp;s=a1c9f3df777c82e0cb429164eea867ef4e21e96f"}, "id": "mxkd8uwe98u91"}}, "name": "t3_y5r84x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/6LirDcn9aXEImo_ytqo0fMNQkp3iwkdn4Jhn7Mavw0s.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665952696.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m missing something&lt;/p&gt;\n\n&lt;p&gt;The graph below has been used to show the increase in # of deaths in 2022.&lt;/p&gt;\n\n&lt;p&gt;According to the bottom line &amp;quot;Excess is calculated by subtracting deaths from the baseline (...) which is calculated as pre pandemic average of 2015-2019 adjusted for the linear trend&amp;quot;, so shouldn&amp;#39;t be meaning that deaths are decreasing and not increasing?&lt;/p&gt;\n\n&lt;p&gt;If I take the baseline and subtract the number of deahts, and deaths are decreasing the number should increase, doesn&amp;#39;t it?&lt;/p&gt;\n\n&lt;p&gt;However, the points on the graph, are indicated as &amp;quot;excess mortality: x deaths/100k&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;What am I missing?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/mxkd8uwe98u91.png?width=2344&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a1c9f3df777c82e0cb429164eea867ef4e21e96f\"&gt;https://preview.redd.it/mxkd8uwe98u91.png?width=2344&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a1c9f3df777c82e0cb429164eea867ef4e21e96f&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y5r84x", "is_robot_indexable": true, "report_reasons": null, "author": "Catmageddon_", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y5r84x/i_am_missing_something_can_you_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y5r84x/i_am_missing_something_can_you_help/", "subreddit_subscribers": 813959, "created_utc": 1665952696.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm trying to generate a gibberish language to use for character dialogue in a game, similar to the 'Animalese' of Animal Crossing. \n\n\nAt the moment, I am hashing the English input sentences, truncating the hash to match the input sentence length, and then mapping each hex character of the hash to an arbitrary syllable (which is associated with an audio clip). While this works well enough, I am hoping to add some realism using universal sentence embeddings, so that similar sentence meanings map to similar gibberish forms and it hopefully seems more like a real language. I need the following features:\n\n1. Sentences with similar meanings should have a similar gibberish output. For example, if the sentence 'hi there' maps to 'grebgol', the sentence 'hello!' should be likely to translate to 'grebgol' as well, or a string similar to it. \n\n2. A gibberish sentence should have approximately the same number of syllables as the input English sentence. e.g. \"Look!\" might generate \"Shleg!\" but \"This path is dangerous\" might generate \"Vnepsweg zeb sirugkijun\". \n\n\nSo far, my code is generating a sentence embedding for each input sentence using Tensorflow Universal Sentence Encoder. But I am not sure how to go about generating a gibberish string from the embedding. I suppose I need some kind of dimensionality reduction like PCA analysis to obtain a set of one dimensional vectors from my list of input sentences. Then I can map the contents of each vector arbitrarily to my syllable recordings. But then my gibberish sentences will all be the same length - this is where I'm stuck.", "author_fullname": "t2_154hkh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Generating gibberish game dialogue from universal sentence encodings", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y5yskh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665973037.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to generate a gibberish language to use for character dialogue in a game, similar to the &amp;#39;Animalese&amp;#39; of Animal Crossing. &lt;/p&gt;\n\n&lt;p&gt;At the moment, I am hashing the English input sentences, truncating the hash to match the input sentence length, and then mapping each hex character of the hash to an arbitrary syllable (which is associated with an audio clip). While this works well enough, I am hoping to add some realism using universal sentence embeddings, so that similar sentence meanings map to similar gibberish forms and it hopefully seems more like a real language. I need the following features:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Sentences with similar meanings should have a similar gibberish output. For example, if the sentence &amp;#39;hi there&amp;#39; maps to &amp;#39;grebgol&amp;#39;, the sentence &amp;#39;hello!&amp;#39; should be likely to translate to &amp;#39;grebgol&amp;#39; as well, or a string similar to it. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;A gibberish sentence should have approximately the same number of syllables as the input English sentence. e.g. &amp;quot;Look!&amp;quot; might generate &amp;quot;Shleg!&amp;quot; but &amp;quot;This path is dangerous&amp;quot; might generate &amp;quot;Vnepsweg zeb sirugkijun&amp;quot;. &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;So far, my code is generating a sentence embedding for each input sentence using Tensorflow Universal Sentence Encoder. But I am not sure how to go about generating a gibberish string from the embedding. I suppose I need some kind of dimensionality reduction like PCA analysis to obtain a set of one dimensional vectors from my list of input sentences. Then I can map the contents of each vector arbitrarily to my syllable recordings. But then my gibberish sentences will all be the same length - this is where I&amp;#39;m stuck.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y5yskh", "is_robot_indexable": true, "report_reasons": null, "author": "zl1asdfg", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y5yskh/generating_gibberish_game_dialogue_from_universal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y5yskh/generating_gibberish_game_dialogue_from_universal/", "subreddit_subscribers": 813959, "created_utc": 1665973037.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've found I generally rely on business knowledge/ metrics when solving problems at work. Which is needed, but sometimes I feel too challenged when I see a \"new\" kind of problem. I think I probably felt challenged in that manner when I was early on in my career.\n\nAre there some resources available to practise this skill?\nOne way to do this are those case studies (like the ones typically asked in consulting), but otherwise I'm at a loss as to what ways to improve this. Or maybe strategies to help break down an ambiguous problem, where / how can I practise this?", "author_fullname": "t2_1fvpf5a1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resources for practising problem solving", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y5s9ns", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665955260.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve found I generally rely on business knowledge/ metrics when solving problems at work. Which is needed, but sometimes I feel too challenged when I see a &amp;quot;new&amp;quot; kind of problem. I think I probably felt challenged in that manner when I was early on in my career.&lt;/p&gt;\n\n&lt;p&gt;Are there some resources available to practise this skill?\nOne way to do this are those case studies (like the ones typically asked in consulting), but otherwise I&amp;#39;m at a loss as to what ways to improve this. Or maybe strategies to help break down an ambiguous problem, where / how can I practise this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y5s9ns", "is_robot_indexable": true, "report_reasons": null, "author": "WillingAstronomer", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y5s9ns/resources_for_practising_problem_solving/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y5s9ns/resources_for_practising_problem_solving/", "subreddit_subscribers": 813959, "created_utc": 1665955260.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm wondering if traditional statistics/EDA/visualization really scales to \"big data\" and whether it is really useful to process an entire \"big dataset\" for EDA vs just sub-sampling.\n\nI realize of course that deep learning **DOES** scale to big data, **and I'm in no way doubting that**. I'm just asking what other data science technique **ALSO** scale to big data (e.g. billions of samples)?\n\nP.S. I'm also asking in the context of map-reduce. That design paradigm seems to imply that data-processing on that scale is useful outside of the context of Deep learning.   \nI'm wondering if I could get practical examples where that is obviously true (preferably in EDA/statistics but other examples are welcome as well).", "author_fullname": "t2_qrw52", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "EDA on \"big data\": is it sufficient to just sub-sample?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y5pi8e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665948483.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m wondering if traditional statistics/EDA/visualization really scales to &amp;quot;big data&amp;quot; and whether it is really useful to process an entire &amp;quot;big dataset&amp;quot; for EDA vs just sub-sampling.&lt;/p&gt;\n\n&lt;p&gt;I realize of course that deep learning &lt;strong&gt;DOES&lt;/strong&gt; scale to big data, &lt;strong&gt;and I&amp;#39;m in no way doubting that&lt;/strong&gt;. I&amp;#39;m just asking what other data science technique &lt;strong&gt;ALSO&lt;/strong&gt; scale to big data (e.g. billions of samples)?&lt;/p&gt;\n\n&lt;p&gt;P.S. I&amp;#39;m also asking in the context of map-reduce. That design paradigm seems to imply that data-processing on that scale is useful outside of the context of Deep learning.&lt;br/&gt;\nI&amp;#39;m wondering if I could get practical examples where that is obviously true (preferably in EDA/statistics but other examples are welcome as well).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y5pi8e", "is_robot_indexable": true, "report_reasons": null, "author": "Udon_noodles", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y5pi8e/eda_on_big_data_is_it_sufficient_to_just_subsample/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y5pi8e/eda_on_big_data_is_it_sufficient_to_just_subsample/", "subreddit_subscribers": 813959, "created_utc": 1665948483.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have given data for users which is right skewed with a long tail, meaning high gmv is driven by few users. Now I have 2 cohorts of users for whom I want to compare gmv distribution. My first instinct was to go for t-test but it has an assumption of normality.  Though I also found I  my readings that if my sample size is large enough (typically &gt; 100) central limit theorem would kick in and the difference in mean should be normally distributed so I should be able to apply t-test on my raw data. \n\nBut there is no literature on effect size calculation if my data is skewed, I am thinking of Cohen's D and since it also assumes normality, perform log normal transformation on my data and perform t test and Cohen's D on that. \n\nFrom my reading transformed t-test p value is applicable for raw data as well but not sure about Cohen's D. \n\nAny guidance on how this kind of analysis is usually done would be really helpful.", "author_fullname": "t2_6ys5mu5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Cohen's D valid for effect size on log transformed data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y5na1y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665943153.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have given data for users which is right skewed with a long tail, meaning high gmv is driven by few users. Now I have 2 cohorts of users for whom I want to compare gmv distribution. My first instinct was to go for t-test but it has an assumption of normality.  Though I also found I  my readings that if my sample size is large enough (typically &amp;gt; 100) central limit theorem would kick in and the difference in mean should be normally distributed so I should be able to apply t-test on my raw data. &lt;/p&gt;\n\n&lt;p&gt;But there is no literature on effect size calculation if my data is skewed, I am thinking of Cohen&amp;#39;s D and since it also assumes normality, perform log normal transformation on my data and perform t test and Cohen&amp;#39;s D on that. &lt;/p&gt;\n\n&lt;p&gt;From my reading transformed t-test p value is applicable for raw data as well but not sure about Cohen&amp;#39;s D. &lt;/p&gt;\n\n&lt;p&gt;Any guidance on how this kind of analysis is usually done would be really helpful.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y5na1y", "is_robot_indexable": true, "report_reasons": null, "author": "user19911506", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y5na1y/is_cohens_d_valid_for_effect_size_on_log/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y5na1y/is_cohens_d_valid_for_effect_size_on_log/", "subreddit_subscribers": 813959, "created_utc": 1665943153.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone. Working on understanding entropy and toying some R code around it. \n\nOne thing Im struggling to understand; when your using entropy to build classification models, why try and minimize entropy instead of maximizing probability? \n\nThe root of the entropy formula is inverse probability, so why minimize this instead of maximizing probability. Is it a pohtato potahto kind of thing? Does it make a difference?", "author_fullname": "t2_ix20cupc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why minimize entropy vs maximize probability when building classification models?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y5ham7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665928155.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone. Working on understanding entropy and toying some R code around it. &lt;/p&gt;\n\n&lt;p&gt;One thing Im struggling to understand; when your using entropy to build classification models, why try and minimize entropy instead of maximizing probability? &lt;/p&gt;\n\n&lt;p&gt;The root of the entropy formula is inverse probability, so why minimize this instead of maximizing probability. Is it a pohtato potahto kind of thing? Does it make a difference?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y5ham7", "is_robot_indexable": true, "report_reasons": null, "author": "crustyporuc", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y5ham7/why_minimize_entropy_vs_maximize_probability_when/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y5ham7/why_minimize_entropy_vs_maximize_probability_when/", "subreddit_subscribers": 813959, "created_utc": 1665928155.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am maintaining a page for all Kaggle Solutions here - [https://kaggle.datagyan.co.in/](https://kaggle.datagyan.co.in/)\n\nIf anyone is interested to contribute to this page(GitHub repo), do hit me up!", "author_fullname": "t2_60oji2x5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kaggle Solutions Page", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y68ntp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666006213.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am maintaining a page for all Kaggle Solutions here - &lt;a href=\"https://kaggle.datagyan.co.in/\"&gt;https://kaggle.datagyan.co.in/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If anyone is interested to contribute to this page(GitHub repo), do hit me up!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y68ntp", "is_robot_indexable": true, "report_reasons": null, "author": "rakash_ram", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y68ntp/kaggle_solutions_page/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y68ntp/kaggle_solutions_page/", "subreddit_subscribers": 813959, "created_utc": 1666006213.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In my current role (F500 but not BigN), I am a data scientist but most of my day i feel more like a backend engineer. I've implemented a small and simple model that serves a simple purpose, which took me roughly a month to complete. It took another 3 months to wrap it as a microservice not only for the product, but for other products to use if they would like to. It took a while to run the backend, understand their microservice framework, and this is my first time creating one.\n\nI understand being a good backend engineer can't hurt, and if I wanted to, it provides skills if I ever want to pivot to SWE. But I feel like there's a LOT more to learn within the data science field already but now I have to add SWE to that list as well?  \n\nOn the one hand, I understand that DS isn't just building models, cleaning data. It's using data to help the business, regardless of the tools you use. So if microservices and proper deployment gain visibility and actually 'productionize' your model, then it's just something you do.\n\nOn the other hand, my mentor told me that that's why we have many software engineers whose strength is creating microservices and making models available via API. \n\n&amp;#x200B;\n\nWould love to hear any thoughts, and if this is normal among experienced data scientists, please comment. I'm sure some newer data scientists will have their eyes opened since these skills are definitely NOT in those \"data science top 10 tools\"", "author_fullname": "t2_1o8m3t81", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to handle necessary non-DS tasks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y620tn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665982919.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my current role (F500 but not BigN), I am a data scientist but most of my day i feel more like a backend engineer. I&amp;#39;ve implemented a small and simple model that serves a simple purpose, which took me roughly a month to complete. It took another 3 months to wrap it as a microservice not only for the product, but for other products to use if they would like to. It took a while to run the backend, understand their microservice framework, and this is my first time creating one.&lt;/p&gt;\n\n&lt;p&gt;I understand being a good backend engineer can&amp;#39;t hurt, and if I wanted to, it provides skills if I ever want to pivot to SWE. But I feel like there&amp;#39;s a LOT more to learn within the data science field already but now I have to add SWE to that list as well?  &lt;/p&gt;\n\n&lt;p&gt;On the one hand, I understand that DS isn&amp;#39;t just building models, cleaning data. It&amp;#39;s using data to help the business, regardless of the tools you use. So if microservices and proper deployment gain visibility and actually &amp;#39;productionize&amp;#39; your model, then it&amp;#39;s just something you do.&lt;/p&gt;\n\n&lt;p&gt;On the other hand, my mentor told me that that&amp;#39;s why we have many software engineers whose strength is creating microservices and making models available via API. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Would love to hear any thoughts, and if this is normal among experienced data scientists, please comment. I&amp;#39;m sure some newer data scientists will have their eyes opened since these skills are definitely NOT in those &amp;quot;data science top 10 tools&amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y620tn", "is_robot_indexable": true, "report_reasons": null, "author": "Sprayquaza98", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y620tn/how_to_handle_necessary_nonds_tasks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y620tn/how_to_handle_necessary_nonds_tasks/", "subreddit_subscribers": 813959, "created_utc": 1665982919.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nWelcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\n\n* Learning resources (e.g. books, tutorials, videos)\n* Traditional education (e.g. schools, degrees, electives)\n* Alternative education (e.g. online courses, bootcamps)\n* Job search questions (e.g. resumes, applying, career prospects)\n* Elementary questions (e.g. where to start, what next)\n\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weekly Entering &amp; Transitioning - Thread 17 Oct, 2022 - 24 Oct, 2022", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y60vf8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665979270.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;\n&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;\n&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;\n&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;\n&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=\"https://www.reddit.com/r/datascience/wiki/frequently-asked-questions\"&gt;FAQ&lt;/a&gt; and Resources pages on our wiki. You can also search for answers in &lt;a href=\"https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new\"&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "new", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y60vf8", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 3, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y60vf8/weekly_entering_transitioning_thread_17_oct_2022/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/datascience/comments/y60vf8/weekly_entering_transitioning_thread_17_oct_2022/", "subreddit_subscribers": 813959, "created_utc": 1665979270.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Good afternoon, \n\nI am curious what others do for freelance work/projects related to data. I am currently versed in Excel, SQL &amp; Tableau and I am looking to put these skills to work in order to make some extra cash. Any and all ideas are greatly appreciated. \n\nThanks in advance!", "author_fullname": "t2_9kxnux7x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Freelance Work", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y5wabn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665965864.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Good afternoon, &lt;/p&gt;\n\n&lt;p&gt;I am curious what others do for freelance work/projects related to data. I am currently versed in Excel, SQL &amp;amp; Tableau and I am looking to put these skills to work in order to make some extra cash. Any and all ideas are greatly appreciated. &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y5wabn", "is_robot_indexable": true, "report_reasons": null, "author": "FuelYourEpic", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y5wabn/data_freelance_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y5wabn/data_freelance_work/", "subreddit_subscribers": 813959, "created_utc": 1665965864.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I know it was probably discussed here a lot but I just wanted to see a sample of all the working people in here - How does your everyday work look like? What do you actually do? What languages you use?\n\nFor me - Junior, working in a fintech startup. Doing pure ML - from preprocessing to modeling. No Data Analysis and no SQL, 100% Python.", "author_fullname": "t2_3hqmko1r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Scientists here - what are your everyday tasks in your job? How does it look like?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y6884v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666004948.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know it was probably discussed here a lot but I just wanted to see a sample of all the working people in here - How does your everyday work look like? What do you actually do? What languages you use?&lt;/p&gt;\n\n&lt;p&gt;For me - Junior, working in a fintech startup. Doing pure ML - from preprocessing to modeling. No Data Analysis and no SQL, 100% Python.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y6884v", "is_robot_indexable": true, "report_reasons": null, "author": "nuriel8833", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y6884v/data_scientists_here_what_are_your_everyday_tasks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y6884v/data_scientists_here_what_are_your_everyday_tasks/", "subreddit_subscribers": 813959, "created_utc": 1666004948.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey Geeks,\n\nI started my career inData Science in year 2019. At that time, there were very less resources to learn SQL for FAANG companies as well as the demand of SQL wasn't much. Now in 2022, the demand of SQL is most. In Every Data filed you can find a SQL is most important. \n\n&amp;#x200B;\n\nIf you are planning to learn SQL  then here is list.\n\n&amp;#x200B;\n\nFacebook Interview Question: [https://www.youtube.com/watch?v=JxV\\_JCQPcU4&amp;t=439s](https://www.youtube.com/watch?v=JxV_JCQPcU4&amp;t=439s)\n\n&amp;#x200B;\n\nAmazon Interview Question: [https://www.youtube.com/watch?v=YPkIezvvt9c](https://www.youtube.com/watch?v=YPkIezvvt9c)\n\n&amp;#x200B;\n\nAdobe  Interview Question: [https://www.youtube.com/watch?v=UEMRLDJRv00](https://www.youtube.com/watch?v=UEMRLDJRv00)", "author_fullname": "t2_otfpcw97", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL for FAANG", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y68674", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666004774.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Geeks,&lt;/p&gt;\n\n&lt;p&gt;I started my career inData Science in year 2019. At that time, there were very less resources to learn SQL for FAANG companies as well as the demand of SQL wasn&amp;#39;t much. Now in 2022, the demand of SQL is most. In Every Data filed you can find a SQL is most important. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If you are planning to learn SQL  then here is list.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Facebook Interview Question: &lt;a href=\"https://www.youtube.com/watch?v=JxV_JCQPcU4&amp;amp;t=439s\"&gt;https://www.youtube.com/watch?v=JxV_JCQPcU4&amp;amp;t=439s&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Amazon Interview Question: &lt;a href=\"https://www.youtube.com/watch?v=YPkIezvvt9c\"&gt;https://www.youtube.com/watch?v=YPkIezvvt9c&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Adobe  Interview Question: &lt;a href=\"https://www.youtube.com/watch?v=UEMRLDJRv00\"&gt;https://www.youtube.com/watch?v=UEMRLDJRv00&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6p4rEbAiM_ICv--pkmPGLoc1LVLmuoo3CBNrFia9BVU.jpg?auto=webp&amp;s=9c6856c27df690da98b6a00b360db7b02892a8b2", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/6p4rEbAiM_ICv--pkmPGLoc1LVLmuoo3CBNrFia9BVU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7a066718a919a3c2b0662c1378edd316ea5189fd", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/6p4rEbAiM_ICv--pkmPGLoc1LVLmuoo3CBNrFia9BVU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f4703aab2fb0a0ebc576b1baa2bfda1aeb8382f2", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/6p4rEbAiM_ICv--pkmPGLoc1LVLmuoo3CBNrFia9BVU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bd43d987fee671af312f5aec17faa9ad6702beb1", "width": 320, "height": 240}], "variants": {}, "id": "FicxSxIjUI0n5lFVigsSLKvFVgUcygFRyjknqo6V_TE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y68674", "is_robot_indexable": true, "report_reasons": null, "author": "shivan118", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y68674/sql_for_faang/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y68674/sql_for_faang/", "subreddit_subscribers": 813959, "created_utc": 1666004774.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "same as title", "author_fullname": "t2_bsfosv4r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Blogs/websites related to Data Science /ML/DL to read?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y61d4n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665980785.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;same as title&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y61d4n", "is_robot_indexable": true, "report_reasons": null, "author": "Adventurous-Grab-20", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y61d4n/best_blogswebsites_related_to_data_science_mldl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y61d4n/best_blogswebsites_related_to_data_science_mldl/", "subreddit_subscribers": 813959, "created_utc": 1665980785.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been trying to search for notebooks where people have used ML on kaggle datasets from the self-driving industry.", "author_fullname": "t2_13t60b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kaggle example notebooks from the self-driving /automotive industry?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y5t4d9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665957395.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been trying to search for notebooks where people have used ML on kaggle datasets from the self-driving industry.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y5t4d9", "is_robot_indexable": true, "report_reasons": null, "author": "drugsarebadmky", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y5t4d9/kaggle_example_notebooks_from_the_selfdriving/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y5t4d9/kaggle_example_notebooks_from_the_selfdriving/", "subreddit_subscribers": 813959, "created_utc": 1665957395.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Q]: Can one apply multiple linear regression to the means of simulations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y5oykw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_28xoyq0t", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "statistics", "selftext": "My problem is sort of hard to explain so I used code to demonstrate. I am simulating different temporal sampling methods from time series data. From this I am looking to see how the sampled data can be used to estimate the annual total from 30-minute data. See this example using R:\n\nExample data:\n\n`set.seed(123)`\n\n`df = bind_rows(tibble(date =seq(as.POSIXct(\"2022-01-01\", tz = \"UTC\"),as.POSIXct(\"2022-12-31\", tz = \"UTC\"),by = \"30 min\"), val=rnorm((17473))%&gt;% cumsum(.), group = \"North\",a = 56, b=96, c=0.68), tibble(date =seq(as.POSIXct(\"2022-01-01\", tz = \"UTC\"),as.POSIXct(\"2022-12-31\", tz = \"UTC\"),by = \"30 min\"), val=rnorm((17473))%&gt;% cumsum(.), group = \"East\",a = 85, b=46, c=0.25), tibble(date =seq(as.POSIXct(\"2022-01-01\", tz = \"UTC\"),as.POSIXct(\"2022-12-31\", tz = \"UTC\"),by = \"30 min\"), val=rnorm((17473))%&gt;% cumsum(.), group = \"South\",a = 60, b=100, c=0.99)) %&gt;% mutate(val = abs(val))`\n\nI calculate the annual sum:\n\n`df_totals= df %&gt;% group_by(group) %&gt;% summarise(annual_amount = mean(val)*(48*365))`\n\nThe loop looks something like this:\n\n`for(j in unique(df$group)){`  \n`df_sub &lt;- df %&gt;% filter(group == j)`  \n`qe &lt;- NULL`  \n`me &lt;- NULL`  \n`we &lt;- NULL`  \n`print(j)`  \n`for(k in 1:25){`  \n`print(k)`  \n`qtemp=tibble()`  \n`for(i in unique(quarters(df_sub$date))){`  \n`q &lt;- df_sub[sample(which(quarters(df_sub$date) == i),1,replace = T),]`  \n`qtemp &lt;- bind_rows(qtemp,q)`  \n`print(\"Quarter Data Report\")`  \n`}`  \n`qe[k] = mean(qtemp$val)*17520`  \n`mtemp=tibble()`  \n`for(i in unique(format(df_sub$date,\"%m\"))){`  \n`m &lt;- df_sub[sample(which(format(df_sub$date,\"%m\") == i),1,replace = T),]`  \n`mtemp &lt;- bind_rows(mtemp,m)`  \n`print(\"Monthly Data Report\")`  \n`}`  \n`me[k] = mean(mtemp$val)*17520`  \n`wtemp=tibble()`  \n`for(i in unique(format(df_sub$date,\"%U\"))){`  \n`w &lt;- df_sub[sample(which(format(df_sub$date,\"%U\") == i),1,replace = T),]`  \n`wtemp &lt;- bind_rows(wtemp,w)`  \n`print(\"Weekly Data Report\")`  \n`}`  \n`we[k] = mean(wtemp$val)*17520`  \n`}`  \n`qe_all = qe_all %&gt;% bind_rows(tibble(est = qe, sample = \"Quarterly\", group =unique(qtemp$group), a = unique(qtemp$a), b = unique(qtemp$b), c = unique(qtemp$c)))`   \n`me_all = me_all %&gt;% bind_rows(tibble(est = me, sample = \"Monthly\", group = unique(mtemp$group), a = unique(mtemp$a), b = unique(mtemp$b), c = unique(mtemp$c)))`   \n`we_all = we_all %&gt;% bind_rows(tibble(est = we, sample = \"Weekly\", group = unique(wtemp$group), a = unique(wtemp$a), b = unique(wtemp$b), c = unique(wtemp$c))) rm(qe,me,we)`  \n`}`\n\n`ests &lt;- ests %&gt;% bind_rows(qe_all, me_all, we_all) %&gt;% left_join(df_totals, by = \"group\") %&gt;% mutate(error = est/annual_amount)`\n\nIn reality the error is much more variable between group and a, b, c.\n\nI am trying to understand how the independent variables a, b, and c affect the dependent variable error for each digital simulated sampling method (Quarterly, Monthly, Weekly). So, there will be 3 regression models. Where y is error, with predictors a, b, and c. In my real data, I am simulating 1000+ times. It doesn't seem correct to use 1000+ observations of y. But what if I took the mean of y (error) for each group (North, East, and South).\n\nHere are my questions, for which I would be grateful to get feedback:\n\n* Is multiple linear regression the best approach here?\n* Would a machine learning method be better, such as random forest?\n* For each regression model, is it reasonable to take the mean error for each group and use the mean error as the dependent variable?\n* Is it an issue for dependent variable to be a percentage in the regression (it's not necessarily constrained between 0 and 1)?\n\nIf I were to use the means, data would look like this, and three regression models would be fit by sample:\n\n`ests %&gt;% group_by(sample, group) %&gt;% summarise(a = unique(a), b = unique(b), c = unique(c), error = mean(error))`\n\nApologies for a long-winded question!", "author_fullname": "t2_28xoyq0t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Q]: Can one apply multiple linear regression to the means of simulations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/statistics", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4apku", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1665798178.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665796362.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.statistics", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My problem is sort of hard to explain so I used code to demonstrate. I am simulating different temporal sampling methods from time series data. From this I am looking to see how the sampled data can be used to estimate the annual total from 30-minute data. See this example using R:&lt;/p&gt;\n\n&lt;p&gt;Example data:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;set.seed(123)&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;df = bind_rows(tibble(date =seq(as.POSIXct(&amp;quot;2022-01-01&amp;quot;, tz = &amp;quot;UTC&amp;quot;),as.POSIXct(&amp;quot;2022-12-31&amp;quot;, tz = &amp;quot;UTC&amp;quot;),by = &amp;quot;30 min&amp;quot;), val=rnorm((17473))%&amp;gt;% cumsum(.), group = &amp;quot;North&amp;quot;,a = 56, b=96, c=0.68), tibble(date =seq(as.POSIXct(&amp;quot;2022-01-01&amp;quot;, tz = &amp;quot;UTC&amp;quot;),as.POSIXct(&amp;quot;2022-12-31&amp;quot;, tz = &amp;quot;UTC&amp;quot;),by = &amp;quot;30 min&amp;quot;), val=rnorm((17473))%&amp;gt;% cumsum(.), group = &amp;quot;East&amp;quot;,a = 85, b=46, c=0.25), tibble(date =seq(as.POSIXct(&amp;quot;2022-01-01&amp;quot;, tz = &amp;quot;UTC&amp;quot;),as.POSIXct(&amp;quot;2022-12-31&amp;quot;, tz = &amp;quot;UTC&amp;quot;),by = &amp;quot;30 min&amp;quot;), val=rnorm((17473))%&amp;gt;% cumsum(.), group = &amp;quot;South&amp;quot;,a = 60, b=100, c=0.99)) %&amp;gt;% mutate(val = abs(val))&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;I calculate the annual sum:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;df_totals= df %&amp;gt;% group_by(group) %&amp;gt;% summarise(annual_amount = mean(val)*(48*365))&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;The loop looks something like this:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;for(j in unique(df$group)){&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;df_sub &amp;lt;- df %&amp;gt;% filter(group == j)&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;qe &amp;lt;- NULL&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;me &amp;lt;- NULL&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;we &amp;lt;- NULL&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;print(j)&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;for(k in 1:25){&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;print(k)&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;qtemp=tibble()&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;for(i in unique(quarters(df_sub$date))){&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;q &amp;lt;- df_sub[sample(which(quarters(df_sub$date) == i),1,replace = T),]&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;qtemp &amp;lt;- bind_rows(qtemp,q)&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;print(&amp;quot;Quarter Data Report&amp;quot;)&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;}&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;qe[k] = mean(qtemp$val)*17520&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;mtemp=tibble()&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;for(i in unique(format(df_sub$date,&amp;quot;%m&amp;quot;))){&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;m &amp;lt;- df_sub[sample(which(format(df_sub$date,&amp;quot;%m&amp;quot;) == i),1,replace = T),]&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;mtemp &amp;lt;- bind_rows(mtemp,m)&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;print(&amp;quot;Monthly Data Report&amp;quot;)&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;}&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;me[k] = mean(mtemp$val)*17520&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;wtemp=tibble()&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;for(i in unique(format(df_sub$date,&amp;quot;%U&amp;quot;))){&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;w &amp;lt;- df_sub[sample(which(format(df_sub$date,&amp;quot;%U&amp;quot;) == i),1,replace = T),]&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;wtemp &amp;lt;- bind_rows(wtemp,w)&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;print(&amp;quot;Weekly Data Report&amp;quot;)&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;}&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;we[k] = mean(wtemp$val)*17520&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;}&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;qe_all = qe_all %&amp;gt;% bind_rows(tibble(est = qe, sample = &amp;quot;Quarterly&amp;quot;, group =unique(qtemp$group), a = unique(qtemp$a), b = unique(qtemp$b), c = unique(qtemp$c)))&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;me_all = me_all %&amp;gt;% bind_rows(tibble(est = me, sample = &amp;quot;Monthly&amp;quot;, group = unique(mtemp$group), a = unique(mtemp$a), b = unique(mtemp$b), c = unique(mtemp$c)))&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;we_all = we_all %&amp;gt;% bind_rows(tibble(est = we, sample = &amp;quot;Weekly&amp;quot;, group = unique(wtemp$group), a = unique(wtemp$a), b = unique(wtemp$b), c = unique(wtemp$c))) rm(qe,me,we)&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;}&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;ests &amp;lt;- ests %&amp;gt;% bind_rows(qe_all, me_all, we_all) %&amp;gt;% left_join(df_totals, by = &amp;quot;group&amp;quot;) %&amp;gt;% mutate(error = est/annual_amount)&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;In reality the error is much more variable between group and a, b, c.&lt;/p&gt;\n\n&lt;p&gt;I am trying to understand how the independent variables a, b, and c affect the dependent variable error for each digital simulated sampling method (Quarterly, Monthly, Weekly). So, there will be 3 regression models. Where y is error, with predictors a, b, and c. In my real data, I am simulating 1000+ times. It doesn&amp;#39;t seem correct to use 1000+ observations of y. But what if I took the mean of y (error) for each group (North, East, and South).&lt;/p&gt;\n\n&lt;p&gt;Here are my questions, for which I would be grateful to get feedback:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Is multiple linear regression the best approach here?&lt;/li&gt;\n&lt;li&gt;Would a machine learning method be better, such as random forest?&lt;/li&gt;\n&lt;li&gt;For each regression model, is it reasonable to take the mean error for each group and use the mean error as the dependent variable?&lt;/li&gt;\n&lt;li&gt;Is it an issue for dependent variable to be a percentage in the regression (it&amp;#39;s not necessarily constrained between 0 and 1)?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If I were to use the means, data would look like this, and three regression models would be fit by sample:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;ests %&amp;gt;% group_by(sample, group) %&amp;gt;% summarise(a = unique(a), b = unique(b), c = unique(c), error = mean(error))&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;Apologies for a long-winded question!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qhfi", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4apku", "is_robot_indexable": true, "report_reasons": null, "author": "squishytea", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/statistics/comments/y4apku/q_can_one_apply_multiple_linear_regression_to_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/statistics/comments/y4apku/q_can_one_apply_multiple_linear_regression_to_the/", "subreddit_subscribers": 521895, "created_utc": 1665796362.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1665947169.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.statistics", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/statistics/comments/y4apku/q_can_one_apply_multiple_linear_regression_to_the/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y5oykw", "is_robot_indexable": true, "report_reasons": null, "author": "squishytea", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_y4apku", "author_flair_text_color": null, "permalink": "/r/datascience/comments/y5oykw/q_can_one_apply_multiple_linear_regression_to_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/statistics/comments/y4apku/q_can_one_apply_multiple_linear_regression_to_the/", "subreddit_subscribers": 813959, "created_utc": 1665947169.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_b2pq7g9m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm looking for a data analyst job. Can you help me with what projects/exp should I mention in the resume as a fresher.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_y68tjd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.22, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/3_CKf-H8fk5m8Abz4vFsoWRQ0BrbLPNJfOXkza_6Nfw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666006648.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/2qq3y0hlrcu91.jpg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/2qq3y0hlrcu91.jpg?auto=webp&amp;s=c7355edd1e8041d95a153efc54392b8ef963b0f6", "width": 1080, "height": 1920}, "resolutions": [{"url": "https://preview.redd.it/2qq3y0hlrcu91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1e54781e836db7e697aac353e7f71bbc30b9198d", "width": 108, "height": 192}, {"url": "https://preview.redd.it/2qq3y0hlrcu91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=dbe0c8fd27b7d2568b914bb064253a11d90df5d1", "width": 216, "height": 384}, {"url": "https://preview.redd.it/2qq3y0hlrcu91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8a5166b3c5631d4687e11019a2f2121befc4fe34", "width": 320, "height": 568}, {"url": "https://preview.redd.it/2qq3y0hlrcu91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c9d36937f6a0b3285f294068f3478f72d25fe2a9", "width": 640, "height": 1137}, {"url": "https://preview.redd.it/2qq3y0hlrcu91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2e79e52ad81b2f546fb749d67937942ced97e0e3", "width": 960, "height": 1706}, {"url": "https://preview.redd.it/2qq3y0hlrcu91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=91275ddd5acb5108841162719221c844e70389a8", "width": 1080, "height": 1920}], "variants": {}, "id": "A3ZsOeohTOBPCfJnGBuFPQgkxKurgp0NekjStukJ9Cw"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "y68tjd", "is_robot_indexable": true, "report_reasons": null, "author": "lordRiddle99", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y68tjd/im_looking_for_a_data_analyst_job_can_you_help_me/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/2qq3y0hlrcu91.jpg", "subreddit_subscribers": 813959, "created_utc": 1666006648.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am going to start uni next year in March and I'm looking to major in finance however I want a second major in data science or statistics. I was wondering whether this would be a good combination for someone looking to find a career in data driven finance markets. Moreover, I would be on scholarship and I don't want to lose my scholarship with bad grades (International student fees are exp). I have no background in computer science (Businees subject O and A'levels with mathematics) so is it easy for a beginner to pick up on data science concepts without grades falling off too much?", "author_fullname": "t2_43lltel8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is data science a good major to pair with finance for my bachelors degree?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y67zx3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666004257.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am going to start uni next year in March and I&amp;#39;m looking to major in finance however I want a second major in data science or statistics. I was wondering whether this would be a good combination for someone looking to find a career in data driven finance markets. Moreover, I would be on scholarship and I don&amp;#39;t want to lose my scholarship with bad grades (International student fees are exp). I have no background in computer science (Businees subject O and A&amp;#39;levels with mathematics) so is it easy for a beginner to pick up on data science concepts without grades falling off too much?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y67zx3", "is_robot_indexable": true, "report_reasons": null, "author": "Mareehaaa", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y67zx3/is_data_science_a_good_major_to_pair_with_finance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y67zx3/is_data_science_a_good_major_to_pair_with_finance/", "subreddit_subscribers": 813959, "created_utc": 1666004257.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,  \nI have two tables :  \n\n\n**User** : ID, Creation\\_Date, Email   \n**API\\_Calls** : ID, Creation\\_Date, User (foreign key), type  \n\n\nI want to be able to construct a user retention table :  \n**User\\_Retention** : Week\\_0, Week\\_1, Week\\_2, Week\\_3   \nThat gives the info of how many users make API Calls (of type==B) :  \nWeek\\_0 = the first week they register \n\nWeek\\_1 = the second week after they register\n\nWeek\\_2 = the third week after they register  \n\n\nWe can compare API\\_Calls.Creation\\_Date and User.Creation\\_Date to see when the call was made with respect to the user account creation.\n\nI'm on Postgres.\n\nAnyone could hep? Thank you very much !:)", "author_fullname": "t2_s0rec", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Complicated User Retention Query", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y61jfh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665981364.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;br/&gt;\nI have two tables :  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;User&lt;/strong&gt; : ID, Creation_Date, Email&lt;br/&gt;\n&lt;strong&gt;API_Calls&lt;/strong&gt; : ID, Creation_Date, User (foreign key), type  &lt;/p&gt;\n\n&lt;p&gt;I want to be able to construct a user retention table :&lt;br/&gt;\n&lt;strong&gt;User_Retention&lt;/strong&gt; : Week_0, Week_1, Week_2, Week_3&lt;br/&gt;\nThat gives the info of how many users make API Calls (of type==B) :&lt;br/&gt;\nWeek_0 = the first week they register &lt;/p&gt;\n\n&lt;p&gt;Week_1 = the second week after they register&lt;/p&gt;\n\n&lt;p&gt;Week_2 = the third week after they register  &lt;/p&gt;\n\n&lt;p&gt;We can compare API_Calls.Creation_Date and User.Creation_Date to see when the call was made with respect to the user account creation.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m on Postgres.&lt;/p&gt;\n\n&lt;p&gt;Anyone could hep? Thank you very much !:)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y61jfh", "is_robot_indexable": true, "report_reasons": null, "author": "swentso", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y61jfh/complicated_user_retention_query/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y61jfh/complicated_user_retention_query/", "subreddit_subscribers": 813959, "created_utc": 1665981364.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I got an interview be a software engineer II at a non-profit. I'm posting in this subreddit because a) I trust this community more than r/cscareerquestions and b)  the role is about developing pipelines to process and analyze neuroimaging data, so it's related to data science.\n\nHere are some relevant details about me:\n\n* I have one year of experience processing and analyzing neuroimaging data in a lab\n* I taught myself python, R, frequentist and Bayesian statistics, and implement new computer vision research for my job\n* I lead a group of PhD students to implement (and improve on) image segmentation algorithms\n* I'm published\n* I have a graduate certificate in neuroscience\n* I have two bachelor degrees in philosophy and English respectively (although I've completed math up to and including differential equations)\n\nHere are some relevant details about the position given my research:\n\n* Given my years of experience, Base pay for a software engineer II at this non-profit is $109,765\n* Base pay for a software engineer in the area is $121,987\n* Cost of living is $44,557\n* I have no idea if they're offering bonuses, stock-options, or profit sharing\n\nThe recruiter/hiring manager wants me to name a salary. I haven't even started the first round of interviews yet.\n\nI don't care how much I'm payed so long as I get my foot in the door. However, I worry that if I value myself too little that they'll be turned off.\n\nHow much should I suggest? I'm thinking 75k to 100k with the caveat that I'm open to negotiation.\n\nAlso, is it a bad sign that they're asking me to name a salary?", "author_fullname": "t2_2ve4vyvh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interviewing to be a software engineer II; they're asking me to list a salary; what salary should I name?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y5ydbx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1665974001.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665971838.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got an interview be a software engineer II at a non-profit. I&amp;#39;m posting in this subreddit because a) I trust this community more than &lt;a href=\"/r/cscareerquestions\"&gt;r/cscareerquestions&lt;/a&gt; and b)  the role is about developing pipelines to process and analyze neuroimaging data, so it&amp;#39;s related to data science.&lt;/p&gt;\n\n&lt;p&gt;Here are some relevant details about me:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I have one year of experience processing and analyzing neuroimaging data in a lab&lt;/li&gt;\n&lt;li&gt;I taught myself python, R, frequentist and Bayesian statistics, and implement new computer vision research for my job&lt;/li&gt;\n&lt;li&gt;I lead a group of PhD students to implement (and improve on) image segmentation algorithms&lt;/li&gt;\n&lt;li&gt;I&amp;#39;m published&lt;/li&gt;\n&lt;li&gt;I have a graduate certificate in neuroscience&lt;/li&gt;\n&lt;li&gt;I have two bachelor degrees in philosophy and English respectively (although I&amp;#39;ve completed math up to and including differential equations)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Here are some relevant details about the position given my research:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Given my years of experience, Base pay for a software engineer II at this non-profit is $109,765&lt;/li&gt;\n&lt;li&gt;Base pay for a software engineer in the area is $121,987&lt;/li&gt;\n&lt;li&gt;Cost of living is $44,557&lt;/li&gt;\n&lt;li&gt;I have no idea if they&amp;#39;re offering bonuses, stock-options, or profit sharing&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The recruiter/hiring manager wants me to name a salary. I haven&amp;#39;t even started the first round of interviews yet.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t care how much I&amp;#39;m payed so long as I get my foot in the door. However, I worry that if I value myself too little that they&amp;#39;ll be turned off.&lt;/p&gt;\n\n&lt;p&gt;How much should I suggest? I&amp;#39;m thinking 75k to 100k with the caveat that I&amp;#39;m open to negotiation.&lt;/p&gt;\n\n&lt;p&gt;Also, is it a bad sign that they&amp;#39;re asking me to name a salary?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y5ydbx", "is_robot_indexable": true, "report_reasons": null, "author": "statius9", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y5ydbx/interviewing_to_be_a_software_engineer_ii_theyre/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y5ydbx/interviewing_to_be_a_software_engineer_ii_theyre/", "subreddit_subscribers": 813959, "created_utc": 1665971838.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}