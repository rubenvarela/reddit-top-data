{"kind": "Listing", "data": {"after": null, "dist": 14, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I hear many cases of Snowflake and Azure Synapse serving as several company's main data warehousing platform, but interestingly I haven't heard much on Databricks serving as the central data warehouse platform even though Databricks themselves claim you can certainly do so. \n\nHas anyone been in a situation where you've built or come across data warehouses with Databricks used primarily?", "author_fullname": "t2_2eu7s20g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone built a data warehouse primarily using Databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y5n0oj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 76, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 76, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665942512.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I hear many cases of Snowflake and Azure Synapse serving as several company&amp;#39;s main data warehousing platform, but interestingly I haven&amp;#39;t heard much on Databricks serving as the central data warehouse platform even though Databricks themselves claim you can certainly do so. &lt;/p&gt;\n\n&lt;p&gt;Has anyone been in a situation where you&amp;#39;ve built or come across data warehouses with Databricks used primarily?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y5n0oj", "is_robot_indexable": true, "report_reasons": null, "author": "No_Stick_8227", "discussion_type": null, "num_comments": 57, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y5n0oj/has_anyone_built_a_data_warehouse_primarily_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y5n0oj/has_anyone_built_a_data_warehouse_primarily_using/", "subreddit_subscribers": 76689, "created_utc": 1665942512.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_dfcot0zg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "These two reference books are my Data Warehousing \"bibles\". The Kimball book is a little dated because it only deals with relational data but the concepts are still relevant.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_y5qf09", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/4Cw5x_WsSkHxjhxeL9rVULrE34WEKLCo5M4cCqtzihY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1665950738.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/gjvx1ehc58u91.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/gjvx1ehc58u91.png?auto=webp&amp;s=1f6bc8c87d650fc1c97e47a06cbb7d8582434626", "width": 1080, "height": 608}, "resolutions": [{"url": "https://preview.redd.it/gjvx1ehc58u91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7c9bb09a7cddd17f4f8be64878d8725d32c92919", "width": 108, "height": 60}, {"url": "https://preview.redd.it/gjvx1ehc58u91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=285e629db347cc5a24a6ac55d6f6a6fcf1b297da", "width": 216, "height": 121}, {"url": "https://preview.redd.it/gjvx1ehc58u91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3efcda85343b64293400f4db2fdd284115c0600f", "width": 320, "height": 180}, {"url": "https://preview.redd.it/gjvx1ehc58u91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c181b4f788fd031cdf8f5152db2d12c0238abf80", "width": 640, "height": 360}, {"url": "https://preview.redd.it/gjvx1ehc58u91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=c22e5e4fc6f4323d1217485d416486b7a81ac3f5", "width": 960, "height": 540}, {"url": "https://preview.redd.it/gjvx1ehc58u91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=469a83ffc82bef1c3c2e83b94fe2a28333816a4d", "width": 1080, "height": 608}], "variants": {}, "id": "YHZ1IyVjNmnpyo_z7Yzi0_QR3Zoq1csfNIYyOYDOQ7o"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y5qf09", "is_robot_indexable": true, "report_reasons": null, "author": "DrRedmondNYC", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y5qf09/these_two_reference_books_are_my_data_warehousing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/gjvx1ehc58u91.png", "subreddit_subscribers": 76689, "created_utc": 1665950738.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_xf2t5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The 5-minute guide to using bucketing in Pyspark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_y5x551", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/kCV2IzWOncPSVsJxFZzkRqwLtbDbErLtLXcOo2-30YI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1665968293.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "luminousmen.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://luminousmen.com/post/the-5-minute-guide-to-using-bucketing-in-pyspark", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XSax_FxC36ok7-BEbHN9NrKnV6NlhieX5B6UFGa5RLQ.jpg?auto=webp&amp;s=e723409d54320773d2ee29ca4ebe9df4beaf8587", "width": 800, "height": 405}, "resolutions": [{"url": "https://external-preview.redd.it/XSax_FxC36ok7-BEbHN9NrKnV6NlhieX5B6UFGa5RLQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=075d846cd132c55db8b6fa73f38320cc61cea070", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/XSax_FxC36ok7-BEbHN9NrKnV6NlhieX5B6UFGa5RLQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=498fa0006518f9959a0a8887126414c16ec44df7", "width": 216, "height": 109}, {"url": "https://external-preview.redd.it/XSax_FxC36ok7-BEbHN9NrKnV6NlhieX5B6UFGa5RLQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c0e9d408378d31d164939f000dc68ea25cbf56e4", "width": 320, "height": 162}, {"url": "https://external-preview.redd.it/XSax_FxC36ok7-BEbHN9NrKnV6NlhieX5B6UFGa5RLQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=32d892adf18fd5dc5f0b36de4aea3c7b07da27b0", "width": 640, "height": 324}], "variants": {}, "id": "a54OnAOZvO5ntK_LEjLuoqJJ9aGHpr0JxLCEvzu3Yzs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "y5x551", "is_robot_indexable": true, "report_reasons": null, "author": "luminoumen", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y5x551/the_5minute_guide_to_using_bucketing_in_pyspark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://luminousmen.com/post/the-5-minute-guide-to-using-bucketing-in-pyspark", "subreddit_subscribers": 76689, "created_utc": 1665968293.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Inspired by the discussion on [OOP patterns](https://www.reddit.com/r/dataengineering/comments/y5bhzg/when_to_use_object_oriented_programming_in_de/), I started thinking about how I came to structure my projects and how others do it.\n\nKeeping in mind that I'm using Dagster as the orchestrator, though I've used very similar patterns with Airflow in the past, here's the rough structure:\n\n    data-platorm/\n    \u251c\u2500 utils/\n    \u2502  \u251c\u2500 utils/\n    \u2502  \u2502  \u251c\u2500 lib/\n    \u2502  \u2502  |  \u251c\u2500 sources/\n    \u2502  \u2502  |  \u251c\u2500 sinks/\n    \u2502  \u2502  \u251c\u2500 helpers/\n    \u2502  \u251c\u2500 utils_tests/\n    \u251c\u2500 &lt;project&gt;/\n    \u2502  \u251c\u2500 &lt;project&gt;/\n    \u2502  |  \u251c\u2500 assets/\n    \u2502  |  \u251c\u2500 lib/\n    \u2502  \u251c\u2500 &lt;project&gt;_tests/\n\nUtils contains almost all logic for sources and sinks, resources, and IO Managers (dagster-specific), as they're often relevant for more than one project, as well as some helper generator functions. A typical file in the `utils` module would look something like:\n\n    @resource\n    def gmail_resource(init_context):\n        return GMail(init_context.resource_config)\n    \n    \n    @op\n    def fetch_from_gmail(context) -&gt; GMailDagsterOutput:\n        return context.resources.gmail_resource.fetch(context.op_config)\n    \n    \n    class GMail(BaseGoogleAPI):\n        def __init__(self, **kwargs):\n            super().__init__(**kwargs)\n    \n        def fetch(self, **kwargs) -&gt; GMailDagsterOutput:\n            pass\n\nInside of each project, the `lib/` folder is used for transformations specific to that project, while a typical asset (pipeline) inside of a project would look something like:\n\n    @asset\n    def my_asset():\n        source_data = fetch_from_gmail()\n        return process_my_asset(source_data)\n    \n\nThis pattern effectively means a single utilities library keeps everything abstracted and can be used by any other projects that come up, ensures a common interface is available and reduces the amount of code we're writing for each new pipeline (in fact, a lot of them can just be changes to YAML configs). If very specific one-off computations are required, we can still import the source class and use or extend it as we want. Having seen a few different patterns in the past, I wonder which others are there, benefits and downsides.", "author_fullname": "t2_681y9mz2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you structure your DE projects?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y5pm4z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665948756.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Inspired by the discussion on &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/y5bhzg/when_to_use_object_oriented_programming_in_de/\"&gt;OOP patterns&lt;/a&gt;, I started thinking about how I came to structure my projects and how others do it.&lt;/p&gt;\n\n&lt;p&gt;Keeping in mind that I&amp;#39;m using Dagster as the orchestrator, though I&amp;#39;ve used very similar patterns with Airflow in the past, here&amp;#39;s the rough structure:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;data-platorm/\n\u251c\u2500 utils/\n\u2502  \u251c\u2500 utils/\n\u2502  \u2502  \u251c\u2500 lib/\n\u2502  \u2502  |  \u251c\u2500 sources/\n\u2502  \u2502  |  \u251c\u2500 sinks/\n\u2502  \u2502  \u251c\u2500 helpers/\n\u2502  \u251c\u2500 utils_tests/\n\u251c\u2500 &amp;lt;project&amp;gt;/\n\u2502  \u251c\u2500 &amp;lt;project&amp;gt;/\n\u2502  |  \u251c\u2500 assets/\n\u2502  |  \u251c\u2500 lib/\n\u2502  \u251c\u2500 &amp;lt;project&amp;gt;_tests/\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Utils contains almost all logic for sources and sinks, resources, and IO Managers (dagster-specific), as they&amp;#39;re often relevant for more than one project, as well as some helper generator functions. A typical file in the &lt;code&gt;utils&lt;/code&gt; module would look something like:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;@resource\ndef gmail_resource(init_context):\n    return GMail(init_context.resource_config)\n\n\n@op\ndef fetch_from_gmail(context) -&amp;gt; GMailDagsterOutput:\n    return context.resources.gmail_resource.fetch(context.op_config)\n\n\nclass GMail(BaseGoogleAPI):\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n\n    def fetch(self, **kwargs) -&amp;gt; GMailDagsterOutput:\n        pass\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Inside of each project, the &lt;code&gt;lib/&lt;/code&gt; folder is used for transformations specific to that project, while a typical asset (pipeline) inside of a project would look something like:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;@asset\ndef my_asset():\n    source_data = fetch_from_gmail()\n    return process_my_asset(source_data)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;This pattern effectively means a single utilities library keeps everything abstracted and can be used by any other projects that come up, ensures a common interface is available and reduces the amount of code we&amp;#39;re writing for each new pipeline (in fact, a lot of them can just be changes to YAML configs). If very specific one-off computations are required, we can still import the source class and use or extend it as we want. Having seen a few different patterns in the past, I wonder which others are there, benefits and downsides.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y5pm4z", "is_robot_indexable": true, "report_reasons": null, "author": "askvinni", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y5pm4z/how_do_you_structure_your_de_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y5pm4z/how_do_you_structure_your_de_projects/", "subreddit_subscribers": 76689, "created_utc": 1665948756.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Howdy. Ive got some experience in SQL and moving data around with some transformations. Currently trying to learn some extra concepts as I'm applying for jobs that are geared more as Data Engineers / SQL Developers.\n\nI was only aware of ETL until recently where on some job postings I saw ELT mentioned.\n\nAfter trying to read up on it (I'm definitely not aware of a lot of the tools used), I don't where the Transform happens. When data is loaded into the warehouse does it get transformed and stored elsewhere in the warehouse? Or does it get transformed as it is goes to the end user?", "author_fullname": "t2_tb8jroz4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "In an ELT process, does the T happen in the data warehouse/lake or on it's way to the end source?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y5zzdq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665976546.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Howdy. Ive got some experience in SQL and moving data around with some transformations. Currently trying to learn some extra concepts as I&amp;#39;m applying for jobs that are geared more as Data Engineers / SQL Developers.&lt;/p&gt;\n\n&lt;p&gt;I was only aware of ETL until recently where on some job postings I saw ELT mentioned.&lt;/p&gt;\n\n&lt;p&gt;After trying to read up on it (I&amp;#39;m definitely not aware of a lot of the tools used), I don&amp;#39;t where the Transform happens. When data is loaded into the warehouse does it get transformed and stored elsewhere in the warehouse? Or does it get transformed as it is goes to the end user?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y5zzdq", "is_robot_indexable": true, "report_reasons": null, "author": "Loben-die-Sonne", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y5zzdq/in_an_elt_process_does_the_t_happen_in_the_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y5zzdq/in_an_elt_process_does_the_t_happen_in_the_data/", "subreddit_subscribers": 76689, "created_utc": 1665976546.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been thinking of making a career switch from digital marketing after 3.5 years in this industry. I realised that I lean more towards the analytics side. I enjoy setting up tools like Google Analytics and creating dashboards for marketers from data extracted from ad and analytics platforms. I'm on my way to learning SQL and BigQuery to improve in this role, but after learning about DE, it seems closer to what I'm genuinely interested in. I am on my way towards the technical marketer route, but the marketing and advertising industry has taken a toll on me and starting something new could be better for my overall well-being. I know it's a long shot from being a DE, and that's why I would need your help.\n\nMy only programming knowledge is basic front-end web dev, primarily JavaScript. I know how to use the terminal and spin up VPS for websites. The only time I need to use GCP is for server-side tagging: just basic things, enough for a marketer to know. \n\nSo far on this subreddit, most people asking for career switch advice have programming and data analyst/scientist backgrounds. So I'm wondering, how can I break through into this industry for someone like me? Or would most companies always prefer someone with these backgrounds?  \n\n\nNgl, this is intimidating, but I always like to start something with the most realistic expectation and work my way towards it. Your perspective and advice are much welcomed and needed.", "author_fullname": "t2_16ia3b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What does it take to break through into DE without any programming background?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y61wm3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665982564.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been thinking of making a career switch from digital marketing after 3.5 years in this industry. I realised that I lean more towards the analytics side. I enjoy setting up tools like Google Analytics and creating dashboards for marketers from data extracted from ad and analytics platforms. I&amp;#39;m on my way to learning SQL and BigQuery to improve in this role, but after learning about DE, it seems closer to what I&amp;#39;m genuinely interested in. I am on my way towards the technical marketer route, but the marketing and advertising industry has taken a toll on me and starting something new could be better for my overall well-being. I know it&amp;#39;s a long shot from being a DE, and that&amp;#39;s why I would need your help.&lt;/p&gt;\n\n&lt;p&gt;My only programming knowledge is basic front-end web dev, primarily JavaScript. I know how to use the terminal and spin up VPS for websites. The only time I need to use GCP is for server-side tagging: just basic things, enough for a marketer to know. &lt;/p&gt;\n\n&lt;p&gt;So far on this subreddit, most people asking for career switch advice have programming and data analyst/scientist backgrounds. So I&amp;#39;m wondering, how can I break through into this industry for someone like me? Or would most companies always prefer someone with these backgrounds?  &lt;/p&gt;\n\n&lt;p&gt;Ngl, this is intimidating, but I always like to start something with the most realistic expectation and work my way towards it. Your perspective and advice are much welcomed and needed.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "y61wm3", "is_robot_indexable": true, "report_reasons": null, "author": "sylliesayrawr", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y61wm3/what_does_it_take_to_break_through_into_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y61wm3/what_does_it_take_to_break_through_into_de/", "subreddit_subscribers": 76689, "created_utc": 1665982564.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Idk if this makes sense or not,\nBut I'm trying to find a tool/query Parser/Editor or something which can query oracle and sql databases at the same time. \n-As we have a database on SQL and the replica exists on Oracle.", "author_fullname": "t2_hsaf7ota", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\"Query Oracle + Sql\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y67r29", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666003450.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Idk if this makes sense or not,\nBut I&amp;#39;m trying to find a tool/query Parser/Editor or something which can query oracle and sql databases at the same time. \n-As we have a database on SQL and the replica exists on Oracle.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y67r29", "is_robot_indexable": true, "report_reasons": null, "author": "protecPotato", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y67r29/query_oracle_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y67r29/query_oracle_sql/", "subreddit_subscribers": 76689, "created_utc": 1666003450.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello folks,I'm in a predicament and I hope some of you can point me in the right direction.\n\nI have some time series data in S3 in parquet format, using HIVE partitioning by ingestion date and another categorical variable. New data comes in daily with a batch job and we use Athena for queries.\n\nWe got tired of this setup and decided to move to a more flexible data stack:Any EL tool (Fivetran, Airbyte, Hevo...) =&gt; Data warehouse =&gt; dbt =&gt; BI tool.\n\nMy current doubt regards the EL tool and how to move the existing data in S3 to a DWH. I was reading the docs of several of these EL tools and the first thing I noticed is that not all of them support parquet data, and those who do don't support HIVE partitioning.\n\nThe first step to me is quite clear: I can't use the data in the existing format, I have to copy it to another bucket and ditch the HIVE partitions at the very least.\n\nHowever, I'm not sure how to address everything else:\n\n* First of all, which EL tool would you recommend and why? Consider that I'd like to use the same tool to extract data from other sources too (mostly Saas)\n* How would you suggest I handle the currently existing data on S3? Should I keep parquet? Should I store it in another format?\n\nNote: consider that I can't directly extract it from the source database, as anything older than \\~6 months gets automatically deleted.  \n\n\nEdit: since some people mentioned it, the DWH we were planning to use is BigQuery, but it's not set in stone yet.", "author_fullname": "t2_zwbba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moving (parquet) data from S3 to warehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y5hsca", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1665939930.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665929483.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello folks,I&amp;#39;m in a predicament and I hope some of you can point me in the right direction.&lt;/p&gt;\n\n&lt;p&gt;I have some time series data in S3 in parquet format, using HIVE partitioning by ingestion date and another categorical variable. New data comes in daily with a batch job and we use Athena for queries.&lt;/p&gt;\n\n&lt;p&gt;We got tired of this setup and decided to move to a more flexible data stack:Any EL tool (Fivetran, Airbyte, Hevo...) =&amp;gt; Data warehouse =&amp;gt; dbt =&amp;gt; BI tool.&lt;/p&gt;\n\n&lt;p&gt;My current doubt regards the EL tool and how to move the existing data in S3 to a DWH. I was reading the docs of several of these EL tools and the first thing I noticed is that not all of them support parquet data, and those who do don&amp;#39;t support HIVE partitioning.&lt;/p&gt;\n\n&lt;p&gt;The first step to me is quite clear: I can&amp;#39;t use the data in the existing format, I have to copy it to another bucket and ditch the HIVE partitions at the very least.&lt;/p&gt;\n\n&lt;p&gt;However, I&amp;#39;m not sure how to address everything else:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;First of all, which EL tool would you recommend and why? Consider that I&amp;#39;d like to use the same tool to extract data from other sources too (mostly Saas)&lt;/li&gt;\n&lt;li&gt;How would you suggest I handle the currently existing data on S3? Should I keep parquet? Should I store it in another format?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Note: consider that I can&amp;#39;t directly extract it from the source database, as anything older than ~6 months gets automatically deleted.  &lt;/p&gt;\n\n&lt;p&gt;Edit: since some people mentioned it, the DWH we were planning to use is BigQuery, but it&amp;#39;s not set in stone yet.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y5hsca", "is_robot_indexable": true, "report_reasons": null, "author": "wtfzambo", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y5hsca/moving_parquet_data_from_s3_to_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y5hsca/moving_parquet_data_from_s3_to_warehouse/", "subreddit_subscribers": 76689, "created_utc": 1665929483.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have gbs of numpy arrays stored in raw files. These arrays represent freq read from a sensor. So basically a timeline.\n\nIm a complete beginner to data engineering but a senior SWE said it doesnt make sense to have any database system for that because its not tabular data where 1min of gathering data from the sensor gives about 1gb of data (so cloud is a no as well).\n\nWould appreciate some feedback on that.", "author_fullname": "t2_55mfs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does a data base make any sense for numpy arrays?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y62xpw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665986052.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have gbs of numpy arrays stored in raw files. These arrays represent freq read from a sensor. So basically a timeline.&lt;/p&gt;\n\n&lt;p&gt;Im a complete beginner to data engineering but a senior SWE said it doesnt make sense to have any database system for that because its not tabular data where 1min of gathering data from the sensor gives about 1gb of data (so cloud is a no as well).&lt;/p&gt;\n\n&lt;p&gt;Would appreciate some feedback on that.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y62xpw", "is_robot_indexable": true, "report_reasons": null, "author": "dongpal", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y62xpw/does_a_data_base_make_any_sense_for_numpy_arrays/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y62xpw/does_a_data_base_make_any_sense_for_numpy_arrays/", "subreddit_subscribers": 76689, "created_utc": 1665986052.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If you always or mostly try to stick to some strategy/technique which makes you work on task efficiently, assuming otherwise you would not complete your task in time or 100% when deadline arrives.\n\nI was reading this [article](https://www.upwork.com/resources/time-management-strategies) where it explains things to keep it mind and specific techniques (e.g. Pomodoro, Rapid Planning Method) to use to make most of our working time to efficiently finish task in time.\n\nI never used these techniques or any other were I used to work and it was fine but the pace of the workplace I am now is different and it seems like I waste or not handle time efficiently to finish my tasks. We use Kanban to track tasks and time in Jira. \n\nHow to improve this? It seems I am too detail-oriented person for what I am expected to do. I am asking more from a \"organize yourself\" perspective.\n\nThank you all!\n\n[View Poll](https://www.reddit.com/poll/y5p25w)", "author_fullname": "t2_7h7lz4mv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you use any time management strategy or technique to efficiently complete your tasks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_y5p25w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 0, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": "", "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1665948991.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665947409.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you always or mostly try to stick to some strategy/technique which makes you work on task efficiently, assuming otherwise you would not complete your task in time or 100% when deadline arrives.&lt;/p&gt;\n\n&lt;p&gt;I was reading this &lt;a href=\"https://www.upwork.com/resources/time-management-strategies\"&gt;article&lt;/a&gt; where it explains things to keep it mind and specific techniques (e.g. Pomodoro, Rapid Planning Method) to use to make most of our working time to efficiently finish task in time.&lt;/p&gt;\n\n&lt;p&gt;I never used these techniques or any other were I used to work and it was fine but the pace of the workplace I am now is different and it seems like I waste or not handle time efficiently to finish my tasks. We use Kanban to track tasks and time in Jira. &lt;/p&gt;\n\n&lt;p&gt;How to improve this? It seems I am too detail-oriented person for what I am expected to do. I am asking more from a &amp;quot;organize yourself&amp;quot; perspective.&lt;/p&gt;\n\n&lt;p&gt;Thank you all!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/y5p25w\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "call_to_action": "", "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y5p25w", "is_robot_indexable": true, "report_reasons": null, "author": "mrflamingosaurus", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1666120209158, "options": [{"text": "Yes, always.", "id": "19185845"}, {"text": "Yes, sometimes.", "id": "19185846"}, {"text": "Almost never", "id": "19185847"}, {"text": "Never", "id": "19185848"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 119, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y5p25w/do_you_use_any_time_management_strategy_or/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/y5p25w/do_you_use_any_time_management_strategy_or/", "subreddit_subscribers": 76689, "created_utc": 1665947409.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there,\n\nI want to setup a managed database for finance that has &lt;1gb data. We currently have one on SQL server express but we want one the entire org can utilize.\n\nWe are a startup and want to scale this with the business. We also don\u2019t have a DBA.\n\nI was thinking of just using azure managed. Thoughts?", "author_fullname": "t2_6a1a5s7g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Work at a startup, trying to decide on a managed db solution", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y69xde", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666009688.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there,&lt;/p&gt;\n\n&lt;p&gt;I want to setup a managed database for finance that has &amp;lt;1gb data. We currently have one on SQL server express but we want one the entire org can utilize.&lt;/p&gt;\n\n&lt;p&gt;We are a startup and want to scale this with the business. We also don\u2019t have a DBA.&lt;/p&gt;\n\n&lt;p&gt;I was thinking of just using azure managed. Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y69xde", "is_robot_indexable": true, "report_reasons": null, "author": "rlybadcpa", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y69xde/work_at_a_startup_trying_to_decide_on_a_managed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y69xde/work_at_a_startup_trying_to_decide_on_a_managed/", "subreddit_subscribers": 76689, "created_utc": 1666009688.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have started using all free resources available to start learning. Want to understand your experience!", "author_fullname": "t2_7illl62r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to move from legacy tech to data engineering in cloud. I have 7 years of mainframe experience but want to move to data engineering. I want to move to contracting. How did you start, please share experience.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y5tb05", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665957861.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have started using all free resources available to start learning. Want to understand your experience!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "y5tb05", "is_robot_indexable": true, "report_reasons": null, "author": "satoshi1000", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y5tb05/best_way_to_move_from_legacy_tech_to_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y5tb05/best_way_to_move_from_legacy_tech_to_data/", "subreddit_subscribers": 76689, "created_utc": 1665957861.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As part of a company reorg I have new job duties and I'm on point to load a lot of batch files to a database. Unfortunately everyone who does this work is in another department and aren't communicative. Due to bureaucracy, it's very unlikely I can get new software installed soon. I have sql, bash, and python on the server.\n\nFiles will be FTP'd to me and a guy is going to send me an email when the transfer is complete. I'll be running my job on a unix server. Googling for ETL only returns blog posts about why I should use this or that software. I need to get started validating data and loading it this week.\n\nAssuming I have a csv file in the format: idnum, firstname, lastname, address\n\nHere's how I was planning on processing it\n\n    import csv\n\n    with open(\"testfile.txt\",'r') as readfile:\n        reader = csv.reader(readfile)\n        for row in reader:\n            fail_reason = ''\n            if not row[0]:\n                fail_reason = \"blank id\"\n            elif not row[1]:\n                fail_reason = \"blank first name\"\n            elif not row[2]:\n                fail_reason = \"blank last name\"\n            elif not row[3]:\n                fail_reason = \"blank address\"\n\n            if fail_reason == '':\n                ###load to table\n\n            else:\n                ##write to error report\n\nAm I on the right track? Is there some obviously better solution that I can do with basic python?\n\nAre there any open source projects that handle something like this? What about books? Everything I can find it about specific software when I just need to do the basics well.", "author_fullname": "t2_sybqoka5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Basic data engineering question.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y5i8fv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665930652.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As part of a company reorg I have new job duties and I&amp;#39;m on point to load a lot of batch files to a database. Unfortunately everyone who does this work is in another department and aren&amp;#39;t communicative. Due to bureaucracy, it&amp;#39;s very unlikely I can get new software installed soon. I have sql, bash, and python on the server.&lt;/p&gt;\n\n&lt;p&gt;Files will be FTP&amp;#39;d to me and a guy is going to send me an email when the transfer is complete. I&amp;#39;ll be running my job on a unix server. Googling for ETL only returns blog posts about why I should use this or that software. I need to get started validating data and loading it this week.&lt;/p&gt;\n\n&lt;p&gt;Assuming I have a csv file in the format: idnum, firstname, lastname, address&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s how I was planning on processing it&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import csv\n\nwith open(&amp;quot;testfile.txt&amp;quot;,&amp;#39;r&amp;#39;) as readfile:\n    reader = csv.reader(readfile)\n    for row in reader:\n        fail_reason = &amp;#39;&amp;#39;\n        if not row[0]:\n            fail_reason = &amp;quot;blank id&amp;quot;\n        elif not row[1]:\n            fail_reason = &amp;quot;blank first name&amp;quot;\n        elif not row[2]:\n            fail_reason = &amp;quot;blank last name&amp;quot;\n        elif not row[3]:\n            fail_reason = &amp;quot;blank address&amp;quot;\n\n        if fail_reason == &amp;#39;&amp;#39;:\n            ###load to table\n\n        else:\n            ##write to error report\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Am I on the right track? Is there some obviously better solution that I can do with basic python?&lt;/p&gt;\n\n&lt;p&gt;Are there any open source projects that handle something like this? What about books? Everything I can find it about specific software when I just need to do the basics well.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y5i8fv", "is_robot_indexable": true, "report_reasons": null, "author": "Various-Spinach4391", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y5i8fv/basic_data_engineering_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y5i8fv/basic_data_engineering_question/", "subreddit_subscribers": 76689, "created_utc": 1665930652.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This seems like a dumb question, but instead of running *poetry run Python .main.py*, how can I invoke the model within a prefect pipeline?\n\nThe agent is on an aks cluster and file system in Blob Storage.", "author_fullname": "t2_8y4c8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I execute a poetry model using Prefect (ie. Python)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y5pk2j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665948613.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This seems like a dumb question, but instead of running &lt;em&gt;poetry run Python .main.py&lt;/em&gt;, how can I invoke the model within a prefect pipeline?&lt;/p&gt;\n\n&lt;p&gt;The agent is on an aks cluster and file system in Blob Storage.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y5pk2j", "is_robot_indexable": true, "report_reasons": null, "author": "azazazazaz3", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y5pk2j/how_do_i_execute_a_poetry_model_using_prefect_ie/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y5pk2j/how_do_i_execute_a_poetry_model_using_prefect_ie/", "subreddit_subscribers": 76689, "created_utc": 1665948613.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}