{"kind": "Listing", "data": {"after": "t3_yifmeg", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've recently launched \"PYTHON CHARTS\", a website that provides lots of matplotlib, seaborn and plotly easy-to-follow tutorials with reproducible code, both in English and Spanish.  \n\n\nLink: [https://python-charts.com/](https://python-charts.com/)  \nLink (spanish): [https://python-charts.com/es/](https://python-charts.com/es/)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/v4kwjk5hn0x91.png?width=939&amp;format=png&amp;auto=webp&amp;s=e2b92d7db2d6c63ce4bff55dabe34e96236d646e\n\nThe posts are filterable based on the chart type and library:\n\nhttps://preview.redd.it/4tfvn5prn0x91.png?width=898&amp;format=png&amp;auto=webp&amp;s=e7cba3f1bda4ec05fcf7f1a21489d1811c3e4a30\n\nEach tutorial will guide the reader step by step from a basic to more styled chart:\n\nhttps://preview.redd.it/yrsnxpdwn0x91.png?width=694&amp;format=png&amp;auto=webp&amp;s=ea772dda73588bbf87326e8ef384d002e0355f76\n\nThe site also provides some color tools to copy matplotlib colors both in HEX or by its name. You can also convert HEX to RGB in the page:\n\nhttps://preview.redd.it/hxhdctl2o0x91.png?width=890&amp;format=png&amp;auto=webp&amp;s=5cc280970d2112986d5ba35205e6aa6f224689e5\n\n&amp;#x200B;\n\n* I created this website on my spare time for all those finding the original docs difficult to follow.\n* This site has its equivalent in R: [https://r-charts.com/](https://r-charts.com/)\n\nHope you like it!", "author_fullname": "t2_17xtdkci", "saved": false, "mod_reason_title": null, "gilded": 1, "clicked": false, "title": "PYTHON CHARTS: a new visualization website feaaturing matplotlib, seaborn and plotly [Over 500 charts with reproducible code]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "media_metadata": {"hxhdctl2o0x91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 156, "x": 108, "u": "https://preview.redd.it/hxhdctl2o0x91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d49faa78c43173423df09eed064f39f235b917fb"}, {"y": 312, "x": 216, "u": "https://preview.redd.it/hxhdctl2o0x91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=070d15f7acdad1a27e2bb2b8b766fc61259724ad"}, {"y": 462, "x": 320, "u": "https://preview.redd.it/hxhdctl2o0x91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=378a569bb1991a38c9a33c92122ac64fe7a25bac"}, {"y": 925, "x": 640, "u": "https://preview.redd.it/hxhdctl2o0x91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9aaa2e2ffdc976ae28ab0ec964a36209f55caecb"}], "s": {"y": 1287, "x": 890, "u": "https://preview.redd.it/hxhdctl2o0x91.png?width=890&amp;format=png&amp;auto=webp&amp;s=5cc280970d2112986d5ba35205e6aa6f224689e5"}, "id": "hxhdctl2o0x91"}, "yrsnxpdwn0x91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 196, "x": 108, "u": "https://preview.redd.it/yrsnxpdwn0x91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=97a73dcc50de895263856f5231cfef7f736de2b7"}, {"y": 393, "x": 216, "u": "https://preview.redd.it/yrsnxpdwn0x91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=83c9687cb4f35b0682db65e2220b3a5bdb357db2"}, {"y": 582, "x": 320, "u": "https://preview.redd.it/yrsnxpdwn0x91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=78c424bb092da63fbb299993698061dd4b914993"}, {"y": 1164, "x": 640, "u": "https://preview.redd.it/yrsnxpdwn0x91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d8b8693ff4e915041e2f3091b3e3f16f60e347a1"}], "s": {"y": 1263, "x": 694, "u": "https://preview.redd.it/yrsnxpdwn0x91.png?width=694&amp;format=png&amp;auto=webp&amp;s=ea772dda73588bbf87326e8ef384d002e0355f76"}, "id": "yrsnxpdwn0x91"}, "4tfvn5prn0x91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 154, "x": 108, "u": "https://preview.redd.it/4tfvn5prn0x91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4fe13e7bcf9fba21016c4395d6841ceac6e359e1"}, {"y": 309, "x": 216, "u": "https://preview.redd.it/4tfvn5prn0x91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5ea2eaf6ba8b30ade2c11467c0bcbe90d9ac75bd"}, {"y": 458, "x": 320, "u": "https://preview.redd.it/4tfvn5prn0x91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=85bb6ccc76d27e2f41050fdcf331383d965b8e8d"}, {"y": 917, "x": 640, "u": "https://preview.redd.it/4tfvn5prn0x91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=315a0165155e0d7a80879af37dd4926141fe9fd8"}], "s": {"y": 1287, "x": 898, "u": "https://preview.redd.it/4tfvn5prn0x91.png?width=898&amp;format=png&amp;auto=webp&amp;s=e7cba3f1bda4ec05fcf7f1a21489d1811c3e4a30"}, "id": "4tfvn5prn0x91"}, "v4kwjk5hn0x91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 146, "x": 108, "u": "https://preview.redd.it/v4kwjk5hn0x91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2a85362a7dd399651eb276041e2b0fb1660b9487"}, {"y": 292, "x": 216, "u": "https://preview.redd.it/v4kwjk5hn0x91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=619c2e347bdf95af0c4152ab72ac87d33a3bc4ad"}, {"y": 432, "x": 320, "u": "https://preview.redd.it/v4kwjk5hn0x91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=361f9cb2b9f0f62aa6374a5dbda6de009dccf2e9"}, {"y": 865, "x": 640, "u": "https://preview.redd.it/v4kwjk5hn0x91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=33a37d4cf365f377f7e9ef1fbd0f57de1bead147"}], "s": {"y": 1270, "x": 939, "u": "https://preview.redd.it/v4kwjk5hn0x91.png?width=939&amp;format=png&amp;auto=webp&amp;s=e2b92d7db2d6c63ce4bff55dabe34e96236d646e"}, "id": "v4kwjk5hn0x91"}}, "name": "t3_yhrlpj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": null, "ups": 1150, "total_awards_received": 6, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1150, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://a.thumbs.redditmedia.com/MuDj-DI2ya1HC8GWH5ykUonYB2TFR0EKw6VLpaf7s20.jpg", "edited": 1667168137.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_1": 3, "gid_2": 1}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1667167934.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve recently launched &amp;quot;PYTHON CHARTS&amp;quot;, a website that provides lots of matplotlib, seaborn and plotly easy-to-follow tutorials with reproducible code, both in English and Spanish.  &lt;/p&gt;\n\n&lt;p&gt;Link: &lt;a href=\"https://python-charts.com/\"&gt;https://python-charts.com/&lt;/a&gt;&lt;br/&gt;\nLink (spanish): &lt;a href=\"https://python-charts.com/es/\"&gt;https://python-charts.com/es/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/v4kwjk5hn0x91.png?width=939&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e2b92d7db2d6c63ce4bff55dabe34e96236d646e\"&gt;https://preview.redd.it/v4kwjk5hn0x91.png?width=939&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e2b92d7db2d6c63ce4bff55dabe34e96236d646e&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The posts are filterable based on the chart type and library:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/4tfvn5prn0x91.png?width=898&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e7cba3f1bda4ec05fcf7f1a21489d1811c3e4a30\"&gt;https://preview.redd.it/4tfvn5prn0x91.png?width=898&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e7cba3f1bda4ec05fcf7f1a21489d1811c3e4a30&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Each tutorial will guide the reader step by step from a basic to more styled chart:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/yrsnxpdwn0x91.png?width=694&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ea772dda73588bbf87326e8ef384d002e0355f76\"&gt;https://preview.redd.it/yrsnxpdwn0x91.png?width=694&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ea772dda73588bbf87326e8ef384d002e0355f76&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The site also provides some color tools to copy matplotlib colors both in HEX or by its name. You can also convert HEX to RGB in the page:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/hxhdctl2o0x91.png?width=890&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5cc280970d2112986d5ba35205e6aa6f224689e5\"&gt;https://preview.redd.it/hxhdctl2o0x91.png?width=890&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5cc280970d2112986d5ba35205e6aa6f224689e5&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I created this website on my spare time for all those finding the original docs difficult to follow.&lt;/li&gt;\n&lt;li&gt;This site has its equivalent in R: &lt;a href=\"https://r-charts.com/\"&gt;https://r-charts.com/&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Hope you like it!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0_TuIn1S-2QxrRD58zU18NOYbfxe9kcuwoZwvmFWoZc.jpg?auto=webp&amp;s=8ef903646fb51923dcb6cb27b58698faf03dbc1d", "width": 1243, "height": 624}, "resolutions": [{"url": "https://external-preview.redd.it/0_TuIn1S-2QxrRD58zU18NOYbfxe9kcuwoZwvmFWoZc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4cc6e4713487ce3349d6cf83a7fec9e9071823d8", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/0_TuIn1S-2QxrRD58zU18NOYbfxe9kcuwoZwvmFWoZc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6b606dd450f8c1be5bbe283bed5c3f5ab82998b5", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/0_TuIn1S-2QxrRD58zU18NOYbfxe9kcuwoZwvmFWoZc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d50aa18680d571207eebc90637d12083fee25ac1", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/0_TuIn1S-2QxrRD58zU18NOYbfxe9kcuwoZwvmFWoZc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=38dd47bfb3af9db830649a261f3d6fb5e56b1e2a", "width": 640, "height": 321}, {"url": "https://external-preview.redd.it/0_TuIn1S-2QxrRD58zU18NOYbfxe9kcuwoZwvmFWoZc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f83dca1ee221fd43232d4114d9f2b28c75f27d24", "width": 960, "height": 481}, {"url": "https://external-preview.redd.it/0_TuIn1S-2QxrRD58zU18NOYbfxe9kcuwoZwvmFWoZc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d6ef7954378293f168e473b6e995c97508bca552", "width": 1080, "height": 542}], "variants": {}, "id": "zl629HmA1ahq55R7YP0OWmhXPCxsLl1yaKOqrgCR1ao"}], "enabled": false}, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 500, "id": "gid_2", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 100, "icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png", "days_of_premium": 7, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Gives 100 Reddit Coins and a week of r/lounge access and ad-free browsing.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Gold", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png"}, {"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 125, "id": "award_5f123e3d-4f48-42f4-9c11-e98b566d5897", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "When you come across a feel-good thing.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Wholesome", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png"}, {"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 30, "id": "award_b4ff447e-05a5-42dc-9002-63568807cfe6", "penny_donate": null, "award_sub_type": "PREMIUM", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_512.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_128.png", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "A glowing commendation for all to see", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "All-Seeing Upvote", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=16&amp;height=16&amp;auto=webp&amp;s=978c93744e53b8c9305467a7be792e5c401eac6c", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=32&amp;height=32&amp;auto=webp&amp;s=d2ee343eef5048ad3add75d4a4d4e3922bb9565a", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=48&amp;height=48&amp;auto=webp&amp;s=7d216fd3a05c61d9fb75b27092844c546d958f14", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=64&amp;height=64&amp;auto=webp&amp;s=b76693f84fd19b04d0c0444a9812d812105e2d8f", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=128&amp;height=128&amp;auto=webp&amp;s=5353352ae9f443c353ef0b7725dabcfc1b3829a5", "width": 128, "height": 128}], "icon_format": "APNG", "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png"}, {"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 100, "id": "gid_1", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Shows the Silver Award... and that's it.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 3, "static_icon_height": 512, "name": "Silver", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "yhrlpj", "is_robot_indexable": true, "report_reasons": null, "author": "JZOSS", "discussion_type": null, "num_comments": 52, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yhrlpj/python_charts_a_new_visualization_website/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yhrlpj/python_charts_a_new_visualization_website/", "subreddit_subscribers": 816408, "created_utc": 1667167934.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_mx27m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Happy Halloween, Pandas! \ud83c\udf83\ud83e\udd13", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_yik3k5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 424, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 424, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/86G5dt-kJ8WsFYzaQV9_qHMkvEwLuBUuxXp_7txXnIs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667240441.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/g2ukf6e2o6x91.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/g2ukf6e2o6x91.jpg?auto=webp&amp;s=9458bd4e911f0d89d9346744867fc8c8cc002879", "width": 800, "height": 800}, "resolutions": [{"url": "https://preview.redd.it/g2ukf6e2o6x91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1314ce78db76952566a0f56e2ca3e4407c00bbdd", "width": 108, "height": 108}, {"url": "https://preview.redd.it/g2ukf6e2o6x91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b0a69ab9c293f9893d8e38cc5c3828446791ec3b", "width": 216, "height": 216}, {"url": "https://preview.redd.it/g2ukf6e2o6x91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ce8b21f871df685436c829fd957d166132f4bb79", "width": 320, "height": 320}, {"url": "https://preview.redd.it/g2ukf6e2o6x91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2f58cea90454aa1e798477412d1c2e8ebdbe5631", "width": 640, "height": 640}], "variants": {}, "id": "dSBXZcOazTOSr0IPE0C1RrVxTaHYuPBHSPuqGB3bbKY"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "yik3k5", "is_robot_indexable": true, "report_reasons": null, "author": "aplarsen", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yik3k5/happy_halloween_pandas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/g2ukf6e2o6x91.jpg", "subreddit_subscribers": 816408, "created_utc": 1667240441.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "RuntimeError: expected scalar type Double but found Float\n\nRuntimeError: expected scalar type Double but found Float\n\nRuntimeError: expected scalar type Double but found Float\n\nRuntimeError: expected scalar type Double but found Float\n\nRuntimeError: expected scalar type Float but found Double", "author_fullname": "t2_1x46mq6e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A poem for Monday written by my neural network", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yik5ze", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 95, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 95, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667240795.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_1": 1}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667240572.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;RuntimeError: expected scalar type Double but found Float&lt;/p&gt;\n\n&lt;p&gt;RuntimeError: expected scalar type Double but found Float&lt;/p&gt;\n\n&lt;p&gt;RuntimeError: expected scalar type Double but found Float&lt;/p&gt;\n\n&lt;p&gt;RuntimeError: expected scalar type Double but found Float&lt;/p&gt;\n\n&lt;p&gt;RuntimeError: expected scalar type Float but found Double&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 100, "id": "gid_1", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Shows the Silver Award... and that's it.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Silver", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yik5ze", "is_robot_indexable": true, "report_reasons": null, "author": "FriddyNanz", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yik5ze/a_poem_for_monday_written_by_my_neural_network/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yik5ze/a_poem_for_monday_written_by_my_neural_network/", "subreddit_subscribers": 816408, "created_utc": 1667240572.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Lets say I have a binary feature , 0 and 1 for example, that 20% of the population is 0 and 80% is 1. From that population I sample and get 40% of the sample is 0 and 60% is 1. Im looking for a metric or a way to sort of measure this divergence. I was thinking simple euclidean distance but maybe there is a better metric Im not aware of.\n\nAnyone happen to know any good metric?  \nThanks", "author_fullname": "t2_3hqmko1r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there any metric to measure difference of a sample distribution from general population?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yi6sxu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667210146.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Lets say I have a binary feature , 0 and 1 for example, that 20% of the population is 0 and 80% is 1. From that population I sample and get 40% of the sample is 0 and 60% is 1. Im looking for a metric or a way to sort of measure this divergence. I was thinking simple euclidean distance but maybe there is a better metric Im not aware of.&lt;/p&gt;\n\n&lt;p&gt;Anyone happen to know any good metric?&lt;br/&gt;\nThanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yi6sxu", "is_robot_indexable": true, "report_reasons": null, "author": "nuriel8833", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yi6sxu/is_there_any_metric_to_measure_difference_of_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yi6sxu/is_there_any_metric_to_measure_difference_of_a/", "subreddit_subscribers": 816408, "created_utc": 1667210146.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nWelcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\n\n* Learning resources (e.g. books, tutorials, videos)\n* Traditional education (e.g. schools, degrees, electives)\n* Alternative education (e.g. online courses, bootcamps)\n* Job search questions (e.g. resumes, applying, career prospects)\n* Elementary questions (e.g. where to start, what next)\n\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weekly Entering &amp; Transitioning - Thread 31 Oct, 2022 - 07 Nov, 2022", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yi05tb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667188868.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;\n&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;\n&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;\n&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;\n&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=\"https://www.reddit.com/r/datascience/wiki/frequently-asked-questions\"&gt;FAQ&lt;/a&gt; and Resources pages on our wiki. You can also search for answers in &lt;a href=\"https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new\"&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "new", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yi05tb", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 3, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yi05tb/weekly_entering_transitioning_thread_31_oct_2022/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/datascience/comments/yi05tb/weekly_entering_transitioning_thread_31_oct_2022/", "subreddit_subscribers": 816408, "created_utc": 1667188868.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "If doing an AB test and tracking something like \u201cavg number of purchases per user\u201d or \u201cavg revenue per user\u201d, etc., should you always time-gate/ limit the amount of observation time you are looking at for each user? \n\nFor example, if I have users enrolling for 7 days, I will only include data from their first 14 days of enrolment. This would result in each user only having 14 days of valid data regardless of which day they enrolled on. \n\nAlternatively, non-time-gating would just be using all the data available. Some users will have more days of data available than others because they enrolled sooner. \n\nI tend to always time-gate, but I\u2019m wondering if the opposite is useful? The assumption is that we are randomizing on the user level and not something like page-views.", "author_fullname": "t2_3dbxxd6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should you always time-gate AB test metrics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yin6qu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667246521.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If doing an AB test and tracking something like \u201cavg number of purchases per user\u201d or \u201cavg revenue per user\u201d, etc., should you always time-gate/ limit the amount of observation time you are looking at for each user? &lt;/p&gt;\n\n&lt;p&gt;For example, if I have users enrolling for 7 days, I will only include data from their first 14 days of enrolment. This would result in each user only having 14 days of valid data regardless of which day they enrolled on. &lt;/p&gt;\n\n&lt;p&gt;Alternatively, non-time-gating would just be using all the data available. Some users will have more days of data available than others because they enrolled sooner. &lt;/p&gt;\n\n&lt;p&gt;I tend to always time-gate, but I\u2019m wondering if the opposite is useful? The assumption is that we are randomizing on the user level and not something like page-views.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yin6qu", "is_robot_indexable": true, "report_reasons": null, "author": "matt22022", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yin6qu/should_you_always_timegate_ab_test_metrics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yin6qu/should_you_always_timegate_ab_test_metrics/", "subreddit_subscribers": 816408, "created_utc": 1667246521.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Dear Colleagues, I hope this message finds all of you well! It is with immense pleasure that we announce the organization of the 4th Conference on Statistics and Data Science (CSDS 2022). It will be held between December 1 and 3, 2022, in virtual format. More information can be found on the event website: http://www.csds2022.ufba.br/ Registration and participation are free! Important dates: Abstract Submission: Until November 6, 2022. Decision on the acceptance of the abstracts: Until November 08, 2022. Submission of the 3 minutes video and 4 slides poster: Until November 20, 2022. Registration for the papers to be included in the scientific program: Until November 20, 2022. Registration for non-presenting participants: Until November 27, 2022. Young statisticians (up to 5 years after their last academic degree) will have the possibility to compete for the \u201cBest Poster Award on Statistics and Data Science\u201d. See more information at: https://csds2022.ufba.br/Awards.html See you soon!", "author_fullname": "t2_p31tpv4z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Conference on Statistics and Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yim8z2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667244646.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dear Colleagues, I hope this message finds all of you well! It is with immense pleasure that we announce the organization of the 4th Conference on Statistics and Data Science (CSDS 2022). It will be held between December 1 and 3, 2022, in virtual format. More information can be found on the event website: &lt;a href=\"http://www.csds2022.ufba.br/\"&gt;http://www.csds2022.ufba.br/&lt;/a&gt; Registration and participation are free! Important dates: Abstract Submission: Until November 6, 2022. Decision on the acceptance of the abstracts: Until November 08, 2022. Submission of the 3 minutes video and 4 slides poster: Until November 20, 2022. Registration for the papers to be included in the scientific program: Until November 20, 2022. Registration for non-presenting participants: Until November 27, 2022. Young statisticians (up to 5 years after their last academic degree) will have the possibility to compete for the \u201cBest Poster Award on Statistics and Data Science\u201d. See more information at: &lt;a href=\"https://csds2022.ufba.br/Awards.html\"&gt;https://csds2022.ufba.br/Awards.html&lt;/a&gt; See you soon!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yim8z2", "is_robot_indexable": true, "report_reasons": null, "author": "TheSearchForWisdom", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yim8z2/conference_on_statistics_and_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yim8z2/conference_on_statistics_and_data_science/", "subreddit_subscribers": 816408, "created_utc": 1667244646.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm a member of a recently formed data science team in a large corporation. I've been asked to put together an outline for a standards / SOP document for our team. Do your organizations have similar documents? What topics do they include?\n\nSo far, I'm envisioning something like the following:\n\n* Project management (Resource considerations, technical due diligence, etc.)\n* Code management (Version control, documentation standards, etc.)\n* Data management (Data access and access control, schema management, ELT, and many other topics)\n* Model development (Tools, best practices, quality control checklist, etc.)\n* Model deployment and management (Examples of deployment options, versioning, communication)\n* Design standards (Various design considerations, links to templates for various deployment platforms)", "author_fullname": "t2_8s6xha6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building a data science team SOP document", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yikwki", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667242027.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a member of a recently formed data science team in a large corporation. I&amp;#39;ve been asked to put together an outline for a standards / SOP document for our team. Do your organizations have similar documents? What topics do they include?&lt;/p&gt;\n\n&lt;p&gt;So far, I&amp;#39;m envisioning something like the following:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Project management (Resource considerations, technical due diligence, etc.)&lt;/li&gt;\n&lt;li&gt;Code management (Version control, documentation standards, etc.)&lt;/li&gt;\n&lt;li&gt;Data management (Data access and access control, schema management, ELT, and many other topics)&lt;/li&gt;\n&lt;li&gt;Model development (Tools, best practices, quality control checklist, etc.)&lt;/li&gt;\n&lt;li&gt;Model deployment and management (Examples of deployment options, versioning, communication)&lt;/li&gt;\n&lt;li&gt;Design standards (Various design considerations, links to templates for various deployment platforms)&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yikwki", "is_robot_indexable": true, "report_reasons": null, "author": "rogue_ego", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yikwki/building_a_data_science_team_sop_document/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yikwki/building_a_data_science_team_sop_document/", "subreddit_subscribers": 816408, "created_utc": 1667242027.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "R package: https://github.com/AndreaCirilloAC/paletter", "author_fullname": "t2_hoj6m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there python library equivalent of paletteR for color palette analysis/visualization?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yif9i8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667230123.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;R package: &lt;a href=\"https://github.com/AndreaCirilloAC/paletter\"&gt;https://github.com/AndreaCirilloAC/paletter&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_bNilZN8FyZNEgWM_DjDge-BJNAvPqNkVMd19daTgR4.jpg?auto=webp&amp;s=ca1e596fc1ebe4c527f1e6972fb215c602dbf521", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/_bNilZN8FyZNEgWM_DjDge-BJNAvPqNkVMd19daTgR4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fd293c0bec4277c8f970709ef04f6062b92e3487", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/_bNilZN8FyZNEgWM_DjDge-BJNAvPqNkVMd19daTgR4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e39381c4b387e423c3d8203a89335f9eece100bb", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/_bNilZN8FyZNEgWM_DjDge-BJNAvPqNkVMd19daTgR4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=63d4a361f75e16567bc08b90f64154586935f748", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/_bNilZN8FyZNEgWM_DjDge-BJNAvPqNkVMd19daTgR4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9bbbed3459004b0510a64e20e818db1a67ee6713", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/_bNilZN8FyZNEgWM_DjDge-BJNAvPqNkVMd19daTgR4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b2259e0e0cbc2cb0f4646dfba85b363fe2705239", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/_bNilZN8FyZNEgWM_DjDge-BJNAvPqNkVMd19daTgR4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2cbaf3f8369f7fe975c9bd11c53867fca460dab7", "width": 1080, "height": 540}], "variants": {}, "id": "eXJPwTdMCkMbCRvV2mf3Us321___OryYv-IAmtnBIw4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yif9i8", "is_robot_indexable": true, "report_reasons": null, "author": "canopey", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yif9i8/is_there_python_library_equivalent_of_paletter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yif9i8/is_there_python_library_equivalent_of_paletter/", "subreddit_subscribers": 816408, "created_utc": 1667230123.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone, I want to do a social network analysis on a specific keyword using data from Twitter. The goal is to assess the connections between different users that talk about a specific subject. Are there any videos/books that are recommended?", "author_fullname": "t2_ekh3q35a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Twitter network analysis", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yimrfb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667245674.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I want to do a social network analysis on a specific keyword using data from Twitter. The goal is to assess the connections between different users that talk about a specific subject. Are there any videos/books that are recommended?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yimrfb", "is_robot_indexable": true, "report_reasons": null, "author": "techteacherTT", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yimrfb/twitter_network_analysis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yimrfb/twitter_network_analysis/", "subreddit_subscribers": 816408, "created_utc": 1667245674.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a series of matrices which I am going to take the norms of and then cluster the norms.  However, doing so results in just a 1D vector.  Normally when I have worked with any clustering algorithms before, it's always been in the 2D or higher cases: what do I do when I only have 1 axis for clustering? Just try clustering along a number line?  Is there something else I could try or another way to do what I am trying to do?", "author_fullname": "t2_31lmg3kf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I cluster values of a 1D vector?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yimph5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667245566.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a series of matrices which I am going to take the norms of and then cluster the norms.  However, doing so results in just a 1D vector.  Normally when I have worked with any clustering algorithms before, it&amp;#39;s always been in the 2D or higher cases: what do I do when I only have 1 axis for clustering? Just try clustering along a number line?  Is there something else I could try or another way to do what I am trying to do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yimph5", "is_robot_indexable": true, "report_reasons": null, "author": "Amun-Aion", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yimph5/how_can_i_cluster_values_of_a_1d_vector/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yimph5/how_can_i_cluster_values_of_a_1d_vector/", "subreddit_subscribers": 816408, "created_utc": 1667245566.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've worked before with teams in software development but this is the first time I work with a team in data science  we are four members we are suppose to assign roles to each member. What are the roles of data science project?", "author_fullname": "t2_22mtojjh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the roles of team members in a data science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yilxlg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667244028.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve worked before with teams in software development but this is the first time I work with a team in data science  we are four members we are suppose to assign roles to each member. What are the roles of data science project?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yilxlg", "is_robot_indexable": true, "report_reasons": null, "author": "sk8er_girl90", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yilxlg/what_are_the_roles_of_team_members_in_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yilxlg/what_are_the_roles_of_team_members_in_a_data/", "subreddit_subscribers": 816408, "created_utc": 1667244028.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey all, had some q's related to bayesian inference and using it for generic business ab testing (ex: what version of an ad has a higher click rate, what type of sales page produces more revenue, etc.).\n\nI have some experience using beta and binomial distributions for this type of task when the metric of interest is a conversion rate, but I generally don't see a lot of examples where the metric of interest isn't a rate online.\n\nMy questions would be:\n\n1. Does anyone have any good resources (preferably in R) of using Bayesian inference in an ab testing framework that isn't solely focused on using beta and binomial distributions? I want to be more prepared for metrics that aren't conversion rates. Could be blog posts or books, but ideally would be showing examples that were focused on experimentation / ab testing\n\n2. Is a language like stan overkill for bayesian ab testing? Doing a bit of research, it seems a bit unnecessary for creating a posterior off a beta prior and binomial likelihood, but not sure about other use cases. I guess this answer might be it depends, but worth asking", "author_fullname": "t2_hlgt6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Couple of general questions on using bayesian inference for experimentation / ab testing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yidy50", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667227056.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, had some q&amp;#39;s related to bayesian inference and using it for generic business ab testing (ex: what version of an ad has a higher click rate, what type of sales page produces more revenue, etc.).&lt;/p&gt;\n\n&lt;p&gt;I have some experience using beta and binomial distributions for this type of task when the metric of interest is a conversion rate, but I generally don&amp;#39;t see a lot of examples where the metric of interest isn&amp;#39;t a rate online.&lt;/p&gt;\n\n&lt;p&gt;My questions would be:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Does anyone have any good resources (preferably in R) of using Bayesian inference in an ab testing framework that isn&amp;#39;t solely focused on using beta and binomial distributions? I want to be more prepared for metrics that aren&amp;#39;t conversion rates. Could be blog posts or books, but ideally would be showing examples that were focused on experimentation / ab testing&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Is a language like stan overkill for bayesian ab testing? Doing a bit of research, it seems a bit unnecessary for creating a posterior off a beta prior and binomial likelihood, but not sure about other use cases. I guess this answer might be it depends, but worth asking&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yidy50", "is_robot_indexable": true, "report_reasons": null, "author": "royhibbertnicekisser", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yidy50/couple_of_general_questions_on_using_bayesian/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yidy50/couple_of_general_questions_on_using_bayesian/", "subreddit_subscribers": 816408, "created_utc": 1667227056.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys!\n\nWanted to ask for directions and advice on how to run MySQL in the docker.  \nCreated a python script and app using it. Everything is just fine, but need to save the output in the DataBase and the company I work for uses MySQL. Can anyone help me set it up or show me where I can learn how?\n\n&amp;#x200B;\n\nKind regards,\n\nyour friendly engineer who's trying to learn DS.", "author_fullname": "t2_fmamadvj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Connect MySQL within the Docker", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yibqx2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667221891.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys!&lt;/p&gt;\n\n&lt;p&gt;Wanted to ask for directions and advice on how to run MySQL in the docker.&lt;br/&gt;\nCreated a python script and app using it. Everything is just fine, but need to save the output in the DataBase and the company I work for uses MySQL. Can anyone help me set it up or show me where I can learn how?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Kind regards,&lt;/p&gt;\n\n&lt;p&gt;your friendly engineer who&amp;#39;s trying to learn DS.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yibqx2", "is_robot_indexable": true, "report_reasons": null, "author": "FoxSinofSloth", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yibqx2/connect_mysql_within_the_docker/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yibqx2/connect_mysql_within_the_docker/", "subreddit_subscribers": 816408, "created_utc": 1667221891.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am looking for a python implementation of the following package\n\n[https://cran.r-project.org/web/packages/REBayes/index.html](https://cran.r-project.org/web/packages/REBayes/index.html)\n\nDoes anybody know if any work has been done in that direction, any new projects which I can pick up and develop over?", "author_fullname": "t2_tug3kxep", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "python code for REBayes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yi9fcw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667216667.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for a python implementation of the following package&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://cran.r-project.org/web/packages/REBayes/index.html\"&gt;https://cran.r-project.org/web/packages/REBayes/index.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Does anybody know if any work has been done in that direction, any new projects which I can pick up and develop over?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pB1e8yz1zTb43ZiqoKLD274IjRAoCjsP2v3Vc7T4y-g.jpg?auto=webp&amp;s=c4f72fe22b48b58fd800bdfd40854f9d4795356d", "width": 1000, "height": 1000}, "resolutions": [{"url": "https://external-preview.redd.it/pB1e8yz1zTb43ZiqoKLD274IjRAoCjsP2v3Vc7T4y-g.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4fd8638ea9437c78a10b3c0c564e5bb832948e30", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/pB1e8yz1zTb43ZiqoKLD274IjRAoCjsP2v3Vc7T4y-g.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7c9cd285b61b7ffb42ec3638020ab2a3c85eba77", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/pB1e8yz1zTb43ZiqoKLD274IjRAoCjsP2v3Vc7T4y-g.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bc8b307e7f213cc80f2653af55ef133a49d4816c", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/pB1e8yz1zTb43ZiqoKLD274IjRAoCjsP2v3Vc7T4y-g.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7df0f5ad584edbfeb01c49a725d2fffc61b02982", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/pB1e8yz1zTb43ZiqoKLD274IjRAoCjsP2v3Vc7T4y-g.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3041f0ca594a60ca78abfe84f876986e8425747e", "width": 960, "height": 960}], "variants": {}, "id": "waPksA41N5JBFZxGzjQNz5ydY0PesgwsKnDU1nuwLrY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yi9fcw", "is_robot_indexable": true, "report_reasons": null, "author": "manishagarwal13", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yi9fcw/python_code_for_rebayes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yi9fcw/python_code_for_rebayes/", "subreddit_subscribers": 816408, "created_utc": 1667216667.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "And What do you like about Data Science?\nAnd What do you dislike about it?", "author_fullname": "t2_p86tmqxg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why did you choose Data Science as your career? Why not Software Development, Cyber Security, Android, IOS &amp; other tech related fields?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yi61fc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667218998.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667208051.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;And What do you like about Data Science?\nAnd What do you dislike about it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yi61fc", "is_robot_indexable": true, "report_reasons": null, "author": "nightin__gale", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yi61fc/why_did_you_choose_data_science_as_your_career/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yi61fc/why_did_you_choose_data_science_as_your_career/", "subreddit_subscribers": 816408, "created_utc": 1667208051.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone, I\u2019m not sure if this is the right place to ask. But, is anyone familiar with a website where I can see an accounts Twitter followers on a specific date? Such as Amazons followers on 1/1/2019? I need to collect this data for an econometrics data set. Thank you!", "author_fullname": "t2_jddu3cu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yi0b69", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667189317.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I\u2019m not sure if this is the right place to ask. But, is anyone familiar with a website where I can see an accounts Twitter followers on a specific date? Such as Amazons followers on 1/1/2019? I need to collect this data for an econometrics data set. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yi0b69", "is_robot_indexable": true, "report_reasons": null, "author": "Virtuosonic", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yi0b69/data_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yi0b69/data_help/", "subreddit_subscribers": 816408, "created_utc": 1667189317.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\nI'm currently in an analytics role and trying to dive into more sophisticated ways of looking at our company's data. One of the ways I was exploring was applying clustering (such as k-means) to time-series data. The only issue is that my object is to find \"users\" and \"devices\" that are anomalous based on hourly traffic. I also have other columns such as \"geo\" as well as some proprietary labels (but the main two are user device combinations)\n\nMy issue is that anytime i attempt to run a clustering algo in Python, the algo just clusters data into it's hourly buckets and I'm not really able to find anything insightful. I spoke to a data scientist who suggested I do the following:\n\n1. scale the data down using a scaling method such as min-max scaler(some users/devices will have much more traffic than others)\n2. Use time pattern as a feature\n\nI don't understand how to do this.\n\nFor example, this is a dummy version of how my table looks like:\n\n&amp;#x200B;\n\nhttps://preview.redd.it/oq81i0ube2x91.png?width=250&amp;format=png&amp;auto=webp&amp;s=69215e678310c61904386207593df11ad0b797be\n\nI think what I'm trying to figure out is how to take that data and turn it into a feature:\n\n{\n\n\"user / device\" : a / roku,\n\n\"timeOfHour\" : 1\n\n\"traffic\" : 100\n\n... and so forth\n\n}\n\nI'm just stuck and not sure the best place. I also tried reading up on papers but my problem seems fairly unique and I can't seem to find a reference point. Does this seem like the right approach?\n\nLastly, when running scalers, am I supposed to run the scaler against ALL of the data? For example, when I applied the robust scaler in sklearn to my data, the end result looked the same when i plotted my charts. My goal is to bring all of the smaller user/device combinations that may have a fraction of the traffic as the top user/devices on the same scale and I'm not sure how to do this. \n\nAny help/tips would be greatly appreciate and I apologize if the above sounds a bit messy!", "author_fullname": "t2_79jdi5ck", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Clustering on Hourly Data with Labels", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 50, "top_awarded_type": null, "hide_score": false, "media_metadata": {"oq81i0ube2x91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 39, "x": 108, "u": "https://preview.redd.it/oq81i0ube2x91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=930c9b7156e0159ac8c0c9de7654ac4155d7ee69"}, {"y": 78, "x": 216, "u": "https://preview.redd.it/oq81i0ube2x91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=830504dfcb785bca415163cdcd039dd326d6e2e5"}], "s": {"y": 91, "x": 250, "u": "https://preview.redd.it/oq81i0ube2x91.png?width=250&amp;format=png&amp;auto=webp&amp;s=69215e678310c61904386207593df11ad0b797be"}, "id": "oq81i0ube2x91"}}, "name": "t3_yi0618", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/eSuqHwuSZ28QmmLE3LbU2c_bCMIwcdm1hucOLNOqAfI.jpg", "edited": 1667190316.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667188884.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently in an analytics role and trying to dive into more sophisticated ways of looking at our company&amp;#39;s data. One of the ways I was exploring was applying clustering (such as k-means) to time-series data. The only issue is that my object is to find &amp;quot;users&amp;quot; and &amp;quot;devices&amp;quot; that are anomalous based on hourly traffic. I also have other columns such as &amp;quot;geo&amp;quot; as well as some proprietary labels (but the main two are user device combinations)&lt;/p&gt;\n\n&lt;p&gt;My issue is that anytime i attempt to run a clustering algo in Python, the algo just clusters data into it&amp;#39;s hourly buckets and I&amp;#39;m not really able to find anything insightful. I spoke to a data scientist who suggested I do the following:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;scale the data down using a scaling method such as min-max scaler(some users/devices will have much more traffic than others)&lt;/li&gt;\n&lt;li&gt;Use time pattern as a feature&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I don&amp;#39;t understand how to do this.&lt;/p&gt;\n\n&lt;p&gt;For example, this is a dummy version of how my table looks like:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/oq81i0ube2x91.png?width=250&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=69215e678310c61904386207593df11ad0b797be\"&gt;https://preview.redd.it/oq81i0ube2x91.png?width=250&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=69215e678310c61904386207593df11ad0b797be&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I think what I&amp;#39;m trying to figure out is how to take that data and turn it into a feature:&lt;/p&gt;\n\n&lt;p&gt;{&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;user / device&amp;quot; : a / roku,&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;timeOfHour&amp;quot; : 1&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;traffic&amp;quot; : 100&lt;/p&gt;\n\n&lt;p&gt;... and so forth&lt;/p&gt;\n\n&lt;p&gt;}&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m just stuck and not sure the best place. I also tried reading up on papers but my problem seems fairly unique and I can&amp;#39;t seem to find a reference point. Does this seem like the right approach?&lt;/p&gt;\n\n&lt;p&gt;Lastly, when running scalers, am I supposed to run the scaler against ALL of the data? For example, when I applied the robust scaler in sklearn to my data, the end result looked the same when i plotted my charts. My goal is to bring all of the smaller user/device combinations that may have a fraction of the traffic as the top user/devices on the same scale and I&amp;#39;m not sure how to do this. &lt;/p&gt;\n\n&lt;p&gt;Any help/tips would be greatly appreciate and I apologize if the above sounds a bit messy!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yi0618", "is_robot_indexable": true, "report_reasons": null, "author": "goku_4110", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yi0618/clustering_on_hourly_data_with_labels/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yi0618/clustering_on_hourly_data_with_labels/", "subreddit_subscribers": 816408, "created_utc": 1667188884.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "&amp;#x200B;\n\nhttps://preview.redd.it/zenwv8w737x91.png?width=702&amp;format=png&amp;auto=webp&amp;s=f3b15b227ea85c3b89df452bc4677fa76934eb83", "author_fullname": "t2_b9xo9qx6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Applied for 30+ internships, but got only 1 call. I'll be graduating in 2023. I'm applying for Data science or Machine learning related internships. What's wrong with my resume? Any suggestions would be helpful.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "media_metadata": {"zenwv8w737x91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 136, "x": 108, "u": "https://preview.redd.it/zenwv8w737x91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=cd6d7d32b6b60577d08a9844fb27d9e87dc84173"}, {"y": 273, "x": 216, "u": "https://preview.redd.it/zenwv8w737x91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=437814bf4c4ab21b40d9dd8433fb6251249a1046"}, {"y": 405, "x": 320, "u": "https://preview.redd.it/zenwv8w737x91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ba6d952c16eed445d958ec3c0e1f209514d84421"}, {"y": 810, "x": 640, "u": "https://preview.redd.it/zenwv8w737x91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b454bf99210f128074c36bed99f82f002e8e0ef4"}], "s": {"y": 889, "x": 702, "u": "https://preview.redd.it/zenwv8w737x91.png?width=702&amp;format=png&amp;auto=webp&amp;s=f3b15b227ea85c3b89df452bc4677fa76934eb83"}, "id": "zenwv8w737x91"}}, "name": "t3_yimok3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/4WD-0DFKXF_XZ5D4d7KmEcr9UFgRduSuzUjEJF79S4Q.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667245515.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/zenwv8w737x91.png?width=702&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f3b15b227ea85c3b89df452bc4677fa76934eb83\"&gt;https://preview.redd.it/zenwv8w737x91.png?width=702&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f3b15b227ea85c3b89df452bc4677fa76934eb83&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "yimok3", "is_robot_indexable": true, "report_reasons": null, "author": "MohamedJihedRiahi", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yimok3/applied_for_30_internships_but_got_only_1_call/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yimok3/applied_for_30_internships_but_got_only_1_call/", "subreddit_subscribers": 816408, "created_utc": 1667245515.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Does anybody know where to get datasets for data scientists for different medical purposes?", "author_fullname": "t2_12ljfz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Medical data sets", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yikmxc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667241497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anybody know where to get datasets for data scientists for different medical purposes?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yikmxc", "is_robot_indexable": true, "report_reasons": null, "author": "Aschellery", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yikmxc/medical_data_sets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yikmxc/medical_data_sets/", "subreddit_subscribers": 816408, "created_utc": 1667241497.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_a7vwxer2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it true that many data scientist experience stress because they have to deal with the ethical implications?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yi3f14", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1667199705.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "www-technologyreview-com.cdn.ampproject.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www-technologyreview-com.cdn.ampproject.org/c/s/www.technologyreview.com/2022/10/28/1062332/responsible-ai-has-a-burnout-problem/amp/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yi3f14", "is_robot_indexable": true, "report_reasons": null, "author": "FaerAengel", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yi3f14/is_it_true_that_many_data_scientist_experience/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www-technologyreview-com.cdn.ampproject.org/c/s/www.technologyreview.com/2022/10/28/1062332/responsible-ai-has-a-burnout-problem/amp/", "subreddit_subscribers": 816408, "created_utc": 1667199705.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I want to store my data for long periods of time. I have my flash drive but from what I've heard the data could be corrupted in 2 years. I could store it in google drive, but I have only 15 GB max storage. All help is helpful, thanks!", "author_fullname": "t2_4hc22kke", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where to store data for long periods of time? (100+ years)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yhryig", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667168661.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to store my data for long periods of time. I have my flash drive but from what I&amp;#39;ve heard the data could be corrupted in 2 years. I could store it in google drive, but I have only 15 GB max storage. All help is helpful, thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yhryig", "is_robot_indexable": true, "report_reasons": null, "author": "SmoKKe9", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yhryig/where_to_store_data_for_long_periods_of_time_100/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yhryig/where_to_store_data_for_long_periods_of_time_100/", "subreddit_subscribers": 816408, "created_utc": 1667168661.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Anyone who knows of companies who hire and train mainly python and its libraries, machine learning. Just wondering how I can earn as I train and would also want to start developing relevant skills as I work on real projects other than wasting time learning everything. Health-related projects are preferred but can start  with anything.", "author_fullname": "t2_tb8frm0q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science jobs for beginners", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yimw9e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667245938.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone who knows of companies who hire and train mainly python and its libraries, machine learning. Just wondering how I can earn as I train and would also want to start developing relevant skills as I work on real projects other than wasting time learning everything. Health-related projects are preferred but can start  with anything.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "yimw9e", "is_robot_indexable": true, "report_reasons": null, "author": "SharpSmiley_faceM", "discussion_type": null, "num_comments": 3, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yimw9e/data_science_jobs_for_beginners/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yimw9e/data_science_jobs_for_beginners/", "subreddit_subscribers": 816408, "created_utc": 1667245938.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have to make a data science task where I have to analyze this algorithm. I don\u00b4t know how to pass this pseudocode to python code. CAn anyone help me to do it? thank you so much\n\nhttps://preview.redd.it/jfn2nqxk94x91.png?width=885&amp;format=png&amp;auto=webp&amp;s=04395f8ff9611210f279fadf88229e4183ff3744", "author_fullname": "t2_e8lhevft", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with this algorithm analysis task plz.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 71, "top_awarded_type": null, "hide_score": false, "media_metadata": {"jfn2nqxk94x91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 55, "x": 108, "u": "https://preview.redd.it/jfn2nqxk94x91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b1602319c43a8239609df1f3a4e2bb909464ee92"}, {"y": 110, "x": 216, "u": "https://preview.redd.it/jfn2nqxk94x91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5b65c0e6a0f038c6bec1c3aa2616ab38445e3e06"}, {"y": 164, "x": 320, "u": "https://preview.redd.it/jfn2nqxk94x91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=83f69e51d4d145b136148e010fb9d4af8c02b25d"}, {"y": 328, "x": 640, "u": "https://preview.redd.it/jfn2nqxk94x91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=fc6ff28954b0ae407b0e369c9966430b572a2c5c"}], "s": {"y": 454, "x": 885, "u": "https://preview.redd.it/jfn2nqxk94x91.png?width=885&amp;format=png&amp;auto=webp&amp;s=04395f8ff9611210f279fadf88229e4183ff3744"}, "id": "jfn2nqxk94x91"}}, "name": "t3_yi82hg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.1, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/H2Srs-1L7I-pohCDWRhAZLbw91G5nVJzNPXTrhYm9gM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667213442.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have to make a data science task where I have to analyze this algorithm. I don\u00b4t know how to pass this pseudocode to python code. CAn anyone help me to do it? thank you so much&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/jfn2nqxk94x91.png?width=885&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=04395f8ff9611210f279fadf88229e4183ff3744\"&gt;https://preview.redd.it/jfn2nqxk94x91.png?width=885&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=04395f8ff9611210f279fadf88229e4183ff3744&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yi82hg", "is_robot_indexable": true, "report_reasons": null, "author": "blunkelsito", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yi82hg/help_with_this_algorithm_analysis_task_plz/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yi82hg/help_with_this_algorithm_analysis_task_plz/", "subreddit_subscribers": 816408, "created_utc": 1667213442.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_kytqh4tu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What\u2019s a definitely real data science job with high pay, low hours, low barrier to entry, flexible work environment, beginner friendly?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yifmeg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.26, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667230942.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "yifmeg", "is_robot_indexable": true, "report_reasons": null, "author": "SeriouslySally36", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yifmeg/whats_a_definitely_real_data_science_job_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yifmeg/whats_a_definitely_real_data_science_job_with/", "subreddit_subscribers": 816408, "created_utc": 1667230942.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}