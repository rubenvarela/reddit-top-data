{"kind": "Listing", "data": {"after": "t3_yi7ao4", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've recently launched \"PYTHON CHARTS\", a website that provides lots of matplotlib, seaborn and plotly easy-to-follow tutorials with reproducible code, both in English and Spanish.  \n\n\nLink: [https://python-charts.com/](https://python-charts.com/)  \nLink (spanish): [https://python-charts.com/es/](https://python-charts.com/es/)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/v4kwjk5hn0x91.png?width=939&amp;format=png&amp;auto=webp&amp;s=e2b92d7db2d6c63ce4bff55dabe34e96236d646e\n\nThe posts are filterable based on the chart type and library:\n\nhttps://preview.redd.it/4tfvn5prn0x91.png?width=898&amp;format=png&amp;auto=webp&amp;s=e7cba3f1bda4ec05fcf7f1a21489d1811c3e4a30\n\nEach tutorial will guide the reader step by step from a basic to more styled chart:\n\nhttps://preview.redd.it/yrsnxpdwn0x91.png?width=694&amp;format=png&amp;auto=webp&amp;s=ea772dda73588bbf87326e8ef384d002e0355f76\n\nThe site also provides some color tools to copy matplotlib colors both in HEX or by its name. You can also convert HEX to RGB in the page:\n\nhttps://preview.redd.it/hxhdctl2o0x91.png?width=890&amp;format=png&amp;auto=webp&amp;s=5cc280970d2112986d5ba35205e6aa6f224689e5\n\n&amp;#x200B;\n\n* I created this website on my spare time for all those finding the original docs difficult to follow.\n* This site has its equivalent in R: [https://r-charts.com/](https://r-charts.com/)\n\nHope you like it!", "author_fullname": "t2_17xtdkci", "saved": false, "mod_reason_title": null, "gilded": 1, "clicked": false, "title": "PYTHON CHARTS: a new visualization website feaaturing matplotlib, seaborn and plotly [Over 500 charts with reproducible code]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "media_metadata": {"hxhdctl2o0x91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 156, "x": 108, "u": "https://preview.redd.it/hxhdctl2o0x91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d49faa78c43173423df09eed064f39f235b917fb"}, {"y": 312, "x": 216, "u": "https://preview.redd.it/hxhdctl2o0x91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=070d15f7acdad1a27e2bb2b8b766fc61259724ad"}, {"y": 462, "x": 320, "u": "https://preview.redd.it/hxhdctl2o0x91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=378a569bb1991a38c9a33c92122ac64fe7a25bac"}, {"y": 925, "x": 640, "u": "https://preview.redd.it/hxhdctl2o0x91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9aaa2e2ffdc976ae28ab0ec964a36209f55caecb"}], "s": {"y": 1287, "x": 890, "u": "https://preview.redd.it/hxhdctl2o0x91.png?width=890&amp;format=png&amp;auto=webp&amp;s=5cc280970d2112986d5ba35205e6aa6f224689e5"}, "id": "hxhdctl2o0x91"}, "yrsnxpdwn0x91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 196, "x": 108, "u": "https://preview.redd.it/yrsnxpdwn0x91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=97a73dcc50de895263856f5231cfef7f736de2b7"}, {"y": 393, "x": 216, "u": "https://preview.redd.it/yrsnxpdwn0x91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=83c9687cb4f35b0682db65e2220b3a5bdb357db2"}, {"y": 582, "x": 320, "u": "https://preview.redd.it/yrsnxpdwn0x91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=78c424bb092da63fbb299993698061dd4b914993"}, {"y": 1164, "x": 640, "u": "https://preview.redd.it/yrsnxpdwn0x91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d8b8693ff4e915041e2f3091b3e3f16f60e347a1"}], "s": {"y": 1263, "x": 694, "u": "https://preview.redd.it/yrsnxpdwn0x91.png?width=694&amp;format=png&amp;auto=webp&amp;s=ea772dda73588bbf87326e8ef384d002e0355f76"}, "id": "yrsnxpdwn0x91"}, "4tfvn5prn0x91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 154, "x": 108, "u": "https://preview.redd.it/4tfvn5prn0x91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4fe13e7bcf9fba21016c4395d6841ceac6e359e1"}, {"y": 309, "x": 216, "u": "https://preview.redd.it/4tfvn5prn0x91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5ea2eaf6ba8b30ade2c11467c0bcbe90d9ac75bd"}, {"y": 458, "x": 320, "u": "https://preview.redd.it/4tfvn5prn0x91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=85bb6ccc76d27e2f41050fdcf331383d965b8e8d"}, {"y": 917, "x": 640, "u": "https://preview.redd.it/4tfvn5prn0x91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=315a0165155e0d7a80879af37dd4926141fe9fd8"}], "s": {"y": 1287, "x": 898, "u": "https://preview.redd.it/4tfvn5prn0x91.png?width=898&amp;format=png&amp;auto=webp&amp;s=e7cba3f1bda4ec05fcf7f1a21489d1811c3e4a30"}, "id": "4tfvn5prn0x91"}, "v4kwjk5hn0x91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 146, "x": 108, "u": "https://preview.redd.it/v4kwjk5hn0x91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2a85362a7dd399651eb276041e2b0fb1660b9487"}, {"y": 292, "x": 216, "u": "https://preview.redd.it/v4kwjk5hn0x91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=619c2e347bdf95af0c4152ab72ac87d33a3bc4ad"}, {"y": 432, "x": 320, "u": "https://preview.redd.it/v4kwjk5hn0x91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=361f9cb2b9f0f62aa6374a5dbda6de009dccf2e9"}, {"y": 865, "x": 640, "u": "https://preview.redd.it/v4kwjk5hn0x91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=33a37d4cf365f377f7e9ef1fbd0f57de1bead147"}], "s": {"y": 1270, "x": 939, "u": "https://preview.redd.it/v4kwjk5hn0x91.png?width=939&amp;format=png&amp;auto=webp&amp;s=e2b92d7db2d6c63ce4bff55dabe34e96236d646e"}, "id": "v4kwjk5hn0x91"}}, "name": "t3_yhrlpj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": null, "ups": 1048, "total_awards_received": 6, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1048, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://a.thumbs.redditmedia.com/MuDj-DI2ya1HC8GWH5ykUonYB2TFR0EKw6VLpaf7s20.jpg", "edited": 1667168137.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_1": 3, "gid_2": 1}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1667167934.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve recently launched &amp;quot;PYTHON CHARTS&amp;quot;, a website that provides lots of matplotlib, seaborn and plotly easy-to-follow tutorials with reproducible code, both in English and Spanish.  &lt;/p&gt;\n\n&lt;p&gt;Link: &lt;a href=\"https://python-charts.com/\"&gt;https://python-charts.com/&lt;/a&gt;&lt;br/&gt;\nLink (spanish): &lt;a href=\"https://python-charts.com/es/\"&gt;https://python-charts.com/es/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/v4kwjk5hn0x91.png?width=939&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e2b92d7db2d6c63ce4bff55dabe34e96236d646e\"&gt;https://preview.redd.it/v4kwjk5hn0x91.png?width=939&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e2b92d7db2d6c63ce4bff55dabe34e96236d646e&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The posts are filterable based on the chart type and library:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/4tfvn5prn0x91.png?width=898&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e7cba3f1bda4ec05fcf7f1a21489d1811c3e4a30\"&gt;https://preview.redd.it/4tfvn5prn0x91.png?width=898&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e7cba3f1bda4ec05fcf7f1a21489d1811c3e4a30&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Each tutorial will guide the reader step by step from a basic to more styled chart:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/yrsnxpdwn0x91.png?width=694&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ea772dda73588bbf87326e8ef384d002e0355f76\"&gt;https://preview.redd.it/yrsnxpdwn0x91.png?width=694&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ea772dda73588bbf87326e8ef384d002e0355f76&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The site also provides some color tools to copy matplotlib colors both in HEX or by its name. You can also convert HEX to RGB in the page:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/hxhdctl2o0x91.png?width=890&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5cc280970d2112986d5ba35205e6aa6f224689e5\"&gt;https://preview.redd.it/hxhdctl2o0x91.png?width=890&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5cc280970d2112986d5ba35205e6aa6f224689e5&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I created this website on my spare time for all those finding the original docs difficult to follow.&lt;/li&gt;\n&lt;li&gt;This site has its equivalent in R: &lt;a href=\"https://r-charts.com/\"&gt;https://r-charts.com/&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Hope you like it!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0_TuIn1S-2QxrRD58zU18NOYbfxe9kcuwoZwvmFWoZc.jpg?auto=webp&amp;s=8ef903646fb51923dcb6cb27b58698faf03dbc1d", "width": 1243, "height": 624}, "resolutions": [{"url": "https://external-preview.redd.it/0_TuIn1S-2QxrRD58zU18NOYbfxe9kcuwoZwvmFWoZc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4cc6e4713487ce3349d6cf83a7fec9e9071823d8", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/0_TuIn1S-2QxrRD58zU18NOYbfxe9kcuwoZwvmFWoZc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6b606dd450f8c1be5bbe283bed5c3f5ab82998b5", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/0_TuIn1S-2QxrRD58zU18NOYbfxe9kcuwoZwvmFWoZc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d50aa18680d571207eebc90637d12083fee25ac1", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/0_TuIn1S-2QxrRD58zU18NOYbfxe9kcuwoZwvmFWoZc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=38dd47bfb3af9db830649a261f3d6fb5e56b1e2a", "width": 640, "height": 321}, {"url": "https://external-preview.redd.it/0_TuIn1S-2QxrRD58zU18NOYbfxe9kcuwoZwvmFWoZc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f83dca1ee221fd43232d4114d9f2b28c75f27d24", "width": 960, "height": 481}, {"url": "https://external-preview.redd.it/0_TuIn1S-2QxrRD58zU18NOYbfxe9kcuwoZwvmFWoZc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d6ef7954378293f168e473b6e995c97508bca552", "width": 1080, "height": 542}], "variants": {}, "id": "zl629HmA1ahq55R7YP0OWmhXPCxsLl1yaKOqrgCR1ao"}], "enabled": false}, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 100, "id": "gid_1", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Shows the Silver Award... and that's it.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 3, "static_icon_height": 512, "name": "Silver", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png"}, {"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 500, "id": "gid_2", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 100, "icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png", "days_of_premium": 7, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Gives 100 Reddit Coins and a week of r/lounge access and ad-free browsing.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Gold", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png"}, {"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 125, "id": "award_5f123e3d-4f48-42f4-9c11-e98b566d5897", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "When you come across a feel-good thing.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Wholesome", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png"}, {"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 30, "id": "award_b4ff447e-05a5-42dc-9002-63568807cfe6", "penny_donate": null, "award_sub_type": "PREMIUM", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_512.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_128.png", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "A glowing commendation for all to see", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "All-Seeing Upvote", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=16&amp;height=16&amp;auto=webp&amp;s=978c93744e53b8c9305467a7be792e5c401eac6c", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=32&amp;height=32&amp;auto=webp&amp;s=d2ee343eef5048ad3add75d4a4d4e3922bb9565a", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=48&amp;height=48&amp;auto=webp&amp;s=7d216fd3a05c61d9fb75b27092844c546d958f14", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=64&amp;height=64&amp;auto=webp&amp;s=b76693f84fd19b04d0c0444a9812d812105e2d8f", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=128&amp;height=128&amp;auto=webp&amp;s=5353352ae9f443c353ef0b7725dabcfc1b3829a5", "width": 128, "height": 128}], "icon_format": "APNG", "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "yhrlpj", "is_robot_indexable": true, "report_reasons": null, "author": "JZOSS", "discussion_type": null, "num_comments": 50, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yhrlpj/python_charts_a_new_visualization_website/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yhrlpj/python_charts_a_new_visualization_website/", "subreddit_subscribers": 816365, "created_utc": 1667167934.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm working with a customer order conversion dataset and I have a doubt regarding its customer id column . It has over 30 unique types of customer id's. Will frequency encoding be a good choice for handling this? There are a couple of customer ids that have the same frequency(5-6). Or should i consider any other method?", "author_fullname": "t2_hhsyvk4n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to handle categorical data with over 30 different types of entries", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yhle4p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667153165.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working with a customer order conversion dataset and I have a doubt regarding its customer id column . It has over 30 unique types of customer id&amp;#39;s. Will frequency encoding be a good choice for handling this? There are a couple of customer ids that have the same frequency(5-6). Or should i consider any other method?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yhle4p", "is_robot_indexable": true, "report_reasons": null, "author": "Competitive-Arm4633", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yhle4p/how_to_handle_categorical_data_with_over_30/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yhle4p/how_to_handle_categorical_data_with_over_30/", "subreddit_subscribers": 816365, "created_utc": 1667153165.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Lets say I have a binary feature , 0 and 1 for example, that 20% of the population is 0 and 80% is 1. From that population I sample and get 40% of the sample is 0 and 60% is 1. Im looking for a metric or a way to sort of measure this divergence. I was thinking simple euclidean distance but maybe there is a better metric Im not aware of.\n\nAnyone happen to know any good metric?  \nThanks", "author_fullname": "t2_3hqmko1r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there any metric to measure difference of a sample distribution from general population?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yi6sxu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667210146.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Lets say I have a binary feature , 0 and 1 for example, that 20% of the population is 0 and 80% is 1. From that population I sample and get 40% of the sample is 0 and 60% is 1. Im looking for a metric or a way to sort of measure this divergence. I was thinking simple euclidean distance but maybe there is a better metric Im not aware of.&lt;/p&gt;\n\n&lt;p&gt;Anyone happen to know any good metric?&lt;br/&gt;\nThanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yi6sxu", "is_robot_indexable": true, "report_reasons": null, "author": "nuriel8833", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yi6sxu/is_there_any_metric_to_measure_difference_of_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yi6sxu/is_there_any_metric_to_measure_difference_of_a/", "subreddit_subscribers": 816365, "created_utc": 1667210146.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_tsq8pf4u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When you use seaborn pairplot to put features against a specific output, and get vertical plots, which non linear regression method can be used then to make sense of it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 28, "top_awarded_type": null, "hide_score": false, "name": "t3_yhpr0y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/SudLUdit_1UFtKEk6TBp6PVdFYKXI5IkRhAGml7_3BI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667163542.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/t8qubsolb0x91.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/t8qubsolb0x91.jpg?auto=webp&amp;s=01b78eab3da9c9f0f1620e6bdfc2d2eb0eea4872", "width": 4032, "height": 825}, "resolutions": [{"url": "https://preview.redd.it/t8qubsolb0x91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=941da5587c1715a7e7f998016ddafc2c1cb2f94a", "width": 108, "height": 22}, {"url": "https://preview.redd.it/t8qubsolb0x91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=deafa2752da2d8b3943e9541a6949d35a7d6010d", "width": 216, "height": 44}, {"url": "https://preview.redd.it/t8qubsolb0x91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e7726c4c4e8e30c8f45ab919c1e707bb84581dcf", "width": 320, "height": 65}, {"url": "https://preview.redd.it/t8qubsolb0x91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9e89f40b0666af22fbfce28914d2042b54c59949", "width": 640, "height": 130}, {"url": "https://preview.redd.it/t8qubsolb0x91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=728591e514f8f1464266718b99c815978decf7c7", "width": 960, "height": 196}, {"url": "https://preview.redd.it/t8qubsolb0x91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4c7b9da2a273c78e7c5fc1fa1f992690353202a2", "width": 1080, "height": 220}], "variants": {}, "id": "ahg6AtQO9E1u6czoLo5GdxH6MNaSXgc-WzJpKgSI5xk"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "yhpr0y", "is_robot_indexable": true, "report_reasons": null, "author": "Vadersdillema", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yhpr0y/when_you_use_seaborn_pairplot_to_put_features/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/t8qubsolb0x91.jpg", "subreddit_subscribers": 816365, "created_utc": 1667163542.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_q8ybkya", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to calculate shapley values from scratch", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 63, "top_awarded_type": null, "hide_score": false, "name": "t3_yi6kmv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/rBgUUOcGs9lUTxw-yLtlrTvQ3OFvsWn-l0Zklb_-3Dc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667209530.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "depends-on-the-definition.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.depends-on-the-definition.com/shapley-values-from-scratch/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hguCAX0KhJnWsSfpUsjEXsIQlQ3r5Mva6TOuEH3SgaY.jpg?auto=webp&amp;s=6cd1a5e37aa7e2b967b2cd2fb298610d5bd9d9e4", "width": 263, "height": 119}, "resolutions": [{"url": "https://external-preview.redd.it/hguCAX0KhJnWsSfpUsjEXsIQlQ3r5Mva6TOuEH3SgaY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=63fd783f3aad52afbbb30f215e10014d5b83b971", "width": 108, "height": 48}, {"url": "https://external-preview.redd.it/hguCAX0KhJnWsSfpUsjEXsIQlQ3r5Mva6TOuEH3SgaY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=224cc5747c8103aa937ba4bcc99a365b04227944", "width": 216, "height": 97}], "variants": {}, "id": "XuDrPqS_nvXfzbqDaMpmmIq4oSrgaFxcmjXxrcroF40"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "yi6kmv", "is_robot_indexable": true, "report_reasons": null, "author": "sterby92", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yi6kmv/how_to_calculate_shapley_values_from_scratch/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.depends-on-the-definition.com/shapley-values-from-scratch/", "subreddit_subscribers": 816365, "created_utc": 1667209530.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nWelcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\n\n* Learning resources (e.g. books, tutorials, videos)\n* Traditional education (e.g. schools, degrees, electives)\n* Alternative education (e.g. online courses, bootcamps)\n* Job search questions (e.g. resumes, applying, career prospects)\n* Elementary questions (e.g. where to start, what next)\n\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weekly Entering &amp; Transitioning - Thread 31 Oct, 2022 - 07 Nov, 2022", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yi05tb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667188868.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;\n&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;\n&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;\n&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;\n&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=\"https://www.reddit.com/r/datascience/wiki/frequently-asked-questions\"&gt;FAQ&lt;/a&gt; and Resources pages on our wiki. You can also search for answers in &lt;a href=\"https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new\"&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "new", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yi05tb", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yi05tb/weekly_entering_transitioning_thread_31_oct_2022/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/datascience/comments/yi05tb/weekly_entering_transitioning_thread_31_oct_2022/", "subreddit_subscribers": 816365, "created_utc": 1667188868.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi guys,\n\nI work in the revenue assurance and data analytics unit of financial control department of the largest bank in my country. My background is in economics and accounting. My boss has asked me to go and search for industry standard certifications in data analytics and data science to register for. The cost will be paid for by the bank.\n\nSo I need suggestions.\n\nThanks", "author_fullname": "t2_7li0w7o9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Analytics/Science certifications", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yidseq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667226679.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;I work in the revenue assurance and data analytics unit of financial control department of the largest bank in my country. My background is in economics and accounting. My boss has asked me to go and search for industry standard certifications in data analytics and data science to register for. The cost will be paid for by the bank.&lt;/p&gt;\n\n&lt;p&gt;So I need suggestions.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yidseq", "is_robot_indexable": true, "report_reasons": null, "author": "Pleasant_Industry_44", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yidseq/data_analyticsscience_certifications/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yidseq/data_analyticsscience_certifications/", "subreddit_subscribers": 816365, "created_utc": 1667226679.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Context: I have two line-charts trying to portray the historical performance of a financial trading indicator called moonindex. The indicator outputs a risk-level between 0 - 100 where 0 = buy and 100 = sell. Which one of these 2 visualisations are the best?\n\nConsider that the person is either fairly new to trading, or has been trading for a while and is looking for new tools and that this charts is going to be on a landing page.\n\nNr 1\n\nhttps://preview.redd.it/dslbnopdb5x91.png?width=3308&amp;format=png&amp;auto=webp&amp;s=b70e8e1f0a8083f671dde7df01f0e712709c3d40\n\nNr 2\n\nhttps://preview.redd.it/tfalvv3cb5x91.png?width=2716&amp;format=png&amp;auto=webp&amp;s=f12977e690cfe21e0fedfacbd4e844a6feae0acc", "author_fullname": "t2_5570yt5s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which of these 2 visualisations is the best?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 57, "top_awarded_type": null, "hide_score": false, "media_metadata": {"tfalvv3cb5x91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 63, "x": 108, "u": "https://preview.redd.it/tfalvv3cb5x91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=270b937dc09582dd165d0318365f9a173ef71bc7"}, {"y": 126, "x": 216, "u": "https://preview.redd.it/tfalvv3cb5x91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e193175147f31886fd097e6e86ad569ded641d7e"}, {"y": 186, "x": 320, "u": "https://preview.redd.it/tfalvv3cb5x91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8f0c588b8e25482eda6b6baa8efb62361fe87a92"}, {"y": 373, "x": 640, "u": "https://preview.redd.it/tfalvv3cb5x91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=35361ce2ae040db03b7b336d2e1dd1487bd55b62"}, {"y": 560, "x": 960, "u": "https://preview.redd.it/tfalvv3cb5x91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=b48e3c2788764e6010d1c240228678a59d89158f"}, {"y": 630, "x": 1080, "u": "https://preview.redd.it/tfalvv3cb5x91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8b6ceff8e0b82bd0cb205370e7860ceca586a60b"}], "s": {"y": 1586, "x": 2716, "u": "https://preview.redd.it/tfalvv3cb5x91.png?width=2716&amp;format=png&amp;auto=webp&amp;s=f12977e690cfe21e0fedfacbd4e844a6feae0acc"}, "id": "tfalvv3cb5x91"}, "dslbnopdb5x91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 44, "x": 108, "u": "https://preview.redd.it/dslbnopdb5x91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=974e85f4e33a989bd0bd6b3eb8567de11c739a77"}, {"y": 88, "x": 216, "u": "https://preview.redd.it/dslbnopdb5x91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=80d423458ea4cb1ef8af6d0cd2b9244bd1c5f4c5"}, {"y": 131, "x": 320, "u": "https://preview.redd.it/dslbnopdb5x91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=bcf5bfffe4f2632da6ec26b2281188b30625cba6"}, {"y": 262, "x": 640, "u": "https://preview.redd.it/dslbnopdb5x91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f4f65e800376331fce61d219ea502ce110dec100"}, {"y": 393, "x": 960, "u": "https://preview.redd.it/dslbnopdb5x91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=87f5db7eb31251f58b486db02527cce686a5057c"}, {"y": 442, "x": 1080, "u": "https://preview.redd.it/dslbnopdb5x91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7f68f1ed0f6ee3d849d2a3f23ffade61921029b1"}], "s": {"y": 1356, "x": 3308, "u": "https://preview.redd.it/dslbnopdb5x91.png?width=3308&amp;format=png&amp;auto=webp&amp;s=b70e8e1f0a8083f671dde7df01f0e712709c3d40"}, "id": "dslbnopdb5x91"}}, "name": "t3_yicrdu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/wFsEQWDqzjsrtv-F0aJ0TTcqUEmZ_PFgRHwiDsiHhlo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667224192.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Context: I have two line-charts trying to portray the historical performance of a financial trading indicator called moonindex. The indicator outputs a risk-level between 0 - 100 where 0 = buy and 100 = sell. Which one of these 2 visualisations are the best?&lt;/p&gt;\n\n&lt;p&gt;Consider that the person is either fairly new to trading, or has been trading for a while and is looking for new tools and that this charts is going to be on a landing page.&lt;/p&gt;\n\n&lt;p&gt;Nr 1&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/dslbnopdb5x91.png?width=3308&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b70e8e1f0a8083f671dde7df01f0e712709c3d40\"&gt;https://preview.redd.it/dslbnopdb5x91.png?width=3308&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b70e8e1f0a8083f671dde7df01f0e712709c3d40&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Nr 2&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/tfalvv3cb5x91.png?width=2716&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f12977e690cfe21e0fedfacbd4e844a6feae0acc\"&gt;https://preview.redd.it/tfalvv3cb5x91.png?width=2716&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f12977e690cfe21e0fedfacbd4e844a6feae0acc&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yicrdu", "is_robot_indexable": true, "report_reasons": null, "author": "skogsraw", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yicrdu/which_of_these_2_visualisations_is_the_best/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yicrdu/which_of_these_2_visualisations_is_the_best/", "subreddit_subscribers": 816365, "created_utc": 1667224192.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone.  \n3 years ago, I graduated from a well renowned french school (ENSAE Paris) as a data scientist.  \nTo be honest, I managed to graduate thanks to good math grades but neglected anything that was applied.  \nI didn't want to work in a company and I liked maths, so I became a maths professor (I don't have a PhD but still teach at the grad level, things are different here from what you might be used to).   \nIronically though, I'm teaching numerical analysis using Python.  \nI only have 8 hours of teaching and a lot of free time on my hands and I was considering working as  a freelance datascientist, using my degree and my experience as a maths professor to my advantage.  \nAny insight is welcome. I will need an online data science course though and I want your suggestions on that one :).", "author_fullname": "t2_7ifvsf2p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "From maths teacher to freelance DS ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yhr8gw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667167171.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone.&lt;br/&gt;\n3 years ago, I graduated from a well renowned french school (ENSAE Paris) as a data scientist.&lt;br/&gt;\nTo be honest, I managed to graduate thanks to good math grades but neglected anything that was applied.&lt;br/&gt;\nI didn&amp;#39;t want to work in a company and I liked maths, so I became a maths professor (I don&amp;#39;t have a PhD but still teach at the grad level, things are different here from what you might be used to).&lt;br/&gt;\nIronically though, I&amp;#39;m teaching numerical analysis using Python.&lt;br/&gt;\nI only have 8 hours of teaching and a lot of free time on my hands and I was considering working as  a freelance datascientist, using my degree and my experience as a maths professor to my advantage.&lt;br/&gt;\nAny insight is welcome. I will need an online data science course though and I want your suggestions on that one :).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yhr8gw", "is_robot_indexable": true, "report_reasons": null, "author": "Benchedpresser", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yhr8gw/from_maths_teacher_to_freelance_ds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yhr8gw/from_maths_teacher_to_freelance_ds/", "subreddit_subscribers": 816365, "created_utc": 1667167171.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'll be finishing my PhD soon where I focussed on applying machine learning to domain problems in materials science. I was hoping that I'd be able to get some feedback from my CV, as I'm applying for what will be my first job soon and I wanted to make sure I was selling my experience in the best light (March 2024 is the final submission deadline but intend to finish earlier). Using a burner to post this as citing my publication record makes me identifiable and I don't want to link my publication record to my personal reddit account.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/lhp8qvlvv5x91.png?width=641&amp;format=png&amp;auto=webp&amp;s=0991b80f4c3b38cc5e2ee8233748109f86bf83b3", "author_fullname": "t2_tunusd2l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CV feedback request", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"lhp8qvlvv5x91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 172, "x": 108, "u": "https://preview.redd.it/lhp8qvlvv5x91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=75bb696faf0ca7ca42fe417d17c826848ba85195"}, {"y": 344, "x": 216, "u": "https://preview.redd.it/lhp8qvlvv5x91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=60d6990bdf7b8d961db0fb14cce245838537cf17"}, {"y": 509, "x": 320, "u": "https://preview.redd.it/lhp8qvlvv5x91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=79b663492c7004b3a1193efd0c2cdea8a76e3943"}, {"y": 1019, "x": 640, "u": "https://preview.redd.it/lhp8qvlvv5x91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=af45dbca17c4ec8744e869986acfa3f251804f9d"}], "s": {"y": 1021, "x": 641, "u": "https://preview.redd.it/lhp8qvlvv5x91.png?width=641&amp;format=png&amp;auto=webp&amp;s=0991b80f4c3b38cc5e2ee8233748109f86bf83b3"}, "id": "lhp8qvlvv5x91"}}, "name": "t3_yifmrz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/bxIyut7BXY3KjVq4XvbC51ZJbo4oVXRGux8IMt3dYy0.jpg", "edited": 1667231375.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667230968.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ll be finishing my PhD soon where I focussed on applying machine learning to domain problems in materials science. I was hoping that I&amp;#39;d be able to get some feedback from my CV, as I&amp;#39;m applying for what will be my first job soon and I wanted to make sure I was selling my experience in the best light (March 2024 is the final submission deadline but intend to finish earlier). Using a burner to post this as citing my publication record makes me identifiable and I don&amp;#39;t want to link my publication record to my personal reddit account.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/lhp8qvlvv5x91.png?width=641&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0991b80f4c3b38cc5e2ee8233748109f86bf83b3\"&gt;https://preview.redd.it/lhp8qvlvv5x91.png?width=641&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0991b80f4c3b38cc5e2ee8233748109f86bf83b3&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "yifmrz", "is_robot_indexable": true, "report_reasons": null, "author": "Resume_Burner_0461", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yifmrz/cv_feedback_request/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yifmrz/cv_feedback_request/", "subreddit_subscribers": 816365, "created_utc": 1667230968.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Intro to Kestra: Open-Source Orchestration and Scheduling Platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_yiffzb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_2rku02rf", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/rsZU_XKIA1X35drrHOdJYJN7dES0AYUDwb8KNqxGP_8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2rku02rf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Intro to Kestra: Open-Source Orchestration and Scheduling Platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_yi7elp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/rsZU_XKIA1X35drrHOdJYJN7dES0AYUDwb8KNqxGP_8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667211718.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/geekculture/intro-to-kestra-open-source-orchestration-and-scheduling-platform-a712f5238491", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MxJAxFI1-2vKTW3Arg0zPDbx06GgohPDCz4nmFynJ4k.jpg?auto=webp&amp;s=778f617d7f7a972eb57b20ef33e2c370f8cc30c0", "width": 800, "height": 450}, "resolutions": [{"url": "https://external-preview.redd.it/MxJAxFI1-2vKTW3Arg0zPDbx06GgohPDCz4nmFynJ4k.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5e4ebe488a3ebad22085af5914a64be16dca0ec2", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/MxJAxFI1-2vKTW3Arg0zPDbx06GgohPDCz4nmFynJ4k.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cd96ef8f3a6359d9afe08b4a74895d35f74735f3", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/MxJAxFI1-2vKTW3Arg0zPDbx06GgohPDCz4nmFynJ4k.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9872dd18aa6970dd461a7406115369c8ef80b14e", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/MxJAxFI1-2vKTW3Arg0zPDbx06GgohPDCz4nmFynJ4k.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a84d91db55c8a125f03590c68927e33a3e94a61a", "width": 640, "height": 360}], "variants": {}, "id": "OIa0U7Tn174Oq36_iYG2t9yb-XxrFBgBisPejYOFvU0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "yi7elp", "is_robot_indexable": true, "report_reasons": null, "author": "tchiotludo", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yi7elp/intro_to_kestra_opensource_orchestration_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/geekculture/intro-to-kestra-open-source-orchestration-and-scheduling-platform-a712f5238491", "subreddit_subscribers": 78446, "created_utc": 1667211718.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1667230526.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/geekculture/intro-to-kestra-open-source-orchestration-and-scheduling-platform-a712f5238491", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MxJAxFI1-2vKTW3Arg0zPDbx06GgohPDCz4nmFynJ4k.jpg?auto=webp&amp;s=778f617d7f7a972eb57b20ef33e2c370f8cc30c0", "width": 800, "height": 450}, "resolutions": [{"url": "https://external-preview.redd.it/MxJAxFI1-2vKTW3Arg0zPDbx06GgohPDCz4nmFynJ4k.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5e4ebe488a3ebad22085af5914a64be16dca0ec2", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/MxJAxFI1-2vKTW3Arg0zPDbx06GgohPDCz4nmFynJ4k.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cd96ef8f3a6359d9afe08b4a74895d35f74735f3", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/MxJAxFI1-2vKTW3Arg0zPDbx06GgohPDCz4nmFynJ4k.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9872dd18aa6970dd461a7406115369c8ef80b14e", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/MxJAxFI1-2vKTW3Arg0zPDbx06GgohPDCz4nmFynJ4k.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a84d91db55c8a125f03590c68927e33a3e94a61a", "width": 640, "height": 360}], "variants": {}, "id": "OIa0U7Tn174Oq36_iYG2t9yb-XxrFBgBisPejYOFvU0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yiffzb", "is_robot_indexable": true, "report_reasons": null, "author": "tchiotludo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_yi7elp", "author_flair_text_color": null, "permalink": "/r/datascience/comments/yiffzb/intro_to_kestra_opensource_orchestration_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/geekculture/intro-to-kestra-open-source-orchestration-and-scheduling-platform-a712f5238491", "subreddit_subscribers": 816365, "created_utc": 1667230526.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My hypothesis is \"students' performance on their history module will be predicted by their level of both history anxiety and general anxiety. Both types of anxiety should have a negative relationship with performance on the history assignment.\"\n\nAs we can see, I have 3 variables; student performance, history anxiety and general anxiety.\n\nI will use r studio to analyse and interpret the data.\n\nI'm thinking that a multiple regression linear model would be suitable for this, because there are more than two variables affecting the other variable. Is that correct?\n\nThank you for anyone who reads. If I win the cost of living bursary I'll send you pictures of my lentils.", "author_fullname": "t2_rciihogo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can anyone advise me on which statistical model to use for my data analysis?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yifak0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667230190.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My hypothesis is &amp;quot;students&amp;#39; performance on their history module will be predicted by their level of both history anxiety and general anxiety. Both types of anxiety should have a negative relationship with performance on the history assignment.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;As we can see, I have 3 variables; student performance, history anxiety and general anxiety.&lt;/p&gt;\n\n&lt;p&gt;I will use r studio to analyse and interpret the data.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking that a multiple regression linear model would be suitable for this, because there are more than two variables affecting the other variable. Is that correct?&lt;/p&gt;\n\n&lt;p&gt;Thank you for anyone who reads. If I win the cost of living bursary I&amp;#39;ll send you pictures of my lentils.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yifak0", "is_robot_indexable": true, "report_reasons": null, "author": "daisiesaremyfavise", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yifak0/can_anyone_advise_me_on_which_statistical_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yifak0/can_anyone_advise_me_on_which_statistical_model/", "subreddit_subscribers": 816365, "created_utc": 1667230190.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "R package: https://github.com/AndreaCirilloAC/paletter", "author_fullname": "t2_hoj6m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there python library equivalent of paletteR for color palette analysis/visualization?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yif9i8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667230123.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;R package: &lt;a href=\"https://github.com/AndreaCirilloAC/paletter\"&gt;https://github.com/AndreaCirilloAC/paletter&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_bNilZN8FyZNEgWM_DjDge-BJNAvPqNkVMd19daTgR4.jpg?auto=webp&amp;s=ca1e596fc1ebe4c527f1e6972fb215c602dbf521", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/_bNilZN8FyZNEgWM_DjDge-BJNAvPqNkVMd19daTgR4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fd293c0bec4277c8f970709ef04f6062b92e3487", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/_bNilZN8FyZNEgWM_DjDge-BJNAvPqNkVMd19daTgR4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e39381c4b387e423c3d8203a89335f9eece100bb", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/_bNilZN8FyZNEgWM_DjDge-BJNAvPqNkVMd19daTgR4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=63d4a361f75e16567bc08b90f64154586935f748", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/_bNilZN8FyZNEgWM_DjDge-BJNAvPqNkVMd19daTgR4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9bbbed3459004b0510a64e20e818db1a67ee6713", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/_bNilZN8FyZNEgWM_DjDge-BJNAvPqNkVMd19daTgR4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b2259e0e0cbc2cb0f4646dfba85b363fe2705239", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/_bNilZN8FyZNEgWM_DjDge-BJNAvPqNkVMd19daTgR4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2cbaf3f8369f7fe975c9bd11c53867fca460dab7", "width": 1080, "height": 540}], "variants": {}, "id": "eXJPwTdMCkMbCRvV2mf3Us321___OryYv-IAmtnBIw4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yif9i8", "is_robot_indexable": true, "report_reasons": null, "author": "canopey", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yif9i8/is_there_python_library_equivalent_of_paletter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yif9i8/is_there_python_library_equivalent_of_paletter/", "subreddit_subscribers": 816365, "created_utc": 1667230123.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_arv2qu36", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Image classification using TensorFlow sequential model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_yif8bt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/O7294PV2O7I?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Image classification using TensorFlow sequential model\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Image classification using TensorFlow sequential model", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/O7294PV2O7I?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Image classification using TensorFlow sequential model\"&gt;&lt;/iframe&gt;", "author_name": "ColorLeaves Technology", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/O7294PV2O7I/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/channel/UCMZK37f6jFyC6KjvjXH73MA"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/O7294PV2O7I?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Image classification using TensorFlow sequential model\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/yif8bt", "height": 200}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/cOdx-icuxVakb_inB0unE7f_7JZ2XQ30gOWf8hvxkGo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667230044.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://youtube.com/watch?v=O7294PV2O7I&amp;feature=share", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/X7AfX-asf1duQlTGHEFsvBL11DLBk1pY5l7jLYgWa3c.jpg?auto=webp&amp;s=196be5c3ab943dfab1fa68f465251cb647949ca1", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/X7AfX-asf1duQlTGHEFsvBL11DLBk1pY5l7jLYgWa3c.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=418099f7b074c9c6ed26c5047e55d58e2bef5fd8", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/X7AfX-asf1duQlTGHEFsvBL11DLBk1pY5l7jLYgWa3c.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a99a284b43046c3125f922a5072fc44db8397dd1", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/X7AfX-asf1duQlTGHEFsvBL11DLBk1pY5l7jLYgWa3c.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=830f297766367c521bc29d55f1b753a3ebb23383", "width": 320, "height": 240}], "variants": {}, "id": "GmNswuXVIKbJ2HgCiZPp-idKAuktgHkgLPW9SNXY6zg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "yif8bt", "is_robot_indexable": true, "report_reasons": null, "author": "Prestigious-Emu-911", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yif8bt/image_classification_using_tensorflow_sequential/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtube.com/watch?v=O7294PV2O7I&amp;feature=share", "subreddit_subscribers": 816365, "created_utc": 1667230044.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Image classification using TensorFlow sequential model", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/O7294PV2O7I?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Image classification using TensorFlow sequential model\"&gt;&lt;/iframe&gt;", "author_name": "ColorLeaves Technology", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/O7294PV2O7I/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/channel/UCMZK37f6jFyC6KjvjXH73MA"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey all, had some q's related to bayesian inference and using it for generic business ab testing (ex: what version of an ad has a higher click rate, what type of sales page produces more revenue, etc.).\n\nI have some experience using beta and binomial distributions for this type of task when the metric of interest is a conversion rate, but I generally don't see a lot of examples where the metric of interest isn't a rate online.\n\nMy questions would be:\n\n1. Does anyone have any good resources (preferably in R) of using Bayesian inference in an ab testing framework that isn't solely focused on using beta and binomial distributions? I want to be more prepared for metrics that aren't conversion rates. Could be blog posts or books, but ideally would be showing examples that were focused on experimentation / ab testing\n\n2. Is a language like stan overkill for bayesian ab testing? Doing a bit of research, it seems a bit unnecessary for creating a posterior off a beta prior and binomial likelihood, but not sure about other use cases. I guess this answer might be it depends, but worth asking", "author_fullname": "t2_hlgt6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Couple of general questions on using bayesian inference for experimentation / ab testing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yidy50", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667227056.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, had some q&amp;#39;s related to bayesian inference and using it for generic business ab testing (ex: what version of an ad has a higher click rate, what type of sales page produces more revenue, etc.).&lt;/p&gt;\n\n&lt;p&gt;I have some experience using beta and binomial distributions for this type of task when the metric of interest is a conversion rate, but I generally don&amp;#39;t see a lot of examples where the metric of interest isn&amp;#39;t a rate online.&lt;/p&gt;\n\n&lt;p&gt;My questions would be:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Does anyone have any good resources (preferably in R) of using Bayesian inference in an ab testing framework that isn&amp;#39;t solely focused on using beta and binomial distributions? I want to be more prepared for metrics that aren&amp;#39;t conversion rates. Could be blog posts or books, but ideally would be showing examples that were focused on experimentation / ab testing&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Is a language like stan overkill for bayesian ab testing? Doing a bit of research, it seems a bit unnecessary for creating a posterior off a beta prior and binomial likelihood, but not sure about other use cases. I guess this answer might be it depends, but worth asking&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yidy50", "is_robot_indexable": true, "report_reasons": null, "author": "royhibbertnicekisser", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yidy50/couple_of_general_questions_on_using_bayesian/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yidy50/couple_of_general_questions_on_using_bayesian/", "subreddit_subscribers": 816365, "created_utc": 1667227056.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_yuq89", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Low-Code Data Apps with FastAPI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_yidvbx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/YXSdgI25BVgmvAru3JsXzIgA6w6ij0OB9Nv_GL1mO4Y.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667226875.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "komputee.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://komputee.com/product", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/zXFOmjbQ8pCqBjLvF3JObmtpDRAND3IU8zuvOCSjaXo.jpg?auto=webp&amp;s=284dc0ba8e08dbf6ce036b7005745ecc9597b837", "width": 2732, "height": 1536}, "resolutions": [{"url": "https://external-preview.redd.it/zXFOmjbQ8pCqBjLvF3JObmtpDRAND3IU8zuvOCSjaXo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7426793a47a8e7492f6226957ac1c2b36bf4340b", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/zXFOmjbQ8pCqBjLvF3JObmtpDRAND3IU8zuvOCSjaXo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=595cfbc30331918771ed5480b68689a12ebdd56b", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/zXFOmjbQ8pCqBjLvF3JObmtpDRAND3IU8zuvOCSjaXo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=191cb0773d5a9b767505080f1288361664f08c0a", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/zXFOmjbQ8pCqBjLvF3JObmtpDRAND3IU8zuvOCSjaXo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0c9e2610962b31546bdb26d119e81b17c2bf574e", "width": 640, "height": 359}, {"url": "https://external-preview.redd.it/zXFOmjbQ8pCqBjLvF3JObmtpDRAND3IU8zuvOCSjaXo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=42449fb3d545f8732baaa3f0e5e2e5ba77aab622", "width": 960, "height": 539}, {"url": "https://external-preview.redd.it/zXFOmjbQ8pCqBjLvF3JObmtpDRAND3IU8zuvOCSjaXo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9b6461f36f73b34895ebf881647d95c3088ffbb3", "width": 1080, "height": 607}], "variants": {}, "id": "BUKgG5FXnDOuDa9JW-WMMcm2FHu2bIZGPWkOXRzD49Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "yidvbx", "is_robot_indexable": true, "report_reasons": null, "author": "luxdav", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yidvbx/lowcode_data_apps_with_fastapi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://komputee.com/product", "subreddit_subscribers": 816365, "created_utc": 1667226875.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm looking to validate my new SaaS idea so sharing the landing page to see if I can build some interest.\n\n&amp;#x200B;\n\nKiku Labs offers a way to get Jupyter Labs with powerful compute and storage for experimenting with your data science projects. The labs are saved and restored between sessions, and you're charged based on the usage.\n\n&amp;#x200B;\n\nFeel free to ask any questions.\n\n&amp;#x200B;\n\nPlease join the waiting list if you're interested in the product.\n\n&amp;#x200B;\n\n[https://kikulabs.com/](https://kikulabs.com/)", "author_fullname": "t2_tuiywd33", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Serverless Jupyter Labs with GPUs, CPUs and high-speed storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yibecy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667221181.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking to validate my new SaaS idea so sharing the landing page to see if I can build some interest.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Kiku Labs offers a way to get Jupyter Labs with powerful compute and storage for experimenting with your data science projects. The labs are saved and restored between sessions, and you&amp;#39;re charged based on the usage.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Feel free to ask any questions.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Please join the waiting list if you&amp;#39;re interested in the product.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://kikulabs.com/\"&gt;https://kikulabs.com/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/63NNkAhQfoBQJoMLfbjQFSekbAQUgiNgKCbB9TQTAqk.jpg?auto=webp&amp;s=c61740351bcf994a3249b92e648bc233a6fbc831", "width": 1601, "height": 330}, "resolutions": [{"url": "https://external-preview.redd.it/63NNkAhQfoBQJoMLfbjQFSekbAQUgiNgKCbB9TQTAqk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f1ff9cd77f9224f5d5624be44f289c6f7180d9fd", "width": 108, "height": 22}, {"url": "https://external-preview.redd.it/63NNkAhQfoBQJoMLfbjQFSekbAQUgiNgKCbB9TQTAqk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9a624845b1e4c47e9eebe267cfcb47d54b66f7c3", "width": 216, "height": 44}, {"url": "https://external-preview.redd.it/63NNkAhQfoBQJoMLfbjQFSekbAQUgiNgKCbB9TQTAqk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5f600031701e00db8bab98bbd92eb892fc38cf3e", "width": 320, "height": 65}, {"url": "https://external-preview.redd.it/63NNkAhQfoBQJoMLfbjQFSekbAQUgiNgKCbB9TQTAqk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=334bc0c6aba9753ddea7876ca2d56fc11b107110", "width": 640, "height": 131}, {"url": "https://external-preview.redd.it/63NNkAhQfoBQJoMLfbjQFSekbAQUgiNgKCbB9TQTAqk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=dc00e7375674078f1daa8a7d72a9aed6f7a465b1", "width": 960, "height": 197}, {"url": "https://external-preview.redd.it/63NNkAhQfoBQJoMLfbjQFSekbAQUgiNgKCbB9TQTAqk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4f29efecc78eb7cd8fa7dae342648719072f56ad", "width": 1080, "height": 222}], "variants": {}, "id": "m_OMKuNpve1NGQyr3sOc0CopfucLSsi0RXLj-1xXxcM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yibecy", "is_robot_indexable": true, "report_reasons": null, "author": "kikulabs", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yibecy/serverless_jupyter_labs_with_gpus_cpus_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yibecy/serverless_jupyter_labs_with_gpus_cpus_and/", "subreddit_subscribers": 816365, "created_utc": 1667221181.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone, I\u2019m not sure if this is the right place to ask. But, is anyone familiar with a website where I can see an accounts Twitter followers on a specific date? Such as Amazons followers on 1/1/2019? I need to collect this data for an econometrics data set. Thank you!", "author_fullname": "t2_jddu3cu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yi0b69", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667189317.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I\u2019m not sure if this is the right place to ask. But, is anyone familiar with a website where I can see an accounts Twitter followers on a specific date? Such as Amazons followers on 1/1/2019? I need to collect this data for an econometrics data set. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yi0b69", "is_robot_indexable": true, "report_reasons": null, "author": "Virtuosonic", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yi0b69/data_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yi0b69/data_help/", "subreddit_subscribers": 816365, "created_utc": 1667189317.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\nI'm currently in an analytics role and trying to dive into more sophisticated ways of looking at our company's data. One of the ways I was exploring was applying clustering (such as k-means) to time-series data. The only issue is that my object is to find \"users\" and \"devices\" that are anomalous based on hourly traffic. I also have other columns such as \"geo\" as well as some proprietary labels (but the main two are user device combinations)\n\nMy issue is that anytime i attempt to run a clustering algo in Python, the algo just clusters data into it's hourly buckets and I'm not really able to find anything insightful. I spoke to a data scientist who suggested I do the following:\n\n1. scale the data down using a scaling method such as min-max scaler(some users/devices will have much more traffic than others)\n2. Use time pattern as a feature\n\nI don't understand how to do this.\n\nFor example, this is a dummy version of how my table looks like:\n\n&amp;#x200B;\n\nhttps://preview.redd.it/oq81i0ube2x91.png?width=250&amp;format=png&amp;auto=webp&amp;s=69215e678310c61904386207593df11ad0b797be\n\nI think what I'm trying to figure out is how to take that data and turn it into a feature:\n\n{\n\n\"user / device\" : a / roku,\n\n\"timeOfHour\" : 1\n\n\"traffic\" : 100\n\n... and so forth\n\n}\n\nI'm just stuck and not sure the best place. I also tried reading up on papers but my problem seems fairly unique and I can't seem to find a reference point. Does this seem like the right approach?\n\nLastly, when running scalers, am I supposed to run the scaler against ALL of the data? For example, when I applied the robust scaler in sklearn to my data, the end result looked the same when i plotted my charts. My goal is to bring all of the smaller user/device combinations that may have a fraction of the traffic as the top user/devices on the same scale and I'm not sure how to do this. \n\nAny help/tips would be greatly appreciate and I apologize if the above sounds a bit messy!", "author_fullname": "t2_79jdi5ck", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Clustering on Hourly Data with Labels", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 50, "top_awarded_type": null, "hide_score": false, "media_metadata": {"oq81i0ube2x91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 39, "x": 108, "u": "https://preview.redd.it/oq81i0ube2x91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=930c9b7156e0159ac8c0c9de7654ac4155d7ee69"}, {"y": 78, "x": 216, "u": "https://preview.redd.it/oq81i0ube2x91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=830504dfcb785bca415163cdcd039dd326d6e2e5"}], "s": {"y": 91, "x": 250, "u": "https://preview.redd.it/oq81i0ube2x91.png?width=250&amp;format=png&amp;auto=webp&amp;s=69215e678310c61904386207593df11ad0b797be"}, "id": "oq81i0ube2x91"}}, "name": "t3_yi0618", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/eSuqHwuSZ28QmmLE3LbU2c_bCMIwcdm1hucOLNOqAfI.jpg", "edited": 1667190316.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667188884.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently in an analytics role and trying to dive into more sophisticated ways of looking at our company&amp;#39;s data. One of the ways I was exploring was applying clustering (such as k-means) to time-series data. The only issue is that my object is to find &amp;quot;users&amp;quot; and &amp;quot;devices&amp;quot; that are anomalous based on hourly traffic. I also have other columns such as &amp;quot;geo&amp;quot; as well as some proprietary labels (but the main two are user device combinations)&lt;/p&gt;\n\n&lt;p&gt;My issue is that anytime i attempt to run a clustering algo in Python, the algo just clusters data into it&amp;#39;s hourly buckets and I&amp;#39;m not really able to find anything insightful. I spoke to a data scientist who suggested I do the following:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;scale the data down using a scaling method such as min-max scaler(some users/devices will have much more traffic than others)&lt;/li&gt;\n&lt;li&gt;Use time pattern as a feature&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I don&amp;#39;t understand how to do this.&lt;/p&gt;\n\n&lt;p&gt;For example, this is a dummy version of how my table looks like:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/oq81i0ube2x91.png?width=250&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=69215e678310c61904386207593df11ad0b797be\"&gt;https://preview.redd.it/oq81i0ube2x91.png?width=250&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=69215e678310c61904386207593df11ad0b797be&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I think what I&amp;#39;m trying to figure out is how to take that data and turn it into a feature:&lt;/p&gt;\n\n&lt;p&gt;{&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;user / device&amp;quot; : a / roku,&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;timeOfHour&amp;quot; : 1&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;traffic&amp;quot; : 100&lt;/p&gt;\n\n&lt;p&gt;... and so forth&lt;/p&gt;\n\n&lt;p&gt;}&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m just stuck and not sure the best place. I also tried reading up on papers but my problem seems fairly unique and I can&amp;#39;t seem to find a reference point. Does this seem like the right approach?&lt;/p&gt;\n\n&lt;p&gt;Lastly, when running scalers, am I supposed to run the scaler against ALL of the data? For example, when I applied the robust scaler in sklearn to my data, the end result looked the same when i plotted my charts. My goal is to bring all of the smaller user/device combinations that may have a fraction of the traffic as the top user/devices on the same scale and I&amp;#39;m not sure how to do this. &lt;/p&gt;\n\n&lt;p&gt;Any help/tips would be greatly appreciate and I apologize if the above sounds a bit messy!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yi0618", "is_robot_indexable": true, "report_reasons": null, "author": "goku_4110", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yi0618/clustering_on_hourly_data_with_labels/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yi0618/clustering_on_hourly_data_with_labels/", "subreddit_subscribers": 816365, "created_utc": 1667188884.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all, I\u2019m a mathematics major in my last year for my bachelor\u2019s and I\u2019m interested in going into data analytics/ data science for my career. I\u2019m debating whether or not to add an applied stats minor to my curriculum, which evens out to four classes a quarter till graduation. The necessary classes will be on sampling surveys and biostatistics. The drawback is that this will really take a toll on me since I do 3 hour round trip commutes to get to school and I work part-time as well. I\u2019d like to know if I can learn these applied skills on my own time via projects and certifications but I feel having an applied stats minor may look better on a resume. But I\u2019d like to leave it up to the more knowledgeable people in this sub: is it worth the perseverance to get the minor or should I devote any extra time I have to polishing my skills in programming and projects? Thanks, all.", "author_fullname": "t2_5j4buy7j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Applied Stats Minor?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yhpc85", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667162555.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I\u2019m a mathematics major in my last year for my bachelor\u2019s and I\u2019m interested in going into data analytics/ data science for my career. I\u2019m debating whether or not to add an applied stats minor to my curriculum, which evens out to four classes a quarter till graduation. The necessary classes will be on sampling surveys and biostatistics. The drawback is that this will really take a toll on me since I do 3 hour round trip commutes to get to school and I work part-time as well. I\u2019d like to know if I can learn these applied skills on my own time via projects and certifications but I feel having an applied stats minor may look better on a resume. But I\u2019d like to leave it up to the more knowledgeable people in this sub: is it worth the perseverance to get the minor or should I devote any extra time I have to polishing my skills in programming and projects? Thanks, all.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yhpc85", "is_robot_indexable": true, "report_reasons": null, "author": "sylargrey15", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yhpc85/applied_stats_minor/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yhpc85/applied_stats_minor/", "subreddit_subscribers": 816365, "created_utc": 1667162555.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I  am currently in my last year of masters in data science, and i was lucky enough to find an internship for my last semester. Data science and machine learning are pretty new domains in my country  it is studied  theoretically at universities and basically non existant in companies. Our supervisor gave us a subject of study , and told us to start doing research .He avoids our questions when asked about data availability.  I know from the experience of other students that companies are reluctent to give data to interns. But without data there's no end of studies' project and no degree.\n\n What can i tell them to convince them that i'm not a data thief? I know that data can be modified, and protected but i really don't know what to tell them.", "author_fullname": "t2_ccp5jozq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data science internship without data ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yhma07", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667155186.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I  am currently in my last year of masters in data science, and i was lucky enough to find an internship for my last semester. Data science and machine learning are pretty new domains in my country  it is studied  theoretically at universities and basically non existant in companies. Our supervisor gave us a subject of study , and told us to start doing research .He avoids our questions when asked about data availability.  I know from the experience of other students that companies are reluctent to give data to interns. But without data there&amp;#39;s no end of studies&amp;#39; project and no degree.&lt;/p&gt;\n\n&lt;p&gt;What can i tell them to convince them that i&amp;#39;m not a data thief? I know that data can be modified, and protected but i really don&amp;#39;t know what to tell them.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yhma07", "is_robot_indexable": true, "report_reasons": null, "author": "Acrobatic_Local_9115", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yhma07/data_science_internship_without_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yhma07/data_science_internship_without_data/", "subreddit_subscribers": 816365, "created_utc": 1667155186.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\n&amp;#x200B;\n\nI'm looking for some advice. I am currently pursuing a B.S. in Applied Mathematics and Physics. However, after a shift of interest, I will be dropping my physics major. I decided to study data science for a year abroad and realized that data science is a career path I want to pursue. I studied introductions to machine learning, data mining, regression, data structures... all using R. Prior to my change in interest, my goal was to pursue a PhD in physics at a top university but now I want to pursue a PhD in data science. I currently am a 6th year student graduating next semester. I currently have a plethora of mathematics and physics courses underneath my belt. I also happen to have co-authored a physics paper in Materials Science and have a decent amount of research experience. My particular areas of research interests (physics and financial engineering) just so happens to be offered at Ivy league schools. In my opinion, I think it is a bit impractical to assume I have a fighting chance at getting offered a PhD position at these universities (Cornell, Columbia, Yale, Stanford, etc...). I do not have a ton of experience in Data Science. Would it be more practical to pursue a masters and obtain more work / research experience before considering a PhD position? I guess an alternative question is: how would I be able to make myself sufficiently competitive to pursue a good Data Science masters / PhD? There are tons of Data Science graduate programs and I'm having some trouble finding applicable ones for me considering graduate application deadlines are around the corner.", "author_fullname": "t2_9ludzebd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Math Bachelors -&gt; Data Science PhD / Masters", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yhm6qz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667154957.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for some advice. I am currently pursuing a B.S. in Applied Mathematics and Physics. However, after a shift of interest, I will be dropping my physics major. I decided to study data science for a year abroad and realized that data science is a career path I want to pursue. I studied introductions to machine learning, data mining, regression, data structures... all using R. Prior to my change in interest, my goal was to pursue a PhD in physics at a top university but now I want to pursue a PhD in data science. I currently am a 6th year student graduating next semester. I currently have a plethora of mathematics and physics courses underneath my belt. I also happen to have co-authored a physics paper in Materials Science and have a decent amount of research experience. My particular areas of research interests (physics and financial engineering) just so happens to be offered at Ivy league schools. In my opinion, I think it is a bit impractical to assume I have a fighting chance at getting offered a PhD position at these universities (Cornell, Columbia, Yale, Stanford, etc...). I do not have a ton of experience in Data Science. Would it be more practical to pursue a masters and obtain more work / research experience before considering a PhD position? I guess an alternative question is: how would I be able to make myself sufficiently competitive to pursue a good Data Science masters / PhD? There are tons of Data Science graduate programs and I&amp;#39;m having some trouble finding applicable ones for me considering graduate application deadlines are around the corner.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yhm6qz", "is_robot_indexable": true, "report_reasons": null, "author": "Ronanwar1", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yhm6qz/math_bachelors_data_science_phd_masters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yhm6qz/math_bachelors_data_science_phd_masters/", "subreddit_subscribers": 816365, "created_utc": 1667154957.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys!\n\nWanted to ask for directions and advice on how to run MySQL in the docker.  \nCreated a python script and app using it. Everything is just fine, but need to save the output in the DataBase and the company I work for uses MySQL. Can anyone help me set it up or show me where I can learn how?\n\n&amp;#x200B;\n\nKind regards,\n\nyour friendly engineer who's trying to learn DS.", "author_fullname": "t2_fmamadvj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Connect MySQL within the Docker", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yibqx2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667221891.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys!&lt;/p&gt;\n\n&lt;p&gt;Wanted to ask for directions and advice on how to run MySQL in the docker.&lt;br/&gt;\nCreated a python script and app using it. Everything is just fine, but need to save the output in the DataBase and the company I work for uses MySQL. Can anyone help me set it up or show me where I can learn how?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Kind regards,&lt;/p&gt;\n\n&lt;p&gt;your friendly engineer who&amp;#39;s trying to learn DS.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yibqx2", "is_robot_indexable": true, "report_reasons": null, "author": "FoxSinofSloth", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yibqx2/connect_mysql_within_the_docker/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yibqx2/connect_mysql_within_the_docker/", "subreddit_subscribers": 816365, "created_utc": 1667221891.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am looking for a python implementation of the following package\n\n[https://cran.r-project.org/web/packages/REBayes/index.html](https://cran.r-project.org/web/packages/REBayes/index.html)\n\nDoes anybody know if any work has been done in that direction, any new projects which I can pick up and develop over?", "author_fullname": "t2_tug3kxep", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "python code for REBayes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yi9fcw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667216667.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for a python implementation of the following package&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://cran.r-project.org/web/packages/REBayes/index.html\"&gt;https://cran.r-project.org/web/packages/REBayes/index.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Does anybody know if any work has been done in that direction, any new projects which I can pick up and develop over?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pB1e8yz1zTb43ZiqoKLD274IjRAoCjsP2v3Vc7T4y-g.jpg?auto=webp&amp;s=c4f72fe22b48b58fd800bdfd40854f9d4795356d", "width": 1000, "height": 1000}, "resolutions": [{"url": "https://external-preview.redd.it/pB1e8yz1zTb43ZiqoKLD274IjRAoCjsP2v3Vc7T4y-g.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4fd8638ea9437c78a10b3c0c564e5bb832948e30", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/pB1e8yz1zTb43ZiqoKLD274IjRAoCjsP2v3Vc7T4y-g.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7c9cd285b61b7ffb42ec3638020ab2a3c85eba77", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/pB1e8yz1zTb43ZiqoKLD274IjRAoCjsP2v3Vc7T4y-g.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bc8b307e7f213cc80f2653af55ef133a49d4816c", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/pB1e8yz1zTb43ZiqoKLD274IjRAoCjsP2v3Vc7T4y-g.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7df0f5ad584edbfeb01c49a725d2fffc61b02982", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/pB1e8yz1zTb43ZiqoKLD274IjRAoCjsP2v3Vc7T4y-g.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3041f0ca594a60ca78abfe84f876986e8425747e", "width": 960, "height": 960}], "variants": {}, "id": "waPksA41N5JBFZxGzjQNz5ydY0PesgwsKnDU1nuwLrY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yi9fcw", "is_robot_indexable": true, "report_reasons": null, "author": "manishagarwal13", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yi9fcw/python_code_for_rebayes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yi9fcw/python_code_for_rebayes/", "subreddit_subscribers": 816365, "created_utc": 1667216667.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "There are many plotting libraries for Python. Which one do you prefer and why?", "author_fullname": "t2_67cz0s3n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Plotnine, Plotly, ALtair or Seaborn. Which one to use", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yi7ao4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667211432.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There are many plotting libraries for Python. Which one do you prefer and why?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yi7ao4", "is_robot_indexable": true, "report_reasons": null, "author": "TywinASOIAF", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yi7ao4/plotnine_plotly_altair_or_seaborn_which_one_to_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yi7ao4/plotnine_plotly_altair_or_seaborn_which_one_to_use/", "subreddit_subscribers": 816365, "created_utc": 1667211432.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}