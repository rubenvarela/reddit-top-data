{"kind": "Listing", "data": {"after": null, "dist": 21, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_7ck5p6ie", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "You SHALL pass...?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_yie8d0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 72, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 72, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/lnEk2tVYT4GtFCmGwB-tTq3n4ISEBUmNufbFl1q91z4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667227728.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/4qpxmtlhm5x91.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/4qpxmtlhm5x91.jpg?auto=webp&amp;s=78bde491c0fec85b4895bbc83cc4395779f3fe8e", "width": 570, "height": 672}, "resolutions": [{"url": "https://preview.redd.it/4qpxmtlhm5x91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=804267614c4a5fee3643f20aebe8a9b33271c42e", "width": 108, "height": 127}, {"url": "https://preview.redd.it/4qpxmtlhm5x91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=92e7086371a4f938dfa77991322aaf484688164f", "width": 216, "height": 254}, {"url": "https://preview.redd.it/4qpxmtlhm5x91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d1684153ec2b42034b0851416b046dcc1d7d2f79", "width": 320, "height": 377}], "variants": {}, "id": "GznJQugTORHUdG19qbwt5U38fSJolrmKEJBXgjGZdgA"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "yie8d0", "is_robot_indexable": true, "report_reasons": null, "author": "Happy-Destruction", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yie8d0/you_shall_pass/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/4qpxmtlhm5x91.jpg", "subreddit_subscribers": 78453, "created_utc": 1667227728.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_irftz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Every data engineer understands you need a clean and good looking \u2018data model\u2019 for the best report performance\u2026.happy Halloween!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_yhw7be", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "ups": 57, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 57, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/G7tubW8hB5hJA7FhU6ZK05t4jxXClnbXEejy6LfP0Yg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667177859.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/bk9d8p27i1x91.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/bk9d8p27i1x91.jpg?auto=webp&amp;s=7d0dc9b64174082f4bc60c1b33ea418ac1c0d6ad", "width": 1586, "height": 2947}, "resolutions": [{"url": "https://preview.redd.it/bk9d8p27i1x91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=97f6a9b2e7dc1ca594382c4c5ba836f2297d79a5", "width": 108, "height": 200}, {"url": "https://preview.redd.it/bk9d8p27i1x91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=de61e7dc6162533dbed3b19325a63a731a2e62b8", "width": 216, "height": 401}, {"url": "https://preview.redd.it/bk9d8p27i1x91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6503b111d647cd4bac941ee150c3e4f1bd20ea71", "width": 320, "height": 594}, {"url": "https://preview.redd.it/bk9d8p27i1x91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e3e1b38489ff32cdf0ede6795997f195f57ee131", "width": 640, "height": 1189}, {"url": "https://preview.redd.it/bk9d8p27i1x91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=817a37ddd31c98d974f030e973228014516047fb", "width": 960, "height": 1783}, {"url": "https://preview.redd.it/bk9d8p27i1x91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=070a47998f4a95e50328815cbb7292427d345ccc", "width": 1080, "height": 2006}], "variants": {}, "id": "9ktEd7qJtq6jdTUCEuC5dcgEHf9PubUsr2crnOD-LRw"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "yhw7be", "is_robot_indexable": true, "report_reasons": null, "author": "mutigers42", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yhw7be/every_data_engineer_understands_you_need_a_clean/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/bk9d8p27i1x91.jpg", "subreddit_subscribers": 78453, "created_utc": 1667177859.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do you have a review process for updating your models? Do you manually review all pull requests or do you have a CI/CD process for updating any (dbt) models? If so, how does it look like? Do you use DataFold or any other tool and what do you like and don't like about it? Any lessons learned?\n\nWe want to give a bit more autonomy to our data analysts and other stakeholders to create their own models, but want to ensure nothing breaks in the meanwhile. Curious to hear your experiences or best practices", "author_fullname": "t2_4hext4tv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CI/CD process for dbt models", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yi5ay3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667206052.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you have a review process for updating your models? Do you manually review all pull requests or do you have a CI/CD process for updating any (dbt) models? If so, how does it look like? Do you use DataFold or any other tool and what do you like and don&amp;#39;t like about it? Any lessons learned?&lt;/p&gt;\n\n&lt;p&gt;We want to give a bit more autonomy to our data analysts and other stakeholders to create their own models, but want to ensure nothing breaks in the meanwhile. Curious to hear your experiences or best practices&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yi5ay3", "is_robot_indexable": true, "report_reasons": null, "author": "mrmaestro1", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yi5ay3/cicd_process_for_dbt_models/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yi5ay3/cicd_process_for_dbt_models/", "subreddit_subscribers": 78453, "created_utc": 1667206052.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi r/dataengineering,\n\nI'm working on an experimental new spreadsheet, [dtable](https://dtable.dev/), that I think could be useful. It aims to bridge the gap between a programming environment and a spreadsheet. Formulas in **dtable** can connect to any API or database in a first-class manor.\n\nThe website and beta signup is here: [https://dtable.dev/](https://dtable.dev/).\nJoin the [discord](https://discord.gg/nNCjCK7NGN) if you're interested in following the progress.\n\n**Please share your thoughts below, I'd love to discuss.**\n\n---\n\n## More design details\n\n**dtable** leverages emerging innovations in language runtime isolation technology to allow running formulas as JavaScript functions on the server in a lightweight and secure manor. These formulas can query any API or backend. You can parameterize these queries using the typical cell reference semantics you're accustomed to in Excel/Google Sheets.\n\nThere are three kinds of formulas\n\n1. standard cell formulas: must return `T: string | number | boolean | null`\n2. column controller formulas: must return `T[]` that fills the column\n3. grid controller formulas: must return `T[][]` that fills an entire grid", "author_fullname": "t2_je56j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A spreadsheet built for data engineers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yhwems", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667178324.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt;,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working on an experimental new spreadsheet, &lt;a href=\"https://dtable.dev/\"&gt;dtable&lt;/a&gt;, that I think could be useful. It aims to bridge the gap between a programming environment and a spreadsheet. Formulas in &lt;strong&gt;dtable&lt;/strong&gt; can connect to any API or database in a first-class manor.&lt;/p&gt;\n\n&lt;p&gt;The website and beta signup is here: &lt;a href=\"https://dtable.dev/\"&gt;https://dtable.dev/&lt;/a&gt;.\nJoin the &lt;a href=\"https://discord.gg/nNCjCK7NGN\"&gt;discord&lt;/a&gt; if you&amp;#39;re interested in following the progress.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Please share your thoughts below, I&amp;#39;d love to discuss.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;h2&gt;More design details&lt;/h2&gt;\n\n&lt;p&gt;&lt;strong&gt;dtable&lt;/strong&gt; leverages emerging innovations in language runtime isolation technology to allow running formulas as JavaScript functions on the server in a lightweight and secure manor. These formulas can query any API or backend. You can parameterize these queries using the typical cell reference semantics you&amp;#39;re accustomed to in Excel/Google Sheets.&lt;/p&gt;\n\n&lt;p&gt;There are three kinds of formulas&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;standard cell formulas: must return &lt;code&gt;T: string | number | boolean | null&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;column controller formulas: must return &lt;code&gt;T[]&lt;/code&gt; that fills the column&lt;/li&gt;\n&lt;li&gt;grid controller formulas: must return &lt;code&gt;T[][]&lt;/code&gt; that fills an entire grid&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yhwems", "is_robot_indexable": true, "report_reasons": null, "author": "mendturtle", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yhwems/a_spreadsheet_built_for_data_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yhwems/a_spreadsheet_built_for_data_engineers/", "subreddit_subscribers": 78453, "created_utc": 1667178324.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Everyone,\n\nI am trying to study for either **Databricks Certified Associate Developer for Apache Spark** or **Databricks Certified Data Engineer Professional**. \n\nAnd I have passed **Google Cloud Professional Data Engineer** recently. I am wondering which one should I get if I want to focus to get Spark knowledge. I heard **Databricks Certified Data Engineer Professional** also covers Spark materials.", "author_fullname": "t2_8big8125", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which Databrick certification I should get?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yi10k6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667191544.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone,&lt;/p&gt;\n\n&lt;p&gt;I am trying to study for either &lt;strong&gt;Databricks Certified Associate Developer for Apache Spark&lt;/strong&gt; or &lt;strong&gt;Databricks Certified Data Engineer Professional&lt;/strong&gt;. &lt;/p&gt;\n\n&lt;p&gt;And I have passed &lt;strong&gt;Google Cloud Professional Data Engineer&lt;/strong&gt; recently. I am wondering which one should I get if I want to focus to get Spark knowledge. I heard &lt;strong&gt;Databricks Certified Data Engineer Professional&lt;/strong&gt; also covers Spark materials.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yi10k6", "is_robot_indexable": true, "report_reasons": null, "author": "Fearless_Card_5611", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yi10k6/which_databrick_certification_i_should_get/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yi10k6/which_databrick_certification_i_should_get/", "subreddit_subscribers": 78453, "created_utc": 1667191544.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_ihzzw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can PowerBI Cloud Service \"be a data warehouse\"?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yia41a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1667218287.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "reddit.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/r/PowerBI/comments/yi9wm7/odd_data_warehouse_question/?utm_source=share&amp;utm_medium=android_app&amp;utm_name=androidcss&amp;utm_term=1&amp;utm_content=share_button", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yia41a", "is_robot_indexable": true, "report_reasons": null, "author": "CorpusCalossum", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yia41a/can_powerbi_cloud_service_be_a_data_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/PowerBI/comments/yi9wm7/odd_data_warehouse_question/?utm_source=share&amp;utm_medium=android_app&amp;utm_name=androidcss&amp;utm_term=1&amp;utm_content=share_button", "subreddit_subscribers": 78453, "created_utc": 1667218287.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m running airflow on composer.\nI have a Dag that:\n\n1-fetches large json from an api\n2-writes the json to a file in GCS\n3-reads the file and do transformations \n4-writes the result to a new file on GCS\n\nMy dag keeps stoping at step 3 with a message of type SIGKILL.\n\nHow can I solve such an issue ?\nWhat are the best practices on passing data between tasks in such a manner ?\n\nThank you", "author_fullname": "t2_98269xyy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow - Passing large data volumes between tasks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yhlxei", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667154317.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m running airflow on composer.\nI have a Dag that:&lt;/p&gt;\n\n&lt;p&gt;1-fetches large json from an api\n2-writes the json to a file in GCS\n3-reads the file and do transformations \n4-writes the result to a new file on GCS&lt;/p&gt;\n\n&lt;p&gt;My dag keeps stoping at step 3 with a message of type SIGKILL.&lt;/p&gt;\n\n&lt;p&gt;How can I solve such an issue ?\nWhat are the best practices on passing data between tasks in such a manner ?&lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yhlxei", "is_robot_indexable": true, "report_reasons": null, "author": "Electronic-Mountain9", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yhlxei/airflow_passing_large_data_volumes_between_tasks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yhlxei/airflow_passing_large_data_volumes_between_tasks/", "subreddit_subscribers": 78453, "created_utc": 1667154317.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2rku02rf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Intro to Kestra: Open-Source Orchestration and Scheduling Platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_yi7elp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/rsZU_XKIA1X35drrHOdJYJN7dES0AYUDwb8KNqxGP_8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667211718.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/geekculture/intro-to-kestra-open-source-orchestration-and-scheduling-platform-a712f5238491", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MxJAxFI1-2vKTW3Arg0zPDbx06GgohPDCz4nmFynJ4k.jpg?auto=webp&amp;s=778f617d7f7a972eb57b20ef33e2c370f8cc30c0", "width": 800, "height": 450}, "resolutions": [{"url": "https://external-preview.redd.it/MxJAxFI1-2vKTW3Arg0zPDbx06GgohPDCz4nmFynJ4k.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5e4ebe488a3ebad22085af5914a64be16dca0ec2", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/MxJAxFI1-2vKTW3Arg0zPDbx06GgohPDCz4nmFynJ4k.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cd96ef8f3a6359d9afe08b4a74895d35f74735f3", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/MxJAxFI1-2vKTW3Arg0zPDbx06GgohPDCz4nmFynJ4k.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9872dd18aa6970dd461a7406115369c8ef80b14e", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/MxJAxFI1-2vKTW3Arg0zPDbx06GgohPDCz4nmFynJ4k.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a84d91db55c8a125f03590c68927e33a3e94a61a", "width": 640, "height": 360}], "variants": {}, "id": "OIa0U7Tn174Oq36_iYG2t9yb-XxrFBgBisPejYOFvU0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "yi7elp", "is_robot_indexable": true, "report_reasons": null, "author": "tchiotludo", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yi7elp/intro_to_kestra_opensource_orchestration_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/geekculture/intro-to-kestra-open-source-orchestration-and-scheduling-platform-a712f5238491", "subreddit_subscribers": 78453, "created_utc": 1667211718.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have this stupid HR system with a prohibitively expensive API. They're sending us emails with employee updates that we'd like to get into the warehouse. Parsing the message is trivial, but how can I actually deliver the email body?", "author_fullname": "t2_89aof", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone have a halfway decent solution for getting automated emails into Google Cloud?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yhxxo9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667182325.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have this stupid HR system with a prohibitively expensive API. They&amp;#39;re sending us emails with employee updates that we&amp;#39;d like to get into the warehouse. Parsing the message is trivial, but how can I actually deliver the email body?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yhxxo9", "is_robot_indexable": true, "report_reasons": null, "author": "PrezRosslin", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yhxxo9/does_anyone_have_a_halfway_decent_solution_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yhxxo9/does_anyone_have_a_halfway_decent_solution_for/", "subreddit_subscribers": 78453, "created_utc": 1667182325.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_ebrwg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Legacy Database Migration: What To Know Before You Start (with advice from those who lived to tell the tale)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_yhsh6q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/00rFi9YBQrQb5gBvicxRqjlouro9MdRcGWgW81veBYk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667169750.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "redis.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://redis.com/blog/legacy-database-migration/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/A3k4pea0fdbmfz20ZItK5bbWvceZDikLQkinhmE4-Kk.jpg?auto=webp&amp;s=5cbe5d2645129b70579d78e8f90575f230c3d6c8", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/A3k4pea0fdbmfz20ZItK5bbWvceZDikLQkinhmE4-Kk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=16ea7eedc0093dbbf67d5565f9814c6e0884811f", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/A3k4pea0fdbmfz20ZItK5bbWvceZDikLQkinhmE4-Kk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=762cde346b463a10c7a98bfd215e8808124de891", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/A3k4pea0fdbmfz20ZItK5bbWvceZDikLQkinhmE4-Kk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=aadf29102225186ae5995e7af5ce9ba8b3be55dc", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/A3k4pea0fdbmfz20ZItK5bbWvceZDikLQkinhmE4-Kk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=dcb7f4a3860976ec8d9068bde34b44dcf8764650", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/A3k4pea0fdbmfz20ZItK5bbWvceZDikLQkinhmE4-Kk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=62b7e9a6152a9a9e4fd0ebd8c31ac72022916a8e", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/A3k4pea0fdbmfz20ZItK5bbWvceZDikLQkinhmE4-Kk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2fac2bcd161db8b0d3f1f8b7bd269aff9b060f7d", "width": 1080, "height": 565}], "variants": {}, "id": "4yID2BUwgoy4AMADwMJcRgqEw6NBtogoOxF3lFvyw6g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yhsh6q", "is_robot_indexable": true, "report_reasons": null, "author": "yourbasicgeek", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yhsh6q/legacy_database_migration_what_to_know_before_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://redis.com/blog/legacy-database-migration/", "subreddit_subscribers": 78453, "created_utc": 1667169750.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a server side/backend developer with an year of experience in developing web services with Java and Spring. For the last 3 months, I've been using Apache Beam's Java SDK for writing ETL pipelines for GCP Dataflow.  \n\nMy work role now requires me to make a permanent switch to DE, and complete the [Databricks Certified Associate Developer for Apache Spark](https://www.databricks.com/learn/certification/apache-spark-developer-associate)  certification. \n\nThe Catch is that the cert is only offered for either python or Scala but I'm currently only proficient with Java. I'm willing to learn either one of these languages but I'm confused about which one to go forward with. My dilemma is as follows:\n\n1) I dislike python but I feel like it's the `lingua franca' of DE and it's not really possible to make a career in this field without mastering it.\n\n2) I love Scala but feel that it might not be too useful other than this cert for DE.\n\n3) At my workplace we use all 3 but Scala is rarest.\n\nAny input would be appreciated, Thanks.", "author_fullname": "t2_3ucivv3g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scala or Python for Data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yieto6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667229094.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a server side/backend developer with an year of experience in developing web services with Java and Spring. For the last 3 months, I&amp;#39;ve been using Apache Beam&amp;#39;s Java SDK for writing ETL pipelines for GCP Dataflow.  &lt;/p&gt;\n\n&lt;p&gt;My work role now requires me to make a permanent switch to DE, and complete the &lt;a href=\"https://www.databricks.com/learn/certification/apache-spark-developer-associate\"&gt;Databricks Certified Associate Developer for Apache Spark&lt;/a&gt;  certification. &lt;/p&gt;\n\n&lt;p&gt;The Catch is that the cert is only offered for either python or Scala but I&amp;#39;m currently only proficient with Java. I&amp;#39;m willing to learn either one of these languages but I&amp;#39;m confused about which one to go forward with. My dilemma is as follows:&lt;/p&gt;\n\n&lt;p&gt;1) I dislike python but I feel like it&amp;#39;s the `lingua franca&amp;#39; of DE and it&amp;#39;s not really possible to make a career in this field without mastering it.&lt;/p&gt;\n\n&lt;p&gt;2) I love Scala but feel that it might not be too useful other than this cert for DE.&lt;/p&gt;\n\n&lt;p&gt;3) At my workplace we use all 3 but Scala is rarest.&lt;/p&gt;\n\n&lt;p&gt;Any input would be appreciated, Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/GJ7MpqsUo8YEPDKlUylWBTa_GWPu4xBncdzyhz_ieJg.jpg?auto=webp&amp;s=28b9ae149e0b4d698c919c86cb9694173c82dafd", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/GJ7MpqsUo8YEPDKlUylWBTa_GWPu4xBncdzyhz_ieJg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c0ab2e6d636c370b278c37013e4e3856a0298ace", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/GJ7MpqsUo8YEPDKlUylWBTa_GWPu4xBncdzyhz_ieJg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8a856bb1f4d2eb3a4a805e32a57aff0511418a3e", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/GJ7MpqsUo8YEPDKlUylWBTa_GWPu4xBncdzyhz_ieJg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1cfb4263d4a5010c46048b82c5393c49e142f48b", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/GJ7MpqsUo8YEPDKlUylWBTa_GWPu4xBncdzyhz_ieJg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=04eed4dbb30b78c729da72ee176b3f9e18fab790", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/GJ7MpqsUo8YEPDKlUylWBTa_GWPu4xBncdzyhz_ieJg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9248e19e8c14006380c590c18b5e059b87fe8d14", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/GJ7MpqsUo8YEPDKlUylWBTa_GWPu4xBncdzyhz_ieJg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b675948c77f088256047dc00427e8ca3ecc8b1f7", "width": 1080, "height": 565}], "variants": {}, "id": "HwfMz-OF8GV89jc_qQVRVxc8W8oTe2mVUnnrYLKLhX8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yieto6", "is_robot_indexable": true, "report_reasons": null, "author": "forneptune", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yieto6/scala_or_python_for_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yieto6/scala_or_python_for_data_engineering/", "subreddit_subscribers": 78453, "created_utc": 1667229094.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Dear data engineers,\n\nI have over 8 years of experience in the domain of data analytics and consulting. I have decided to pivot to a data engineering role (I did work on a few data engineering projects too previously). If it matters, I am proficient in SQL, Python, Scala, Bash, Hive, Spark.\n\nSince this would be my first company in my new career, I have decided to keep the following criteria while looking for a company (in the priority order)\n\n* Companies where I can learn software engineering principles in general. Although I know most of the major tools/frameworks that a DE uses, I want to know how all of them fit together with rest of teams and business units\n* Places where I can focus solely on improving my skills\n* moderate work life balance\n* Salary is not a criteria, learning is\n\nWith the above criteria in mind, can you please suggest me some companies in India that you are aware of? If you are not from India, please suggest what should I look for when searching for companies and any other red flags\n\nI have decided not to go back to data analytics domain. So this move to DE is not an impulsive decision\n\n___\n\nMy 2 cents to people working in the domain of data analytics and ML\n\n* As cliched as it sounds, ponder over the question \"Where do you want to be in 5 years\". Based on what I have seen, most organizations will eventually move you to a more managerial/stakeholder facing/ppt making role. Observe yourself, do some introspection on if you would enjoy such roles a few years down the line. I didn't, not one bit\n* Prepare for being comfortable with ambiguity. With the right amount of effort, ML Models can be built, but tying it to daily business operations especially involving a lot of stakeholders is a much bigger beast. Do you enjoy doing it?", "author_fullname": "t2_szesl9z4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Companies in India with good learning opportunities for data engineers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yiddau", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667225654.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dear data engineers,&lt;/p&gt;\n\n&lt;p&gt;I have over 8 years of experience in the domain of data analytics and consulting. I have decided to pivot to a data engineering role (I did work on a few data engineering projects too previously). If it matters, I am proficient in SQL, Python, Scala, Bash, Hive, Spark.&lt;/p&gt;\n\n&lt;p&gt;Since this would be my first company in my new career, I have decided to keep the following criteria while looking for a company (in the priority order)&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Companies where I can learn software engineering principles in general. Although I know most of the major tools/frameworks that a DE uses, I want to know how all of them fit together with rest of teams and business units&lt;/li&gt;\n&lt;li&gt;Places where I can focus solely on improving my skills&lt;/li&gt;\n&lt;li&gt;moderate work life balance&lt;/li&gt;\n&lt;li&gt;Salary is not a criteria, learning is&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;With the above criteria in mind, can you please suggest me some companies in India that you are aware of? If you are not from India, please suggest what should I look for when searching for companies and any other red flags&lt;/p&gt;\n\n&lt;p&gt;I have decided not to go back to data analytics domain. So this move to DE is not an impulsive decision&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;My 2 cents to people working in the domain of data analytics and ML&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;As cliched as it sounds, ponder over the question &amp;quot;Where do you want to be in 5 years&amp;quot;. Based on what I have seen, most organizations will eventually move you to a more managerial/stakeholder facing/ppt making role. Observe yourself, do some introspection on if you would enjoy such roles a few years down the line. I didn&amp;#39;t, not one bit&lt;/li&gt;\n&lt;li&gt;Prepare for being comfortable with ambiguity. With the right amount of effort, ML Models can be built, but tying it to daily business operations especially involving a lot of stakeholders is a much bigger beast. Do you enjoy doing it?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yiddau", "is_robot_indexable": true, "report_reasons": null, "author": "yetanotherruser", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yiddau/companies_in_india_with_good_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yiddau/companies_in_india_with_good_learning/", "subreddit_subscribers": 78453, "created_utc": 1667225654.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6ff333ne", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt Coalesce 2022 takeaways", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yibhy1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1667221366.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blef.fr", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.blef.fr/dbt-coalesce-takeaways-2022/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "I'm the dataman", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yibhy1", "is_robot_indexable": true, "report_reasons": null, "author": "blef__", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/yibhy1/dbt_coalesce_2022_takeaways/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.blef.fr/dbt-coalesce-takeaways-2022/", "subreddit_subscribers": 78453, "created_utc": 1667221366.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We\u2019re looking at leveraging FastAPI as an abstraction layer over our Snowflake data warehouse, to allow third party systems access to the data (think of it as self-service reverse ETL).\n\nI\u2019ve come from the analytics and BI side of things rather than from software engineering, so I have some knowledge gaps.\n\nWhere would we store the list of users that had permission to access the API along with their scope and hashed password? Would we simply keep it in Snowflake given that this is the database that the API would sit over, or would we store them in DynamoDB or something like that?\n\nKeen to get feedback on this.\n\nAlso, are any of you already doing this in a production setting? What is your use case (if you don\u2019t mind me asking)? Wanting to get as prepared as I can with a bit of a PoC and value proposition for the business.", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Novice Question: storing credentials", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yi5jey", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667206697.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We\u2019re looking at leveraging FastAPI as an abstraction layer over our Snowflake data warehouse, to allow third party systems access to the data (think of it as self-service reverse ETL).&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve come from the analytics and BI side of things rather than from software engineering, so I have some knowledge gaps.&lt;/p&gt;\n\n&lt;p&gt;Where would we store the list of users that had permission to access the API along with their scope and hashed password? Would we simply keep it in Snowflake given that this is the database that the API would sit over, or would we store them in DynamoDB or something like that?&lt;/p&gt;\n\n&lt;p&gt;Keen to get feedback on this.&lt;/p&gt;\n\n&lt;p&gt;Also, are any of you already doing this in a production setting? What is your use case (if you don\u2019t mind me asking)? Wanting to get as prepared as I can with a bit of a PoC and value proposition for the business.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yi5jey", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yi5jey/novice_question_storing_credentials/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yi5jey/novice_question_storing_credentials/", "subreddit_subscribers": 78453, "created_utc": 1667206697.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We use AWS managed airflow service to handle our databricks and other scheduled pipelines. Our list of DAGs is really starting to grow and we\u2019d like to add some kind of version control system to our DAG development. Does anyone managed their DAGs in bitbucket? Does anyone have any best practices on how to manage DAGs? Right now each developer uploads their DAGs to an S3 bucket and then activates the DAGs in the Airflow UI when ready for production.  I\u2019m afraid that without versioning these DAGs that anything\u2019s could go wrong if someone uploads an unreviewed file.", "author_fullname": "t2_8y2a4hfy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow DAG version control process suggestions.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yii0l2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667236327.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We use AWS managed airflow service to handle our databricks and other scheduled pipelines. Our list of DAGs is really starting to grow and we\u2019d like to add some kind of version control system to our DAG development. Does anyone managed their DAGs in bitbucket? Does anyone have any best practices on how to manage DAGs? Right now each developer uploads their DAGs to an S3 bucket and then activates the DAGs in the Airflow UI when ready for production.  I\u2019m afraid that without versioning these DAGs that anything\u2019s could go wrong if someone uploads an unreviewed file.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yii0l2", "is_robot_indexable": true, "report_reasons": null, "author": "Known-Delay7227", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yii0l2/airflow_dag_version_control_process_suggestions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yii0l2/airflow_dag_version_control_process_suggestions/", "subreddit_subscribers": 78453, "created_utc": 1667236327.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to store my data for long periods of time. I have my flash drive but from what I've heard the data could be corrupted in 2 years. I could store it in google drive, but I have only 15 GB max storage. All help is helpful, thanks!", "author_fullname": "t2_4hc22kke", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where to store data for long periods of time? (100+ years)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yhrydo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.59, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667168654.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to store my data for long periods of time. I have my flash drive but from what I&amp;#39;ve heard the data could be corrupted in 2 years. I could store it in google drive, but I have only 15 GB max storage. All help is helpful, thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yhrydo", "is_robot_indexable": true, "report_reasons": null, "author": "SmoKKe9", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yhrydo/where_to_store_data_for_long_periods_of_time_100/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yhrydo/where_to_store_data_for_long_periods_of_time_100/", "subreddit_subscribers": 78453, "created_utc": 1667168654.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, I would like to say a big thank you to this community for the daily dose of knowledge and the fun with it.... So I have a task and I am really close the deadline, so here it goes:\n\nSo there is a software(Ignition Maker) that is automating the pulling of the data from the IOT sensors and loading them into a Postgres DB.... now it turns out that the software they are using is creating some other tables which refer to the IOT sensors tagid and some other columns that contain metadata about the sensors....so If I am to get information about a particular device, I will have to do some joins which led me to create a VIEW. Now the thing is, the software that automates the pulling of the data, creates a different table automatically per month so that I can have a better understanding of the values that are generated and to also help for future analysis....\n\nNow, things to note, having to always do a JOIN to get the information I need is stressful, plus I think, it will even slow down the query time as the data expands and I currently have more than a million rows....\n\nSo my plan is to do a data model, in which I have a new database with new tables  that are redefined with tables that are NORMALIZED and have a better structure, so I can query them easily and most likely will have reduced JOINS...\n\nPlus I have to create interactive reports in which a user has a GUI where they can click on the list of IOT devices and select one of them and automatically they can see a bar or column graph of the highest value generated in all the week for that month.\n\n1. What do you think about this process?\n\n2. I am trying to see how I can do an ETL to achieve the live dumping of the data or query I will write to pull the data from the original db into my redifined Database\n\n&amp;#x200B;\n\nAlso: Part of the requirement is to  have a live backup or replication of the database but this is separate from this original problem stated above BUT I plan to just do a Master/Slave replication for that... BUT the pressing issue is having to pull the data and create live interactive reports, in which the user can select the timeframe he wants to set and see the values e.g I can check for data for  a device within September 15th to present and I just get a very nice report of the values.\n\n&amp;#x200B;\n\nPlease Help, I need suggestions and how I can go about this efficiently... Thank you", "author_fullname": "t2_mklzceft", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Creating interactive and LIVE reports from IOT Sonsor data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yigtym", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667233714.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I would like to say a big thank you to this community for the daily dose of knowledge and the fun with it.... So I have a task and I am really close the deadline, so here it goes:&lt;/p&gt;\n\n&lt;p&gt;So there is a software(Ignition Maker) that is automating the pulling of the data from the IOT sensors and loading them into a Postgres DB.... now it turns out that the software they are using is creating some other tables which refer to the IOT sensors tagid and some other columns that contain metadata about the sensors....so If I am to get information about a particular device, I will have to do some joins which led me to create a VIEW. Now the thing is, the software that automates the pulling of the data, creates a different table automatically per month so that I can have a better understanding of the values that are generated and to also help for future analysis....&lt;/p&gt;\n\n&lt;p&gt;Now, things to note, having to always do a JOIN to get the information I need is stressful, plus I think, it will even slow down the query time as the data expands and I currently have more than a million rows....&lt;/p&gt;\n\n&lt;p&gt;So my plan is to do a data model, in which I have a new database with new tables  that are redefined with tables that are NORMALIZED and have a better structure, so I can query them easily and most likely will have reduced JOINS...&lt;/p&gt;\n\n&lt;p&gt;Plus I have to create interactive reports in which a user has a GUI where they can click on the list of IOT devices and select one of them and automatically they can see a bar or column graph of the highest value generated in all the week for that month.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;What do you think about this process?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I am trying to see how I can do an ETL to achieve the live dumping of the data or query I will write to pull the data from the original db into my redifined Database&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Also: Part of the requirement is to  have a live backup or replication of the database but this is separate from this original problem stated above BUT I plan to just do a Master/Slave replication for that... BUT the pressing issue is having to pull the data and create live interactive reports, in which the user can select the timeframe he wants to set and see the values e.g I can check for data for  a device within September 15th to present and I just get a very nice report of the values.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Please Help, I need suggestions and how I can go about this efficiently... Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yigtym", "is_robot_indexable": true, "report_reasons": null, "author": "deedatagod", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yigtym/creating_interactive_and_live_reports_from_iot/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yigtym/creating_interactive_and_live_reports_from_iot/", "subreddit_subscribers": 78453, "created_utc": 1667233714.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am writing a few dataframes (spark, scala) and it would be great if I could see the schema of the frames at compile time. I am assuming this is possible since scala is a statically typed language, but I might be wrong.\n\nIdeally it'd show me the schema once Intellij is done with compiling so that I don't have to execute the program every time I want to check that I haven't made a mistake.\n\n&amp;#x200B;\n\nHappy about any pointers and sorry if this is a stupid question.", "author_fullname": "t2_mxg4sp1e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a plugin/way to show the schema of the dataframe I am creating at compile time?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yidim7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667226014.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am writing a few dataframes (spark, scala) and it would be great if I could see the schema of the frames at compile time. I am assuming this is possible since scala is a statically typed language, but I might be wrong.&lt;/p&gt;\n\n&lt;p&gt;Ideally it&amp;#39;d show me the schema once Intellij is done with compiling so that I don&amp;#39;t have to execute the program every time I want to check that I haven&amp;#39;t made a mistake.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Happy about any pointers and sorry if this is a stupid question.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yidim7", "is_robot_indexable": true, "report_reasons": null, "author": "BlereTech", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yidim7/is_there_a_pluginway_to_show_the_schema_of_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yidim7/is_there_a_pluginway_to_show_the_schema_of_the/", "subreddit_subscribers": 78453, "created_utc": 1667226014.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI'm interested in the Databricks Certification exams, especially for Data Engineering but they seem a bit too costy for personal reasons. Are there any Vouchers or any discounts events like Microsoft Ignite for Azure? At least I couldn't find similiar events through searching.\n\nAlready thanks and best regards!", "author_fullname": "t2_bgbrbly9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any Databricks Certification Vouchers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yiddn5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667225679.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m interested in the Databricks Certification exams, especially for Data Engineering but they seem a bit too costy for personal reasons. Are there any Vouchers or any discounts events like Microsoft Ignite for Azure? At least I couldn&amp;#39;t find similiar events through searching.&lt;/p&gt;\n\n&lt;p&gt;Already thanks and best regards!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yiddn5", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Inspection3886", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yiddn5/are_there_any_databricks_certification_vouchers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yiddn5/are_there_any_databricks_certification_vouchers/", "subreddit_subscribers": 78453, "created_utc": 1667225679.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am attempting to add an SSH username/private key. It shows as added but when i go to apply it, doesn\u2019t show up in the drop down with all the other credentials", "author_fullname": "t2_qs43cth", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Jenkins SSH Credentials\u2026help?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yibd3t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667221107.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am attempting to add an SSH username/private key. It shows as added but when i go to apply it, doesn\u2019t show up in the drop down with all the other credentials&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yibd3t", "is_robot_indexable": true, "report_reasons": null, "author": "jolllof", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yibd3t/jenkins_ssh_credentialshelp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yibd3t/jenkins_ssh_credentialshelp/", "subreddit_subscribers": 78453, "created_utc": 1667221107.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am trying to find a better living in this third world country. Is it even possible to get a remote job in first world country and they are willing to pay maybe half of the average market salary there for someone from third world country as a junior data engineer? Or do I need at least a senior or more level? $40k is really life-changing for me.", "author_fullname": "t2_tm5irceo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job for Third World Country with First World Country Company and Salary", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yie5al", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.2, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667227523.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to find a better living in this third world country. Is it even possible to get a remote job in first world country and they are willing to pay maybe half of the average market salary there for someone from third world country as a junior data engineer? Or do I need at least a senior or more level? $40k is really life-changing for me.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yie5al", "is_robot_indexable": true, "report_reasons": null, "author": "natas_m", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yie5al/job_for_third_world_country_with_first_world/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yie5al/job_for_third_world_country_with_first_world/", "subreddit_subscribers": 78453, "created_utc": 1667227523.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}