{"kind": "Listing", "data": {"after": null, "dist": 21, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone!\n\nI already know Python and SQL and I\u2019m wondering what would be a good skill to learn next for becoming more experienced with data engineering.\n\nThank you in advance!", "author_fullname": "t2_4841f127", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What skill would you learn after Python and SQL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yhhl2y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 91, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 91, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667144994.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone!&lt;/p&gt;\n\n&lt;p&gt;I already know Python and SQL and I\u2019m wondering what would be a good skill to learn next for becoming more experienced with data engineering.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yhhl2y", "is_robot_indexable": true, "report_reasons": null, "author": "The-Fourth-Hokage", "discussion_type": null, "num_comments": 74, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yhhl2y/what_skill_would_you_learn_after_python_and_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yhhl2y/what_skill_would_you_learn_after_python_and_sql/", "subreddit_subscribers": 78429, "created_utc": 1667144994.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I realize that job titles tend to be arbitrary - but I\u2019ve recently gotten told by multiple people that my title is incorrect and compensation is too low based off my job responsibilities.\n\nMy official title is operations analyst and my total comp is around 70k - I currently have 3 years of experience working as an analyst. And my company is a mid sized saas tech firm based on the west coast. \n\nResponsibilities- I  spend 50% of my time in snowflake analyzing data and creating various scripts/schemas using dbt - and 30% of the time using etl/elt tools to load data from various sources into our warehouse.. and the remaining 20% of the time I\u2019m creating dashboards with our bi tool. The business would love the bi portion of my work to be higher - but I really try keep my work to 60hrs a week - and the moving/cleaning of data takes up the majority of time.\n\nI\u2019ve been told my title should be anything ranging from data analyst, analytics engineer, data engineer and even product analyst.. so I\u2019m just curious what everyone on the de subreddit thoughts are regarding my title and compensation? And if I\u2019m not near or at the official data engineer title yet - what steps should I take to move myself in that direction?", "author_fullname": "t2_d11os2fi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I a Data Engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yhhqbf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 67, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 67, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667146684.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667145351.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I realize that job titles tend to be arbitrary - but I\u2019ve recently gotten told by multiple people that my title is incorrect and compensation is too low based off my job responsibilities.&lt;/p&gt;\n\n&lt;p&gt;My official title is operations analyst and my total comp is around 70k - I currently have 3 years of experience working as an analyst. And my company is a mid sized saas tech firm based on the west coast. &lt;/p&gt;\n\n&lt;p&gt;Responsibilities- I  spend 50% of my time in snowflake analyzing data and creating various scripts/schemas using dbt - and 30% of the time using etl/elt tools to load data from various sources into our warehouse.. and the remaining 20% of the time I\u2019m creating dashboards with our bi tool. The business would love the bi portion of my work to be higher - but I really try keep my work to 60hrs a week - and the moving/cleaning of data takes up the majority of time.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been told my title should be anything ranging from data analyst, analytics engineer, data engineer and even product analyst.. so I\u2019m just curious what everyone on the de subreddit thoughts are regarding my title and compensation? And if I\u2019m not near or at the official data engineer title yet - what steps should I take to move myself in that direction?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yhhqbf", "is_robot_indexable": true, "report_reasons": null, "author": "General-Geologist-53", "discussion_type": null, "num_comments": 52, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yhhqbf/am_i_a_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yhhqbf/am_i_a_data_engineer/", "subreddit_subscribers": 78429, "created_utc": 1667145351.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_irftz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Every data engineer understands you need a clean and good looking \u2018data model\u2019 for the best report performance\u2026.happy Halloween!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_yhw7be", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "ups": 60, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 60, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/G7tubW8hB5hJA7FhU6ZK05t4jxXClnbXEejy6LfP0Yg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667177859.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/bk9d8p27i1x91.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/bk9d8p27i1x91.jpg?auto=webp&amp;s=7d0dc9b64174082f4bc60c1b33ea418ac1c0d6ad", "width": 1586, "height": 2947}, "resolutions": [{"url": "https://preview.redd.it/bk9d8p27i1x91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=97f6a9b2e7dc1ca594382c4c5ba836f2297d79a5", "width": 108, "height": 200}, {"url": "https://preview.redd.it/bk9d8p27i1x91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=de61e7dc6162533dbed3b19325a63a731a2e62b8", "width": 216, "height": 401}, {"url": "https://preview.redd.it/bk9d8p27i1x91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6503b111d647cd4bac941ee150c3e4f1bd20ea71", "width": 320, "height": 594}, {"url": "https://preview.redd.it/bk9d8p27i1x91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e3e1b38489ff32cdf0ede6795997f195f57ee131", "width": 640, "height": 1189}, {"url": "https://preview.redd.it/bk9d8p27i1x91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=817a37ddd31c98d974f030e973228014516047fb", "width": 960, "height": 1783}, {"url": "https://preview.redd.it/bk9d8p27i1x91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=070a47998f4a95e50328815cbb7292427d345ccc", "width": 1080, "height": 2006}], "variants": {}, "id": "9ktEd7qJtq6jdTUCEuC5dcgEHf9PubUsr2crnOD-LRw"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "yhw7be", "is_robot_indexable": true, "report_reasons": null, "author": "mutigers42", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yhw7be/every_data_engineer_understands_you_need_a_clean/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/bk9d8p27i1x91.jpg", "subreddit_subscribers": 78429, "created_utc": 1667177859.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi r/dataengineering,\n\nI'm working on an experimental new spreadsheet, [dtable](https://dtable.dev/), that I think could be useful. It aims to bridge the gap between a programming environment and a spreadsheet. Formulas in **dtable** can connect to any API or database in a first-class manor.\n\nThe website and beta signup is here: [https://dtable.dev/](https://dtable.dev/).\nJoin the [discord](https://discord.gg/nNCjCK7NGN) if you're interested in following the progress.\n\n**Please share your thoughts below, I'd love to discuss.**\n\n---\n\n## More design details\n\n**dtable** leverages emerging innovations in language runtime isolation technology to allow running formulas as JavaScript functions on the server in a lightweight and secure manor. These formulas can query any API or backend. You can parameterize these queries using the typical cell reference semantics you're accustomed to in Excel/Google Sheets.\n\nThere are three kinds of formulas\n\n1. standard cell formulas: must return `T: string | number | boolean | null`\n2. column controller formulas: must return `T[]` that fills the column\n3. grid controller formulas: must return `T[][]` that fills an entire grid", "author_fullname": "t2_je56j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A spreadsheet built for data engineers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yhwems", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667178324.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt;,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working on an experimental new spreadsheet, &lt;a href=\"https://dtable.dev/\"&gt;dtable&lt;/a&gt;, that I think could be useful. It aims to bridge the gap between a programming environment and a spreadsheet. Formulas in &lt;strong&gt;dtable&lt;/strong&gt; can connect to any API or database in a first-class manor.&lt;/p&gt;\n\n&lt;p&gt;The website and beta signup is here: &lt;a href=\"https://dtable.dev/\"&gt;https://dtable.dev/&lt;/a&gt;.\nJoin the &lt;a href=\"https://discord.gg/nNCjCK7NGN\"&gt;discord&lt;/a&gt; if you&amp;#39;re interested in following the progress.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Please share your thoughts below, I&amp;#39;d love to discuss.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;h2&gt;More design details&lt;/h2&gt;\n\n&lt;p&gt;&lt;strong&gt;dtable&lt;/strong&gt; leverages emerging innovations in language runtime isolation technology to allow running formulas as JavaScript functions on the server in a lightweight and secure manor. These formulas can query any API or backend. You can parameterize these queries using the typical cell reference semantics you&amp;#39;re accustomed to in Excel/Google Sheets.&lt;/p&gt;\n\n&lt;p&gt;There are three kinds of formulas&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;standard cell formulas: must return &lt;code&gt;T: string | number | boolean | null&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;column controller formulas: must return &lt;code&gt;T[]&lt;/code&gt; that fills the column&lt;/li&gt;\n&lt;li&gt;grid controller formulas: must return &lt;code&gt;T[][]&lt;/code&gt; that fills an entire grid&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yhwems", "is_robot_indexable": true, "report_reasons": null, "author": "mendturtle", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yhwems/a_spreadsheet_built_for_data_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yhwems/a_spreadsheet_built_for_data_engineers/", "subreddit_subscribers": 78429, "created_utc": 1667178324.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do you have a review process for updating your models? Do you manually review all pull requests or do you have a CI/CD process for updating any (dbt) models? If so, how does it look like? Do you use DataFold or any other tool and what do you like and don't like about it? Any lessons learned?\n\nWe want to give a bit more autonomy to our data analysts and other stakeholders to create their own models, but want to ensure nothing breaks in the meanwhile. Curious to hear your experiences or best practices", "author_fullname": "t2_4hext4tv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CI/CD process for dbt models", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yi5ay3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667206052.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you have a review process for updating your models? Do you manually review all pull requests or do you have a CI/CD process for updating any (dbt) models? If so, how does it look like? Do you use DataFold or any other tool and what do you like and don&amp;#39;t like about it? Any lessons learned?&lt;/p&gt;\n\n&lt;p&gt;We want to give a bit more autonomy to our data analysts and other stakeholders to create their own models, but want to ensure nothing breaks in the meanwhile. Curious to hear your experiences or best practices&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yi5ay3", "is_robot_indexable": true, "report_reasons": null, "author": "mrmaestro1", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yi5ay3/cicd_process_for_dbt_models/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yi5ay3/cicd_process_for_dbt_models/", "subreddit_subscribers": 78429, "created_utc": 1667206052.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Everyone,\n\nI am trying to study for either **Databricks Certified Associate Developer for Apache Spark** or **Databricks Certified Data Engineer Professional**. \n\nAnd I have passed **Google Cloud Professional Data Engineer** recently. I am wondering which one should I get if I want to focus to get Spark knowledge. I heard **Databricks Certified Data Engineer Professional** also covers Spark materials.", "author_fullname": "t2_8big8125", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which Databrick certification I should get?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yi10k6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667191544.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone,&lt;/p&gt;\n\n&lt;p&gt;I am trying to study for either &lt;strong&gt;Databricks Certified Associate Developer for Apache Spark&lt;/strong&gt; or &lt;strong&gt;Databricks Certified Data Engineer Professional&lt;/strong&gt;. &lt;/p&gt;\n\n&lt;p&gt;And I have passed &lt;strong&gt;Google Cloud Professional Data Engineer&lt;/strong&gt; recently. I am wondering which one should I get if I want to focus to get Spark knowledge. I heard &lt;strong&gt;Databricks Certified Data Engineer Professional&lt;/strong&gt; also covers Spark materials.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yi10k6", "is_robot_indexable": true, "report_reasons": null, "author": "Fearless_Card_5611", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yi10k6/which_databrick_certification_i_should_get/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yi10k6/which_databrick_certification_i_should_get/", "subreddit_subscribers": 78429, "created_utc": 1667191544.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m running airflow on composer.\nI have a Dag that:\n\n1-fetches large json from an api\n2-writes the json to a file in GCS\n3-reads the file and do transformations \n4-writes the result to a new file on GCS\n\nMy dag keeps stoping at step 3 with a message of type SIGKILL.\n\nHow can I solve such an issue ?\nWhat are the best practices on passing data between tasks in such a manner ?\n\nThank you", "author_fullname": "t2_98269xyy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow - Passing large data volumes between tasks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yhlxei", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667154317.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m running airflow on composer.\nI have a Dag that:&lt;/p&gt;\n\n&lt;p&gt;1-fetches large json from an api\n2-writes the json to a file in GCS\n3-reads the file and do transformations \n4-writes the result to a new file on GCS&lt;/p&gt;\n\n&lt;p&gt;My dag keeps stoping at step 3 with a message of type SIGKILL.&lt;/p&gt;\n\n&lt;p&gt;How can I solve such an issue ?\nWhat are the best practices on passing data between tasks in such a manner ?&lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yhlxei", "is_robot_indexable": true, "report_reasons": null, "author": "Electronic-Mountain9", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yhlxei/airflow_passing_large_data_volumes_between_tasks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yhlxei/airflow_passing_large_data_volumes_between_tasks/", "subreddit_subscribers": 78429, "created_utc": 1667154317.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2rku02rf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Intro to Kestra: Open-Source Orchestration and Scheduling Platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_yi7elp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/rsZU_XKIA1X35drrHOdJYJN7dES0AYUDwb8KNqxGP_8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667211718.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/geekculture/intro-to-kestra-open-source-orchestration-and-scheduling-platform-a712f5238491", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MxJAxFI1-2vKTW3Arg0zPDbx06GgohPDCz4nmFynJ4k.jpg?auto=webp&amp;s=778f617d7f7a972eb57b20ef33e2c370f8cc30c0", "width": 800, "height": 450}, "resolutions": [{"url": "https://external-preview.redd.it/MxJAxFI1-2vKTW3Arg0zPDbx06GgohPDCz4nmFynJ4k.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5e4ebe488a3ebad22085af5914a64be16dca0ec2", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/MxJAxFI1-2vKTW3Arg0zPDbx06GgohPDCz4nmFynJ4k.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cd96ef8f3a6359d9afe08b4a74895d35f74735f3", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/MxJAxFI1-2vKTW3Arg0zPDbx06GgohPDCz4nmFynJ4k.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9872dd18aa6970dd461a7406115369c8ef80b14e", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/MxJAxFI1-2vKTW3Arg0zPDbx06GgohPDCz4nmFynJ4k.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a84d91db55c8a125f03590c68927e33a3e94a61a", "width": 640, "height": 360}], "variants": {}, "id": "OIa0U7Tn174Oq36_iYG2t9yb-XxrFBgBisPejYOFvU0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "yi7elp", "is_robot_indexable": true, "report_reasons": null, "author": "tchiotludo", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yi7elp/intro_to_kestra_opensource_orchestration_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/geekculture/intro-to-kestra-open-source-orchestration-and-scheduling-platform-a712f5238491", "subreddit_subscribers": 78429, "created_utc": 1667211718.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have this stupid HR system with a prohibitively expensive API. They're sending us emails with employee updates that we'd like to get into the warehouse. Parsing the message is trivial, but how can I actually deliver the email body?", "author_fullname": "t2_89aof", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone have a halfway decent solution for getting automated emails into Google Cloud?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yhxxo9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667182325.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have this stupid HR system with a prohibitively expensive API. They&amp;#39;re sending us emails with employee updates that we&amp;#39;d like to get into the warehouse. Parsing the message is trivial, but how can I actually deliver the email body?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yhxxo9", "is_robot_indexable": true, "report_reasons": null, "author": "PrezRosslin", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yhxxo9/does_anyone_have_a_halfway_decent_solution_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yhxxo9/does_anyone_have_a_halfway_decent_solution_for/", "subreddit_subscribers": 78429, "created_utc": 1667182325.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_ebrwg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Legacy Database Migration: What To Know Before You Start (with advice from those who lived to tell the tale)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_yhsh6q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/00rFi9YBQrQb5gBvicxRqjlouro9MdRcGWgW81veBYk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667169750.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "redis.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://redis.com/blog/legacy-database-migration/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/A3k4pea0fdbmfz20ZItK5bbWvceZDikLQkinhmE4-Kk.jpg?auto=webp&amp;s=5cbe5d2645129b70579d78e8f90575f230c3d6c8", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/A3k4pea0fdbmfz20ZItK5bbWvceZDikLQkinhmE4-Kk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=16ea7eedc0093dbbf67d5565f9814c6e0884811f", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/A3k4pea0fdbmfz20ZItK5bbWvceZDikLQkinhmE4-Kk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=762cde346b463a10c7a98bfd215e8808124de891", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/A3k4pea0fdbmfz20ZItK5bbWvceZDikLQkinhmE4-Kk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=aadf29102225186ae5995e7af5ce9ba8b3be55dc", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/A3k4pea0fdbmfz20ZItK5bbWvceZDikLQkinhmE4-Kk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=dcb7f4a3860976ec8d9068bde34b44dcf8764650", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/A3k4pea0fdbmfz20ZItK5bbWvceZDikLQkinhmE4-Kk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=62b7e9a6152a9a9e4fd0ebd8c31ac72022916a8e", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/A3k4pea0fdbmfz20ZItK5bbWvceZDikLQkinhmE4-Kk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2fac2bcd161db8b0d3f1f8b7bd269aff9b060f7d", "width": 1080, "height": 565}], "variants": {}, "id": "4yID2BUwgoy4AMADwMJcRgqEw6NBtogoOxF3lFvyw6g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yhsh6q", "is_robot_indexable": true, "report_reasons": null, "author": "yourbasicgeek", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yhsh6q/legacy_database_migration_what_to_know_before_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://redis.com/blog/legacy-database-migration/", "subreddit_subscribers": 78429, "created_utc": 1667169750.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We\u2019re looking at leveraging FastAPI as an abstraction layer over our Snowflake data warehouse, to allow third party systems access to the data (think of it as self-service reverse ETL).\n\nI\u2019ve come from the analytics and BI side of things rather than from software engineering, so I have some knowledge gaps.\n\nWhere would we store the list of users that had permission to access the API along with their scope and hashed password? Would we simply keep it in Snowflake given that this is the database that the API would sit over, or would we store them in DynamoDB or something like that?\n\nKeen to get feedback on this.\n\nAlso, are any of you already doing this in a production setting? What is your use case (if you don\u2019t mind me asking)? Wanting to get as prepared as I can with a bit of a PoC and value proposition for the business.", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Novice Question: storing credentials", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yi5jey", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667206697.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We\u2019re looking at leveraging FastAPI as an abstraction layer over our Snowflake data warehouse, to allow third party systems access to the data (think of it as self-service reverse ETL).&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve come from the analytics and BI side of things rather than from software engineering, so I have some knowledge gaps.&lt;/p&gt;\n\n&lt;p&gt;Where would we store the list of users that had permission to access the API along with their scope and hashed password? Would we simply keep it in Snowflake given that this is the database that the API would sit over, or would we store them in DynamoDB or something like that?&lt;/p&gt;\n\n&lt;p&gt;Keen to get feedback on this.&lt;/p&gt;\n\n&lt;p&gt;Also, are any of you already doing this in a production setting? What is your use case (if you don\u2019t mind me asking)? Wanting to get as prepared as I can with a bit of a PoC and value proposition for the business.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yi5jey", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yi5jey/novice_question_storing_credentials/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yi5jey/novice_question_storing_credentials/", "subreddit_subscribers": 78429, "created_utc": 1667206697.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_ihzzw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can PowerBI Cloud Service \"be a data warehouse\"?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yia41a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1667218287.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "reddit.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/r/PowerBI/comments/yi9wm7/odd_data_warehouse_question/?utm_source=share&amp;utm_medium=android_app&amp;utm_name=androidcss&amp;utm_term=1&amp;utm_content=share_button", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yia41a", "is_robot_indexable": true, "report_reasons": null, "author": "CorpusCalossum", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yia41a/can_powerbi_cloud_service_be_a_data_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/PowerBI/comments/yi9wm7/odd_data_warehouse_question/?utm_source=share&amp;utm_medium=android_app&amp;utm_name=androidcss&amp;utm_term=1&amp;utm_content=share_button", "subreddit_subscribers": 78429, "created_utc": 1667218287.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to store my data for long periods of time. I have my flash drive but from what I've heard the data could be corrupted in 2 years. I could store it in google drive, but I have only 15 GB max storage. All help is helpful, thanks!", "author_fullname": "t2_4hc22kke", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where to store data for long periods of time? (100+ years)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yhrydo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.53, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667168654.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to store my data for long periods of time. I have my flash drive but from what I&amp;#39;ve heard the data could be corrupted in 2 years. I could store it in google drive, but I have only 15 GB max storage. All help is helpful, thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yhrydo", "is_robot_indexable": true, "report_reasons": null, "author": "SmoKKe9", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yhrydo/where_to_store_data_for_long_periods_of_time_100/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yhrydo/where_to_store_data_for_long_periods_of_time_100/", "subreddit_subscribers": 78429, "created_utc": 1667168654.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2rtceaie", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DynamoDB, Ten Years Later", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_yhidtu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/UtqN-9ETk6lxYLyC_W3oNo1QZSQxE3p5aAgZ4nuel9k.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667146897.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "mydistributed.systems", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.mydistributed.systems/2022/10/dynamodb-ten-years-later.html", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yU0M4Ai8KWwYnjSOVEFyYnfxChaW_gKOgdulABSbISE.jpg?auto=webp&amp;s=782634f9434a2c719ebc141bde1d4918364b5475", "width": 260, "height": 130}, "resolutions": [{"url": "https://external-preview.redd.it/yU0M4Ai8KWwYnjSOVEFyYnfxChaW_gKOgdulABSbISE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6c43dbc1ff9c8839e21373a8668ce83fffd78e9b", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/yU0M4Ai8KWwYnjSOVEFyYnfxChaW_gKOgdulABSbISE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=46e48640bba0f6318a5e5ecd56988d347e013e2e", "width": 216, "height": 108}], "variants": {}, "id": "UzvD1SXjYOoQpbX7xz6iLZain6oMkSiDy8NPr4WBuaE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yhidtu", "is_robot_indexable": true, "report_reasons": null, "author": "roohitavaf", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yhidtu/dynamodb_ten_years_later/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.mydistributed.systems/2022/10/dynamodb-ten-years-later.html", "subreddit_subscribers": 78429, "created_utc": 1667146897.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there,\n\nI potentially have some support from my company to pay for a course. I am working in Data Analysis and Project Management with Developer experience. Would you rather recommend DataCamp or DataQuest for Data Engineering? I have few understanding of this field.\n\nAdditionally I will do the DataClub Zoomcamp. But I would like to use the support from my company to choose one of these courses. I like them as I as well can do some Data Analytics courses when signed up for a yearly subscription. I tried out both and besides that DataQuest is more do-it-yourself vs. DataCamp being more handholding I do not see much of a difference. When it comes to the course content of course I dont know what would prepare me better for a Data Engineering role.\n\nCould you support with deciding or even have a third or fourth one to share?\n\nThank you. :)", "author_fullname": "t2_9v9dakww", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DataCamp vs DataQuest vs other advices?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yhgovd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "19bba012-ac9d-11eb-b77b-0eec37c01719", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667142771.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there,&lt;/p&gt;\n\n&lt;p&gt;I potentially have some support from my company to pay for a course. I am working in Data Analysis and Project Management with Developer experience. Would you rather recommend DataCamp or DataQuest for Data Engineering? I have few understanding of this field.&lt;/p&gt;\n\n&lt;p&gt;Additionally I will do the DataClub Zoomcamp. But I would like to use the support from my company to choose one of these courses. I like them as I as well can do some Data Analytics courses when signed up for a yearly subscription. I tried out both and besides that DataQuest is more do-it-yourself vs. DataCamp being more handholding I do not see much of a difference. When it comes to the course content of course I dont know what would prepare me better for a Data Engineering role.&lt;/p&gt;\n\n&lt;p&gt;Could you support with deciding or even have a third or fourth one to share?&lt;/p&gt;\n\n&lt;p&gt;Thank you. :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Aspiring Data Engineer / Analyst", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yhgovd", "is_robot_indexable": true, "report_reasons": null, "author": "binchentso", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/yhgovd/datacamp_vs_dataquest_vs_other_advices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yhgovd/datacamp_vs_dataquest_vs_other_advices/", "subreddit_subscribers": 78429, "created_utc": 1667142771.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6ff333ne", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt Coalesce 2022 takeaways", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yibhy1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1667221366.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blef.fr", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.blef.fr/dbt-coalesce-takeaways-2022/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "I'm the dataman", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yibhy1", "is_robot_indexable": true, "report_reasons": null, "author": "blef__", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/yibhy1/dbt_coalesce_2022_takeaways/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.blef.fr/dbt-coalesce-takeaways-2022/", "subreddit_subscribers": 78429, "created_utc": 1667221366.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am attempting to add an SSH username/private key. It shows as added but when i go to apply it, doesn\u2019t show up in the drop down with all the other credentials", "author_fullname": "t2_qs43cth", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Jenkins SSH Credentials\u2026help?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yibd3t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667221107.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am attempting to add an SSH username/private key. It shows as added but when i go to apply it, doesn\u2019t show up in the drop down with all the other credentials&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yibd3t", "is_robot_indexable": true, "report_reasons": null, "author": "jolllof", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yibd3t/jenkins_ssh_credentialshelp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yibd3t/jenkins_ssh_credentialshelp/", "subreddit_subscribers": 78429, "created_utc": 1667221107.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "i fixed all errors and now i get this one and im not able to fix it\n\n    Exception has occurred: Py4JJavaError\n    An error occurred while calling o45.load.\n    : java.lang.ClassCastException: java.util.ArrayList cannot be cast to java.lang.String\n    \tat org.apache.spark.sql.internal.SessionState.$anonfun$newHadoopConfWithOptions$1(SessionState.scala:105)\n    \tat org.apache.spark.sql.internal.SessionState.$anonfun$newHadoopConfWithOptions$1$adapted(SessionState.scala:105)\n    \tat scala.collection.immutable.Map$Map3.foreach(Map.scala:376)\n    \tat org.apache.spark.sql.internal.SessionState.newHadoopConfWithOptions(SessionState.scala:105)\n    \tat org.apache.spark.sql.execution.datasources.DataSource.newHadoopConfiguration(DataSource.scala:116)\n    \tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:369)\n    \tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:228)\n    \tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:210)\n    \tat scala.Option.getOrElse(Option.scala:189)\n    \tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:210)\n    \tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    \tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    \tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    \tat java.lang.reflect.Method.invoke(Method.java:498)\n    \tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n    \tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n    \tat py4j.Gateway.invoke(Gateway.java:282)\n    \tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n    \tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n    \tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n    \tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n    \tat java.lang.Thread.run(Thread.java:748)\n\ndoes anyone have an idea what can i do?", "author_fullname": "t2_jymoyt2i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trying to run Pyspark on windows 10 using vscode", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yibd1v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667221104.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i fixed all errors and now i get this one and im not able to fix it&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Exception has occurred: Py4JJavaError\nAn error occurred while calling o45.load.\n: java.lang.ClassCastException: java.util.ArrayList cannot be cast to java.lang.String\n    at org.apache.spark.sql.internal.SessionState.$anonfun$newHadoopConfWithOptions$1(SessionState.scala:105)\n    at org.apache.spark.sql.internal.SessionState.$anonfun$newHadoopConfWithOptions$1$adapted(SessionState.scala:105)\n    at scala.collection.immutable.Map$Map3.foreach(Map.scala:376)\n    at org.apache.spark.sql.internal.SessionState.newHadoopConfWithOptions(SessionState.scala:105)\n    at org.apache.spark.sql.execution.datasources.DataSource.newHadoopConfiguration(DataSource.scala:116)\n    at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:369)\n    at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:228)\n    at org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:210)\n    at scala.Option.getOrElse(Option.scala:189)\n    at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:210)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:498)\n    at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n    at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n    at py4j.Gateway.invoke(Gateway.java:282)\n    at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n    at py4j.commands.CallCommand.execute(CallCommand.java:79)\n    at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n    at py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n    at java.lang.Thread.run(Thread.java:748)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;does anyone have an idea what can i do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yibd1v", "is_robot_indexable": true, "report_reasons": null, "author": "Metalmorphd", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yibd1v/trying_to_run_pyspark_on_windows_10_using_vscode/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yibd1v/trying_to_run_pyspark_on_windows_10_using_vscode/", "subreddit_subscribers": 78429, "created_utc": 1667221104.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Context is\u2014 engineering team has Postgres source database in an EC2. Change data capture is not going to happen on it, trust me, it\u2019s not haha. I\u2019ll spare the backstory there, but we are stuck with having to daily full reloads of tables in to snowflake. \n\nWhat tools are good performance-wise (potentially handle a daily reload of a table with 100 million rows in a timely manner) that are also affordable? Potentially self-hosted or self-managed? Also not interested in writing completely custom code like python for it. \n\nAirbyte hosted in k8s? Open to ideas. Thank you! \n\nWe\u2019re using Stitch right now, it works really quite well actually. Just hoping to find something else that we could save a bit of money on not using Stitch.", "author_fullname": "t2_c6w52", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Performant (but affordable) tools for full reloads from Postgres to snowflake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yhi1il", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667146094.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Context is\u2014 engineering team has Postgres source database in an EC2. Change data capture is not going to happen on it, trust me, it\u2019s not haha. I\u2019ll spare the backstory there, but we are stuck with having to daily full reloads of tables in to snowflake. &lt;/p&gt;\n\n&lt;p&gt;What tools are good performance-wise (potentially handle a daily reload of a table with 100 million rows in a timely manner) that are also affordable? Potentially self-hosted or self-managed? Also not interested in writing completely custom code like python for it. &lt;/p&gt;\n\n&lt;p&gt;Airbyte hosted in k8s? Open to ideas. Thank you! &lt;/p&gt;\n\n&lt;p&gt;We\u2019re using Stitch right now, it works really quite well actually. Just hoping to find something else that we could save a bit of money on not using Stitch.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yhi1il", "is_robot_indexable": true, "report_reasons": null, "author": "EmergenL", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yhi1il/performant_but_affordable_tools_for_full_reloads/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yhi1il/performant_but_affordable_tools_for_full_reloads/", "subreddit_subscribers": 78429, "created_utc": 1667146094.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Kusto Detective Agency's 4th (and so far hardest) case is live today. \n\nReminder, you can play at [detective.kusto.io](https://detective.kusto.io/), this is an official Azure minigame to help users learn about Kusto (ADX), you can win prizes and official Microsoft Credly badges (many to be earned!), and you can get a totally free cluster by signing up with the instructions in the onboarding challenge.\n\nHere's a thread on [r/kustodetectiveagency](https://www.reddit.com/r/kustodetectiveagency/) if you're after a hint, maybe some kind souls can help you out! (Or if you just want to show off your badges)\n\n[https://www.reddit.com/r/kustodetectiveagency/comments/yhk0on/case\\_4\\_thread\\_hints\\_tips\\_theories\\_badges/](https://www.reddit.com/r/kustodetectiveagency/comments/yhk0on/case_4_thread_hints_tips_theories_badges/)", "author_fullname": "t2_3urcm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Kusto/Azure Data Explorer] Kusto Detective Agency - Case 4 is live and now KDA has its own subreddit @ r/kustodetectiveagency - win prizes and Microsoft Credly badges whilst sharpening your big data skills", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yhkv6r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667152089.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Kusto Detective Agency&amp;#39;s 4th (and so far hardest) case is live today. &lt;/p&gt;\n\n&lt;p&gt;Reminder, you can play at &lt;a href=\"https://detective.kusto.io/\"&gt;detective.kusto.io&lt;/a&gt;, this is an official Azure minigame to help users learn about Kusto (ADX), you can win prizes and official Microsoft Credly badges (many to be earned!), and you can get a totally free cluster by signing up with the instructions in the onboarding challenge.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s a thread on &lt;a href=\"https://www.reddit.com/r/kustodetectiveagency/\"&gt;r/kustodetectiveagency&lt;/a&gt; if you&amp;#39;re after a hint, maybe some kind souls can help you out! (Or if you just want to show off your badges)&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/kustodetectiveagency/comments/yhk0on/case_4_thread_hints_tips_theories_badges/\"&gt;https://www.reddit.com/r/kustodetectiveagency/comments/yhk0on/case_4_thread_hints_tips_theories_badges/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yhkv6r", "is_robot_indexable": true, "report_reasons": null, "author": "wittykitty", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yhkv6r/kustoazure_data_explorer_kusto_detective_agency/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yhkv6r/kustoazure_data_explorer_kusto_detective_agency/", "subreddit_subscribers": 78429, "created_utc": 1667152089.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've got 25 worker nodes (on prem data center) for a new Geospatial Data Conversion and Analysis SaaS App\nI'm struggling to figure out best methodology to handle running jobs\nWe want normally one job on one machine because most of our tools and software is multithreaded and if not it's too much of impact on I/O or other resources \nMany big Geospatial data processing jobs are heavy CPU Dependenant and so most worker nodes are 32-64 threads \n\nWe also have one spark cluster for running pyspark and geotrellis and Geomesa and mrgeo \nI was thinking of using Kestra or Luigi but these are new to us.\nAnyone have experience in this and have some recommendations?\nmaps@techmaven.net\nhttps://portfolio.techmaven.net", "author_fullname": "t2_4fps3x6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "job queue workflows/orchestration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yhfupx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667140638.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got 25 worker nodes (on prem data center) for a new Geospatial Data Conversion and Analysis SaaS App\nI&amp;#39;m struggling to figure out best methodology to handle running jobs\nWe want normally one job on one machine because most of our tools and software is multithreaded and if not it&amp;#39;s too much of impact on I/O or other resources \nMany big Geospatial data processing jobs are heavy CPU Dependenant and so most worker nodes are 32-64 threads &lt;/p&gt;\n\n&lt;p&gt;We also have one spark cluster for running pyspark and geotrellis and Geomesa and mrgeo \nI was thinking of using Kestra or Luigi but these are new to us.\nAnyone have experience in this and have some recommendations?\n&lt;a href=\"mailto:maps@techmaven.net\"&gt;maps@techmaven.net&lt;/a&gt;\n&lt;a href=\"https://portfolio.techmaven.net\"&gt;https://portfolio.techmaven.net&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yhfupx", "is_robot_indexable": true, "report_reasons": null, "author": "techmavengeospatial", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yhfupx/job_queue_workflowsorchestration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yhfupx/job_queue_workflowsorchestration/", "subreddit_subscribers": 78429, "created_utc": 1667140638.0, "num_crossposts": 2, "media": null, "is_video": false}}], "before": null}}