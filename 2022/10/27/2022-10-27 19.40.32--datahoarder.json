{"kind": "Listing", "data": {"after": "t3_yep6at", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm bringing online a 12GBPS SAS Jbod with 90 18tb drives on it and am stuck trying to decided between a couple deployment scenarios. \n\nI can deploy with a 1950x (16 core threadripper) or a more modern 5950x (16 core ryzen) both with 128gb of ram. I was leaning to the thread ripper as i'm not entirely sure i'm going to run anything on the host much beyond the OS and the 5950x has a better resell value should I decide to sell it. Any real reason to go 5950x over the thread ripper? Power consumption isn't really an issue. \n\nI've got a bunch of systems in play already here (with about 1/4 of 2pb used across a few Supermicro builds / jbods) that i'm going to consolidate here. I'm thinking once I get the data over (I have serious data backed up in two off site locations) i'm going to rebuild the other systems into a ceph cluster. For now, i'm debating truenas or proxmox with zfs pools. I'm thinking 10 of 9 drives with one hotspare per, but i'm open to other suggestions. \n\nFeel free to tell me where I'm probably making the wrong decisions.", "author_fullname": "t2_8kd6x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New 1.5+ pb storage array, looking for advice.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yeg63t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666837952.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m bringing online a 12GBPS SAS Jbod with 90 18tb drives on it and am stuck trying to decided between a couple deployment scenarios. &lt;/p&gt;\n\n&lt;p&gt;I can deploy with a 1950x (16 core threadripper) or a more modern 5950x (16 core ryzen) both with 128gb of ram. I was leaning to the thread ripper as i&amp;#39;m not entirely sure i&amp;#39;m going to run anything on the host much beyond the OS and the 5950x has a better resell value should I decide to sell it. Any real reason to go 5950x over the thread ripper? Power consumption isn&amp;#39;t really an issue. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve got a bunch of systems in play already here (with about 1/4 of 2pb used across a few Supermicro builds / jbods) that i&amp;#39;m going to consolidate here. I&amp;#39;m thinking once I get the data over (I have serious data backed up in two off site locations) i&amp;#39;m going to rebuild the other systems into a ceph cluster. For now, i&amp;#39;m debating truenas or proxmox with zfs pools. I&amp;#39;m thinking 10 of 9 drives with one hotspare per, but i&amp;#39;m open to other suggestions. &lt;/p&gt;\n\n&lt;p&gt;Feel free to tell me where I&amp;#39;m probably making the wrong decisions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yeg63t", "is_robot_indexable": true, "report_reasons": null, "author": "SwallowedBuckyBalls", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yeg63t/new_15_pb_storage_array_looking_for_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yeg63t/new_15_pb_storage_array_looking_for_advice/", "subreddit_subscribers": 649343, "created_utc": 1666837952.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, what is the best future proof cloud backup service? By future proof i mean like no chance to lose your files or that the service ever closes and such...\n\nI currently use iCloud since forever and which i like. And since iCloud is owned by Apple, i think it pretty much is future proof but i heard that its not actually cloud backup service but more like a sync service or something like idk if thats true or not?", "author_fullname": "t2_mhetsykv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best future proof cloud backup service?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ye6qif", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666812804.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, what is the best future proof cloud backup service? By future proof i mean like no chance to lose your files or that the service ever closes and such...&lt;/p&gt;\n\n&lt;p&gt;I currently use iCloud since forever and which i like. And since iCloud is owned by Apple, i think it pretty much is future proof but i heard that its not actually cloud backup service but more like a sync service or something like idk if thats true or not?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ye6qif", "is_robot_indexable": true, "report_reasons": null, "author": "AnarkyGotham", "discussion_type": null, "num_comments": 38, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ye6qif/best_future_proof_cloud_backup_service/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ye6qif/best_future_proof_cloud_backup_service/", "subreddit_subscribers": 649343, "created_utc": 1666812804.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_4v1y3v4g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Finally expanded my DIY nettop based NAS and cleaned up the mess", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 102, "top_awarded_type": null, "hide_score": false, "media_metadata": {"it9twubekdw91": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 78, "x": 108, "u": "https://preview.redd.it/it9twubekdw91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e5cbf923507857b1643e3b02ba27887d04811e1c"}, {"y": 157, "x": 216, "u": "https://preview.redd.it/it9twubekdw91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8e87f79cf5c045de78d84491844e5b66ccf74440"}, {"y": 233, "x": 320, "u": "https://preview.redd.it/it9twubekdw91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e397f79f976b5dc5325d45572f153aea4b6f612c"}, {"y": 467, "x": 640, "u": "https://preview.redd.it/it9twubekdw91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7d09f99194d84d6bd7b8a0032a7dc2e6250a763b"}, {"y": 701, "x": 960, "u": "https://preview.redd.it/it9twubekdw91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b13922042ba40bb676a33c1f9a0e44baaa801f65"}, {"y": 788, "x": 1080, "u": "https://preview.redd.it/it9twubekdw91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=685c36c3ade45bea134943c1a2e78df19e3366ea"}], "s": {"y": 2443, "x": 3345, "u": "https://preview.redd.it/it9twubekdw91.jpg?width=3345&amp;format=pjpg&amp;auto=webp&amp;s=6e2bd5a704c8409f482eccd8ef0bc4cd72ffd08a"}, "id": "it9twubekdw91"}, "e724b8yckdw91": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 166, "x": 108, "u": "https://preview.redd.it/e724b8yckdw91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=349cb9418b46f70c10fea8c97a89f640b2162ea7"}, {"y": 332, "x": 216, "u": "https://preview.redd.it/e724b8yckdw91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a57b38cdb7de70533649181572fc37eeb4a9a91c"}, {"y": 492, "x": 320, "u": "https://preview.redd.it/e724b8yckdw91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f537faaa667af11ac8e657fe196a2a7f17bb99e2"}, {"y": 985, "x": 640, "u": "https://preview.redd.it/e724b8yckdw91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ac96968726788d3c642a22149db0ef18e6ffb39b"}, {"y": 1477, "x": 960, "u": "https://preview.redd.it/e724b8yckdw91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4df1ac7cb21342fd89a10afa7878a996ca229d03"}, {"y": 1662, "x": 1080, "u": "https://preview.redd.it/e724b8yckdw91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4334ca1e5470ceda60a74a6c2392939ca6875451"}], "s": {"y": 3453, "x": 2243, "u": "https://preview.redd.it/e724b8yckdw91.jpg?width=2243&amp;format=pjpg&amp;auto=webp&amp;s=71f7bdb356c53478978890b9909530d9eced8f1e"}, "id": "e724b8yckdw91"}, "oxbznmj9kdw91": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 79, "x": 108, "u": "https://preview.redd.it/oxbznmj9kdw91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bb6a3b09794f4604c20e7ebc070b69faa06382f6"}, {"y": 158, "x": 216, "u": "https://preview.redd.it/oxbznmj9kdw91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=304a6bfe26680148b8fb1b8604358898dc4da85e"}, {"y": 234, "x": 320, "u": "https://preview.redd.it/oxbznmj9kdw91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5896eb3e0fc9ba50e28f4317e9e9a5365c2562fb"}, {"y": 468, "x": 640, "u": "https://preview.redd.it/oxbznmj9kdw91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=cbcd077a9f2ffab75fefaf95fe179d2e9d532f52"}, {"y": 703, "x": 960, "u": "https://preview.redd.it/oxbznmj9kdw91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6ff41d070b197cf9613bdb3f90b2c7fe2c0da19f"}, {"y": 790, "x": 1080, "u": "https://preview.redd.it/oxbznmj9kdw91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f9270ea8bbd58bf7260f8cc0a1c58a09d01a4836"}], "s": {"y": 1995, "x": 2724, "u": "https://preview.redd.it/oxbznmj9kdw91.jpg?width=2724&amp;format=pjpg&amp;auto=webp&amp;s=c55fb587258c964e5f0d186508ce55bd57a44cf9"}, "id": "oxbznmj9kdw91"}, "vjztwi2ckdw91": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 35, "x": 108, "u": "https://preview.redd.it/vjztwi2ckdw91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a77fa735449b26f7e2dd3301313dfb7155f9fa3f"}, {"y": 71, "x": 216, "u": "https://preview.redd.it/vjztwi2ckdw91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=77ea8ad28c8abc2068c6f6e941d8e27b93258f30"}, {"y": 105, "x": 320, "u": "https://preview.redd.it/vjztwi2ckdw91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=293ff35b0954d9462f65916b04138d4562abbb49"}], "s": {"y": 196, "x": 594, "u": "https://preview.redd.it/vjztwi2ckdw91.jpg?width=594&amp;format=pjpg&amp;auto=webp&amp;s=b26db008ce30105c8f3ecc907d7c1693722212a2"}, "id": "vjztwi2ckdw91"}}, "name": "t3_yewe3z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 10, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"caption": "Final result", "media_id": "oxbznmj9kdw91", "id": 202605380}, {"media_id": "vjztwi2ckdw91", "id": 202605381}, {"caption": "The Mess", "media_id": "e724b8yckdw91", "id": 202605382}, {"media_id": "it9twubekdw91", "id": 202605383}]}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/sw8deZY04NT75BJv4dxs4F9s-9V3_IT9B4ZOYssk-VA.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666888134.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/yewe3z", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "6TB OMV Safe", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yewe3z", "is_robot_indexable": true, "report_reasons": null, "author": "Le55more", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/yewe3z/finally_expanded_my_diy_nettop_based_nas_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/yewe3z", "subreddit_subscribers": 649343, "created_utc": 1666888134.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I am about to buy a LSI SAS 9212-4i4e PCI Express to 6Gb/s SAS HBA. \n\nFeatures are:\n\nhttps://preview.redd.it/1075j1dbpcw91.png?width=527&amp;format=png&amp;auto=webp&amp;s=d046ca4038968ffa8bfef62a73f10a8894bba6e7\n\nBut I am still quite confused with the specs and information I found online...\n\nCan I use 16 HDDs with this card, without the card bottlenecking? Because its just PCIe 2.0 x8", "author_fullname": "t2_69o8ab94", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LSI SAS 9212-4i4e with 16 HDDs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 67, "top_awarded_type": null, "hide_score": false, "media_metadata": {"1075j1dbpcw91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 52, "x": 108, "u": "https://preview.redd.it/1075j1dbpcw91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d08d876764a6693b0ed3fcdc27256fa646a4b2d4"}, {"y": 104, "x": 216, "u": "https://preview.redd.it/1075j1dbpcw91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c3a83ff85fc8fbeb7e27482d74664c9fd222c2dd"}, {"y": 154, "x": 320, "u": "https://preview.redd.it/1075j1dbpcw91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ba3d0700b2469ceee1e9b19e3c7c15d8460705ff"}], "s": {"y": 254, "x": 527, "u": "https://preview.redd.it/1075j1dbpcw91.png?width=527&amp;format=png&amp;auto=webp&amp;s=d046ca4038968ffa8bfef62a73f10a8894bba6e7"}, "id": "1075j1dbpcw91"}}, "name": "t3_yesa7d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/Qg42SYAqNxTsLVW2hsQhgPXL_V920flwfKYGmLS7200.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666878073.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I am about to buy a LSI SAS 9212-4i4e PCI Express to 6Gb/s SAS HBA. &lt;/p&gt;\n\n&lt;p&gt;Features are:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/1075j1dbpcw91.png?width=527&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d046ca4038968ffa8bfef62a73f10a8894bba6e7\"&gt;https://preview.redd.it/1075j1dbpcw91.png?width=527&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d046ca4038968ffa8bfef62a73f10a8894bba6e7&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;But I am still quite confused with the specs and information I found online...&lt;/p&gt;\n\n&lt;p&gt;Can I use 16 HDDs with this card, without the card bottlenecking? Because its just PCIe 2.0 x8&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yesa7d", "is_robot_indexable": true, "report_reasons": null, "author": "clouder300", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yesa7d/lsi_sas_92124i4e_with_16_hdds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yesa7d/lsi_sas_92124i4e_with_16_hdds/", "subreddit_subscribers": 649343, "created_utc": 1666878073.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I downloaded my messages from facebook via the \"Download your information\" tool. When I go to download the messages however, they are split up in 6 zip files of 2.5GB.\n\nWhat I can't figure out is how to use these files together. Do I unzip them and put them in the same folder? Or do I put the contents of them in the same folder? Or something else?\n\nI noticed that only one of the zip files contains an index.html", "author_fullname": "t2_1cckztt1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Facebook Messages Download", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yebvpk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666825821.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I downloaded my messages from facebook via the &amp;quot;Download your information&amp;quot; tool. When I go to download the messages however, they are split up in 6 zip files of 2.5GB.&lt;/p&gt;\n\n&lt;p&gt;What I can&amp;#39;t figure out is how to use these files together. Do I unzip them and put them in the same folder? Or do I put the contents of them in the same folder? Or something else?&lt;/p&gt;\n\n&lt;p&gt;I noticed that only one of the zip files contains an index.html&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yebvpk", "is_robot_indexable": true, "report_reasons": null, "author": "SirJenselot", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yebvpk/facebook_messages_download/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yebvpk/facebook_messages_download/", "subreddit_subscribers": 649343, "created_utc": 1666825821.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am not a significant hoarder, but I do have a TB or two that would be better on archive storage.  Some are old (gone) machine backups, phone backups, training videos I wanted to make sure were not lost.  Other than periodic confirmation the archives are ok I have no need to access them.\n\nDoes anyone use Amazon's long term storage like Glacier? https://aws.amazon.com/s3/storage-classes/glacier/\n\nFor still readily available, milliseconds to few hours, a TB is about $5/mo.  I hate a monthly fee; however to know that is taken care of could be worth it.  With that and a local hard drive I would feel comfortable about the data.\n\nThere is even a long-term, slow access (12 hours), for about $1/TB/mo.  Ultimately this is probably what most of my data needs, but I need to get comfortable with it first.\n\nAny opinions of Glacier?  Are there other similar services that are good/better/cheaper?", "author_fullname": "t2_59nfbq0s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Amazon S3 Glacier Long-Term Storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yearui", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666822887.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am not a significant hoarder, but I do have a TB or two that would be better on archive storage.  Some are old (gone) machine backups, phone backups, training videos I wanted to make sure were not lost.  Other than periodic confirmation the archives are ok I have no need to access them.&lt;/p&gt;\n\n&lt;p&gt;Does anyone use Amazon&amp;#39;s long term storage like Glacier? &lt;a href=\"https://aws.amazon.com/s3/storage-classes/glacier/\"&gt;https://aws.amazon.com/s3/storage-classes/glacier/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;For still readily available, milliseconds to few hours, a TB is about $5/mo.  I hate a monthly fee; however to know that is taken care of could be worth it.  With that and a local hard drive I would feel comfortable about the data.&lt;/p&gt;\n\n&lt;p&gt;There is even a long-term, slow access (12 hours), for about $1/TB/mo.  Ultimately this is probably what most of my data needs, but I need to get comfortable with it first.&lt;/p&gt;\n\n&lt;p&gt;Any opinions of Glacier?  Are there other similar services that are good/better/cheaper?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yearui", "is_robot_indexable": true, "report_reasons": null, "author": "saltyreddrum", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yearui/amazon_s3_glacier_longterm_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yearui/amazon_s3_glacier_longterm_storage/", "subreddit_subscribers": 649343, "created_utc": 1666822887.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi guys,\n\nI'm looking to build a new NAS around an older Ryzen APU like the 3400GE.\n\nI plan to drop in a LSI card and 3 nvmes. I want to host a ZFS with raidz1 and run Ubuntu, Plex and nextcloud.\n\nI want to serve the house, several family members with different storage needs.\n\nI'm open to suggestions for all the other components. I also own a pikvm so remote mgmt is not an issue.\n\nI'd appreciate some suggestions for case, power source, motherboard etc.\n\nThanks!", "author_fullname": "t2_qvc3x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I want to build a NAS around a Ryzen PRO 3400GE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yesgte", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666881103.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666878556.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking to build a new NAS around an older Ryzen APU like the 3400GE.&lt;/p&gt;\n\n&lt;p&gt;I plan to drop in a LSI card and 3 nvmes. I want to host a ZFS with raidz1 and run Ubuntu, Plex and nextcloud.&lt;/p&gt;\n\n&lt;p&gt;I want to serve the house, several family members with different storage needs.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m open to suggestions for all the other components. I also own a pikvm so remote mgmt is not an issue.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d appreciate some suggestions for case, power source, motherboard etc.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yesgte", "is_robot_indexable": true, "report_reasons": null, "author": "fcmircea", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yesgte/i_want_to_build_a_nas_around_a_ryzen_pro_3400ge/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yesgte/i_want_to_build_a_nas_around_a_ryzen_pro_3400ge/", "subreddit_subscribers": 649343, "created_utc": 1666878556.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello!\n\nI am trying to see if there is a simple way to mass-export articles. I've been playing around with IMPORTXML in GoogleSheets, while I have been able to pull dates, titles, descriptions, images of articles, I have been unable to pull the actual article content itself.\n\nFor context, I'm basically working on a passion project of some transcripts of a podcast I like, that I wanted to print and bind for personal reading. There are over 50 posts so I was curious if there was some way to mass export these. I'm dreading copying and pasting the content from each article. \n\nI should note that I am not a developer and know nothing about writing/running scripts. Hoping there might be an easy way for a novice to pull this. \n\n&amp;#x200B;\n\nThank you for any help or direction!", "author_fullname": "t2_tbqxmu6h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Export Blog/Article Content", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yesdup", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666878336.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;I am trying to see if there is a simple way to mass-export articles. I&amp;#39;ve been playing around with IMPORTXML in GoogleSheets, while I have been able to pull dates, titles, descriptions, images of articles, I have been unable to pull the actual article content itself.&lt;/p&gt;\n\n&lt;p&gt;For context, I&amp;#39;m basically working on a passion project of some transcripts of a podcast I like, that I wanted to print and bind for personal reading. There are over 50 posts so I was curious if there was some way to mass export these. I&amp;#39;m dreading copying and pasting the content from each article. &lt;/p&gt;\n\n&lt;p&gt;I should note that I am not a developer and know nothing about writing/running scripts. Hoping there might be an easy way for a novice to pull this. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you for any help or direction!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yesdup", "is_robot_indexable": true, "report_reasons": null, "author": "AccioFawkes", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yesdup/export_blogarticle_content/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yesdup/export_blogarticle_content/", "subreddit_subscribers": 649343, "created_utc": 1666878336.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My team have an upcoming project where we have to upload videos from our conference every day to an s3 bucket so other members of our team can then download and edit those videos at a later time.  \nWe have a 1GB/s wired network connection and are looking to max it out when uploading the rather large files (20-40gb/ea) to S3.  \nMy question is- what software is the fastest to upload to S3? It is probably a Mac, but we should have access to a Windows box if needed.  It has to be a GUI as the user is somewhat technical, but not comfortable with the command line.", "author_fullname": "t2_5hqsm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the fastest upload client for aws s3?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yerxy5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666877172.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My team have an upcoming project where we have to upload videos from our conference every day to an s3 bucket so other members of our team can then download and edit those videos at a later time.&lt;br/&gt;\nWe have a 1GB/s wired network connection and are looking to max it out when uploading the rather large files (20-40gb/ea) to S3.&lt;br/&gt;\nMy question is- what software is the fastest to upload to S3? It is probably a Mac, but we should have access to a Windows box if needed.  It has to be a GUI as the user is somewhat technical, but not comfortable with the command line.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "70TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yerxy5", "is_robot_indexable": true, "report_reasons": null, "author": "el_heffe80", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/yerxy5/what_is_the_fastest_upload_client_for_aws_s3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yerxy5/what_is_the_fastest_upload_client_for_aws_s3/", "subreddit_subscribers": 649343, "created_utc": 1666877172.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Are bad sectors and bit flipping the only cause of file corruption in HDD ?\n\nAny way to detect it immedietly other than CHKDSK ?\n\nOr will the computer just notify me immedietly when that happens", "author_fullname": "t2_5p9rx19x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HDD file corruption causes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yepd4q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666871433.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666869758.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are bad sectors and bit flipping the only cause of file corruption in HDD ?&lt;/p&gt;\n\n&lt;p&gt;Any way to detect it immedietly other than CHKDSK ?&lt;/p&gt;\n\n&lt;p&gt;Or will the computer just notify me immedietly when that happens&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "yepd4q", "is_robot_indexable": true, "report_reasons": null, "author": "VladamirLem9781", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yepd4q/hdd_file_corruption_causes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yepd4q/hdd_file_corruption_causes/", "subreddit_subscribers": 649343, "created_utc": 1666869758.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "**Objective:** Replace buggy Marvell-based PCIe eSATA card with suitable SAS HBA in a ***Desktop*** computer running Windows 10 Pro, for use with individual drives in self-powered eSATA enclosures.\n\n**Question:** Can this support connecting SATA drives in external, self-powered **eSATA** connector enclosures that can be connected **while the PC is** ***booted up*** **and** ***Windows is running*** ? And conversely, will it be possible to disconnect such drives with the Windows option to \"Safely Remove Hardware\" while the PC is running?\n\nI've searched for hours and can't find answer to this question, but perhaps I'm not asking correctly, and this is actually a question of \"Can you hot swap external drives connected to SAS HBA\" ? \ud83e\udd10 \n\nI realize most people are using HBA cards for more extensive, dedicated, always-on storage purposes. I really want to have option to connect SATA drives in external eSATA enclosures to my Win10 PC, AND have the option to attach them while Windows is running, and remove them using the *Safely Remove Hardware* option, also while Windows is running. I'd also like to be able to connect more than 2 at the same time.\n\nYour experience and guidance here will be **VERY** appreciated....**THANKS !**\n\n(The eSATA PCIe card currently installed, now causing problems: [IOCrest/Syba SD-SA2PEX-2E](https://www.sybausa.com/index.php?route=product/product&amp;product_id=168) )", "author_fullname": "t2_suissw8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Replace eSATA PCIe in Win10 PC with SAS HBA for connecting self-powered eSATA drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yf03pc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666896869.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Objective:&lt;/strong&gt; Replace buggy Marvell-based PCIe eSATA card with suitable SAS HBA in a &lt;strong&gt;&lt;em&gt;Desktop&lt;/em&gt;&lt;/strong&gt; computer running Windows 10 Pro, for use with individual drives in self-powered eSATA enclosures.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Question:&lt;/strong&gt; Can this support connecting SATA drives in external, self-powered &lt;strong&gt;eSATA&lt;/strong&gt; connector enclosures that can be connected &lt;strong&gt;while the PC is&lt;/strong&gt; &lt;strong&gt;&lt;em&gt;booted up&lt;/em&gt;&lt;/strong&gt; &lt;strong&gt;and&lt;/strong&gt; &lt;strong&gt;&lt;em&gt;Windows is running&lt;/em&gt;&lt;/strong&gt; ? And conversely, will it be possible to disconnect such drives with the Windows option to &amp;quot;Safely Remove Hardware&amp;quot; while the PC is running?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve searched for hours and can&amp;#39;t find answer to this question, but perhaps I&amp;#39;m not asking correctly, and this is actually a question of &amp;quot;Can you hot swap external drives connected to SAS HBA&amp;quot; ? \ud83e\udd10 &lt;/p&gt;\n\n&lt;p&gt;I realize most people are using HBA cards for more extensive, dedicated, always-on storage purposes. I really want to have option to connect SATA drives in external eSATA enclosures to my Win10 PC, AND have the option to attach them while Windows is running, and remove them using the &lt;em&gt;Safely Remove Hardware&lt;/em&gt; option, also while Windows is running. I&amp;#39;d also like to be able to connect more than 2 at the same time.&lt;/p&gt;\n\n&lt;p&gt;Your experience and guidance here will be &lt;strong&gt;VERY&lt;/strong&gt; appreciated....&lt;strong&gt;THANKS !&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;(The eSATA PCIe card currently installed, now causing problems: &lt;a href=\"https://www.sybausa.com/index.php?route=product/product&amp;amp;product_id=168\"&gt;IOCrest/Syba SD-SA2PEX-2E&lt;/a&gt; )&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yf03pc", "is_robot_indexable": true, "report_reasons": null, "author": "Redditations2u", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yf03pc/replace_esata_pcie_in_win10_pc_with_sas_hba_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yf03pc/replace_esata_pcie_in_win10_pc_with_sas_hba_for/", "subreddit_subscribers": 649343, "created_utc": 1666896869.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I made an unplanned purchase of 20TB drives this week when a friend saw them on Best Buy for $330 ($16.50 / TB). And since I expect these are going to last me for quite awhile I want to make sure I'm kicking things off right. I'll be consolidating various other drives onto these and using some for clients.\n\nWould love it if some of you could share what you like to do to get a new drive up and running in terms of formatting, cluster sizes, surface tests, stress tests, smart tests, etc. \n\nWhat got me thinking of this is u/Malossi167's comment in [this thread](https://www.reddit.com/r/DataHoarder/comments/yc98hc/comment/itl2g4m/?utm_source=share&amp;utm_medium=web2x&amp;context=3) (so thanks!). Would love to see what steps others use.\n\nFor the record these are likely to remain unshucked, GPT formatted Windows drives. Thanks! \n\nhttps://preview.redd.it/z0iigbqy7ew91.png?width=1081&amp;format=png&amp;auto=webp&amp;s=2a71d7457a5fcd669135f9e27c188d600124bc74", "author_fullname": "t2_7exdh8w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you onboard a new drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 104, "top_awarded_type": null, "hide_score": true, "media_metadata": {"z0iigbqy7ew91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 80, "x": 108, "u": "https://preview.redd.it/z0iigbqy7ew91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5d01b1f201943300d2ec66178029faccc91836e9"}, {"y": 161, "x": 216, "u": "https://preview.redd.it/z0iigbqy7ew91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c876f66c97db2db542e1b825286567f84339e3f2"}, {"y": 239, "x": 320, "u": "https://preview.redd.it/z0iigbqy7ew91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=863e3e99048f17c631c6d646c34474f524fbaaac"}, {"y": 478, "x": 640, "u": "https://preview.redd.it/z0iigbqy7ew91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=40c60303257cf1d24871d0257a804bff99853685"}, {"y": 717, "x": 960, "u": "https://preview.redd.it/z0iigbqy7ew91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=fbc5b357223639744b691733c9498c7cfb8e748e"}, {"y": 807, "x": 1080, "u": "https://preview.redd.it/z0iigbqy7ew91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cc1751c25b61fdc8c431551d3d7ca85209fe1ab2"}], "s": {"y": 808, "x": 1081, "u": "https://preview.redd.it/z0iigbqy7ew91.png?width=1081&amp;format=png&amp;auto=webp&amp;s=2a71d7457a5fcd669135f9e27c188d600124bc74"}, "id": "z0iigbqy7ew91"}}, "name": "t3_yezwh4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/646c03qmxvVVldNv0tICivJXAsVwxoovLVwnSDfPTxQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666896370.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I made an unplanned purchase of 20TB drives this week when a friend saw them on Best Buy for $330 ($16.50 / TB). And since I expect these are going to last me for quite awhile I want to make sure I&amp;#39;m kicking things off right. I&amp;#39;ll be consolidating various other drives onto these and using some for clients.&lt;/p&gt;\n\n&lt;p&gt;Would love it if some of you could share what you like to do to get a new drive up and running in terms of formatting, cluster sizes, surface tests, stress tests, smart tests, etc. &lt;/p&gt;\n\n&lt;p&gt;What got me thinking of this is &lt;a href=\"/u/Malossi167\"&gt;u/Malossi167&lt;/a&gt;&amp;#39;s comment in &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/yc98hc/comment/itl2g4m/?utm_source=share&amp;amp;utm_medium=web2x&amp;amp;context=3\"&gt;this thread&lt;/a&gt; (so thanks!). Would love to see what steps others use.&lt;/p&gt;\n\n&lt;p&gt;For the record these are likely to remain unshucked, GPT formatted Windows drives. Thanks! &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/z0iigbqy7ew91.png?width=1081&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2a71d7457a5fcd669135f9e27c188d600124bc74\"&gt;https://preview.redd.it/z0iigbqy7ew91.png?width=1081&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2a71d7457a5fcd669135f9e27c188d600124bc74&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yezwh4", "is_robot_indexable": true, "report_reasons": null, "author": "wdinaun", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yezwh4/how_do_you_onboard_a_new_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yezwh4/how_do_you_onboard_a_new_drive/", "subreddit_subscribers": 649343, "created_utc": 1666896370.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019ve got 1T of PDFs that I\u2019d like to be able to easily access and reference. My computer struggles since they are mostly image scans of 19th century book (also Adobe reader is a dogshit program). My plan is to buy some kind of external storage for my entire PDF library, so I am looking for recommendations for what drive or device to buy. Also, is there some kind of external storage that has its own built in memory to make it easier for my computer to view?", "author_fullname": "t2_zqqlk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PDF storage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yeyjg2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666893055.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve got 1T of PDFs that I\u2019d like to be able to easily access and reference. My computer struggles since they are mostly image scans of 19th century book (also Adobe reader is a dogshit program). My plan is to buy some kind of external storage for my entire PDF library, so I am looking for recommendations for what drive or device to buy. Also, is there some kind of external storage that has its own built in memory to make it easier for my computer to view?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yeyjg2", "is_robot_indexable": true, "report_reasons": null, "author": "Riccma02", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yeyjg2/pdf_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yeyjg2/pdf_storage/", "subreddit_subscribers": 649343, "created_utc": 1666893055.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_h6kxy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ioSafe Synology NAS Fire Test", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_yew1zy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/pe0HgpXKIZQ?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"ioSafe Synology NAS Fire Test!\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": {"oembed": {"provider_url": "https://www.youtube.com/", "title": "ioSafe Synology NAS Fire Test!", "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/pe0HgpXKIZQ?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"ioSafe Synology NAS Fire Test!\"&gt;&lt;/iframe&gt;", "thumbnail_width": 480, "height": 200, "width": 356, "version": "1.0", "author_name": "Lon.TV", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/pe0HgpXKIZQ/hqdefault.jpg", "type": "video", "thumbnail_height": 360, "author_url": "https://www.youtube.com/user/LonSeidman"}, "type": "youtube.com"}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/pe0HgpXKIZQ?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"ioSafe Synology NAS Fire Test!\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/yew1zy", "height": 200}, "link_flair_text": "video", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/IaMEPsIrvKlApDuBFgn5hKzfq_VEtXxD6NJV6zNzJq8.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666887230.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=pe0HgpXKIZQ", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QSk2NMorQ3hvuQgIdfr3xf4OPVQxN9Yd-skTEqBw360.jpg?auto=webp&amp;s=4ccc7a138879ec9b9054ebc74492d2e138b66ac9", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/QSk2NMorQ3hvuQgIdfr3xf4OPVQxN9Yd-skTEqBw360.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2de733801731630f5c6e40e63c214794a0e9dfa6", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/QSk2NMorQ3hvuQgIdfr3xf4OPVQxN9Yd-skTEqBw360.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=98f6d7d8392ec8f4eaa470a47493405010175ed7", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/QSk2NMorQ3hvuQgIdfr3xf4OPVQxN9Yd-skTEqBw360.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d25d7e2bff74f0f190f605c4b4a0b5df4a3f6404", "width": 320, "height": 240}], "variants": {}, "id": "bwuiSu7a6Hsy_qiLtRhb9vuzg7__N8OIWftoN8op3us"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "400TB raw", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "yew1zy", "is_robot_indexable": true, "report_reasons": null, "author": "It_Is1-24PM", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/yew1zy/iosafe_synology_nas_fire_test/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=pe0HgpXKIZQ", "subreddit_subscribers": 649343, "created_utc": 1666887230.0, "num_crossposts": 0, "media": {"oembed": {"provider_url": "https://www.youtube.com/", "title": "ioSafe Synology NAS Fire Test!", "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/pe0HgpXKIZQ?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"ioSafe Synology NAS Fire Test!\"&gt;&lt;/iframe&gt;", "thumbnail_width": 480, "height": 200, "width": 356, "version": "1.0", "author_name": "Lon.TV", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/pe0HgpXKIZQ/hqdefault.jpg", "type": "video", "thumbnail_height": 360, "author_url": "https://www.youtube.com/user/LonSeidman"}, "type": "youtube.com"}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Backstory\n\nI live in Europe and back in 2018 a friend of mine was in the US and picked up a few Easystore 8TBs for me. I shucked them all and put them in my Synology NAS. All worked bar one which could not be detected. I connected it back to my PC first using a WD Elements adapter/case (the Euro version of the Easystore) and the drive was not even detected. Then I used the Easystore \"adapter\" and it powered up but it was detected as a 2TB drive and I could do nothing with it. Windows Disk Manager said it needed to be initialized but threw an error when I tried.  WD Utilities said the SMART test failed and that I had apparently entered a password wrong 5 times. The only option was to Erase but then it threw an exception with no details when I tried that. It was a legit disk too, not one that someone had swaped out and sent back to the store. Since I was not in the US and I had shucked it I assumed I would get no help from WD and put it in a box and forgot about it.\n\nSo now in 2022 its out of warranty and I am curious if there is anything I can do to revive it? Amazingly I still had the adapter from the Easystore case attached to it. I plugged it in again today and it was the same as before. I dont hear any funny sounds either. It spins up when I connect it to the computer, shows up in Disk Manager, still as 2TB but I still cant do anything with it.\n\nOne thing I am not sure about is whether the Easystore adapter I am using is the one that came with the 8TB drive. I had a batch of Easystore 3TB drives previously and it may be from those so maybe that is having trouble with the 8TB drive. The product id is 25fb firmware revision 3004 according to WD Utilities", "author_fullname": "t2_4ercn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trying to revive a WD 8TB Easystore white label I shucked a few years ago that never worked", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yev4xa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666885913.0, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666885055.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Backstory&lt;/p&gt;\n\n&lt;p&gt;I live in Europe and back in 2018 a friend of mine was in the US and picked up a few Easystore 8TBs for me. I shucked them all and put them in my Synology NAS. All worked bar one which could not be detected. I connected it back to my PC first using a WD Elements adapter/case (the Euro version of the Easystore) and the drive was not even detected. Then I used the Easystore &amp;quot;adapter&amp;quot; and it powered up but it was detected as a 2TB drive and I could do nothing with it. Windows Disk Manager said it needed to be initialized but threw an error when I tried.  WD Utilities said the SMART test failed and that I had apparently entered a password wrong 5 times. The only option was to Erase but then it threw an exception with no details when I tried that. It was a legit disk too, not one that someone had swaped out and sent back to the store. Since I was not in the US and I had shucked it I assumed I would get no help from WD and put it in a box and forgot about it.&lt;/p&gt;\n\n&lt;p&gt;So now in 2022 its out of warranty and I am curious if there is anything I can do to revive it? Amazingly I still had the adapter from the Easystore case attached to it. I plugged it in again today and it was the same as before. I dont hear any funny sounds either. It spins up when I connect it to the computer, shows up in Disk Manager, still as 2TB but I still cant do anything with it.&lt;/p&gt;\n\n&lt;p&gt;One thing I am not sure about is whether the Easystore adapter I am using is the one that came with the 8TB drive. I had a batch of Easystore 3TB drives previously and it may be from those so maybe that is having trouble with the 8TB drive. The product id is 25fb firmware revision 3004 according to WD Utilities&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "90TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yev4xa", "is_robot_indexable": true, "report_reasons": null, "author": "brimur", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/yev4xa/trying_to_revive_a_wd_8tb_easystore_white_label_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yev4xa/trying_to_revive_a_wd_8tb_easystore_white_label_i/", "subreddit_subscribers": 649343, "created_utc": 1666885055.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a large collection of clippings from [newspapers.com](https://newspapers.com). Is there a way to grab them all at once instead of downloading them one at a time. I ask because there are thousands, and 1 by 1 downloading would quite a while.", "author_fullname": "t2_s7xdm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bulk Clipping Aquisition", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yeuhsa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666883501.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a large collection of clippings from &lt;a href=\"https://newspapers.com\"&gt;newspapers.com&lt;/a&gt;. Is there a way to grab them all at once instead of downloading them one at a time. I ask because there are thousands, and 1 by 1 downloading would quite a while.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yeuhsa", "is_robot_indexable": true, "report_reasons": null, "author": "macstratdb", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yeuhsa/bulk_clipping_aquisition/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yeuhsa/bulk_clipping_aquisition/", "subreddit_subscribers": 649343, "created_utc": 1666883501.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019m looking at getting a 20tb drive to put into my PC. I\u2019d write to it overnight from the SSD I record 4K gameplay to during the day. I wouldn\u2019t hear the writing at night since the PC is in my office. I would read 4K video from it though while editing on Premiere.\n\nOne question I can\u2019t seem to find an answer on is how much noise differs between basic, NAS, Enterprise drives *when at idle* (or just doing simple reads). Would I notice any difference between, say, a WD Red Pro vs. a WD Gold just sitting there? Or a Seagate Ironwolf Pro vs. Seagate Exos? Are these both any louder than even a typical WD Red or Seagate Barracuda?\n\nBecause if not then I have no issue with getting the enterprise drive instead of the NAS, given the former\u2019s more impressive specs.\n\nYour advice is appreciated.", "author_fullname": "t2_3zfljicy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much does NAS vs. Enterprise hard drive noise differ in idle use?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yes45p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666877894.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666877624.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m looking at getting a 20tb drive to put into my PC. I\u2019d write to it overnight from the SSD I record 4K gameplay to during the day. I wouldn\u2019t hear the writing at night since the PC is in my office. I would read 4K video from it though while editing on Premiere.&lt;/p&gt;\n\n&lt;p&gt;One question I can\u2019t seem to find an answer on is how much noise differs between basic, NAS, Enterprise drives &lt;em&gt;when at idle&lt;/em&gt; (or just doing simple reads). Would I notice any difference between, say, a WD Red Pro vs. a WD Gold just sitting there? Or a Seagate Ironwolf Pro vs. Seagate Exos? Are these both any louder than even a typical WD Red or Seagate Barracuda?&lt;/p&gt;\n\n&lt;p&gt;Because if not then I have no issue with getting the enterprise drive instead of the NAS, given the former\u2019s more impressive specs.&lt;/p&gt;\n\n&lt;p&gt;Your advice is appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yes45p", "is_robot_indexable": true, "report_reasons": null, "author": "sharingmyxp", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yes45p/how_much_does_nas_vs_enterprise_hard_drive_noise/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yes45p/how_much_does_nas_vs_enterprise_hard_drive_noise/", "subreddit_subscribers": 649343, "created_utc": 1666877624.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am currently in the process of building a new server and in the process of looking for parts someone is offering me (those would be additional to my new main server, the more storage the better? :p ) \n\na bundle of  three older netapp JBODs (including disks see image)  \n1. NetApp Unnamed 24bay 2.5\" 2x IOM6 Sas controllers and 15x 600gb  \n2. NetApp FS2040 with 12x 600gb  \n3. NetApp DS14M4 with 14x 300gb\n\nFor 250\u20ac / 250 USD\n\nI am not sure if this is a good deal tho, but i am thinking of it bc i got a bunch (like 25x 3.5\" 3tb) Sas drives laying around i dont really have a place for since i am usually only using higher capacity exos drives in my newer servers.\n\n[https://cache.willhaben.at/mmo/2/614/813/572\\_-1961687663.jpg](https://cache.willhaben.at/mmo/2/614/813/572_-1961687663.jpg)", "author_fullname": "t2_8jnr5wv6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice | A good idea to buy old Netapps for Backup storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yerhxd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666875968.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently in the process of building a new server and in the process of looking for parts someone is offering me (those would be additional to my new main server, the more storage the better? :p ) &lt;/p&gt;\n\n&lt;p&gt;a bundle of  three older netapp JBODs (including disks see image)&lt;br/&gt;\n1. NetApp Unnamed 24bay 2.5&amp;quot; 2x IOM6 Sas controllers and 15x 600gb&lt;br/&gt;\n2. NetApp FS2040 with 12x 600gb&lt;br/&gt;\n3. NetApp DS14M4 with 14x 300gb&lt;/p&gt;\n\n&lt;p&gt;For 250\u20ac / 250 USD&lt;/p&gt;\n\n&lt;p&gt;I am not sure if this is a good deal tho, but i am thinking of it bc i got a bunch (like 25x 3.5&amp;quot; 3tb) Sas drives laying around i dont really have a place for since i am usually only using higher capacity exos drives in my newer servers.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://cache.willhaben.at/mmo/2/614/813/572_-1961687663.jpg\"&gt;https://cache.willhaben.at/mmo/2/614/813/572_-1961687663.jpg&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/j-7r26GYbfBsNLoVWcKbXJAxGsAR9Esz7yMerVEP5hM.jpg?auto=webp&amp;s=24c89c5044d404c4338817afcd3b0479c588cd81", "width": 992, "height": 1024}, "resolutions": [{"url": "https://external-preview.redd.it/j-7r26GYbfBsNLoVWcKbXJAxGsAR9Esz7yMerVEP5hM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1a9108f305248371feeb4bfc726c07f1e8d325af", "width": 108, "height": 111}, {"url": "https://external-preview.redd.it/j-7r26GYbfBsNLoVWcKbXJAxGsAR9Esz7yMerVEP5hM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ab90f537645678feb707929c2204db03ebc918fa", "width": 216, "height": 222}, {"url": "https://external-preview.redd.it/j-7r26GYbfBsNLoVWcKbXJAxGsAR9Esz7yMerVEP5hM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ddf146dbfa560d00ee9f4347919adf29e06fe08b", "width": 320, "height": 330}, {"url": "https://external-preview.redd.it/j-7r26GYbfBsNLoVWcKbXJAxGsAR9Esz7yMerVEP5hM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0def5ad521e22b2a1157dbfa1b9b6123245d798b", "width": 640, "height": 660}, {"url": "https://external-preview.redd.it/j-7r26GYbfBsNLoVWcKbXJAxGsAR9Esz7yMerVEP5hM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2c789165a1a7dc0fdc460e752028db5c1710c5dd", "width": 960, "height": 990}], "variants": {}, "id": "dA6zF67vtl4neOBm5qXd_2xvhQjhKrcoHIy9A4fs68o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yerhxd", "is_robot_indexable": true, "report_reasons": null, "author": "Pommes254", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yerhxd/advice_a_good_idea_to_buy_old_netapps_for_backup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yerhxd/advice_a_good_idea_to_buy_old_netapps_for_backup/", "subreddit_subscribers": 649343, "created_utc": 1666875968.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Heyah !\n\nSo I come with a weird situation. Pretty much, a few months ago (around 4 months), I'd in mind to do a home server, building a PC. The idea behind this was to be able to gather all the content / games / programs from all my PCs into one place. Went for it with Unraid.\n\nAfter not so long, I was not really happy about it, feeling like I wasn't hitting the full potential : When i'm moving, some of my stuff is still unavailable, not being able to really do install my stuff the way I wanted on it, getting errors, and so making everything synchronized... Well even more a mess.\n\nLast week, after some holidays, the worst happened. The mainboard died. After 4 months. I feel like it's the too much thing. I'm thinking about switching the motherboard to another one for just that purpose, getting back my files and selling what I can to have some of my money back.\n\nAnd now I realize that maybe my solution is Cloud oriented. I use a OneDrive folder (basic) just to synchronize a few things, and I've to admit it's closer to what I'd need / like. \n\nSo I've started to look at some solutions for that and really liked the idea of icedrive / pcloud where you could have encrypted stuff for well the safety part (at the opposite of OneDrive / GDrive) and also get it for a lifetime. \n\nI just wanted to know what would be the best based on my needs. I want something good for storage (Like 3-5Tb), but also being able to install stuff on it (at least the main files) and then being able to have everything synchronized between 3-4 PC and my phone.\n\nAm I going in the right way ?  \nThanks a lot o/", "author_fullname": "t2_w6xai3n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[New Setup Question] Issue with a NAS, thinking to move to Cloud Services", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yeramh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666875423.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Heyah !&lt;/p&gt;\n\n&lt;p&gt;So I come with a weird situation. Pretty much, a few months ago (around 4 months), I&amp;#39;d in mind to do a home server, building a PC. The idea behind this was to be able to gather all the content / games / programs from all my PCs into one place. Went for it with Unraid.&lt;/p&gt;\n\n&lt;p&gt;After not so long, I was not really happy about it, feeling like I wasn&amp;#39;t hitting the full potential : When i&amp;#39;m moving, some of my stuff is still unavailable, not being able to really do install my stuff the way I wanted on it, getting errors, and so making everything synchronized... Well even more a mess.&lt;/p&gt;\n\n&lt;p&gt;Last week, after some holidays, the worst happened. The mainboard died. After 4 months. I feel like it&amp;#39;s the too much thing. I&amp;#39;m thinking about switching the motherboard to another one for just that purpose, getting back my files and selling what I can to have some of my money back.&lt;/p&gt;\n\n&lt;p&gt;And now I realize that maybe my solution is Cloud oriented. I use a OneDrive folder (basic) just to synchronize a few things, and I&amp;#39;ve to admit it&amp;#39;s closer to what I&amp;#39;d need / like. &lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;ve started to look at some solutions for that and really liked the idea of icedrive / pcloud where you could have encrypted stuff for well the safety part (at the opposite of OneDrive / GDrive) and also get it for a lifetime. &lt;/p&gt;\n\n&lt;p&gt;I just wanted to know what would be the best based on my needs. I want something good for storage (Like 3-5Tb), but also being able to install stuff on it (at least the main files) and then being able to have everything synchronized between 3-4 PC and my phone.&lt;/p&gt;\n\n&lt;p&gt;Am I going in the right way ?&lt;br/&gt;\nThanks a lot o/&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yeramh", "is_robot_indexable": true, "report_reasons": null, "author": "RPAmont", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yeramh/new_setup_question_issue_with_a_nas_thinking_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yeramh/new_setup_question_issue_with_a_nas_thinking_to/", "subreddit_subscribers": 649343, "created_utc": 1666875423.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I recently found an all in one Windows PC which has these specs:\n\n4GB RAM\n\n512 HDD [very slow from what I\u2019ve seen by connecting external SSDs like Samsung T7\u2019s and copying files to HDD]\n\nIntel i3-4150 @3.50 GHz\n\nI opened it up but it doesn\u2019t look like I can upgrade it by adding an internal SSD or extra RAM.\n\nNow, my question is, can I use this as a NAS by installing another OS if I use the internal HDD as storage? Even 512GB makes a difference as I can dump all my \u201cdon\u2019t want but can\u2019t delete\u201d files there.\n\nSorry if I sound dumb, I\u2019m new to Windows and have been using multiple T7 SSDs for storage for a couple of years now.", "author_fullname": "t2_lwukmzjl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about repurposing an old Windows PC.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yem46a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666858198.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently found an all in one Windows PC which has these specs:&lt;/p&gt;\n\n&lt;p&gt;4GB RAM&lt;/p&gt;\n\n&lt;p&gt;512 HDD [very slow from what I\u2019ve seen by connecting external SSDs like Samsung T7\u2019s and copying files to HDD]&lt;/p&gt;\n\n&lt;p&gt;Intel i3-4150 @3.50 GHz&lt;/p&gt;\n\n&lt;p&gt;I opened it up but it doesn\u2019t look like I can upgrade it by adding an internal SSD or extra RAM.&lt;/p&gt;\n\n&lt;p&gt;Now, my question is, can I use this as a NAS by installing another OS if I use the internal HDD as storage? Even 512GB makes a difference as I can dump all my \u201cdon\u2019t want but can\u2019t delete\u201d files there.&lt;/p&gt;\n\n&lt;p&gt;Sorry if I sound dumb, I\u2019m new to Windows and have been using multiple T7 SSDs for storage for a couple of years now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yem46a", "is_robot_indexable": true, "report_reasons": null, "author": "kids-ate-my-liver", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yem46a/question_about_repurposing_an_old_windows_pc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yem46a/question_about_repurposing_an_old_windows_pc/", "subreddit_subscribers": 649343, "created_utc": 1666858198.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Can anyone tel me if I\u2019m SOL on this? Places WD recommends for data recovery are saying 500$-2400$. Opening it up seems to be very difficult and I\u2019m not seeing much in terms of guides for this new style The drive is Barely a year in so it\u2019s covered under warranty but I have my projects on there and don\u2019t want to lose it all.", "author_fullname": "t2_77d0ww6c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WD my passport 4tb: under warranty, but the port is toast:", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yegjpx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666839050.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can anyone tel me if I\u2019m SOL on this? Places WD recommends for data recovery are saying 500$-2400$. Opening it up seems to be very difficult and I\u2019m not seeing much in terms of guides for this new style The drive is Barely a year in so it\u2019s covered under warranty but I have my projects on there and don\u2019t want to lose it all.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yegjpx", "is_robot_indexable": true, "report_reasons": null, "author": "capcomwearego", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yegjpx/wd_my_passport_4tb_under_warranty_but_the_port_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yegjpx/wd_my_passport_4tb_under_warranty_but_the_port_is/", "subreddit_subscribers": 649343, "created_utc": 1666839050.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I'm going to be buying the following:\n\n \n\nSynology DS920+\n\n1 WD Ultrastar 20tb drive (or red, still researching and deciding which to get)\n\nAnd then 3 more HDs of varying size\n\n&amp;#x200B;\n\nNot really relevant but I'll be using this to host my plex server I share with friends+family, videos I shoot myself (hobbyist videographer and photographer), and general data storage such as programs, games maybe, the works. \n\n&amp;#x200B;\n\nQuestion is the ds920+ is $549.99,  Ultra star is $386, and a 12tb ultrastar is $210 at the moment.\n\n&amp;#x200B;\n\nI'm willing to pay these prices but I'd just get salty if I pull the trigger on all that stuff now and then in a month I go back and look at all the money I could have saved. I also don't even know if stuff like this goes on sale during the holidays (pretty sure hds do but not familiar enough to say for sure)\n\n&amp;#x200B;\n\nSo ya, what do you guys think I should do!", "author_fullname": "t2_2462fpy4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I wait till black friday to build my plex server?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yeeyev", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666834446.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;m going to be buying the following:&lt;/p&gt;\n\n&lt;p&gt;Synology DS920+&lt;/p&gt;\n\n&lt;p&gt;1 WD Ultrastar 20tb drive (or red, still researching and deciding which to get)&lt;/p&gt;\n\n&lt;p&gt;And then 3 more HDs of varying size&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Not really relevant but I&amp;#39;ll be using this to host my plex server I share with friends+family, videos I shoot myself (hobbyist videographer and photographer), and general data storage such as programs, games maybe, the works. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Question is the ds920+ is $549.99,  Ultra star is $386, and a 12tb ultrastar is $210 at the moment.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m willing to pay these prices but I&amp;#39;d just get salty if I pull the trigger on all that stuff now and then in a month I go back and look at all the money I could have saved. I also don&amp;#39;t even know if stuff like this goes on sale during the holidays (pretty sure hds do but not familiar enough to say for sure)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So ya, what do you guys think I should do!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yeeyev", "is_robot_indexable": true, "report_reasons": null, "author": "footballthrowaway3", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yeeyev/should_i_wait_till_black_friday_to_build_my_plex/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yeeyev/should_i_wait_till_black_friday_to_build_my_plex/", "subreddit_subscribers": 649343, "created_utc": 1666834446.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Having gotten done with my NAS, I now installed two 12TB drives internally in my desktop PC. They\u2019re not the main drives - my primary C: drive is a striped set of SSDs. But the new drives, for lack of any motivation one way or another, I\u2019ve setup as RAID0. My motherboard handles the RAID and so now I\u2019ve got a single 24TB volume in Windows. I\u2019m using Win7 Pro still but that\u2019s fine. The usage for this drive will be a lot of virtual machines, as well as a junk drive for downloading and parsing through gobs of data to save what I want and trash the rest. Aside from that, no idea\u2026 whatever the future holds. I\u2019m also getting a RAM upgrade in a few days I\u2019ll be installing new chips and get myself up to 32GB RAM. Mostly to accommodate running a bunch of VMs. \n\nSo, my question is: do you think raiding them is overkill and unnecessary, and should I instead make them jbods? I\u2019ve had this machine for quite a few years already and the mobo has done a great job with my C drive raid, so I don\u2019t really have any worries about messing up an array due to anything other than actual damage. \n\nI\u2019m just trying to make the best decision now, before the drive starts to really accumulate a lot of data. \n\nThanks for any opinions you may have.", "author_fullname": "t2_iejnv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Finally got my drives installed and would like to know what you think of RAID0 vs two JBODs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ye6ccn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666811823.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Having gotten done with my NAS, I now installed two 12TB drives internally in my desktop PC. They\u2019re not the main drives - my primary C: drive is a striped set of SSDs. But the new drives, for lack of any motivation one way or another, I\u2019ve setup as RAID0. My motherboard handles the RAID and so now I\u2019ve got a single 24TB volume in Windows. I\u2019m using Win7 Pro still but that\u2019s fine. The usage for this drive will be a lot of virtual machines, as well as a junk drive for downloading and parsing through gobs of data to save what I want and trash the rest. Aside from that, no idea\u2026 whatever the future holds. I\u2019m also getting a RAM upgrade in a few days I\u2019ll be installing new chips and get myself up to 32GB RAM. Mostly to accommodate running a bunch of VMs. &lt;/p&gt;\n\n&lt;p&gt;So, my question is: do you think raiding them is overkill and unnecessary, and should I instead make them jbods? I\u2019ve had this machine for quite a few years already and the mobo has done a great job with my C drive raid, so I don\u2019t really have any worries about messing up an array due to anything other than actual damage. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m just trying to make the best decision now, before the drive starts to really accumulate a lot of data. &lt;/p&gt;\n\n&lt;p&gt;Thanks for any opinions you may have.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ye6ccn", "is_robot_indexable": true, "report_reasons": null, "author": "AndrewZabar", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ye6ccn/finally_got_my_drives_installed_and_would_like_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ye6ccn/finally_got_my_drives_installed_and_would_like_to/", "subreddit_subscribers": 649343, "created_utc": 1666811823.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "RAID 10 array won\u2019t start in Ubuntu", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yep9q7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_13embn", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "homelab", "selftext": "I've tried to do as much troubleshooting as i can but nothing has worked so far so I thought I should try posting here. \n\nI am running Ubuntu Server with x4 8TB drives set up in RAID 10. Originally configured in mdadm when I first installed the OS. Everything was going fine until I tried to add x4 more 8TB drives to the array. I thought I did it correctly as it took a couple of days to finish and it reported that it went successfully. However /dev/md0 wasn't using the extra space. I can't remember exactly what i did to it but my Ubuntu install became corrupted and kept booting into recovery mode. Now whenever I try to start my array it keeps spitting out errors about no superblocks and not enough drives to start the array. I apologize if I don;t provide enough information I'm just lost on what to do.\n\n    ubuntu@ubuntu:~$ sudo mdadm --assemble --scan --force --verbose\n    mdadm: looking for devices for /dev/md/0\n    mdadm: No super block found on /dev/loop8 (Expected magic a92b4efc, got d5ab4258)\n    mdadm: no RAID superblock on /dev/loop8\n    mdadm: No super block found on /dev/dm-0 (Expected magic a92b4efc, got 00000000)\n    mdadm: no RAID superblock on /dev/dm-0\n    mdadm: No super block found on 8:130 (Expected magic a92b4efc, got 07020701)\n    mdadm: no RAID superblock on 8:130\n    mdadm: No super block found on /dev/sdi1 (Expected magic a92b4efc, got 00000000)\n    mdadm: no RAID superblock on /dev/sdi1\n    mdadm: No super block found on /dev/sdi (Expected magic a92b4efc, got e86a9721)\n    mdadm: no RAID superblock on /dev/sdi\n    mdadm: No super block found on /dev/sdf1 (Expected magic a92b4efc, got 00000831)\n    mdadm: no RAID superblock on /dev/sdf1\n    mdadm: No super block found on /dev/sdf (Expected magic a92b4efc, got 00000000)\n    mdadm: no RAID superblock on /dev/sdf\n    mdadm: No super block found on /dev/sdd (Expected magic a92b4efc, got 00000000)\n    mdadm: no RAID superblock on /dev/sdd\n    mdadm: No super block found on /dev/sdc (Expected magic a92b4efc, got 00000000)\n    mdadm: no RAID superblock on /dev/sdc\n    mdadm: No super block found on /dev/sdb (Expected magic a92b4efc, got 00000000)\n    mdadm: no RAID superblock on /dev/sdb\n    mdadm: No super block found on /dev/sda (Expected magic a92b4efc, got 00000000)\n    mdadm: no RAID superblock on /dev/sda\n    mdadm: No super block found on /dev/nvme1n1p3 (Expected magic a92b4efc, got 0000043c)\n    mdadm: no RAID superblock on /dev/nvme1n1p3\n    mdadm: No super block found on /dev/nvme1n1p2 (Expected magic a92b4efc, got 00000000)\n    mdadm: no RAID superblock on /dev/nvme1n1p2\n    mdadm: No super block found on /dev/nvme1n1p1 (Expected magic a92b4efc, got 00000000)\n    mdadm: no RAID superblock on /dev/nvme1n1p1\n    mdadm: No super block found on /dev/nvme1n1 (Expected magic a92b4efc, got 00000000)\n    mdadm: no RAID superblock on /dev/nvme1n1\n    mdadm: No super block found on /dev/nvme0n1p4 (Expected magic a92b4efc, got e9ffc701)\n    mdadm: no RAID superblock on /dev/nvme0n1p4\n    mdadm: No super block found on /dev/nvme0n1p3 (Expected magic a92b4efc, got e30eccdf)\n    mdadm: no RAID superblock on /dev/nvme0n1p3\n    mdadm: No super block found on /dev/nvme0n1p2 (Expected magic a92b4efc, got 00000000)\n    mdadm: no RAID superblock on /dev/nvme0n1p2\n    mdadm: No super block found on /dev/nvme0n1p1 (Expected magic a92b4efc, got 65a7ad5a)\n    mdadm: no RAID superblock on /dev/nvme0n1p1\n    mdadm: No super block found on /dev/nvme0n1 (Expected magic a92b4efc, got 00000000)\n    mdadm: no RAID superblock on /dev/nvme0n1\n    mdadm: No super block found on /dev/loop7 (Expected magic a92b4efc, got a6c8346c)\n    mdadm: no RAID superblock on /dev/loop7\n    mdadm: No super block found on /dev/loop6 (Expected magic a92b4efc, got 1a090af0)\n    mdadm: no RAID superblock on /dev/loop6\n    mdadm: No super block found on /dev/loop5 (Expected magic a92b4efc, got 3e22646e)\n    mdadm: no RAID superblock on /dev/loop5\n    mdadm: No super block found on /dev/loop4 (Expected magic a92b4efc, got c4b43b1a)\n    mdadm: no RAID superblock on /dev/loop4\n    mdadm: No super block found on /dev/loop3 (Expected magic a92b4efc, got 1bd7e597)\n    mdadm: no RAID superblock on /dev/loop3\n    mdadm: No super block found on /dev/loop2 (Expected magic a92b4efc, got 3a23b8f9)\n    mdadm: no RAID superblock on /dev/loop2\n    mdadm: /dev/loop1 is too small for md: size is 8 sectors.\n    mdadm: no RAID superblock on /dev/loop1\n    mdadm: No super block found on /dev/loop0 (Expected magic a92b4efc, got feedffbf)\n    mdadm: no RAID superblock on /dev/loop0\n    mdadm: /dev/sdj is identified as a member of /dev/md/0, slot 4.\n    mdadm: /dev/sdh is identified as a member of /dev/md/0, slot 5.\n    mdadm: /dev/sdg is identified as a member of /dev/md/0, slot 6.\n    mdadm: /dev/sde is identified as a member of /dev/md/0, slot 7.\n    mdadm: no uptodate device for slot 0 of /dev/md/0\n    mdadm: no uptodate device for slot 1 of /dev/md/0\n    mdadm: no uptodate device for slot 2 of /dev/md/0\n    mdadm: no uptodate device for slot 3 of /dev/md/0\n    mdadm: added /dev/sdh to /dev/md/0 as 5\n    mdadm: added /dev/sdg to /dev/md/0 as 6\n    mdadm: added /dev/sde to /dev/md/0 as 7\n    mdadm: added /dev/sdj to /dev/md/0 as 4\n    mdadm: /dev/md/0 assembled from 4 drives - not enough to start the array.\n    \n    ubuntu@ubuntu:~$ sudo mdadm --detail /dev/md0\n    /dev/md0:\n               Version : 1.2\n            Raid Level : raid10\n         Total Devices : 4\n           Persistence : Superblock is persistent\n    \n                 State : inactive\n       Working Devices : 4\n    \n                  Name : ubuntu-server:0\n                  UUID : ad6b3838:2414b1d5:ec5ddd26:af9c216e\n                Events : 134880\n    \n        Number   Major   Minor   RaidDevice\n    \n           -       8       64        -        /dev/sde\n           -       8      144        -        /dev/sdj\n           -       8      112        -        /dev/sdh\n           -       8       96        -        /dev/sdg\n    \n    ubuntu@ubuntu:~$ sudo mdadm --examine /dev/sd[ejhg]\n    /dev/sde:\n              Magic : a92b4efc\n            Version : 1.2\n        Feature Map : 0x1\n         Array UUID : ad6b3838:2414b1d5:ec5ddd26:af9c216e\n               Name : ubuntu-server:0\n      Creation Time : Mon Apr 25 03:30:35 2022\n         Raid Level : raid10\n       Raid Devices : 8\n    \n     Avail Dev Size : 15627790000 sectors (7.28 TiB 8.00 TB)\n         Array Size : 31255578624 KiB (29.11 TiB 32.01 TB)\n      Used Dev Size : 15627789312 sectors (7.28 TiB 8.00 TB)\n        Data Offset : 263168 sectors\n       Super Offset : 8 sectors\n       Unused Space : before=263080 sectors, after=688 sectors\n              State : clean\n        Device UUID : 7e855b7b:deea5506:96349577:2b25d081\n    \n    Internal Bitmap : 8 sectors from superblock\n        Update Time : Sun Oct 23 08:53:58 2022\n      Bad Block Log : 512 entries available at offset 72 sectors\n           Checksum : 623d147b - correct\n             Events : 134880\n    \n             Layout : near=2\n         Chunk Size : 512K\n    \n       Device Role : Active device 7\n       Array State : AAAAAAAA ('A' == active, '.' == missing, 'R' == replacing)\n    /dev/sdg:\n              Magic : a92b4efc\n            Version : 1.2\n        Feature Map : 0x1\n         Array UUID : ad6b3838:2414b1d5:ec5ddd26:af9c216e\n               Name : ubuntu-server:0\n      Creation Time : Mon Apr 25 03:30:35 2022\n         Raid Level : raid10\n       Raid Devices : 8\n    \n     Avail Dev Size : 15627790000 sectors (7.28 TiB 8.00 TB)\n         Array Size : 31255578624 KiB (29.11 TiB 32.01 TB)\n      Used Dev Size : 15627789312 sectors (7.28 TiB 8.00 TB)\n        Data Offset : 263168 sectors\n       Super Offset : 8 sectors\n       Unused Space : before=263080 sectors, after=688 sectors\n              State : clean\n        Device UUID : b50b1791:f6998cd1:20ca9527:f00624fd\n    \n    Internal Bitmap : 8 sectors from superblock\n        Update Time : Sun Oct 23 08:53:58 2022\n      Bad Block Log : 512 entries available at offset 72 sectors\n           Checksum : 6e83c11b - correct\n             Events : 134880\n    \n             Layout : near=2\n         Chunk Size : 512K\n    \n       Device Role : Active device 6\n       Array State : AAAAAAAA ('A' == active, '.' == missing, 'R' == replacing)\n    /dev/sdh:\n              Magic : a92b4efc\n            Version : 1.2\n        Feature Map : 0x1\n         Array UUID : ad6b3838:2414b1d5:ec5ddd26:af9c216e\n               Name : ubuntu-server:0\n      Creation Time : Mon Apr 25 03:30:35 2022\n         Raid Level : raid10\n       Raid Devices : 8\n    \n     Avail Dev Size : 15627790000 sectors (7.28 TiB 8.00 TB)\n         Array Size : 31255578624 KiB (29.11 TiB 32.01 TB)\n      Used Dev Size : 15627789312 sectors (7.28 TiB 8.00 TB)\n        Data Offset : 263168 sectors\n       Super Offset : 8 sectors\n       Unused Space : before=263080 sectors, after=688 sectors\n              State : clean\n        Device UUID : dd8a9053:9d0a5076:220829ff:76c4294c\n    \n    Internal Bitmap : 8 sectors from superblock\n        Update Time : Sun Oct 23 08:53:58 2022\n      Bad Block Log : 512 entries available at offset 72 sectors\n           Checksum : fc59ac72 - correct\n             Events : 134880\n    \n             Layout : near=2\n         Chunk Size : 512K\n    \n       Device Role : Active device 5\n       Array State : AAAAAAAA ('A' == active, '.' == missing, 'R' == replacing)\n    /dev/sdj:\n              Magic : a92b4efc\n            Version : 1.2\n        Feature Map : 0x1\n         Array UUID : ad6b3838:2414b1d5:ec5ddd26:af9c216e\n               Name : ubuntu-server:0\n      Creation Time : Mon Apr 25 03:30:35 2022\n         Raid Level : raid10\n       Raid Devices : 8\n    \n     Avail Dev Size : 15627790000 sectors (7.28 TiB 8.00 TB)\n         Array Size : 31255578624 KiB (29.11 TiB 32.01 TB)\n      Used Dev Size : 15627789312 sectors (7.28 TiB 8.00 TB)\n        Data Offset : 263168 sectors\n       Super Offset : 8 sectors\n       Unused Space : before=263080 sectors, after=688 sectors\n              State : clean\n        Device UUID : 6d03c728:18db42e5:b9e21779:17846ff2\n    \n    Internal Bitmap : 8 sectors from superblock\n        Update Time : Sun Oct 23 08:53:58 2022\n      Bad Block Log : 512 entries available at offset 72 sectors\n           Checksum : 60b78fb7 - correct\n             Events : 134880\n    \n             Layout : near=2\n         Chunk Size : 512K\n    \n       Device Role : Active device 4\n       Array State : AAAAAAAA ('A' == active, '.' == missing, 'R' == replacing)\n    \n    ubuntu@ubuntu:~$ sudo fdisk -l\n    Disk /dev/loop0: 2.33 GiB, 2502324224 bytes, 4887352 sectors\n    Units: sectors of 1 * 512 = 512 bytes\n    Sector size (logical/physical): 512 bytes / 512 bytes\n    I/O size (minimum/optimal): 512 bytes / 512 bytes\n    \n    \n    Disk /dev/loop1: 4 KiB, 4096 bytes, 8 sectors\n    Units: sectors of 1 * 512 = 512 bytes\n    Sector size (logical/physical): 512 bytes / 512 bytes\n    I/O size (minimum/optimal): 512 bytes / 512 bytes\n    \n    \n    Disk /dev/loop2: 61.89 MiB, 64901120 bytes, 126760 sectors\n    Units: sectors of 1 * 512 = 512 bytes\n    Sector size (logical/physical): 512 bytes / 512 bytes\n    I/O size (minimum/optimal): 512 bytes / 512 bytes\n    \n    \n    Disk /dev/loop3: 248.76 MiB, 260841472 bytes, 509456 sectors\n    Units: sectors of 1 * 512 = 512 bytes\n    Sector size (logical/physical): 512 bytes / 512 bytes\n    I/O size (minimum/optimal): 512 bytes / 512 bytes\n    \n    \n    Disk /dev/loop4: 155.63 MiB, 163188736 bytes, 318728 sectors\n    Units: sectors of 1 * 512 = 512 bytes\n    Sector size (logical/physical): 512 bytes / 512 bytes\n    I/O size (minimum/optimal): 512 bytes / 512 bytes\n    \n    \n    Disk /dev/loop5: 45.86 MiB, 48087040 bytes, 93920 sectors\n    Units: sectors of 1 * 512 = 512 bytes\n    Sector size (logical/physical): 512 bytes / 512 bytes\n    I/O size (minimum/optimal): 512 bytes / 512 bytes\n    \n    \n    Disk /dev/loop6: 43.63 MiB, 45748224 bytes, 89352 sectors\n    Units: sectors of 1 * 512 = 512 bytes\n    Sector size (logical/physical): 512 bytes / 512 bytes\n    I/O size (minimum/optimal): 512 bytes / 512 bytes\n    \n    \n    Disk /dev/loop7: 284 KiB, 290816 bytes, 568 sectors\n    Units: sectors of 1 * 512 = 512 bytes\n    Sector size (logical/physical): 512 bytes / 512 bytes\n    I/O size (minimum/optimal): 512 bytes / 512 bytes\n    \n    \n    Disk /dev/nvme0n1: 232.89 GiB, 250059350016 bytes, 488397168 sectors\n    Disk model: Samsung SSD 970 EVO Plus 250GB          \n    Units: sectors of 1 * 512 = 512 bytes\n    Sector size (logical/physical): 512 bytes / 512 bytes\n    I/O size (minimum/optimal): 512 bytes / 512 bytes\n    Disklabel type: gpt\n    Disk identifier: 25219762-95A8-4EF4-B80E-4B0E7B825FA6\n    \n    Device            Start       End   Sectors   Size Type\n    /dev/nvme0n1p1     4096      6143      2048     1M BIOS boot\n    /dev/nvme0n1p2     6144   1054719   1048576   512M EFI System\n    /dev/nvme0n1p3 34609152 488397134 453787983 216.4G Solaris /usr &amp; Apple ZFS\n    /dev/nvme0n1p4  1054720  34609151  33554432    16G Linux swap\n    \n    Partition table entries are not in disk order.\n    \n    \n    Disk /dev/nvme1n1: 1.82 TiB, 2000398934016 bytes, 3907029168 sectors\n    Disk model: CT2000P1SSD8                            \n    Units: sectors of 1 * 512 = 512 bytes\n    Sector size (logical/physical): 512 bytes / 512 bytes\n    I/O size (minimum/optimal): 512 bytes / 512 bytes\n    Disklabel type: gpt\n    Disk identifier: 7DBD0048-CC6F-47B7-9D1D-DFF8F0EC4778\n    \n    Device            Start        End    Sectors  Size Type\n    /dev/nvme1n1p1     2048    2203647    2201600    1G EFI System\n    /dev/nvme1n1p2  2203648   10592255    8388608    4G Linux swap\n    /dev/nvme1n1p3 10592256 3907028991 3896436736  1.8T Linux filesystem\n    \n    \n    Disk /dev/sda: 7.28 TiB, 8001563222016 bytes, 15628053168 sectors\n    Disk model: ST8000VN004-2M21\n    Units: sectors of 1 * 512 = 512 bytes\n    Sector size (logical/physical): 512 bytes / 4096 bytes\n    I/O size (minimum/optimal): 4096 bytes / 4096 bytes\n    Disklabel type: gpt\n    Disk identifier: 0D138220-2859-4650-93BF-995597CF7432\n    \n    \n    Disk /dev/sdb: 7.28 TiB, 8001563222016 bytes, 15628053168 sectors\n    Disk model: ST8000VN004-2M21\n    Units: sectors of 1 * 512 = 512 bytes\n    Sector size (logical/physical): 512 bytes / 4096 bytes\n    I/O size (minimum/optimal): 4096 bytes / 4096 bytes\n    Disklabel type: gpt\n    Disk identifier: DF32EDEF-2811-4AA9-8907-B458BDEFFCB3\n    \n    \n    Disk /dev/sdc: 7.28 TiB, 8001563222016 bytes, 15628053168 sectors\n    Disk model: ST8000VN004-2M21\n    Units: sectors of 1 * 512 = 512 bytes\n    Sector size (logical/physical): 512 bytes / 4096 bytes\n    I/O size (minimum/optimal): 4096 bytes / 4096 bytes\n    Disklabel type: gpt\n    Disk identifier: 9B38A391-A114-4F19-ABAF-1D51B203A413\n    \n    \n    Disk /dev/sdd: 7.28 TiB, 8001563222016 bytes, 15628053168 sectors\n    Disk model: ST8000VN004-2M21\n    Units: sectors of 1 * 512 = 512 bytes\n    Sector size (logical/physical): 512 bytes / 4096 bytes\n    I/O size (minimum/optimal): 4096 bytes / 4096 bytes\n    Disklabel type: gpt\n    Disk identifier: F8A132FC-7182-4F45-AA6C-249FC54B1DB1\n    The primary GPT table is corrupt, but the backup appears OK, so that will be used.\n    \n    \n    Disk /dev/sde: 7.28 TiB, 8001563222016 bytes, 15628053168 sectors\n    Disk model: ST8000VN004-3CP1\n    Units: sectors of 1 * 512 = 512 bytes\n    Sector size (logical/physical): 512 bytes / 4096 bytes\n    I/O size (minimum/optimal): 4096 bytes / 4096 bytes\n    Disklabel type: gpt\n    Disk identifier: 9E44DF4B-EEBE-C041-9165-AE8A48979F0E\n    \n    Device     Start         End     Sectors  Size Type\n    /dev/sde1   2048 15628053134 15628051087  7.3T Linux filesystem\n    \n    \n    Disk /dev/sdf: 16.37 TiB, 18000207937536 bytes, 35156656128 sectors\n    Disk model: Generic         \n    Units: sectors of 1 * 512 = 512 bytes\n    Sector size (logical/physical): 512 bytes / 4096 bytes\n    I/O size (minimum/optimal): 4096 bytes / 4096 bytes\n    Disklabel type: gpt\n    Disk identifier: 181FFD43-67EA-442A-B8FF-0F7340AE38CA\n    \n    Device     Start         End     Sectors  Size Type\n    /dev/sdf1   2048 35156654079 35156652032 16.4T Linux filesystem\n    The primary GPT table is corrupt, but the backup appears OK, so that will be used.\n    \n    \n    Disk /dev/sdg: 7.28 TiB, 8001563222016 bytes, 15628053168 sectors\n    Disk model: ST8000VN004-3CP1\n    Units: sectors of 1 * 512 = 512 bytes\n    Sector size (logical/physical): 512 bytes / 4096 bytes\n    I/O size (minimum/optimal): 4096 bytes / 4096 bytes\n    Disklabel type: gpt\n    Disk identifier: 86748330-EA1C-8A4C-8A81-E275EB752D85\n    \n    Device     Start         End     Sectors  Size Type\n    /dev/sdg1   2048 15628053134 15628051087  7.3T Linux filesystem\n    The primary GPT table is corrupt, but the backup appears OK, so that will be used.\n    \n    \n    Disk /dev/sdh: 7.28 TiB, 8001563222016 bytes, 15628053168 sectors\n    Disk model: ST8000VN004-3CP1\n    Units: sectors of 1 * 512 = 512 bytes\n    Sector size (logical/physical): 512 bytes / 4096 bytes\n    I/O size (minimum/optimal): 4096 bytes / 4096 bytes\n    Disklabel type: gpt\n    Disk identifier: BF77BC62-B1F6-254C-BFA5-19265B42CDAF\n    \n    Device     Start         End     Sectors  Size Type\n    /dev/sdh1   2048 15628053134 15628051087  7.3T Linux filesystem\n    \n    \n    Disk /dev/sdi: 57.62 GiB, 61865984000 bytes, 120832000 sectors\n    Disk model: USB Flash Drive \n    Units: sectors of 1 * 512 = 512 bytes\n    Sector size (logical/physical): 512 bytes / 512 bytes\n    I/O size (minimum/optimal): 512 bytes / 512 bytes\n    Disklabel type: dos\n    Disk identifier: 0xc8f094fe\n    \n    Device     Boot     Start       End   Sectors  Size Id Type\n    /dev/sdi1  *         2048 120766463 120764416 57.6G  7 HPFS/NTFS/exFAT\n    /dev/sdi2       120766464 120831999     65536   32M ef EFI (FAT-12/16/32)\n    The primary GPT table is corrupt, but the backup appears OK, so that will be used.\n    \n    \n    Disk /dev/sdj: 7.28 TiB, 8001563222016 bytes, 15628053168 sectors\n    Disk model: ST8000VN004-3CP1\n    Units: sectors of 1 * 512 = 512 bytes\n    Sector size (logical/physical): 512 bytes / 4096 bytes\n    I/O size (minimum/optimal): 4096 bytes / 4096 bytes\n    Disklabel type: gpt\n    Disk identifier: 517F2D59-9B0E-4B46-82CF-DCC530CB6564\n    \n    Device     Start         End     Sectors  Size Type\n    /dev/sdj1   2048 15628053134 15628051087  7.3T Linux filesystem\n    \n    \n    Disk /dev/mapper/ventoy: 3.4 GiB, 3654957056 bytes, 7138588 sectors\n    Units: sectors of 1 * 512 = 512 bytes\n    Sector size (logical/physical): 512 bytes / 512 bytes\n    I/O size (minimum/optimal): 512 bytes / 512 bytes\n    Disklabel type: gpt\n    Disk identifier: A09DB2B8-B5F6-43AE-AFB3-91E0A90189A1\n    \n    Device                     Start     End Sectors  Size Type\n    /dev/mapper/ventoy-part1      64 7129427 7129364  3.4G Microsoft basic data\n    /dev/mapper/ventoy-part2 7129428 7137923    8496  4.1M EFI System\n    /dev/mapper/ventoy-part3 7137924 7138523     600  300K Microsoft basic data\n    \n    \n    Disk /dev/loop8: 81.26 MiB, 85209088 bytes, 166424 sectors\n    Units: sectors of 1 * 512 = 512 bytes\n    Sector size (logical/physical): 512 bytes / 512 bytes\n    I/O size (minimum/optimal): 512 bytes / 512 bytes\n    \n\nIf anyone requests any more information I'll gladly do so. I'm grabbing this info from a live instance of Ubuntu. I just wanna get my array back up so I can pull all my data off it for a backup (which in hindsight I should've done before I started messing with my array).", "author_fullname": "t2_13embn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "RAID 10 array won't start in Ubuntu Server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/homelab", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yeoq1o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666867688.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.homelab", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve tried to do as much troubleshooting as i can but nothing has worked so far so I thought I should try posting here. &lt;/p&gt;\n\n&lt;p&gt;I am running Ubuntu Server with x4 8TB drives set up in RAID 10. Originally configured in mdadm when I first installed the OS. Everything was going fine until I tried to add x4 more 8TB drives to the array. I thought I did it correctly as it took a couple of days to finish and it reported that it went successfully. However /dev/md0 wasn&amp;#39;t using the extra space. I can&amp;#39;t remember exactly what i did to it but my Ubuntu install became corrupted and kept booting into recovery mode. Now whenever I try to start my array it keeps spitting out errors about no superblocks and not enough drives to start the array. I apologize if I don;t provide enough information I&amp;#39;m just lost on what to do.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;ubuntu@ubuntu:~$ sudo mdadm --assemble --scan --force --verbose\nmdadm: looking for devices for /dev/md/0\nmdadm: No super block found on /dev/loop8 (Expected magic a92b4efc, got d5ab4258)\nmdadm: no RAID superblock on /dev/loop8\nmdadm: No super block found on /dev/dm-0 (Expected magic a92b4efc, got 00000000)\nmdadm: no RAID superblock on /dev/dm-0\nmdadm: No super block found on 8:130 (Expected magic a92b4efc, got 07020701)\nmdadm: no RAID superblock on 8:130\nmdadm: No super block found on /dev/sdi1 (Expected magic a92b4efc, got 00000000)\nmdadm: no RAID superblock on /dev/sdi1\nmdadm: No super block found on /dev/sdi (Expected magic a92b4efc, got e86a9721)\nmdadm: no RAID superblock on /dev/sdi\nmdadm: No super block found on /dev/sdf1 (Expected magic a92b4efc, got 00000831)\nmdadm: no RAID superblock on /dev/sdf1\nmdadm: No super block found on /dev/sdf (Expected magic a92b4efc, got 00000000)\nmdadm: no RAID superblock on /dev/sdf\nmdadm: No super block found on /dev/sdd (Expected magic a92b4efc, got 00000000)\nmdadm: no RAID superblock on /dev/sdd\nmdadm: No super block found on /dev/sdc (Expected magic a92b4efc, got 00000000)\nmdadm: no RAID superblock on /dev/sdc\nmdadm: No super block found on /dev/sdb (Expected magic a92b4efc, got 00000000)\nmdadm: no RAID superblock on /dev/sdb\nmdadm: No super block found on /dev/sda (Expected magic a92b4efc, got 00000000)\nmdadm: no RAID superblock on /dev/sda\nmdadm: No super block found on /dev/nvme1n1p3 (Expected magic a92b4efc, got 0000043c)\nmdadm: no RAID superblock on /dev/nvme1n1p3\nmdadm: No super block found on /dev/nvme1n1p2 (Expected magic a92b4efc, got 00000000)\nmdadm: no RAID superblock on /dev/nvme1n1p2\nmdadm: No super block found on /dev/nvme1n1p1 (Expected magic a92b4efc, got 00000000)\nmdadm: no RAID superblock on /dev/nvme1n1p1\nmdadm: No super block found on /dev/nvme1n1 (Expected magic a92b4efc, got 00000000)\nmdadm: no RAID superblock on /dev/nvme1n1\nmdadm: No super block found on /dev/nvme0n1p4 (Expected magic a92b4efc, got e9ffc701)\nmdadm: no RAID superblock on /dev/nvme0n1p4\nmdadm: No super block found on /dev/nvme0n1p3 (Expected magic a92b4efc, got e30eccdf)\nmdadm: no RAID superblock on /dev/nvme0n1p3\nmdadm: No super block found on /dev/nvme0n1p2 (Expected magic a92b4efc, got 00000000)\nmdadm: no RAID superblock on /dev/nvme0n1p2\nmdadm: No super block found on /dev/nvme0n1p1 (Expected magic a92b4efc, got 65a7ad5a)\nmdadm: no RAID superblock on /dev/nvme0n1p1\nmdadm: No super block found on /dev/nvme0n1 (Expected magic a92b4efc, got 00000000)\nmdadm: no RAID superblock on /dev/nvme0n1\nmdadm: No super block found on /dev/loop7 (Expected magic a92b4efc, got a6c8346c)\nmdadm: no RAID superblock on /dev/loop7\nmdadm: No super block found on /dev/loop6 (Expected magic a92b4efc, got 1a090af0)\nmdadm: no RAID superblock on /dev/loop6\nmdadm: No super block found on /dev/loop5 (Expected magic a92b4efc, got 3e22646e)\nmdadm: no RAID superblock on /dev/loop5\nmdadm: No super block found on /dev/loop4 (Expected magic a92b4efc, got c4b43b1a)\nmdadm: no RAID superblock on /dev/loop4\nmdadm: No super block found on /dev/loop3 (Expected magic a92b4efc, got 1bd7e597)\nmdadm: no RAID superblock on /dev/loop3\nmdadm: No super block found on /dev/loop2 (Expected magic a92b4efc, got 3a23b8f9)\nmdadm: no RAID superblock on /dev/loop2\nmdadm: /dev/loop1 is too small for md: size is 8 sectors.\nmdadm: no RAID superblock on /dev/loop1\nmdadm: No super block found on /dev/loop0 (Expected magic a92b4efc, got feedffbf)\nmdadm: no RAID superblock on /dev/loop0\nmdadm: /dev/sdj is identified as a member of /dev/md/0, slot 4.\nmdadm: /dev/sdh is identified as a member of /dev/md/0, slot 5.\nmdadm: /dev/sdg is identified as a member of /dev/md/0, slot 6.\nmdadm: /dev/sde is identified as a member of /dev/md/0, slot 7.\nmdadm: no uptodate device for slot 0 of /dev/md/0\nmdadm: no uptodate device for slot 1 of /dev/md/0\nmdadm: no uptodate device for slot 2 of /dev/md/0\nmdadm: no uptodate device for slot 3 of /dev/md/0\nmdadm: added /dev/sdh to /dev/md/0 as 5\nmdadm: added /dev/sdg to /dev/md/0 as 6\nmdadm: added /dev/sde to /dev/md/0 as 7\nmdadm: added /dev/sdj to /dev/md/0 as 4\nmdadm: /dev/md/0 assembled from 4 drives - not enough to start the array.\n\nubuntu@ubuntu:~$ sudo mdadm --detail /dev/md0\n/dev/md0:\n           Version : 1.2\n        Raid Level : raid10\n     Total Devices : 4\n       Persistence : Superblock is persistent\n\n             State : inactive\n   Working Devices : 4\n\n              Name : ubuntu-server:0\n              UUID : ad6b3838:2414b1d5:ec5ddd26:af9c216e\n            Events : 134880\n\n    Number   Major   Minor   RaidDevice\n\n       -       8       64        -        /dev/sde\n       -       8      144        -        /dev/sdj\n       -       8      112        -        /dev/sdh\n       -       8       96        -        /dev/sdg\n\nubuntu@ubuntu:~$ sudo mdadm --examine /dev/sd[ejhg]\n/dev/sde:\n          Magic : a92b4efc\n        Version : 1.2\n    Feature Map : 0x1\n     Array UUID : ad6b3838:2414b1d5:ec5ddd26:af9c216e\n           Name : ubuntu-server:0\n  Creation Time : Mon Apr 25 03:30:35 2022\n     Raid Level : raid10\n   Raid Devices : 8\n\n Avail Dev Size : 15627790000 sectors (7.28 TiB 8.00 TB)\n     Array Size : 31255578624 KiB (29.11 TiB 32.01 TB)\n  Used Dev Size : 15627789312 sectors (7.28 TiB 8.00 TB)\n    Data Offset : 263168 sectors\n   Super Offset : 8 sectors\n   Unused Space : before=263080 sectors, after=688 sectors\n          State : clean\n    Device UUID : 7e855b7b:deea5506:96349577:2b25d081\n\nInternal Bitmap : 8 sectors from superblock\n    Update Time : Sun Oct 23 08:53:58 2022\n  Bad Block Log : 512 entries available at offset 72 sectors\n       Checksum : 623d147b - correct\n         Events : 134880\n\n         Layout : near=2\n     Chunk Size : 512K\n\n   Device Role : Active device 7\n   Array State : AAAAAAAA (&amp;#39;A&amp;#39; == active, &amp;#39;.&amp;#39; == missing, &amp;#39;R&amp;#39; == replacing)\n/dev/sdg:\n          Magic : a92b4efc\n        Version : 1.2\n    Feature Map : 0x1\n     Array UUID : ad6b3838:2414b1d5:ec5ddd26:af9c216e\n           Name : ubuntu-server:0\n  Creation Time : Mon Apr 25 03:30:35 2022\n     Raid Level : raid10\n   Raid Devices : 8\n\n Avail Dev Size : 15627790000 sectors (7.28 TiB 8.00 TB)\n     Array Size : 31255578624 KiB (29.11 TiB 32.01 TB)\n  Used Dev Size : 15627789312 sectors (7.28 TiB 8.00 TB)\n    Data Offset : 263168 sectors\n   Super Offset : 8 sectors\n   Unused Space : before=263080 sectors, after=688 sectors\n          State : clean\n    Device UUID : b50b1791:f6998cd1:20ca9527:f00624fd\n\nInternal Bitmap : 8 sectors from superblock\n    Update Time : Sun Oct 23 08:53:58 2022\n  Bad Block Log : 512 entries available at offset 72 sectors\n       Checksum : 6e83c11b - correct\n         Events : 134880\n\n         Layout : near=2\n     Chunk Size : 512K\n\n   Device Role : Active device 6\n   Array State : AAAAAAAA (&amp;#39;A&amp;#39; == active, &amp;#39;.&amp;#39; == missing, &amp;#39;R&amp;#39; == replacing)\n/dev/sdh:\n          Magic : a92b4efc\n        Version : 1.2\n    Feature Map : 0x1\n     Array UUID : ad6b3838:2414b1d5:ec5ddd26:af9c216e\n           Name : ubuntu-server:0\n  Creation Time : Mon Apr 25 03:30:35 2022\n     Raid Level : raid10\n   Raid Devices : 8\n\n Avail Dev Size : 15627790000 sectors (7.28 TiB 8.00 TB)\n     Array Size : 31255578624 KiB (29.11 TiB 32.01 TB)\n  Used Dev Size : 15627789312 sectors (7.28 TiB 8.00 TB)\n    Data Offset : 263168 sectors\n   Super Offset : 8 sectors\n   Unused Space : before=263080 sectors, after=688 sectors\n          State : clean\n    Device UUID : dd8a9053:9d0a5076:220829ff:76c4294c\n\nInternal Bitmap : 8 sectors from superblock\n    Update Time : Sun Oct 23 08:53:58 2022\n  Bad Block Log : 512 entries available at offset 72 sectors\n       Checksum : fc59ac72 - correct\n         Events : 134880\n\n         Layout : near=2\n     Chunk Size : 512K\n\n   Device Role : Active device 5\n   Array State : AAAAAAAA (&amp;#39;A&amp;#39; == active, &amp;#39;.&amp;#39; == missing, &amp;#39;R&amp;#39; == replacing)\n/dev/sdj:\n          Magic : a92b4efc\n        Version : 1.2\n    Feature Map : 0x1\n     Array UUID : ad6b3838:2414b1d5:ec5ddd26:af9c216e\n           Name : ubuntu-server:0\n  Creation Time : Mon Apr 25 03:30:35 2022\n     Raid Level : raid10\n   Raid Devices : 8\n\n Avail Dev Size : 15627790000 sectors (7.28 TiB 8.00 TB)\n     Array Size : 31255578624 KiB (29.11 TiB 32.01 TB)\n  Used Dev Size : 15627789312 sectors (7.28 TiB 8.00 TB)\n    Data Offset : 263168 sectors\n   Super Offset : 8 sectors\n   Unused Space : before=263080 sectors, after=688 sectors\n          State : clean\n    Device UUID : 6d03c728:18db42e5:b9e21779:17846ff2\n\nInternal Bitmap : 8 sectors from superblock\n    Update Time : Sun Oct 23 08:53:58 2022\n  Bad Block Log : 512 entries available at offset 72 sectors\n       Checksum : 60b78fb7 - correct\n         Events : 134880\n\n         Layout : near=2\n     Chunk Size : 512K\n\n   Device Role : Active device 4\n   Array State : AAAAAAAA (&amp;#39;A&amp;#39; == active, &amp;#39;.&amp;#39; == missing, &amp;#39;R&amp;#39; == replacing)\n\nubuntu@ubuntu:~$ sudo fdisk -l\nDisk /dev/loop0: 2.33 GiB, 2502324224 bytes, 4887352 sectors\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\n\n\nDisk /dev/loop1: 4 KiB, 4096 bytes, 8 sectors\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\n\n\nDisk /dev/loop2: 61.89 MiB, 64901120 bytes, 126760 sectors\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\n\n\nDisk /dev/loop3: 248.76 MiB, 260841472 bytes, 509456 sectors\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\n\n\nDisk /dev/loop4: 155.63 MiB, 163188736 bytes, 318728 sectors\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\n\n\nDisk /dev/loop5: 45.86 MiB, 48087040 bytes, 93920 sectors\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\n\n\nDisk /dev/loop6: 43.63 MiB, 45748224 bytes, 89352 sectors\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\n\n\nDisk /dev/loop7: 284 KiB, 290816 bytes, 568 sectors\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\n\n\nDisk /dev/nvme0n1: 232.89 GiB, 250059350016 bytes, 488397168 sectors\nDisk model: Samsung SSD 970 EVO Plus 250GB          \nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisklabel type: gpt\nDisk identifier: 25219762-95A8-4EF4-B80E-4B0E7B825FA6\n\nDevice            Start       End   Sectors   Size Type\n/dev/nvme0n1p1     4096      6143      2048     1M BIOS boot\n/dev/nvme0n1p2     6144   1054719   1048576   512M EFI System\n/dev/nvme0n1p3 34609152 488397134 453787983 216.4G Solaris /usr &amp;amp; Apple ZFS\n/dev/nvme0n1p4  1054720  34609151  33554432    16G Linux swap\n\nPartition table entries are not in disk order.\n\n\nDisk /dev/nvme1n1: 1.82 TiB, 2000398934016 bytes, 3907029168 sectors\nDisk model: CT2000P1SSD8                            \nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisklabel type: gpt\nDisk identifier: 7DBD0048-CC6F-47B7-9D1D-DFF8F0EC4778\n\nDevice            Start        End    Sectors  Size Type\n/dev/nvme1n1p1     2048    2203647    2201600    1G EFI System\n/dev/nvme1n1p2  2203648   10592255    8388608    4G Linux swap\n/dev/nvme1n1p3 10592256 3907028991 3896436736  1.8T Linux filesystem\n\n\nDisk /dev/sda: 7.28 TiB, 8001563222016 bytes, 15628053168 sectors\nDisk model: ST8000VN004-2M21\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 4096 bytes\nI/O size (minimum/optimal): 4096 bytes / 4096 bytes\nDisklabel type: gpt\nDisk identifier: 0D138220-2859-4650-93BF-995597CF7432\n\n\nDisk /dev/sdb: 7.28 TiB, 8001563222016 bytes, 15628053168 sectors\nDisk model: ST8000VN004-2M21\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 4096 bytes\nI/O size (minimum/optimal): 4096 bytes / 4096 bytes\nDisklabel type: gpt\nDisk identifier: DF32EDEF-2811-4AA9-8907-B458BDEFFCB3\n\n\nDisk /dev/sdc: 7.28 TiB, 8001563222016 bytes, 15628053168 sectors\nDisk model: ST8000VN004-2M21\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 4096 bytes\nI/O size (minimum/optimal): 4096 bytes / 4096 bytes\nDisklabel type: gpt\nDisk identifier: 9B38A391-A114-4F19-ABAF-1D51B203A413\n\n\nDisk /dev/sdd: 7.28 TiB, 8001563222016 bytes, 15628053168 sectors\nDisk model: ST8000VN004-2M21\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 4096 bytes\nI/O size (minimum/optimal): 4096 bytes / 4096 bytes\nDisklabel type: gpt\nDisk identifier: F8A132FC-7182-4F45-AA6C-249FC54B1DB1\nThe primary GPT table is corrupt, but the backup appears OK, so that will be used.\n\n\nDisk /dev/sde: 7.28 TiB, 8001563222016 bytes, 15628053168 sectors\nDisk model: ST8000VN004-3CP1\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 4096 bytes\nI/O size (minimum/optimal): 4096 bytes / 4096 bytes\nDisklabel type: gpt\nDisk identifier: 9E44DF4B-EEBE-C041-9165-AE8A48979F0E\n\nDevice     Start         End     Sectors  Size Type\n/dev/sde1   2048 15628053134 15628051087  7.3T Linux filesystem\n\n\nDisk /dev/sdf: 16.37 TiB, 18000207937536 bytes, 35156656128 sectors\nDisk model: Generic         \nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 4096 bytes\nI/O size (minimum/optimal): 4096 bytes / 4096 bytes\nDisklabel type: gpt\nDisk identifier: 181FFD43-67EA-442A-B8FF-0F7340AE38CA\n\nDevice     Start         End     Sectors  Size Type\n/dev/sdf1   2048 35156654079 35156652032 16.4T Linux filesystem\nThe primary GPT table is corrupt, but the backup appears OK, so that will be used.\n\n\nDisk /dev/sdg: 7.28 TiB, 8001563222016 bytes, 15628053168 sectors\nDisk model: ST8000VN004-3CP1\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 4096 bytes\nI/O size (minimum/optimal): 4096 bytes / 4096 bytes\nDisklabel type: gpt\nDisk identifier: 86748330-EA1C-8A4C-8A81-E275EB752D85\n\nDevice     Start         End     Sectors  Size Type\n/dev/sdg1   2048 15628053134 15628051087  7.3T Linux filesystem\nThe primary GPT table is corrupt, but the backup appears OK, so that will be used.\n\n\nDisk /dev/sdh: 7.28 TiB, 8001563222016 bytes, 15628053168 sectors\nDisk model: ST8000VN004-3CP1\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 4096 bytes\nI/O size (minimum/optimal): 4096 bytes / 4096 bytes\nDisklabel type: gpt\nDisk identifier: BF77BC62-B1F6-254C-BFA5-19265B42CDAF\n\nDevice     Start         End     Sectors  Size Type\n/dev/sdh1   2048 15628053134 15628051087  7.3T Linux filesystem\n\n\nDisk /dev/sdi: 57.62 GiB, 61865984000 bytes, 120832000 sectors\nDisk model: USB Flash Drive \nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisklabel type: dos\nDisk identifier: 0xc8f094fe\n\nDevice     Boot     Start       End   Sectors  Size Id Type\n/dev/sdi1  *         2048 120766463 120764416 57.6G  7 HPFS/NTFS/exFAT\n/dev/sdi2       120766464 120831999     65536   32M ef EFI (FAT-12/16/32)\nThe primary GPT table is corrupt, but the backup appears OK, so that will be used.\n\n\nDisk /dev/sdj: 7.28 TiB, 8001563222016 bytes, 15628053168 sectors\nDisk model: ST8000VN004-3CP1\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 4096 bytes\nI/O size (minimum/optimal): 4096 bytes / 4096 bytes\nDisklabel type: gpt\nDisk identifier: 517F2D59-9B0E-4B46-82CF-DCC530CB6564\n\nDevice     Start         End     Sectors  Size Type\n/dev/sdj1   2048 15628053134 15628051087  7.3T Linux filesystem\n\n\nDisk /dev/mapper/ventoy: 3.4 GiB, 3654957056 bytes, 7138588 sectors\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisklabel type: gpt\nDisk identifier: A09DB2B8-B5F6-43AE-AFB3-91E0A90189A1\n\nDevice                     Start     End Sectors  Size Type\n/dev/mapper/ventoy-part1      64 7129427 7129364  3.4G Microsoft basic data\n/dev/mapper/ventoy-part2 7129428 7137923    8496  4.1M EFI System\n/dev/mapper/ventoy-part3 7137924 7138523     600  300K Microsoft basic data\n\n\nDisk /dev/loop8: 81.26 MiB, 85209088 bytes, 166424 sectors\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;If anyone requests any more information I&amp;#39;ll gladly do so. I&amp;#39;m grabbing this info from a live instance of Ubuntu. I just wanna get my array back up so I can pull all my data off it for a backup (which in hindsight I should&amp;#39;ve done before I started messing with my array).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "664a26e4-322a-11e6-80ae-0e0378709321", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2ubz7", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff6347", "id": "yeoq1o", "is_robot_indexable": true, "report_reasons": null, "author": "hellodarkness_avi", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/homelab/comments/yeoq1o/raid_10_array_wont_start_in_ubuntu_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/homelab/comments/yeoq1o/raid_10_array_wont_start_in_ubuntu_server/", "subreddit_subscribers": 525977, "created_utc": 1666867688.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1666869468.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.homelab", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/homelab/comments/yeoq1o/raid_10_array_wont_start_in_ubuntu_server/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yep9q7", "is_robot_indexable": true, "report_reasons": null, "author": "hellodarkness_avi", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_yeoq1o", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yep9q7/raid_10_array_wont_start_in_ubuntu/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/homelab/comments/yeoq1o/raid_10_array_wont_start_in_ubuntu_server/", "subreddit_subscribers": 649343, "created_utc": 1666869468.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi\n\nI am looking for ideas on how to back up my entire PC including OS with an external hard drive using this Windows Image thing.\n\nFrom what I understand so far is I\u2019ll need to partition a portion to format for the OS to be stored.\n\nI want this system to be almost entirely autonomous and purely used as a fail safe, every time I save a document or any kind progress on my PC, the external hard drive will update itself simultaneously. A like for like. Should the worst happen, I set up my external hard drive to a new system and set up everything as it was as if nothing happened.\n\nAnd maybe a 3rd partition for manual general use/extra storage I don\u2019t have a particular need on my PC, all about having options!\n\nIs what I\u2019m think of entirely possible? If not what can I do?\n\nAlso advice on reputable brands and drives you use, I have been eyeing up the WD Elements or WD My Book and also the Seagate FireCuda Gaming Hub, the RGB chroma isn\u2019t necessary but a nice touch nonetheless.\n\nLooking forward to your thoughts!", "author_fullname": "t2_6z8llexv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automatic Back-Up of Entire System", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yep6at", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666869154.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi&lt;/p&gt;\n\n&lt;p&gt;I am looking for ideas on how to back up my entire PC including OS with an external hard drive using this Windows Image thing.&lt;/p&gt;\n\n&lt;p&gt;From what I understand so far is I\u2019ll need to partition a portion to format for the OS to be stored.&lt;/p&gt;\n\n&lt;p&gt;I want this system to be almost entirely autonomous and purely used as a fail safe, every time I save a document or any kind progress on my PC, the external hard drive will update itself simultaneously. A like for like. Should the worst happen, I set up my external hard drive to a new system and set up everything as it was as if nothing happened.&lt;/p&gt;\n\n&lt;p&gt;And maybe a 3rd partition for manual general use/extra storage I don\u2019t have a particular need on my PC, all about having options!&lt;/p&gt;\n\n&lt;p&gt;Is what I\u2019m think of entirely possible? If not what can I do?&lt;/p&gt;\n\n&lt;p&gt;Also advice on reputable brands and drives you use, I have been eyeing up the WD Elements or WD My Book and also the Seagate FireCuda Gaming Hub, the RGB chroma isn\u2019t necessary but a nice touch nonetheless.&lt;/p&gt;\n\n&lt;p&gt;Looking forward to your thoughts!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yep6at", "is_robot_indexable": true, "report_reasons": null, "author": "CompanyHot885", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yep6at/automatic_backup_of_entire_system/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yep6at/automatic_backup_of_entire_system/", "subreddit_subscribers": 649343, "created_utc": 1666869154.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}