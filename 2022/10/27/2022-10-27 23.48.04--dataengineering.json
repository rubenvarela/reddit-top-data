{"kind": "Listing", "data": {"after": "t3_yem6ft", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_n5n50", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "It's cron all the way down", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_yez0ad", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 73, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 73, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/MwYU41FHiIcEBAI85vrnfPDevtFvvInRFv0d-dk1TIc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666894200.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/yaeal5qi2ew91.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/yaeal5qi2ew91.png?auto=webp&amp;s=852a00695350cf3b53d3b12f6e0b768ffb674e52", "width": 491, "height": 668}, "resolutions": [{"url": "https://preview.redd.it/yaeal5qi2ew91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=cd87e1377ad8483c4d7be12d098843c6e94b552d", "width": 108, "height": 146}, {"url": "https://preview.redd.it/yaeal5qi2ew91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=884cf89534e839ae088fbad7b62c86c8339fd0f0", "width": 216, "height": 293}, {"url": "https://preview.redd.it/yaeal5qi2ew91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=679d791cac63dfb5ebc616c8bcc18d16bf314d2d", "width": 320, "height": 435}], "variants": {}, "id": "4S2EpRx0f1SPFIO8tuJkQjwqwfmjqojxHLWrE24pFwU"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "yez0ad", "is_robot_indexable": true, "report_reasons": null, "author": "FireflyCaptain", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yez0ad/its_cron_all_the_way_down/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/yaeal5qi2ew91.png", "subreddit_subscribers": 78089, "created_utc": 1666894200.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, \n\nI am a data engineer with almost 4 years of experience. I am currently based in Switzerland and my total compensation is around 180k in the insurance industry. \n\nI feel that as a data engineer I won't be able to significantly increase my income anymore in Europe. \n\nDo you have some tips how to create an additional source of income as a DE in Europe? My evenings and weekends are relatively free, but I am not sure if it is enough time for a side gig.", "author_fullname": "t2_5p9fb9t6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Additional sources of income for a data engineer with a day job", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yelbn4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 50, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 50, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666855730.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666855148.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, &lt;/p&gt;\n\n&lt;p&gt;I am a data engineer with almost 4 years of experience. I am currently based in Switzerland and my total compensation is around 180k in the insurance industry. &lt;/p&gt;\n\n&lt;p&gt;I feel that as a data engineer I won&amp;#39;t be able to significantly increase my income anymore in Europe. &lt;/p&gt;\n\n&lt;p&gt;Do you have some tips how to create an additional source of income as a DE in Europe? My evenings and weekends are relatively free, but I am not sure if it is enough time for a side gig.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yelbn4", "is_robot_indexable": true, "report_reasons": null, "author": "DigAggressive2982", "discussion_type": null, "num_comments": 86, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yelbn4/additional_sources_of_income_for_a_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yelbn4/additional_sources_of_income_for_a_data_engineer/", "subreddit_subscribers": 78089, "created_utc": 1666855148.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know it varies on background, but what do you expect from a junior / medior / senior DE? What are the \"must-know\" questions based on seniority? \n\nDo you usually do live coding? If yes what kind of problems do you focus on?\n\nIf the candidate has a personal project do you care about it? Even if its a medior/senior candidate?", "author_fullname": "t2_xcba5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Technical interviewers! Based on seniority what do you usually expect from candidates?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yesj6s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666878728.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know it varies on background, but what do you expect from a junior / medior / senior DE? What are the &amp;quot;must-know&amp;quot; questions based on seniority? &lt;/p&gt;\n\n&lt;p&gt;Do you usually do live coding? If yes what kind of problems do you focus on?&lt;/p&gt;\n\n&lt;p&gt;If the candidate has a personal project do you care about it? Even if its a medior/senior candidate?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "yesj6s", "is_robot_indexable": true, "report_reasons": null, "author": "mackbenc", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yesj6s/technical_interviewers_based_on_seniority_what_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yesj6s/technical_interviewers_based_on_seniority_what_do/", "subreddit_subscribers": 78089, "created_utc": 1666878728.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As in title. No context given, open interpretation. I'm interested in responses. :)", "author_fullname": "t2_9e7m1qmr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What makes a good data engineer? What differentiates good data engineer from the rest?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yeclpm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666827798.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As in title. No context given, open interpretation. I&amp;#39;m interested in responses. :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yeclpm", "is_robot_indexable": true, "report_reasons": null, "author": "LewWariat", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yeclpm/what_makes_a_good_data_engineer_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yeclpm/what_makes_a_good_data_engineer_what/", "subreddit_subscribers": 78089, "created_utc": 1666827798.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What the title says.", "author_fullname": "t2_52v5oro5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "You have $500 to spend on education and professional development before the end of the year. How do you spend it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yecawp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666833342.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666826968.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What the title says.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yecawp", "is_robot_indexable": true, "report_reasons": null, "author": "skiwhatwhat", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yecawp/you_have_500_to_spend_on_education_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yecawp/you_have_500_to_spend_on_education_and/", "subreddit_subscribers": 78089, "created_utc": 1666826968.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I wanted to ask this, I have read about batch processing and stream processing at a high level but in my project, I am doing data ingestion from an OLTP system during its freeze time. this is batch processing right??", "author_fullname": "t2_6f6khk66", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "data ingestion from an OLTP system", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yeqbm0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666872683.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I wanted to ask this, I have read about batch processing and stream processing at a high level but in my project, I am doing data ingestion from an OLTP system during its freeze time. this is batch processing right??&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yeqbm0", "is_robot_indexable": true, "report_reasons": null, "author": "mainak17", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yeqbm0/data_ingestion_from_an_oltp_system/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yeqbm0/data_ingestion_from_an_oltp_system/", "subreddit_subscribers": 78089, "created_utc": 1666872683.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2mhgth69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to reuse TaskGroups in Airflow and make better DAGs!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 115, "top_awarded_type": null, "hide_score": false, "name": "t3_yet4s9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/kQej6qOOo8JGH9ju51v0FDrUiUDJVpdZ3-F0OA8Z6Xk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666880210.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "linkedin.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.linkedin.com/feed/update/urn:li:activity:6991398253325869056/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/wjBoxa4Xip5X_Ad91SVIwaPQTeC0x7_DdtkeJbEE4UM.jpg?auto=webp&amp;s=a0763b5976d29e8e4384e2962bc4b36f4bcc686a", "width": 1070, "height": 884}, "resolutions": [{"url": "https://external-preview.redd.it/wjBoxa4Xip5X_Ad91SVIwaPQTeC0x7_DdtkeJbEE4UM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=200ec977c8639c6dbac5d6f33a9ef1a21441e02c", "width": 108, "height": 89}, {"url": "https://external-preview.redd.it/wjBoxa4Xip5X_Ad91SVIwaPQTeC0x7_DdtkeJbEE4UM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3047e22b937f4b8151b527b23aa77afd4eb06997", "width": 216, "height": 178}, {"url": "https://external-preview.redd.it/wjBoxa4Xip5X_Ad91SVIwaPQTeC0x7_DdtkeJbEE4UM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e5eec2d89144e34c161e689b3da410e9aa830fd8", "width": 320, "height": 264}, {"url": "https://external-preview.redd.it/wjBoxa4Xip5X_Ad91SVIwaPQTeC0x7_DdtkeJbEE4UM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0929bb8f062b909c1a14b85e6c84046f6d875afc", "width": 640, "height": 528}, {"url": "https://external-preview.redd.it/wjBoxa4Xip5X_Ad91SVIwaPQTeC0x7_DdtkeJbEE4UM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=aef87130e11caa93c395a6fc3425dbd43080da0d", "width": 960, "height": 793}], "variants": {}, "id": "0Tq7PdBUStgC5qLm6ITurkrMJDr7r6CwK2viNt1k3dY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yet4s9", "is_robot_indexable": true, "report_reasons": null, "author": "marclamberti", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yet4s9/how_to_reuse_taskgroups_in_airflow_and_make/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.linkedin.com/feed/update/urn:li:activity:6991398253325869056/", "subreddit_subscribers": 78089, "created_utc": 1666880210.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Update: resolved \n\nHi all,\n\nI'm hoping someone can help me here.\n\nI'm connecting to three tables in Snowflake - header, batch\\_data, employees. Both detail tables connect to the header table on header.header\\_id. I'm trying to create a nested dataset that can be converted into **both** xml and json.\n\nSimplified, but assume the tables are as follows:\n\nheader: header\\_id, batch\n\nbatch\\_data: header\\_id, amount, description\n\nemployees: header\\_id, person\n\nThere is a one to many header &gt; batch\\_data, and also a one to many header &gt; employees.\n\nThe structure will be somewhat like this (json view):\n\n    {\n      \"id\": 123,\n      \"batch\": \"something\"\n      \"batch_data\": [\n        {\n          \"amount\": 15.30,\n          \"description\": \"some description\"\n        },\n        {\n          \"amount\": 16.74,\n          \"description\": \"some other description\"\n        }\n      ],\n      \"employees\": [\n        {\n          \"person\": \"John\"\n        },\n        {\n          \"person\": \"Jane\"\n        }\n      ]\n    }\n\nI can't simply do a pandas.merge as I don't want to fan out the dataset when there are multiple batch records and multiple employee records for the same header.\n\nI'm feeling considerably lost.\n\nAny guidance would be really appreciated!", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Python question I'm too afraid to ask on Stack Overflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yeh4ka", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666895505.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666840771.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Update: resolved &lt;/p&gt;\n\n&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m hoping someone can help me here.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m connecting to three tables in Snowflake - header, batch_data, employees. Both detail tables connect to the header table on header.header_id. I&amp;#39;m trying to create a nested dataset that can be converted into &lt;strong&gt;both&lt;/strong&gt; xml and json.&lt;/p&gt;\n\n&lt;p&gt;Simplified, but assume the tables are as follows:&lt;/p&gt;\n\n&lt;p&gt;header: header_id, batch&lt;/p&gt;\n\n&lt;p&gt;batch_data: header_id, amount, description&lt;/p&gt;\n\n&lt;p&gt;employees: header_id, person&lt;/p&gt;\n\n&lt;p&gt;There is a one to many header &amp;gt; batch_data, and also a one to many header &amp;gt; employees.&lt;/p&gt;\n\n&lt;p&gt;The structure will be somewhat like this (json view):&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;{\n  &amp;quot;id&amp;quot;: 123,\n  &amp;quot;batch&amp;quot;: &amp;quot;something&amp;quot;\n  &amp;quot;batch_data&amp;quot;: [\n    {\n      &amp;quot;amount&amp;quot;: 15.30,\n      &amp;quot;description&amp;quot;: &amp;quot;some description&amp;quot;\n    },\n    {\n      &amp;quot;amount&amp;quot;: 16.74,\n      &amp;quot;description&amp;quot;: &amp;quot;some other description&amp;quot;\n    }\n  ],\n  &amp;quot;employees&amp;quot;: [\n    {\n      &amp;quot;person&amp;quot;: &amp;quot;John&amp;quot;\n    },\n    {\n      &amp;quot;person&amp;quot;: &amp;quot;Jane&amp;quot;\n    }\n  ]\n}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I can&amp;#39;t simply do a pandas.merge as I don&amp;#39;t want to fan out the dataset when there are multiple batch records and multiple employee records for the same header.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m feeling considerably lost.&lt;/p&gt;\n\n&lt;p&gt;Any guidance would be really appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yeh4ka", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yeh4ka/python_question_im_too_afraid_to_ask_on_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yeh4ka/python_question_im_too_afraid_to_ask_on_stack/", "subreddit_subscribers": 78089, "created_utc": 1666840771.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_aehfkmkb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks Zero to Hero! - Session 2 | Data Pipeline to Data Lake | Chal...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_yefd2d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/W8FCirJB5C0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Databricks Zero to Hero! - Session 2 | Data Pipeline to Data Lake | Challenges\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Databricks Zero to Hero! - Session 2 | Data Pipeline to Data Lake | Challenges", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/W8FCirJB5C0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Databricks Zero to Hero! - Session 2 | Data Pipeline to Data Lake | Challenges\"&gt;&lt;/iframe&gt;", "author_name": "Cloud and Data Science", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/W8FCirJB5C0/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/c/CloudDataScience"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/W8FCirJB5C0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Databricks Zero to Hero! - Session 2 | Data Pipeline to Data Lake | Challenges\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/yefd2d", "height": 200}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/drcVPOOR6yHmRP_rouZPmeaOAxp-8NC6zQoJs2ARBqU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666835648.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtube.com/watch?v=W8FCirJB5C0&amp;feature=share", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/IFtNyI7Qnu-NjG5S3kmINMrvINRJieC1DAklgGr7c18.jpg?auto=webp&amp;s=e965a0ddebb354ebf6ed1e281feddf66a64ec50f", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/IFtNyI7Qnu-NjG5S3kmINMrvINRJieC1DAklgGr7c18.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=11cbdb9e2952643145d10d60d8dee81bfc2dd5e5", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/IFtNyI7Qnu-NjG5S3kmINMrvINRJieC1DAklgGr7c18.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9d4a669c935a6040cf840907be6a0b43ba285892", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/IFtNyI7Qnu-NjG5S3kmINMrvINRJieC1DAklgGr7c18.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=adc30e049ba01c711fb8f88211fb847ffb1d0e63", "width": 320, "height": 240}], "variants": {}, "id": "vWI321XYGFXz-xCeOWkIjCQMwnKbHVrg7u1WUMofqQE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "yefd2d", "is_robot_indexable": true, "report_reasons": null, "author": "Successful-Aide3077", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yefd2d/databricks_zero_to_hero_session_2_data_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtube.com/watch?v=W8FCirJB5C0&amp;feature=share", "subreddit_subscribers": 78089, "created_utc": 1666835648.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Databricks Zero to Hero! - Session 2 | Data Pipeline to Data Lake | Challenges", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/W8FCirJB5C0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Databricks Zero to Hero! - Session 2 | Data Pipeline to Data Lake | Challenges\"&gt;&lt;/iframe&gt;", "author_name": "Cloud and Data Science", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/W8FCirJB5C0/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/c/CloudDataScience"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m doing a data science master\u2019s and don\u2019t come from a very technical background prior. Sure, ML models are cool and all, but honestly I get more satisfaction out of cleaning and processing data earlier in the lifecycle and I\u2019m more analytics minded. I don\u2019t have credentials to be doing neural nets and feel like chasing the data science title would be a waste and an opportunity cost.\n\nWith this kind of disposition I feel like I might be a better fit for data engineering.\n\nWhat would you advise? Any encouraging words to fight the inevitable impostor syndrome? Haha. Thanks all", "author_fullname": "t2_k1u5d2ej", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I pivot to data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yel4ih", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666854373.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m doing a data science master\u2019s and don\u2019t come from a very technical background prior. Sure, ML models are cool and all, but honestly I get more satisfaction out of cleaning and processing data earlier in the lifecycle and I\u2019m more analytics minded. I don\u2019t have credentials to be doing neural nets and feel like chasing the data science title would be a waste and an opportunity cost.&lt;/p&gt;\n\n&lt;p&gt;With this kind of disposition I feel like I might be a better fit for data engineering.&lt;/p&gt;\n\n&lt;p&gt;What would you advise? Any encouraging words to fight the inevitable impostor syndrome? Haha. Thanks all&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yel4ih", "is_robot_indexable": true, "report_reasons": null, "author": "Far_Country_3732", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yel4ih/should_i_pivot_to_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yel4ih/should_i_pivot_to_data_engineering/", "subreddit_subscribers": 78089, "created_utc": 1666854373.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In Berlin, what should be the salary expectation for someone who has been working as a DE for 3 years and before that as Backend Dev 3 more years? \n\nI mostly worked at small companies where the role required both a bit backend and data experience, I fit in this pretty well. For example at my current place we work with Neo4j, ElasticSearch and GraphQL, separate for different tenants/customers. I am responsible for all the steps for integration of a new data source, from analysis and modelling to pushing, to exposing the data via ES and GraphQL API. We do ETLs on Databricks with PySpark and Pandas. I don't manage teams but I do guide one or two juniors we have in my team.\n\nSo far I am quite okay with my current pay but I feel like I am constantly underselling myself specially because I suck at negotiations.", "author_fullname": "t2_12lkky", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Salary expectations for Berlin, Germany", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yewd6n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666888050.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In Berlin, what should be the salary expectation for someone who has been working as a DE for 3 years and before that as Backend Dev 3 more years? &lt;/p&gt;\n\n&lt;p&gt;I mostly worked at small companies where the role required both a bit backend and data experience, I fit in this pretty well. For example at my current place we work with Neo4j, ElasticSearch and GraphQL, separate for different tenants/customers. I am responsible for all the steps for integration of a new data source, from analysis and modelling to pushing, to exposing the data via ES and GraphQL API. We do ETLs on Databricks with PySpark and Pandas. I don&amp;#39;t manage teams but I do guide one or two juniors we have in my team.&lt;/p&gt;\n\n&lt;p&gt;So far I am quite okay with my current pay but I feel like I am constantly underselling myself specially because I suck at negotiations.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yewd6n", "is_robot_indexable": true, "report_reasons": null, "author": "ratulotron", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yewd6n/salary_expectations_for_berlin_germany/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yewd6n/salary_expectations_for_berlin_germany/", "subreddit_subscribers": 78089, "created_utc": 1666888050.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, \n\n  \nI am converting a unix time column to a datetime human readable format, and while using the function below I have a weird behaviour.  \n\nThe column creationDate contains unix stamps like : `1666828800032`\n\nWhat is also weird is the year is the only anomaly. the rest is fine.\n\nUsing external conversion tools showed that the original format is correct.\n\nThanks!  \n\n\nhttps://preview.redd.it/2olqs5azcdw91.png?width=600&amp;format=png&amp;auto=webp&amp;s=a558bbd1c23bd076c08598c2d5ac2b64853f7b56", "author_fullname": "t2_o1lpjxry", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PySpark from_unixtime year not working as expected.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 130, "top_awarded_type": null, "hide_score": false, "media_metadata": {"2olqs5azcdw91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 100, "x": 108, "u": "https://preview.redd.it/2olqs5azcdw91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ddf7e7485806641393a4da2538164c318b750bc5"}, {"y": 200, "x": 216, "u": "https://preview.redd.it/2olqs5azcdw91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d13e56eda982a17567ee7faae55903d133a8386e"}, {"y": 297, "x": 320, "u": "https://preview.redd.it/2olqs5azcdw91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=45c94555e8c1eaf762319ea04a440fb4dea817e8"}], "s": {"y": 558, "x": 600, "u": "https://preview.redd.it/2olqs5azcdw91.png?width=600&amp;format=png&amp;auto=webp&amp;s=a558bbd1c23bd076c08598c2d5ac2b64853f7b56"}, "id": "2olqs5azcdw91"}}, "name": "t3_yevc6n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/1QsNuqylwhtXWrMSxGyb7QH1hchOGlSwEnWhrnhiVl8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666885543.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, &lt;/p&gt;\n\n&lt;p&gt;I am converting a unix time column to a datetime human readable format, and while using the function below I have a weird behaviour.  &lt;/p&gt;\n\n&lt;p&gt;The column creationDate contains unix stamps like : &lt;code&gt;1666828800032&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;What is also weird is the year is the only anomaly. the rest is fine.&lt;/p&gt;\n\n&lt;p&gt;Using external conversion tools showed that the original format is correct.&lt;/p&gt;\n\n&lt;p&gt;Thanks!  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/2olqs5azcdw91.png?width=600&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a558bbd1c23bd076c08598c2d5ac2b64853f7b56\"&gt;https://preview.redd.it/2olqs5azcdw91.png?width=600&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a558bbd1c23bd076c08598c2d5ac2b64853f7b56&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yevc6n", "is_robot_indexable": true, "report_reasons": null, "author": "Minimum-Freedom9865", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yevc6n/pyspark_from_unixtime_year_not_working_as_expected/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yevc6n/pyspark_from_unixtime_year_not_working_as_expected/", "subreddit_subscribers": 78089, "created_utc": 1666885543.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! Curious to know how folks in the community address corrections and adjustments in datapoints in their data pipelines. \n\nExample is if a sensor returns a wild value and you want to null that value, or replace it with something else, where does that sit in your process. \n\nI\u2019ve got an excel file right now that matches a few fields up and corrects it that way, but I don\u2019t think it\u2019s scales very well. Basically have to reprocess the entire pipeline (ETL) to reflect the changes. \n\nThoughts?", "author_fullname": "t2_ahu1o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Correcting data in pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yermwm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666876344.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! Curious to know how folks in the community address corrections and adjustments in datapoints in their data pipelines. &lt;/p&gt;\n\n&lt;p&gt;Example is if a sensor returns a wild value and you want to null that value, or replace it with something else, where does that sit in your process. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve got an excel file right now that matches a few fields up and corrects it that way, but I don\u2019t think it\u2019s scales very well. Basically have to reprocess the entire pipeline (ETL) to reflect the changes. &lt;/p&gt;\n\n&lt;p&gt;Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yermwm", "is_robot_indexable": true, "report_reasons": null, "author": "Namur007", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yermwm/correcting_data_in_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yermwm/correcting_data_in_pipeline/", "subreddit_subscribers": 78089, "created_utc": 1666876344.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "1. Create Iceberg Catalog\n2. Create Iceberg Table\n3. Insert records into table", "author_fullname": "t2_ce2ldlob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Video: 2 minute demonstration of how to get started with Iceberg tables in Dremio Cloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_yeqeef", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 2400, "fallback_url": "https://v.redd.it/qyoi0hgfbcw91/DASH_720.mp4?source=fallback", "height": 720, "width": 1280, "scrubber_media_url": "https://v.redd.it/qyoi0hgfbcw91/DASH_96.mp4", "dash_url": "https://v.redd.it/qyoi0hgfbcw91/DASHPlaylist.mpd?a=1669506484%2CNmNkMTI4NWMwNTdiMzc2ZDMwMjk1Mzg3MWM4YTQ4ZWM0NmFkN2RiNTNiYWEzNGQ4ODJmMTI3Zjg1ZjE5NzYxMA%3D%3D&amp;v=1&amp;f=sd", "duration": 141, "hls_url": "https://v.redd.it/qyoi0hgfbcw91/HLSPlaylist.m3u8?a=1669506484%2CMzNkOGQxY2MwZDM3MzUwNWFiZGU1MDVlN2QwZDY3NTc4YmU5NDc1MzBhYTE4ODUzZTI3ZTYzOGIyYTUyNGNlMQ%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/HDN-bKsKkKwNMcWMnGUXXD7dPmMrKubBurEYWuqDEY8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666872911.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;ol&gt;\n&lt;li&gt;Create Iceberg Catalog&lt;/li&gt;\n&lt;li&gt;Create Iceberg Table&lt;/li&gt;\n&lt;li&gt;Insert records into table&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/qyoi0hgfbcw91", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/zabDP_2fdwCp92duIqc1DjS7sAA0Mx5tW5BjOJ9-eio.png?format=pjpg&amp;auto=webp&amp;s=f5bcc0925bdd28b75394e336614e675e0a960d11", "width": 1600, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/zabDP_2fdwCp92duIqc1DjS7sAA0Mx5tW5BjOJ9-eio.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=98edb62f8b5c3c43a08cef522e186022210c8512", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/zabDP_2fdwCp92duIqc1DjS7sAA0Mx5tW5BjOJ9-eio.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=66672738d1777cadab320c12a1610bd061522088", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/zabDP_2fdwCp92duIqc1DjS7sAA0Mx5tW5BjOJ9-eio.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=9ae9292e417d21e9e14590df37fa779875b2656c", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/zabDP_2fdwCp92duIqc1DjS7sAA0Mx5tW5BjOJ9-eio.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=2c46a75476d46040d8accc03b605fa85eec7aff7", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/zabDP_2fdwCp92duIqc1DjS7sAA0Mx5tW5BjOJ9-eio.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=94c86fe0248ddb4e98fbf19abb0475b36d8b1ff7", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/zabDP_2fdwCp92duIqc1DjS7sAA0Mx5tW5BjOJ9-eio.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=3f64f552197572eac8f07cc340947566596f257c", "width": 1080, "height": 607}], "variants": {}, "id": "qQtKOSP1_UbVF1Z1wBujWLI9flsKMyJ3n30SqjAE-Dg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yeqeef", "is_robot_indexable": true, "report_reasons": null, "author": "amdatalakehouse", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yeqeef/video_2_minute_demonstration_of_how_to_get/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/qyoi0hgfbcw91", "subreddit_subscribers": 78089, "created_utc": 1666872911.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 2400, "fallback_url": "https://v.redd.it/qyoi0hgfbcw91/DASH_720.mp4?source=fallback", "height": 720, "width": 1280, "scrubber_media_url": "https://v.redd.it/qyoi0hgfbcw91/DASH_96.mp4", "dash_url": "https://v.redd.it/qyoi0hgfbcw91/DASHPlaylist.mpd?a=1669506484%2CNmNkMTI4NWMwNTdiMzc2ZDMwMjk1Mzg3MWM4YTQ4ZWM0NmFkN2RiNTNiYWEzNGQ4ODJmMTI3Zjg1ZjE5NzYxMA%3D%3D&amp;v=1&amp;f=sd", "duration": 141, "hls_url": "https://v.redd.it/qyoi0hgfbcw91/HLSPlaylist.m3u8?a=1669506484%2CMzNkOGQxY2MwZDM3MzUwNWFiZGU1MDVlN2QwZDY3NTc4YmU5NDc1MzBhYTE4ODUzZTI3ZTYzOGIyYTUyNGNlMQ%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are a SaaS company in the cybersecurity industry. Looking to hear what you have used as a BI Visualization solution in a similar situation. At our company\u2019s core we are a O365 Microsoft shop but have recently had a large VC funding injection and are moving to scrap our old products on Azure/Dynamics and recreate our new products on AWS (App) and Snowflake (Analytics). We use PowerBI for reporting to our internal stakeholders and will continue to do so.\n\nRight now I\u2019m leaning towards PowerBI embedded as we want our analytics teams who are experts in PBI to manage and deploy these client dashboards and let app focus on what they do best outside analytics and just import these dashboards into IFrames on the apps themselves. \n\nMy main concern is that we are on really tight timelines so will this a heavy lift, especially being on Azure and AWS both connecting through Privatelink? My second concern is we  will have thousands of clients that we\u2019ll have to distribute these dashboards too and the management of IAM access roles between app and PBI will be too complex. \n\nAre there other solutions you recommend? Can we pass a user token to PBI from the app to only expose certain data and will it get out of hand to manage? Thanks for your help on this.", "author_fullname": "t2_811imwee", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Client facing Viz Embedded Solution for SaaS company", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yehwcb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666843166.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are a SaaS company in the cybersecurity industry. Looking to hear what you have used as a BI Visualization solution in a similar situation. At our company\u2019s core we are a O365 Microsoft shop but have recently had a large VC funding injection and are moving to scrap our old products on Azure/Dynamics and recreate our new products on AWS (App) and Snowflake (Analytics). We use PowerBI for reporting to our internal stakeholders and will continue to do so.&lt;/p&gt;\n\n&lt;p&gt;Right now I\u2019m leaning towards PowerBI embedded as we want our analytics teams who are experts in PBI to manage and deploy these client dashboards and let app focus on what they do best outside analytics and just import these dashboards into IFrames on the apps themselves. &lt;/p&gt;\n\n&lt;p&gt;My main concern is that we are on really tight timelines so will this a heavy lift, especially being on Azure and AWS both connecting through Privatelink? My second concern is we  will have thousands of clients that we\u2019ll have to distribute these dashboards too and the management of IAM access roles between app and PBI will be too complex. &lt;/p&gt;\n\n&lt;p&gt;Are there other solutions you recommend? Can we pass a user token to PBI from the app to only expose certain data and will it get out of hand to manage? Thanks for your help on this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yehwcb", "is_robot_indexable": true, "report_reasons": null, "author": "Reasonable_Top_6420", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yehwcb/client_facing_viz_embedded_solution_for_saas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yehwcb/client_facing_viz_embedded_solution_for_saas/", "subreddit_subscribers": 78089, "created_utc": 1666843166.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Will put the sign up link in the comments. You'll need to apply to join their Slack org, then check the #oa-book-club channel to review dates and other information.", "author_fullname": "t2_4041g9mz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Operational Analytics (Club) Book Club: Fundamentals of Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yf34ge", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666904151.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Will put the sign up link in the comments. You&amp;#39;ll need to apply to join their Slack org, then check the #oa-book-club channel to review dates and other information.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yf34ge", "is_robot_indexable": true, "report_reasons": null, "author": "aamoscodes", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yf34ge/operational_analytics_club_book_club_fundamentals/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yf34ge/operational_analytics_club_book_club_fundamentals/", "subreddit_subscribers": 78089, "created_utc": 1666904151.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What is the difference between a data engineer and etl developer? What would be the differentiating use of tools/languages? What methodologies/best practices should either know? I am aware there is often overlap of responsibilities/similarities in tasks between the two, but need to know if a role I applied to internally should be titled ETL developer or am right in asking for the role to be titled Data Engineer instead.", "author_fullname": "t2_3h5wixaf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineer vs ETL developer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yezrg0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666896029.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is the difference between a data engineer and etl developer? What would be the differentiating use of tools/languages? What methodologies/best practices should either know? I am aware there is often overlap of responsibilities/similarities in tasks between the two, but need to know if a role I applied to internally should be titled ETL developer or am right in asking for the role to be titled Data Engineer instead.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yezrg0", "is_robot_indexable": true, "report_reasons": null, "author": "J0hnDutt00n", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yezrg0/data_engineer_vs_etl_developer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yezrg0/data_engineer_vs_etl_developer/", "subreddit_subscribers": 78089, "created_utc": 1666896029.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need a solution that scales and shrinks as needed.", "author_fullname": "t2_tfwkz0xa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hey! Any tips on how I can build a Webhook on Google Cloud Run that receives JSON POST requests, do a little transformation and store them into a Google MySQL DB?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yewc5i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666887956.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need a solution that scales and shrinks as needed.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yewc5i", "is_robot_indexable": true, "report_reasons": null, "author": "Far_Object_7904", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yewc5i/hey_any_tips_on_how_i_can_build_a_webhook_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yewc5i/hey_any_tips_on_how_i_can_build_a_webhook_on/", "subreddit_subscribers": 78089, "created_utc": 1666887956.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3g7ch6cj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Real-time Analytics Database Architecture with Dhruba Borthakur (creator of HDFS &amp; RocksDB)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_yekm2i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Km5880rqbCO76pyqAVh74co_R7ees_UJgsJZ3yd9PAY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666852421.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "rockset.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://rockset.com/videos/real-time-analytics-software-architecture-with-dhruba-borthakur/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6CWeTgF6po6pMQbaVMZ-BZfpStVIyQIrCnFfLjusodc.jpg?auto=webp&amp;s=524499db2b7772d4c7529dc7d770ca7f8e5fc1fb", "width": 1200, "height": 627}, "resolutions": [{"url": "https://external-preview.redd.it/6CWeTgF6po6pMQbaVMZ-BZfpStVIyQIrCnFfLjusodc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0669791390a4a1ee3e629bc4009c128cf6cc2220", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/6CWeTgF6po6pMQbaVMZ-BZfpStVIyQIrCnFfLjusodc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=684cec6bd50fa76c9c057b07837f8604c042ba67", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/6CWeTgF6po6pMQbaVMZ-BZfpStVIyQIrCnFfLjusodc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e0b0ba92185c55974645965ee4cb2e32042a8488", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/6CWeTgF6po6pMQbaVMZ-BZfpStVIyQIrCnFfLjusodc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=eb49fc8b3dcf0b1e24818b37043cd7127814249c", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/6CWeTgF6po6pMQbaVMZ-BZfpStVIyQIrCnFfLjusodc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c5dd698dbcab2c6ce3cacb08f70727629f484641", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/6CWeTgF6po6pMQbaVMZ-BZfpStVIyQIrCnFfLjusodc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7576f70750d9b7fcecfb151c264b7124f2b228ba", "width": 1080, "height": 564}], "variants": {}, "id": "rQkLQl-IFo_4RNyw15f11BiVBkPO5JYpPpXNSa80ZDc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yekm2i", "is_robot_indexable": true, "report_reasons": null, "author": "ssb61", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yekm2i/realtime_analytics_database_architecture_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://rockset.com/videos/real-time-analytics-software-architecture-with-dhruba-borthakur/", "subreddit_subscribers": 78089, "created_utc": 1666852421.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI'm currently working with a Microsoft 365 shop for a company moving away from Excel reporting.\n\nThey're using SharePoint to Dataverse to PowerBI as a stand in untill a more robust solution is viable.\n\nMy question is, how could I involve Python (Prefect) in terms of not having to run it from my local machine? So having a script run on a scheduled basis from a server (if that even makes sense)?\n\nI'm very new to data engineering (as you've probably guessed) as is the company I'm working for so any guidance much appreciated.", "author_fullname": "t2_4s6pt7r6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Run Python not from local machine.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yeisl7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666846028.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working with a Microsoft 365 shop for a company moving away from Excel reporting.&lt;/p&gt;\n\n&lt;p&gt;They&amp;#39;re using SharePoint to Dataverse to PowerBI as a stand in untill a more robust solution is viable.&lt;/p&gt;\n\n&lt;p&gt;My question is, how could I involve Python (Prefect) in terms of not having to run it from my local machine? So having a script run on a scheduled basis from a server (if that even makes sense)?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m very new to data engineering (as you&amp;#39;ve probably guessed) as is the company I&amp;#39;m working for so any guidance much appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yeisl7", "is_robot_indexable": true, "report_reasons": null, "author": "breadncheesetheking1", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yeisl7/run_python_not_from_local_machine/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yeisl7/run_python_not_from_local_machine/", "subreddit_subscribers": 78089, "created_utc": 1666846028.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_buql0vn1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL query to find Facebook common friends", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_yei2bt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/khlyseDlZJs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Hard - SQL Query - Interview - Find users with more than 3 common friends\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Hard - SQL Query - Interview - Find users with more than 3 common friends", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/khlyseDlZJs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Hard - SQL Query - Interview - Find users with more than 3 common friends\"&gt;&lt;/iframe&gt;", "author_name": "Select From Data", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/khlyseDlZJs/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/channel/UCPgrXg1ZT5YvlB1Ulg5PTXA"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/khlyseDlZJs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Hard - SQL Query - Interview - Find users with more than 3 common friends\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/yei2bt", "height": 200}, "link_flair_text": "Interview", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/81cUIjGVmbdcflULmLQMQQgscH47wsTJNDvGxteX568.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666843663.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/khlyseDlZJs", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/SCWWj-R9u62dXSUG8L8ikqgTaZgF68WCZ3xmBCM3a40.jpg?auto=webp&amp;s=4b812947c8a19ed5b6bccfff11c56ce1dd84fcdf", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/SCWWj-R9u62dXSUG8L8ikqgTaZgF68WCZ3xmBCM3a40.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=716d60ab595c6c600ee91355fd815fde08e51699", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/SCWWj-R9u62dXSUG8L8ikqgTaZgF68WCZ3xmBCM3a40.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=188d5e7099eed3df209cd6872d247a00b913a50f", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/SCWWj-R9u62dXSUG8L8ikqgTaZgF68WCZ3xmBCM3a40.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6f72e84aae6297a2a29f8279ef8d1362b829e007", "width": 320, "height": 240}], "variants": {}, "id": "rnOWOQZ-e_inMSh_J9JNadMVThOcBDclsGdjslQcdYQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "yei2bt", "is_robot_indexable": true, "report_reasons": null, "author": "Spirited_Novel2792", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yei2bt/sql_query_to_find_facebook_common_friends/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/khlyseDlZJs", "subreddit_subscribers": 78089, "created_utc": 1666843663.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Hard - SQL Query - Interview - Find users with more than 3 common friends", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/khlyseDlZJs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Hard - SQL Query - Interview - Find users with more than 3 common friends\"&gt;&lt;/iframe&gt;", "author_name": "Select From Data", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/khlyseDlZJs/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/channel/UCPgrXg1ZT5YvlB1Ulg5PTXA"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Today we used requests and os libraries to write object oriented programs that help us to fetch data from the web (html files) and store them in a temp folder. We put these tasks in apache airflow and saw how airflow schedules these tasks to fetch web data. Here is the video https://www.youtube.com/watch?v=NvU5kxgtUpE", "author_fullname": "t2_ck47kwls", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "using airflow to fetch web data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yf4seh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666908085.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Today we used requests and os libraries to write object oriented programs that help us to fetch data from the web (html files) and store them in a temp folder. We put these tasks in apache airflow and saw how airflow schedules these tasks to fetch web data. Here is the video &lt;a href=\"https://www.youtube.com/watch?v=NvU5kxgtUpE\"&gt;https://www.youtube.com/watch?v=NvU5kxgtUpE&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1e25_scX4wJ_YpFSTVZczuYMCTsmW9UHt9TpSMsPODw.jpg?auto=webp&amp;s=1113a2c334403c48e65782a13567f1a6acbb818e", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/1e25_scX4wJ_YpFSTVZczuYMCTsmW9UHt9TpSMsPODw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a653a99d1b5d5c137de5483d47ff0f7defe6f857", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/1e25_scX4wJ_YpFSTVZczuYMCTsmW9UHt9TpSMsPODw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=341ec7eb87d1c4e59481c7316495ffd986decbbc", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/1e25_scX4wJ_YpFSTVZczuYMCTsmW9UHt9TpSMsPODw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4c02396ddc791a3cc73e936e7c4cbaf0f70a83f1", "width": 320, "height": 240}], "variants": {}, "id": "eE41GQD9d0XY9OK9AaKrtI1yeFDpGfgy-bQXha-6oVM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yf4seh", "is_robot_indexable": true, "report_reasons": null, "author": "DaliCodes", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yf4seh/using_airflow_to_fetch_web_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yf4seh/using_airflow_to_fetch_web_data/", "subreddit_subscribers": 78089, "created_utc": 1666908085.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have an interview coming up with Tesla for DE and wanted to know if anyone here has given interviews at Tesla for DE. Would really help :)", "author_fullname": "t2_ahi836bi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tesla Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yf23eu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666901657.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an interview coming up with Tesla for DE and wanted to know if anyone here has given interviews at Tesla for DE. Would really help :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yf23eu", "is_robot_indexable": true, "report_reasons": null, "author": "yyforthewin", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yf23eu/tesla_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yf23eu/tesla_data_engineering/", "subreddit_subscribers": 78089, "created_utc": 1666901657.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am in the early stages of building out a data model / data warehouse in my company. We are loosely following star schema design patterns. \n\nOne of the common analyses our users need is sales / orders by new and repeat users at all levels in our product hierarchy.\n\nIs anyone aware of any design patterns or approaches we could use to model our data?", "author_fullname": "t2_128qvy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Modelling new and repeat customers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yextvb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666891360.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am in the early stages of building out a data model / data warehouse in my company. We are loosely following star schema design patterns. &lt;/p&gt;\n\n&lt;p&gt;One of the common analyses our users need is sales / orders by new and repeat users at all levels in our product hierarchy.&lt;/p&gt;\n\n&lt;p&gt;Is anyone aware of any design patterns or approaches we could use to model our data?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yextvb", "is_robot_indexable": true, "report_reasons": null, "author": "mathewtrivett", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yextvb/modelling_new_and_repeat_customers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yextvb/modelling_new_and_repeat_customers/", "subreddit_subscribers": 78089, "created_utc": 1666891360.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_kyoi486i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Analytics and Machine Learning Integration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_yem6ft", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/HZ6A6FZR12gQEweQfgjsgYZedZfX94MkQLRMW-LG0xM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666858439.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/gooddata-developers/cooperation-between-data-analytics-and-machine-learning-54ffb047cf20", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XRuipPTWZVrIPOyRvPoLp4It9uAXVUq-obPS3ffMHgE.jpg?auto=webp&amp;s=e7e9a3f526d2ea9aec7a0bd9d23008daac98cfca", "width": 1200, "height": 674}, "resolutions": [{"url": "https://external-preview.redd.it/XRuipPTWZVrIPOyRvPoLp4It9uAXVUq-obPS3ffMHgE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c1c9972279d5e784c0f55ae4d020c937480fc269", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/XRuipPTWZVrIPOyRvPoLp4It9uAXVUq-obPS3ffMHgE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6f9b48bb241c6d0df7fd64ef4f7ae9fbcce28223", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/XRuipPTWZVrIPOyRvPoLp4It9uAXVUq-obPS3ffMHgE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b32f57ad7deb5067ede595d7650a208b0a7904fe", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/XRuipPTWZVrIPOyRvPoLp4It9uAXVUq-obPS3ffMHgE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0f2a34a2e220039250cab0108c31e617a40e3991", "width": 640, "height": 359}, {"url": "https://external-preview.redd.it/XRuipPTWZVrIPOyRvPoLp4It9uAXVUq-obPS3ffMHgE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9931e08b2e33079bcfda16c7bc1ae08fab7de3f6", "width": 960, "height": 539}, {"url": "https://external-preview.redd.it/XRuipPTWZVrIPOyRvPoLp4It9uAXVUq-obPS3ffMHgE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3b4e845936cae4b532e14f205736887a5f163736", "width": 1080, "height": 606}], "variants": {}, "id": "1j7JSz5-gepwKFTbsjTMWqzYcHRUTKEnkYetTXyg8JY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yem6ft", "is_robot_indexable": true, "report_reasons": null, "author": "AmphibianInfamous574", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yem6ft/data_analytics_and_machine_learning_integration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/gooddata-developers/cooperation-between-data-analytics-and-machine-learning-54ffb047cf20", "subreddit_subscribers": 78089, "created_utc": 1666858439.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}