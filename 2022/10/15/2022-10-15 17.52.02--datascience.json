{"kind": "Listing", "data": {"after": "t3_y45n2s", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "2.5 weeks ago I received an email for scheduling a phone screen from this recruiter. There were slots throughout October. I thought I wasn't prepared so to give me more time I scheduled it for today. Then came this message :/", "author_fullname": "t2_1likqpjn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this a normal occurrence?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 68, "top_awarded_type": null, "hide_score": false, "name": "t3_y3zv1u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 410, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 410, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/juGq60lJOatOQvj_039rVsGADKKgOUAzJkdT4My7n7s.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1665768163.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;2.5 weeks ago I received an email for scheduling a phone screen from this recruiter. There were slots throughout October. I thought I wasn&amp;#39;t prepared so to give me more time I scheduled it for today. Then came this message :/&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/bpwspcng2tt91.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/bpwspcng2tt91.jpg?auto=webp&amp;s=07a30ee7ed56ef21bf0b4eb20ab6bc484c14606a", "width": 1080, "height": 526}, "resolutions": [{"url": "https://preview.redd.it/bpwspcng2tt91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4e091e39f72d97a4d99a9b3bd47e90094157c3f4", "width": 108, "height": 52}, {"url": "https://preview.redd.it/bpwspcng2tt91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7e78b6d8b8f3240c2803eb0b8dedce8132bfc99a", "width": 216, "height": 105}, {"url": "https://preview.redd.it/bpwspcng2tt91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e5e4a7dc9244e47dc0823cf96033233916e3f01a", "width": 320, "height": 155}, {"url": "https://preview.redd.it/bpwspcng2tt91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=dd2fe2744c4bdad7bc0b5678a8c54ba9d60c61f7", "width": 640, "height": 311}, {"url": "https://preview.redd.it/bpwspcng2tt91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=cca9fe14743ec9f8a894e66fe75f18bea54f5723", "width": 960, "height": 467}, {"url": "https://preview.redd.it/bpwspcng2tt91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b17602641dd854ea84c70c43f20f1eb98fc0005c", "width": 1080, "height": 526}], "variants": {}, "id": "x3eRgX-XgcK6LGtBsSxg0Ls1pDkxQiqyUGQlG8ZoKQ8"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "y3zv1u", "is_robot_indexable": true, "report_reasons": null, "author": "Unusuala1l2e3x4", "discussion_type": null, "num_comments": 67, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y3zv1u/is_this_a_normal_occurrence/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/bpwspcng2tt91.jpg", "subreddit_subscribers": 813711, "created_utc": 1665768163.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello guys.\n\nI'm a former Data Scientist, and I feel really comfortable doing Python stuff and providing value for the business. But in my recent job I just build the model, push the repo and then the MLOPS take care of the infrastructure and things more related to deployment.\n\nI think the tendency in the market is that we are transitioning to roles where the DS can do and end to end project. My question is, any resource online where I can start learning about deployment? Or am I overexagerating with deployment and being able to let the repo ready for deployment is all that is needed?\n\nThanks in advance.", "author_fullname": "t2_qlc00nj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where can I learn more about the engineering part of the role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4962a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 44, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 44, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665791848.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a former Data Scientist, and I feel really comfortable doing Python stuff and providing value for the business. But in my recent job I just build the model, push the repo and then the MLOPS take care of the infrastructure and things more related to deployment.&lt;/p&gt;\n\n&lt;p&gt;I think the tendency in the market is that we are transitioning to roles where the DS can do and end to end project. My question is, any resource online where I can start learning about deployment? Or am I overexagerating with deployment and being able to let the repo ready for deployment is all that is needed?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4962a", "is_robot_indexable": true, "report_reasons": null, "author": "lautaromgo", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4962a/where_can_i_learn_more_about_the_engineering_part/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4962a/where_can_i_learn_more_about_the_engineering_part/", "subreddit_subscribers": 813711, "created_utc": 1665791848.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m interested in learning more about Bayesian Models, and am trying to decide if it would be beneficial to implement them at my work (I work in retail). In what situations do you all use Bayesian models over frequentists models?", "author_fullname": "t2_fjll57b4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "In what situations would a Bayesian model work better than frequentist model?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4obe5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 56, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 56, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665841364.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m interested in learning more about Bayesian Models, and am trying to decide if it would be beneficial to implement them at my work (I work in retail). In what situations do you all use Bayesian models over frequentists models?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4obe5", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Resort-4196", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4obe5/in_what_situations_would_a_bayesian_model_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4obe5/in_what_situations_would_a_bayesian_model_work/", "subreddit_subscribers": 813711, "created_utc": 1665841364.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone! I\u2019m a junior DS where my manager and my skip are almost the same age. That got me thinking what could have my skip done in his career that made him a director level guy as opposed to my manager who is a senior manager. \n\nI thought there will be people here who were able to reach a very senior position. I\u2019m interested to know was there a particular project that you did that made you rise or consistently good exceeding expectations got your promoted.\n\nThanks! Have a good weekend!", "author_fullname": "t2_bv171ji2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DS who were able to climb the corporate ladder, what do you think you did that stood out?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y41ete", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665771944.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone! I\u2019m a junior DS where my manager and my skip are almost the same age. That got me thinking what could have my skip done in his career that made him a director level guy as opposed to my manager who is a senior manager. &lt;/p&gt;\n\n&lt;p&gt;I thought there will be people here who were able to reach a very senior position. I\u2019m interested to know was there a particular project that you did that made you rise or consistently good exceeding expectations got your promoted.&lt;/p&gt;\n\n&lt;p&gt;Thanks! Have a good weekend!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y41ete", "is_robot_indexable": true, "report_reasons": null, "author": "quite--average", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y41ete/ds_who_were_able_to_climb_the_corporate_ladder/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y41ete/ds_who_were_able_to_climb_the_corporate_ladder/", "subreddit_subscribers": 813711, "created_utc": 1665771944.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Mini intro: I'm currently into my 3rd year of bachelor's in mathematics with a minor in data sciences. I decided on this path 2 years ago when I decided to venture out of my current field of engineering. So I have no experience in the tech field yet. \n\nI'm studying part time and I'm not sure if I have the case of imposter syndrome or I really do feel inadequate. In classes, I think I do okay, as I help others with their codes. Please don't take me for boasting or flexing, I had a full time software engineer seeking help from me and praising me as well, and this further adds to my confusion because I can't think that I'm actually bad. \n\nWhen I'm browsing LinkedIn, I see people at my level with very good portfolios, like reducing man-hours by 70% by implementing this-that algorithm etc in their internships. I'm applying for an apprenticeship that has a second assessment coming up and I just feel stressed even though I got past their first assessment. \n\nHas anyone experienced this and how do I go about solving this?", "author_fullname": "t2_vezlk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I know where I stand?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_y4h2re", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 0, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": "", "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665817320.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Mini intro: I&amp;#39;m currently into my 3rd year of bachelor&amp;#39;s in mathematics with a minor in data sciences. I decided on this path 2 years ago when I decided to venture out of my current field of engineering. So I have no experience in the tech field yet. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m studying part time and I&amp;#39;m not sure if I have the case of imposter syndrome or I really do feel inadequate. In classes, I think I do okay, as I help others with their codes. Please don&amp;#39;t take me for boasting or flexing, I had a full time software engineer seeking help from me and praising me as well, and this further adds to my confusion because I can&amp;#39;t think that I&amp;#39;m actually bad. &lt;/p&gt;\n\n&lt;p&gt;When I&amp;#39;m browsing LinkedIn, I see people at my level with very good portfolios, like reducing man-hours by 70% by implementing this-that algorithm etc in their internships. I&amp;#39;m applying for an apprenticeship that has a second assessment coming up and I just feel stressed even though I got past their first assessment. &lt;/p&gt;\n\n&lt;p&gt;Has anyone experienced this and how do I go about solving this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "call_to_action": "", "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4h2re", "is_robot_indexable": true, "report_reasons": null, "author": "Wheynelau", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4h2re/how_do_i_know_where_i_stand/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4h2re/how_do_i_know_where_i_stand/", "subreddit_subscribers": 813711, "created_utc": 1665817320.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm convinced I want to take this MDS program from UBC and I'm just looking for any feedback from anyone who works in the data science field. From my own personal research, it looks like the UBC MDS teaches more applicable skills and content to use in the workplace, but if anyone has any thoughts or experience, I would love to hear it!\n\nHere's the link to the instructor's github. There's links within this site that explain what content is covered in the courses\n\n[https://ubc-mds.github.io/](https://ubc-mds.github.io/)", "author_fullname": "t2_27hfqocy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on the UBC Master of Data Science program?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y44wk9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665780697.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m convinced I want to take this MDS program from UBC and I&amp;#39;m just looking for any feedback from anyone who works in the data science field. From my own personal research, it looks like the UBC MDS teaches more applicable skills and content to use in the workplace, but if anyone has any thoughts or experience, I would love to hear it!&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the link to the instructor&amp;#39;s github. There&amp;#39;s links within this site that explain what content is covered in the courses&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://ubc-mds.github.io/\"&gt;https://ubc-mds.github.io/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y44wk9", "is_robot_indexable": true, "report_reasons": null, "author": "thewhitest_brownguy", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y44wk9/thoughts_on_the_ubc_master_of_data_science_program/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y44wk9/thoughts_on_the_ubc_master_of_data_science_program/", "subreddit_subscribers": 813711, "created_utc": 1665780697.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,\n\nLong history short: the analytics director of my non-tech company, who is a DS illiterate, has hired a Data Science Lead that has considerably fewer qualifications, and just 2 years more work experience than me (senior DS). In our first interaction, he bragged about how he created a segmentation model using a random forest with an accuracy of 94% in his previous role ...\n\nI was previously leading our team of 3 DS and 2 DE. It is quite blurred how we will collaborate and divide the roles, management responsibilities, and workload.\n\nIt is still early days, but I wanted to get insights and advice from the community, from people who have been in a similar situation. I've done a few google searches on this topic and haven't found anything. Maybe everyone out there has competent and knowledgeable data science leads/managers? It could be the case, as I guess you can't fake being a data science lead and get away with it, can you?\n\n* How do senior data scientists learn and are mentored by lead data scientists in your organizations? Is there a way to check informally if this guy has knowledge/skills that I can really pick up and learn from him?\n* Should I transfer to him all my management responsibilities and the projects I own?\n* Any advice about how to cope with this situation, especially during his first 100 days would be gold. I guess working patterns and assumptions that solidify at the beginning will stay there. Thank you!", "author_fullname": "t2_5phwwjob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Have you ever been under a Data Science Lead/Manager who knew less than you? How did you cope?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4pxoe", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665845545.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;Long history short: the analytics director of my non-tech company, who is a DS illiterate, has hired a Data Science Lead that has considerably fewer qualifications, and just 2 years more work experience than me (senior DS). In our first interaction, he bragged about how he created a segmentation model using a random forest with an accuracy of 94% in his previous role ...&lt;/p&gt;\n\n&lt;p&gt;I was previously leading our team of 3 DS and 2 DE. It is quite blurred how we will collaborate and divide the roles, management responsibilities, and workload.&lt;/p&gt;\n\n&lt;p&gt;It is still early days, but I wanted to get insights and advice from the community, from people who have been in a similar situation. I&amp;#39;ve done a few google searches on this topic and haven&amp;#39;t found anything. Maybe everyone out there has competent and knowledgeable data science leads/managers? It could be the case, as I guess you can&amp;#39;t fake being a data science lead and get away with it, can you?&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;How do senior data scientists learn and are mentored by lead data scientists in your organizations? Is there a way to check informally if this guy has knowledge/skills that I can really pick up and learn from him?&lt;/li&gt;\n&lt;li&gt;Should I transfer to him all my management responsibilities and the projects I own?&lt;/li&gt;\n&lt;li&gt;Any advice about how to cope with this situation, especially during his first 100 days would be gold. I guess working patterns and assumptions that solidify at the beginning will stay there. Thank you!&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4pxoe", "is_robot_indexable": true, "report_reasons": null, "author": "werthobakew", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4pxoe/have_you_ever_been_under_a_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4pxoe/have_you_ever_been_under_a_data_science/", "subreddit_subscribers": 813711, "created_utc": 1665845545.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My goal is to have a place to ask question regarding Data Analyst stuff (like eigendecomposition, matrix reconstruction, eigenvector centrality) and next month regarding Data Science stuff.\n\nI've tried to ask question regarding eigendecomposition in StackOverflow and datascience.StackExchange.com, but to no avail. No one answered the question. I guess, Data Analyst and Data Scientist rarely use these forum.", "author_fullname": "t2_5yye765o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where do Data Analyst and Data Science ask question most of the time (except StackOverflow and StackExchange)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4o199", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665840608.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My goal is to have a place to ask question regarding Data Analyst stuff (like eigendecomposition, matrix reconstruction, eigenvector centrality) and next month regarding Data Science stuff.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried to ask question regarding eigendecomposition in StackOverflow and datascience.StackExchange.com, but to no avail. No one answered the question. I guess, Data Analyst and Data Scientist rarely use these forum.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4o199", "is_robot_indexable": true, "report_reasons": null, "author": "kidfromtheast", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4o199/where_do_data_analyst_and_data_science_ask/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4o199/where_do_data_analyst_and_data_science_ask/", "subreddit_subscribers": 813711, "created_utc": 1665840608.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_b7z7a6t4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can we interprate this box plot in regards to outliers? Is it every value above the upper fence? In that case, about 1/6 of the total values are outliers.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 63, "top_awarded_type": null, "hide_score": true, "name": "t3_y4s8cy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/UWHyL0uAC086_fianjiO7-5pLIEDNayzi2NR-f-4BMQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1665851355.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/huwywux7xzt91.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/huwywux7xzt91.png?auto=webp&amp;s=cc6f6317e6afdb86edfa0a0697abc5389db52959", "width": 1235, "height": 558}, "resolutions": [{"url": "https://preview.redd.it/huwywux7xzt91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=354cbccb19304de12debc55cc8d33a43903f0154", "width": 108, "height": 48}, {"url": "https://preview.redd.it/huwywux7xzt91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9d755cc7e5fb2ad51cfd84900f23a0f24d9946fb", "width": 216, "height": 97}, {"url": "https://preview.redd.it/huwywux7xzt91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c2c5d8040432cfe013af7cb7ac4129eeb1323ea4", "width": 320, "height": 144}, {"url": "https://preview.redd.it/huwywux7xzt91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b4aecf1ee052431c08f937a5bf6970d4df7345ab", "width": 640, "height": 289}, {"url": "https://preview.redd.it/huwywux7xzt91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=4f7b19fb35ff96c01378537c995f150394dfee9b", "width": 960, "height": 433}, {"url": "https://preview.redd.it/huwywux7xzt91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=aed86c9be16cb475c3ef613a845f2ca16d8440b6", "width": 1080, "height": 487}], "variants": {}, "id": "6kbHq0P-iIt0cbMHwt0Gx-R_gKWvfSEj9XwDcGdZ6AA"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4s8cy", "is_robot_indexable": true, "report_reasons": null, "author": "Outside-Werewolf-983", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4s8cy/how_can_we_interprate_this_box_plot_in_regards_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/huwywux7xzt91.png", "subreddit_subscribers": 813711, "created_utc": 1665851355.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey Guys &amp; Gals!!!\n\nSo, I'm currently running some regressions and similar, in order to create a trading algorithm. I've collected and cleaned daily price data for each currency pair, and I have organised relevant variables. I'm looking to build an algorithm in order to best determine future price changes, based on a few variable. Some are dummy, some are percentage values. \n\nI've ran simple OLS regressions to see I have a strong and statistically significant (at 0.001% level) between my dummy and price data, although I'm struggling to work out how to incorporate more variables into this. I also don't think OLS is the best way to do this, should I be using MA(?) Or EMA(?)? I've done an economics degree with econometrics moudles so I know a bit about what I'm doing, although not enough to do what I want to.  (clearly \ud83d\ude02!)\n\nAny advice would be massively appreciated! I'm currency learning to use python, would NumPy or similar be satisfactory? \n\nThanks again!", "author_fullname": "t2_cj4nfibx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What tools should I run to determine the best predictive power?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4mshz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665837182.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Guys &amp;amp; Gals!!!&lt;/p&gt;\n\n&lt;p&gt;So, I&amp;#39;m currently running some regressions and similar, in order to create a trading algorithm. I&amp;#39;ve collected and cleaned daily price data for each currency pair, and I have organised relevant variables. I&amp;#39;m looking to build an algorithm in order to best determine future price changes, based on a few variable. Some are dummy, some are percentage values. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve ran simple OLS regressions to see I have a strong and statistically significant (at 0.001% level) between my dummy and price data, although I&amp;#39;m struggling to work out how to incorporate more variables into this. I also don&amp;#39;t think OLS is the best way to do this, should I be using MA(?) Or EMA(?)? I&amp;#39;ve done an economics degree with econometrics moudles so I know a bit about what I&amp;#39;m doing, although not enough to do what I want to.  (clearly \ud83d\ude02!)&lt;/p&gt;\n\n&lt;p&gt;Any advice would be massively appreciated! I&amp;#39;m currency learning to use python, would NumPy or similar be satisfactory? &lt;/p&gt;\n\n&lt;p&gt;Thanks again!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4mshz", "is_robot_indexable": true, "report_reasons": null, "author": "ChoccyRoccy", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4mshz/what_tools_should_i_run_to_determine_the_best/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4mshz/what_tools_should_i_run_to_determine_the_best/", "subreddit_subscribers": 813711, "created_utc": 1665837182.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello Everyone,\n\nUp until now I have extensively worked on computer vision problems for the past 3-4 years but did not get a lot of opportunity to work on NLP problems. Therefore, I want to get an overview of the current research status and its applications in the NLP domain. Can anyone suggest some good papers to read in the NLP domain to get a brief of the current research status there?\n\nThanks a lot!", "author_fullname": "t2_59mwk2ku", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NLP research status", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4i1jz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665820973.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone,&lt;/p&gt;\n\n&lt;p&gt;Up until now I have extensively worked on computer vision problems for the past 3-4 years but did not get a lot of opportunity to work on NLP problems. Therefore, I want to get an overview of the current research status and its applications in the NLP domain. Can anyone suggest some good papers to read in the NLP domain to get a brief of the current research status there?&lt;/p&gt;\n\n&lt;p&gt;Thanks a lot!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4i1jz", "is_robot_indexable": true, "report_reasons": null, "author": "Eve26th", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4i1jz/nlp_research_status/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4i1jz/nlp_research_status/", "subreddit_subscribers": 813711, "created_utc": 1665820973.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello data fellows,\n\nDo you think that it generally makes sense to develop and invest a lot of time in improving technical skills in DL, as a generalist data scientist? Meaning, as someone that is not in research scientist/ML engineer position and/or doesn\u2019t work in big-tech?\n\nI am not talking about being able to build a simple sequential model with Keras and feeding np arrays, but rather going much deeper with Functional/Subclassing APIs and then use tf.Datasets and generators to feed Tensorflow data pipelines.\n\nThe reason why I am asking is that I love this stuff, but I don\u2019t know how many firms outside of big tech use these technologies out there. If in the end all they expect/understand/value is knowing SQL and some basic Python, is it worth going down the more technical path? Will it give me an edge in the long run?\n\nThanks for your feedback!\n\nA nice weekend everyone", "author_fullname": "t2_538mr0fs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Focus on Deep Learning: does it make generally sense?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4hbw4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665818276.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello data fellows,&lt;/p&gt;\n\n&lt;p&gt;Do you think that it generally makes sense to develop and invest a lot of time in improving technical skills in DL, as a generalist data scientist? Meaning, as someone that is not in research scientist/ML engineer position and/or doesn\u2019t work in big-tech?&lt;/p&gt;\n\n&lt;p&gt;I am not talking about being able to build a simple sequential model with Keras and feeding np arrays, but rather going much deeper with Functional/Subclassing APIs and then use tf.Datasets and generators to feed Tensorflow data pipelines.&lt;/p&gt;\n\n&lt;p&gt;The reason why I am asking is that I love this stuff, but I don\u2019t know how many firms outside of big tech use these technologies out there. If in the end all they expect/understand/value is knowing SQL and some basic Python, is it worth going down the more technical path? Will it give me an edge in the long run?&lt;/p&gt;\n\n&lt;p&gt;Thanks for your feedback!&lt;/p&gt;\n\n&lt;p&gt;A nice weekend everyone&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4hbw4", "is_robot_indexable": true, "report_reasons": null, "author": "funkyhog", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4hbw4/focus_on_deep_learning_does_it_make_generally/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4hbw4/focus_on_deep_learning_does_it_make_generally/", "subreddit_subscribers": 813711, "created_utc": 1665818276.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For a VAE architecture and a dataset, say CIFAR-10, if the hidden/latent space is intentionally kept large to (say) 1000-d, I am assuming that the VAE will automatically not use the extra variables/dimensions in latent space which it does not need. The unneeded dimensions don't learn anything meaningful and therefore remain a standard, multivariate, Gaussian distribution. This serves as a signal that such dimensions can safely be removed without significantly impacting the model's performance.\n\nI have implemented quite a few of them which can be referred to [here](https://github.com/arjun-majumdar/Autoencoders_Experiments).\n\nAm I right with my hypothesis? Is there any research paper substantiating my hand wavy hypothesis?", "author_fullname": "t2_2mmql89p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Variational Autoencoder automatic latent dimension selection", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y44lch", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1665779915.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For a VAE architecture and a dataset, say CIFAR-10, if the hidden/latent space is intentionally kept large to (say) 1000-d, I am assuming that the VAE will automatically not use the extra variables/dimensions in latent space which it does not need. The unneeded dimensions don&amp;#39;t learn anything meaningful and therefore remain a standard, multivariate, Gaussian distribution. This serves as a signal that such dimensions can safely be removed without significantly impacting the model&amp;#39;s performance.&lt;/p&gt;\n\n&lt;p&gt;I have implemented quite a few of them which can be referred to &lt;a href=\"https://github.com/arjun-majumdar/Autoencoders_Experiments\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Am I right with my hypothesis? Is there any research paper substantiating my hand wavy hypothesis?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/v-zcG-iCJpPZTY9_tEMIOKUyfUGszf-DAMCLBwB8eVY.jpg?auto=webp&amp;s=9921c21fa0775e7899b8db2c4bc552637c75d4dd", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/v-zcG-iCJpPZTY9_tEMIOKUyfUGszf-DAMCLBwB8eVY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=516b56be414f533d25bb5024e9d9f93cc233080a", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/v-zcG-iCJpPZTY9_tEMIOKUyfUGszf-DAMCLBwB8eVY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=11fd41ed921c1d2a7eef140a0443be51c5c0412c", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/v-zcG-iCJpPZTY9_tEMIOKUyfUGszf-DAMCLBwB8eVY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bcde4f07e2ce5d52dda3c73dc2a803075a33c312", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/v-zcG-iCJpPZTY9_tEMIOKUyfUGszf-DAMCLBwB8eVY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=828b0269972260f31d6348cb7f1d0cc359473629", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/v-zcG-iCJpPZTY9_tEMIOKUyfUGszf-DAMCLBwB8eVY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=487787c40d8ee720095e35c0ca39b301737f0db3", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/v-zcG-iCJpPZTY9_tEMIOKUyfUGszf-DAMCLBwB8eVY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0611e65849b8b8cf554fbf87236bd550fbe47825", "width": 1080, "height": 540}], "variants": {}, "id": "qVZwfmpHSEYQi6t9QQ4RiKAbcVn2-Nj7xGlngPrWp44"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y44lch", "is_robot_indexable": true, "report_reasons": null, "author": "grid_world", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y44lch/variational_autoencoder_automatic_latent/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y44lch/variational_autoencoder_automatic_latent/", "subreddit_subscribers": 813711, "created_utc": 1665779915.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I understand that you need to do Power analysis in order to figure out what sample size you need for your AB test, but something that I have difficulty coming up with is \u201cwhat MDE should we use?\u201d  Researching online hasn\u2019t been much help because all I see are examples of where they just give an MDE to use but don\u2019t explain the process of getting there. \n\nFor my company, a lot of our tests have very low operational costs, so in almost all cases any positive performance is worth rolling out. Basically, even if we saw only a 0.05% lift, if it was statistically significant, we\u2019d probably implement the change. This has led me down a path where I basically just check to see what MDE we can reasonably detect given the number of users coming into the platform INSTEAD of determining what MDE is actually valuable. I feel like this is the wrong approach, but I\u2019m unsure what else to do given that our \u201cgoal\u201d MDE is basically anything above 0. This especially makes it difficult for me to determine when I should stop the tests as well, other than picking a somewhat arbitrary end point of 3-4 weeks and then seeing if there is any directional value from the data. \n\nWhat would you do in this situation? How do you determine the MDE for your AB tests? \n\nThanks!", "author_fullname": "t2_3dbxxd6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to determine what value is good for minimum detectable effect (MDE) for AB testing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_y4t1y1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665853411.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I understand that you need to do Power analysis in order to figure out what sample size you need for your AB test, but something that I have difficulty coming up with is \u201cwhat MDE should we use?\u201d  Researching online hasn\u2019t been much help because all I see are examples of where they just give an MDE to use but don\u2019t explain the process of getting there. &lt;/p&gt;\n\n&lt;p&gt;For my company, a lot of our tests have very low operational costs, so in almost all cases any positive performance is worth rolling out. Basically, even if we saw only a 0.05% lift, if it was statistically significant, we\u2019d probably implement the change. This has led me down a path where I basically just check to see what MDE we can reasonably detect given the number of users coming into the platform INSTEAD of determining what MDE is actually valuable. I feel like this is the wrong approach, but I\u2019m unsure what else to do given that our \u201cgoal\u201d MDE is basically anything above 0. This especially makes it difficult for me to determine when I should stop the tests as well, other than picking a somewhat arbitrary end point of 3-4 weeks and then seeing if there is any directional value from the data. &lt;/p&gt;\n\n&lt;p&gt;What would you do in this situation? How do you determine the MDE for your AB tests? &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4t1y1", "is_robot_indexable": true, "report_reasons": null, "author": "matt22022", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4t1y1/how_to_determine_what_value_is_good_for_minimum/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4t1y1/how_to_determine_what_value_is_good_for_minimum/", "subreddit_subscribers": 813711, "created_utc": 1665853411.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "If anyone has either graduated from the program or is currently in the program and could give me their review that would be much appreciated!\n\nThanks in advance, any feedback is appreciated!", "author_fullname": "t2_4wwb784o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Rutgers University New Burnswick good for data science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_y4sqhr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1665852622.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "msds-stat.rutgers.edu", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If anyone has either graduated from the program or is currently in the program and could give me their review that would be much appreciated!&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance, any feedback is appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://msds-stat.rutgers.edu/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4sqhr", "is_robot_indexable": true, "report_reasons": null, "author": "ssbhagat", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4sqhr/is_rutgers_university_new_burnswick_good_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://msds-stat.rutgers.edu/", "subreddit_subscribers": 813711, "created_utc": 1665852622.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I understand the difference between ML and DL ,which one is used mostly in your day to day jobs. As a  Data Science Beginner which area should i be focusing more ML or DL from a job perspective?", "author_fullname": "t2_bsfosv4r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is widely used ML or DL in your day to day jobs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_y4s3sr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665851026.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I understand the difference between ML and DL ,which one is used mostly in your day to day jobs. As a  Data Science Beginner which area should i be focusing more ML or DL from a job perspective?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4s3sr", "is_robot_indexable": true, "report_reasons": null, "author": "Adventurous-Grab-20", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4s3sr/what_is_widely_used_ml_or_dl_in_your_day_to_day/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4s3sr/what_is_widely_used_ml_or_dl_in_your_day_to_day/", "subreddit_subscribers": 813711, "created_utc": 1665851026.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "logging in spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_y4rn8m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_sx1wry60", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "apachespark", "selftext": "Hey, we are moving to databricks, using pyspark etc...How should logs be defined here?I mean, spark uses lazy evaluation, and what i define is executed only when some action is called for example:\n\n    df = spark.read.parquet(path) # read data\n    df = df.filter(expression) # apply filters\n    df = df.withColumn(\"predictions\", predict_proba(*columns)) # simple model predictions\n    df.write.parquet(path) # write new dataframe\n\nApplying model predict proba, also apply filters are actually done on last line of [code.Am](https://code.Am) i correct?\n\nHow should i then write logs.I cannot put [log.info](https://log.info)(\"Applying filter) on second line, since filters are applied when dataframe is actually written to path.\n\nI cant have something like this:\n\n    df = spark.read.parquet(path) # read data\n    log.info(\"Appyling filter)\n    df = df.filter(expression) # apply filters\n    log.info(\"Make predictions)\n    df = df.withColumn(\"predictions\", predict_proba(*columns)) # simple model predictions\n    df.write.parquet(path) # write new dataframe\n\nIs this more correct:\n\n    df = spark.read.parquet(path) # read data\n    log.info(\"Define filter transformation)\n    df = df.filter(expression) # apply filters\n    log.info(\"Define model predictions)\n    df = df.withColumn(\"predictions\", predict_proba(*columns)) # simple model predictions\n    log.info(\"Apply filter, make predictions, write data)\n    df.write.parquet(path) # write new dataframe", "author_fullname": "t2_sx1wry60", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "logging in spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/apachespark", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4r0xd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1665848287.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.apachespark", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, we are moving to databricks, using pyspark etc...How should logs be defined here?I mean, spark uses lazy evaluation, and what i define is executed only when some action is called for example:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;df = spark.read.parquet(path) # read data\ndf = df.filter(expression) # apply filters\ndf = df.withColumn(&amp;quot;predictions&amp;quot;, predict_proba(*columns)) # simple model predictions\ndf.write.parquet(path) # write new dataframe\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Applying model predict proba, also apply filters are actually done on last line of &lt;a href=\"https://code.Am\"&gt;code.Am&lt;/a&gt; i correct?&lt;/p&gt;\n\n&lt;p&gt;How should i then write logs.I cannot put &lt;a href=\"https://log.info\"&gt;log.info&lt;/a&gt;(&amp;quot;Applying filter) on second line, since filters are applied when dataframe is actually written to path.&lt;/p&gt;\n\n&lt;p&gt;I cant have something like this:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;df = spark.read.parquet(path) # read data\nlog.info(&amp;quot;Appyling filter)\ndf = df.filter(expression) # apply filters\nlog.info(&amp;quot;Make predictions)\ndf = df.withColumn(&amp;quot;predictions&amp;quot;, predict_proba(*columns)) # simple model predictions\ndf.write.parquet(path) # write new dataframe\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Is this more correct:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;df = spark.read.parquet(path) # read data\nlog.info(&amp;quot;Define filter transformation)\ndf = df.filter(expression) # apply filters\nlog.info(&amp;quot;Define model predictions)\ndf = df.withColumn(&amp;quot;predictions&amp;quot;, predict_proba(*columns)) # simple model predictions\nlog.info(&amp;quot;Apply filter, make predictions, write data)\ndf.write.parquet(path) # write new dataframe\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/2laARYRmzqEA4GSj9GhMXjI561TT2O2Ma0450c_lZGk.jpg?auto=webp&amp;s=08ba096453f419afbee40446156aed4ecf0b3d98", "width": 3384, "height": 573}, "resolutions": [{"url": "https://external-preview.redd.it/2laARYRmzqEA4GSj9GhMXjI561TT2O2Ma0450c_lZGk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4b0a701530d3e2c366f5327b425530afe2bf37d1", "width": 108, "height": 18}, {"url": "https://external-preview.redd.it/2laARYRmzqEA4GSj9GhMXjI561TT2O2Ma0450c_lZGk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=821f3f1eb3f88b0466163abfa85d9f5fb14cb09a", "width": 216, "height": 36}, {"url": "https://external-preview.redd.it/2laARYRmzqEA4GSj9GhMXjI561TT2O2Ma0450c_lZGk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=26ac6b01b572721c4eea756c9cb4be6eb47fb980", "width": 320, "height": 54}, {"url": "https://external-preview.redd.it/2laARYRmzqEA4GSj9GhMXjI561TT2O2Ma0450c_lZGk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=22d6a361137c677144a034c908df1be59f616539", "width": 640, "height": 108}, {"url": "https://external-preview.redd.it/2laARYRmzqEA4GSj9GhMXjI561TT2O2Ma0450c_lZGk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0ff8b435b669d1527b3c5caccd67697117cd496e", "width": 960, "height": 162}, {"url": "https://external-preview.redd.it/2laARYRmzqEA4GSj9GhMXjI561TT2O2Ma0450c_lZGk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a0076f310a1a9f13527e351247583a9de492ccf0", "width": 1080, "height": 182}], "variants": {}, "id": "m700koTmer0UoiMGYQ9DSkYJhMlt4-VvVeiR2LNIzxo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32fy8", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4r0xd", "is_robot_indexable": true, "report_reasons": null, "author": "AcceptableProcess772", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/apachespark/comments/y4r0xd/logging_in_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/apachespark/comments/y4r0xd/logging_in_spark/", "subreddit_subscribers": 10311, "created_utc": 1665848287.0, "num_crossposts": 3, "media": null, "is_video": false}], "created": 1665849879.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.apachespark", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/apachespark/comments/y4r0xd/logging_in_spark/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/2laARYRmzqEA4GSj9GhMXjI561TT2O2Ma0450c_lZGk.jpg?auto=webp&amp;s=08ba096453f419afbee40446156aed4ecf0b3d98", "width": 3384, "height": 573}, "resolutions": [{"url": "https://external-preview.redd.it/2laARYRmzqEA4GSj9GhMXjI561TT2O2Ma0450c_lZGk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4b0a701530d3e2c366f5327b425530afe2bf37d1", "width": 108, "height": 18}, {"url": "https://external-preview.redd.it/2laARYRmzqEA4GSj9GhMXjI561TT2O2Ma0450c_lZGk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=821f3f1eb3f88b0466163abfa85d9f5fb14cb09a", "width": 216, "height": 36}, {"url": "https://external-preview.redd.it/2laARYRmzqEA4GSj9GhMXjI561TT2O2Ma0450c_lZGk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=26ac6b01b572721c4eea756c9cb4be6eb47fb980", "width": 320, "height": 54}, {"url": "https://external-preview.redd.it/2laARYRmzqEA4GSj9GhMXjI561TT2O2Ma0450c_lZGk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=22d6a361137c677144a034c908df1be59f616539", "width": 640, "height": 108}, {"url": "https://external-preview.redd.it/2laARYRmzqEA4GSj9GhMXjI561TT2O2Ma0450c_lZGk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0ff8b435b669d1527b3c5caccd67697117cd496e", "width": 960, "height": 162}, {"url": "https://external-preview.redd.it/2laARYRmzqEA4GSj9GhMXjI561TT2O2Ma0450c_lZGk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a0076f310a1a9f13527e351247583a9de492ccf0", "width": 1080, "height": 182}], "variants": {}, "id": "m700koTmer0UoiMGYQ9DSkYJhMlt4-VvVeiR2LNIzxo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4rn8m", "is_robot_indexable": true, "report_reasons": null, "author": "AcceptableProcess772", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_y4r0xd", "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4rn8m/logging_in_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/apachespark/comments/y4r0xd/logging_in_spark/", "subreddit_subscribers": 813711, "created_utc": 1665849879.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "TL;DR: Has industry demand on experts in Bayesian-ML for Control Engineering?\n\n&amp;#x200B;\n\nHey,\n\nI'm a CS student right before my master thesis and I have to take a decision between two career topics:\n\n1. Becoming an NLP expert.\n2. Becoming an expert on Bayesian-ML for Control Engineering.\n\nThe path I want to take is Master-Thesis --&gt; PhD --&gt; Industry. There are many pros and cons for me to take any of these two. I'm here because I doubt the demand of the industry on additional experts in *Bayesian-ML for Control Engineering*. The doubts originate from the following reason.\n\nPeople are working on Bayesian methods since decades and engineering also does respectively. So it might be, that experts from these decades are already spread through the industry.\n\nNLP in comparison is pretty new and on high demand without a doubt.\n\nDoes someone has insights for me on the demand of the industry on Bayesian-ML in Control Engineering? More specifically I could also ask, if Kalman Filters and Gaussian Processes are of interest?\n\n&amp;#x200B;\n\nI'm thanking every reader for his/her/&lt;other pronouns&gt; attention and even more for answers :)\n\nLinks to informative threads are also appreciated (I only found average useful ones)!", "author_fullname": "t2_kmck7zwg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Demand on Bayesian-ML in Control Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4q6rh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665846168.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TL;DR: Has industry demand on experts in Bayesian-ML for Control Engineering?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Hey,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a CS student right before my master thesis and I have to take a decision between two career topics:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Becoming an NLP expert.&lt;/li&gt;\n&lt;li&gt;Becoming an expert on Bayesian-ML for Control Engineering.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The path I want to take is Master-Thesis --&amp;gt; PhD --&amp;gt; Industry. There are many pros and cons for me to take any of these two. I&amp;#39;m here because I doubt the demand of the industry on additional experts in &lt;em&gt;Bayesian-ML for Control Engineering&lt;/em&gt;. The doubts originate from the following reason.&lt;/p&gt;\n\n&lt;p&gt;People are working on Bayesian methods since decades and engineering also does respectively. So it might be, that experts from these decades are already spread through the industry.&lt;/p&gt;\n\n&lt;p&gt;NLP in comparison is pretty new and on high demand without a doubt.&lt;/p&gt;\n\n&lt;p&gt;Does someone has insights for me on the demand of the industry on Bayesian-ML in Control Engineering? More specifically I could also ask, if Kalman Filters and Gaussian Processes are of interest?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thanking every reader for his/her/&amp;lt;other pronouns&amp;gt; attention and even more for answers :)&lt;/p&gt;\n\n&lt;p&gt;Links to informative threads are also appreciated (I only found average useful ones)!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4q6rh", "is_robot_indexable": true, "report_reasons": null, "author": "Michael_Skowronek", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4q6rh/demand_on_bayesianml_in_control_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4q6rh/demand_on_bayesianml_in_control_engineering/", "subreddit_subscribers": 813711, "created_utc": 1665846168.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,  I am wondering about about some recent trends I have been experienced at work with younger or less experienced data scientists.\n\nPeople are fitting these large multivariate, nonlinear models that come directly from python libraries, for example PyOD outlier detection.   They just compare results from all the built in ML algos.   They don't think about any simple methods what so ever for detecting outliers.   However, the end user always drills down to univariate to see if the features are significant anyway.     So I don't see the purpose in testing the advanced algos without a baseline.\n\nSo instead of starting with a basic statistical outlier method, or univariate or linear method,like PCA, all of this is skipped and considered irrelevant or \"dinosaur\".  \n\nMy argument is that if you don't have a baseline simple method, you will never understand the benefit the ML algo brings .    Basically if they cant can't find a benefit over univariate ,  they shouldn't promote the advanced methods yet.\n\nWhat are your thoughts on this?\n\nHow do I convince these people to slow down and take baby steps to see the benefits without insulting them?  \n\nHow do I stop ignorant management from listening to these trendy individuals? Its quite frustrating when a simple method beats a complex desired method, but someone won't listen because they want to look smart.", "author_fullname": "t2_3qgvuco6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Simpler Methods over Advanced Algos", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4npv5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665839731.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,  I am wondering about about some recent trends I have been experienced at work with younger or less experienced data scientists.&lt;/p&gt;\n\n&lt;p&gt;People are fitting these large multivariate, nonlinear models that come directly from python libraries, for example PyOD outlier detection.   They just compare results from all the built in ML algos.   They don&amp;#39;t think about any simple methods what so ever for detecting outliers.   However, the end user always drills down to univariate to see if the features are significant anyway.     So I don&amp;#39;t see the purpose in testing the advanced algos without a baseline.&lt;/p&gt;\n\n&lt;p&gt;So instead of starting with a basic statistical outlier method, or univariate or linear method,like PCA, all of this is skipped and considered irrelevant or &amp;quot;dinosaur&amp;quot;.  &lt;/p&gt;\n\n&lt;p&gt;My argument is that if you don&amp;#39;t have a baseline simple method, you will never understand the benefit the ML algo brings .    Basically if they cant can&amp;#39;t find a benefit over univariate ,  they shouldn&amp;#39;t promote the advanced methods yet.&lt;/p&gt;\n\n&lt;p&gt;What are your thoughts on this?&lt;/p&gt;\n\n&lt;p&gt;How do I convince these people to slow down and take baby steps to see the benefits without insulting them?  &lt;/p&gt;\n\n&lt;p&gt;How do I stop ignorant management from listening to these trendy individuals? Its quite frustrating when a simple method beats a complex desired method, but someone won&amp;#39;t listen because they want to look smart.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4npv5", "is_robot_indexable": true, "report_reasons": null, "author": "Atxaquariguy", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4npv5/simpler_methods_over_advanced_algos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4npv5/simpler_methods_over_advanced_algos/", "subreddit_subscribers": 813711, "created_utc": 1665839731.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "A chart is displayed with precision and recall scores. The table underneath calculated the scores so they were double format 1, 0 .67 etc and it grouped by certain fields such as week.\n\nThe chart then converted these doubles to % and displayed by month using SUM(precision)\n\nI was requested to also include additional field, hour (24 hr clock) as they wanted to be able to filter on the charts by the hour.\n\nI did this, and obviously when we added this to the GROUP BY the sum(precision) values increased in number, and the chart range now goes up to 900%.\n\nWhat can I do to make this range display accurate %s between 0 - 100?\n\nor is this a bogus calculation? THanks!", "author_fullname": "t2_eejku9w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "calculating with group by", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4nmur", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665839501.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A chart is displayed with precision and recall scores. The table underneath calculated the scores so they were double format 1, 0 .67 etc and it grouped by certain fields such as week.&lt;/p&gt;\n\n&lt;p&gt;The chart then converted these doubles to % and displayed by month using SUM(precision)&lt;/p&gt;\n\n&lt;p&gt;I was requested to also include additional field, hour (24 hr clock) as they wanted to be able to filter on the charts by the hour.&lt;/p&gt;\n\n&lt;p&gt;I did this, and obviously when we added this to the GROUP BY the sum(precision) values increased in number, and the chart range now goes up to 900%.&lt;/p&gt;\n\n&lt;p&gt;What can I do to make this range display accurate %s between 0 - 100?&lt;/p&gt;\n\n&lt;p&gt;or is this a bogus calculation? THanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4nmur", "is_robot_indexable": true, "report_reasons": null, "author": "panadol64", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4nmur/calculating_with_group_by/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4nmur/calculating_with_group_by/", "subreddit_subscribers": 813711, "created_utc": 1665839501.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi guys,\n\nJunior analyst here and I was hoping I can pick your brains on a challenge. I have an ecommerce dataset for customer purchases and the challenge is to measure the share of customers who purchased from multiple categories in a month and continue to purchase in multiple categories in succeeding months.\n\nHas anyone done a similar project before through Python? It would be great to hear your thoughts on how I might approach this in the code.\n\nThank you!\n\n[sample ecommerce dataset](https://preview.redd.it/7xzu56eauyt91.png?width=1452&amp;format=png&amp;auto=webp&amp;s=8e8469cfd113fd52c0d16be4a5db47d6412c264f)", "author_fullname": "t2_87cwramh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Measuring customers who purchased from multiple categories", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 137, "top_awarded_type": null, "hide_score": false, "media_metadata": {"7xzu56eauyt91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 105, "x": 108, "u": "https://preview.redd.it/7xzu56eauyt91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1bbf710f77e92a4d1d1ac5d440a08ea23416246b"}, {"y": 211, "x": 216, "u": "https://preview.redd.it/7xzu56eauyt91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0633909f195b1ac7a26ece125fb3ff4aacbc5748"}, {"y": 313, "x": 320, "u": "https://preview.redd.it/7xzu56eauyt91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=1f0409b5e4736caadd2427b86f5d313d45b305c0"}, {"y": 627, "x": 640, "u": "https://preview.redd.it/7xzu56eauyt91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=fc06bf96cb5ed05ccf630904e60ba8a0292074d6"}, {"y": 941, "x": 960, "u": "https://preview.redd.it/7xzu56eauyt91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=fef8ce00b11eb07251d0861ad5ea36cbb6fe0018"}, {"y": 1059, "x": 1080, "u": "https://preview.redd.it/7xzu56eauyt91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f11702db91c6ea0717063d23c7ba8e2baa32939a"}], "s": {"y": 1424, "x": 1452, "u": "https://preview.redd.it/7xzu56eauyt91.png?width=1452&amp;format=png&amp;auto=webp&amp;s=8e8469cfd113fd52c0d16be4a5db47d6412c264f"}, "id": "7xzu56eauyt91"}}, "name": "t3_y4n33g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/8nl7snpB-ohbPTVE_qFBJA8OFTPVjP5t0Vksq4QvjBw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665838019.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;Junior analyst here and I was hoping I can pick your brains on a challenge. I have an ecommerce dataset for customer purchases and the challenge is to measure the share of customers who purchased from multiple categories in a month and continue to purchase in multiple categories in succeeding months.&lt;/p&gt;\n\n&lt;p&gt;Has anyone done a similar project before through Python? It would be great to hear your thoughts on how I might approach this in the code.&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/7xzu56eauyt91.png?width=1452&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8e8469cfd113fd52c0d16be4a5db47d6412c264f\"&gt;sample ecommerce dataset&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4n33g", "is_robot_indexable": true, "report_reasons": null, "author": "Shirt_Reasonable", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4n33g/measuring_customers_who_purchased_from_multiple/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4n33g/measuring_customers_who_purchased_from_multiple/", "subreddit_subscribers": 813711, "created_utc": 1665838019.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "A few months ago I started a data science focused blog. I\u2019ve posted a few tutorials but I\u2019ve mostly posted data stories about things that interest me. I try to make an interactive element that is usually a small web app that lets you interact with the data. I\u2019ve had some moderate success with about 10 thousand unique visitors in September. \n\nMy question is, do y\u2019all care about these data stories? I would prefer to make things people want, and I\u2019m not sure I\u2019m doing that. A few ideas I had that y\u2019all might like:\n\n- Live streams of doing data science projects. Scraping, cleaning, and modeling in one chunk of time. \n- Technical posts. Do a project and walk  through the code. Basically blog post with code. Not a tutorial exactly though. \n- Mini data products with all code attached to remake/remix yourself. \n\nI\u2019m open to ideas. So, what kind of content would you like more of?\n\nThe blog is [datafantic.com](https://datafantic.com). My goal here is not to get clicks but to understand y\u2019all better. My target audience is other data scientists, and I would like to create content y\u2019all like.", "author_fullname": "t2_a0kcgwo4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you want in a data science publication (blog)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4jlh7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1665826689.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A few months ago I started a data science focused blog. I\u2019ve posted a few tutorials but I\u2019ve mostly posted data stories about things that interest me. I try to make an interactive element that is usually a small web app that lets you interact with the data. I\u2019ve had some moderate success with about 10 thousand unique visitors in September. &lt;/p&gt;\n\n&lt;p&gt;My question is, do y\u2019all care about these data stories? I would prefer to make things people want, and I\u2019m not sure I\u2019m doing that. A few ideas I had that y\u2019all might like:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Live streams of doing data science projects. Scraping, cleaning, and modeling in one chunk of time. &lt;/li&gt;\n&lt;li&gt;Technical posts. Do a project and walk  through the code. Basically blog post with code. Not a tutorial exactly though. &lt;/li&gt;\n&lt;li&gt;Mini data products with all code attached to remake/remix yourself. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I\u2019m open to ideas. So, what kind of content would you like more of?&lt;/p&gt;\n\n&lt;p&gt;The blog is &lt;a href=\"https://datafantic.com\"&gt;datafantic.com&lt;/a&gt;. My goal here is not to get clicks but to understand y\u2019all better. My target audience is other data scientists, and I would like to create content y\u2019all like.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jK_Rae0h1ebDEMtfUdLFkxTifROb_wRsOUsOXOyoYdQ.jpg?auto=webp&amp;s=24573f8cb91746901ee7305d63ee2cd574f44ed6", "width": 950, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/jK_Rae0h1ebDEMtfUdLFkxTifROb_wRsOUsOXOyoYdQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e632d1dfa8e6ae10a550016f4832af44f791cd64", "width": 108, "height": 68}, {"url": "https://external-preview.redd.it/jK_Rae0h1ebDEMtfUdLFkxTifROb_wRsOUsOXOyoYdQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0b32276b51d8974c4fd7c9486b6f80143396a5bb", "width": 216, "height": 136}, {"url": "https://external-preview.redd.it/jK_Rae0h1ebDEMtfUdLFkxTifROb_wRsOUsOXOyoYdQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c0135baa377781ee5db9898c61eb0aae9d724ef4", "width": 320, "height": 202}, {"url": "https://external-preview.redd.it/jK_Rae0h1ebDEMtfUdLFkxTifROb_wRsOUsOXOyoYdQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a5c4fedefb2f0b1f2cad8c65898887bf23e8dfc5", "width": 640, "height": 404}], "variants": {}, "id": "4ThJ0-MX4f9TGEZ0W5hZ8TGZk7Hp7jMc1Hwr4rtRwpc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4jlh7", "is_robot_indexable": true, "report_reasons": null, "author": "robert_ritz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4jlh7/what_do_you_want_in_a_data_science_publication/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4jlh7/what_do_you_want_in_a_data_science_publication/", "subreddit_subscribers": 813711, "created_utc": 1665826689.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "There are lot's of algorithm explanations out there like [this](https://blog.acolyer.org/2015/04/22/distributed-snapshots-determining-global-states-of-distributed-systems/) one, but i can't fine real code examples. Without those i really don't get it.", "author_fullname": "t2_ehomo9o8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hey guys, can you share code examples of Distributed Snapshot implementation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4h2pt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1665817318.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There are lot&amp;#39;s of algorithm explanations out there like &lt;a href=\"https://blog.acolyer.org/2015/04/22/distributed-snapshots-determining-global-states-of-distributed-systems/\"&gt;this&lt;/a&gt; one, but i can&amp;#39;t fine real code examples. Without those i really don&amp;#39;t get it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/BT3kbNfcl3kI2H2nl1QXFawJd0TfjkBzRyYw0Hrp8rU.jpg?auto=webp&amp;s=f8886d1524cf7796ae19a1569105de6973edb193", "width": 2020, "height": 1210}, "resolutions": [{"url": "https://external-preview.redd.it/BT3kbNfcl3kI2H2nl1QXFawJd0TfjkBzRyYw0Hrp8rU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b62351658eeffe4d8ff6fec079a3aa9116878956", "width": 108, "height": 64}, {"url": "https://external-preview.redd.it/BT3kbNfcl3kI2H2nl1QXFawJd0TfjkBzRyYw0Hrp8rU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d27934942280f2711b7e1813c40ff721b183922f", "width": 216, "height": 129}, {"url": "https://external-preview.redd.it/BT3kbNfcl3kI2H2nl1QXFawJd0TfjkBzRyYw0Hrp8rU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8f479db9832afd78b03b6f8126500c72ccf22eb0", "width": 320, "height": 191}, {"url": "https://external-preview.redd.it/BT3kbNfcl3kI2H2nl1QXFawJd0TfjkBzRyYw0Hrp8rU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=655e06a6d32ba60f061cfce11448d3f403e9e846", "width": 640, "height": 383}, {"url": "https://external-preview.redd.it/BT3kbNfcl3kI2H2nl1QXFawJd0TfjkBzRyYw0Hrp8rU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e8697ab8a7cdf53755d083352e271584d4cd904a", "width": 960, "height": 575}, {"url": "https://external-preview.redd.it/BT3kbNfcl3kI2H2nl1QXFawJd0TfjkBzRyYw0Hrp8rU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=53697970008a9daf145eaf0dccb5f9d311f5ad02", "width": 1080, "height": 646}], "variants": {}, "id": "JIJ5n3_5EsXlCbpR6FAYDGRDfZKADDwAEmi50TblsFU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y4h2pt", "is_robot_indexable": true, "report_reasons": null, "author": "nevermindever42", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y4h2pt/hey_guys_can_you_share_code_examples_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y4h2pt/hey_guys_can_you_share_code_examples_of/", "subreddit_subscribers": 813711, "created_utc": 1665817318.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Recently trying to forecast a 30 000 historical data (over just one year) time series, I found out that statsmodels was really not practical for iterating over many experiments. So I was wondering what you guys would use. Just the modeling part. No feature extraction or missing values imputation. Just the modeling.", "author_fullname": "t2_5m3xqp2l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "People working in forecasting high frequency / big time series, what packages do you use?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_y49htc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 0, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": "", "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665792774.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Recently trying to forecast a 30 000 historical data (over just one year) time series, I found out that statsmodels was really not practical for iterating over many experiments. So I was wondering what you guys would use. Just the modeling part. No feature extraction or missing values imputation. Just the modeling.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "call_to_action": "", "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y49htc", "is_robot_indexable": true, "report_reasons": null, "author": "LoLingLikeHell", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y49htc/people_working_in_forecasting_high_frequency_big/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y49htc/people_working_in_forecasting_high_frequency_big/", "subreddit_subscribers": 813711, "created_utc": 1665792774.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey folks, I'm a DS based in the UK, but thanks to my wife I can legally work both in the EU and the US, and current economic shifts have made me consider the future!\n\nI'd prefer to not just randomly scroll though LinkedIn job ads... does anybody have advice on a good way to find opportunities? Recruiters?  Start contracting?  Or do I just have to Google endlessly?", "author_fullname": "t2_1pqzu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scoping out about jobs abroad", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y45n2s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665782539.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks, I&amp;#39;m a DS based in the UK, but thanks to my wife I can legally work both in the EU and the US, and current economic shifts have made me consider the future!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d prefer to not just randomly scroll though LinkedIn job ads... does anybody have advice on a good way to find opportunities? Recruiters?  Start contracting?  Or do I just have to Google endlessly?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "y45n2s", "is_robot_indexable": true, "report_reasons": null, "author": "Crimsoneer", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y45n2s/scoping_out_about_jobs_abroad/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y45n2s/scoping_out_about_jobs_abroad/", "subreddit_subscribers": 813711, "created_utc": 1665782539.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}