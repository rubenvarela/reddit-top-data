{"kind": "Listing", "data": {"after": "t3_y446kw", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I understand USB 3.2 Gen 2 can do \"up to\" 10 GBit/Sec.  \n\nWhat thought of speeds can be expected from pairing this enclosure with M.2 NVMe assuming its connected to the proper USB port.  \n\nAt first hand it seems a bit of an absurdity but assuming a spare  M.2 NVMe does it make sense?\n\nThank you.", "author_fullname": "t2_11dj0v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the theoretical read/write speeds of such combo ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_y43pp1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "ups": 202, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 202, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/_DpwuCrvwTKyT1KME9zij7lE-wj7brM55plOYsWhCj8.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1665777698.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I understand USB 3.2 Gen 2 can do &amp;quot;up to&amp;quot; 10 GBit/Sec.  &lt;/p&gt;\n\n&lt;p&gt;What thought of speeds can be expected from pairing this enclosure with M.2 NVMe assuming its connected to the proper USB port.  &lt;/p&gt;\n\n&lt;p&gt;At first hand it seems a bit of an absurdity but assuming a spare  M.2 NVMe does it make sense?&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/hx7quoatutt91.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/hx7quoatutt91.jpg?auto=webp&amp;s=f25808c7830c4f217939792f1c42bb2f788aeef3", "width": 1284, "height": 1621}, "resolutions": [{"url": "https://preview.redd.it/hx7quoatutt91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1cb1cad5d497b085e53d65e6946635486ef157c2", "width": 108, "height": 136}, {"url": "https://preview.redd.it/hx7quoatutt91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3b6bee85bcaa74a7f55d837132922fe7c6c7ed0d", "width": 216, "height": 272}, {"url": "https://preview.redd.it/hx7quoatutt91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d2427a94668c202013dc172fe244f3935cc91736", "width": 320, "height": 403}, {"url": "https://preview.redd.it/hx7quoatutt91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=402a7c4856a885d3d3beec2e77ab3501464f71d3", "width": 640, "height": 807}, {"url": "https://preview.redd.it/hx7quoatutt91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e439ecddb579b54a5591a6a992d629e6b8d216dd", "width": 960, "height": 1211}, {"url": "https://preview.redd.it/hx7quoatutt91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5b6d3d1c19f79e625ea73dcc672c76c501a30b02", "width": 1080, "height": 1363}], "variants": {}, "id": "mVqVlVKYtgGqJOiMyrIzJ3Ezokacr3HZ7vJXc6KuJMw"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "130TB", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y43pp1", "is_robot_indexable": true, "report_reasons": null, "author": "nando1969", "discussion_type": null, "num_comments": 65, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/y43pp1/what_are_the_theoretical_readwrite_speeds_of_such/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/hx7quoatutt91.jpg", "subreddit_subscribers": 647797, "created_utc": 1665777698.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Before, I used to be able to right click a stream and copy the source URL, paste it in VLC and stream and record. Seems like the Chaturbate player no longer allows that. Has anyone found a way to hoard their favorite streams from Chaturbate?", "author_fullname": "t2_5i5zgezr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Capturing streams from Chaturbate", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4au9r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665796754.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Before, I used to be able to right click a stream and copy the source URL, paste it in VLC and stream and record. Seems like the Chaturbate player no longer allows that. Has anyone found a way to hoard their favorite streams from Chaturbate?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y4au9r", "is_robot_indexable": true, "report_reasons": null, "author": "FantasticContent", "discussion_type": null, "num_comments": 38, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y4au9r/capturing_streams_from_chaturbate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y4au9r/capturing_streams_from_chaturbate/", "subreddit_subscribers": 647797, "created_utc": 1665796754.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_8dw6a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "xklb v1.18: subreddit/redditor databases; download from tube and reddit databases; reddit-selftext link extraction", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_y432c0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/mDQsCVU6p9bYbMkCOZ-eKOx9oldy-4ccA9SF5Pg48Yg.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1665776087.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/chapmanjacobd/lb/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bGGX2Uawlc64vMWYFwgisT7WynxSCjNg_7Vh-upnR-4.jpg?auto=webp&amp;s=28f33b18e1e7fa94d8fe139eff68478a2379b4bd", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/bGGX2Uawlc64vMWYFwgisT7WynxSCjNg_7Vh-upnR-4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=77c77971facf342f57c78cadd62351d86df44d0a", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/bGGX2Uawlc64vMWYFwgisT7WynxSCjNg_7Vh-upnR-4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=aca45ec743766647104e3a7c5aee8db2f42a78de", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/bGGX2Uawlc64vMWYFwgisT7WynxSCjNg_7Vh-upnR-4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=864058452ba6a1c25f11f94cdf0e25b0cd54ffd9", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/bGGX2Uawlc64vMWYFwgisT7WynxSCjNg_7Vh-upnR-4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f2c3c494337417f1514a0cdf0934ecd69dc07e5d", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/bGGX2Uawlc64vMWYFwgisT7WynxSCjNg_7Vh-upnR-4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2f612dee2ad45b9b8dbd4bdcebb3a8d751184acd", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/bGGX2Uawlc64vMWYFwgisT7WynxSCjNg_7Vh-upnR-4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=88eb8f37be9214f96b86a1dd3b633d808d2c5482", "width": 1080, "height": 540}], "variants": {}, "id": "ob8sDkK7HJSxJCaBtV_DV1wQBFtQdUGlDD4w2LFSBhM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "60TB", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y432c0", "is_robot_indexable": true, "report_reasons": null, "author": "BuonaparteII", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/y432c0/xklb_v118_subredditredditor_databases_download/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/chapmanjacobd/lb/", "subreddit_subscribers": 647797, "created_utc": 1665776087.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all, I do regular backups of all of my devices, cards, and external drives, which a lot of the times includes tens of gigabytes of video footage (I do freelance videography work). I know I could most likely just delete all this footage after but as data hoarders understand, we would rather have a thorough archive of what we've shot, even if we'll never use the footage again.\n\nI've recently started using Handbrake to compress some of my archived footage which has been great - I have projects that had over 100GB of video footage in them and compressing the video files has literally halved the amount of storage space needed for those files. The only downside is, the compressed files are brand new files and the old still exist. So the only way I can actually benefit from this system is if I delete the old files, which I'm hesitant to do since those original files have all the \"created at\", \"modified at\", and other data associated with the actual original creation.\n\nWhat I'd love to be able to do is use some kind of tool or process to be able to delete these files but automatically replace them with a little data file that contains all that info. That way if I go looking for the files someday in the future and I navigate to the directory I know they should be in, I can see the files that *were* there plus all the original data from them, but it's just like a .txt file or something like that but which has the same name as the original file (different extension though obviously).\n\nIs anyone aware of something that does this or a workflow I could use to do it manually but in bulk? Any thoughts anyone has would be greatly appreciated! Cheers  \n\n\nEDIT: Forgot to mention, I have both MacOS and Windows machines but usually my backup processes take place on Windows so looking for preferably a tool/process for Windows, but can make Mac work as well.", "author_fullname": "t2_10a2c7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a method of deleting files but keeping some sort of placeholder file indicating that they were there + the metadata associated with them", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y44gu2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1665779962.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665779596.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I do regular backups of all of my devices, cards, and external drives, which a lot of the times includes tens of gigabytes of video footage (I do freelance videography work). I know I could most likely just delete all this footage after but as data hoarders understand, we would rather have a thorough archive of what we&amp;#39;ve shot, even if we&amp;#39;ll never use the footage again.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve recently started using Handbrake to compress some of my archived footage which has been great - I have projects that had over 100GB of video footage in them and compressing the video files has literally halved the amount of storage space needed for those files. The only downside is, the compressed files are brand new files and the old still exist. So the only way I can actually benefit from this system is if I delete the old files, which I&amp;#39;m hesitant to do since those original files have all the &amp;quot;created at&amp;quot;, &amp;quot;modified at&amp;quot;, and other data associated with the actual original creation.&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;d love to be able to do is use some kind of tool or process to be able to delete these files but automatically replace them with a little data file that contains all that info. That way if I go looking for the files someday in the future and I navigate to the directory I know they should be in, I can see the files that &lt;em&gt;were&lt;/em&gt; there plus all the original data from them, but it&amp;#39;s just like a .txt file or something like that but which has the same name as the original file (different extension though obviously).&lt;/p&gt;\n\n&lt;p&gt;Is anyone aware of something that does this or a workflow I could use to do it manually but in bulk? Any thoughts anyone has would be greatly appreciated! Cheers  &lt;/p&gt;\n\n&lt;p&gt;EDIT: Forgot to mention, I have both MacOS and Windows machines but usually my backup processes take place on Windows so looking for preferably a tool/process for Windows, but can make Mac work as well.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y44gu2", "is_robot_indexable": true, "report_reasons": null, "author": "DoctorVanNostrandMD", "discussion_type": null, "num_comments": 13, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y44gu2/looking_for_a_method_of_deleting_files_but/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y44gu2/looking_for_a_method_of_deleting_files_but/", "subreddit_subscribers": 647797, "created_utc": 1665779596.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Yes, you read that correctly. The goal is to archive large parts of Discord.\n\n&amp;#x200B;\n\n**Why?**\n\nIt is important to archive a platform like Discord. Discord has replaced forums as a platform for exchanging information on specific topics. These forums are fortunately largely covered by e.g. the Wayback-Machine. The problem is that Discord is quite closed and can't be easily archived.\n\n&amp;#x200B;\n\n**How can the whole thing be done?**\n\nMe and a friend have thought about something. We have developed a website and a discord bot. Every server admin can index his server with the bot. On [Search-Cord.com](https://Search-Cord.com) you can search all messages in a few milliseconds. The usernames no longer contain #tags so that no users can be contacted against their will.\n\n**The current state:**\n\nCurrently we have about 20 servers with a total of about 3 million messages archived?\n\n&amp;#x200B;\n\n**What about opensource?**\n\nThe complete source code can be found on Github.\n\n**What if someone does not want their messages to be in the archive?**\n\nOn the website you can autentify yourself with discord and then delete all messages from the archive and put yourself on a blacklist to prevent future messages from being archived.", "author_fullname": "t2_3z9flfls", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lets archive Discord!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_y4u1rt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Archiving", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1665855956.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Yes, you read that correctly. The goal is to archive large parts of Discord.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Why?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;It is important to archive a platform like Discord. Discord has replaced forums as a platform for exchanging information on specific topics. These forums are fortunately largely covered by e.g. the Wayback-Machine. The problem is that Discord is quite closed and can&amp;#39;t be easily archived.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;How can the whole thing be done?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Me and a friend have thought about something. We have developed a website and a discord bot. Every server admin can index his server with the bot. On &lt;a href=\"https://Search-Cord.com\"&gt;Search-Cord.com&lt;/a&gt; you can search all messages in a few milliseconds. The usernames no longer contain #tags so that no users can be contacted against their will.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The current state:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Currently we have about 20 servers with a total of about 3 million messages archived?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What about opensource?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;The complete source code can be found on Github.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What if someone does not want their messages to be in the archive?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;On the website you can autentify yourself with discord and then delete all messages from the archive and put yourself on a blacklist to prevent future messages from being archived.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZWCkekSyfRryVl2n7MjmaqKot6Mcy_AkzVZwfI_SbFg.jpg?auto=webp&amp;s=bf363860e48824c4e5999bd270e074714989c2ed", "width": 1000, "height": 1000}, "resolutions": [{"url": "https://external-preview.redd.it/ZWCkekSyfRryVl2n7MjmaqKot6Mcy_AkzVZwfI_SbFg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1878cf494a8f6654cc31182e470f59dfc7d27e50", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/ZWCkekSyfRryVl2n7MjmaqKot6Mcy_AkzVZwfI_SbFg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a322ac5ca5dc1f8588d4a57a26c4bf9383622c0f", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/ZWCkekSyfRryVl2n7MjmaqKot6Mcy_AkzVZwfI_SbFg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=55820265efa9373cb634da3be611f09d4202df53", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/ZWCkekSyfRryVl2n7MjmaqKot6Mcy_AkzVZwfI_SbFg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2b36d95d9327795f1d01a67c620d7d4958f3201d", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/ZWCkekSyfRryVl2n7MjmaqKot6Mcy_AkzVZwfI_SbFg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1a072a4a2cc388149a6bb95f6ec00eea819b9470", "width": 960, "height": 960}], "variants": {}, "id": "T2GIaTFxI1lo9UgmAAqcoKeUdkavB6CKKyANqAyEi6I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "20TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "y4u1rt", "is_robot_indexable": true, "report_reasons": null, "author": "calvinwaran", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/y4u1rt/lets_archive_discord/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y4u1rt/lets_archive_discord/", "subreddit_subscribers": 647797, "created_utc": 1665855956.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "hey guys, there\u2019s a website with about 300 recipes I\u2019d like to add to my hoard. I\u2019ve just been using the print recipe feature to make pdfs and it works fine, but I was wondering if anyone knows a better way than just doing this about 290 more times? \n\nI\u2019m not interested in archiving the whole website, just the recipes themselves. I\u2019m willing to go through them all individually but I would rather not if there\u2019s an easier way lol. \n\nThanks!", "author_fullname": "t2_1uhlwc4j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Downloading Recipes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4eza9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.54, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665809835.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey guys, there\u2019s a website with about 300 recipes I\u2019d like to add to my hoard. I\u2019ve just been using the print recipe feature to make pdfs and it works fine, but I was wondering if anyone knows a better way than just doing this about 290 more times? &lt;/p&gt;\n\n&lt;p&gt;I\u2019m not interested in archiving the whole website, just the recipes themselves. I\u2019m willing to go through them all individually but I would rather not if there\u2019s an easier way lol. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y4eza9", "is_robot_indexable": true, "report_reasons": null, "author": "UndyingArtist", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y4eza9/downloading_recipes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y4eza9/downloading_recipes/", "subreddit_subscribers": 647797, "created_utc": 1665809835.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Long story short: I need sports data. Do any of you know where I could find professional sports data for EVERY player in a league specifically NBA, MLB, and NFL. Any ideas would be much appreciated!  ( I already know about the popular sports reference site, I am looking for alternatives)", "author_fullname": "t2_8rbcsrwo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need sports data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_y4vpan", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665860243.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Long story short: I need sports data. Do any of you know where I could find professional sports data for EVERY player in a league specifically NBA, MLB, and NFL. Any ideas would be much appreciated!  ( I already know about the popular sports reference site, I am looking for alternatives)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y4vpan", "is_robot_indexable": true, "report_reasons": null, "author": "Traditional_Soil5753", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y4vpan/i_need_sports_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y4vpan/i_need_sports_data/", "subreddit_subscribers": 647797, "created_utc": 1665860243.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "The website in question :  [https://weilbyte.github.io/tiktok-tts/](https://weilbyte.github.io/tiktok-tts/)\n\nI downloaded the code from the author's github page and also right-click-save'd it. But it both of these only work when I have internet connection? What should I do?", "author_fullname": "t2_ml52arso", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trying to archive an applet/tool website but it seems to only work when I have internet access. What should I do to get permanent offline usage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_y4voij", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1665860186.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The website in question :  &lt;a href=\"https://weilbyte.github.io/tiktok-tts/\"&gt;https://weilbyte.github.io/tiktok-tts/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I downloaded the code from the author&amp;#39;s github page and also right-click-save&amp;#39;d it. But it both of these only work when I have internet connection? What should I do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Wdh_kjDAhlqMRiOHvyL0-s_mLxuPjMgGVEOxKkgjzMo.jpg?auto=webp&amp;s=ed2eba7e9e39f1286974a2cf347e9d5996e0611c", "width": 491, "height": 553}, "resolutions": [{"url": "https://external-preview.redd.it/Wdh_kjDAhlqMRiOHvyL0-s_mLxuPjMgGVEOxKkgjzMo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4bf6103e048a09a3247864a38379df7d173dc169", "width": 108, "height": 121}, {"url": "https://external-preview.redd.it/Wdh_kjDAhlqMRiOHvyL0-s_mLxuPjMgGVEOxKkgjzMo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7a366c0dca4204268f59cc284546fedeb671616c", "width": 216, "height": 243}, {"url": "https://external-preview.redd.it/Wdh_kjDAhlqMRiOHvyL0-s_mLxuPjMgGVEOxKkgjzMo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=aea10fdd8f20e8964f3f4105e7ad83bbb2ff9194", "width": 320, "height": 360}], "variants": {}, "id": "M4bKAxU3jQ6z_rAAzXBNxqg-zEPVzi0rly1ULCoWq24"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y4voij", "is_robot_indexable": true, "report_reasons": null, "author": "m_betelgeuse", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y4voij/trying_to_archive_an_applettool_website_but_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y4voij/trying_to_archive_an_applettool_website_but_it/", "subreddit_subscribers": 647797, "created_utc": 1665860186.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_2i4oc8js", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Turned off the computer while disk was open. Now it can'be detected at all. It is not dead, this has happened before, I just can't remember the fix.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_y4ndu2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 4800, "fallback_url": "https://v.redd.it/7favyz7lwyt91/DASH_1080.mp4?source=fallback", "height": 1080, "width": 607, "scrubber_media_url": "https://v.redd.it/7favyz7lwyt91/DASH_96.mp4", "dash_url": "https://v.redd.it/7favyz7lwyt91/DASHPlaylist.mpd?a=1668454970%2COWE0MjM3NDk2YjU3NmRhZTY2YzY4Zjk5YjRiMzhmYmRhMTdhMTUwZWNmYmI3MDUyNTEyOGZiMGU2ODQwMWRiYQ%3D%3D&amp;v=1&amp;f=sd", "duration": 12, "hls_url": "https://v.redd.it/7favyz7lwyt91/HLSPlaylist.m3u8?a=1668454970%2CYTJjZWVhYmIxZjlmMGNlNzFhZGM5ZjQ0Yzg3ZTc4NDRhM2U0MGRmMjdkN2MzZDllZGFmY2NjNzYyODFmMDE1OQ%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/iukMcImQk3T_cT9LeIrkvaw1djAGcsgdwZkiElTPP-E.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1665838832.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/7favyz7lwyt91", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/om8UoYVQaiYt5r9fCpWvgyPziNjXgS-twpu5Cjcjzu0.png?format=pjpg&amp;auto=webp&amp;s=3c57e3603b8e23f607a6570100ebc392148b5661", "width": 1080, "height": 1920}, "resolutions": [{"url": "https://external-preview.redd.it/om8UoYVQaiYt5r9fCpWvgyPziNjXgS-twpu5Cjcjzu0.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=09bd0ce54add0f0b55837610668888e0c2e10e97", "width": 108, "height": 192}, {"url": "https://external-preview.redd.it/om8UoYVQaiYt5r9fCpWvgyPziNjXgS-twpu5Cjcjzu0.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=87b91ddfc6d1f8ffb200f086bcc0e32e0bc669cd", "width": 216, "height": 384}, {"url": "https://external-preview.redd.it/om8UoYVQaiYt5r9fCpWvgyPziNjXgS-twpu5Cjcjzu0.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=c6afac8232c79450b007d2a2d8de3780d95d8246", "width": 320, "height": 568}, {"url": "https://external-preview.redd.it/om8UoYVQaiYt5r9fCpWvgyPziNjXgS-twpu5Cjcjzu0.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=c611e44dc0db57da28441ec0ef5c6f7ed21a6536", "width": 640, "height": 1137}, {"url": "https://external-preview.redd.it/om8UoYVQaiYt5r9fCpWvgyPziNjXgS-twpu5Cjcjzu0.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=2d4532686fde3cd5b45f0d4dbe5ae5523bb4a2ea", "width": 960, "height": 1706}, {"url": "https://external-preview.redd.it/om8UoYVQaiYt5r9fCpWvgyPziNjXgS-twpu5Cjcjzu0.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=04927cc6651837b181959e55f0de7c27547d8968", "width": 1080, "height": 1920}], "variants": {}, "id": "8CpiNZVtF_BEE0y-y2mhmVSrAUii1jEiOIf6XKzEzDo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y4ndu2", "is_robot_indexable": true, "report_reasons": null, "author": "ABPAM", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y4ndu2/turned_off_the_computer_while_disk_was_open_now/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/7favyz7lwyt91", "subreddit_subscribers": 647797, "created_utc": 1665838832.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 4800, "fallback_url": "https://v.redd.it/7favyz7lwyt91/DASH_1080.mp4?source=fallback", "height": 1080, "width": 607, "scrubber_media_url": "https://v.redd.it/7favyz7lwyt91/DASH_96.mp4", "dash_url": "https://v.redd.it/7favyz7lwyt91/DASHPlaylist.mpd?a=1668454970%2COWE0MjM3NDk2YjU3NmRhZTY2YzY4Zjk5YjRiMzhmYmRhMTdhMTUwZWNmYmI3MDUyNTEyOGZiMGU2ODQwMWRiYQ%3D%3D&amp;v=1&amp;f=sd", "duration": 12, "hls_url": "https://v.redd.it/7favyz7lwyt91/HLSPlaylist.m3u8?a=1668454970%2CYTJjZWVhYmIxZjlmMGNlNzFhZGM5ZjQ0Yzg3ZTc4NDRhM2U0MGRmMjdkN2MzZDllZGFmY2NjNzYyODFmMDE1OQ%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "&amp;#x200B;\n\n[Keep in mind i've dropped this harddrive a few times \\(once or twice\\)](https://preview.redd.it/4tin8knirxt91.png?width=804&amp;format=png&amp;auto=webp&amp;s=5b0903544609f389b0c9ec617ef2625d26b84ebe)", "author_fullname": "t2_91tg7rqo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Drive failing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 5, "top_awarded_type": null, "hide_score": false, "media_metadata": {"4tin8knirxt91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 4, "x": 108, "u": "https://preview.redd.it/4tin8knirxt91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7d9c17106d46b13e7ec262e75ef7aa4fa2ed297d"}, {"y": 8, "x": 216, "u": "https://preview.redd.it/4tin8knirxt91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=457d46981c9a5e62d897afe73c54d2ac67db4cf4"}, {"y": 12, "x": 320, "u": "https://preview.redd.it/4tin8knirxt91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=82a7670b5f6cfc2731ac7baf5c071e295339b65d"}, {"y": 24, "x": 640, "u": "https://preview.redd.it/4tin8knirxt91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=aec5deb9ac3a71951660147ffaa80f8a0e037c6d"}], "s": {"y": 31, "x": 804, "u": "https://preview.redd.it/4tin8knirxt91.png?width=804&amp;format=png&amp;auto=webp&amp;s=5b0903544609f389b0c9ec617ef2625d26b84ebe"}, "id": "4tin8knirxt91"}}, "name": "t3_y4j5a8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/Kh-oUCleNUegGcs1Mbr8WsWTBBLB0cF10MK0-yzc6lc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665825080.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/4tin8knirxt91.png?width=804&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5b0903544609f389b0c9ec617ef2625d26b84ebe\"&gt;Keep in mind i&amp;#39;ve dropped this harddrive a few times (once or twice)&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y4j5a8", "is_robot_indexable": true, "report_reasons": null, "author": "ComputerLovveerrBoy", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y4j5a8/drive_failing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y4j5a8/drive_failing/", "subreddit_subscribers": 647797, "created_utc": 1665825080.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Putting together a 8-12 bay NAS soon. Haven't decided between Unraid and QNAP. I don't care about noise or power consumption, just performance and longevity.", "author_fullname": "t2_23kjb158", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WD Red Pro or Gold?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4i3bq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665821146.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Putting together a 8-12 bay NAS soon. Haven&amp;#39;t decided between Unraid and QNAP. I don&amp;#39;t care about noise or power consumption, just performance and longevity.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y4i3bq", "is_robot_indexable": true, "report_reasons": null, "author": "werdmouf", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y4i3bq/wd_red_pro_or_gold/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y4i3bq/wd_red_pro_or_gold/", "subreddit_subscribers": 647797, "created_utc": 1665821146.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "First off if this is the wrong place or wrong question i am sorry ill look elsewhere.\n\nI have 2x3tb 2x8tb of growing data. All drives are external and really spread out , not sure the total actual data vs copies of data (future project) im looking to build a second PC for shucking drives in the future and build up a better setup. My question is what route should i go? Should i purchase 2 10+tb drives and put them into the new system and copy all my data over or just keep adding and growing my current setup. The 2 n 8 drives will go into a 10bay pc and be replaced once bay is full or drives die off. I've not played or tried any raid setup. Ive just been manually cloning the drives once a year.", "author_fullname": "t2_3suaq7sd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "building a NAS for my growing collection.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y44xge", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665780763.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First off if this is the wrong place or wrong question i am sorry ill look elsewhere.&lt;/p&gt;\n\n&lt;p&gt;I have 2x3tb 2x8tb of growing data. All drives are external and really spread out , not sure the total actual data vs copies of data (future project) im looking to build a second PC for shucking drives in the future and build up a better setup. My question is what route should i go? Should i purchase 2 10+tb drives and put them into the new system and copy all my data over or just keep adding and growing my current setup. The 2 n 8 drives will go into a 10bay pc and be replaced once bay is full or drives die off. I&amp;#39;ve not played or tried any raid setup. Ive just been manually cloning the drives once a year.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y44xge", "is_robot_indexable": true, "report_reasons": null, "author": "JBizz86", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y44xge/building_a_nas_for_my_growing_collection/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y44xge/building_a_nas_for_my_growing_collection/", "subreddit_subscribers": 647797, "created_utc": 1665780763.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "how can I predict that some data on hdd are going to get corrupted, is there a software for that ?\n\nhow can I know that any bit  of data has been corrupted, does the computer show a notification, is there a software to detect that ?", "author_fullname": "t2_5p9rx19x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HDD data corruption (loss)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4gkgu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.42, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665815437.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;how can I predict that some data on hdd are going to get corrupted, is there a software for that ?&lt;/p&gt;\n\n&lt;p&gt;how can I know that any bit  of data has been corrupted, does the computer show a notification, is there a software to detect that ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y4gkgu", "is_robot_indexable": true, "report_reasons": null, "author": "VladamirLem9781", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y4gkgu/hdd_data_corruption_loss/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y4gkgu/hdd_data_corruption_loss/", "subreddit_subscribers": 647797, "created_utc": 1665815437.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "After many months of research, I went with a TB3 4xSATA enclosure and went to work...\n\nInternal chip is reported as:\n\n`ASMedia Technology Inc. ASM1062 Serial ATA Controller (rev 01)`\n\nI installed a pair of old 2tb drives and started badblocks destructive mode to stress the TB3 link and chip. It ran for about 2 days with no errors on the ATA or TB connection.\n\nThen I ran some tests with SMART and hd-idle. SMART pass through worked fine with the exception of an old samsung HD204 2TB disk (known to have some SMART quirks). Continued these tests on the drives I installed later (listed below).\n\nDisks will spin down from hd-idle and hdparm, and they will spin up again when the mounted filesystem is accessed. No filesystem errors.\n\nNext I mounted 2x6TB and 2x5TB drives and began a transfer test. Initiated LUKS encryption then balanced a total of 8TB across all 4 drives with no link resets, full data scrub with no problems. HDD temps stayed around 28C-35C under hours of I/O. Copying data from an individual drive can sustain 200MB/s. I did not saturate the bus with read/s writes to all drives simultaneously. When balancing the data there is a cumulative \\~500MB/s (about 119-130MB/s per drive) for hours.\n\nSet it all up with a mergerfs pool and have been running it as a data server with a few docker containers which periodically write data to the array, and a few containers periodically reading from the array.\n\nSo far I can say everything is working to my liking. Haven't tested hot swap because I don't practice hot swap and I don't know if the device  supports hot swap.\n\nThe most important things are having the drives sleep after inactivity and spin up when accessed, without any ATA, filesystem, or TB link resets/problems.\n\nFor anyone else curious about TB3 external arrays related to data/system stability and behavior, I hope this info helps.\n\nIt's an Akitio TB3, I was pleasantly surprised with the first phone call I made to sales.\n\n[https://www.akitio.com/desktop-storage/akitio-thunder3-quad](https://www.akitio.com/desktop-storage/akitio-thunder3-quad)", "author_fullname": "t2_3z08rn1y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My experience with TB3 external enclosure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4aigq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1665795766.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After many months of research, I went with a TB3 4xSATA enclosure and went to work...&lt;/p&gt;\n\n&lt;p&gt;Internal chip is reported as:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;ASMedia Technology Inc. ASM1062 Serial ATA Controller (rev 01)&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;I installed a pair of old 2tb drives and started badblocks destructive mode to stress the TB3 link and chip. It ran for about 2 days with no errors on the ATA or TB connection.&lt;/p&gt;\n\n&lt;p&gt;Then I ran some tests with SMART and hd-idle. SMART pass through worked fine with the exception of an old samsung HD204 2TB disk (known to have some SMART quirks). Continued these tests on the drives I installed later (listed below).&lt;/p&gt;\n\n&lt;p&gt;Disks will spin down from hd-idle and hdparm, and they will spin up again when the mounted filesystem is accessed. No filesystem errors.&lt;/p&gt;\n\n&lt;p&gt;Next I mounted 2x6TB and 2x5TB drives and began a transfer test. Initiated LUKS encryption then balanced a total of 8TB across all 4 drives with no link resets, full data scrub with no problems. HDD temps stayed around 28C-35C under hours of I/O. Copying data from an individual drive can sustain 200MB/s. I did not saturate the bus with read/s writes to all drives simultaneously. When balancing the data there is a cumulative ~500MB/s (about 119-130MB/s per drive) for hours.&lt;/p&gt;\n\n&lt;p&gt;Set it all up with a mergerfs pool and have been running it as a data server with a few docker containers which periodically write data to the array, and a few containers periodically reading from the array.&lt;/p&gt;\n\n&lt;p&gt;So far I can say everything is working to my liking. Haven&amp;#39;t tested hot swap because I don&amp;#39;t practice hot swap and I don&amp;#39;t know if the device  supports hot swap.&lt;/p&gt;\n\n&lt;p&gt;The most important things are having the drives sleep after inactivity and spin up when accessed, without any ATA, filesystem, or TB link resets/problems.&lt;/p&gt;\n\n&lt;p&gt;For anyone else curious about TB3 external arrays related to data/system stability and behavior, I hope this info helps.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s an Akitio TB3, I was pleasantly surprised with the first phone call I made to sales.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.akitio.com/desktop-storage/akitio-thunder3-quad\"&gt;https://www.akitio.com/desktop-storage/akitio-thunder3-quad&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/u4veYcBxmWIN_V8phD0kVzJJQkPqzrvWoJjcejBLLwU.jpg?auto=webp&amp;s=b8c0d3cb0be36011ef8dec921343055edc24c57c", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/u4veYcBxmWIN_V8phD0kVzJJQkPqzrvWoJjcejBLLwU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2f7494472179b825878d4e8cc665a23f4c84309c", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/u4veYcBxmWIN_V8phD0kVzJJQkPqzrvWoJjcejBLLwU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f1376f527dd1d9bde3e12225d3eda4aa788db395", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/u4veYcBxmWIN_V8phD0kVzJJQkPqzrvWoJjcejBLLwU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0dc787946070a4dabfac40d006b8696c91934b56", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/u4veYcBxmWIN_V8phD0kVzJJQkPqzrvWoJjcejBLLwU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=cd62da6d5f1c2c77ea9c981d4775cb56083cc0e3", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/u4veYcBxmWIN_V8phD0kVzJJQkPqzrvWoJjcejBLLwU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=edea7a2c8fd921f1515a7568e51de713fa6648a4", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/u4veYcBxmWIN_V8phD0kVzJJQkPqzrvWoJjcejBLLwU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=295755aed02525eb66e13b3d82632d13f00cf399", "width": 1080, "height": 540}], "variants": {}, "id": "e8ePT1T3p9b5cl5g0yjwYmc-UOVmqjDEAoXAFIo_FlM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y4aigq", "is_robot_indexable": true, "report_reasons": null, "author": "kram3210", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y4aigq/my_experience_with_tb3_external_enclosure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y4aigq/my_experience_with_tb3_external_enclosure/", "subreddit_subscribers": 647797, "created_utc": 1665795766.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am trying to come up with something similar to those expensive DAS units that I can configure myself.\n\nI found a unit that even used BTRFS, but I would assume their \"gui\" wouldn't include the same level of features as accessing the drives themselves.\n\nSo, I wonder what options are available to build an external DAS unit that works over usb 3.2 and or thunderbolt 3/4?\n\n&amp;#x200B;\n\nAlternatively, an external drive enclosure that supports raid 1+0?\n\nAlso, would you recommend if going the enclosure route that I have an extra external drive to keep important files safe?\n\n&amp;#x200B;\n\nWhat are your experiences with roadwarrior style for managing storage?  \nI'll have a large lithium battery to run this, plugged into the 12v on a vehicle. I don't need much storage on the go, but I'd like to be able to keep VM backups and storage for video/photos local.\n\nI'm also likely to have the option for remote VMs, but this is a road I've yet to cross.", "author_fullname": "t2_gru9m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Roadwarrior configuration?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y47mjv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665787559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to come up with something similar to those expensive DAS units that I can configure myself.&lt;/p&gt;\n\n&lt;p&gt;I found a unit that even used BTRFS, but I would assume their &amp;quot;gui&amp;quot; wouldn&amp;#39;t include the same level of features as accessing the drives themselves.&lt;/p&gt;\n\n&lt;p&gt;So, I wonder what options are available to build an external DAS unit that works over usb 3.2 and or thunderbolt 3/4?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Alternatively, an external drive enclosure that supports raid 1+0?&lt;/p&gt;\n\n&lt;p&gt;Also, would you recommend if going the enclosure route that I have an extra external drive to keep important files safe?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What are your experiences with roadwarrior style for managing storage?&lt;br/&gt;\nI&amp;#39;ll have a large lithium battery to run this, plugged into the 12v on a vehicle. I don&amp;#39;t need much storage on the go, but I&amp;#39;d like to be able to keep VM backups and storage for video/photos local.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m also likely to have the option for remote VMs, but this is a road I&amp;#39;ve yet to cross.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y47mjv", "is_robot_indexable": true, "report_reasons": null, "author": "uberbewb", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y47mjv/roadwarrior_configuration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y47mjv/roadwarrior_configuration/", "subreddit_subscribers": 647797, "created_utc": 1665787559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone, \nI'm in the process of digitizing a large storage of paper documents. I have access to good office printers, so scanning most of the standard documents was a breeze. But I'm having issues with larger format documents. Especially paper rolls (so about 3-4m x 80cm wide), but also larger DIN A0 documents (e.g. Blueprints, plans, family trees, posters, etc.). \nI checked local services, but they can only handle DIN formats, but not the rolls. \nDo you guys have any ideas on how I could digitize them in somewhat good quality? I was thinking of taking lots of photos and stitching them with photomerge in Photoshop, but that failed quite badly. \nAre there maybe some scanner apps specialized for this, or are there any other techniques than I'm missing? \nThanks for any help in advance!", "author_fullname": "t2_uxafe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Digitizing large format paper documents for storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y46ool", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665785158.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, \nI&amp;#39;m in the process of digitizing a large storage of paper documents. I have access to good office printers, so scanning most of the standard documents was a breeze. But I&amp;#39;m having issues with larger format documents. Especially paper rolls (so about 3-4m x 80cm wide), but also larger DIN A0 documents (e.g. Blueprints, plans, family trees, posters, etc.). \nI checked local services, but they can only handle DIN formats, but not the rolls. \nDo you guys have any ideas on how I could digitize them in somewhat good quality? I was thinking of taking lots of photos and stitching them with photomerge in Photoshop, but that failed quite badly. \nAre there maybe some scanner apps specialized for this, or are there any other techniques than I&amp;#39;m missing? \nThanks for any help in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y46ool", "is_robot_indexable": true, "report_reasons": null, "author": "corny96", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y46ool/digitizing_large_format_paper_documents_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y46ool/digitizing_large_format_paper_documents_for/", "subreddit_subscribers": 647797, "created_utc": 1665785158.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "As the title indicates, I'm looking for S3 compatible storage provider that I can use with rclone on Linux to dump (long term backup) files. These will be primarily Borg backup files from my NAS storage. Any suggestions for a reasonably priced provider for home use segment?", "author_fullname": "t2_s7edcv9d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommendations for S3 compatible cold storage provider with ultra low price tag?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y44rep", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665780337.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title indicates, I&amp;#39;m looking for S3 compatible storage provider that I can use with rclone on Linux to dump (long term backup) files. These will be primarily Borg backup files from my NAS storage. Any suggestions for a reasonably priced provider for home use segment?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y44rep", "is_robot_indexable": true, "report_reasons": null, "author": "useless-oracle", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y44rep/recommendations_for_s3_compatible_cold_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y44rep/recommendations_for_s3_compatible_cold_storage/", "subreddit_subscribers": 647797, "created_utc": 1665780337.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Easiest way to archive an entire website subdirectory", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y43zou", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_shla9q08", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "WaybackMachine", "selftext": "Before anyone tells me to Google it, I did and it was unsurprisingly futile \ud83d\ude05. The algorithm isn't exactly designed to provide helpful results anymore, so naturally I've come to Reddit for answers.\n\nEarlier this week, I was laid off from a nascent digital media publication after finding out our site was being shuttered. We were to our parent company what The Wirecutter became to the New York Times a few years ago: a subdirectory hosted on a more prominent domain offering purchasing advice based on product testing insights.\n\nAs everyone on my team is about to lose all record of the hard work we put in over the last six months, I'm desperate to find a straightforward method of archiving every page in the subdirectory without manually pasting every URL into Wayback Machine. I'm skeptical the company is going to provide a backup given how long it's taking to reach a decision on whether or not they even want to. It's seemingly in limbo, and I'm not sure how much time we have before the site goes dark.\n\n[HTTrack](https://www.httrack.com/) seems to be a popular option, but I don't have a Windows or Linux machine, as I exclusively work on a Mac, and it doesn't appear to be compatible with MacOS. I also found [WaybackArchiver](https://github.com/buren/wayback_archiver) on GitHub, but I'm out of my depth just trying to follow the installation instructions. I like to think i'm tech literate, but I only have a vague understanding of sitemaps, let alone how to use a crawler or what a Gemfile even is. \n\nPlease, if anyone has a solution to automate a full subdirectory archival a layman could quickly pick up and execute, I'll owe you a beer or a blunt \u2014 whatever floats your boat.", "author_fullname": "t2_shla9q08", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Easiest way to archive an entire website subdirectory", "link_flair_richtext": [], "subreddit_name_prefixed": "r/WaybackMachine", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y43z5s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1665778353.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.WaybackMachine", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Before anyone tells me to Google it, I did and it was unsurprisingly futile \ud83d\ude05. The algorithm isn&amp;#39;t exactly designed to provide helpful results anymore, so naturally I&amp;#39;ve come to Reddit for answers.&lt;/p&gt;\n\n&lt;p&gt;Earlier this week, I was laid off from a nascent digital media publication after finding out our site was being shuttered. We were to our parent company what The Wirecutter became to the New York Times a few years ago: a subdirectory hosted on a more prominent domain offering purchasing advice based on product testing insights.&lt;/p&gt;\n\n&lt;p&gt;As everyone on my team is about to lose all record of the hard work we put in over the last six months, I&amp;#39;m desperate to find a straightforward method of archiving every page in the subdirectory without manually pasting every URL into Wayback Machine. I&amp;#39;m skeptical the company is going to provide a backup given how long it&amp;#39;s taking to reach a decision on whether or not they even want to. It&amp;#39;s seemingly in limbo, and I&amp;#39;m not sure how much time we have before the site goes dark.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.httrack.com/\"&gt;HTTrack&lt;/a&gt; seems to be a popular option, but I don&amp;#39;t have a Windows or Linux machine, as I exclusively work on a Mac, and it doesn&amp;#39;t appear to be compatible with MacOS. I also found &lt;a href=\"https://github.com/buren/wayback_archiver\"&gt;WaybackArchiver&lt;/a&gt; on GitHub, but I&amp;#39;m out of my depth just trying to follow the installation instructions. I like to think i&amp;#39;m tech literate, but I only have a vague understanding of sitemaps, let alone how to use a crawler or what a Gemfile even is. &lt;/p&gt;\n\n&lt;p&gt;Please, if anyone has a solution to automate a full subdirectory archival a layman could quickly pick up and execute, I&amp;#39;ll owe you a beer or a blunt \u2014 whatever floats your boat.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/tgdafAt2hOfyEFP2YVpJAL51ZycsTiEt8VxN2HoM1eg.jpg?auto=webp&amp;s=d7f0508bee931f5ec01c81898799c76e53a49c3a", "width": 300, "height": 233}, "resolutions": [{"url": "https://external-preview.redd.it/tgdafAt2hOfyEFP2YVpJAL51ZycsTiEt8VxN2HoM1eg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1ddefedb0f954f724be9d99fc4940672fa80d82c", "width": 108, "height": 83}, {"url": "https://external-preview.redd.it/tgdafAt2hOfyEFP2YVpJAL51ZycsTiEt8VxN2HoM1eg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=881ad6280f8960bc672a6e1d3566590968c5eca8", "width": 216, "height": 167}], "variants": {}, "id": "IqlRJ_uGr1gJ9Z81mzoF33bSshgJZY-BlRfO9FbM4NA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qptp", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y43z5s", "is_robot_indexable": true, "report_reasons": null, "author": "FrackingEnthusiast", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/WaybackMachine/comments/y43z5s/easiest_way_to_archive_an_entire_website/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/WaybackMachine/comments/y43z5s/easiest_way_to_archive_an_entire_website/", "subreddit_subscribers": 1463, "created_utc": 1665778353.0, "num_crossposts": 3, "media": null, "is_video": false}], "created": 1665778393.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.WaybackMachine", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/WaybackMachine/comments/y43z5s/easiest_way_to_archive_an_entire_website/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/tgdafAt2hOfyEFP2YVpJAL51ZycsTiEt8VxN2HoM1eg.jpg?auto=webp&amp;s=d7f0508bee931f5ec01c81898799c76e53a49c3a", "width": 300, "height": 233}, "resolutions": [{"url": "https://external-preview.redd.it/tgdafAt2hOfyEFP2YVpJAL51ZycsTiEt8VxN2HoM1eg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1ddefedb0f954f724be9d99fc4940672fa80d82c", "width": 108, "height": 83}, {"url": "https://external-preview.redd.it/tgdafAt2hOfyEFP2YVpJAL51ZycsTiEt8VxN2HoM1eg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=881ad6280f8960bc672a6e1d3566590968c5eca8", "width": 216, "height": 167}], "variants": {}, "id": "IqlRJ_uGr1gJ9Z81mzoF33bSshgJZY-BlRfO9FbM4NA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y43zou", "is_robot_indexable": true, "report_reasons": null, "author": "FrackingEnthusiast", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_y43z5s", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y43zou/easiest_way_to_archive_an_entire_website/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/WaybackMachine/comments/y43z5s/easiest_way_to_archive_an_entire_website/", "subreddit_subscribers": 647797, "created_utc": 1665778393.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've got a Dell r710 and I'm looking to outfit it with 6 drives. Gonna use unRAID for my media server. I've heard of people using an SSD in one bay to store the os on so if that's a thing and it'll make the system more reliable I'll gladly do that. Anyways I can't find any non shady looking sellers on Newegg but I'm looking to get 6 SAS 3.5 HDDs. I'd like to get as much storage as possible for less than $150 per drive. Any recommendations ? If I have to choose between reliability vs storage size I'll choose reliability every time. I appreciate any recommendations you can give.", "author_fullname": "t2_1ytjqpie", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with drive recommendations ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4k1w6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665828320.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got a Dell r710 and I&amp;#39;m looking to outfit it with 6 drives. Gonna use unRAID for my media server. I&amp;#39;ve heard of people using an SSD in one bay to store the os on so if that&amp;#39;s a thing and it&amp;#39;ll make the system more reliable I&amp;#39;ll gladly do that. Anyways I can&amp;#39;t find any non shady looking sellers on Newegg but I&amp;#39;m looking to get 6 SAS 3.5 HDDs. I&amp;#39;d like to get as much storage as possible for less than $150 per drive. Any recommendations ? If I have to choose between reliability vs storage size I&amp;#39;ll choose reliability every time. I appreciate any recommendations you can give.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y4k1w6", "is_robot_indexable": true, "report_reasons": null, "author": "SirLance-a-lot", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y4k1w6/help_with_drive_recommendations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y4k1w6/help_with_drive_recommendations/", "subreddit_subscribers": 647797, "created_utc": 1665828320.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Cheapest I've seen them lately are about 70-75 dollars a TB.\n\nWhen you take into consideration, their read/write speeds cap at roughly 530MB/sec  and the prices and performance of M.2 NVMe or the cheap TB Price of HDD ($13-15/TB) they have to be of the worse values out there for storage.\n\nIs it because they can fit laptops due to their 2.5\" form factor?\n\nUnless of course, I'm missing something obvious, would not be the first time.\n\nPlease share your input, thank you.", "author_fullname": "t2_11dj0v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts about the SAMSUNG 870 QVO SATA III 2.5\" SSD 8TB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4g45a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1665825170.0, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665813762.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Cheapest I&amp;#39;ve seen them lately are about 70-75 dollars a TB.&lt;/p&gt;\n\n&lt;p&gt;When you take into consideration, their read/write speeds cap at roughly 530MB/sec  and the prices and performance of M.2 NVMe or the cheap TB Price of HDD ($13-15/TB) they have to be of the worse values out there for storage.&lt;/p&gt;\n\n&lt;p&gt;Is it because they can fit laptops due to their 2.5&amp;quot; form factor?&lt;/p&gt;\n\n&lt;p&gt;Unless of course, I&amp;#39;m missing something obvious, would not be the first time.&lt;/p&gt;\n\n&lt;p&gt;Please share your input, thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "130TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "y4g45a", "is_robot_indexable": true, "report_reasons": null, "author": "nando1969", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/y4g45a/thoughts_about_the_samsung_870_qvo_sata_iii_25/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y4g45a/thoughts_about_the_samsung_870_qvo_sata_iii_25/", "subreddit_subscribers": 647797, "created_utc": 1665813762.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have been googling for a day, but unable to find what should be an easy answer. This is a super noob question I'm sure, but I'm at a loss. I have quite a large amount of data that I need to run a script on, and want the hard drives where I'm storing and saving the data to be mirrored to prevent issues. The amount of data that is actually being manipulated is more then I'm used to, and big enough that I am actually using a surprising amount of storage (satellite images, with smallish pixels, over many years, many times a year, for a large area). \n\nUpgrading my workstation to work with and edit some large datasets. I have 4 internal hard drives: two identical 1TB SSDs a separate 2TB drive for backup, and a Boot drive is at 500GB. Cloud-based backup as well, but that is not important. \n\nI have been trying to get the two identical 1TB SSDs to be mirrors of each other, (Ideally maintaining the files in Disk 3, but I have room to move them off if I need to reformat) but the option is not even showing up in Windows. (see photo). I'm running Windows 10 home. My other windows machine does have the option. I'm at a loss, and tutorial videos are not helpful at this point. \n\n&amp;#x200B;\n\nhttps://preview.redd.it/mz95r24gfwt91.png?width=767&amp;format=png&amp;auto=webp&amp;s=17345abafe6ada11e45c41932fb356edb88d8956", "author_fullname": "t2_5vkgrd9n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mirror drive not showing up as an option", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 54, "top_awarded_type": null, "hide_score": false, "media_metadata": {"mz95r24gfwt91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 42, "x": 108, "u": "https://preview.redd.it/mz95r24gfwt91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=13f42ed4613c5b11f9cf5ff60020a8a13aaa1f03"}, {"y": 84, "x": 216, "u": "https://preview.redd.it/mz95r24gfwt91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=02286cb6365c464b160387f81254c2039238ab89"}, {"y": 124, "x": 320, "u": "https://preview.redd.it/mz95r24gfwt91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=05ca5fe533a777c0858b34921e4412231549ec15"}, {"y": 249, "x": 640, "u": "https://preview.redd.it/mz95r24gfwt91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=12be49c49ef4647241bbeb6054699c6b34c75e06"}], "s": {"y": 299, "x": 767, "u": "https://preview.redd.it/mz95r24gfwt91.png?width=767&amp;format=png&amp;auto=webp&amp;s=17345abafe6ada11e45c41932fb356edb88d8956"}, "id": "mz95r24gfwt91"}}, "name": "t3_y4etjq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/WIkCKSDz7xRNUW4tR3VmlbCgCbnwOAjwXNWPPt6U6zU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665809275.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been googling for a day, but unable to find what should be an easy answer. This is a super noob question I&amp;#39;m sure, but I&amp;#39;m at a loss. I have quite a large amount of data that I need to run a script on, and want the hard drives where I&amp;#39;m storing and saving the data to be mirrored to prevent issues. The amount of data that is actually being manipulated is more then I&amp;#39;m used to, and big enough that I am actually using a surprising amount of storage (satellite images, with smallish pixels, over many years, many times a year, for a large area). &lt;/p&gt;\n\n&lt;p&gt;Upgrading my workstation to work with and edit some large datasets. I have 4 internal hard drives: two identical 1TB SSDs a separate 2TB drive for backup, and a Boot drive is at 500GB. Cloud-based backup as well, but that is not important. &lt;/p&gt;\n\n&lt;p&gt;I have been trying to get the two identical 1TB SSDs to be mirrors of each other, (Ideally maintaining the files in Disk 3, but I have room to move them off if I need to reformat) but the option is not even showing up in Windows. (see photo). I&amp;#39;m running Windows 10 home. My other windows machine does have the option. I&amp;#39;m at a loss, and tutorial videos are not helpful at this point. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/mz95r24gfwt91.png?width=767&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=17345abafe6ada11e45c41932fb356edb88d8956\"&gt;https://preview.redd.it/mz95r24gfwt91.png?width=767&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=17345abafe6ada11e45c41932fb356edb88d8956&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y4etjq", "is_robot_indexable": true, "report_reasons": null, "author": "Geog_Master", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y4etjq/mirror_drive_not_showing_up_as_an_option/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y4etjq/mirror_drive_not_showing_up_as_an_option/", "subreddit_subscribers": 647797, "created_utc": 1665809275.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I know the whole back and forth of the validity of \"Lifetime Services\", but hoping someone knows whether or not the offcloud deal might spring back up or should I move on?", "author_fullname": "t2_r6ovc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is the stacksocial lifetime offcloud gone permanently?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4ab2o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.42, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665795152.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know the whole back and forth of the validity of &amp;quot;Lifetime Services&amp;quot;, but hoping someone knows whether or not the offcloud deal might spring back up or should I move on?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y4ab2o", "is_robot_indexable": true, "report_reasons": null, "author": "charleykinkaid", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y4ab2o/is_the_stacksocial_lifetime_offcloud_gone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y4ab2o/is_the_stacksocial_lifetime_offcloud_gone/", "subreddit_subscribers": 647797, "created_utc": 1665795152.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My father was a big time record collector. He would literally skip meals for most of a week to have cash to buy a new vinyl record, as my mother tells it. He passed about 15 years ago, so his collection has sat dormant for awite awhile. One of his last gifts he got was a USB turntable. My brother doesn't want the records and I don't have the physical space. It seems that growing this collection was kind of his life mission. He would refer to anything non vinyl as \"Inferior music.\"\n\n My goal for now is to get his USB turntable, and rip every single album, so my brother and I can have our own little piece of the music my father sacrificed so much to afford. This will be a nightmare project. I ballpark at least 100 albums, and I'd be thoroughly unsurprised if it was closer to 200, and at a very conservative 30 minutes, that's 50 hours of ripping, at minimum. If I do this, I want to do this ONCE. I replace my hard drives every 4 years, and I know USB drives and SD/Micro SD are famous for short lifespans, so I'm looking for something we could keep for as long as possible. I'm not looking for huge storage capacity. Ripping direct WAV files, this should easily take up less than a TB. I want to be certain we could play these for as long as possible though. My brother isn't into music, and the music he is into he'll just go to YouTube for. I have no doubt he'll take the thing storing the music, throw it in a safe, and it'll never see the light of day again. Another reason that having a long term format is very important. It's going to sit there for a very, very long time.\n\n I'm considering Blu Ray-R discs, but there's probably something better for this task. I also don't have a Blu Ray drive, so that would add minimum $100 to the project. To those who are more informed about storage than me, any advice? What would you do in my shoes? Thanks to anyone who can help me", "author_fullname": "t2_52rh4bqu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What would be the best storage device for an extended period of time?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_y48kir", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 0, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": "", "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665790146.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My father was a big time record collector. He would literally skip meals for most of a week to have cash to buy a new vinyl record, as my mother tells it. He passed about 15 years ago, so his collection has sat dormant for awite awhile. One of his last gifts he got was a USB turntable. My brother doesn&amp;#39;t want the records and I don&amp;#39;t have the physical space. It seems that growing this collection was kind of his life mission. He would refer to anything non vinyl as &amp;quot;Inferior music.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;My goal for now is to get his USB turntable, and rip every single album, so my brother and I can have our own little piece of the music my father sacrificed so much to afford. This will be a nightmare project. I ballpark at least 100 albums, and I&amp;#39;d be thoroughly unsurprised if it was closer to 200, and at a very conservative 30 minutes, that&amp;#39;s 50 hours of ripping, at minimum. If I do this, I want to do this ONCE. I replace my hard drives every 4 years, and I know USB drives and SD/Micro SD are famous for short lifespans, so I&amp;#39;m looking for something we could keep for as long as possible. I&amp;#39;m not looking for huge storage capacity. Ripping direct WAV files, this should easily take up less than a TB. I want to be certain we could play these for as long as possible though. My brother isn&amp;#39;t into music, and the music he is into he&amp;#39;ll just go to YouTube for. I have no doubt he&amp;#39;ll take the thing storing the music, throw it in a safe, and it&amp;#39;ll never see the light of day again. Another reason that having a long term format is very important. It&amp;#39;s going to sit there for a very, very long time.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m considering Blu Ray-R discs, but there&amp;#39;s probably something better for this task. I also don&amp;#39;t have a Blu Ray drive, so that would add minimum $100 to the project. To those who are more informed about storage than me, any advice? What would you do in my shoes? Thanks to anyone who can help me&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "call_to_action": "", "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y48kir", "is_robot_indexable": true, "report_reasons": null, "author": "Breude", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y48kir/what_would_be_the_best_storage_device_for_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y48kir/what_would_be_the_best_storage_device_for_an/", "subreddit_subscribers": 647797, "created_utc": 1665790146.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\n I am not in a position to judge whether I should buy this HDD\n\nit is an:\n\n&amp;#x200B;\n\nhttps://preview.redd.it/0t7b3oefmut91.png?width=283&amp;format=png&amp;auto=webp&amp;s=eefd6bd3e6ea54e228298c84e1aa2c09b5609fce\n\n&amp;#x200B;\n\nhttps://preview.redd.it/qhqbudobmut91.png?width=639&amp;format=png&amp;auto=webp&amp;s=80d5c8b7544191e090463244521a4b5799cc6ddc\n\nWhat do You Think?\n\nPls help to decide\n\nTHX", "author_fullname": "t2_xdwxg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with SMART DATA Pls.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"0t7b3oefmut91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 156, "x": 108, "u": "https://preview.redd.it/0t7b3oefmut91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=de4f1479a3016e36a76346513513d0b8c49da95c"}, {"y": 313, "x": 216, "u": "https://preview.redd.it/0t7b3oefmut91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1e6e18e9d47439001e438371cb7944318e47ed7b"}], "s": {"y": 411, "x": 283, "u": "https://preview.redd.it/0t7b3oefmut91.png?width=283&amp;format=png&amp;auto=webp&amp;s=eefd6bd3e6ea54e228298c84e1aa2c09b5609fce"}, "id": "0t7b3oefmut91"}, "qhqbudobmut91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 96, "x": 108, "u": "https://preview.redd.it/qhqbudobmut91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ec6370475084bc2ecf1d4f763820b2396262215e"}, {"y": 192, "x": 216, "u": "https://preview.redd.it/qhqbudobmut91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0ff4f1790a032fd69cbdb1aab53ecf7d61787242"}, {"y": 285, "x": 320, "u": "https://preview.redd.it/qhqbudobmut91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2687536b35f20274e8fb777cdc5492bf3def8a30"}], "s": {"y": 570, "x": 639, "u": "https://preview.redd.it/qhqbudobmut91.png?width=639&amp;format=png&amp;auto=webp&amp;s=80d5c8b7544191e090463244521a4b5799cc6ddc"}, "id": "qhqbudobmut91"}}, "name": "t3_y47fbk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/7F78P0u8y37RKEXikjDD1bUWPdaW9DGMIzsW1iHqdwc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665787026.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I am not in a position to judge whether I should buy this HDD&lt;/p&gt;\n\n&lt;p&gt;it is an:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/0t7b3oefmut91.png?width=283&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=eefd6bd3e6ea54e228298c84e1aa2c09b5609fce\"&gt;https://preview.redd.it/0t7b3oefmut91.png?width=283&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=eefd6bd3e6ea54e228298c84e1aa2c09b5609fce&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/qhqbudobmut91.png?width=639&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=80d5c8b7544191e090463244521a4b5799cc6ddc\"&gt;https://preview.redd.it/qhqbudobmut91.png?width=639&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=80d5c8b7544191e090463244521a4b5799cc6ddc&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;What do You Think?&lt;/p&gt;\n\n&lt;p&gt;Pls help to decide&lt;/p&gt;\n\n&lt;p&gt;THX&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y47fbk", "is_robot_indexable": true, "report_reasons": null, "author": "Witzker", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y47fbk/help_with_smart_data_pls/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y47fbk/help_with_smart_data_pls/", "subreddit_subscribers": 647797, "created_utc": 1665787026.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "What sorts of data do you guys hoard? Statistics? Prices? Web scraping? \n\nThe reason I ask is because I want to start my own collection lab with a simple raspberry pi and mount it to some hard drives, but I\u2019m not sure where to start or where to get real time data or if I\u2019m looking in the wrong place. \n\nDo you use premade software or make your own for these collections?\nWhat format of storage do you use and in what cases?\nWhat situational data do you include? Time of day? Temperature? Do you simply extrapolate afterwards?\n\nThese are all things that can be done by me, and is likely a personal preference, but I\u2019d love to hear what you guys think would be cool.", "author_fullname": "t2_7nmskexv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data collection ideas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y446kw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665778884.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What sorts of data do you guys hoard? Statistics? Prices? Web scraping? &lt;/p&gt;\n\n&lt;p&gt;The reason I ask is because I want to start my own collection lab with a simple raspberry pi and mount it to some hard drives, but I\u2019m not sure where to start or where to get real time data or if I\u2019m looking in the wrong place. &lt;/p&gt;\n\n&lt;p&gt;Do you use premade software or make your own for these collections?\nWhat format of storage do you use and in what cases?\nWhat situational data do you include? Time of day? Temperature? Do you simply extrapolate afterwards?&lt;/p&gt;\n\n&lt;p&gt;These are all things that can be done by me, and is likely a personal preference, but I\u2019d love to hear what you guys think would be cool.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y446kw", "is_robot_indexable": true, "report_reasons": null, "author": "Zerodlang", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y446kw/data_collection_ideas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y446kw/data_collection_ideas/", "subreddit_subscribers": 647797, "created_utc": 1665778884.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}