{"kind": "Listing", "data": {"after": "t3_y4g45a", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I understand USB 3.2 Gen 2 can do \"up to\" 10 GBit/Sec.  \n\nWhat thought of speeds can be expected from pairing this enclosure with M.2 NVMe assuming its connected to the proper USB port.  \n\nAt first hand it seems a bit of an absurdity but assuming a spare  M.2 NVMe does it make sense?\n\nThank you.", "author_fullname": "t2_11dj0v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the theoretical read/write speeds of such combo ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_y43pp1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "ups": 202, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 202, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/_DpwuCrvwTKyT1KME9zij7lE-wj7brM55plOYsWhCj8.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1665777698.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I understand USB 3.2 Gen 2 can do &amp;quot;up to&amp;quot; 10 GBit/Sec.  &lt;/p&gt;\n\n&lt;p&gt;What thought of speeds can be expected from pairing this enclosure with M.2 NVMe assuming its connected to the proper USB port.  &lt;/p&gt;\n\n&lt;p&gt;At first hand it seems a bit of an absurdity but assuming a spare  M.2 NVMe does it make sense?&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/hx7quoatutt91.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/hx7quoatutt91.jpg?auto=webp&amp;s=f25808c7830c4f217939792f1c42bb2f788aeef3", "width": 1284, "height": 1621}, "resolutions": [{"url": "https://preview.redd.it/hx7quoatutt91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1cb1cad5d497b085e53d65e6946635486ef157c2", "width": 108, "height": 136}, {"url": "https://preview.redd.it/hx7quoatutt91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3b6bee85bcaa74a7f55d837132922fe7c6c7ed0d", "width": 216, "height": 272}, {"url": "https://preview.redd.it/hx7quoatutt91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d2427a94668c202013dc172fe244f3935cc91736", "width": 320, "height": 403}, {"url": "https://preview.redd.it/hx7quoatutt91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=402a7c4856a885d3d3beec2e77ab3501464f71d3", "width": 640, "height": 807}, {"url": "https://preview.redd.it/hx7quoatutt91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e439ecddb579b54a5591a6a992d629e6b8d216dd", "width": 960, "height": 1211}, {"url": "https://preview.redd.it/hx7quoatutt91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5b6d3d1c19f79e625ea73dcc672c76c501a30b02", "width": 1080, "height": 1363}], "variants": {}, "id": "mVqVlVKYtgGqJOiMyrIzJ3Ezokacr3HZ7vJXc6KuJMw"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "130TB", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y43pp1", "is_robot_indexable": true, "report_reasons": null, "author": "nando1969", "discussion_type": null, "num_comments": 65, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/y43pp1/what_are_the_theoretical_readwrite_speeds_of_such/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/hx7quoatutt91.jpg", "subreddit_subscribers": 647759, "created_utc": 1665777698.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_1xprym4r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there anyway i can recover data on this drive(nvme ssd)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 97, "top_awarded_type": null, "hide_score": false, "name": "t3_y4lofj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "ups": 194, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 194, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/GLZn7ANgvhfarZJuNVAi7J74j1t32d9TxpTZO_xLIBk.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1665833757.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/nasd7k5fhyt91.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/nasd7k5fhyt91.png?auto=webp&amp;s=388728c7ce74b6a33c705320080923e0ca0d2689", "width": 368, "height": 255}, "resolutions": [{"url": "https://preview.redd.it/nasd7k5fhyt91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f5150ce2d2831e07af2fd488ae9adca41975ad97", "width": 108, "height": 74}, {"url": "https://preview.redd.it/nasd7k5fhyt91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=818aaa2f5f1710d732e32cc3008cc13cee01261b", "width": 216, "height": 149}, {"url": "https://preview.redd.it/nasd7k5fhyt91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8fc5c11fed6b33127c628726488566aa62203f80", "width": 320, "height": 221}], "variants": {}, "id": "JtmiCd93uHQpTNs88pp819z3QALCF4h-tW--cB_kAkg"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "16TB", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y4lofj", "is_robot_indexable": true, "report_reasons": null, "author": "ProbablyNotHappy", "discussion_type": null, "num_comments": 53, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/y4lofj/is_there_anyway_i_can_recover_data_on_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/nasd7k5fhyt91.png", "subreddit_subscribers": 647759, "created_utc": 1665833757.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I would like to start keeping an archive of mine and others github accounts with full revision history. Are there any tools that can do this historically? I assume I will have to run my own git or svn server, but I am unsure about how to scrape and then import into my private archive.\n\nEdit: Thanks for the answers", "author_fullname": "t2_tihoe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any tools for cloning github repos with revision?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y40qsg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 58, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 58, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1665776267.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665770333.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like to start keeping an archive of mine and others github accounts with full revision history. Are there any tools that can do this historically? I assume I will have to run my own git or svn server, but I am unsure about how to scrape and then import into my private archive.&lt;/p&gt;\n\n&lt;p&gt;Edit: Thanks for the answers&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y40qsg", "is_robot_indexable": true, "report_reasons": null, "author": "just_for_saving61", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y40qsg/any_tools_for_cloning_github_repos_with_revision/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y40qsg/any_tools_for_cloning_github_repos_with_revision/", "subreddit_subscribers": 647759, "created_utc": 1665770333.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Before, I used to be able to right click a stream and copy the source URL, paste it in VLC and stream and record. Seems like the Chaturbate player no longer allows that. Has anyone found a way to hoard their favorite streams from Chaturbate?", "author_fullname": "t2_5i5zgezr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Capturing streams from Chaturbate", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4au9r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665796754.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Before, I used to be able to right click a stream and copy the source URL, paste it in VLC and stream and record. Seems like the Chaturbate player no longer allows that. Has anyone found a way to hoard their favorite streams from Chaturbate?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y4au9r", "is_robot_indexable": true, "report_reasons": null, "author": "FantasticContent", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y4au9r/capturing_streams_from_chaturbate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y4au9r/capturing_streams_from_chaturbate/", "subreddit_subscribers": 647759, "created_utc": 1665796754.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just bought a Jonsbo N1 from Newegg and I want to make an 80TB-100TB NAS to edit raw 6K video right out of it on Davinci Resolve. (2GB to 15GB per clip)  \nI've read that 10GBE is a good idea for future proofing, but I'm not sure how this can benefit me right now since all I have at home is a Verizon Wi-Fi 6 router and my PC has a X570i Mobo with (2.5) Intel Gigabit Ethernet &amp; Wi-Fi 6 (802.11ax) (No more expandability on the Mobo, since the only PCIE port has my Graphics Card)  \nI've also read that ECC RAM may be benefitial for this, not really sure how, since I'm ignorant on the subject of NAS &amp; ECC.\n\nI'm planning to buy 5 x 20TB WD Red Pro drives, since sometimes I find them for $350 a piece and they are CMR drives, which are supposed to be faster and more suitable for my purposes.\n\nRequirements:\n\n* Mini-ITX\n* Speed &amp; Total Storage are a priority over parity\n* Fast Read-Write Speeds  \n\n\nI've already read u/poipoipoi post where he ends up buying an EPYC3101D4I-2T since it already has:  \n\n\n1. 2x 10GB Lan Ports\n2. 4 x ECC Compatible DDR4 DIMM slots (rather than 2 as on standard Mini Itx Mobos)\n3. Included EPYC 3101 4 cores, 4 threads processor with Heatsink\n4. 6 SATA Ports in total 4 x Oculink port + 2 x SATAIII ports (instead of 4 like regular Mini Itx Mobos)\n5. u/poipoipoi also added an Ableconn Dual PCIe NVMe M.2 SSD Adapter Card with 2 x 1TB NVMe for write cache + 1 x 512GB NVMe on the Mobo for Read Cache\n\nHere is the original post: [https://www.reddit.com/r/DataHoarder/comments/thwykb/newbie\\_moving\\_off\\_synology\\_and\\_going\\_to\\_build\\_a/](https://www.reddit.com/r/DataHoarder/comments/thwykb/newbie_moving_off_synology_and_going_to_build_a/)  \n\n\nQuestions:  \n\n\n1. Is 64GB of RAM enough for 80TB-100TB?\n2. Is ECC really necessary?\n3. Is WIP exclusively managed by the cache drives if I proper configure TrueNAS/UnRaid?\n4. Is 10GB LAN really necessary for editing 6K raw video files? (2GB to 15GB per clip)\n5. Are CMR drives better for my purpose than SMR drives?\n6. Is this 4 core/threads EPYC 3101 a good option or will a 6c/12t Ryzen achieve more performance?\n7. If I do a setup similar to u/poipoipoi, should I add an additional 2.5\" SSD for a bootable drive?\n\n* Or can a caching/storage drive be used as a bootable drive?\n\nThanks in advance!", "author_fullname": "t2_aye1wimg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Newbie building Jonsbo N1 Mini NAS for Raw 6K Video Editing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y40rrh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665770398.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just bought a Jonsbo N1 from Newegg and I want to make an 80TB-100TB NAS to edit raw 6K video right out of it on Davinci Resolve. (2GB to 15GB per clip)&lt;br/&gt;\nI&amp;#39;ve read that 10GBE is a good idea for future proofing, but I&amp;#39;m not sure how this can benefit me right now since all I have at home is a Verizon Wi-Fi 6 router and my PC has a X570i Mobo with (2.5) Intel Gigabit Ethernet &amp;amp; Wi-Fi 6 (802.11ax) (No more expandability on the Mobo, since the only PCIE port has my Graphics Card)&lt;br/&gt;\nI&amp;#39;ve also read that ECC RAM may be benefitial for this, not really sure how, since I&amp;#39;m ignorant on the subject of NAS &amp;amp; ECC.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m planning to buy 5 x 20TB WD Red Pro drives, since sometimes I find them for $350 a piece and they are CMR drives, which are supposed to be faster and more suitable for my purposes.&lt;/p&gt;\n\n&lt;p&gt;Requirements:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Mini-ITX&lt;/li&gt;\n&lt;li&gt;Speed &amp;amp; Total Storage are a priority over parity&lt;/li&gt;\n&lt;li&gt;Fast Read-Write Speeds&lt;br/&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;ve already read &lt;a href=\"/u/poipoipoi\"&gt;u/poipoipoi&lt;/a&gt; post where he ends up buying an EPYC3101D4I-2T since it already has:  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;2x 10GB Lan Ports&lt;/li&gt;\n&lt;li&gt;4 x ECC Compatible DDR4 DIMM slots (rather than 2 as on standard Mini Itx Mobos)&lt;/li&gt;\n&lt;li&gt;Included EPYC 3101 4 cores, 4 threads processor with Heatsink&lt;/li&gt;\n&lt;li&gt;6 SATA Ports in total 4 x Oculink port + 2 x SATAIII ports (instead of 4 like regular Mini Itx Mobos)&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"/u/poipoipoi\"&gt;u/poipoipoi&lt;/a&gt; also added an Ableconn Dual PCIe NVMe M.2 SSD Adapter Card with 2 x 1TB NVMe for write cache + 1 x 512GB NVMe on the Mobo for Read Cache&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Here is the original post: &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/thwykb/newbie_moving_off_synology_and_going_to_build_a/\"&gt;https://www.reddit.com/r/DataHoarder/comments/thwykb/newbie_moving_off_synology_and_going_to_build_a/&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;Questions:  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Is 64GB of RAM enough for 80TB-100TB?&lt;/li&gt;\n&lt;li&gt;Is ECC really necessary?&lt;/li&gt;\n&lt;li&gt;Is WIP exclusively managed by the cache drives if I proper configure TrueNAS/UnRaid?&lt;/li&gt;\n&lt;li&gt;Is 10GB LAN really necessary for editing 6K raw video files? (2GB to 15GB per clip)&lt;/li&gt;\n&lt;li&gt;Are CMR drives better for my purpose than SMR drives?&lt;/li&gt;\n&lt;li&gt;Is this 4 core/threads EPYC 3101 a good option or will a 6c/12t Ryzen achieve more performance?&lt;/li&gt;\n&lt;li&gt;If I do a setup similar to &lt;a href=\"/u/poipoipoi\"&gt;u/poipoipoi&lt;/a&gt;, should I add an additional 2.5&amp;quot; SSD for a bootable drive?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Or can a caching/storage drive be used as a bootable drive?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y40rrh", "is_robot_indexable": true, "report_reasons": null, "author": "OrneryReplacement862", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y40rrh/newbie_building_jonsbo_n1_mini_nas_for_raw_6k/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y40rrh/newbie_building_jonsbo_n1_mini_nas_for_raw_6k/", "subreddit_subscribers": 647759, "created_utc": 1665770398.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_8dw6a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "xklb v1.18: subreddit/redditor databases; download from tube and reddit databases; reddit-selftext link extraction", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_y432c0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/mDQsCVU6p9bYbMkCOZ-eKOx9oldy-4ccA9SF5Pg48Yg.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1665776087.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/chapmanjacobd/lb/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bGGX2Uawlc64vMWYFwgisT7WynxSCjNg_7Vh-upnR-4.jpg?auto=webp&amp;s=28f33b18e1e7fa94d8fe139eff68478a2379b4bd", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/bGGX2Uawlc64vMWYFwgisT7WynxSCjNg_7Vh-upnR-4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=77c77971facf342f57c78cadd62351d86df44d0a", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/bGGX2Uawlc64vMWYFwgisT7WynxSCjNg_7Vh-upnR-4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=aca45ec743766647104e3a7c5aee8db2f42a78de", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/bGGX2Uawlc64vMWYFwgisT7WynxSCjNg_7Vh-upnR-4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=864058452ba6a1c25f11f94cdf0e25b0cd54ffd9", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/bGGX2Uawlc64vMWYFwgisT7WynxSCjNg_7Vh-upnR-4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f2c3c494337417f1514a0cdf0934ecd69dc07e5d", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/bGGX2Uawlc64vMWYFwgisT7WynxSCjNg_7Vh-upnR-4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2f612dee2ad45b9b8dbd4bdcebb3a8d751184acd", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/bGGX2Uawlc64vMWYFwgisT7WynxSCjNg_7Vh-upnR-4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=88eb8f37be9214f96b86a1dd3b633d808d2c5482", "width": 1080, "height": 540}], "variants": {}, "id": "ob8sDkK7HJSxJCaBtV_DV1wQBFtQdUGlDD4w2LFSBhM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "60TB", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y432c0", "is_robot_indexable": true, "report_reasons": null, "author": "BuonaparteII", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/y432c0/xklb_v118_subredditredditor_databases_download/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/chapmanjacobd/lb/", "subreddit_subscribers": 647759, "created_utc": 1665776087.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all, I do regular backups of all of my devices, cards, and external drives, which a lot of the times includes tens of gigabytes of video footage (I do freelance videography work). I know I could most likely just delete all this footage after but as data hoarders understand, we would rather have a thorough archive of what we've shot, even if we'll never use the footage again.\n\nI've recently started using Handbrake to compress some of my archived footage which has been great - I have projects that had over 100GB of video footage in them and compressing the video files has literally halved the amount of storage space needed for those files. The only downside is, the compressed files are brand new files and the old still exist. So the only way I can actually benefit from this system is if I delete the old files, which I'm hesitant to do since those original files have all the \"created at\", \"modified at\", and other data associated with the actual original creation.\n\nWhat I'd love to be able to do is use some kind of tool or process to be able to delete these files but automatically replace them with a little data file that contains all that info. That way if I go looking for the files someday in the future and I navigate to the directory I know they should be in, I can see the files that *were* there plus all the original data from them, but it's just like a .txt file or something like that but which has the same name as the original file (different extension though obviously).\n\nIs anyone aware of something that does this or a workflow I could use to do it manually but in bulk? Any thoughts anyone has would be greatly appreciated! Cheers  \n\n\nEDIT: Forgot to mention, I have both MacOS and Windows machines but usually my backup processes take place on Windows so looking for preferably a tool/process for Windows, but can make Mac work as well.", "author_fullname": "t2_10a2c7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a method of deleting files but keeping some sort of placeholder file indicating that they were there + the metadata associated with them", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y44gu2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1665779962.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665779596.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I do regular backups of all of my devices, cards, and external drives, which a lot of the times includes tens of gigabytes of video footage (I do freelance videography work). I know I could most likely just delete all this footage after but as data hoarders understand, we would rather have a thorough archive of what we&amp;#39;ve shot, even if we&amp;#39;ll never use the footage again.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve recently started using Handbrake to compress some of my archived footage which has been great - I have projects that had over 100GB of video footage in them and compressing the video files has literally halved the amount of storage space needed for those files. The only downside is, the compressed files are brand new files and the old still exist. So the only way I can actually benefit from this system is if I delete the old files, which I&amp;#39;m hesitant to do since those original files have all the &amp;quot;created at&amp;quot;, &amp;quot;modified at&amp;quot;, and other data associated with the actual original creation.&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;d love to be able to do is use some kind of tool or process to be able to delete these files but automatically replace them with a little data file that contains all that info. That way if I go looking for the files someday in the future and I navigate to the directory I know they should be in, I can see the files that &lt;em&gt;were&lt;/em&gt; there plus all the original data from them, but it&amp;#39;s just like a .txt file or something like that but which has the same name as the original file (different extension though obviously).&lt;/p&gt;\n\n&lt;p&gt;Is anyone aware of something that does this or a workflow I could use to do it manually but in bulk? Any thoughts anyone has would be greatly appreciated! Cheers  &lt;/p&gt;\n\n&lt;p&gt;EDIT: Forgot to mention, I have both MacOS and Windows machines but usually my backup processes take place on Windows so looking for preferably a tool/process for Windows, but can make Mac work as well.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y44gu2", "is_robot_indexable": true, "report_reasons": null, "author": "DoctorVanNostrandMD", "discussion_type": null, "num_comments": 13, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y44gu2/looking_for_a_method_of_deleting_files_but/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y44gu2/looking_for_a_method_of_deleting_files_but/", "subreddit_subscribers": 647759, "created_utc": 1665779596.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "&amp;#x200B;\n\n[Keep in mind i've dropped this harddrive a few times \\(once or twice\\)](https://preview.redd.it/4tin8knirxt91.png?width=804&amp;format=png&amp;auto=webp&amp;s=5b0903544609f389b0c9ec617ef2625d26b84ebe)", "author_fullname": "t2_91tg7rqo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Drive failing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 5, "top_awarded_type": null, "hide_score": false, "media_metadata": {"4tin8knirxt91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 4, "x": 108, "u": "https://preview.redd.it/4tin8knirxt91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7d9c17106d46b13e7ec262e75ef7aa4fa2ed297d"}, {"y": 8, "x": 216, "u": "https://preview.redd.it/4tin8knirxt91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=457d46981c9a5e62d897afe73c54d2ac67db4cf4"}, {"y": 12, "x": 320, "u": "https://preview.redd.it/4tin8knirxt91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=82a7670b5f6cfc2731ac7baf5c071e295339b65d"}, {"y": 24, "x": 640, "u": "https://preview.redd.it/4tin8knirxt91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=aec5deb9ac3a71951660147ffaa80f8a0e037c6d"}], "s": {"y": 31, "x": 804, "u": "https://preview.redd.it/4tin8knirxt91.png?width=804&amp;format=png&amp;auto=webp&amp;s=5b0903544609f389b0c9ec617ef2625d26b84ebe"}, "id": "4tin8knirxt91"}}, "name": "t3_y4j5a8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/Kh-oUCleNUegGcs1Mbr8WsWTBBLB0cF10MK0-yzc6lc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665825080.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/4tin8knirxt91.png?width=804&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5b0903544609f389b0c9ec617ef2625d26b84ebe\"&gt;Keep in mind i&amp;#39;ve dropped this harddrive a few times (once or twice)&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y4j5a8", "is_robot_indexable": true, "report_reasons": null, "author": "ComputerLovveerrBoy", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y4j5a8/drive_failing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y4j5a8/drive_failing/", "subreddit_subscribers": 647759, "created_utc": 1665825080.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Putting together a 8-12 bay NAS soon. Haven't decided between Unraid and QNAP. I don't care about noise or power consumption, just performance and longevity.", "author_fullname": "t2_23kjb158", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WD Red Pro or Gold?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4i3bq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665821146.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Putting together a 8-12 bay NAS soon. Haven&amp;#39;t decided between Unraid and QNAP. I don&amp;#39;t care about noise or power consumption, just performance and longevity.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y4i3bq", "is_robot_indexable": true, "report_reasons": null, "author": "werdmouf", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y4i3bq/wd_red_pro_or_gold/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y4i3bq/wd_red_pro_or_gold/", "subreddit_subscribers": 647759, "created_utc": 1665821146.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "hey guys, there\u2019s a website with about 300 recipes I\u2019d like to add to my hoard. I\u2019ve just been using the print recipe feature to make pdfs and it works fine, but I was wondering if anyone knows a better way than just doing this about 290 more times? \n\nI\u2019m not interested in archiving the whole website, just the recipes themselves. I\u2019m willing to go through them all individually but I would rather not if there\u2019s an easier way lol. \n\nThanks!", "author_fullname": "t2_1uhlwc4j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Downloading Recipes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4eza9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665809835.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey guys, there\u2019s a website with about 300 recipes I\u2019d like to add to my hoard. I\u2019ve just been using the print recipe feature to make pdfs and it works fine, but I was wondering if anyone knows a better way than just doing this about 290 more times? &lt;/p&gt;\n\n&lt;p&gt;I\u2019m not interested in archiving the whole website, just the recipes themselves. I\u2019m willing to go through them all individually but I would rather not if there\u2019s an easier way lol. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y4eza9", "is_robot_indexable": true, "report_reasons": null, "author": "UndyingArtist", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y4eza9/downloading_recipes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y4eza9/downloading_recipes/", "subreddit_subscribers": 647759, "created_utc": 1665809835.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_2i4oc8js", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Turned off the computer while disk was open. Now it can'be detected at all. It is not dead, this has happened before, I just can't remember the fix.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_y4ndu2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.45, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 4800, "fallback_url": "https://v.redd.it/7favyz7lwyt91/DASH_1080.mp4?source=fallback", "height": 1080, "width": 607, "scrubber_media_url": "https://v.redd.it/7favyz7lwyt91/DASH_96.mp4", "dash_url": "https://v.redd.it/7favyz7lwyt91/DASHPlaylist.mpd?a=1668448323%2COWViMTk0NzkxZTU2ZWVlNjM4NGQ0YWQwMGJiOTBjMTE0YWVhYTU3MzYwODI0MWU2ZTNhYTY2M2FkYjQ4ZTFlMQ%3D%3D&amp;v=1&amp;f=sd", "duration": 12, "hls_url": "https://v.redd.it/7favyz7lwyt91/HLSPlaylist.m3u8?a=1668448323%2CNTk0M2M0YjhkNjM2MDU4YmVjNmU4NjRmOTRmNGI5ODJmNTI3NzA5Zjk1ODYwZWIyMDFlOTEzN2U4YTdkODY0MQ%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/iukMcImQk3T_cT9LeIrkvaw1djAGcsgdwZkiElTPP-E.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1665838832.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/7favyz7lwyt91", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/om8UoYVQaiYt5r9fCpWvgyPziNjXgS-twpu5Cjcjzu0.png?format=pjpg&amp;auto=webp&amp;s=3c57e3603b8e23f607a6570100ebc392148b5661", "width": 1080, "height": 1920}, "resolutions": [{"url": "https://external-preview.redd.it/om8UoYVQaiYt5r9fCpWvgyPziNjXgS-twpu5Cjcjzu0.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=09bd0ce54add0f0b55837610668888e0c2e10e97", "width": 108, "height": 192}, {"url": "https://external-preview.redd.it/om8UoYVQaiYt5r9fCpWvgyPziNjXgS-twpu5Cjcjzu0.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=87b91ddfc6d1f8ffb200f086bcc0e32e0bc669cd", "width": 216, "height": 384}, {"url": "https://external-preview.redd.it/om8UoYVQaiYt5r9fCpWvgyPziNjXgS-twpu5Cjcjzu0.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=c6afac8232c79450b007d2a2d8de3780d95d8246", "width": 320, "height": 568}, {"url": "https://external-preview.redd.it/om8UoYVQaiYt5r9fCpWvgyPziNjXgS-twpu5Cjcjzu0.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=c611e44dc0db57da28441ec0ef5c6f7ed21a6536", "width": 640, "height": 1137}, {"url": "https://external-preview.redd.it/om8UoYVQaiYt5r9fCpWvgyPziNjXgS-twpu5Cjcjzu0.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=2d4532686fde3cd5b45f0d4dbe5ae5523bb4a2ea", "width": 960, "height": 1706}, {"url": "https://external-preview.redd.it/om8UoYVQaiYt5r9fCpWvgyPziNjXgS-twpu5Cjcjzu0.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=04927cc6651837b181959e55f0de7c27547d8968", "width": 1080, "height": 1920}], "variants": {}, "id": "8CpiNZVtF_BEE0y-y2mhmVSrAUii1jEiOIf6XKzEzDo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y4ndu2", "is_robot_indexable": true, "report_reasons": null, "author": "ABPAM", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y4ndu2/turned_off_the_computer_while_disk_was_open_now/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/7favyz7lwyt91", "subreddit_subscribers": 647759, "created_utc": 1665838832.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 4800, "fallback_url": "https://v.redd.it/7favyz7lwyt91/DASH_1080.mp4?source=fallback", "height": 1080, "width": 607, "scrubber_media_url": "https://v.redd.it/7favyz7lwyt91/DASH_96.mp4", "dash_url": "https://v.redd.it/7favyz7lwyt91/DASHPlaylist.mpd?a=1668448323%2COWViMTk0NzkxZTU2ZWVlNjM4NGQ0YWQwMGJiOTBjMTE0YWVhYTU3MzYwODI0MWU2ZTNhYTY2M2FkYjQ4ZTFlMQ%3D%3D&amp;v=1&amp;f=sd", "duration": 12, "hls_url": "https://v.redd.it/7favyz7lwyt91/HLSPlaylist.m3u8?a=1668448323%2CNTk0M2M0YjhkNjM2MDU4YmVjNmU4NjRmOTRmNGI5ODJmNTI3NzA5Zjk1ODYwZWIyMDFlOTEzN2U4YTdkODY0MQ%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "First off if this is the wrong place or wrong question i am sorry ill look elsewhere.\n\nI have 2x3tb 2x8tb of growing data. All drives are external and really spread out , not sure the total actual data vs copies of data (future project) im looking to build a second PC for shucking drives in the future and build up a better setup. My question is what route should i go? Should i purchase 2 10+tb drives and put them into the new system and copy all my data over or just keep adding and growing my current setup. The 2 n 8 drives will go into a 10bay pc and be replaced once bay is full or drives die off. I've not played or tried any raid setup. Ive just been manually cloning the drives once a year.", "author_fullname": "t2_3suaq7sd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "building a NAS for my growing collection.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y44xge", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665780763.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First off if this is the wrong place or wrong question i am sorry ill look elsewhere.&lt;/p&gt;\n\n&lt;p&gt;I have 2x3tb 2x8tb of growing data. All drives are external and really spread out , not sure the total actual data vs copies of data (future project) im looking to build a second PC for shucking drives in the future and build up a better setup. My question is what route should i go? Should i purchase 2 10+tb drives and put them into the new system and copy all my data over or just keep adding and growing my current setup. The 2 n 8 drives will go into a 10bay pc and be replaced once bay is full or drives die off. I&amp;#39;ve not played or tried any raid setup. Ive just been manually cloning the drives once a year.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y44xge", "is_robot_indexable": true, "report_reasons": null, "author": "JBizz86", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y44xge/building_a_nas_for_my_growing_collection/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y44xge/building_a_nas_for_my_growing_collection/", "subreddit_subscribers": 647759, "created_utc": 1665780763.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "how can I predict that some data on hdd are going to get corrupted, is there a software for that ?\n\nhow can I know that any bit  of data has been corrupted, does the computer show a notification, is there a software to detect that ?", "author_fullname": "t2_5p9rx19x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HDD data corruption (loss)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4gkgu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665815437.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;how can I predict that some data on hdd are going to get corrupted, is there a software for that ?&lt;/p&gt;\n\n&lt;p&gt;how can I know that any bit  of data has been corrupted, does the computer show a notification, is there a software to detect that ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y4gkgu", "is_robot_indexable": true, "report_reasons": null, "author": "VladamirLem9781", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y4gkgu/hdd_data_corruption_loss/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y4gkgu/hdd_data_corruption_loss/", "subreddit_subscribers": 647759, "created_utc": 1665815437.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My father was a big time record collector. He would literally skip meals for most of a week to have cash to buy a new vinyl record, as my mother tells it. He passed about 15 years ago, so his collection has sat dormant for awite awhile. One of his last gifts he got was a USB turntable. My brother doesn't want the records and I don't have the physical space. It seems that growing this collection was kind of his life mission. He would refer to anything non vinyl as \"Inferior music.\"\n\n My goal for now is to get his USB turntable, and rip every single album, so my brother and I can have our own little piece of the music my father sacrificed so much to afford. This will be a nightmare project. I ballpark at least 100 albums, and I'd be thoroughly unsurprised if it was closer to 200, and at a very conservative 30 minutes, that's 50 hours of ripping, at minimum. If I do this, I want to do this ONCE. I replace my hard drives every 4 years, and I know USB drives and SD/Micro SD are famous for short lifespans, so I'm looking for something we could keep for as long as possible. I'm not looking for huge storage capacity. Ripping direct WAV files, this should easily take up less than a TB. I want to be certain we could play these for as long as possible though. My brother isn't into music, and the music he is into he'll just go to YouTube for. I have no doubt he'll take the thing storing the music, throw it in a safe, and it'll never see the light of day again. Another reason that having a long term format is very important. It's going to sit there for a very, very long time.\n\n I'm considering Blu Ray-R discs, but there's probably something better for this task. I also don't have a Blu Ray drive, so that would add minimum $100 to the project. To those who are more informed about storage than me, any advice? What would you do in my shoes? Thanks to anyone who can help me", "author_fullname": "t2_52rh4bqu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What would be the best storage device for an extended period of time?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y48kir", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665790146.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My father was a big time record collector. He would literally skip meals for most of a week to have cash to buy a new vinyl record, as my mother tells it. He passed about 15 years ago, so his collection has sat dormant for awite awhile. One of his last gifts he got was a USB turntable. My brother doesn&amp;#39;t want the records and I don&amp;#39;t have the physical space. It seems that growing this collection was kind of his life mission. He would refer to anything non vinyl as &amp;quot;Inferior music.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;My goal for now is to get his USB turntable, and rip every single album, so my brother and I can have our own little piece of the music my father sacrificed so much to afford. This will be a nightmare project. I ballpark at least 100 albums, and I&amp;#39;d be thoroughly unsurprised if it was closer to 200, and at a very conservative 30 minutes, that&amp;#39;s 50 hours of ripping, at minimum. If I do this, I want to do this ONCE. I replace my hard drives every 4 years, and I know USB drives and SD/Micro SD are famous for short lifespans, so I&amp;#39;m looking for something we could keep for as long as possible. I&amp;#39;m not looking for huge storage capacity. Ripping direct WAV files, this should easily take up less than a TB. I want to be certain we could play these for as long as possible though. My brother isn&amp;#39;t into music, and the music he is into he&amp;#39;ll just go to YouTube for. I have no doubt he&amp;#39;ll take the thing storing the music, throw it in a safe, and it&amp;#39;ll never see the light of day again. Another reason that having a long term format is very important. It&amp;#39;s going to sit there for a very, very long time.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m considering Blu Ray-R discs, but there&amp;#39;s probably something better for this task. I also don&amp;#39;t have a Blu Ray drive, so that would add minimum $100 to the project. To those who are more informed about storage than me, any advice? What would you do in my shoes? Thanks to anyone who can help me&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y48kir", "is_robot_indexable": true, "report_reasons": null, "author": "Breude", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y48kir/what_would_be_the_best_storage_device_for_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y48kir/what_would_be_the_best_storage_device_for_an/", "subreddit_subscribers": 647759, "created_utc": 1665790146.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am trying to come up with something similar to those expensive DAS units that I can configure myself.\n\nI found a unit that even used BTRFS, but I would assume their \"gui\" wouldn't include the same level of features as accessing the drives themselves.\n\nSo, I wonder what options are available to build an external DAS unit that works over usb 3.2 and or thunderbolt 3/4?\n\n&amp;#x200B;\n\nAlternatively, an external drive enclosure that supports raid 1+0?\n\nAlso, would you recommend if going the enclosure route that I have an extra external drive to keep important files safe?\n\n&amp;#x200B;\n\nWhat are your experiences with roadwarrior style for managing storage?  \nI'll have a large lithium battery to run this, plugged into the 12v on a vehicle. I don't need much storage on the go, but I'd like to be able to keep VM backups and storage for video/photos local.\n\nI'm also likely to have the option for remote VMs, but this is a road I've yet to cross.", "author_fullname": "t2_gru9m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Roadwarrior configuration?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y47mjv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665787559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to come up with something similar to those expensive DAS units that I can configure myself.&lt;/p&gt;\n\n&lt;p&gt;I found a unit that even used BTRFS, but I would assume their &amp;quot;gui&amp;quot; wouldn&amp;#39;t include the same level of features as accessing the drives themselves.&lt;/p&gt;\n\n&lt;p&gt;So, I wonder what options are available to build an external DAS unit that works over usb 3.2 and or thunderbolt 3/4?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Alternatively, an external drive enclosure that supports raid 1+0?&lt;/p&gt;\n\n&lt;p&gt;Also, would you recommend if going the enclosure route that I have an extra external drive to keep important files safe?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What are your experiences with roadwarrior style for managing storage?&lt;br/&gt;\nI&amp;#39;ll have a large lithium battery to run this, plugged into the 12v on a vehicle. I don&amp;#39;t need much storage on the go, but I&amp;#39;d like to be able to keep VM backups and storage for video/photos local.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m also likely to have the option for remote VMs, but this is a road I&amp;#39;ve yet to cross.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y47mjv", "is_robot_indexable": true, "report_reasons": null, "author": "uberbewb", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y47mjv/roadwarrior_configuration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y47mjv/roadwarrior_configuration/", "subreddit_subscribers": 647759, "created_utc": 1665787559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone, \nI'm in the process of digitizing a large storage of paper documents. I have access to good office printers, so scanning most of the standard documents was a breeze. But I'm having issues with larger format documents. Especially paper rolls (so about 3-4m x 80cm wide), but also larger DIN A0 documents (e.g. Blueprints, plans, family trees, posters, etc.). \nI checked local services, but they can only handle DIN formats, but not the rolls. \nDo you guys have any ideas on how I could digitize them in somewhat good quality? I was thinking of taking lots of photos and stitching them with photomerge in Photoshop, but that failed quite badly. \nAre there maybe some scanner apps specialized for this, or are there any other techniques than I'm missing? \nThanks for any help in advance!", "author_fullname": "t2_uxafe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Digitizing large format paper documents for storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y46ool", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665785158.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, \nI&amp;#39;m in the process of digitizing a large storage of paper documents. I have access to good office printers, so scanning most of the standard documents was a breeze. But I&amp;#39;m having issues with larger format documents. Especially paper rolls (so about 3-4m x 80cm wide), but also larger DIN A0 documents (e.g. Blueprints, plans, family trees, posters, etc.). \nI checked local services, but they can only handle DIN formats, but not the rolls. \nDo you guys have any ideas on how I could digitize them in somewhat good quality? I was thinking of taking lots of photos and stitching them with photomerge in Photoshop, but that failed quite badly. \nAre there maybe some scanner apps specialized for this, or are there any other techniques than I&amp;#39;m missing? \nThanks for any help in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y46ool", "is_robot_indexable": true, "report_reasons": null, "author": "corny96", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y46ool/digitizing_large_format_paper_documents_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y46ool/digitizing_large_format_paper_documents_for/", "subreddit_subscribers": 647759, "created_utc": 1665785158.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "As the title indicates, I'm looking for S3 compatible storage provider that I can use with rclone on Linux to dump (long term backup) files. These will be primarily Borg backup files from my NAS storage. Any suggestions for a reasonably priced provider for home use segment?", "author_fullname": "t2_s7edcv9d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommendations for S3 compatible cold storage provider with ultra low price tag?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y44rep", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665780337.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title indicates, I&amp;#39;m looking for S3 compatible storage provider that I can use with rclone on Linux to dump (long term backup) files. These will be primarily Borg backup files from my NAS storage. Any suggestions for a reasonably priced provider for home use segment?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y44rep", "is_robot_indexable": true, "report_reasons": null, "author": "useless-oracle", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y44rep/recommendations_for_s3_compatible_cold_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y44rep/recommendations_for_s3_compatible_cold_storage/", "subreddit_subscribers": 647759, "created_utc": 1665780337.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Easiest way to archive an entire website subdirectory", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y43zou", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_shla9q08", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "WaybackMachine", "selftext": "Before anyone tells me to Google it, I did and it was unsurprisingly futile \ud83d\ude05. The algorithm isn't exactly designed to provide helpful results anymore, so naturally I've come to Reddit for answers.\n\nEarlier this week, I was laid off from a nascent digital media publication after finding out our site was being shuttered. We were to our parent company what The Wirecutter became to the New York Times a few years ago: a subdirectory hosted on a more prominent domain offering purchasing advice based on product testing insights.\n\nAs everyone on my team is about to lose all record of the hard work we put in over the last six months, I'm desperate to find a straightforward method of archiving every page in the subdirectory without manually pasting every URL into Wayback Machine. I'm skeptical the company is going to provide a backup given how long it's taking to reach a decision on whether or not they even want to. It's seemingly in limbo, and I'm not sure how much time we have before the site goes dark.\n\n[HTTrack](https://www.httrack.com/) seems to be a popular option, but I don't have a Windows or Linux machine, as I exclusively work on a Mac, and it doesn't appear to be compatible with MacOS. I also found [WaybackArchiver](https://github.com/buren/wayback_archiver) on GitHub, but I'm out of my depth just trying to follow the installation instructions. I like to think i'm tech literate, but I only have a vague understanding of sitemaps, let alone how to use a crawler or what a Gemfile even is. \n\nPlease, if anyone has a solution to automate a full subdirectory archival a layman could quickly pick up and execute, I'll owe you a beer or a blunt \u2014 whatever floats your boat.", "author_fullname": "t2_shla9q08", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Easiest way to archive an entire website subdirectory", "link_flair_richtext": [], "subreddit_name_prefixed": "r/WaybackMachine", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y43z5s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1665778353.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.WaybackMachine", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Before anyone tells me to Google it, I did and it was unsurprisingly futile \ud83d\ude05. The algorithm isn&amp;#39;t exactly designed to provide helpful results anymore, so naturally I&amp;#39;ve come to Reddit for answers.&lt;/p&gt;\n\n&lt;p&gt;Earlier this week, I was laid off from a nascent digital media publication after finding out our site was being shuttered. We were to our parent company what The Wirecutter became to the New York Times a few years ago: a subdirectory hosted on a more prominent domain offering purchasing advice based on product testing insights.&lt;/p&gt;\n\n&lt;p&gt;As everyone on my team is about to lose all record of the hard work we put in over the last six months, I&amp;#39;m desperate to find a straightforward method of archiving every page in the subdirectory without manually pasting every URL into Wayback Machine. I&amp;#39;m skeptical the company is going to provide a backup given how long it&amp;#39;s taking to reach a decision on whether or not they even want to. It&amp;#39;s seemingly in limbo, and I&amp;#39;m not sure how much time we have before the site goes dark.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.httrack.com/\"&gt;HTTrack&lt;/a&gt; seems to be a popular option, but I don&amp;#39;t have a Windows or Linux machine, as I exclusively work on a Mac, and it doesn&amp;#39;t appear to be compatible with MacOS. I also found &lt;a href=\"https://github.com/buren/wayback_archiver\"&gt;WaybackArchiver&lt;/a&gt; on GitHub, but I&amp;#39;m out of my depth just trying to follow the installation instructions. I like to think i&amp;#39;m tech literate, but I only have a vague understanding of sitemaps, let alone how to use a crawler or what a Gemfile even is. &lt;/p&gt;\n\n&lt;p&gt;Please, if anyone has a solution to automate a full subdirectory archival a layman could quickly pick up and execute, I&amp;#39;ll owe you a beer or a blunt \u2014 whatever floats your boat.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/tgdafAt2hOfyEFP2YVpJAL51ZycsTiEt8VxN2HoM1eg.jpg?auto=webp&amp;s=d7f0508bee931f5ec01c81898799c76e53a49c3a", "width": 300, "height": 233}, "resolutions": [{"url": "https://external-preview.redd.it/tgdafAt2hOfyEFP2YVpJAL51ZycsTiEt8VxN2HoM1eg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1ddefedb0f954f724be9d99fc4940672fa80d82c", "width": 108, "height": 83}, {"url": "https://external-preview.redd.it/tgdafAt2hOfyEFP2YVpJAL51ZycsTiEt8VxN2HoM1eg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=881ad6280f8960bc672a6e1d3566590968c5eca8", "width": 216, "height": 167}], "variants": {}, "id": "IqlRJ_uGr1gJ9Z81mzoF33bSshgJZY-BlRfO9FbM4NA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qptp", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y43z5s", "is_robot_indexable": true, "report_reasons": null, "author": "FrackingEnthusiast", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/WaybackMachine/comments/y43z5s/easiest_way_to_archive_an_entire_website/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/WaybackMachine/comments/y43z5s/easiest_way_to_archive_an_entire_website/", "subreddit_subscribers": 1463, "created_utc": 1665778353.0, "num_crossposts": 3, "media": null, "is_video": false}], "created": 1665778393.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.WaybackMachine", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/WaybackMachine/comments/y43z5s/easiest_way_to_archive_an_entire_website/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/tgdafAt2hOfyEFP2YVpJAL51ZycsTiEt8VxN2HoM1eg.jpg?auto=webp&amp;s=d7f0508bee931f5ec01c81898799c76e53a49c3a", "width": 300, "height": 233}, "resolutions": [{"url": "https://external-preview.redd.it/tgdafAt2hOfyEFP2YVpJAL51ZycsTiEt8VxN2HoM1eg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1ddefedb0f954f724be9d99fc4940672fa80d82c", "width": 108, "height": 83}, {"url": "https://external-preview.redd.it/tgdafAt2hOfyEFP2YVpJAL51ZycsTiEt8VxN2HoM1eg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=881ad6280f8960bc672a6e1d3566590968c5eca8", "width": 216, "height": 167}], "variants": {}, "id": "IqlRJ_uGr1gJ9Z81mzoF33bSshgJZY-BlRfO9FbM4NA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y43zou", "is_robot_indexable": true, "report_reasons": null, "author": "FrackingEnthusiast", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_y43z5s", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y43zou/easiest_way_to_archive_an_entire_website/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/WaybackMachine/comments/y43z5s/easiest_way_to_archive_an_entire_website/", "subreddit_subscribers": 647759, "created_utc": 1665778393.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've got a Dell r710 and I'm looking to outfit it with 6 drives. Gonna use unRAID for my media server. I've heard of people using an SSD in one bay to store the os on so if that's a thing and it'll make the system more reliable I'll gladly do that. Anyways I can't find any non shady looking sellers on Newegg but I'm looking to get 6 SAS 3.5 HDDs. I'd like to get as much storage as possible for less than $150 per drive. Any recommendations ? If I have to choose between reliability vs storage size I'll choose reliability every time. I appreciate any recommendations you can give.", "author_fullname": "t2_1ytjqpie", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with drive recommendations ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4k1w6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665828320.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got a Dell r710 and I&amp;#39;m looking to outfit it with 6 drives. Gonna use unRAID for my media server. I&amp;#39;ve heard of people using an SSD in one bay to store the os on so if that&amp;#39;s a thing and it&amp;#39;ll make the system more reliable I&amp;#39;ll gladly do that. Anyways I can&amp;#39;t find any non shady looking sellers on Newegg but I&amp;#39;m looking to get 6 SAS 3.5 HDDs. I&amp;#39;d like to get as much storage as possible for less than $150 per drive. Any recommendations ? If I have to choose between reliability vs storage size I&amp;#39;ll choose reliability every time. I appreciate any recommendations you can give.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y4k1w6", "is_robot_indexable": true, "report_reasons": null, "author": "SirLance-a-lot", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y4k1w6/help_with_drive_recommendations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y4k1w6/help_with_drive_recommendations/", "subreddit_subscribers": 647759, "created_utc": 1665828320.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "After many months of research, I went with a TB3 4xSATA enclosure and went to work...\n\nInternal chip is reported as:\n\n`ASMedia Technology Inc. ASM1062 Serial ATA Controller (rev 01)`\n\nI installed a pair of old 2tb drives and started badblocks destructive mode to stress the TB3 link and chip. It ran for about 2 days with no errors on the ATA or TB connection.\n\nThen I ran some tests with SMART and hd-idle. SMART pass through worked fine with the exception of an old samsung HD204 2TB disk (known to have some SMART quirks). Continued these tests on the drives I installed later (listed below).\n\nDisks will spin down from hd-idle and hdparm, and they will spin up again when the mounted filesystem is accessed. No filesystem errors.\n\nNext I mounted 2x6TB and 2x5TB drives and began a transfer test. Initiated LUKS encryption then balanced a total of 8TB across all 4 drives with no link resets, full data scrub with no problems. HDD temps stayed around 28C-35C under hours of I/O. Copying data from an individual drive can sustain 200MB/s. I did not saturate the bus with read/s writes to all drives simultaneously. When balancing the data there is a cumulative \\~500MB/s (about 119-130MB/s per drive) for hours.\n\nSet it all up with a mergerfs pool and have been running it as a data server with a few docker containers which periodically write data to the array, and a few containers periodically reading from the array.\n\nSo far I can say everything is working to my liking. Haven't tested hot swap because I don't practice hot swap and I don't know if the device  supports hot swap.\n\nThe most important things are having the drives sleep after inactivity and spin up when accessed, without any ATA, filesystem, or TB link resets/problems.\n\nFor anyone else curious about TB3 external arrays related to data/system stability and behavior, I hope this info helps.\n\nIt's an Akitio TB3, I was pleasantly surprised with the first phone call I made to sales.\n\n[https://www.akitio.com/desktop-storage/akitio-thunder3-quad](https://www.akitio.com/desktop-storage/akitio-thunder3-quad)", "author_fullname": "t2_3z08rn1y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My experience with TB3 external enclosure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4aigq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1665795766.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After many months of research, I went with a TB3 4xSATA enclosure and went to work...&lt;/p&gt;\n\n&lt;p&gt;Internal chip is reported as:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;ASMedia Technology Inc. ASM1062 Serial ATA Controller (rev 01)&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;I installed a pair of old 2tb drives and started badblocks destructive mode to stress the TB3 link and chip. It ran for about 2 days with no errors on the ATA or TB connection.&lt;/p&gt;\n\n&lt;p&gt;Then I ran some tests with SMART and hd-idle. SMART pass through worked fine with the exception of an old samsung HD204 2TB disk (known to have some SMART quirks). Continued these tests on the drives I installed later (listed below).&lt;/p&gt;\n\n&lt;p&gt;Disks will spin down from hd-idle and hdparm, and they will spin up again when the mounted filesystem is accessed. No filesystem errors.&lt;/p&gt;\n\n&lt;p&gt;Next I mounted 2x6TB and 2x5TB drives and began a transfer test. Initiated LUKS encryption then balanced a total of 8TB across all 4 drives with no link resets, full data scrub with no problems. HDD temps stayed around 28C-35C under hours of I/O. Copying data from an individual drive can sustain 200MB/s. I did not saturate the bus with read/s writes to all drives simultaneously. When balancing the data there is a cumulative ~500MB/s (about 119-130MB/s per drive) for hours.&lt;/p&gt;\n\n&lt;p&gt;Set it all up with a mergerfs pool and have been running it as a data server with a few docker containers which periodically write data to the array, and a few containers periodically reading from the array.&lt;/p&gt;\n\n&lt;p&gt;So far I can say everything is working to my liking. Haven&amp;#39;t tested hot swap because I don&amp;#39;t practice hot swap and I don&amp;#39;t know if the device  supports hot swap.&lt;/p&gt;\n\n&lt;p&gt;The most important things are having the drives sleep after inactivity and spin up when accessed, without any ATA, filesystem, or TB link resets/problems.&lt;/p&gt;\n\n&lt;p&gt;For anyone else curious about TB3 external arrays related to data/system stability and behavior, I hope this info helps.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s an Akitio TB3, I was pleasantly surprised with the first phone call I made to sales.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.akitio.com/desktop-storage/akitio-thunder3-quad\"&gt;https://www.akitio.com/desktop-storage/akitio-thunder3-quad&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/u4veYcBxmWIN_V8phD0kVzJJQkPqzrvWoJjcejBLLwU.jpg?auto=webp&amp;s=b8c0d3cb0be36011ef8dec921343055edc24c57c", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/u4veYcBxmWIN_V8phD0kVzJJQkPqzrvWoJjcejBLLwU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2f7494472179b825878d4e8cc665a23f4c84309c", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/u4veYcBxmWIN_V8phD0kVzJJQkPqzrvWoJjcejBLLwU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f1376f527dd1d9bde3e12225d3eda4aa788db395", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/u4veYcBxmWIN_V8phD0kVzJJQkPqzrvWoJjcejBLLwU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0dc787946070a4dabfac40d006b8696c91934b56", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/u4veYcBxmWIN_V8phD0kVzJJQkPqzrvWoJjcejBLLwU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=cd62da6d5f1c2c77ea9c981d4775cb56083cc0e3", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/u4veYcBxmWIN_V8phD0kVzJJQkPqzrvWoJjcejBLLwU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=edea7a2c8fd921f1515a7568e51de713fa6648a4", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/u4veYcBxmWIN_V8phD0kVzJJQkPqzrvWoJjcejBLLwU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=295755aed02525eb66e13b3d82632d13f00cf399", "width": 1080, "height": 540}], "variants": {}, "id": "e8ePT1T3p9b5cl5g0yjwYmc-UOVmqjDEAoXAFIo_FlM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y4aigq", "is_robot_indexable": true, "report_reasons": null, "author": "kram3210", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y4aigq/my_experience_with_tb3_external_enclosure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y4aigq/my_experience_with_tb3_external_enclosure/", "subreddit_subscribers": 647759, "created_utc": 1665795766.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I know the whole back and forth of the validity of \"Lifetime Services\", but hoping someone knows whether or not the offcloud deal might spring back up or should I move on?", "author_fullname": "t2_r6ovc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is the stacksocial lifetime offcloud gone permanently?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4ab2o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665795152.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know the whole back and forth of the validity of &amp;quot;Lifetime Services&amp;quot;, but hoping someone knows whether or not the offcloud deal might spring back up or should I move on?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y4ab2o", "is_robot_indexable": true, "report_reasons": null, "author": "charleykinkaid", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y4ab2o/is_the_stacksocial_lifetime_offcloud_gone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y4ab2o/is_the_stacksocial_lifetime_offcloud_gone/", "subreddit_subscribers": 647759, "created_utc": 1665795152.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\n I am not in a position to judge whether I should buy this HDD\n\nit is an:\n\n&amp;#x200B;\n\nhttps://preview.redd.it/0t7b3oefmut91.png?width=283&amp;format=png&amp;auto=webp&amp;s=eefd6bd3e6ea54e228298c84e1aa2c09b5609fce\n\n&amp;#x200B;\n\nhttps://preview.redd.it/qhqbudobmut91.png?width=639&amp;format=png&amp;auto=webp&amp;s=80d5c8b7544191e090463244521a4b5799cc6ddc\n\nWhat do You Think?\n\nPls help to decide\n\nTHX", "author_fullname": "t2_xdwxg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with SMART DATA Pls.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"0t7b3oefmut91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 156, "x": 108, "u": "https://preview.redd.it/0t7b3oefmut91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=de4f1479a3016e36a76346513513d0b8c49da95c"}, {"y": 313, "x": 216, "u": "https://preview.redd.it/0t7b3oefmut91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1e6e18e9d47439001e438371cb7944318e47ed7b"}], "s": {"y": 411, "x": 283, "u": "https://preview.redd.it/0t7b3oefmut91.png?width=283&amp;format=png&amp;auto=webp&amp;s=eefd6bd3e6ea54e228298c84e1aa2c09b5609fce"}, "id": "0t7b3oefmut91"}, "qhqbudobmut91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 96, "x": 108, "u": "https://preview.redd.it/qhqbudobmut91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ec6370475084bc2ecf1d4f763820b2396262215e"}, {"y": 192, "x": 216, "u": "https://preview.redd.it/qhqbudobmut91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0ff4f1790a032fd69cbdb1aab53ecf7d61787242"}, {"y": 285, "x": 320, "u": "https://preview.redd.it/qhqbudobmut91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2687536b35f20274e8fb777cdc5492bf3def8a30"}], "s": {"y": 570, "x": 639, "u": "https://preview.redd.it/qhqbudobmut91.png?width=639&amp;format=png&amp;auto=webp&amp;s=80d5c8b7544191e090463244521a4b5799cc6ddc"}, "id": "qhqbudobmut91"}}, "name": "t3_y47fbk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/7F78P0u8y37RKEXikjDD1bUWPdaW9DGMIzsW1iHqdwc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665787026.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I am not in a position to judge whether I should buy this HDD&lt;/p&gt;\n\n&lt;p&gt;it is an:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/0t7b3oefmut91.png?width=283&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=eefd6bd3e6ea54e228298c84e1aa2c09b5609fce\"&gt;https://preview.redd.it/0t7b3oefmut91.png?width=283&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=eefd6bd3e6ea54e228298c84e1aa2c09b5609fce&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/qhqbudobmut91.png?width=639&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=80d5c8b7544191e090463244521a4b5799cc6ddc\"&gt;https://preview.redd.it/qhqbudobmut91.png?width=639&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=80d5c8b7544191e090463244521a4b5799cc6ddc&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;What do You Think?&lt;/p&gt;\n\n&lt;p&gt;Pls help to decide&lt;/p&gt;\n\n&lt;p&gt;THX&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y47fbk", "is_robot_indexable": true, "report_reasons": null, "author": "Witzker", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y47fbk/help_with_smart_data_pls/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y47fbk/help_with_smart_data_pls/", "subreddit_subscribers": 647759, "created_utc": 1665787026.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "What sorts of data do you guys hoard? Statistics? Prices? Web scraping? \n\nThe reason I ask is because I want to start my own collection lab with a simple raspberry pi and mount it to some hard drives, but I\u2019m not sure where to start or where to get real time data or if I\u2019m looking in the wrong place. \n\nDo you use premade software or make your own for these collections?\nWhat format of storage do you use and in what cases?\nWhat situational data do you include? Time of day? Temperature? Do you simply extrapolate afterwards?\n\nThese are all things that can be done by me, and is likely a personal preference, but I\u2019d love to hear what you guys think would be cool.", "author_fullname": "t2_7nmskexv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data collection ideas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y446kw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665778884.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What sorts of data do you guys hoard? Statistics? Prices? Web scraping? &lt;/p&gt;\n\n&lt;p&gt;The reason I ask is because I want to start my own collection lab with a simple raspberry pi and mount it to some hard drives, but I\u2019m not sure where to start or where to get real time data or if I\u2019m looking in the wrong place. &lt;/p&gt;\n\n&lt;p&gt;Do you use premade software or make your own for these collections?\nWhat format of storage do you use and in what cases?\nWhat situational data do you include? Time of day? Temperature? Do you simply extrapolate afterwards?&lt;/p&gt;\n\n&lt;p&gt;These are all things that can be done by me, and is likely a personal preference, but I\u2019d love to hear what you guys think would be cool.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y446kw", "is_robot_indexable": true, "report_reasons": null, "author": "Zerodlang", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y446kw/data_collection_ideas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y446kw/data_collection_ideas/", "subreddit_subscribers": 647759, "created_utc": 1665778884.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I want a mini case like the fractal 804 and 8 drive bays at least. I know I will need drive cages and stuff, but idk about the other components. Apparently there's something called a jbod? I didn't know where to start, even though I searched it up", "author_fullname": "t2_4nmwdtj6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "help creating a beginners das", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4n3nj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665838063.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I want a mini case like the fractal 804 and 8 drive bays at least. I know I will need drive cages and stuff, but idk about the other components. Apparently there&amp;#39;s something called a jbod? I didn&amp;#39;t know where to start, even though I searched it up&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y4n3nj", "is_robot_indexable": true, "report_reasons": null, "author": "writingsimple", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y4n3nj/help_creating_a_beginners_das/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y4n3nj/help_creating_a_beginners_das/", "subreddit_subscribers": 647759, "created_utc": 1665838063.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Cheapest I've seen them lately are about 70-75 dollars a TB.\n\nWhen you take into consideration, their read/write speeds cap at roughly 530MB/sec  and the prices and performance of M.2 NVMe or the cheap TB Price of HDD ($13-15/TB) they have to be of the worse values out there for storage.\n\nIs it because they can fit laptops due to their 2.5\" form factor?\n\nUnless of course, I'm missing something obvious, would not be the first time.\n\nPlease share your input, thank you.", "author_fullname": "t2_11dj0v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts about the SAMSUNG 870 QVO SATA III 2.5\" SSD 8TB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4g45a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1665825170.0, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665813762.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Cheapest I&amp;#39;ve seen them lately are about 70-75 dollars a TB.&lt;/p&gt;\n\n&lt;p&gt;When you take into consideration, their read/write speeds cap at roughly 530MB/sec  and the prices and performance of M.2 NVMe or the cheap TB Price of HDD ($13-15/TB) they have to be of the worse values out there for storage.&lt;/p&gt;\n\n&lt;p&gt;Is it because they can fit laptops due to their 2.5&amp;quot; form factor?&lt;/p&gt;\n\n&lt;p&gt;Unless of course, I&amp;#39;m missing something obvious, would not be the first time.&lt;/p&gt;\n\n&lt;p&gt;Please share your input, thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "130TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "y4g45a", "is_robot_indexable": true, "report_reasons": null, "author": "nando1969", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/y4g45a/thoughts_about_the_samsung_870_qvo_sata_iii_25/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y4g45a/thoughts_about_the_samsung_870_qvo_sata_iii_25/", "subreddit_subscribers": 647759, "created_utc": 1665813762.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}