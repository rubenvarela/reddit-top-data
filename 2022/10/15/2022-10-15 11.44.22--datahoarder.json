{"kind": "Listing", "data": {"after": "t3_y44rep", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I understand USB 3.2 Gen 2 can do \"up to\" 10 GBit/Sec.  \n\nWhat thought of speeds can be expected from pairing this enclosure with M.2 NVMe assuming its connected to the proper USB port.  \n\nAt first hand it seems a bit of an absurdity but assuming a spare  M.2 NVMe does it make sense?\n\nThank you.", "author_fullname": "t2_11dj0v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the theoretical read/write speeds of such combo ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_y43pp1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "ups": 178, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 178, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/_DpwuCrvwTKyT1KME9zij7lE-wj7brM55plOYsWhCj8.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1665777698.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I understand USB 3.2 Gen 2 can do &amp;quot;up to&amp;quot; 10 GBit/Sec.  &lt;/p&gt;\n\n&lt;p&gt;What thought of speeds can be expected from pairing this enclosure with M.2 NVMe assuming its connected to the proper USB port.  &lt;/p&gt;\n\n&lt;p&gt;At first hand it seems a bit of an absurdity but assuming a spare  M.2 NVMe does it make sense?&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/hx7quoatutt91.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/hx7quoatutt91.jpg?auto=webp&amp;s=f25808c7830c4f217939792f1c42bb2f788aeef3", "width": 1284, "height": 1621}, "resolutions": [{"url": "https://preview.redd.it/hx7quoatutt91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1cb1cad5d497b085e53d65e6946635486ef157c2", "width": 108, "height": 136}, {"url": "https://preview.redd.it/hx7quoatutt91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3b6bee85bcaa74a7f55d837132922fe7c6c7ed0d", "width": 216, "height": 272}, {"url": "https://preview.redd.it/hx7quoatutt91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d2427a94668c202013dc172fe244f3935cc91736", "width": 320, "height": 403}, {"url": "https://preview.redd.it/hx7quoatutt91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=402a7c4856a885d3d3beec2e77ab3501464f71d3", "width": 640, "height": 807}, {"url": "https://preview.redd.it/hx7quoatutt91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e439ecddb579b54a5591a6a992d629e6b8d216dd", "width": 960, "height": 1211}, {"url": "https://preview.redd.it/hx7quoatutt91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5b6d3d1c19f79e625ea73dcc672c76c501a30b02", "width": 1080, "height": 1363}], "variants": {}, "id": "mVqVlVKYtgGqJOiMyrIzJ3Ezokacr3HZ7vJXc6KuJMw"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "130TB", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y43pp1", "is_robot_indexable": true, "report_reasons": null, "author": "nando1969", "discussion_type": null, "num_comments": 57, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/y43pp1/what_are_the_theoretical_readwrite_speeds_of_such/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/hx7quoatutt91.jpg", "subreddit_subscribers": 647575, "created_utc": 1665777698.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I would like to start keeping an archive of mine and others github accounts with full revision history. Are there any tools that can do this historically? I assume I will have to run my own git or svn server, but I am unsure about how to scrape and then import into my private archive.\n\nEdit: Thanks for the answers", "author_fullname": "t2_tihoe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any tools for cloning github repos with revision?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y40qsg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 59, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 59, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1665776267.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665770333.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like to start keeping an archive of mine and others github accounts with full revision history. Are there any tools that can do this historically? I assume I will have to run my own git or svn server, but I am unsure about how to scrape and then import into my private archive.&lt;/p&gt;\n\n&lt;p&gt;Edit: Thanks for the answers&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y40qsg", "is_robot_indexable": true, "report_reasons": null, "author": "just_for_saving61", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y40qsg/any_tools_for_cloning_github_repos_with_revision/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y40qsg/any_tools_for_cloning_github_repos_with_revision/", "subreddit_subscribers": 647575, "created_utc": 1665770333.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Before, I used to be able to right click a stream and copy the source URL, paste it in VLC and stream and record. Seems like the Chaturbate player no longer allows that. Has anyone found a way to hoard their favorite streams from Chaturbate?", "author_fullname": "t2_5i5zgezr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Capturing streams from Chaturbate", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4au9r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665796754.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Before, I used to be able to right click a stream and copy the source URL, paste it in VLC and stream and record. Seems like the Chaturbate player no longer allows that. Has anyone found a way to hoard their favorite streams from Chaturbate?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y4au9r", "is_robot_indexable": true, "report_reasons": null, "author": "FantasticContent", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y4au9r/capturing_streams_from_chaturbate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y4au9r/capturing_streams_from_chaturbate/", "subreddit_subscribers": 647575, "created_utc": 1665796754.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just bought a Jonsbo N1 from Newegg and I want to make an 80TB-100TB NAS to edit raw 6K video right out of it on Davinci Resolve. (2GB to 15GB per clip)  \nI've read that 10GBE is a good idea for future proofing, but I'm not sure how this can benefit me right now since all I have at home is a Verizon Wi-Fi 6 router and my PC has a X570i Mobo with (2.5) Intel Gigabit Ethernet &amp; Wi-Fi 6 (802.11ax) (No more expandability on the Mobo, since the only PCIE port has my Graphics Card)  \nI've also read that ECC RAM may be benefitial for this, not really sure how, since I'm ignorant on the subject of NAS &amp; ECC.\n\nI'm planning to buy 5 x 20TB WD Red Pro drives, since sometimes I find them for $350 a piece and they are CMR drives, which are supposed to be faster and more suitable for my purposes.\n\nRequirements:\n\n* Mini-ITX\n* Speed &amp; Total Storage are a priority over parity\n* Fast Read-Write Speeds  \n\n\nI've already read u/poipoipoi post where he ends up buying an EPYC3101D4I-2T since it already has:  \n\n\n1. 2x 10GB Lan Ports\n2. 4 x ECC Compatible DDR4 DIMM slots (rather than 2 as on standard Mini Itx Mobos)\n3. Included EPYC 3101 4 cores, 4 threads processor with Heatsink\n4. 6 SATA Ports in total 4 x Oculink port + 2 x SATAIII ports (instead of 4 like regular Mini Itx Mobos)\n5. u/poipoipoi also added an Ableconn Dual PCIe NVMe M.2 SSD Adapter Card with 2 x 1TB NVMe for write cache + 1 x 512GB NVMe on the Mobo for Read Cache\n\nHere is the original post: [https://www.reddit.com/r/DataHoarder/comments/thwykb/newbie\\_moving\\_off\\_synology\\_and\\_going\\_to\\_build\\_a/](https://www.reddit.com/r/DataHoarder/comments/thwykb/newbie_moving_off_synology_and_going_to_build_a/)  \n\n\nQuestions:  \n\n\n1. Is 64GB of RAM enough for 80TB-100TB?\n2. Is ECC really necessary?\n3. Is WIP exclusively managed by the cache drives if I proper configure TrueNAS/UnRaid?\n4. Is 10GB LAN really necessary for editing 6K raw video files? (2GB to 15GB per clip)\n5. Are CMR drives better for my purpose than SMR drives?\n6. Is this 4 core/threads EPYC 3101 a good option or will a 6c/12t Ryzen achieve more performance?\n7. If I do a setup similar to u/poipoipoi, should I add an additional 2.5\" SSD for a bootable drive?\n\n* Or can a caching/storage drive be used as a bootable drive?\n\nThanks in advance!", "author_fullname": "t2_aye1wimg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Newbie building Jonsbo N1 Mini NAS for Raw 6K Video Editing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y40rrh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665770398.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just bought a Jonsbo N1 from Newegg and I want to make an 80TB-100TB NAS to edit raw 6K video right out of it on Davinci Resolve. (2GB to 15GB per clip)&lt;br/&gt;\nI&amp;#39;ve read that 10GBE is a good idea for future proofing, but I&amp;#39;m not sure how this can benefit me right now since all I have at home is a Verizon Wi-Fi 6 router and my PC has a X570i Mobo with (2.5) Intel Gigabit Ethernet &amp;amp; Wi-Fi 6 (802.11ax) (No more expandability on the Mobo, since the only PCIE port has my Graphics Card)&lt;br/&gt;\nI&amp;#39;ve also read that ECC RAM may be benefitial for this, not really sure how, since I&amp;#39;m ignorant on the subject of NAS &amp;amp; ECC.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m planning to buy 5 x 20TB WD Red Pro drives, since sometimes I find them for $350 a piece and they are CMR drives, which are supposed to be faster and more suitable for my purposes.&lt;/p&gt;\n\n&lt;p&gt;Requirements:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Mini-ITX&lt;/li&gt;\n&lt;li&gt;Speed &amp;amp; Total Storage are a priority over parity&lt;/li&gt;\n&lt;li&gt;Fast Read-Write Speeds&lt;br/&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;ve already read &lt;a href=\"/u/poipoipoi\"&gt;u/poipoipoi&lt;/a&gt; post where he ends up buying an EPYC3101D4I-2T since it already has:  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;2x 10GB Lan Ports&lt;/li&gt;\n&lt;li&gt;4 x ECC Compatible DDR4 DIMM slots (rather than 2 as on standard Mini Itx Mobos)&lt;/li&gt;\n&lt;li&gt;Included EPYC 3101 4 cores, 4 threads processor with Heatsink&lt;/li&gt;\n&lt;li&gt;6 SATA Ports in total 4 x Oculink port + 2 x SATAIII ports (instead of 4 like regular Mini Itx Mobos)&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"/u/poipoipoi\"&gt;u/poipoipoi&lt;/a&gt; also added an Ableconn Dual PCIe NVMe M.2 SSD Adapter Card with 2 x 1TB NVMe for write cache + 1 x 512GB NVMe on the Mobo for Read Cache&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Here is the original post: &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/thwykb/newbie_moving_off_synology_and_going_to_build_a/\"&gt;https://www.reddit.com/r/DataHoarder/comments/thwykb/newbie_moving_off_synology_and_going_to_build_a/&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;Questions:  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Is 64GB of RAM enough for 80TB-100TB?&lt;/li&gt;\n&lt;li&gt;Is ECC really necessary?&lt;/li&gt;\n&lt;li&gt;Is WIP exclusively managed by the cache drives if I proper configure TrueNAS/UnRaid?&lt;/li&gt;\n&lt;li&gt;Is 10GB LAN really necessary for editing 6K raw video files? (2GB to 15GB per clip)&lt;/li&gt;\n&lt;li&gt;Are CMR drives better for my purpose than SMR drives?&lt;/li&gt;\n&lt;li&gt;Is this 4 core/threads EPYC 3101 a good option or will a 6c/12t Ryzen achieve more performance?&lt;/li&gt;\n&lt;li&gt;If I do a setup similar to &lt;a href=\"/u/poipoipoi\"&gt;u/poipoipoi&lt;/a&gt;, should I add an additional 2.5&amp;quot; SSD for a bootable drive?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Or can a caching/storage drive be used as a bootable drive?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y40rrh", "is_robot_indexable": true, "report_reasons": null, "author": "OrneryReplacement862", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y40rrh/newbie_building_jonsbo_n1_mini_nas_for_raw_6k/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y40rrh/newbie_building_jonsbo_n1_mini_nas_for_raw_6k/", "subreddit_subscribers": 647575, "created_utc": 1665770398.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_8dw6a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "xklb v1.18: subreddit/redditor databases; download from tube and reddit databases; reddit-selftext link extraction", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_y432c0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/mDQsCVU6p9bYbMkCOZ-eKOx9oldy-4ccA9SF5Pg48Yg.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1665776087.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/chapmanjacobd/lb/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bGGX2Uawlc64vMWYFwgisT7WynxSCjNg_7Vh-upnR-4.jpg?auto=webp&amp;s=28f33b18e1e7fa94d8fe139eff68478a2379b4bd", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/bGGX2Uawlc64vMWYFwgisT7WynxSCjNg_7Vh-upnR-4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=77c77971facf342f57c78cadd62351d86df44d0a", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/bGGX2Uawlc64vMWYFwgisT7WynxSCjNg_7Vh-upnR-4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=aca45ec743766647104e3a7c5aee8db2f42a78de", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/bGGX2Uawlc64vMWYFwgisT7WynxSCjNg_7Vh-upnR-4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=864058452ba6a1c25f11f94cdf0e25b0cd54ffd9", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/bGGX2Uawlc64vMWYFwgisT7WynxSCjNg_7Vh-upnR-4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f2c3c494337417f1514a0cdf0934ecd69dc07e5d", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/bGGX2Uawlc64vMWYFwgisT7WynxSCjNg_7Vh-upnR-4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2f612dee2ad45b9b8dbd4bdcebb3a8d751184acd", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/bGGX2Uawlc64vMWYFwgisT7WynxSCjNg_7Vh-upnR-4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=88eb8f37be9214f96b86a1dd3b633d808d2c5482", "width": 1080, "height": 540}], "variants": {}, "id": "ob8sDkK7HJSxJCaBtV_DV1wQBFtQdUGlDD4w2LFSBhM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "60TB", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y432c0", "is_robot_indexable": true, "report_reasons": null, "author": "BuonaparteII", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/y432c0/xklb_v118_subredditredditor_databases_download/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/chapmanjacobd/lb/", "subreddit_subscribers": 647575, "created_utc": 1665776087.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello datahoarders!\n\nI've been a lurker here for a while, and I really appreciate the informative community here. I recently purchased a Mac mini M1 with 256GB internal space and 16GB of ram, and I'm looking to use it for school, music production and leisure - it will be my main desktop. Therefore, I am in need of some storage. My question to you all is, how much do I realistically need to invest in to future proof myself? I know this is subjective, so I've conjured up some rough estimates of how much storage I'd need for the different purposes, based on previous experiences and future wants to give you a better understanding, I suppose. Here they are:\n\n&amp;#x200B;\n\nI'm thinking of getting an SSD (Samsung T7) with 2TB:\n\n\\~300GB of Music Project Files on Logic Pro X and Ableton Live\n\n\\~1TB of Audio Plugins / Instrument Libraries\n\nThat's \\~700GB to spare for other activities and such\n\n&amp;#x200B;\n\nI'll also get an HDD for things that don't require a high read/write speed (I think?), my original idea was a 10TB WD Elements External Hard drive:\n\n\\~2TB of TV-Shows\n\n\\~1TB of Movies\n\n\\~500GB of Music rips (from online purchases AND ripping my Vinyl-collection at some point)\n\n\\~300GB of Audiobooks\n\n\\~100GB of Comics\n\n\\~50GB of eBooks\n\nThat's \\~6TB to spare, for now\n\n&amp;#x200B;\n\nIs this a smart way to go about it, or is 6TB wayyyyy too much space to spare? Are there better, or cheaper ways of doing this? I hope these questions are answerable, but I'll happily expand upon anything, if needed.\n\nThanks in advance!", "author_fullname": "t2_76inijfi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much storage do I realistically need for music production + leisure (Music, TV, Movies, eBooks etc.)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y3ywwd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665765846.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello datahoarders!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been a lurker here for a while, and I really appreciate the informative community here. I recently purchased a Mac mini M1 with 256GB internal space and 16GB of ram, and I&amp;#39;m looking to use it for school, music production and leisure - it will be my main desktop. Therefore, I am in need of some storage. My question to you all is, how much do I realistically need to invest in to future proof myself? I know this is subjective, so I&amp;#39;ve conjured up some rough estimates of how much storage I&amp;#39;d need for the different purposes, based on previous experiences and future wants to give you a better understanding, I suppose. Here they are:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking of getting an SSD (Samsung T7) with 2TB:&lt;/p&gt;\n\n&lt;p&gt;~300GB of Music Project Files on Logic Pro X and Ableton Live&lt;/p&gt;\n\n&lt;p&gt;~1TB of Audio Plugins / Instrument Libraries&lt;/p&gt;\n\n&lt;p&gt;That&amp;#39;s ~700GB to spare for other activities and such&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ll also get an HDD for things that don&amp;#39;t require a high read/write speed (I think?), my original idea was a 10TB WD Elements External Hard drive:&lt;/p&gt;\n\n&lt;p&gt;~2TB of TV-Shows&lt;/p&gt;\n\n&lt;p&gt;~1TB of Movies&lt;/p&gt;\n\n&lt;p&gt;~500GB of Music rips (from online purchases AND ripping my Vinyl-collection at some point)&lt;/p&gt;\n\n&lt;p&gt;~300GB of Audiobooks&lt;/p&gt;\n\n&lt;p&gt;~100GB of Comics&lt;/p&gt;\n\n&lt;p&gt;~50GB of eBooks&lt;/p&gt;\n\n&lt;p&gt;That&amp;#39;s ~6TB to spare, for now&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Is this a smart way to go about it, or is 6TB wayyyyy too much space to spare? Are there better, or cheaper ways of doing this? I hope these questions are answerable, but I&amp;#39;ll happily expand upon anything, if needed.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y3ywwd", "is_robot_indexable": true, "report_reasons": null, "author": "Floppi23", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y3ywwd/how_much_storage_do_i_realistically_need_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y3ywwd/how_much_storage_do_i_realistically_need_for/", "subreddit_subscribers": 647575, "created_utc": 1665765846.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey Folks,  \n\n\nNeed some help with my product knowledge on overhead scanners. I feel like I've dropped into a bit of an enthusiast black hole which is rare on the internet these days. \n\nKeeping it simple - opinions fine -\n\n\\- why does the Scansnap SV600 still come up in conversations when it's 10 years old? If the product was a success, surely Fujitsu would have released a new version by now? \n\n\\- Is there a current reigning champ for overhead scanners? The SV 600 and CZUR seem to be the main two options, with the rest either a lot less expensive or having some kind of bespoke application that makes the product a little less appealing.\n\nI just need to be able to scan books and ideally product boxes that sometimes have more useful content than the threadbare instructions inside. \n\nThanks to anyone that can help.", "author_fullname": "t2_1jzhoqbr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question re: overhead scanners", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y3ulvn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665755666.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Folks,  &lt;/p&gt;\n\n&lt;p&gt;Need some help with my product knowledge on overhead scanners. I feel like I&amp;#39;ve dropped into a bit of an enthusiast black hole which is rare on the internet these days. &lt;/p&gt;\n\n&lt;p&gt;Keeping it simple - opinions fine -&lt;/p&gt;\n\n&lt;p&gt;- why does the Scansnap SV600 still come up in conversations when it&amp;#39;s 10 years old? If the product was a success, surely Fujitsu would have released a new version by now? &lt;/p&gt;\n\n&lt;p&gt;- Is there a current reigning champ for overhead scanners? The SV 600 and CZUR seem to be the main two options, with the rest either a lot less expensive or having some kind of bespoke application that makes the product a little less appealing.&lt;/p&gt;\n\n&lt;p&gt;I just need to be able to scan books and ideally product boxes that sometimes have more useful content than the threadbare instructions inside. &lt;/p&gt;\n\n&lt;p&gt;Thanks to anyone that can help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y3ulvn", "is_robot_indexable": true, "report_reasons": null, "author": "bjd533", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y3ulvn/question_re_overhead_scanners/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y3ulvn/question_re_overhead_scanners/", "subreddit_subscribers": 647575, "created_utc": 1665755666.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "hey guys, there\u2019s a website with about 300 recipes I\u2019d like to add to my hoard. I\u2019ve just been using the print recipe feature to make pdfs and it works fine, but I was wondering if anyone knows a better way than just doing this about 290 more times? \n\nI\u2019m not interested in archiving the whole website, just the recipes themselves. I\u2019m willing to go through them all individually but I would rather not if there\u2019s an easier way lol. \n\nThanks!", "author_fullname": "t2_1uhlwc4j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Downloading Recipes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4eza9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665809835.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey guys, there\u2019s a website with about 300 recipes I\u2019d like to add to my hoard. I\u2019ve just been using the print recipe feature to make pdfs and it works fine, but I was wondering if anyone knows a better way than just doing this about 290 more times? &lt;/p&gt;\n\n&lt;p&gt;I\u2019m not interested in archiving the whole website, just the recipes themselves. I\u2019m willing to go through them all individually but I would rather not if there\u2019s an easier way lol. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y4eza9", "is_robot_indexable": true, "report_reasons": null, "author": "UndyingArtist", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y4eza9/downloading_recipes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y4eza9/downloading_recipes/", "subreddit_subscribers": 647575, "created_utc": 1665809835.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "how can I predict that some data on hdd are going to get corrupted, is there a software for that ?\n\nhow can I know that any bit  of data has been corrupted, does the computer show a notification, is there a software to detect that ?", "author_fullname": "t2_5p9rx19x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HDD data corruption (loss)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4gkgu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665815437.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;how can I predict that some data on hdd are going to get corrupted, is there a software for that ?&lt;/p&gt;\n\n&lt;p&gt;how can I know that any bit  of data has been corrupted, does the computer show a notification, is there a software to detect that ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y4gkgu", "is_robot_indexable": true, "report_reasons": null, "author": "VladamirLem9781", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y4gkgu/hdd_data_corruption_loss/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y4gkgu/hdd_data_corruption_loss/", "subreddit_subscribers": 647575, "created_utc": 1665815437.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all, I do regular backups of all of my devices, cards, and external drives, which a lot of the times includes tens of gigabytes of video footage (I do freelance videography work). I know I could most likely just delete all this footage after but as data hoarders understand, we would rather have a thorough archive of what we've shot, even if we'll never use the footage again.\n\nI've recently started using Handbrake to compress some of my archived footage which has been great - I have projects that had over 100GB of video footage in them and compressing the video files has literally halved the amount of storage space needed for those files. The only downside is, the compressed files are brand new files and the old still exist. So the only way I can actually benefit from this system is if I delete the old files, which I'm hesitant to do since those original files have all the \"created at\", \"modified at\", and other data associated with the actual original creation.\n\nWhat I'd love to be able to do is use some kind of tool or process to be able to delete these files but automatically replace them with a little data file that contains all that info. That way if I go looking for the files someday in the future and I navigate to the directory I know they should be in, I can see the files that *were* there plus all the original data from them, but it's just like a .txt file or something like that but which has the same name as the original file (different extension though obviously).\n\nIs anyone aware of something that does this or a workflow I could use to do it manually but in bulk? Any thoughts anyone has would be greatly appreciated! Cheers  \n\n\nEDIT: Forgot to mention, I have both MacOS and Windows machines but usually my backup processes take place on Windows so looking for preferably a tool/process for Windows, but can make Mac work as well.", "author_fullname": "t2_10a2c7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a method of deleting files but keeping some sort of placeholder file indicating that they were there + the metadata associated with them", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y44gu2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1665779962.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665779596.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I do regular backups of all of my devices, cards, and external drives, which a lot of the times includes tens of gigabytes of video footage (I do freelance videography work). I know I could most likely just delete all this footage after but as data hoarders understand, we would rather have a thorough archive of what we&amp;#39;ve shot, even if we&amp;#39;ll never use the footage again.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve recently started using Handbrake to compress some of my archived footage which has been great - I have projects that had over 100GB of video footage in them and compressing the video files has literally halved the amount of storage space needed for those files. The only downside is, the compressed files are brand new files and the old still exist. So the only way I can actually benefit from this system is if I delete the old files, which I&amp;#39;m hesitant to do since those original files have all the &amp;quot;created at&amp;quot;, &amp;quot;modified at&amp;quot;, and other data associated with the actual original creation.&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;d love to be able to do is use some kind of tool or process to be able to delete these files but automatically replace them with a little data file that contains all that info. That way if I go looking for the files someday in the future and I navigate to the directory I know they should be in, I can see the files that &lt;em&gt;were&lt;/em&gt; there plus all the original data from them, but it&amp;#39;s just like a .txt file or something like that but which has the same name as the original file (different extension though obviously).&lt;/p&gt;\n\n&lt;p&gt;Is anyone aware of something that does this or a workflow I could use to do it manually but in bulk? Any thoughts anyone has would be greatly appreciated! Cheers  &lt;/p&gt;\n\n&lt;p&gt;EDIT: Forgot to mention, I have both MacOS and Windows machines but usually my backup processes take place on Windows so looking for preferably a tool/process for Windows, but can make Mac work as well.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y44gu2", "is_robot_indexable": true, "report_reasons": null, "author": "DoctorVanNostrandMD", "discussion_type": null, "num_comments": 8, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y44gu2/looking_for_a_method_of_deleting_files_but/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y44gu2/looking_for_a_method_of_deleting_files_but/", "subreddit_subscribers": 647575, "created_utc": 1665779596.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Howdy everyone, I was hoping to get some suggestions/help with an upgrade I would like to make to my current setup. \n\nRight now, its a mess, I have a CM stacker case with 5.25\" to 3.5\" adapters taking up the front, I don't even have room for the power button, it is inside the case. I am using cheap pcie sata adapters for the extra ports necessary. I use stable-bits drive pool to manage the storage. I like drivepool, I do not like the trouble it is anytime I need to make a storage change, or find a specific drive... its a nightmare.\n\nso I have a Ryzen 2700x machine I would like to put in its place, but I don't want to rebuild the storage the same way.\n\nsince I have rackspace nearby, I would like to move the 10 or so drives into a hot-swappable rack mount chassis, DAS seems the way to go, so I have been looking at various DAS shelves on ebay. and it fits my budget but I have some questions.\n\nI figure I would be willing to invest around 500 into this, as with most things, if I can save a couple dollars I am ok with it. what would you invest in?\n\nhow much trouble will I have getting my standard ntfs sata drives to show jbod without destroying the data on them on my windows server? \n\nI have been a sysadmin for years, but I am quite unfamiliar with these DAS shelves.", "author_fullname": "t2_6mzp3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with choosing a DAS option.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y3wqvp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.53, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665760755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Howdy everyone, I was hoping to get some suggestions/help with an upgrade I would like to make to my current setup. &lt;/p&gt;\n\n&lt;p&gt;Right now, its a mess, I have a CM stacker case with 5.25&amp;quot; to 3.5&amp;quot; adapters taking up the front, I don&amp;#39;t even have room for the power button, it is inside the case. I am using cheap pcie sata adapters for the extra ports necessary. I use stable-bits drive pool to manage the storage. I like drivepool, I do not like the trouble it is anytime I need to make a storage change, or find a specific drive... its a nightmare.&lt;/p&gt;\n\n&lt;p&gt;so I have a Ryzen 2700x machine I would like to put in its place, but I don&amp;#39;t want to rebuild the storage the same way.&lt;/p&gt;\n\n&lt;p&gt;since I have rackspace nearby, I would like to move the 10 or so drives into a hot-swappable rack mount chassis, DAS seems the way to go, so I have been looking at various DAS shelves on ebay. and it fits my budget but I have some questions.&lt;/p&gt;\n\n&lt;p&gt;I figure I would be willing to invest around 500 into this, as with most things, if I can save a couple dollars I am ok with it. what would you invest in?&lt;/p&gt;\n\n&lt;p&gt;how much trouble will I have getting my standard ntfs sata drives to show jbod without destroying the data on them on my windows server? &lt;/p&gt;\n\n&lt;p&gt;I have been a sysadmin for years, but I am quite unfamiliar with these DAS shelves.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y3wqvp", "is_robot_indexable": true, "report_reasons": null, "author": "schmag", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y3wqvp/help_with_choosing_a_das_option/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y3wqvp/help_with_choosing_a_das_option/", "subreddit_subscribers": 647575, "created_utc": 1665760755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've got a Dell r710 and I'm looking to outfit it with 6 drives. Gonna use unRAID for my media server. I've heard of people using an SSD in one bay to store the os on so if that's a thing and it'll make the system more reliable I'll gladly do that. Anyways I can't find any non shady looking sellers on Newegg but I'm looking to get 6 SAS 3.5 HDDs. I'd like to get as much storage as possible for less than $150 per drive. Any recommendations ? If I have to choose between reliability vs storage size I'll choose reliability every time. I appreciate any recommendations you can give.", "author_fullname": "t2_1ytjqpie", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with drive recommendations ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_y4k1w6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665828320.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got a Dell r710 and I&amp;#39;m looking to outfit it with 6 drives. Gonna use unRAID for my media server. I&amp;#39;ve heard of people using an SSD in one bay to store the os on so if that&amp;#39;s a thing and it&amp;#39;ll make the system more reliable I&amp;#39;ll gladly do that. Anyways I can&amp;#39;t find any non shady looking sellers on Newegg but I&amp;#39;m looking to get 6 SAS 3.5 HDDs. I&amp;#39;d like to get as much storage as possible for less than $150 per drive. Any recommendations ? If I have to choose between reliability vs storage size I&amp;#39;ll choose reliability every time. I appreciate any recommendations you can give.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y4k1w6", "is_robot_indexable": true, "report_reasons": null, "author": "SirLance-a-lot", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y4k1w6/help_with_drive_recommendations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y4k1w6/help_with_drive_recommendations/", "subreddit_subscribers": 647575, "created_utc": 1665828320.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "&amp;#x200B;\n\n[Keep in mind i've dropped this harddrive a few times \\(once or twice\\)](https://preview.redd.it/4tin8knirxt91.png?width=804&amp;format=png&amp;auto=webp&amp;s=5b0903544609f389b0c9ec617ef2625d26b84ebe)", "author_fullname": "t2_91tg7rqo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Drive failing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 5, "top_awarded_type": null, "hide_score": false, "media_metadata": {"4tin8knirxt91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 4, "x": 108, "u": "https://preview.redd.it/4tin8knirxt91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7d9c17106d46b13e7ec262e75ef7aa4fa2ed297d"}, {"y": 8, "x": 216, "u": "https://preview.redd.it/4tin8knirxt91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=457d46981c9a5e62d897afe73c54d2ac67db4cf4"}, {"y": 12, "x": 320, "u": "https://preview.redd.it/4tin8knirxt91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=82a7670b5f6cfc2731ac7baf5c071e295339b65d"}, {"y": 24, "x": 640, "u": "https://preview.redd.it/4tin8knirxt91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=aec5deb9ac3a71951660147ffaa80f8a0e037c6d"}], "s": {"y": 31, "x": 804, "u": "https://preview.redd.it/4tin8knirxt91.png?width=804&amp;format=png&amp;auto=webp&amp;s=5b0903544609f389b0c9ec617ef2625d26b84ebe"}, "id": "4tin8knirxt91"}}, "name": "t3_y4j5a8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/Kh-oUCleNUegGcs1Mbr8WsWTBBLB0cF10MK0-yzc6lc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665825080.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/4tin8knirxt91.png?width=804&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5b0903544609f389b0c9ec617ef2625d26b84ebe\"&gt;Keep in mind i&amp;#39;ve dropped this harddrive a few times (once or twice)&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y4j5a8", "is_robot_indexable": true, "report_reasons": null, "author": "ComputerLovveerrBoy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y4j5a8/drive_failing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y4j5a8/drive_failing/", "subreddit_subscribers": 647575, "created_utc": 1665825080.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Putting together a 8-12 bay NAS soon. Haven't decided between Unraid and QNAP. I don't care about noise or power consumption, just performance and longevity.", "author_fullname": "t2_23kjb158", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WD Red Pro or Gold?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4i3bq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665821146.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Putting together a 8-12 bay NAS soon. Haven&amp;#39;t decided between Unraid and QNAP. I don&amp;#39;t care about noise or power consumption, just performance and longevity.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y4i3bq", "is_robot_indexable": true, "report_reasons": null, "author": "werdmouf", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y4i3bq/wd_red_pro_or_gold/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y4i3bq/wd_red_pro_or_gold/", "subreddit_subscribers": 647575, "created_utc": 1665821146.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "After many months of research, I went with a TB3 4xSATA enclosure and went to work...\n\nInternal chip is reported as:\n\n`ASMedia Technology Inc. ASM1062 Serial ATA Controller (rev 01)`\n\nI installed a pair of old 2tb drives and started badblocks destructive mode to stress the TB3 link and chip. It ran for about 2 days with no errors on the ATA or TB connection.\n\nThen I ran some tests with SMART and hd-idle. SMART pass through worked fine with the exception of an old samsung HD204 2TB disk (known to have some SMART quirks). Continued these tests on the drives I installed later (listed below).\n\nDisks will spin down from hd-idle and hdparm, and they will spin up again when the mounted filesystem is accessed. No filesystem errors.\n\nNext I mounted 2x6TB and 2x5TB drives and began a transfer test. Initiated LUKS encryption then balanced a total of 8TB across all 4 drives with no link resets, full data scrub with no problems. HDD temps stayed around 28C-35C under hours of I/O. Copying data from an individual drive can sustain 200MB/s. I did not saturate the bus with read/s writes to all drives simultaneously. When balancing the data there is a cumulative \\~500MB/s (about 119-130MB/s per drive) for hours.\n\nSet it all up with a mergerfs pool and have been running it as a data server with a few docker containers which periodically write data to the array, and a few containers periodically reading from the array.\n\nSo far I can say everything is working to my liking. Haven't tested hot swap because I don't practice hot swap and I don't know if the device  supports hot swap.\n\nThe most important things are having the drives sleep after inactivity and spin up when accessed, without any ATA, filesystem, or TB link resets/problems.\n\nFor anyone else curious about TB3 external arrays related to data/system stability and behavior, I hope this info helps.\n\nIt's an Akitio TB3, I was pleasantly surprised with the first phone call I made to sales.\n\n[https://www.akitio.com/desktop-storage/akitio-thunder3-quad](https://www.akitio.com/desktop-storage/akitio-thunder3-quad)", "author_fullname": "t2_3z08rn1y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My experience with TB3 external enclosure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4aigq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1665795766.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After many months of research, I went with a TB3 4xSATA enclosure and went to work...&lt;/p&gt;\n\n&lt;p&gt;Internal chip is reported as:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;ASMedia Technology Inc. ASM1062 Serial ATA Controller (rev 01)&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;I installed a pair of old 2tb drives and started badblocks destructive mode to stress the TB3 link and chip. It ran for about 2 days with no errors on the ATA or TB connection.&lt;/p&gt;\n\n&lt;p&gt;Then I ran some tests with SMART and hd-idle. SMART pass through worked fine with the exception of an old samsung HD204 2TB disk (known to have some SMART quirks). Continued these tests on the drives I installed later (listed below).&lt;/p&gt;\n\n&lt;p&gt;Disks will spin down from hd-idle and hdparm, and they will spin up again when the mounted filesystem is accessed. No filesystem errors.&lt;/p&gt;\n\n&lt;p&gt;Next I mounted 2x6TB and 2x5TB drives and began a transfer test. Initiated LUKS encryption then balanced a total of 8TB across all 4 drives with no link resets, full data scrub with no problems. HDD temps stayed around 28C-35C under hours of I/O. Copying data from an individual drive can sustain 200MB/s. I did not saturate the bus with read/s writes to all drives simultaneously. When balancing the data there is a cumulative ~500MB/s (about 119-130MB/s per drive) for hours.&lt;/p&gt;\n\n&lt;p&gt;Set it all up with a mergerfs pool and have been running it as a data server with a few docker containers which periodically write data to the array, and a few containers periodically reading from the array.&lt;/p&gt;\n\n&lt;p&gt;So far I can say everything is working to my liking. Haven&amp;#39;t tested hot swap because I don&amp;#39;t practice hot swap and I don&amp;#39;t know if the device  supports hot swap.&lt;/p&gt;\n\n&lt;p&gt;The most important things are having the drives sleep after inactivity and spin up when accessed, without any ATA, filesystem, or TB link resets/problems.&lt;/p&gt;\n\n&lt;p&gt;For anyone else curious about TB3 external arrays related to data/system stability and behavior, I hope this info helps.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s an Akitio TB3, I was pleasantly surprised with the first phone call I made to sales.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.akitio.com/desktop-storage/akitio-thunder3-quad\"&gt;https://www.akitio.com/desktop-storage/akitio-thunder3-quad&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/u4veYcBxmWIN_V8phD0kVzJJQkPqzrvWoJjcejBLLwU.jpg?auto=webp&amp;s=b8c0d3cb0be36011ef8dec921343055edc24c57c", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/u4veYcBxmWIN_V8phD0kVzJJQkPqzrvWoJjcejBLLwU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2f7494472179b825878d4e8cc665a23f4c84309c", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/u4veYcBxmWIN_V8phD0kVzJJQkPqzrvWoJjcejBLLwU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f1376f527dd1d9bde3e12225d3eda4aa788db395", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/u4veYcBxmWIN_V8phD0kVzJJQkPqzrvWoJjcejBLLwU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0dc787946070a4dabfac40d006b8696c91934b56", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/u4veYcBxmWIN_V8phD0kVzJJQkPqzrvWoJjcejBLLwU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=cd62da6d5f1c2c77ea9c981d4775cb56083cc0e3", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/u4veYcBxmWIN_V8phD0kVzJJQkPqzrvWoJjcejBLLwU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=edea7a2c8fd921f1515a7568e51de713fa6648a4", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/u4veYcBxmWIN_V8phD0kVzJJQkPqzrvWoJjcejBLLwU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=295755aed02525eb66e13b3d82632d13f00cf399", "width": 1080, "height": 540}], "variants": {}, "id": "e8ePT1T3p9b5cl5g0yjwYmc-UOVmqjDEAoXAFIo_FlM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y4aigq", "is_robot_indexable": true, "report_reasons": null, "author": "kram3210", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y4aigq/my_experience_with_tb3_external_enclosure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y4aigq/my_experience_with_tb3_external_enclosure/", "subreddit_subscribers": 647575, "created_utc": 1665795766.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "First off if this is the wrong place or wrong question i am sorry ill look elsewhere.\n\nI have 2x3tb 2x8tb of growing data. All drives are external and really spread out , not sure the total actual data vs copies of data (future project) im looking to build a second PC for shucking drives in the future and build up a better setup. My question is what route should i go? Should i purchase 2 10+tb drives and put them into the new system and copy all my data over or just keep adding and growing my current setup. The 2 n 8 drives will go into a 10bay pc and be replaced once bay is full or drives die off. I've not played or tried any raid setup. Ive just been manually cloning the drives once a year.", "author_fullname": "t2_3suaq7sd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "building a NAS for my growing collection.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y44xge", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665780763.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First off if this is the wrong place or wrong question i am sorry ill look elsewhere.&lt;/p&gt;\n\n&lt;p&gt;I have 2x3tb 2x8tb of growing data. All drives are external and really spread out , not sure the total actual data vs copies of data (future project) im looking to build a second PC for shucking drives in the future and build up a better setup. My question is what route should i go? Should i purchase 2 10+tb drives and put them into the new system and copy all my data over or just keep adding and growing my current setup. The 2 n 8 drives will go into a 10bay pc and be replaced once bay is full or drives die off. I&amp;#39;ve not played or tried any raid setup. Ive just been manually cloning the drives once a year.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y44xge", "is_robot_indexable": true, "report_reasons": null, "author": "JBizz86", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y44xge/building_a_nas_for_my_growing_collection/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y44xge/building_a_nas_for_my_growing_collection/", "subreddit_subscribers": 647575, "created_utc": 1665780763.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "For those who don't know : [https://www.hetzner.com/storage/storage-box](https://www.hetzner.com/storage/storage-box)  \n\n\n  \nI searched on Google for a software that could help me do that (something similar to dropbox/backblaze backup), but didn't find anything.  \n\n\nThanks in advance!", "author_fullname": "t2_j2jycayf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking to find a way to automatically backup a certain folder/drive to a Hetzner Storage box.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y3tql8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665753455.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For those who don&amp;#39;t know : &lt;a href=\"https://www.hetzner.com/storage/storage-box\"&gt;https://www.hetzner.com/storage/storage-box&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;I searched on Google for a software that could help me do that (something similar to dropbox/backblaze backup), but didn&amp;#39;t find anything.  &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y3tql8", "is_robot_indexable": true, "report_reasons": null, "author": "ketaminejunkie1337", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y3tql8/looking_to_find_a_way_to_automatically_backup_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y3tql8/looking_to_find_a_way_to_automatically_backup_a/", "subreddit_subscribers": 647575, "created_utc": 1665753455.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Cheapest I've seen them lately are about 70-75 dollars a TB.\n\nWhen you take into consideration, their read/write speeds cap at roughly 530MB/sec  and the prices and performance of M.2 NVMe or the cheap TB Price of HDD ($13-15/TB) they have to be of the worse values out there for storage.\n\nIs it because they can fit laptops due to their 2.5\" form factor?\n\nUnless of course, I'm missing something obvious, would not be the first time.\n\nPlease share your input, thank you.", "author_fullname": "t2_11dj0v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts about the SAMSUNG 870 QVO SATA III 2.5\" SSD 8TB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4g45a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1665825170.0, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665813762.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Cheapest I&amp;#39;ve seen them lately are about 70-75 dollars a TB.&lt;/p&gt;\n\n&lt;p&gt;When you take into consideration, their read/write speeds cap at roughly 530MB/sec  and the prices and performance of M.2 NVMe or the cheap TB Price of HDD ($13-15/TB) they have to be of the worse values out there for storage.&lt;/p&gt;\n\n&lt;p&gt;Is it because they can fit laptops due to their 2.5&amp;quot; form factor?&lt;/p&gt;\n\n&lt;p&gt;Unless of course, I&amp;#39;m missing something obvious, would not be the first time.&lt;/p&gt;\n\n&lt;p&gt;Please share your input, thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "130TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "y4g45a", "is_robot_indexable": true, "report_reasons": null, "author": "nando1969", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/y4g45a/thoughts_about_the_samsung_870_qvo_sata_iii_25/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y4g45a/thoughts_about_the_samsung_870_qvo_sata_iii_25/", "subreddit_subscribers": 647575, "created_utc": 1665813762.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have been googling for a day, but unable to find what should be an easy answer. This is a super noob question I'm sure, but I'm at a loss. I have quite a large amount of data that I need to run a script on, and want the hard drives where I'm storing and saving the data to be mirrored to prevent issues. The amount of data that is actually being manipulated is more then I'm used to, and big enough that I am actually using a surprising amount of storage (satellite images, with smallish pixels, over many years, many times a year, for a large area). \n\nUpgrading my workstation to work with and edit some large datasets. I have 4 internal hard drives: two identical 1TB SSDs a separate 2TB drive for backup, and a Boot drive is at 500GB. Cloud-based backup as well, but that is not important. \n\nI have been trying to get the two identical 1TB SSDs to be mirrors of each other, (Ideally maintaining the files in Disk 3, but I have room to move them off if I need to reformat) but the option is not even showing up in Windows. (see photo). I'm running Windows 10 home. My other windows machine does have the option. I'm at a loss, and tutorial videos are not helpful at this point. \n\n&amp;#x200B;\n\nhttps://preview.redd.it/mz95r24gfwt91.png?width=767&amp;format=png&amp;auto=webp&amp;s=17345abafe6ada11e45c41932fb356edb88d8956", "author_fullname": "t2_5vkgrd9n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mirror drive not showing up as an option", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 54, "top_awarded_type": null, "hide_score": false, "media_metadata": {"mz95r24gfwt91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 42, "x": 108, "u": "https://preview.redd.it/mz95r24gfwt91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=13f42ed4613c5b11f9cf5ff60020a8a13aaa1f03"}, {"y": 84, "x": 216, "u": "https://preview.redd.it/mz95r24gfwt91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=02286cb6365c464b160387f81254c2039238ab89"}, {"y": 124, "x": 320, "u": "https://preview.redd.it/mz95r24gfwt91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=05ca5fe533a777c0858b34921e4412231549ec15"}, {"y": 249, "x": 640, "u": "https://preview.redd.it/mz95r24gfwt91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=12be49c49ef4647241bbeb6054699c6b34c75e06"}], "s": {"y": 299, "x": 767, "u": "https://preview.redd.it/mz95r24gfwt91.png?width=767&amp;format=png&amp;auto=webp&amp;s=17345abafe6ada11e45c41932fb356edb88d8956"}, "id": "mz95r24gfwt91"}}, "name": "t3_y4etjq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/WIkCKSDz7xRNUW4tR3VmlbCgCbnwOAjwXNWPPt6U6zU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665809275.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been googling for a day, but unable to find what should be an easy answer. This is a super noob question I&amp;#39;m sure, but I&amp;#39;m at a loss. I have quite a large amount of data that I need to run a script on, and want the hard drives where I&amp;#39;m storing and saving the data to be mirrored to prevent issues. The amount of data that is actually being manipulated is more then I&amp;#39;m used to, and big enough that I am actually using a surprising amount of storage (satellite images, with smallish pixels, over many years, many times a year, for a large area). &lt;/p&gt;\n\n&lt;p&gt;Upgrading my workstation to work with and edit some large datasets. I have 4 internal hard drives: two identical 1TB SSDs a separate 2TB drive for backup, and a Boot drive is at 500GB. Cloud-based backup as well, but that is not important. &lt;/p&gt;\n\n&lt;p&gt;I have been trying to get the two identical 1TB SSDs to be mirrors of each other, (Ideally maintaining the files in Disk 3, but I have room to move them off if I need to reformat) but the option is not even showing up in Windows. (see photo). I&amp;#39;m running Windows 10 home. My other windows machine does have the option. I&amp;#39;m at a loss, and tutorial videos are not helpful at this point. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/mz95r24gfwt91.png?width=767&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=17345abafe6ada11e45c41932fb356edb88d8956\"&gt;https://preview.redd.it/mz95r24gfwt91.png?width=767&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=17345abafe6ada11e45c41932fb356edb88d8956&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y4etjq", "is_robot_indexable": true, "report_reasons": null, "author": "Geog_Master", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y4etjq/mirror_drive_not_showing_up_as_an_option/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y4etjq/mirror_drive_not_showing_up_as_an_option/", "subreddit_subscribers": 647575, "created_utc": 1665809275.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I know the whole back and forth of the validity of \"Lifetime Services\", but hoping someone knows whether or not the offcloud deal might spring back up or should I move on?", "author_fullname": "t2_r6ovc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is the stacksocial lifetime offcloud gone permanently?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y4ab2o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665795152.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know the whole back and forth of the validity of &amp;quot;Lifetime Services&amp;quot;, but hoping someone knows whether or not the offcloud deal might spring back up or should I move on?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y4ab2o", "is_robot_indexable": true, "report_reasons": null, "author": "charleykinkaid", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y4ab2o/is_the_stacksocial_lifetime_offcloud_gone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y4ab2o/is_the_stacksocial_lifetime_offcloud_gone/", "subreddit_subscribers": 647575, "created_utc": 1665795152.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My father was a big time record collector. He would literally skip meals for most of a week to have cash to buy a new vinyl record, as my mother tells it. He passed about 15 years ago, so his collection has sat dormant for awite awhile. One of his last gifts he got was a USB turntable. My brother doesn't want the records and I don't have the physical space. It seems that growing this collection was kind of his life mission. He would refer to anything non vinyl as \"Inferior music.\"\n\n My goal for now is to get his USB turntable, and rip every single album, so my brother and I can have our own little piece of the music my father sacrificed so much to afford. This will be a nightmare project. I ballpark at least 100 albums, and I'd be thoroughly unsurprised if it was closer to 200, and at a very conservative 30 minutes, that's 50 hours of ripping, at minimum. If I do this, I want to do this ONCE. I replace my hard drives every 4 years, and I know USB drives and SD/Micro SD are famous for short lifespans, so I'm looking for something we could keep for as long as possible. I'm not looking for huge storage capacity. Ripping direct WAV files, this should easily take up less than a TB. I want to be certain we could play these for as long as possible though. My brother isn't into music, and the music he is into he'll just go to YouTube for. I have no doubt he'll take the thing storing the music, throw it in a safe, and it'll never see the light of day again. Another reason that having a long term format is very important. It's going to sit there for a very, very long time.\n\n I'm considering Blu Ray-R discs, but there's probably something better for this task. I also don't have a Blu Ray drive, so that would add minimum $100 to the project. To those who are more informed about storage than me, any advice? What would you do in my shoes? Thanks to anyone who can help me", "author_fullname": "t2_52rh4bqu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What would be the best storage device for an extended period of time?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_y48kir", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 0, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": "", "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665790146.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My father was a big time record collector. He would literally skip meals for most of a week to have cash to buy a new vinyl record, as my mother tells it. He passed about 15 years ago, so his collection has sat dormant for awite awhile. One of his last gifts he got was a USB turntable. My brother doesn&amp;#39;t want the records and I don&amp;#39;t have the physical space. It seems that growing this collection was kind of his life mission. He would refer to anything non vinyl as &amp;quot;Inferior music.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;My goal for now is to get his USB turntable, and rip every single album, so my brother and I can have our own little piece of the music my father sacrificed so much to afford. This will be a nightmare project. I ballpark at least 100 albums, and I&amp;#39;d be thoroughly unsurprised if it was closer to 200, and at a very conservative 30 minutes, that&amp;#39;s 50 hours of ripping, at minimum. If I do this, I want to do this ONCE. I replace my hard drives every 4 years, and I know USB drives and SD/Micro SD are famous for short lifespans, so I&amp;#39;m looking for something we could keep for as long as possible. I&amp;#39;m not looking for huge storage capacity. Ripping direct WAV files, this should easily take up less than a TB. I want to be certain we could play these for as long as possible though. My brother isn&amp;#39;t into music, and the music he is into he&amp;#39;ll just go to YouTube for. I have no doubt he&amp;#39;ll take the thing storing the music, throw it in a safe, and it&amp;#39;ll never see the light of day again. Another reason that having a long term format is very important. It&amp;#39;s going to sit there for a very, very long time.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m considering Blu Ray-R discs, but there&amp;#39;s probably something better for this task. I also don&amp;#39;t have a Blu Ray drive, so that would add minimum $100 to the project. To those who are more informed about storage than me, any advice? What would you do in my shoes? Thanks to anyone who can help me&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "call_to_action": "", "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y48kir", "is_robot_indexable": true, "report_reasons": null, "author": "Breude", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y48kir/what_would_be_the_best_storage_device_for_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y48kir/what_would_be_the_best_storage_device_for_an/", "subreddit_subscribers": 647575, "created_utc": 1665790146.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am trying to come up with something similar to those expensive DAS units that I can configure myself.\n\nI found a unit that even used BTRFS, but I would assume their \"gui\" wouldn't include the same level of features as accessing the drives themselves.\n\nSo, I wonder what options are available to build an external DAS unit that works over usb 3.2 and or thunderbolt 3/4?\n\n&amp;#x200B;\n\nAlternatively, an external drive enclosure that supports raid 1+0?\n\nAlso, would you recommend if going the enclosure route that I have an extra external drive to keep important files safe?\n\n&amp;#x200B;\n\nWhat are your experiences with roadwarrior style for managing storage?  \nI'll have a large lithium battery to run this, plugged into the 12v on a vehicle. I don't need much storage on the go, but I'd like to be able to keep VM backups and storage for video/photos local.\n\nI'm also likely to have the option for remote VMs, but this is a road I've yet to cross.", "author_fullname": "t2_gru9m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Roadwarrior configuration?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y47mjv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665787559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to come up with something similar to those expensive DAS units that I can configure myself.&lt;/p&gt;\n\n&lt;p&gt;I found a unit that even used BTRFS, but I would assume their &amp;quot;gui&amp;quot; wouldn&amp;#39;t include the same level of features as accessing the drives themselves.&lt;/p&gt;\n\n&lt;p&gt;So, I wonder what options are available to build an external DAS unit that works over usb 3.2 and or thunderbolt 3/4?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Alternatively, an external drive enclosure that supports raid 1+0?&lt;/p&gt;\n\n&lt;p&gt;Also, would you recommend if going the enclosure route that I have an extra external drive to keep important files safe?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What are your experiences with roadwarrior style for managing storage?&lt;br/&gt;\nI&amp;#39;ll have a large lithium battery to run this, plugged into the 12v on a vehicle. I don&amp;#39;t need much storage on the go, but I&amp;#39;d like to be able to keep VM backups and storage for video/photos local.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m also likely to have the option for remote VMs, but this is a road I&amp;#39;ve yet to cross.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y47mjv", "is_robot_indexable": true, "report_reasons": null, "author": "uberbewb", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y47mjv/roadwarrior_configuration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y47mjv/roadwarrior_configuration/", "subreddit_subscribers": 647575, "created_utc": 1665787559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\n I am not in a position to judge whether I should buy this HDD\n\nit is an:\n\n&amp;#x200B;\n\nhttps://preview.redd.it/0t7b3oefmut91.png?width=283&amp;format=png&amp;auto=webp&amp;s=eefd6bd3e6ea54e228298c84e1aa2c09b5609fce\n\n&amp;#x200B;\n\nhttps://preview.redd.it/qhqbudobmut91.png?width=639&amp;format=png&amp;auto=webp&amp;s=80d5c8b7544191e090463244521a4b5799cc6ddc\n\nWhat do You Think?\n\nPls help to decide\n\nTHX", "author_fullname": "t2_xdwxg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with SMART DATA Pls.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"0t7b3oefmut91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 156, "x": 108, "u": "https://preview.redd.it/0t7b3oefmut91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=de4f1479a3016e36a76346513513d0b8c49da95c"}, {"y": 313, "x": 216, "u": "https://preview.redd.it/0t7b3oefmut91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1e6e18e9d47439001e438371cb7944318e47ed7b"}], "s": {"y": 411, "x": 283, "u": "https://preview.redd.it/0t7b3oefmut91.png?width=283&amp;format=png&amp;auto=webp&amp;s=eefd6bd3e6ea54e228298c84e1aa2c09b5609fce"}, "id": "0t7b3oefmut91"}, "qhqbudobmut91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 96, "x": 108, "u": "https://preview.redd.it/qhqbudobmut91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ec6370475084bc2ecf1d4f763820b2396262215e"}, {"y": 192, "x": 216, "u": "https://preview.redd.it/qhqbudobmut91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0ff4f1790a032fd69cbdb1aab53ecf7d61787242"}, {"y": 285, "x": 320, "u": "https://preview.redd.it/qhqbudobmut91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2687536b35f20274e8fb777cdc5492bf3def8a30"}], "s": {"y": 570, "x": 639, "u": "https://preview.redd.it/qhqbudobmut91.png?width=639&amp;format=png&amp;auto=webp&amp;s=80d5c8b7544191e090463244521a4b5799cc6ddc"}, "id": "qhqbudobmut91"}}, "name": "t3_y47fbk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/7F78P0u8y37RKEXikjDD1bUWPdaW9DGMIzsW1iHqdwc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665787026.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I am not in a position to judge whether I should buy this HDD&lt;/p&gt;\n\n&lt;p&gt;it is an:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/0t7b3oefmut91.png?width=283&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=eefd6bd3e6ea54e228298c84e1aa2c09b5609fce\"&gt;https://preview.redd.it/0t7b3oefmut91.png?width=283&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=eefd6bd3e6ea54e228298c84e1aa2c09b5609fce&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/qhqbudobmut91.png?width=639&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=80d5c8b7544191e090463244521a4b5799cc6ddc\"&gt;https://preview.redd.it/qhqbudobmut91.png?width=639&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=80d5c8b7544191e090463244521a4b5799cc6ddc&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;What do You Think?&lt;/p&gt;\n\n&lt;p&gt;Pls help to decide&lt;/p&gt;\n\n&lt;p&gt;THX&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y47fbk", "is_robot_indexable": true, "report_reasons": null, "author": "Witzker", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y47fbk/help_with_smart_data_pls/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y47fbk/help_with_smart_data_pls/", "subreddit_subscribers": 647575, "created_utc": 1665787026.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone, \nI'm in the process of digitizing a large storage of paper documents. I have access to good office printers, so scanning most of the standard documents was a breeze. But I'm having issues with larger format documents. Especially paper rolls (so about 3-4m x 80cm wide), but also larger DIN A0 documents (e.g. Blueprints, plans, family trees, posters, etc.). \nI checked local services, but they can only handle DIN formats, but not the rolls. \nDo you guys have any ideas on how I could digitize them in somewhat good quality? I was thinking of taking lots of photos and stitching them with photomerge in Photoshop, but that failed quite badly. \nAre there maybe some scanner apps specialized for this, or are there any other techniques than I'm missing? \nThanks for any help in advance!", "author_fullname": "t2_uxafe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Digitizing large format paper documents for storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y46ool", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665785158.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, \nI&amp;#39;m in the process of digitizing a large storage of paper documents. I have access to good office printers, so scanning most of the standard documents was a breeze. But I&amp;#39;m having issues with larger format documents. Especially paper rolls (so about 3-4m x 80cm wide), but also larger DIN A0 documents (e.g. Blueprints, plans, family trees, posters, etc.). \nI checked local services, but they can only handle DIN formats, but not the rolls. \nDo you guys have any ideas on how I could digitize them in somewhat good quality? I was thinking of taking lots of photos and stitching them with photomerge in Photoshop, but that failed quite badly. \nAre there maybe some scanner apps specialized for this, or are there any other techniques than I&amp;#39;m missing? \nThanks for any help in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y46ool", "is_robot_indexable": true, "report_reasons": null, "author": "corny96", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y46ool/digitizing_large_format_paper_documents_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y46ool/digitizing_large_format_paper_documents_for/", "subreddit_subscribers": 647575, "created_utc": 1665785158.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "As the title indicates, I'm looking for S3 compatible storage provider that I can use with rclone on Linux to dump (long term backup) files. These will be primarily Borg backup files from my NAS storage. Any suggestions for a reasonably priced provider for home use segment?", "author_fullname": "t2_s7edcv9d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommendations for S3 compatible cold storage provider with ultra low price tag?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y44rep", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665780337.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title indicates, I&amp;#39;m looking for S3 compatible storage provider that I can use with rclone on Linux to dump (long term backup) files. These will be primarily Borg backup files from my NAS storage. Any suggestions for a reasonably priced provider for home use segment?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "y44rep", "is_robot_indexable": true, "report_reasons": null, "author": "useless-oracle", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/y44rep/recommendations_for_s3_compatible_cold_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/y44rep/recommendations_for_s3_compatible_cold_storage/", "subreddit_subscribers": 647575, "created_utc": 1665780337.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}