{"kind": "Listing", "data": {"after": "t3_y816ut", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_4tczv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "every time I hear someone say num-pee i die a little bit", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "meta", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_y7ycxz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "ups": 146, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meta", "can_mod_post": false, "score": 146, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/8ifUPQbWM946tcFz4Vg7wIPw5tcMaSuMpDdLm9qyyXo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666173070.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/aylc75laiqu91.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/aylc75laiqu91.png?auto=webp&amp;s=811d064f28c698d46d822b83b6b0e59ba36cf0ff", "width": 225, "height": 225}, "resolutions": [{"url": "https://preview.redd.it/aylc75laiqu91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=28c0ec8e54a7859652b0dc689287cd5298e7dec4", "width": 108, "height": 108}, {"url": "https://preview.redd.it/aylc75laiqu91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d9956e566ba76b8eec221428731f7170c360c21e", "width": 216, "height": 216}], "variants": {}, "id": "mXRYaAVfSayNzyW4E87Hes-sLP2gVI-6dqexq2_QSsc"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7ycxz", "is_robot_indexable": true, "report_reasons": null, "author": "MAFiA303", "discussion_type": null, "num_comments": 44, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7ycxz/every_time_i_hear_someone_say_numpee_i_die_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/aylc75laiqu91.png", "subreddit_subscribers": 814313, "created_utc": 1666173070.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_amfdjuba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Q] Based on your experience why does adding so many input features possibly worsen your models?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7kizv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 95, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 95, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666131032.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7kizv", "is_robot_indexable": true, "report_reasons": null, "author": "limedove", "discussion_type": null, "num_comments": 49, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7kizv/q_based_on_your_experience_why_does_adding_so/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7kizv/q_based_on_your_experience_why_does_adding_so/", "subreddit_subscribers": 814313, "created_utc": 1666131032.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "OK, I know this question will make a lot of you mad. I can see the replies now: Data science means different things at different companies, different algos are used for different contexts, Python vs R, senior vs junior roles, you're focusing on technologies and implementation while neglecting business context, etc. Yeah, I get it. My goal with this post is, with your help, to build a list of technologies/platform/skills from the broad array of what's considered data science and should be known by a DS with about 3 years of experience, in the opinion of the poster (that's you). Nothing is too broad or specific. For example, Naive Bayes, GNNs, containerization, and Docker are all valid answers (yes, I realize Docker is an implementation of containerization, and that's my point..) Please, if you would be so kind, include why you think it's important and to what depth/capability a DS with 3 years of experience should have with it. Since I'm a python person, let's exclude R from the conversation.\n\nWhy am I asking this? In full candor, I feel like I am seriously stagnating. I am really the only DS in my company, so it's very easy to lose sight of where the field is currently because so much of my job is simple excel/pandas stuff. I would potentially like to start interviewing, but I feel like I am far behind where a typical DS with my YOE would be. Like, for example, I have no clue how to use airflow or any non-AWS scheduler, every time I do anything related to ML (a very rare occurrence, unfortunately), I have completely forgotten the sklearn syntax, I know pretty much nothing about actually training an NN, I know in theory what a basic NN is, but I have no idea about graph NNs or graph databases or graph anything. I still have no clue what distinguishes a data warehouse from a database after reading countless articles. I feel like I don't even know what I don't know; for anything I do know, it's hard to tell if what I'm doing is the best practice.\n\nMany thanks in advance!", "author_fullname": "t2_i7wlt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What technologies/skills should a data scientist with ~ 3 years of experience be familiar with?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y78uss", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 89, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 89, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666104212.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666103915.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;OK, I know this question will make a lot of you mad. I can see the replies now: Data science means different things at different companies, different algos are used for different contexts, Python vs R, senior vs junior roles, you&amp;#39;re focusing on technologies and implementation while neglecting business context, etc. Yeah, I get it. My goal with this post is, with your help, to build a list of technologies/platform/skills from the broad array of what&amp;#39;s considered data science and should be known by a DS with about 3 years of experience, in the opinion of the poster (that&amp;#39;s you). Nothing is too broad or specific. For example, Naive Bayes, GNNs, containerization, and Docker are all valid answers (yes, I realize Docker is an implementation of containerization, and that&amp;#39;s my point..) Please, if you would be so kind, include why you think it&amp;#39;s important and to what depth/capability a DS with 3 years of experience should have with it. Since I&amp;#39;m a python person, let&amp;#39;s exclude R from the conversation.&lt;/p&gt;\n\n&lt;p&gt;Why am I asking this? In full candor, I feel like I am seriously stagnating. I am really the only DS in my company, so it&amp;#39;s very easy to lose sight of where the field is currently because so much of my job is simple excel/pandas stuff. I would potentially like to start interviewing, but I feel like I am far behind where a typical DS with my YOE would be. Like, for example, I have no clue how to use airflow or any non-AWS scheduler, every time I do anything related to ML (a very rare occurrence, unfortunately), I have completely forgotten the sklearn syntax, I know pretty much nothing about actually training an NN, I know in theory what a basic NN is, but I have no idea about graph NNs or graph databases or graph anything. I still have no clue what distinguishes a data warehouse from a database after reading countless articles. I feel like I don&amp;#39;t even know what I don&amp;#39;t know; for anything I do know, it&amp;#39;s hard to tell if what I&amp;#39;m doing is the best practice.&lt;/p&gt;\n\n&lt;p&gt;Many thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y78uss", "is_robot_indexable": true, "report_reasons": null, "author": "jewami", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y78uss/what_technologiesskills_should_a_data_scientist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y78uss/what_technologiesskills_should_a_data_scientist/", "subreddit_subscribers": 814313, "created_utc": 1666103915.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Maybe anyone has faced this issue before, I am investigating if there are clusters of users based on number of particular actions they took. Users have different lifespans in the system so time series have variable lengths, in addition some users only take certain actions which uncorrelated with their time spent in the system. I am looking at Dynamic Time Warping, but the problem of short time series for some users and sparse feature makes it seem like inappropriate solution. Any recommendations?", "author_fullname": "t2_daczn1t9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the recommended modeling approaches for clustering of several Multivariate Timeseries data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7kupq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666131823.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Maybe anyone has faced this issue before, I am investigating if there are clusters of users based on number of particular actions they took. Users have different lifespans in the system so time series have variable lengths, in addition some users only take certain actions which uncorrelated with their time spent in the system. I am looking at Dynamic Time Warping, but the problem of short time series for some users and sparse feature makes it seem like inappropriate solution. Any recommendations?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7kupq", "is_robot_indexable": true, "report_reasons": null, "author": "neural_net_ork", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7kupq/what_are_the_recommended_modeling_approaches_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7kupq/what_are_the_recommended_modeling_approaches_for/", "subreddit_subscribers": 814313, "created_utc": 1666131823.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "[https://doordash.engineering/2022/10/18/augmenting-fuzzy-matching-with-human-review-to-maximize-precision-and-recall/](https://doordash.engineering/2022/10/18/augmenting-fuzzy-matching-with-human-review-to-maximize-precision-and-recall/)\n\nI recently solved a business problem at DoorDash: we needed a way to onboard new advertisers (brands that sell products at convenience/grocery stores) at scale, without having to manually identify all their products that are available on DoorDash. We used a fuzzy-matching classifier with a human in the loop.\n\nThe part I find the most interesting is how we were able to take an out-of-the-box fuzzy matching algorithm and \u2013 with relatively little technical effort \u2013 tweak it to improve precision and recall. See table toward the end of the piece.\n\nComment away, either here or on the post itself!", "author_fullname": "t2_5kfet", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DoorDash Eng Blog: Augmenting fuzzy matching with human review to maximize precision and recall", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7nl7s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666138929.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://doordash.engineering/2022/10/18/augmenting-fuzzy-matching-with-human-review-to-maximize-precision-and-recall/\"&gt;https://doordash.engineering/2022/10/18/augmenting-fuzzy-matching-with-human-review-to-maximize-precision-and-recall/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I recently solved a business problem at DoorDash: we needed a way to onboard new advertisers (brands that sell products at convenience/grocery stores) at scale, without having to manually identify all their products that are available on DoorDash. We used a fuzzy-matching classifier with a human in the loop.&lt;/p&gt;\n\n&lt;p&gt;The part I find the most interesting is how we were able to take an out-of-the-box fuzzy matching algorithm and \u2013 with relatively little technical effort \u2013 tweak it to improve precision and recall. See table toward the end of the piece.&lt;/p&gt;\n\n&lt;p&gt;Comment away, either here or on the post itself!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7nl7s", "is_robot_indexable": true, "report_reasons": null, "author": "chikinn", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7nl7s/doordash_eng_blog_augmenting_fuzzy_matching_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7nl7s/doordash_eng_blog_augmenting_fuzzy_matching_with/", "subreddit_subscribers": 814313, "created_utc": 1666138929.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In the spring I will be teaching the first Data Analytics class ever taught at my university. This class will be focusing on data visualization and communication. I have my textbooks and my class plan already, but I wanted to pose a question to you all. Is there something you wished you learned in your data visualization class that was not taught?", "author_fullname": "t2_lydp1nun", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Teaching a Data Analytics Class", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7r1hx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666148583.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In the spring I will be teaching the first Data Analytics class ever taught at my university. This class will be focusing on data visualization and communication. I have my textbooks and my class plan already, but I wanted to pose a question to you all. Is there something you wished you learned in your data visualization class that was not taught?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7r1hx", "is_robot_indexable": true, "report_reasons": null, "author": "Newd_Librarian", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7r1hx/teaching_a_data_analytics_class/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7r1hx/teaching_a_data_analytics_class/", "subreddit_subscribers": 814313, "created_utc": 1666148583.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am confused on how to build my portfolio or even what platforms to use.  I\u2019ve been overwhelmed and trying to find answers about this without much luck. \n\nIf I\u2019m trying to showcase SQL, R, Python, tableau and Microsoft excel, what are the best platforms and strategies for going about this?\n\nEdit: I\u2019m transitioning into data analysis", "author_fullname": "t2_t1en7quk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Structure Portfolio", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7u9ky", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666158466.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am confused on how to build my portfolio or even what platforms to use.  I\u2019ve been overwhelmed and trying to find answers about this without much luck. &lt;/p&gt;\n\n&lt;p&gt;If I\u2019m trying to showcase SQL, R, Python, tableau and Microsoft excel, what are the best platforms and strategies for going about this?&lt;/p&gt;\n\n&lt;p&gt;Edit: I\u2019m transitioning into data analysis&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7u9ky", "is_robot_indexable": true, "report_reasons": null, "author": "SeaRocks10", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7u9ky/how_to_structure_portfolio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7u9ky/how_to_structure_portfolio/", "subreddit_subscribers": 814313, "created_utc": 1666158466.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm guessing most of you have heard the world war II era story used to illustrate survivorship bias. If not, it's featured on the wikipedia page: [https://en.wikipedia.org/wiki/Survivorship\\_bias](https://en.wikipedia.org/wiki/Survivorship_bias)\n\nOther than that, there are many other biases/paradoxes/pitfalls than the non-statistically minded might fall into. A decent list can be found here: [https://stats.stackexchange.com/questions/23779/most-interesting-statistical-paradoxes/592495#592495](https://stats.stackexchange.com/questions/23779/most-interesting-statistical-paradoxes/592495#592495)\n\nSome were inspired by historical failures (e.g. the survivorship bias again) but others seem to have started more as brain teasers. [https://en.wikipedia.org/wiki/Sleeping\\_Beauty\\_problem](https://en.wikipedia.org/wiki/Sleeping_Beauty_problem)\n\nAdditional, some are fairly easy to come across (Simpson's paradox is applicable to a lot of real world data) whereas others might be more niche.\n\nRegardless, I would say that the thing all of these examples have in common is basically:\n\n*There appears to be an obvious answer/interpretation, but that answer/interpretation is either not a sure thing or the correct answer/interpretation is in blatant contradiction to the obvious answer.*\n\nBy that definition, has anything like this come up on the job?", "author_fullname": "t2_s47x31rw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Paradoxes (or at least pitfalls) on the job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7omp4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666142023.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666141803.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m guessing most of you have heard the world war II era story used to illustrate survivorship bias. If not, it&amp;#39;s featured on the wikipedia page: &lt;a href=\"https://en.wikipedia.org/wiki/Survivorship_bias\"&gt;https://en.wikipedia.org/wiki/Survivorship_bias&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Other than that, there are many other biases/paradoxes/pitfalls than the non-statistically minded might fall into. A decent list can be found here: &lt;a href=\"https://stats.stackexchange.com/questions/23779/most-interesting-statistical-paradoxes/592495#592495\"&gt;https://stats.stackexchange.com/questions/23779/most-interesting-statistical-paradoxes/592495#592495&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Some were inspired by historical failures (e.g. the survivorship bias again) but others seem to have started more as brain teasers. &lt;a href=\"https://en.wikipedia.org/wiki/Sleeping_Beauty_problem\"&gt;https://en.wikipedia.org/wiki/Sleeping_Beauty_problem&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Additional, some are fairly easy to come across (Simpson&amp;#39;s paradox is applicable to a lot of real world data) whereas others might be more niche.&lt;/p&gt;\n\n&lt;p&gt;Regardless, I would say that the thing all of these examples have in common is basically:&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;There appears to be an obvious answer/interpretation, but that answer/interpretation is either not a sure thing or the correct answer/interpretation is in blatant contradiction to the obvious answer.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;By that definition, has anything like this come up on the job?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/a1DhEZ4c4gmsM5mqKxahsd-VvK5lheeFUccaBLODQ5k.jpg?auto=webp&amp;s=8e886a7d7b52e99c00fb213bfb8130938ee2b2a4", "width": 1200, "height": 894}, "resolutions": [{"url": "https://external-preview.redd.it/a1DhEZ4c4gmsM5mqKxahsd-VvK5lheeFUccaBLODQ5k.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a6fc2d9acd533989d7d6c71fb702626994cc8a42", "width": 108, "height": 80}, {"url": "https://external-preview.redd.it/a1DhEZ4c4gmsM5mqKxahsd-VvK5lheeFUccaBLODQ5k.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=77c6e6c880e7741ea362b3770253ffc7ca1f1af7", "width": 216, "height": 160}, {"url": "https://external-preview.redd.it/a1DhEZ4c4gmsM5mqKxahsd-VvK5lheeFUccaBLODQ5k.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bc6b40a946b177471c5024f1063879f0a898249c", "width": 320, "height": 238}, {"url": "https://external-preview.redd.it/a1DhEZ4c4gmsM5mqKxahsd-VvK5lheeFUccaBLODQ5k.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=dc782b33b53cdaeb2174d372a76c2b613cd7aa67", "width": 640, "height": 476}, {"url": "https://external-preview.redd.it/a1DhEZ4c4gmsM5mqKxahsd-VvK5lheeFUccaBLODQ5k.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=cd99878f734a1fed6b0fbc3dcc94c4c71caf1cad", "width": 960, "height": 715}, {"url": "https://external-preview.redd.it/a1DhEZ4c4gmsM5mqKxahsd-VvK5lheeFUccaBLODQ5k.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c74213b7277cfa3202d33b09fbf6c52f7ee8dab5", "width": 1080, "height": 804}], "variants": {}, "id": "SNQxXIF511m-ex3iNlA-2c78ApiWKGIXo6QtamSh1qY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7omp4", "is_robot_indexable": true, "report_reasons": null, "author": "Western-Elevator-456", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7omp4/paradoxes_or_at_least_pitfalls_on_the_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7omp4/paradoxes_or_at_least_pitfalls_on_the_job/", "subreddit_subscribers": 814313, "created_utc": 1666141803.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Currently I use DataViz and was wondering if there was something similar,  one with a nice wizard, convenient table filtering, and schemas, but with Git integration and allows for you to work in other coding languages like Python too. \n\nI\u2019m currently looking into DBeaver. I\u2019m pretty new to all of this so sorry if this post isn\u2019t worded too well. Thanks in advance!", "author_fullname": "t2_11re2h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which IDE would be best for PostgreSQL and python?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7i8ju", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666125713.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently I use DataViz and was wondering if there was something similar,  one with a nice wizard, convenient table filtering, and schemas, but with Git integration and allows for you to work in other coding languages like Python too. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m currently looking into DBeaver. I\u2019m pretty new to all of this so sorry if this post isn\u2019t worded too well. Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7i8ju", "is_robot_indexable": true, "report_reasons": null, "author": "proudaggie", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7i8ju/which_ide_would_be_best_for_postgresql_and_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7i8ju/which_ide_would_be_best_for_postgresql_and_python/", "subreddit_subscribers": 814313, "created_utc": 1666125713.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I had some trouble with the softer side of data science when I first started as a data scientist. During my consulting days, I learned a lot about understanding and communicating with clients, which I want to share.\n\n&amp;#x200B;\n\nBelow are some tips:\n\n&amp;#x200B;\n\n ### How to adopt a business mindset\n\n\\- **Understand how the business makes money.** For you to add value to the business it is crucial to understand their revenue streams and how they make money. \n\n\\- **Relate your work to a business KPI.** To measure the impact of your work, it can be very helpful to relate this to a business KPI. Not always possible, but if you can do it will help in understanding how you can generate value.\n\n\\- **Ask for feedback from your manager.** This is very underutilized. Asking for feedback makes you vulnerable, but it will help in understanding what your manager thinks is important. Plus, it shows that you are willing to learn (which is very important in business).\n\n&amp;#x200B;\n\n### How to manage time\n\n\\- **Prioritize tasks before analysis.** Before touching data, making a list of all actions you need to do will give more clarity in the process and help in planning your time better. Data science comes with a lot of uncertainty, which will take some of them away. \n\n\\- **Use a data analytics project template.** A document where you describe your hypotheses, data needed, and stakeholders will make you way more efficient. \n\n\\- **Plan update meetings with stakeholders to create soft deadlines for yourself.** This helps you to work towards a date and get work done. \n\n&amp;#x200B;\n\n### How to communicate insights\n\n\\- **Learn good data visualization practices.** Understand how you structure a Powerpoint deck and how you present recommendations. I advise to google for Mckinsey's Powerpoint breakdown. \n\n\\- **Create a dialogue where questions can be asked.** The one you are communicating with will definitely have questions. Allow room in your communication for insights and ask \"was this clear?\" after complicated parts.\n\n\\- **Show you are trying to help, not to criticize.** Do not position yourself as the person that knows everything and that the other party is wrong. Be helpful and try to understand where they are coming from.\n\n&amp;#x200B;\n\n### How to collaborate with others\n\n\\- **Write code together.** Writing code together helps to stay sharp and spot errors. This will lead to better work.\n\n\\- **Use Kanban boards to assign tasks and track progress.** Use Kanban boards to decompose big assignments into smaller tasks. Keep the board updated to track progress.\n\n\\- **Have multiple update calls per week.** This depends on the project, but having update calls with your peers \\~2 times per week to discuss challenges helps to spend less time on parts where you are stuck. \n\n&amp;#x200B;\n\nHopefully, this was useful for you. If you have more tips, let me know in the comments!", "author_fullname": "t2_6f4y2kr6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Some advice on the softer side of data science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7a5ae", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666108194.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666106874.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I had some trouble with the softer side of data science when I first started as a data scientist. During my consulting days, I learned a lot about understanding and communicating with clients, which I want to share.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Below are some tips:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;### How to adopt a business mindset&lt;/p&gt;\n\n&lt;p&gt;- &lt;strong&gt;Understand how the business makes money.&lt;/strong&gt; For you to add value to the business it is crucial to understand their revenue streams and how they make money. &lt;/p&gt;\n\n&lt;p&gt;- &lt;strong&gt;Relate your work to a business KPI.&lt;/strong&gt; To measure the impact of your work, it can be very helpful to relate this to a business KPI. Not always possible, but if you can do it will help in understanding how you can generate value.&lt;/p&gt;\n\n&lt;p&gt;- &lt;strong&gt;Ask for feedback from your manager.&lt;/strong&gt; This is very underutilized. Asking for feedback makes you vulnerable, but it will help in understanding what your manager thinks is important. Plus, it shows that you are willing to learn (which is very important in business).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;h3&gt;How to manage time&lt;/h3&gt;\n\n&lt;p&gt;- &lt;strong&gt;Prioritize tasks before analysis.&lt;/strong&gt; Before touching data, making a list of all actions you need to do will give more clarity in the process and help in planning your time better. Data science comes with a lot of uncertainty, which will take some of them away. &lt;/p&gt;\n\n&lt;p&gt;- &lt;strong&gt;Use a data analytics project template.&lt;/strong&gt; A document where you describe your hypotheses, data needed, and stakeholders will make you way more efficient. &lt;/p&gt;\n\n&lt;p&gt;- &lt;strong&gt;Plan update meetings with stakeholders to create soft deadlines for yourself.&lt;/strong&gt; This helps you to work towards a date and get work done. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;h3&gt;How to communicate insights&lt;/h3&gt;\n\n&lt;p&gt;- &lt;strong&gt;Learn good data visualization practices.&lt;/strong&gt; Understand how you structure a Powerpoint deck and how you present recommendations. I advise to google for Mckinsey&amp;#39;s Powerpoint breakdown. &lt;/p&gt;\n\n&lt;p&gt;- &lt;strong&gt;Create a dialogue where questions can be asked.&lt;/strong&gt; The one you are communicating with will definitely have questions. Allow room in your communication for insights and ask &amp;quot;was this clear?&amp;quot; after complicated parts.&lt;/p&gt;\n\n&lt;p&gt;- &lt;strong&gt;Show you are trying to help, not to criticize.&lt;/strong&gt; Do not position yourself as the person that knows everything and that the other party is wrong. Be helpful and try to understand where they are coming from.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;h3&gt;How to collaborate with others&lt;/h3&gt;\n\n&lt;p&gt;- &lt;strong&gt;Write code together.&lt;/strong&gt; Writing code together helps to stay sharp and spot errors. This will lead to better work.&lt;/p&gt;\n\n&lt;p&gt;- &lt;strong&gt;Use Kanban boards to assign tasks and track progress.&lt;/strong&gt; Use Kanban boards to decompose big assignments into smaller tasks. Keep the board updated to track progress.&lt;/p&gt;\n\n&lt;p&gt;- &lt;strong&gt;Have multiple update calls per week.&lt;/strong&gt; This depends on the project, but having update calls with your peers ~2 times per week to discuss challenges helps to spend less time on parts where you are stuck. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Hopefully, this was useful for you. If you have more tips, let me know in the comments!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7a5ae", "is_robot_indexable": true, "report_reasons": null, "author": "thomasvarekamp", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7a5ae/some_advice_on_the_softer_side_of_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7a5ae/some_advice_on_the_softer_side_of_data_science/", "subreddit_subscribers": 814313, "created_utc": 1666106874.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Suppose I sell flip flops and I have it set up with the following row titles:\nUPC, Item Name, Price\n\nI want to get the price people are selling online, like Amazon and have excel automatically populate a row with the title \u201cOnline Price\u201d\n\nWould this be possible via excel or is this type of data project possible through other softwares?", "author_fullname": "t2_2lmomuub", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a way to extract the price of an item on the internet and directly match it to your item price?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7a24t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666106666.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Suppose I sell flip flops and I have it set up with the following row titles:\nUPC, Item Name, Price&lt;/p&gt;\n\n&lt;p&gt;I want to get the price people are selling online, like Amazon and have excel automatically populate a row with the title \u201cOnline Price\u201d&lt;/p&gt;\n\n&lt;p&gt;Would this be possible via excel or is this type of data project possible through other softwares?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7a24t", "is_robot_indexable": true, "report_reasons": null, "author": "tryingtogetintoIB", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7a24t/is_there_a_way_to_extract_the_price_of_an_item_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7a24t/is_there_a_way_to_extract_the_price_of_an_item_on/", "subreddit_subscribers": 814313, "created_utc": 1666106666.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello!\n\nDo you belong to any other *active* Data Science or Data related communities? Whether that is on Reddit, Discord, a forum?\n\nThe Discord channels that I belong to are really quiet. It would be good to spread my wings a little wider.", "author_fullname": "t2_9k8sa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Other Active Data Science-Related Communities?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7ly78", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666134603.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;Do you belong to any other &lt;em&gt;active&lt;/em&gt; Data Science or Data related communities? Whether that is on Reddit, Discord, a forum?&lt;/p&gt;\n\n&lt;p&gt;The Discord channels that I belong to are really quiet. It would be good to spread my wings a little wider.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7ly78", "is_robot_indexable": true, "report_reasons": null, "author": "MrMadium", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7ly78/other_active_data_sciencerelated_communities/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7ly78/other_active_data_sciencerelated_communities/", "subreddit_subscribers": 814313, "created_utc": 1666134603.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have weather data from stations across the US but of course this data corresponds to single lat/lon coordinates whereas I'd like data at every coordinate across the entire US. Thus, I'm going to need to do some sort of spatial interpolation (or similar).\n\nI've read that krigging (Gaussian Process Regression) is often used for spatial interpolation though I can't see the benefit over something like KNN if I'm not going to be using the uncertainty estimate it comes with. Krigging is very computationally expensive and explaining the theory behind it is difficult at best. Neglecting uncertainty quantification since it won't be used, is the main advantage  properly designed mean and covariance functions in which the model reverts back to in the areas far from data points?", "author_fullname": "t2_91itiala", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Krigging for Spatial Interpolation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7hwfm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666124931.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have weather data from stations across the US but of course this data corresponds to single lat/lon coordinates whereas I&amp;#39;d like data at every coordinate across the entire US. Thus, I&amp;#39;m going to need to do some sort of spatial interpolation (or similar).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve read that krigging (Gaussian Process Regression) is often used for spatial interpolation though I can&amp;#39;t see the benefit over something like KNN if I&amp;#39;m not going to be using the uncertainty estimate it comes with. Krigging is very computationally expensive and explaining the theory behind it is difficult at best. Neglecting uncertainty quantification since it won&amp;#39;t be used, is the main advantage  properly designed mean and covariance functions in which the model reverts back to in the areas far from data points?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7hwfm", "is_robot_indexable": true, "report_reasons": null, "author": "MGeeeeeezy", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7hwfm/krigging_for_spatial_interpolation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7hwfm/krigging_for_spatial_interpolation/", "subreddit_subscribers": 814313, "created_utc": 1666124931.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I wasn't aware that amazon offered online learning. I can't seem to find any reviews online, and I wanted to know what this community thought of it ? \n\nHas anyone taken these courses ?", "author_fullname": "t2_13t60b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reviews of courses offered by Amazon for Data science, SQL, python, etc.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7cyqy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666113431.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wasn&amp;#39;t aware that amazon offered online learning. I can&amp;#39;t seem to find any reviews online, and I wanted to know what this community thought of it ? &lt;/p&gt;\n\n&lt;p&gt;Has anyone taken these courses ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7cyqy", "is_robot_indexable": true, "report_reasons": null, "author": "drugsarebadmky", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7cyqy/reviews_of_courses_offered_by_amazon_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7cyqy/reviews_of_courses_offered_by_amazon_for_data/", "subreddit_subscribers": 814313, "created_utc": 1666113431.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nHi mates\n\nI hope you are doing well.\n\nWould you please tell me the **difference between** the ***Retention*** and the ***Propensity*** models?  \nAs I understand, the propensity model has three types: **Propensity to buy**, **Propensity to churn**, and **Propensity to unsubscribe**.\n\nIs the **retention model** the same as the **propensity to churn**?\n\nThank you in advance", "author_fullname": "t2_8otyl3bx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Difference between Propensity model and Retention model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7ymoz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666173922.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi mates&lt;/p&gt;\n\n&lt;p&gt;I hope you are doing well.&lt;/p&gt;\n\n&lt;p&gt;Would you please tell me the &lt;strong&gt;difference between&lt;/strong&gt; the &lt;strong&gt;&lt;em&gt;Retention&lt;/em&gt;&lt;/strong&gt; and the &lt;strong&gt;&lt;em&gt;Propensity&lt;/em&gt;&lt;/strong&gt; models?&lt;br/&gt;\nAs I understand, the propensity model has three types: &lt;strong&gt;Propensity to buy&lt;/strong&gt;, &lt;strong&gt;Propensity to churn&lt;/strong&gt;, and &lt;strong&gt;Propensity to unsubscribe&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;Is the &lt;strong&gt;retention model&lt;/strong&gt; the same as the &lt;strong&gt;propensity to churn&lt;/strong&gt;?&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7ymoz", "is_robot_indexable": true, "report_reasons": null, "author": "Masoud_mirza", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7ymoz/difference_between_propensity_model_and_retention/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7ymoz/difference_between_propensity_model_and_retention/", "subreddit_subscribers": 814313, "created_utc": 1666173922.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\nAs a DA expecting offers for both roles, Analytics Engineer and Data Scientist Product Analytics, I was wondering how the community viewed each role?\n\nIs one harder to break into? Does one generally lead to better opportunities down the road? Is pay expected to be higher for one vs the other (I\u2019m expecting similar based on recruiter conversation)? Is one more or less \u2018future proof\u2019?\n\n\u200b\n\nI think I know which one I would be a more natural fit for but I\u2019m curious about the perception of the roles from others in the industry.", "author_fullname": "t2_1oj5wdu2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\u201cBetter\u201d career? AE vs DS product", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7pean", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666143921.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a DA expecting offers for both roles, Analytics Engineer and Data Scientist Product Analytics, I was wondering how the community viewed each role?&lt;/p&gt;\n\n&lt;p&gt;Is one harder to break into? Does one generally lead to better opportunities down the road? Is pay expected to be higher for one vs the other (I\u2019m expecting similar based on recruiter conversation)? Is one more or less \u2018future proof\u2019?&lt;/p&gt;\n\n&lt;p&gt;\u200b&lt;/p&gt;\n\n&lt;p&gt;I think I know which one I would be a more natural fit for but I\u2019m curious about the perception of the roles from others in the industry.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7pean", "is_robot_indexable": true, "report_reasons": null, "author": "bigfeller2", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7pean/better_career_ae_vs_ds_product/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7pean/better_career_ae_vs_ds_product/", "subreddit_subscribers": 814313, "created_utc": 1666143921.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Where to start? No, that\u2019s my question.\n\nAn age old problem of many, disparate data sources entered manually. \n\nWho is trying to solve this issue at scale, and is doing it well?\n\nIf the answer is so large, it needs to be broken down, then do, please.", "author_fullname": "t2_5gltv6d9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Manual data entry - who\u2019s who", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7asl8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666108420.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Where to start? No, that\u2019s my question.&lt;/p&gt;\n\n&lt;p&gt;An age old problem of many, disparate data sources entered manually. &lt;/p&gt;\n\n&lt;p&gt;Who is trying to solve this issue at scale, and is doing it well?&lt;/p&gt;\n\n&lt;p&gt;If the answer is so large, it needs to be broken down, then do, please.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7asl8", "is_robot_indexable": true, "report_reasons": null, "author": "montana_mija", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7asl8/manual_data_entry_whos_who/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7asl8/manual_data_entry_whos_who/", "subreddit_subscribers": 814313, "created_utc": 1666108420.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "First year undergrad studying physics with data science. Around 25% of my course modules is data science (if I study undergrad bachelors, otherwise if I keep studying undergrad masters it would be 40% data science.). Data science modules that I am going to study in the next 3 years:\n\n-Introduction to Data Science\n\n-Practical Techniques for Data Science\n\n-Data Science Project Portfolio\n\n-Statistical Data Analysis\n\n-Machine Learning and Artificial\n\n-Professional Skills for Data Science\n\nIf I chose to stay in integrated undergraduate Masters (4 year course) then I can choose these extra data science modules on my fourth year:\n\n-Practical Machine Learning\n\n-Introduction to Computer Vision\n\n-Computer Graphics\n\n-Risk and Decision-Making for Data Science and AI\n\n-Machine Learning for Visual Data Analysis\n\n-Time Series\n\n-Applied Statistics\n\nShould I study just for bachelors and then do postgraduate masters in data science or stay in undergrad masters (if I stay in undergrad masters i dont want to do any further study). I know that postgraduate Masters are more highly regarded than undergraduate masters, plus I can have a chance to study for postgraduates in a more prestigious university if I do well in my current course and I want to also study less years as possible (tuition fees are expensive) and be more efficient in terms of time, money and value.\n\nAlso, since I dont have a pure maths/computer science background, what do you advice me to do for my technical skills (so far I self taught Python and I will get to code way more than other students from normal physics as part of my course from next semester). I am trying yo be proactive with my technical skills but dont know from where to get started. I want to build a resume that's decent enough for summer 2023 internship.", "author_fullname": "t2_cxq07y37", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "majoring in physics and minoring in data science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_y831jt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666186817.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First year undergrad studying physics with data science. Around 25% of my course modules is data science (if I study undergrad bachelors, otherwise if I keep studying undergrad masters it would be 40% data science.). Data science modules that I am going to study in the next 3 years:&lt;/p&gt;\n\n&lt;p&gt;-Introduction to Data Science&lt;/p&gt;\n\n&lt;p&gt;-Practical Techniques for Data Science&lt;/p&gt;\n\n&lt;p&gt;-Data Science Project Portfolio&lt;/p&gt;\n\n&lt;p&gt;-Statistical Data Analysis&lt;/p&gt;\n\n&lt;p&gt;-Machine Learning and Artificial&lt;/p&gt;\n\n&lt;p&gt;-Professional Skills for Data Science&lt;/p&gt;\n\n&lt;p&gt;If I chose to stay in integrated undergraduate Masters (4 year course) then I can choose these extra data science modules on my fourth year:&lt;/p&gt;\n\n&lt;p&gt;-Practical Machine Learning&lt;/p&gt;\n\n&lt;p&gt;-Introduction to Computer Vision&lt;/p&gt;\n\n&lt;p&gt;-Computer Graphics&lt;/p&gt;\n\n&lt;p&gt;-Risk and Decision-Making for Data Science and AI&lt;/p&gt;\n\n&lt;p&gt;-Machine Learning for Visual Data Analysis&lt;/p&gt;\n\n&lt;p&gt;-Time Series&lt;/p&gt;\n\n&lt;p&gt;-Applied Statistics&lt;/p&gt;\n\n&lt;p&gt;Should I study just for bachelors and then do postgraduate masters in data science or stay in undergrad masters (if I stay in undergrad masters i dont want to do any further study). I know that postgraduate Masters are more highly regarded than undergraduate masters, plus I can have a chance to study for postgraduates in a more prestigious university if I do well in my current course and I want to also study less years as possible (tuition fees are expensive) and be more efficient in terms of time, money and value.&lt;/p&gt;\n\n&lt;p&gt;Also, since I dont have a pure maths/computer science background, what do you advice me to do for my technical skills (so far I self taught Python and I will get to code way more than other students from normal physics as part of my course from next semester). I am trying yo be proactive with my technical skills but dont know from where to get started. I want to build a resume that&amp;#39;s decent enough for summer 2023 internship.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y831jt", "is_robot_indexable": true, "report_reasons": null, "author": "Substantial-Peach562", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y831jt/majoring_in_physics_and_minoring_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y831jt/majoring_in_physics_and_minoring_in_data_science/", "subreddit_subscribers": 814313, "created_utc": 1666186817.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have some mixed data that I thought I'd first transform into embeddings and then cluster the embedding. However, since I'm clustering embeddings does that mean that I'm going to lose all interpretability of the clusters? I know there's some loss of interpreability when using embeddings but I'm not clear on what the degree of that loss is. Anyone care to clarify?", "author_fullname": "t2_5ox025vb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Clustering embeddings", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_y82y0u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666186559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have some mixed data that I thought I&amp;#39;d first transform into embeddings and then cluster the embedding. However, since I&amp;#39;m clustering embeddings does that mean that I&amp;#39;m going to lose all interpretability of the clusters? I know there&amp;#39;s some loss of interpreability when using embeddings but I&amp;#39;m not clear on what the degree of that loss is. Anyone care to clarify?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y82y0u", "is_robot_indexable": true, "report_reasons": null, "author": "SomaDomaBoma", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y82y0u/clustering_embeddings/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y82y0u/clustering_embeddings/", "subreddit_subscribers": 814313, "created_utc": 1666186559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently working to address customer churn among deposit accounts of a retail bank. In this case, the churn is not explicitly defined since a customer- either an individual, or a corporate entity, both using the account primarily to fulfil business related transactions- is free to deposit or withdraw any amount at any point in time.\n\nI am inclined towards approaching this as an anomaly detection problem rather a classification one: i.e., identify customers as likely to churn by detecting anomalous patterns in their behaviour such as frequent, increasing withdrawals and/or declining credits?\n\nI would like to hear your opinion on this. Also, if you could cite any approach/existing solution for a similar problem. I am currently reading up on the following that considers hierarchical Temporal Memory Approach to address churn.\n\nhttps://core.ac.uk/download/pdf/225895269.pdf", "author_fullname": "t2_1mp5bur7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Analyzing churn when it cannot be defined by an event", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_y82jtt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666185558.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently working to address customer churn among deposit accounts of a retail bank. In this case, the churn is not explicitly defined since a customer- either an individual, or a corporate entity, both using the account primarily to fulfil business related transactions- is free to deposit or withdraw any amount at any point in time.&lt;/p&gt;\n\n&lt;p&gt;I am inclined towards approaching this as an anomaly detection problem rather a classification one: i.e., identify customers as likely to churn by detecting anomalous patterns in their behaviour such as frequent, increasing withdrawals and/or declining credits?&lt;/p&gt;\n\n&lt;p&gt;I would like to hear your opinion on this. Also, if you could cite any approach/existing solution for a similar problem. I am currently reading up on the following that considers hierarchical Temporal Memory Approach to address churn.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://core.ac.uk/download/pdf/225895269.pdf\"&gt;https://core.ac.uk/download/pdf/225895269.pdf&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y82jtt", "is_robot_indexable": true, "report_reasons": null, "author": "sn71", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y82jtt/analyzing_churn_when_it_cannot_be_defined_by_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y82jtt/analyzing_churn_when_it_cannot_be_defined_by_an/", "subreddit_subscribers": 814313, "created_utc": 1666185558.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "hello,\n\nI'm planning on using the shortened version of the [schwartz value survey](https://www.framevoicereport.org/media/1093/the-short-schwartzs-value-survey.pdf) (SSVS) in my master's thesis. there are 10 basic human values and participants rate each of them on a likert-scale (0 to 8). I will later relate this survey data to some behavior of the participants *(like \"participants who value conformity behave like this\")* \\-but, I am completely lost on how to analyze the survey data. I guess I need to create a score for each participant, but is it possible? or logical? *(values have a circumplex structure -each value is similar to one other while also being the opposite of another. so yielding just one score per individual seems like it wouldn't make sense? like they would cancel each other out somehow? i don't know)*\n\nusing factor analysis, the 10 values can be reduced into a couple (?) of dimensions (I guess). but would that lead to a score? or a score with two dimensions (like a point coordinate in xy-axis)? \n\ndoes anybody have any clue? help.........please?", "author_fullname": "t2_664rqg0i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "schwartz value survey -analysis", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y800ys", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666178445.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hello,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m planning on using the shortened version of the &lt;a href=\"https://www.framevoicereport.org/media/1093/the-short-schwartzs-value-survey.pdf\"&gt;schwartz value survey&lt;/a&gt; (SSVS) in my master&amp;#39;s thesis. there are 10 basic human values and participants rate each of them on a likert-scale (0 to 8). I will later relate this survey data to some behavior of the participants &lt;em&gt;(like &amp;quot;participants who value conformity behave like this&amp;quot;)&lt;/em&gt; -but, I am completely lost on how to analyze the survey data. I guess I need to create a score for each participant, but is it possible? or logical? &lt;em&gt;(values have a circumplex structure -each value is similar to one other while also being the opposite of another. so yielding just one score per individual seems like it wouldn&amp;#39;t make sense? like they would cancel each other out somehow? i don&amp;#39;t know)&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;using factor analysis, the 10 values can be reduced into a couple (?) of dimensions (I guess). but would that lead to a score? or a score with two dimensions (like a point coordinate in xy-axis)? &lt;/p&gt;\n\n&lt;p&gt;does anybody have any clue? help.........please?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y800ys", "is_robot_indexable": true, "report_reasons": null, "author": "cauliflowingo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y800ys/schwartz_value_survey_analysis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y800ys/schwartz_value_survey_analysis/", "subreddit_subscribers": 814313, "created_utc": 1666178445.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Assumptions before performing tests", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7zsrk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_6wfy9q4l", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "rstats", "selftext": "For example, I want to run an Anova test. \n\nDo I need to check if the data qualifies all assumptions?\n\nWhat do I do when the data does not fulfill any of the assumptions? \n\nWhat is the best way to confirm a normal distribution before such tests? Is a qqplot good enough?", "author_fullname": "t2_6wfy9q4l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Assumptions before performing tests", "link_flair_richtext": [], "subreddit_name_prefixed": "r/rstats", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7ex5k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666117965.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.rstats", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For example, I want to run an Anova test. &lt;/p&gt;\n\n&lt;p&gt;Do I need to check if the data qualifies all assumptions?&lt;/p&gt;\n\n&lt;p&gt;What do I do when the data does not fulfill any of the assumptions? &lt;/p&gt;\n\n&lt;p&gt;What is the best way to confirm a normal distribution before such tests? Is a qqplot good enough?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r8n0", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7ex5k", "is_robot_indexable": true, "report_reasons": null, "author": "1SageK1", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/rstats/comments/y7ex5k/assumptions_before_performing_tests/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/rstats/comments/y7ex5k/assumptions_before_performing_tests/", "subreddit_subscribers": 67759, "created_utc": 1666117965.0, "num_crossposts": 3, "media": null, "is_video": false}], "created": 1666177732.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.rstats", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/rstats/comments/y7ex5k/assumptions_before_performing_tests/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7zsrk", "is_robot_indexable": true, "report_reasons": null, "author": "1SageK1", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_y7ex5k", "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7zsrk/assumptions_before_performing_tests/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/rstats/comments/y7ex5k/assumptions_before_performing_tests/", "subreddit_subscribers": 814313, "created_utc": 1666177732.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm working on a project to learn \"to think\" about the problem in a Data Science way; this is because I've mostly done coding and usually machine learning, but nothing focused on problems, so I started one.\n\n&amp;#x200B;\n\nIn this problem, I need to figure out which companies are more likely to grow in the future by looking at some of their data which says how long they've been operating vs. how big they are. I have all this data and...I'm struggling to come up with a path ahead. A friend of mine suggested using random forests and classifying them (since it's categorical data: time being \"first period, second period, etc.\" and their \"growth\" is measured as \"new, middle, big\") however, I am unsure how to do this. \n\n&amp;#x200B;\n\nI did do the random forest and got some values, but they're giving me, as expected, a result like:\n\n&amp;#x200B;\n\n    Company 1 - random forest: 0.98, growth: new, time: second_period\"\n\nWhich...upon looking at it, means nothing to me. I'm unsure about how to go about doing this, I used to do this a few years ago, but ever since I moved to language models and other such things, I feel like I'm super rusty and not even sure where to go from here...could you please help me out? At least how should I be thinking about the problem", "author_fullname": "t2_3lnrl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Not sure if I'm doing the right thing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7jzbv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666129740.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on a project to learn &amp;quot;to think&amp;quot; about the problem in a Data Science way; this is because I&amp;#39;ve mostly done coding and usually machine learning, but nothing focused on problems, so I started one.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;In this problem, I need to figure out which companies are more likely to grow in the future by looking at some of their data which says how long they&amp;#39;ve been operating vs. how big they are. I have all this data and...I&amp;#39;m struggling to come up with a path ahead. A friend of mine suggested using random forests and classifying them (since it&amp;#39;s categorical data: time being &amp;quot;first period, second period, etc.&amp;quot; and their &amp;quot;growth&amp;quot; is measured as &amp;quot;new, middle, big&amp;quot;) however, I am unsure how to do this. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I did do the random forest and got some values, but they&amp;#39;re giving me, as expected, a result like:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Company 1 - random forest: 0.98, growth: new, time: second_period&amp;quot;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Which...upon looking at it, means nothing to me. I&amp;#39;m unsure about how to go about doing this, I used to do this a few years ago, but ever since I moved to language models and other such things, I feel like I&amp;#39;m super rusty and not even sure where to go from here...could you please help me out? At least how should I be thinking about the problem&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7jzbv", "is_robot_indexable": true, "report_reasons": null, "author": "Proxify", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7jzbv/not_sure_if_im_doing_the_right_thing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7jzbv/not_sure_if_im_doing_the_right_thing/", "subreddit_subscribers": 814313, "created_utc": 1666129740.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have an interview coming up where I was given data and asked to do an EDA and create classification models. That part was easy for me as it is my bread and butter and what I enjoy doing. However, for the interview I have to create a presentation with my EDA, summary of my work and final recommendations. The presentation audience is marketing strategists for the company. I have very limited experience doing these types of presentations. Does anyone with experience doing this type of thing have advice on the best way to present my work? \n\nI used Jupyter notebook for everything if that is relevant. Thanks in advance for any help/advice offered!", "author_fullname": "t2_4vipyddb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to present EDA and models to non-technical audience?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7bem7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666109848.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an interview coming up where I was given data and asked to do an EDA and create classification models. That part was easy for me as it is my bread and butter and what I enjoy doing. However, for the interview I have to create a presentation with my EDA, summary of my work and final recommendations. The presentation audience is marketing strategists for the company. I have very limited experience doing these types of presentations. Does anyone with experience doing this type of thing have advice on the best way to present my work? &lt;/p&gt;\n\n&lt;p&gt;I used Jupyter notebook for everything if that is relevant. Thanks in advance for any help/advice offered!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7bem7", "is_robot_indexable": true, "report_reasons": null, "author": "bballerkt7", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7bem7/how_to_present_eda_and_models_to_nontechnical/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7bem7/how_to_present_eda_and_models_to_nontechnical/", "subreddit_subscribers": 814313, "created_utc": 1666109848.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "1. Install the `opendatasets` library\n\n       '''A Python library for downloading datasets from Kaggle, Google Drive, and \n          other online sources'''\n\n2. Use the `opendatasets.download` helper function.\n3. Get Kaggle Credentials.\n\n          * Download `Kaggle.json` file.\n\n          * Enter your user name and Kaggle API or store the `Kaggle.json` file in \n            the same directory with the Jupyter notebook. \n\n4. Query the directory where the dataset has been downloaded to using the OS Module. \n\n          * The module comes as a Python standard utility Module.\n\n# Import the OS module\n\n'''\nIt helps with querying the directory where the dataset has been downloaded to;\n\n - That is done by interacting with the underlying operating system \n\n \nWith the OS module one can;\n\n * create and remove a folder(directory). \n * Fetch the contents of a directory.\n * Change and identifying the current directory among other operations.\n \n '''\n\nOpen the downloaded dataset(CSV/EXCEL) using python's pandas library.\n\n[Reference and Further Reading](https://www.youtube.com/watch?v=7Jgur9q2ZVk)", "author_fullname": "t2_60pa85jj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to download Kaggle datasets using opendatasets simple python command.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y816ut", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666186195.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666181851.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Install the &lt;code&gt;opendatasets&lt;/code&gt; library&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;&amp;#39;&amp;#39;A Python library for downloading datasets from Kaggle, Google Drive, and \n      other online sources&amp;#39;&amp;#39;&amp;#39;&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Use the &lt;code&gt;opendatasets.download&lt;/code&gt; helper function.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Get Kaggle Credentials.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;  * Download `Kaggle.json` file.\n\n  * Enter your user name and Kaggle API or store the `Kaggle.json` file in \n    the same directory with the Jupyter notebook. \n&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Query the directory where the dataset has been downloaded to using the OS Module. &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;  * The module comes as a Python standard utility Module.\n&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;h1&gt;Import the OS module&lt;/h1&gt;\n\n&lt;p&gt;&amp;#39;&amp;#39;&amp;#39;\nIt helps with querying the directory where the dataset has been downloaded to;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;That is done by interacting with the underlying operating system &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;With the OS module one can;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;create and remove a folder(directory). &lt;/li&gt;\n&lt;li&gt;Fetch the contents of a directory.&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Change and identifying the current directory among other operations.&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Open the downloaded dataset(CSV/EXCEL) using python&amp;#39;s pandas library.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=7Jgur9q2ZVk\"&gt;Reference and Further Reading&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/uOt_PD-7hHV4IoD7E1K_kDSMWBm0W77znOmibU3MvrY.jpg?auto=webp&amp;s=0e258a4e50cd6a14216e47ebef0cb84d05e1d4fb", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/uOt_PD-7hHV4IoD7E1K_kDSMWBm0W77znOmibU3MvrY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d4efd34e5b617aea08faa8b305d3701a3d215887", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/uOt_PD-7hHV4IoD7E1K_kDSMWBm0W77znOmibU3MvrY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=518eb66e09878731c3fe0cf9e46903dfa13bb41d", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/uOt_PD-7hHV4IoD7E1K_kDSMWBm0W77znOmibU3MvrY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=05b9309ee35587cc75f04fb8c67ef60667984fa0", "width": 320, "height": 240}], "variants": {}, "id": "kshlJzmXaPkxCanmARcF44TdJFeYOfTCssWYMRQGXyE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y816ut", "is_robot_indexable": true, "report_reasons": null, "author": "SOTP_", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y816ut/how_to_download_kaggle_datasets_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y816ut/how_to_download_kaggle_datasets_using/", "subreddit_subscribers": 814313, "created_utc": 1666181851.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}