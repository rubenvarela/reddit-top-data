{"kind": "Listing", "data": {"after": "t3_y816ut", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_4tczv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "every time I hear someone say num-pee i die a little bit", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "meta", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_y7ycxz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 270, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meta", "can_mod_post": false, "score": 270, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/8ifUPQbWM946tcFz4Vg7wIPw5tcMaSuMpDdLm9qyyXo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666173070.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/aylc75laiqu91.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/aylc75laiqu91.png?auto=webp&amp;s=811d064f28c698d46d822b83b6b0e59ba36cf0ff", "width": 225, "height": 225}, "resolutions": [{"url": "https://preview.redd.it/aylc75laiqu91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=28c0ec8e54a7859652b0dc689287cd5298e7dec4", "width": 108, "height": 108}, {"url": "https://preview.redd.it/aylc75laiqu91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d9956e566ba76b8eec221428731f7170c360c21e", "width": 216, "height": 216}], "variants": {}, "id": "mXRYaAVfSayNzyW4E87Hes-sLP2gVI-6dqexq2_QSsc"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7ycxz", "is_robot_indexable": true, "report_reasons": null, "author": "MAFiA303", "discussion_type": null, "num_comments": 77, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7ycxz/every_time_i_hear_someone_say_numpee_i_die_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/aylc75laiqu91.png", "subreddit_subscribers": 814349, "created_utc": 1666173070.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_amfdjuba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Q] Based on your experience why does adding so many input features possibly worsen your models?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7kizv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 88, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 88, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666131032.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7kizv", "is_robot_indexable": true, "report_reasons": null, "author": "limedove", "discussion_type": null, "num_comments": 51, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7kizv/q_based_on_your_experience_why_does_adding_so/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7kizv/q_based_on_your_experience_why_does_adding_so/", "subreddit_subscribers": 814349, "created_utc": 1666131032.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Maybe anyone has faced this issue before, I am investigating if there are clusters of users based on number of particular actions they took. Users have different lifespans in the system so time series have variable lengths, in addition some users only take certain actions which uncorrelated with their time spent in the system. I am looking at Dynamic Time Warping, but the problem of short time series for some users and sparse feature makes it seem like inappropriate solution. Any recommendations?", "author_fullname": "t2_daczn1t9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the recommended modeling approaches for clustering of several Multivariate Timeseries data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7kupq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666131823.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Maybe anyone has faced this issue before, I am investigating if there are clusters of users based on number of particular actions they took. Users have different lifespans in the system so time series have variable lengths, in addition some users only take certain actions which uncorrelated with their time spent in the system. I am looking at Dynamic Time Warping, but the problem of short time series for some users and sparse feature makes it seem like inappropriate solution. Any recommendations?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7kupq", "is_robot_indexable": true, "report_reasons": null, "author": "neural_net_ork", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7kupq/what_are_the_recommended_modeling_approaches_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7kupq/what_are_the_recommended_modeling_approaches_for/", "subreddit_subscribers": 814349, "created_utc": 1666131823.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In the spring I will be teaching the first Data Analytics class ever taught at my university. This class will be focusing on data visualization and communication. I have my textbooks and my class plan already, but I wanted to pose a question to you all. Is there something you wished you learned in your data visualization class that was not taught?", "author_fullname": "t2_lydp1nun", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Teaching a Data Analytics Class", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7r1hx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666148583.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In the spring I will be teaching the first Data Analytics class ever taught at my university. This class will be focusing on data visualization and communication. I have my textbooks and my class plan already, but I wanted to pose a question to you all. Is there something you wished you learned in your data visualization class that was not taught?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7r1hx", "is_robot_indexable": true, "report_reasons": null, "author": "Newd_Librarian", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7r1hx/teaching_a_data_analytics_class/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7r1hx/teaching_a_data_analytics_class/", "subreddit_subscribers": 814349, "created_utc": 1666148583.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "[https://doordash.engineering/2022/10/18/augmenting-fuzzy-matching-with-human-review-to-maximize-precision-and-recall/](https://doordash.engineering/2022/10/18/augmenting-fuzzy-matching-with-human-review-to-maximize-precision-and-recall/)\n\nI recently solved a business problem at DoorDash: we needed a way to onboard new advertisers (brands that sell products at convenience/grocery stores) at scale, without having to manually identify all their products that are available on DoorDash. We used a fuzzy-matching classifier with a human in the loop.\n\nThe part I find the most interesting is how we were able to take an out-of-the-box fuzzy matching algorithm and \u2013 with relatively little technical effort \u2013 tweak it to improve precision and recall. See table toward the end of the piece.\n\nComment away, either here or on the post itself!", "author_fullname": "t2_5kfet", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DoorDash Eng Blog: Augmenting fuzzy matching with human review to maximize precision and recall", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7nl7s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666138929.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://doordash.engineering/2022/10/18/augmenting-fuzzy-matching-with-human-review-to-maximize-precision-and-recall/\"&gt;https://doordash.engineering/2022/10/18/augmenting-fuzzy-matching-with-human-review-to-maximize-precision-and-recall/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I recently solved a business problem at DoorDash: we needed a way to onboard new advertisers (brands that sell products at convenience/grocery stores) at scale, without having to manually identify all their products that are available on DoorDash. We used a fuzzy-matching classifier with a human in the loop.&lt;/p&gt;\n\n&lt;p&gt;The part I find the most interesting is how we were able to take an out-of-the-box fuzzy matching algorithm and \u2013 with relatively little technical effort \u2013 tweak it to improve precision and recall. See table toward the end of the piece.&lt;/p&gt;\n\n&lt;p&gt;Comment away, either here or on the post itself!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7nl7s", "is_robot_indexable": true, "report_reasons": null, "author": "chikinn", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7nl7s/doordash_eng_blog_augmenting_fuzzy_matching_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7nl7s/doordash_eng_blog_augmenting_fuzzy_matching_with/", "subreddit_subscribers": 814349, "created_utc": 1666138929.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am confused on how to build my portfolio or even what platforms to use.  I\u2019ve been overwhelmed and trying to find answers about this without much luck. \n\nIf I\u2019m trying to showcase SQL, R, Python, tableau and Microsoft excel, what are the best platforms and strategies for going about this?\n\nEdit: I\u2019m transitioning into data analysis", "author_fullname": "t2_t1en7quk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Structure Portfolio", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7u9ky", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666158466.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am confused on how to build my portfolio or even what platforms to use.  I\u2019ve been overwhelmed and trying to find answers about this without much luck. &lt;/p&gt;\n\n&lt;p&gt;If I\u2019m trying to showcase SQL, R, Python, tableau and Microsoft excel, what are the best platforms and strategies for going about this?&lt;/p&gt;\n\n&lt;p&gt;Edit: I\u2019m transitioning into data analysis&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7u9ky", "is_robot_indexable": true, "report_reasons": null, "author": "SeaRocks10", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7u9ky/how_to_structure_portfolio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7u9ky/how_to_structure_portfolio/", "subreddit_subscribers": 814349, "created_utc": 1666158466.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm guessing most of you have heard the world war II era story used to illustrate survivorship bias. If not, it's featured on the wikipedia page: [https://en.wikipedia.org/wiki/Survivorship\\_bias](https://en.wikipedia.org/wiki/Survivorship_bias)\n\nOther than that, there are many other biases/paradoxes/pitfalls than the non-statistically minded might fall into. A decent list can be found here: [https://stats.stackexchange.com/questions/23779/most-interesting-statistical-paradoxes/592495#592495](https://stats.stackexchange.com/questions/23779/most-interesting-statistical-paradoxes/592495#592495)\n\nSome were inspired by historical failures (e.g. the survivorship bias again) but others seem to have started more as brain teasers. [https://en.wikipedia.org/wiki/Sleeping\\_Beauty\\_problem](https://en.wikipedia.org/wiki/Sleeping_Beauty_problem)\n\nAdditional, some are fairly easy to come across (Simpson's paradox is applicable to a lot of real world data) whereas others might be more niche.\n\nRegardless, I would say that the thing all of these examples have in common is basically:\n\n*There appears to be an obvious answer/interpretation, but that answer/interpretation is either not a sure thing or the correct answer/interpretation is in blatant contradiction to the obvious answer.*\n\nBy that definition, has anything like this come up on the job?", "author_fullname": "t2_s47x31rw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Paradoxes (or at least pitfalls) on the job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7omp4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666142023.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666141803.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m guessing most of you have heard the world war II era story used to illustrate survivorship bias. If not, it&amp;#39;s featured on the wikipedia page: &lt;a href=\"https://en.wikipedia.org/wiki/Survivorship_bias\"&gt;https://en.wikipedia.org/wiki/Survivorship_bias&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Other than that, there are many other biases/paradoxes/pitfalls than the non-statistically minded might fall into. A decent list can be found here: &lt;a href=\"https://stats.stackexchange.com/questions/23779/most-interesting-statistical-paradoxes/592495#592495\"&gt;https://stats.stackexchange.com/questions/23779/most-interesting-statistical-paradoxes/592495#592495&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Some were inspired by historical failures (e.g. the survivorship bias again) but others seem to have started more as brain teasers. &lt;a href=\"https://en.wikipedia.org/wiki/Sleeping_Beauty_problem\"&gt;https://en.wikipedia.org/wiki/Sleeping_Beauty_problem&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Additional, some are fairly easy to come across (Simpson&amp;#39;s paradox is applicable to a lot of real world data) whereas others might be more niche.&lt;/p&gt;\n\n&lt;p&gt;Regardless, I would say that the thing all of these examples have in common is basically:&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;There appears to be an obvious answer/interpretation, but that answer/interpretation is either not a sure thing or the correct answer/interpretation is in blatant contradiction to the obvious answer.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;By that definition, has anything like this come up on the job?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/a1DhEZ4c4gmsM5mqKxahsd-VvK5lheeFUccaBLODQ5k.jpg?auto=webp&amp;s=8e886a7d7b52e99c00fb213bfb8130938ee2b2a4", "width": 1200, "height": 894}, "resolutions": [{"url": "https://external-preview.redd.it/a1DhEZ4c4gmsM5mqKxahsd-VvK5lheeFUccaBLODQ5k.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a6fc2d9acd533989d7d6c71fb702626994cc8a42", "width": 108, "height": 80}, {"url": "https://external-preview.redd.it/a1DhEZ4c4gmsM5mqKxahsd-VvK5lheeFUccaBLODQ5k.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=77c6e6c880e7741ea362b3770253ffc7ca1f1af7", "width": 216, "height": 160}, {"url": "https://external-preview.redd.it/a1DhEZ4c4gmsM5mqKxahsd-VvK5lheeFUccaBLODQ5k.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bc6b40a946b177471c5024f1063879f0a898249c", "width": 320, "height": 238}, {"url": "https://external-preview.redd.it/a1DhEZ4c4gmsM5mqKxahsd-VvK5lheeFUccaBLODQ5k.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=dc782b33b53cdaeb2174d372a76c2b613cd7aa67", "width": 640, "height": 476}, {"url": "https://external-preview.redd.it/a1DhEZ4c4gmsM5mqKxahsd-VvK5lheeFUccaBLODQ5k.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=cd99878f734a1fed6b0fbc3dcc94c4c71caf1cad", "width": 960, "height": 715}, {"url": "https://external-preview.redd.it/a1DhEZ4c4gmsM5mqKxahsd-VvK5lheeFUccaBLODQ5k.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c74213b7277cfa3202d33b09fbf6c52f7ee8dab5", "width": 1080, "height": 804}], "variants": {}, "id": "SNQxXIF511m-ex3iNlA-2c78ApiWKGIXo6QtamSh1qY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7omp4", "is_robot_indexable": true, "report_reasons": null, "author": "Western-Elevator-456", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7omp4/paradoxes_or_at_least_pitfalls_on_the_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7omp4/paradoxes_or_at_least_pitfalls_on_the_job/", "subreddit_subscribers": 814349, "created_utc": 1666141803.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Currently I use DataViz and was wondering if there was something similar,  one with a nice wizard, convenient table filtering, and schemas, but with Git integration and allows for you to work in other coding languages like Python too. \n\nI\u2019m currently looking into DBeaver. I\u2019m pretty new to all of this so sorry if this post isn\u2019t worded too well. Thanks in advance!", "author_fullname": "t2_11re2h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which IDE would be best for PostgreSQL and python?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7i8ju", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666125713.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently I use DataViz and was wondering if there was something similar,  one with a nice wizard, convenient table filtering, and schemas, but with Git integration and allows for you to work in other coding languages like Python too. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m currently looking into DBeaver. I\u2019m pretty new to all of this so sorry if this post isn\u2019t worded too well. Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7i8ju", "is_robot_indexable": true, "report_reasons": null, "author": "proudaggie", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7i8ju/which_ide_would_be_best_for_postgresql_and_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7i8ju/which_ide_would_be_best_for_postgresql_and_python/", "subreddit_subscribers": 814349, "created_utc": 1666125713.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Do you link to your Kaggle? Or perhaps your Github, which contains the underlying .ipynb files? I want to make sure I\u2019m communicating my work in a way that aligns with how other data science practitioners do it. \n\nThanks for your input!", "author_fullname": "t2_ceqh7wvy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you present your portfolio on LinkedIn?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_y87smb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666198209.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you link to your Kaggle? Or perhaps your Github, which contains the underlying .ipynb files? I want to make sure I\u2019m communicating my work in a way that aligns with how other data science practitioners do it. &lt;/p&gt;\n\n&lt;p&gt;Thanks for your input!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "y87smb", "is_robot_indexable": true, "report_reasons": null, "author": "boston_acc", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y87smb/how_do_you_present_your_portfolio_on_linkedin/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y87smb/how_do_you_present_your_portfolio_on_linkedin/", "subreddit_subscribers": 814349, "created_utc": 1666198209.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello!\n\nDo you belong to any other *active* Data Science or Data related communities? Whether that is on Reddit, Discord, a forum?\n\nThe Discord channels that I belong to are really quiet. It would be good to spread my wings a little wider.", "author_fullname": "t2_9k8sa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Other Active Data Science-Related Communities?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7ly78", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666134603.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;Do you belong to any other &lt;em&gt;active&lt;/em&gt; Data Science or Data related communities? Whether that is on Reddit, Discord, a forum?&lt;/p&gt;\n\n&lt;p&gt;The Discord channels that I belong to are really quiet. It would be good to spread my wings a little wider.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7ly78", "is_robot_indexable": true, "report_reasons": null, "author": "MrMadium", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7ly78/other_active_data_sciencerelated_communities/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7ly78/other_active_data_sciencerelated_communities/", "subreddit_subscribers": 814349, "created_utc": 1666134603.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have weather data from stations across the US but of course this data corresponds to single lat/lon coordinates whereas I'd like data at every coordinate across the entire US. Thus, I'm going to need to do some sort of spatial interpolation (or similar).\n\nI've read that krigging (Gaussian Process Regression) is often used for spatial interpolation though I can't see the benefit over something like KNN if I'm not going to be using the uncertainty estimate it comes with. Krigging is very computationally expensive and explaining the theory behind it is difficult at best. Neglecting uncertainty quantification since it won't be used, is the main advantage  properly designed mean and covariance functions in which the model reverts back to in the areas far from data points?", "author_fullname": "t2_91itiala", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Krigging for Spatial Interpolation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7hwfm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666124931.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have weather data from stations across the US but of course this data corresponds to single lat/lon coordinates whereas I&amp;#39;d like data at every coordinate across the entire US. Thus, I&amp;#39;m going to need to do some sort of spatial interpolation (or similar).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve read that krigging (Gaussian Process Regression) is often used for spatial interpolation though I can&amp;#39;t see the benefit over something like KNN if I&amp;#39;m not going to be using the uncertainty estimate it comes with. Krigging is very computationally expensive and explaining the theory behind it is difficult at best. Neglecting uncertainty quantification since it won&amp;#39;t be used, is the main advantage  properly designed mean and covariance functions in which the model reverts back to in the areas far from data points?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7hwfm", "is_robot_indexable": true, "report_reasons": null, "author": "MGeeeeeezy", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7hwfm/krigging_for_spatial_interpolation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7hwfm/krigging_for_spatial_interpolation/", "subreddit_subscribers": 814349, "created_utc": 1666124931.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nHi mates\n\nI hope you are doing well.\n\nWould you please tell me the **difference between** the ***Retention*** and the ***Propensity*** models?  \nAs I understand, the propensity model has three types: **Propensity to buy**, **Propensity to churn**, and **Propensity to unsubscribe**.\n\nIs the **retention model** the same as the **propensity to churn**?\n\nThank you in advance", "author_fullname": "t2_8otyl3bx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Difference between Propensity model and Retention model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7ymoz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666173922.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi mates&lt;/p&gt;\n\n&lt;p&gt;I hope you are doing well.&lt;/p&gt;\n\n&lt;p&gt;Would you please tell me the &lt;strong&gt;difference between&lt;/strong&gt; the &lt;strong&gt;&lt;em&gt;Retention&lt;/em&gt;&lt;/strong&gt; and the &lt;strong&gt;&lt;em&gt;Propensity&lt;/em&gt;&lt;/strong&gt; models?&lt;br/&gt;\nAs I understand, the propensity model has three types: &lt;strong&gt;Propensity to buy&lt;/strong&gt;, &lt;strong&gt;Propensity to churn&lt;/strong&gt;, and &lt;strong&gt;Propensity to unsubscribe&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;Is the &lt;strong&gt;retention model&lt;/strong&gt; the same as the &lt;strong&gt;propensity to churn&lt;/strong&gt;?&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7ymoz", "is_robot_indexable": true, "report_reasons": null, "author": "Masoud_mirza", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7ymoz/difference_between_propensity_model_and_retention/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7ymoz/difference_between_propensity_model_and_retention/", "subreddit_subscribers": 814349, "created_utc": 1666173922.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\nAs a DA expecting offers for both roles, Analytics Engineer and Data Scientist Product Analytics, I was wondering how the community viewed each role?\n\nIs one harder to break into? Does one generally lead to better opportunities down the road? Is pay expected to be higher for one vs the other (I\u2019m expecting similar based on recruiter conversation)? Is one more or less \u2018future proof\u2019?\n\n\u200b\n\nI think I know which one I would be a more natural fit for but I\u2019m curious about the perception of the roles from others in the industry.", "author_fullname": "t2_1oj5wdu2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\u201cBetter\u201d career? AE vs DS product", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7pean", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666143921.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a DA expecting offers for both roles, Analytics Engineer and Data Scientist Product Analytics, I was wondering how the community viewed each role?&lt;/p&gt;\n\n&lt;p&gt;Is one harder to break into? Does one generally lead to better opportunities down the road? Is pay expected to be higher for one vs the other (I\u2019m expecting similar based on recruiter conversation)? Is one more or less \u2018future proof\u2019?&lt;/p&gt;\n\n&lt;p&gt;\u200b&lt;/p&gt;\n\n&lt;p&gt;I think I know which one I would be a more natural fit for but I\u2019m curious about the perception of the roles from others in the industry.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7pean", "is_robot_indexable": true, "report_reasons": null, "author": "bigfeller2", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7pean/better_career_ae_vs_ds_product/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7pean/better_career_ae_vs_ds_product/", "subreddit_subscribers": 814349, "created_utc": 1666143921.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Im using the `refresh_token` &gt; `fetch new access_token` &gt; `make request` flow to fetch json data from Xero. \n\nBut for some reason providing the same tokens and credentials to tap-xero's config.json returns `tap_xero.client.XeroNotFoundError: HTTP-error-code: 404, Error: The resource you have specified cannot be found.`\n\nThe command args are: `tap-xero -c config.json -d &gt; cat.json`\n\nSinger's documentation is really lacking for their dedicated taps.", "author_fullname": "t2_n732f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone used Singer's tap-xero to fetch Xero data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_y89cok", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666201883.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im using the &lt;code&gt;refresh_token&lt;/code&gt; &amp;gt; &lt;code&gt;fetch new access_token&lt;/code&gt; &amp;gt; &lt;code&gt;make request&lt;/code&gt; flow to fetch json data from Xero. &lt;/p&gt;\n\n&lt;p&gt;But for some reason providing the same tokens and credentials to tap-xero&amp;#39;s config.json returns &lt;code&gt;tap_xero.client.XeroNotFoundError: HTTP-error-code: 404, Error: The resource you have specified cannot be found.&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;The command args are: &lt;code&gt;tap-xero -c config.json -d &amp;gt; cat.json&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;Singer&amp;#39;s documentation is really lacking for their dedicated taps.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y89cok", "is_robot_indexable": true, "report_reasons": null, "author": "buckypimpin", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y89cok/has_anyone_used_singers_tapxero_to_fetch_xero_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y89cok/has_anyone_used_singers_tapxero_to_fetch_xero_data/", "subreddit_subscribers": 814349, "created_utc": 1666201883.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, I have been trying to scrap the school schedule (for obvious reasons, of course). And so far, I saw coursicle claims that they get the data from \"Smith's public listing course\". I've tried to find it but no use, then I found a reddit post from the cofounder of coursicle himself saying that he ping the school gateway ([https://www.reddit.com/r/gatech/comments/r0datq/where\\_does\\_coursicle\\_get\\_its\\_class\\_seats\\_data\\_from/](https://www.reddit.com/r/gatech/comments/r0datq/where_does_coursicle_get_its_class_seats_data_from/)). I'm not sure whether I understand his idea right, but I can't find any way to access my school schedule without actually have to login in, which is a big deal when employ bot to server. So do you have any suggestion, or have any source that has college's courses available publicly, please let me know. Thank you\n\nhttps://preview.redd.it/m23sd3e6ssu91.png?width=907&amp;format=png&amp;auto=webp&amp;s=288959bf76d09287f908b4b019fa0890756c9c51", "author_fullname": "t2_eo1lh8sj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Public College schedule from Coursicle", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 16, "top_awarded_type": null, "hide_score": true, "media_metadata": {"m23sd3e6ssu91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 12, "x": 108, "u": "https://preview.redd.it/m23sd3e6ssu91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6f035c5a7fe36151c0497efd5b4c7266ba7bca5b"}, {"y": 25, "x": 216, "u": "https://preview.redd.it/m23sd3e6ssu91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f49e3225bd5cb82be7a0e1662a497a2cf33116ad"}, {"y": 38, "x": 320, "u": "https://preview.redd.it/m23sd3e6ssu91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=503a99350e3bfa9efeebe99f181cd505f09d7f4a"}, {"y": 76, "x": 640, "u": "https://preview.redd.it/m23sd3e6ssu91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=db7ff2816c4a6a1220dfbba36873020eb55aa599"}], "s": {"y": 109, "x": 907, "u": "https://preview.redd.it/m23sd3e6ssu91.png?width=907&amp;format=png&amp;auto=webp&amp;s=288959bf76d09287f908b4b019fa0890756c9c51"}, "id": "m23sd3e6ssu91"}}, "name": "t3_y88uyt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/-A-f9IFIg2xrA82oOkM5O_ESc1W53HXKOTUR4W59Z2A.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666200713.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I have been trying to scrap the school schedule (for obvious reasons, of course). And so far, I saw coursicle claims that they get the data from &amp;quot;Smith&amp;#39;s public listing course&amp;quot;. I&amp;#39;ve tried to find it but no use, then I found a reddit post from the cofounder of coursicle himself saying that he ping the school gateway (&lt;a href=\"https://www.reddit.com/r/gatech/comments/r0datq/where_does_coursicle_get_its_class_seats_data_from/\"&gt;https://www.reddit.com/r/gatech/comments/r0datq/where_does_coursicle_get_its_class_seats_data_from/&lt;/a&gt;). I&amp;#39;m not sure whether I understand his idea right, but I can&amp;#39;t find any way to access my school schedule without actually have to login in, which is a big deal when employ bot to server. So do you have any suggestion, or have any source that has college&amp;#39;s courses available publicly, please let me know. Thank you&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/m23sd3e6ssu91.png?width=907&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=288959bf76d09287f908b4b019fa0890756c9c51\"&gt;https://preview.redd.it/m23sd3e6ssu91.png?width=907&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=288959bf76d09287f908b4b019fa0890756c9c51&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y88uyt", "is_robot_indexable": true, "report_reasons": null, "author": "PiccoloStreet3002", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y88uyt/public_college_schedule_from_coursicle/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y88uyt/public_college_schedule_from_coursicle/", "subreddit_subscribers": 814349, "created_utc": 1666200713.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello all! \n\nI've been pretty excited reading about all the advancements in LLMs over the years but never took the time to dip my toes in. I'm also a PC gamer and waited until the gpu market dipped a bit to finally buy a RTX3080 and figured might as well get into some hobbyist ML/deep learning experimentation with a new GPU with so many CUDA cores. \n\nI'm aware its still nothing in comparison to an A100 or the like and that I might still be fairly limited working with any LLM, but wondering if anyone has any experience, tips or guidance on what's possible without a multi-gpu at-home setup, like what's the biggest model one could play with on a single 3080, what to expect in terms of process time per token, the biggest feasible model one could or should use to fine tune on a closed domain dataset, etc. \n\nIf I'm being completely unrealistic in even attempting to fine-tune an LLM locally, please also feel free to clear me of any dilusions. \n\nRegardless, it's still so fascinating to see all the developments in the space happening so quickly. This is a super exciting time we're living in, and hopefully these kinds of technologies will be more accessible to hobbyists as they're developed to require less compute and consume less energy.\n\nThanks in advance for any guidance!", "author_fullname": "t2_5z0my9eb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "At-home LLM experimentation questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_y87bub", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666197106.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all! &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been pretty excited reading about all the advancements in LLMs over the years but never took the time to dip my toes in. I&amp;#39;m also a PC gamer and waited until the gpu market dipped a bit to finally buy a RTX3080 and figured might as well get into some hobbyist ML/deep learning experimentation with a new GPU with so many CUDA cores. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m aware its still nothing in comparison to an A100 or the like and that I might still be fairly limited working with any LLM, but wondering if anyone has any experience, tips or guidance on what&amp;#39;s possible without a multi-gpu at-home setup, like what&amp;#39;s the biggest model one could play with on a single 3080, what to expect in terms of process time per token, the biggest feasible model one could or should use to fine tune on a closed domain dataset, etc. &lt;/p&gt;\n\n&lt;p&gt;If I&amp;#39;m being completely unrealistic in even attempting to fine-tune an LLM locally, please also feel free to clear me of any dilusions. &lt;/p&gt;\n\n&lt;p&gt;Regardless, it&amp;#39;s still so fascinating to see all the developments in the space happening so quickly. This is a super exciting time we&amp;#39;re living in, and hopefully these kinds of technologies will be more accessible to hobbyists as they&amp;#39;re developed to require less compute and consume less energy.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for any guidance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y87bub", "is_robot_indexable": true, "report_reasons": null, "author": "smarthaiti", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y87bub/athome_llm_experimentation_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y87bub/athome_llm_experimentation_questions/", "subreddit_subscribers": 814349, "created_utc": 1666197106.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Dear fellow smart data expert \n\nI\u2019m working on this Ubereats project to measure/determine restaurant\u2019s success through these variables \nI\u2019ve these variables (restaurant ratings 1-6) ,(restaurant ratings count 1-7k) , (food hygiene ratings 1-5) (daily deals %) (spend $ )  (delivery fees $)\n\nWhat confuse me most is some restaurants have high ratings with low ratings counts \n\nCan\u2019t think further from this \n\nHelp \n\nThanks", "author_fullname": "t2_6ku703xx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I determine if a restaurant is doing well through these variables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_y87aea", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666197013.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dear fellow smart data expert &lt;/p&gt;\n\n&lt;p&gt;I\u2019m working on this Ubereats project to measure/determine restaurant\u2019s success through these variables \nI\u2019ve these variables (restaurant ratings 1-6) ,(restaurant ratings count 1-7k) , (food hygiene ratings 1-5) (daily deals %) (spend $ )  (delivery fees $)&lt;/p&gt;\n\n&lt;p&gt;What confuse me most is some restaurants have high ratings with low ratings counts &lt;/p&gt;\n\n&lt;p&gt;Can\u2019t think further from this &lt;/p&gt;\n\n&lt;p&gt;Help &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y87aea", "is_robot_indexable": true, "report_reasons": null, "author": "Street-Target9245", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y87aea/how_can_i_determine_if_a_restaurant_is_doing_well/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y87aea/how_can_i_determine_if_a_restaurant_is_doing_well/", "subreddit_subscribers": 814349, "created_utc": 1666197013.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have some mixed data that I thought I'd first transform into embeddings and then cluster the embedding. However, since I'm clustering embeddings does that mean that I'm going to lose all interpretability of the clusters? I know there's some loss of interpreability when using embeddings but I'm not clear on what the degree of that loss is. Anyone care to clarify?", "author_fullname": "t2_5ox025vb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Clustering embeddings", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y82y0u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666186559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have some mixed data that I thought I&amp;#39;d first transform into embeddings and then cluster the embedding. However, since I&amp;#39;m clustering embeddings does that mean that I&amp;#39;m going to lose all interpretability of the clusters? I know there&amp;#39;s some loss of interpreability when using embeddings but I&amp;#39;m not clear on what the degree of that loss is. Anyone care to clarify?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y82y0u", "is_robot_indexable": true, "report_reasons": null, "author": "SomaDomaBoma", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y82y0u/clustering_embeddings/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y82y0u/clustering_embeddings/", "subreddit_subscribers": 814349, "created_utc": 1666186559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "hello,\n\nI'm planning on using the shortened version of the [schwartz value survey](https://www.framevoicereport.org/media/1093/the-short-schwartzs-value-survey.pdf) (SSVS) in my master's thesis. there are 10 basic human values and participants rate each of them on a likert-scale (0 to 8). I will later relate this survey data to some behavior of the participants *(like \"participants who value conformity behave like this\")* \\-but, I am completely lost on how to analyze the survey data. I guess I need to create a score for each participant, but is it possible? or logical? *(values have a circumplex structure -each value is similar to one other while also being the opposite of another. so yielding just one score per individual seems like it wouldn't make sense? like they would cancel each other out somehow? i don't know)*\n\nusing factor analysis, the 10 values can be reduced into a couple (?) of dimensions (I guess). but would that lead to a score? or a score with two dimensions (like a point coordinate in xy-axis)? \n\ndoes anybody have any clue? help.........please?", "author_fullname": "t2_664rqg0i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "schwartz value survey -analysis", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y800ys", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666178445.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hello,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m planning on using the shortened version of the &lt;a href=\"https://www.framevoicereport.org/media/1093/the-short-schwartzs-value-survey.pdf\"&gt;schwartz value survey&lt;/a&gt; (SSVS) in my master&amp;#39;s thesis. there are 10 basic human values and participants rate each of them on a likert-scale (0 to 8). I will later relate this survey data to some behavior of the participants &lt;em&gt;(like &amp;quot;participants who value conformity behave like this&amp;quot;)&lt;/em&gt; -but, I am completely lost on how to analyze the survey data. I guess I need to create a score for each participant, but is it possible? or logical? &lt;em&gt;(values have a circumplex structure -each value is similar to one other while also being the opposite of another. so yielding just one score per individual seems like it wouldn&amp;#39;t make sense? like they would cancel each other out somehow? i don&amp;#39;t know)&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;using factor analysis, the 10 values can be reduced into a couple (?) of dimensions (I guess). but would that lead to a score? or a score with two dimensions (like a point coordinate in xy-axis)? &lt;/p&gt;\n\n&lt;p&gt;does anybody have any clue? help.........please?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y800ys", "is_robot_indexable": true, "report_reasons": null, "author": "cauliflowingo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y800ys/schwartz_value_survey_analysis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y800ys/schwartz_value_survey_analysis/", "subreddit_subscribers": 814349, "created_utc": 1666178445.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Assumptions before performing tests", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7zsrk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_6wfy9q4l", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "rstats", "selftext": "For example, I want to run an Anova test. \n\nDo I need to check if the data qualifies all assumptions?\n\nWhat do I do when the data does not fulfill any of the assumptions? \n\nWhat is the best way to confirm a normal distribution before such tests? Is a qqplot good enough?", "author_fullname": "t2_6wfy9q4l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Assumptions before performing tests", "link_flair_richtext": [], "subreddit_name_prefixed": "r/rstats", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7ex5k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666117965.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.rstats", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For example, I want to run an Anova test. &lt;/p&gt;\n\n&lt;p&gt;Do I need to check if the data qualifies all assumptions?&lt;/p&gt;\n\n&lt;p&gt;What do I do when the data does not fulfill any of the assumptions? &lt;/p&gt;\n\n&lt;p&gt;What is the best way to confirm a normal distribution before such tests? Is a qqplot good enough?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r8n0", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7ex5k", "is_robot_indexable": true, "report_reasons": null, "author": "1SageK1", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/rstats/comments/y7ex5k/assumptions_before_performing_tests/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/rstats/comments/y7ex5k/assumptions_before_performing_tests/", "subreddit_subscribers": 67764, "created_utc": 1666117965.0, "num_crossposts": 3, "media": null, "is_video": false}], "created": 1666177732.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.rstats", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/rstats/comments/y7ex5k/assumptions_before_performing_tests/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7zsrk", "is_robot_indexable": true, "report_reasons": null, "author": "1SageK1", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_y7ex5k", "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7zsrk/assumptions_before_performing_tests/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/rstats/comments/y7ex5k/assumptions_before_performing_tests/", "subreddit_subscribers": 814349, "created_utc": 1666177732.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm working on a project to learn \"to think\" about the problem in a Data Science way; this is because I've mostly done coding and usually machine learning, but nothing focused on problems, so I started one.\n\n&amp;#x200B;\n\nIn this problem, I need to figure out which companies are more likely to grow in the future by looking at some of their data which says how long they've been operating vs. how big they are. I have all this data and...I'm struggling to come up with a path ahead. A friend of mine suggested using random forests and classifying them (since it's categorical data: time being \"first period, second period, etc.\" and their \"growth\" is measured as \"new, middle, big\") however, I am unsure how to do this. \n\n&amp;#x200B;\n\nI did do the random forest and got some values, but they're giving me, as expected, a result like:\n\n&amp;#x200B;\n\n    Company 1 - random forest: 0.98, growth: new, time: second_period\"\n\nWhich...upon looking at it, means nothing to me. I'm unsure about how to go about doing this, I used to do this a few years ago, but ever since I moved to language models and other such things, I feel like I'm super rusty and not even sure where to go from here...could you please help me out? At least how should I be thinking about the problem", "author_fullname": "t2_3lnrl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Not sure if I'm doing the right thing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7jzbv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666129740.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on a project to learn &amp;quot;to think&amp;quot; about the problem in a Data Science way; this is because I&amp;#39;ve mostly done coding and usually machine learning, but nothing focused on problems, so I started one.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;In this problem, I need to figure out which companies are more likely to grow in the future by looking at some of their data which says how long they&amp;#39;ve been operating vs. how big they are. I have all this data and...I&amp;#39;m struggling to come up with a path ahead. A friend of mine suggested using random forests and classifying them (since it&amp;#39;s categorical data: time being &amp;quot;first period, second period, etc.&amp;quot; and their &amp;quot;growth&amp;quot; is measured as &amp;quot;new, middle, big&amp;quot;) however, I am unsure how to do this. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I did do the random forest and got some values, but they&amp;#39;re giving me, as expected, a result like:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Company 1 - random forest: 0.98, growth: new, time: second_period&amp;quot;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Which...upon looking at it, means nothing to me. I&amp;#39;m unsure about how to go about doing this, I used to do this a few years ago, but ever since I moved to language models and other such things, I feel like I&amp;#39;m super rusty and not even sure where to go from here...could you please help me out? At least how should I be thinking about the problem&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7jzbv", "is_robot_indexable": true, "report_reasons": null, "author": "Proxify", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7jzbv/not_sure_if_im_doing_the_right_thing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7jzbv/not_sure_if_im_doing_the_right_thing/", "subreddit_subscribers": 814349, "created_utc": 1666129740.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "*(I apologize in advance if this is the wrong forum for my question. I'm not entirely sure where to direct it.)*\n\n**Background:**  \nI'm a business professor in Boston, and I expect to be awarded tenure this spring. I also expect my teaching and service demands to reduce quite a bit in the next year. I would like to use this sudden flexibility to begin developing my technical and data skills, which are severely lacking. I am fine with a long-term pursuit (2+ years). I teach undergraduate analytics, but in a very applied and simple way (e.g., Google Analytics, SPSS, linear regression, binary logistic regression, cluster analysis, etc.).\n\n**What I'm looking for:**  \nMy priorities in developing a side hustle are as such (in this order):\n\n1. Gain career flexibility. My PhD currently limits me to academia.\n2. Gain some opportunities for freelance consulting.\n3. Improve my capacity to build interesting datasets that could help my research and my students.\n4. Develop a more visible skillset that I can publicly showcase (this is understandably vague). Long-term ambitions are to build more of an online presence oriented around an in-demand skillset.\n\n**Ideas:**  \nSome areas that I am brainstorming:\n\n1. Machine Learning (Not sure what this industry looks like, so may be a naiive idea)\n2. Data engineering (could help me build unique datasets, but would not have access to servers)\n3. Web development\n4. Data visualization\n5. Data science (I understand that some of the topics above fall under this category)\n\nAll of these topics have equal intuitive appeal to me. My problem is that I do not fully understand the dynamics of these industries, as I've been tucked away in my academic bubble plugging away at my personal research projects. I am looking to break out of this bubble a bit, while also holding onto the security it provides (not looking to leave academia anytime soon).\n\nWould love any insights you may have to offer!", "author_fullname": "t2_1ybsrlm1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help me pick a side hustle", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y85i96", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666192813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;em&gt;(I apologize in advance if this is the wrong forum for my question. I&amp;#39;m not entirely sure where to direct it.)&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Background:&lt;/strong&gt;&lt;br/&gt;\nI&amp;#39;m a business professor in Boston, and I expect to be awarded tenure this spring. I also expect my teaching and service demands to reduce quite a bit in the next year. I would like to use this sudden flexibility to begin developing my technical and data skills, which are severely lacking. I am fine with a long-term pursuit (2+ years). I teach undergraduate analytics, but in a very applied and simple way (e.g., Google Analytics, SPSS, linear regression, binary logistic regression, cluster analysis, etc.).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What I&amp;#39;m looking for:&lt;/strong&gt;&lt;br/&gt;\nMy priorities in developing a side hustle are as such (in this order):&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Gain career flexibility. My PhD currently limits me to academia.&lt;/li&gt;\n&lt;li&gt;Gain some opportunities for freelance consulting.&lt;/li&gt;\n&lt;li&gt;Improve my capacity to build interesting datasets that could help my research and my students.&lt;/li&gt;\n&lt;li&gt;Develop a more visible skillset that I can publicly showcase (this is understandably vague). Long-term ambitions are to build more of an online presence oriented around an in-demand skillset.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;Ideas:&lt;/strong&gt;&lt;br/&gt;\nSome areas that I am brainstorming:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Machine Learning (Not sure what this industry looks like, so may be a naiive idea)&lt;/li&gt;\n&lt;li&gt;Data engineering (could help me build unique datasets, but would not have access to servers)&lt;/li&gt;\n&lt;li&gt;Web development&lt;/li&gt;\n&lt;li&gt;Data visualization&lt;/li&gt;\n&lt;li&gt;Data science (I understand that some of the topics above fall under this category)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;All of these topics have equal intuitive appeal to me. My problem is that I do not fully understand the dynamics of these industries, as I&amp;#39;ve been tucked away in my academic bubble plugging away at my personal research projects. I am looking to break out of this bubble a bit, while also holding onto the security it provides (not looking to leave academia anytime soon).&lt;/p&gt;\n\n&lt;p&gt;Would love any insights you may have to offer!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y85i96", "is_robot_indexable": true, "report_reasons": null, "author": "iscurred", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y85i96/help_me_pick_a_side_hustle/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y85i96/help_me_pick_a_side_hustle/", "subreddit_subscribers": 814349, "created_utc": 1666192813.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "First year undergrad studying physics with data science. Around 25% of my course modules is data science (if I study undergrad bachelors, otherwise if I keep studying undergrad masters it would be 40% data science.). Data science modules that I am going to study in the next 3 years:\n\n-Introduction to Data Science\n\n-Practical Techniques for Data Science\n\n-Data Science Project Portfolio\n\n-Statistical Data Analysis\n\n-Machine Learning and Artificial\n\n-Professional Skills for Data Science\n\nIf I chose to stay in integrated undergraduate Masters (4 year course) then I can choose these extra data science modules on my fourth year:\n\n-Practical Machine Learning\n\n-Introduction to Computer Vision\n\n-Computer Graphics\n\n-Risk and Decision-Making for Data Science and AI\n\n-Machine Learning for Visual Data Analysis\n\n-Time Series\n\n-Applied Statistics\n\nShould I study just for bachelors and then do postgraduate masters in data science or stay in undergrad masters (if I stay in undergrad masters i dont want to do any further study). I know that postgraduate Masters are more highly regarded than undergraduate masters, plus I can have a chance to study for postgraduates in a more prestigious university if I do well in my current course and I want to also study less years as possible (tuition fees are expensive) and be more efficient in terms of time, money and value.\n\nAlso, since I dont have a pure maths/computer science background, what do you advice me to do for my technical skills (so far I self taught Python and I will get to code way more than other students from normal physics as part of my course from next semester). I am trying yo be proactive with my technical skills but dont know from where to get started. I want to build a resume that's decent enough for summer 2023 internship.", "author_fullname": "t2_cxq07y37", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "majoring in physics and minoring in data science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y831jt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666186817.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First year undergrad studying physics with data science. Around 25% of my course modules is data science (if I study undergrad bachelors, otherwise if I keep studying undergrad masters it would be 40% data science.). Data science modules that I am going to study in the next 3 years:&lt;/p&gt;\n\n&lt;p&gt;-Introduction to Data Science&lt;/p&gt;\n\n&lt;p&gt;-Practical Techniques for Data Science&lt;/p&gt;\n\n&lt;p&gt;-Data Science Project Portfolio&lt;/p&gt;\n\n&lt;p&gt;-Statistical Data Analysis&lt;/p&gt;\n\n&lt;p&gt;-Machine Learning and Artificial&lt;/p&gt;\n\n&lt;p&gt;-Professional Skills for Data Science&lt;/p&gt;\n\n&lt;p&gt;If I chose to stay in integrated undergraduate Masters (4 year course) then I can choose these extra data science modules on my fourth year:&lt;/p&gt;\n\n&lt;p&gt;-Practical Machine Learning&lt;/p&gt;\n\n&lt;p&gt;-Introduction to Computer Vision&lt;/p&gt;\n\n&lt;p&gt;-Computer Graphics&lt;/p&gt;\n\n&lt;p&gt;-Risk and Decision-Making for Data Science and AI&lt;/p&gt;\n\n&lt;p&gt;-Machine Learning for Visual Data Analysis&lt;/p&gt;\n\n&lt;p&gt;-Time Series&lt;/p&gt;\n\n&lt;p&gt;-Applied Statistics&lt;/p&gt;\n\n&lt;p&gt;Should I study just for bachelors and then do postgraduate masters in data science or stay in undergrad masters (if I stay in undergrad masters i dont want to do any further study). I know that postgraduate Masters are more highly regarded than undergraduate masters, plus I can have a chance to study for postgraduates in a more prestigious university if I do well in my current course and I want to also study less years as possible (tuition fees are expensive) and be more efficient in terms of time, money and value.&lt;/p&gt;\n\n&lt;p&gt;Also, since I dont have a pure maths/computer science background, what do you advice me to do for my technical skills (so far I self taught Python and I will get to code way more than other students from normal physics as part of my course from next semester). I am trying yo be proactive with my technical skills but dont know from where to get started. I want to build a resume that&amp;#39;s decent enough for summer 2023 internship.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y831jt", "is_robot_indexable": true, "report_reasons": null, "author": "Substantial-Peach562", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y831jt/majoring_in_physics_and_minoring_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y831jt/majoring_in_physics_and_minoring_in_data_science/", "subreddit_subscribers": 814349, "created_utc": 1666186817.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently working to address customer churn among deposit accounts of a retail bank. In this case, the churn is not explicitly defined since a customer- either an individual, or a corporate entity, both using the account primarily to fulfil business related transactions- is free to deposit or withdraw any amount at any point in time.\n\nI am inclined towards approaching this as an anomaly detection problem rather a classification one: i.e., identify customers as likely to churn by detecting anomalous patterns in their behaviour such as frequent, increasing withdrawals and/or declining credits?\n\nI would like to hear your opinion on this. Also, if you could cite any approach/existing solution for a similar problem. I am currently reading up on the following that considers hierarchical Temporal Memory Approach to address churn.\n\nhttps://core.ac.uk/download/pdf/225895269.pdf", "author_fullname": "t2_1mp5bur7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Analyzing churn when it cannot be defined by an event", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y82jtt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666185558.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently working to address customer churn among deposit accounts of a retail bank. In this case, the churn is not explicitly defined since a customer- either an individual, or a corporate entity, both using the account primarily to fulfil business related transactions- is free to deposit or withdraw any amount at any point in time.&lt;/p&gt;\n\n&lt;p&gt;I am inclined towards approaching this as an anomaly detection problem rather a classification one: i.e., identify customers as likely to churn by detecting anomalous patterns in their behaviour such as frequent, increasing withdrawals and/or declining credits?&lt;/p&gt;\n\n&lt;p&gt;I would like to hear your opinion on this. Also, if you could cite any approach/existing solution for a similar problem. I am currently reading up on the following that considers hierarchical Temporal Memory Approach to address churn.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://core.ac.uk/download/pdf/225895269.pdf\"&gt;https://core.ac.uk/download/pdf/225895269.pdf&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y82jtt", "is_robot_indexable": true, "report_reasons": null, "author": "sn71", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y82jtt/analyzing_churn_when_it_cannot_be_defined_by_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y82jtt/analyzing_churn_when_it_cannot_be_defined_by_an/", "subreddit_subscribers": 814349, "created_utc": 1666185558.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "1. Install the `opendatasets` library\n\n       '''A Python library for downloading datasets from Kaggle, Google Drive, and \n          other online sources'''\n\n2. Use the `opendatasets.download` helper function.\n3. Get Kaggle Credentials.\n\n          * Download `Kaggle.json` file.\n\n          * Enter your user name and Kaggle API or store the `Kaggle.json` file in \n            the same directory with the Jupyter notebook. \n\n4. Query the directory where the dataset has been downloaded to using the OS Module. \n\n          * The module comes as a Python standard utility Module.\n\n# Import the OS module\n\n'''\nIt helps with querying the directory where the dataset has been downloaded to;\n\n - That is done by interacting with the underlying operating system \n\n \nWith the OS module one can;\n\n * create and remove a folder(directory). \n * Fetch the contents of a directory.\n * Change and identifying the current directory among other operations.\n \n '''\n\nOpen the downloaded dataset(CSV/EXCEL) using python's pandas library.\n\n[Reference and Further Reading](https://www.youtube.com/watch?v=7Jgur9q2ZVk)", "author_fullname": "t2_60pa85jj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to download Kaggle datasets using opendatasets simple python command.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y816ut", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666186195.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666181851.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Install the &lt;code&gt;opendatasets&lt;/code&gt; library&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;&amp;#39;&amp;#39;A Python library for downloading datasets from Kaggle, Google Drive, and \n      other online sources&amp;#39;&amp;#39;&amp;#39;&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Use the &lt;code&gt;opendatasets.download&lt;/code&gt; helper function.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Get Kaggle Credentials.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;  * Download `Kaggle.json` file.\n\n  * Enter your user name and Kaggle API or store the `Kaggle.json` file in \n    the same directory with the Jupyter notebook. \n&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Query the directory where the dataset has been downloaded to using the OS Module. &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;  * The module comes as a Python standard utility Module.\n&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;h1&gt;Import the OS module&lt;/h1&gt;\n\n&lt;p&gt;&amp;#39;&amp;#39;&amp;#39;\nIt helps with querying the directory where the dataset has been downloaded to;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;That is done by interacting with the underlying operating system &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;With the OS module one can;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;create and remove a folder(directory). &lt;/li&gt;\n&lt;li&gt;Fetch the contents of a directory.&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Change and identifying the current directory among other operations.&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Open the downloaded dataset(CSV/EXCEL) using python&amp;#39;s pandas library.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=7Jgur9q2ZVk\"&gt;Reference and Further Reading&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/uOt_PD-7hHV4IoD7E1K_kDSMWBm0W77znOmibU3MvrY.jpg?auto=webp&amp;s=0e258a4e50cd6a14216e47ebef0cb84d05e1d4fb", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/uOt_PD-7hHV4IoD7E1K_kDSMWBm0W77znOmibU3MvrY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d4efd34e5b617aea08faa8b305d3701a3d215887", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/uOt_PD-7hHV4IoD7E1K_kDSMWBm0W77znOmibU3MvrY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=518eb66e09878731c3fe0cf9e46903dfa13bb41d", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/uOt_PD-7hHV4IoD7E1K_kDSMWBm0W77znOmibU3MvrY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=05b9309ee35587cc75f04fb8c67ef60667984fa0", "width": 320, "height": 240}], "variants": {}, "id": "kshlJzmXaPkxCanmARcF44TdJFeYOfTCssWYMRQGXyE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y816ut", "is_robot_indexable": true, "report_reasons": null, "author": "SOTP_", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y816ut/how_to_download_kaggle_datasets_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y816ut/how_to_download_kaggle_datasets_using/", "subreddit_subscribers": 814349, "created_utc": 1666181851.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}