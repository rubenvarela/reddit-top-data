{"kind": "Listing", "data": {"after": "t3_y8cl4u", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_4tczv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "every time I hear someone say num-pee i die a little bit", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "meta", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_y7ycxz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 421, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meta", "can_mod_post": false, "score": 421, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/8ifUPQbWM946tcFz4Vg7wIPw5tcMaSuMpDdLm9qyyXo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666173070.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/aylc75laiqu91.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/aylc75laiqu91.png?auto=webp&amp;s=811d064f28c698d46d822b83b6b0e59ba36cf0ff", "width": 225, "height": 225}, "resolutions": [{"url": "https://preview.redd.it/aylc75laiqu91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=28c0ec8e54a7859652b0dc689287cd5298e7dec4", "width": 108, "height": 108}, {"url": "https://preview.redd.it/aylc75laiqu91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d9956e566ba76b8eec221428731f7170c360c21e", "width": 216, "height": 216}], "variants": {}, "id": "mXRYaAVfSayNzyW4E87Hes-sLP2gVI-6dqexq2_QSsc"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7ycxz", "is_robot_indexable": true, "report_reasons": null, "author": "MAFiA303", "discussion_type": null, "num_comments": 105, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7ycxz/every_time_i_hear_someone_say_numpee_i_die_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/aylc75laiqu91.png", "subreddit_subscribers": 814398, "created_utc": 1666173070.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In the spring I will be teaching the first Data Analytics class ever taught at my university. This class will be focusing on data visualization and communication. I have my textbooks and my class plan already, but I wanted to pose a question to you all. Is there something you wished you learned in your data visualization class that was not taught?", "author_fullname": "t2_lydp1nun", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Teaching a Data Analytics Class", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7r1hx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666148583.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In the spring I will be teaching the first Data Analytics class ever taught at my university. This class will be focusing on data visualization and communication. I have my textbooks and my class plan already, but I wanted to pose a question to you all. Is there something you wished you learned in your data visualization class that was not taught?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7r1hx", "is_robot_indexable": true, "report_reasons": null, "author": "Newd_Librarian", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7r1hx/teaching_a_data_analytics_class/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7r1hx/teaching_a_data_analytics_class/", "subreddit_subscribers": 814398, "created_utc": 1666148583.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am confused on how to build my portfolio or even what platforms to use.  I\u2019ve been overwhelmed and trying to find answers about this without much luck. \n\nIf I\u2019m trying to showcase SQL, R, Python, tableau and Microsoft excel, what are the best platforms and strategies for going about this?\n\nEdit: I\u2019m transitioning into data analysis", "author_fullname": "t2_t1en7quk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Structure Portfolio", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7u9ky", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666158466.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am confused on how to build my portfolio or even what platforms to use.  I\u2019ve been overwhelmed and trying to find answers about this without much luck. &lt;/p&gt;\n\n&lt;p&gt;If I\u2019m trying to showcase SQL, R, Python, tableau and Microsoft excel, what are the best platforms and strategies for going about this?&lt;/p&gt;\n\n&lt;p&gt;Edit: I\u2019m transitioning into data analysis&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7u9ky", "is_robot_indexable": true, "report_reasons": null, "author": "SeaRocks10", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7u9ky/how_to_structure_portfolio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7u9ky/how_to_structure_portfolio/", "subreddit_subscribers": 814398, "created_utc": 1666158466.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "[https://doordash.engineering/2022/10/18/augmenting-fuzzy-matching-with-human-review-to-maximize-precision-and-recall/](https://doordash.engineering/2022/10/18/augmenting-fuzzy-matching-with-human-review-to-maximize-precision-and-recall/)\n\nI recently solved a business problem at DoorDash: we needed a way to onboard new advertisers (brands that sell products at convenience/grocery stores) at scale, without having to manually identify all their products that are available on DoorDash. We used a fuzzy-matching classifier with a human in the loop.\n\nThe part I find the most interesting is how we were able to take an out-of-the-box fuzzy matching algorithm and \u2013 with relatively little technical effort \u2013 tweak it to improve precision and recall. See table toward the end of the piece.\n\nComment away, either here or on the post itself!", "author_fullname": "t2_5kfet", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DoorDash Eng Blog: Augmenting fuzzy matching with human review to maximize precision and recall", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7nl7s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666138929.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://doordash.engineering/2022/10/18/augmenting-fuzzy-matching-with-human-review-to-maximize-precision-and-recall/\"&gt;https://doordash.engineering/2022/10/18/augmenting-fuzzy-matching-with-human-review-to-maximize-precision-and-recall/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I recently solved a business problem at DoorDash: we needed a way to onboard new advertisers (brands that sell products at convenience/grocery stores) at scale, without having to manually identify all their products that are available on DoorDash. We used a fuzzy-matching classifier with a human in the loop.&lt;/p&gt;\n\n&lt;p&gt;The part I find the most interesting is how we were able to take an out-of-the-box fuzzy matching algorithm and \u2013 with relatively little technical effort \u2013 tweak it to improve precision and recall. See table toward the end of the piece.&lt;/p&gt;\n\n&lt;p&gt;Comment away, either here or on the post itself!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7nl7s", "is_robot_indexable": true, "report_reasons": null, "author": "chikinn", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7nl7s/doordash_eng_blog_augmenting_fuzzy_matching_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7nl7s/doordash_eng_blog_augmenting_fuzzy_matching_with/", "subreddit_subscribers": 814398, "created_utc": 1666138929.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm guessing most of you have heard the world war II era story used to illustrate survivorship bias. If not, it's featured on the wikipedia page: [https://en.wikipedia.org/wiki/Survivorship\\_bias](https://en.wikipedia.org/wiki/Survivorship_bias)\n\nOther than that, there are many other biases/paradoxes/pitfalls than the non-statistically minded might fall into. A decent list can be found here: [https://stats.stackexchange.com/questions/23779/most-interesting-statistical-paradoxes/592495#592495](https://stats.stackexchange.com/questions/23779/most-interesting-statistical-paradoxes/592495#592495)\n\nSome were inspired by historical failures (e.g. the survivorship bias again) but others seem to have started more as brain teasers. [https://en.wikipedia.org/wiki/Sleeping\\_Beauty\\_problem](https://en.wikipedia.org/wiki/Sleeping_Beauty_problem)\n\nAdditional, some are fairly easy to come across (Simpson's paradox is applicable to a lot of real world data) whereas others might be more niche.\n\nRegardless, I would say that the thing all of these examples have in common is basically:\n\n*There appears to be an obvious answer/interpretation, but that answer/interpretation is either not a sure thing or the correct answer/interpretation is in blatant contradiction to the obvious answer.*\n\nBy that definition, has anything like this come up on the job?", "author_fullname": "t2_s47x31rw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Paradoxes (or at least pitfalls) on the job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7omp4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666142023.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666141803.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m guessing most of you have heard the world war II era story used to illustrate survivorship bias. If not, it&amp;#39;s featured on the wikipedia page: &lt;a href=\"https://en.wikipedia.org/wiki/Survivorship_bias\"&gt;https://en.wikipedia.org/wiki/Survivorship_bias&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Other than that, there are many other biases/paradoxes/pitfalls than the non-statistically minded might fall into. A decent list can be found here: &lt;a href=\"https://stats.stackexchange.com/questions/23779/most-interesting-statistical-paradoxes/592495#592495\"&gt;https://stats.stackexchange.com/questions/23779/most-interesting-statistical-paradoxes/592495#592495&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Some were inspired by historical failures (e.g. the survivorship bias again) but others seem to have started more as brain teasers. &lt;a href=\"https://en.wikipedia.org/wiki/Sleeping_Beauty_problem\"&gt;https://en.wikipedia.org/wiki/Sleeping_Beauty_problem&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Additional, some are fairly easy to come across (Simpson&amp;#39;s paradox is applicable to a lot of real world data) whereas others might be more niche.&lt;/p&gt;\n\n&lt;p&gt;Regardless, I would say that the thing all of these examples have in common is basically:&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;There appears to be an obvious answer/interpretation, but that answer/interpretation is either not a sure thing or the correct answer/interpretation is in blatant contradiction to the obvious answer.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;By that definition, has anything like this come up on the job?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/a1DhEZ4c4gmsM5mqKxahsd-VvK5lheeFUccaBLODQ5k.jpg?auto=webp&amp;s=8e886a7d7b52e99c00fb213bfb8130938ee2b2a4", "width": 1200, "height": 894}, "resolutions": [{"url": "https://external-preview.redd.it/a1DhEZ4c4gmsM5mqKxahsd-VvK5lheeFUccaBLODQ5k.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a6fc2d9acd533989d7d6c71fb702626994cc8a42", "width": 108, "height": 80}, {"url": "https://external-preview.redd.it/a1DhEZ4c4gmsM5mqKxahsd-VvK5lheeFUccaBLODQ5k.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=77c6e6c880e7741ea362b3770253ffc7ca1f1af7", "width": 216, "height": 160}, {"url": "https://external-preview.redd.it/a1DhEZ4c4gmsM5mqKxahsd-VvK5lheeFUccaBLODQ5k.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bc6b40a946b177471c5024f1063879f0a898249c", "width": 320, "height": 238}, {"url": "https://external-preview.redd.it/a1DhEZ4c4gmsM5mqKxahsd-VvK5lheeFUccaBLODQ5k.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=dc782b33b53cdaeb2174d372a76c2b613cd7aa67", "width": 640, "height": 476}, {"url": "https://external-preview.redd.it/a1DhEZ4c4gmsM5mqKxahsd-VvK5lheeFUccaBLODQ5k.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=cd99878f734a1fed6b0fbc3dcc94c4c71caf1cad", "width": 960, "height": 715}, {"url": "https://external-preview.redd.it/a1DhEZ4c4gmsM5mqKxahsd-VvK5lheeFUccaBLODQ5k.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c74213b7277cfa3202d33b09fbf6c52f7ee8dab5", "width": 1080, "height": 804}], "variants": {}, "id": "SNQxXIF511m-ex3iNlA-2c78ApiWKGIXo6QtamSh1qY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7omp4", "is_robot_indexable": true, "report_reasons": null, "author": "Western-Elevator-456", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7omp4/paradoxes_or_at_least_pitfalls_on_the_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7omp4/paradoxes_or_at_least_pitfalls_on_the_job/", "subreddit_subscribers": 814398, "created_utc": 1666141803.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Do you link to your Kaggle? Or perhaps your Github, which contains the underlying .ipynb files? I want to make sure I\u2019m communicating my work in a way that aligns with how other data science practitioners do it. \n\nThanks for your input!", "author_fullname": "t2_ceqh7wvy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you present your portfolio on LinkedIn?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y87smb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666198209.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you link to your Kaggle? Or perhaps your Github, which contains the underlying .ipynb files? I want to make sure I\u2019m communicating my work in a way that aligns with how other data science practitioners do it. &lt;/p&gt;\n\n&lt;p&gt;Thanks for your input!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "y87smb", "is_robot_indexable": true, "report_reasons": null, "author": "boston_acc", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y87smb/how_do_you_present_your_portfolio_on_linkedin/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y87smb/how_do_you_present_your_portfolio_on_linkedin/", "subreddit_subscribers": 814398, "created_utc": 1666198209.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello!\n\nDo you belong to any other *active* Data Science or Data related communities? Whether that is on Reddit, Discord, a forum?\n\nThe Discord channels that I belong to are really quiet. It would be good to spread my wings a little wider.", "author_fullname": "t2_9k8sa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Other Active Data Science-Related Communities?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7ly78", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666134603.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;Do you belong to any other &lt;em&gt;active&lt;/em&gt; Data Science or Data related communities? Whether that is on Reddit, Discord, a forum?&lt;/p&gt;\n\n&lt;p&gt;The Discord channels that I belong to are really quiet. It would be good to spread my wings a little wider.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7ly78", "is_robot_indexable": true, "report_reasons": null, "author": "MrMadium", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7ly78/other_active_data_sciencerelated_communities/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7ly78/other_active_data_sciencerelated_communities/", "subreddit_subscribers": 814398, "created_utc": 1666134603.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm new to data analysis and excel. I have a question to see how you all might address a problem I'm having. \n\nA group of 20 students take an exam. Some pass and some fail. Students who fail, retake the test a few days later. This continues until all students have passed the exam. \n\nI have data on the student name, pass/fail, date of exam, and exam attempt #. \n\nWhat's the best way to represent this data to show student performance over time? Ideally there would be some indication of exam attempt # on the graph/chart as well. \n\nThanks in advance for help and advice!", "author_fullname": "t2_40s55kmr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the best way to represent this data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y89tsj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666203006.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m new to data analysis and excel. I have a question to see how you all might address a problem I&amp;#39;m having. &lt;/p&gt;\n\n&lt;p&gt;A group of 20 students take an exam. Some pass and some fail. Students who fail, retake the test a few days later. This continues until all students have passed the exam. &lt;/p&gt;\n\n&lt;p&gt;I have data on the student name, pass/fail, date of exam, and exam attempt #. &lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the best way to represent this data to show student performance over time? Ideally there would be some indication of exam attempt # on the graph/chart as well. &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for help and advice!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y89tsj", "is_robot_indexable": true, "report_reasons": null, "author": "guppyguyco", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y89tsj/whats_the_best_way_to_represent_this_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y89tsj/whats_the_best_way_to_represent_this_data/", "subreddit_subscribers": 814398, "created_utc": 1666203006.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nHi mates\n\nI hope you are doing well.\n\nWould you please tell me the **difference between** the ***Retention*** and the ***Propensity*** models?  \nAs I understand, the propensity model has three types: **Propensity to buy**, **Propensity to churn**, and **Propensity to unsubscribe**.\n\nIs the **retention model** the same as the **propensity to churn**?\n\nThank you in advance", "author_fullname": "t2_8otyl3bx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Difference between Propensity model and Retention model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7ymoz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666173922.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi mates&lt;/p&gt;\n\n&lt;p&gt;I hope you are doing well.&lt;/p&gt;\n\n&lt;p&gt;Would you please tell me the &lt;strong&gt;difference between&lt;/strong&gt; the &lt;strong&gt;&lt;em&gt;Retention&lt;/em&gt;&lt;/strong&gt; and the &lt;strong&gt;&lt;em&gt;Propensity&lt;/em&gt;&lt;/strong&gt; models?&lt;br/&gt;\nAs I understand, the propensity model has three types: &lt;strong&gt;Propensity to buy&lt;/strong&gt;, &lt;strong&gt;Propensity to churn&lt;/strong&gt;, and &lt;strong&gt;Propensity to unsubscribe&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;Is the &lt;strong&gt;retention model&lt;/strong&gt; the same as the &lt;strong&gt;propensity to churn&lt;/strong&gt;?&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7ymoz", "is_robot_indexable": true, "report_reasons": null, "author": "Masoud_mirza", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7ymoz/difference_between_propensity_model_and_retention/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7ymoz/difference_between_propensity_model_and_retention/", "subreddit_subscribers": 814398, "created_utc": 1666173922.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\nAs a DA expecting offers for both roles, Analytics Engineer and Data Scientist Product Analytics, I was wondering how the community viewed each role?\n\nIs one harder to break into? Does one generally lead to better opportunities down the road? Is pay expected to be higher for one vs the other (I\u2019m expecting similar based on recruiter conversation)? Is one more or less \u2018future proof\u2019?\n\n\u200b\n\nI think I know which one I would be a more natural fit for but I\u2019m curious about the perception of the roles from others in the industry.", "author_fullname": "t2_1oj5wdu2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\u201cBetter\u201d career? AE vs DS product", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7pean", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666143921.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a DA expecting offers for both roles, Analytics Engineer and Data Scientist Product Analytics, I was wondering how the community viewed each role?&lt;/p&gt;\n\n&lt;p&gt;Is one harder to break into? Does one generally lead to better opportunities down the road? Is pay expected to be higher for one vs the other (I\u2019m expecting similar based on recruiter conversation)? Is one more or less \u2018future proof\u2019?&lt;/p&gt;\n\n&lt;p&gt;\u200b&lt;/p&gt;\n\n&lt;p&gt;I think I know which one I would be a more natural fit for but I\u2019m curious about the perception of the roles from others in the industry.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7pean", "is_robot_indexable": true, "report_reasons": null, "author": "bigfeller2", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7pean/better_career_ae_vs_ds_product/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y7pean/better_career_ae_vs_ds_product/", "subreddit_subscribers": 814398, "created_utc": 1666143921.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey all, so I have a dataset with 8000 rows and 200+ features, mostly numerical. By looking at summary statistics, I see that a good chunk of these features (100ish) have zeroes for 75%+ of their entries. Seems to me like all these zeroes won't contain any useful info for an eventual model, and it would simplify my process a lot to reduce the dimensionality. Would it be wise to simply remove features like this and continue on my way or would I be missing out on lots of possible info? Maybe take all of these sparse columns and use PCA to hopefully reduce them to one or two principal components?", "author_fullname": "t2_d86jaoff", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Filtering out features?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_y8fnsj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666216639.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, so I have a dataset with 8000 rows and 200+ features, mostly numerical. By looking at summary statistics, I see that a good chunk of these features (100ish) have zeroes for 75%+ of their entries. Seems to me like all these zeroes won&amp;#39;t contain any useful info for an eventual model, and it would simplify my process a lot to reduce the dimensionality. Would it be wise to simply remove features like this and continue on my way or would I be missing out on lots of possible info? Maybe take all of these sparse columns and use PCA to hopefully reduce them to one or two principal components?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y8fnsj", "is_robot_indexable": true, "report_reasons": null, "author": "Objective-Simple-836", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y8fnsj/filtering_out_features/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y8fnsj/filtering_out_features/", "subreddit_subscribers": 814398, "created_utc": 1666216639.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "There's a concept in graph theory, in particular when talking about tournaments, known as a median order, which is essentially an ordering of the vertices that maximizes the amount of edges pointing in the increasing direction with respect to the ordering.\n\nThis can be thought of multiplying the adjacency matrix by a permutation matrix on the right and on the left, such that the sum of the upper triangular part of the matrix is maximal.\n\nI've coded it as an integer program [github link here](https://github.com/alonso-cancino/median_orders), but the problem is really slow. I've been thinking if maybe it could be done with some sort of reinforcement learning procedure, where you'd input the adjacency matrix of the graph and it orders the rows/columns in such a way that maximices the upper triangular sum.\n\nIs this a viable strategy or is this one of those places where ML does not apply? Is there any good reference for trying to solve integer optimization problems with ML?", "author_fullname": "t2_8j3x0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this problem \"solvable\" with some ML technique?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y8ctq4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666209996.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There&amp;#39;s a concept in graph theory, in particular when talking about tournaments, known as a median order, which is essentially an ordering of the vertices that maximizes the amount of edges pointing in the increasing direction with respect to the ordering.&lt;/p&gt;\n\n&lt;p&gt;This can be thought of multiplying the adjacency matrix by a permutation matrix on the right and on the left, such that the sum of the upper triangular part of the matrix is maximal.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve coded it as an integer program &lt;a href=\"https://github.com/alonso-cancino/median_orders\"&gt;github link here&lt;/a&gt;, but the problem is really slow. I&amp;#39;ve been thinking if maybe it could be done with some sort of reinforcement learning procedure, where you&amp;#39;d input the adjacency matrix of the graph and it orders the rows/columns in such a way that maximices the upper triangular sum.&lt;/p&gt;\n\n&lt;p&gt;Is this a viable strategy or is this one of those places where ML does not apply? Is there any good reference for trying to solve integer optimization problems with ML?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Ah6w4nBNbPGP36O_njNAtcMATQmVY7Ul5UnwtVOKTm0.jpg?auto=webp&amp;s=a76366a3402c347763a45516a3e596c74737b1ed", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/Ah6w4nBNbPGP36O_njNAtcMATQmVY7Ul5UnwtVOKTm0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3916f66b61f9600c4d90738234d1e0a3e4e4d437", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/Ah6w4nBNbPGP36O_njNAtcMATQmVY7Ul5UnwtVOKTm0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c72f2e956ed5ea858865141458240b1f18146cb8", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/Ah6w4nBNbPGP36O_njNAtcMATQmVY7Ul5UnwtVOKTm0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8dbc48c0818783af329f8dde028dad84f5cb9b11", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/Ah6w4nBNbPGP36O_njNAtcMATQmVY7Ul5UnwtVOKTm0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a0f809d905f8a09e0c37d4b606670734e7cbfb60", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/Ah6w4nBNbPGP36O_njNAtcMATQmVY7Ul5UnwtVOKTm0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1e5361c376e5dcca8eac85bcf0b729a47aaa4aa3", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/Ah6w4nBNbPGP36O_njNAtcMATQmVY7Ul5UnwtVOKTm0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=27e5e2356ab0271b5a7d504c914070696b6e8a7b", "width": 1080, "height": 540}], "variants": {}, "id": "Wq9ag5G5LtLj5Qnn-YA2InyN3z_A52IZbamkEA_wXec"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y8ctq4", "is_robot_indexable": true, "report_reasons": null, "author": "Alozzk", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y8ctq4/is_this_problem_solvable_with_some_ml_technique/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y8ctq4/is_this_problem_solvable_with_some_ml_technique/", "subreddit_subscribers": 814398, "created_utc": 1666209996.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I don't get enough \u201cbad\u201d samples, because it\u2019s almost impossible and challenging for our customers to artificially capture defects (bad samples) in production. Without bad samples, we cannot create or optimize algorithms. \n\n&amp;#x200B;\n\nAny suggestions?", "author_fullname": "t2_t9mt0bic", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need more bad samples in order to create and optimize algorithms", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y8bzin", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666208013.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t get enough \u201cbad\u201d samples, because it\u2019s almost impossible and challenging for our customers to artificially capture defects (bad samples) in production. Without bad samples, we cannot create or optimize algorithms. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y8bzin", "is_robot_indexable": true, "report_reasons": null, "author": "alovna88", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y8bzin/i_need_more_bad_samples_in_order_to_create_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y8bzin/i_need_more_bad_samples_in_order_to_create_and/", "subreddit_subscribers": 814398, "created_utc": 1666208013.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone,\n\nWe're looking for an experienced data scientist to join our small data team, and I wanted to open it up here instead of casting into the abyss of Linkedin. High-level stats: we've been in business for over 20 years \u2013 we're in the top-5 of our segment, we're 100% fully remote, and we keep EST hours. Our team is focused on using ML (NLP and deep learning, generally) for efforts like extracting signal from unstructured text (e.g., slot filling, classification), enhancing our recommendation/matching pipeline, and modeling our segment of the market.\n\nI'm someone who's worked in some FAANG-types, some startups, and in academia, and there are a few qualities that I appreciate in particular about this role:\n\n* the technical challenges we work on are like the fundamental NLU research tasks that I worked on in grad school, except without the p-value hacking or SOA-bake-off games. These are topics a lot of us are interested in, but, when we find a company working on them, we've usually joined company once the interesting decisions have already been made \u2013 that's not the case here. I'm able to explore what is, for me, the substantial intersection between my interests and the company's technical needs\n* the data team has the freedom and independence to do our work properly and to generate results we believe in. We do maintain a good delivery cadence and we apply \"all the adages\" (e.g., don't let perfect be the enemy of the good), but (1) respect and trust are extremely strong between teams and (2) deliverables are kept small and are usually POCs or MVPs that we want to evaluate experimentally\n* No blood in the water \u2013 no one is competitive or cutthroat; we're all \"pulling in the same direction\" and it feels that way. Nothing is territorial\n* We have a lot of data and the resources to analyze it pragmatically\n* Competitive compensation\n\nTo succeed here, I think the list above should sound appealing \u2013 and, of course, that's not everyone. Some people are happiest working onsite, some personalities enjoy a collegial but competitive atmosphere, etc., but for a certain set of sensibilities, this role offers, what has been for me, a unique opportunity.\n\nAs far as technical background, real-world experience with these will be helpful:\n\n* Python (we tend to share work in Jupyter notebooks)\n* ML libraries like some of these \u2013 NumPy, pandas, SciPy, scikit-learn, SpaCy, fastai, XGBoost, PyMC3\n* PyTorch or TensorFlow (experience with Huggingface in particular is relevant)\n* Transformer-based NLP models like BERT for tasks like text and token classification as well as entity extraction\n* Tasks like classification, clustering, efficient matching, outlier/anomaly detection, churn analysis, LTV analysis\n\nAlso relevant:\n\n* Interpretability (e.g., Shapley values, similarity measures)\n* Model optimization (GPU/CPU, inference/training, distillation)\n* SQL, Bash\n\nFeel free to DM me with any comments or questions.", "author_fullname": "t2_5xwew", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Hiring] Remote Data Scientist (NLP &amp; Recommendations)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y8bxb8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666207873.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re looking for an experienced data scientist to join our small data team, and I wanted to open it up here instead of casting into the abyss of Linkedin. High-level stats: we&amp;#39;ve been in business for over 20 years \u2013 we&amp;#39;re in the top-5 of our segment, we&amp;#39;re 100% fully remote, and we keep EST hours. Our team is focused on using ML (NLP and deep learning, generally) for efforts like extracting signal from unstructured text (e.g., slot filling, classification), enhancing our recommendation/matching pipeline, and modeling our segment of the market.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m someone who&amp;#39;s worked in some FAANG-types, some startups, and in academia, and there are a few qualities that I appreciate in particular about this role:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;the technical challenges we work on are like the fundamental NLU research tasks that I worked on in grad school, except without the p-value hacking or SOA-bake-off games. These are topics a lot of us are interested in, but, when we find a company working on them, we&amp;#39;ve usually joined company once the interesting decisions have already been made \u2013 that&amp;#39;s not the case here. I&amp;#39;m able to explore what is, for me, the substantial intersection between my interests and the company&amp;#39;s technical needs&lt;/li&gt;\n&lt;li&gt;the data team has the freedom and independence to do our work properly and to generate results we believe in. We do maintain a good delivery cadence and we apply &amp;quot;all the adages&amp;quot; (e.g., don&amp;#39;t let perfect be the enemy of the good), but (1) respect and trust are extremely strong between teams and (2) deliverables are kept small and are usually POCs or MVPs that we want to evaluate experimentally&lt;/li&gt;\n&lt;li&gt;No blood in the water \u2013 no one is competitive or cutthroat; we&amp;#39;re all &amp;quot;pulling in the same direction&amp;quot; and it feels that way. Nothing is territorial&lt;/li&gt;\n&lt;li&gt;We have a lot of data and the resources to analyze it pragmatically&lt;/li&gt;\n&lt;li&gt;Competitive compensation&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;To succeed here, I think the list above should sound appealing \u2013 and, of course, that&amp;#39;s not everyone. Some people are happiest working onsite, some personalities enjoy a collegial but competitive atmosphere, etc., but for a certain set of sensibilities, this role offers, what has been for me, a unique opportunity.&lt;/p&gt;\n\n&lt;p&gt;As far as technical background, real-world experience with these will be helpful:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Python (we tend to share work in Jupyter notebooks)&lt;/li&gt;\n&lt;li&gt;ML libraries like some of these \u2013 NumPy, pandas, SciPy, scikit-learn, SpaCy, fastai, XGBoost, PyMC3&lt;/li&gt;\n&lt;li&gt;PyTorch or TensorFlow (experience with Huggingface in particular is relevant)&lt;/li&gt;\n&lt;li&gt;Transformer-based NLP models like BERT for tasks like text and token classification as well as entity extraction&lt;/li&gt;\n&lt;li&gt;Tasks like classification, clustering, efficient matching, outlier/anomaly detection, churn analysis, LTV analysis&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Also relevant:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Interpretability (e.g., Shapley values, similarity measures)&lt;/li&gt;\n&lt;li&gt;Model optimization (GPU/CPU, inference/training, distillation)&lt;/li&gt;\n&lt;li&gt;SQL, Bash&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Feel free to DM me with any comments or questions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y8bxb8", "is_robot_indexable": true, "report_reasons": null, "author": "MontyCarleau", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y8bxb8/hiring_remote_data_scientist_nlp_recommendations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y8bxb8/hiring_remote_data_scientist_nlp_recommendations/", "subreddit_subscribers": 814398, "created_utc": 1666207873.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\nIn reference to the title: I mean at a much more granular level than 'programming', 'statistics' etc.\n\nFor instance, I'm currently studying an MS in Statistics (with a focus on computational statistics), and I studied mathematics &amp; statistics for my BS. Never once did we cover topics such as 'bias variance tradeoffs', models such as XGboost, or sophisticated imputation methods such as MICE.\n\nI worked previously in teams with very maths/stats heavy backgrounds, and never really found it an issue. Recently interviewing for other roles it is apparent there is some sort of gap in my knowledge I'm unsure how to fill - or even what area I'm missing.\n\n**How do you structure the skill hierarchy for data science? Which areas do you think are most important in order to become a well-rounded data scientist?**", "author_fullname": "t2_4g4zpv1c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What skill groups would you break the data science profession into?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y8buny", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666207704.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;In reference to the title: I mean at a much more granular level than &amp;#39;programming&amp;#39;, &amp;#39;statistics&amp;#39; etc.&lt;/p&gt;\n\n&lt;p&gt;For instance, I&amp;#39;m currently studying an MS in Statistics (with a focus on computational statistics), and I studied mathematics &amp;amp; statistics for my BS. Never once did we cover topics such as &amp;#39;bias variance tradeoffs&amp;#39;, models such as XGboost, or sophisticated imputation methods such as MICE.&lt;/p&gt;\n\n&lt;p&gt;I worked previously in teams with very maths/stats heavy backgrounds, and never really found it an issue. Recently interviewing for other roles it is apparent there is some sort of gap in my knowledge I&amp;#39;m unsure how to fill - or even what area I&amp;#39;m missing.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;How do you structure the skill hierarchy for data science? Which areas do you think are most important in order to become a well-rounded data scientist?&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y8buny", "is_robot_indexable": true, "report_reasons": null, "author": "EatsShootsAndLeavz", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y8buny/what_skill_groups_would_you_break_the_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y8buny/what_skill_groups_would_you_break_the_data/", "subreddit_subscribers": 814398, "created_utc": 1666207704.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Pretty unsophisticated data person here. I work in housing/urban planning so mostly work with census/county assessor parcel data to examine neighborhood housing market trends/indicators. Starting to feel like there might be a better tool for doing more sophisticated analysis than excel. Maybe SPSS? Thoughts?", "author_fullname": "t2_r38s8kc8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Next step up from excel for data analysis?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y8azf0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666205709.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Pretty unsophisticated data person here. I work in housing/urban planning so mostly work with census/county assessor parcel data to examine neighborhood housing market trends/indicators. Starting to feel like there might be a better tool for doing more sophisticated analysis than excel. Maybe SPSS? Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y8azf0", "is_robot_indexable": true, "report_reasons": null, "author": "theEarnestUrbanist", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y8azf0/next_step_up_from_excel_for_data_analysis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y8azf0/next_step_up_from_excel_for_data_analysis/", "subreddit_subscribers": 814398, "created_utc": 1666205709.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Im using the `refresh_token` &gt; `fetch new access_token` &gt; `make request` flow to fetch json data from Xero. \n\nBut for some reason providing the same tokens and credentials to tap-xero's config.json returns `tap_xero.client.XeroNotFoundError: HTTP-error-code: 404, Error: The resource you have specified cannot be found.`\n\nThe command args are: `tap-xero -c config.json -d &gt; cat.json`\n\nSinger's documentation is really lacking for their dedicated taps.", "author_fullname": "t2_n732f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone used Singer's tap-xero to fetch Xero data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y89cok", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666201883.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im using the &lt;code&gt;refresh_token&lt;/code&gt; &amp;gt; &lt;code&gt;fetch new access_token&lt;/code&gt; &amp;gt; &lt;code&gt;make request&lt;/code&gt; flow to fetch json data from Xero. &lt;/p&gt;\n\n&lt;p&gt;But for some reason providing the same tokens and credentials to tap-xero&amp;#39;s config.json returns &lt;code&gt;tap_xero.client.XeroNotFoundError: HTTP-error-code: 404, Error: The resource you have specified cannot be found.&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;The command args are: &lt;code&gt;tap-xero -c config.json -d &amp;gt; cat.json&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;Singer&amp;#39;s documentation is really lacking for their dedicated taps.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y89cok", "is_robot_indexable": true, "report_reasons": null, "author": "buckypimpin", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y89cok/has_anyone_used_singers_tapxero_to_fetch_xero_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y89cok/has_anyone_used_singers_tapxero_to_fetch_xero_data/", "subreddit_subscribers": 814398, "created_utc": 1666201883.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, I have been trying to scrap the school schedule (for obvious reasons, of course). And so far, I saw coursicle claims that they get the data from \"Smith's public listing course\". I've tried to find it but no use, then I found a reddit post from the cofounder of coursicle himself saying that he ping the school gateway ([https://www.reddit.com/r/gatech/comments/r0datq/where\\_does\\_coursicle\\_get\\_its\\_class\\_seats\\_data\\_from/](https://www.reddit.com/r/gatech/comments/r0datq/where_does_coursicle_get_its_class_seats_data_from/)). I'm not sure whether I understand his idea right, but I can't find any way to access my school schedule without actually have to login in, which is a big deal when employ bot to server. So do you have any suggestion, or have any source that has college's courses available publicly, please let me know. Thank you\n\nhttps://preview.redd.it/m23sd3e6ssu91.png?width=907&amp;format=png&amp;auto=webp&amp;s=288959bf76d09287f908b4b019fa0890756c9c51", "author_fullname": "t2_eo1lh8sj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Public College schedule from Coursicle", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 16, "top_awarded_type": null, "hide_score": false, "media_metadata": {"m23sd3e6ssu91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 12, "x": 108, "u": "https://preview.redd.it/m23sd3e6ssu91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6f035c5a7fe36151c0497efd5b4c7266ba7bca5b"}, {"y": 25, "x": 216, "u": "https://preview.redd.it/m23sd3e6ssu91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f49e3225bd5cb82be7a0e1662a497a2cf33116ad"}, {"y": 38, "x": 320, "u": "https://preview.redd.it/m23sd3e6ssu91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=503a99350e3bfa9efeebe99f181cd505f09d7f4a"}, {"y": 76, "x": 640, "u": "https://preview.redd.it/m23sd3e6ssu91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=db7ff2816c4a6a1220dfbba36873020eb55aa599"}], "s": {"y": 109, "x": 907, "u": "https://preview.redd.it/m23sd3e6ssu91.png?width=907&amp;format=png&amp;auto=webp&amp;s=288959bf76d09287f908b4b019fa0890756c9c51"}, "id": "m23sd3e6ssu91"}}, "name": "t3_y88uyt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/-A-f9IFIg2xrA82oOkM5O_ESc1W53HXKOTUR4W59Z2A.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666200713.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I have been trying to scrap the school schedule (for obvious reasons, of course). And so far, I saw coursicle claims that they get the data from &amp;quot;Smith&amp;#39;s public listing course&amp;quot;. I&amp;#39;ve tried to find it but no use, then I found a reddit post from the cofounder of coursicle himself saying that he ping the school gateway (&lt;a href=\"https://www.reddit.com/r/gatech/comments/r0datq/where_does_coursicle_get_its_class_seats_data_from/\"&gt;https://www.reddit.com/r/gatech/comments/r0datq/where_does_coursicle_get_its_class_seats_data_from/&lt;/a&gt;). I&amp;#39;m not sure whether I understand his idea right, but I can&amp;#39;t find any way to access my school schedule without actually have to login in, which is a big deal when employ bot to server. So do you have any suggestion, or have any source that has college&amp;#39;s courses available publicly, please let me know. Thank you&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/m23sd3e6ssu91.png?width=907&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=288959bf76d09287f908b4b019fa0890756c9c51\"&gt;https://preview.redd.it/m23sd3e6ssu91.png?width=907&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=288959bf76d09287f908b4b019fa0890756c9c51&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y88uyt", "is_robot_indexable": true, "report_reasons": null, "author": "PiccoloStreet3002", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y88uyt/public_college_schedule_from_coursicle/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y88uyt/public_college_schedule_from_coursicle/", "subreddit_subscribers": 814398, "created_utc": 1666200713.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello all! \n\nI've been pretty excited reading about all the advancements in LLMs over the years but never took the time to dip my toes in. I'm also a PC gamer and waited until the gpu market dipped a bit to finally buy a RTX3080 and figured might as well get into some hobbyist ML/deep learning experimentation with a new GPU with so many CUDA cores. \n\nI'm aware its still nothing in comparison to an A100 or the like and that I might still be fairly limited working with any LLM, but wondering if anyone has any experience, tips or guidance on what's possible without a multi-gpu at-home setup, like what's the biggest model one could play with on a single 3080, what to expect in terms of process time per token, the biggest feasible model one could or should use to fine tune on a closed domain dataset, etc. \n\nIf I'm being completely unrealistic in even attempting to fine-tune an LLM locally, please also feel free to clear me of any dilusions. \n\nRegardless, it's still so fascinating to see all the developments in the space happening so quickly. This is a super exciting time we're living in, and hopefully these kinds of technologies will be more accessible to hobbyists as they're developed to require less compute and consume less energy.\n\nThanks in advance for any guidance!", "author_fullname": "t2_5z0my9eb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "At-home LLM experimentation questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y87bub", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666197106.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all! &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been pretty excited reading about all the advancements in LLMs over the years but never took the time to dip my toes in. I&amp;#39;m also a PC gamer and waited until the gpu market dipped a bit to finally buy a RTX3080 and figured might as well get into some hobbyist ML/deep learning experimentation with a new GPU with so many CUDA cores. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m aware its still nothing in comparison to an A100 or the like and that I might still be fairly limited working with any LLM, but wondering if anyone has any experience, tips or guidance on what&amp;#39;s possible without a multi-gpu at-home setup, like what&amp;#39;s the biggest model one could play with on a single 3080, what to expect in terms of process time per token, the biggest feasible model one could or should use to fine tune on a closed domain dataset, etc. &lt;/p&gt;\n\n&lt;p&gt;If I&amp;#39;m being completely unrealistic in even attempting to fine-tune an LLM locally, please also feel free to clear me of any dilusions. &lt;/p&gt;\n\n&lt;p&gt;Regardless, it&amp;#39;s still so fascinating to see all the developments in the space happening so quickly. This is a super exciting time we&amp;#39;re living in, and hopefully these kinds of technologies will be more accessible to hobbyists as they&amp;#39;re developed to require less compute and consume less energy.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for any guidance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y87bub", "is_robot_indexable": true, "report_reasons": null, "author": "smarthaiti", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y87bub/athome_llm_experimentation_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y87bub/athome_llm_experimentation_questions/", "subreddit_subscribers": 814398, "created_utc": 1666197106.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Dear fellow smart data expert \n\nI\u2019m working on this Ubereats project to measure/determine restaurant\u2019s success through these variables \nI\u2019ve these variables (restaurant ratings 1-6) ,(restaurant ratings count 1-7k) , (food hygiene ratings 1-5) (daily deals %) (spend $ )  (delivery fees $)\n\nWhat confuse me most is some restaurants have high ratings with low ratings counts \n\nCan\u2019t think further from this \n\nHelp \n\nThanks", "author_fullname": "t2_6ku703xx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I determine if a restaurant is doing well through these variables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y87aea", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666197013.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dear fellow smart data expert &lt;/p&gt;\n\n&lt;p&gt;I\u2019m working on this Ubereats project to measure/determine restaurant\u2019s success through these variables \nI\u2019ve these variables (restaurant ratings 1-6) ,(restaurant ratings count 1-7k) , (food hygiene ratings 1-5) (daily deals %) (spend $ )  (delivery fees $)&lt;/p&gt;\n\n&lt;p&gt;What confuse me most is some restaurants have high ratings with low ratings counts &lt;/p&gt;\n\n&lt;p&gt;Can\u2019t think further from this &lt;/p&gt;\n\n&lt;p&gt;Help &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y87aea", "is_robot_indexable": true, "report_reasons": null, "author": "Street-Target9245", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y87aea/how_can_i_determine_if_a_restaurant_is_doing_well/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y87aea/how_can_i_determine_if_a_restaurant_is_doing_well/", "subreddit_subscribers": 814398, "created_utc": 1666197013.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "*(I apologize in advance if this is the wrong forum for my question. I'm not entirely sure where to direct it.)*\n\n**Background:**  \nI'm a business professor in Boston, and I expect to be awarded tenure this spring. I also expect my teaching and service demands to reduce quite a bit in the next year. I would like to use this sudden flexibility to begin developing my technical and data skills, which are severely lacking. I am fine with a long-term pursuit (2+ years). I teach undergraduate analytics, but in a very applied and simple way (e.g., Google Analytics, SPSS, linear regression, binary logistic regression, cluster analysis, etc.).\n\n**What I'm looking for:**  \nMy priorities in developing a side hustle are as such (in this order):\n\n1. Gain career flexibility. My PhD currently limits me to academia.\n2. Gain some opportunities for freelance consulting.\n3. Improve my capacity to build interesting datasets that could help my research and my students.\n4. Develop a more visible skillset that I can publicly showcase (this is understandably vague). Long-term ambitions are to build more of an online presence oriented around an in-demand skillset.\n\n**Ideas:**  \nSome areas that I am brainstorming:\n\n1. Machine Learning (Not sure what this industry looks like, so may be a naiive idea)\n2. Data engineering (could help me build unique datasets, but would not have access to servers)\n3. Web development\n4. Data visualization\n5. Data science (I understand that some of the topics above fall under this category)\n\nAll of these topics have equal intuitive appeal to me. My problem is that I do not fully understand the dynamics of these industries, as I've been tucked away in my academic bubble plugging away at my personal research projects. I am looking to break out of this bubble a bit, while also holding onto the security it provides (not looking to leave academia anytime soon).\n\nWould love any insights you may have to offer!", "author_fullname": "t2_1ybsrlm1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help me pick a side hustle", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y85i96", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666192813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;em&gt;(I apologize in advance if this is the wrong forum for my question. I&amp;#39;m not entirely sure where to direct it.)&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Background:&lt;/strong&gt;&lt;br/&gt;\nI&amp;#39;m a business professor in Boston, and I expect to be awarded tenure this spring. I also expect my teaching and service demands to reduce quite a bit in the next year. I would like to use this sudden flexibility to begin developing my technical and data skills, which are severely lacking. I am fine with a long-term pursuit (2+ years). I teach undergraduate analytics, but in a very applied and simple way (e.g., Google Analytics, SPSS, linear regression, binary logistic regression, cluster analysis, etc.).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What I&amp;#39;m looking for:&lt;/strong&gt;&lt;br/&gt;\nMy priorities in developing a side hustle are as such (in this order):&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Gain career flexibility. My PhD currently limits me to academia.&lt;/li&gt;\n&lt;li&gt;Gain some opportunities for freelance consulting.&lt;/li&gt;\n&lt;li&gt;Improve my capacity to build interesting datasets that could help my research and my students.&lt;/li&gt;\n&lt;li&gt;Develop a more visible skillset that I can publicly showcase (this is understandably vague). Long-term ambitions are to build more of an online presence oriented around an in-demand skillset.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;Ideas:&lt;/strong&gt;&lt;br/&gt;\nSome areas that I am brainstorming:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Machine Learning (Not sure what this industry looks like, so may be a naiive idea)&lt;/li&gt;\n&lt;li&gt;Data engineering (could help me build unique datasets, but would not have access to servers)&lt;/li&gt;\n&lt;li&gt;Web development&lt;/li&gt;\n&lt;li&gt;Data visualization&lt;/li&gt;\n&lt;li&gt;Data science (I understand that some of the topics above fall under this category)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;All of these topics have equal intuitive appeal to me. My problem is that I do not fully understand the dynamics of these industries, as I&amp;#39;ve been tucked away in my academic bubble plugging away at my personal research projects. I am looking to break out of this bubble a bit, while also holding onto the security it provides (not looking to leave academia anytime soon).&lt;/p&gt;\n\n&lt;p&gt;Would love any insights you may have to offer!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y85i96", "is_robot_indexable": true, "report_reasons": null, "author": "iscurred", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y85i96/help_me_pick_a_side_hustle/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y85i96/help_me_pick_a_side_hustle/", "subreddit_subscribers": 814398, "created_utc": 1666192813.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have some mixed data that I thought I'd first transform into embeddings and then cluster the embedding. However, since I'm clustering embeddings does that mean that I'm going to lose all interpretability of the clusters? I know there's some loss of interpreability when using embeddings but I'm not clear on what the degree of that loss is. Anyone care to clarify?", "author_fullname": "t2_5ox025vb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Clustering embeddings", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y82y0u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666186559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have some mixed data that I thought I&amp;#39;d first transform into embeddings and then cluster the embedding. However, since I&amp;#39;m clustering embeddings does that mean that I&amp;#39;m going to lose all interpretability of the clusters? I know there&amp;#39;s some loss of interpreability when using embeddings but I&amp;#39;m not clear on what the degree of that loss is. Anyone care to clarify?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y82y0u", "is_robot_indexable": true, "report_reasons": null, "author": "SomaDomaBoma", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y82y0u/clustering_embeddings/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y82y0u/clustering_embeddings/", "subreddit_subscribers": 814398, "created_utc": 1666186559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "hello,\n\nI'm planning on using the shortened version of the [schwartz value survey](https://www.framevoicereport.org/media/1093/the-short-schwartzs-value-survey.pdf) (SSVS) in my master's thesis. there are 10 basic human values and participants rate each of them on a likert-scale (0 to 8). I will later relate this survey data to some behavior of the participants *(like \"participants who value conformity behave like this\")* \\-but, I am completely lost on how to analyze the survey data. I guess I need to create a score for each participant, but is it possible? or logical? *(values have a circumplex structure -each value is similar to one other while also being the opposite of another. so yielding just one score per individual seems like it wouldn't make sense? like they would cancel each other out somehow? i don't know)*\n\nusing factor analysis, the 10 values can be reduced into a couple (?) of dimensions (I guess). but would that lead to a score? or a score with two dimensions (like a point coordinate in xy-axis)? \n\ndoes anybody have any clue? help.........please?", "author_fullname": "t2_664rqg0i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "schwartz value survey -analysis", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y800ys", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666178445.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hello,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m planning on using the shortened version of the &lt;a href=\"https://www.framevoicereport.org/media/1093/the-short-schwartzs-value-survey.pdf\"&gt;schwartz value survey&lt;/a&gt; (SSVS) in my master&amp;#39;s thesis. there are 10 basic human values and participants rate each of them on a likert-scale (0 to 8). I will later relate this survey data to some behavior of the participants &lt;em&gt;(like &amp;quot;participants who value conformity behave like this&amp;quot;)&lt;/em&gt; -but, I am completely lost on how to analyze the survey data. I guess I need to create a score for each participant, but is it possible? or logical? &lt;em&gt;(values have a circumplex structure -each value is similar to one other while also being the opposite of another. so yielding just one score per individual seems like it wouldn&amp;#39;t make sense? like they would cancel each other out somehow? i don&amp;#39;t know)&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;using factor analysis, the 10 values can be reduced into a couple (?) of dimensions (I guess). but would that lead to a score? or a score with two dimensions (like a point coordinate in xy-axis)? &lt;/p&gt;\n\n&lt;p&gt;does anybody have any clue? help.........please?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y800ys", "is_robot_indexable": true, "report_reasons": null, "author": "cauliflowingo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y800ys/schwartz_value_survey_analysis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y800ys/schwartz_value_survey_analysis/", "subreddit_subscribers": 814398, "created_utc": 1666178445.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Assumptions before performing tests", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7zsrk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_6wfy9q4l", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "rstats", "selftext": "For example, I want to run an Anova test. \n\nDo I need to check if the data qualifies all assumptions?\n\nWhat do I do when the data does not fulfill any of the assumptions? \n\nWhat is the best way to confirm a normal distribution before such tests? Is a qqplot good enough?", "author_fullname": "t2_6wfy9q4l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Assumptions before performing tests", "link_flair_richtext": [], "subreddit_name_prefixed": "r/rstats", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y7ex5k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666117965.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.rstats", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For example, I want to run an Anova test. &lt;/p&gt;\n\n&lt;p&gt;Do I need to check if the data qualifies all assumptions?&lt;/p&gt;\n\n&lt;p&gt;What do I do when the data does not fulfill any of the assumptions? &lt;/p&gt;\n\n&lt;p&gt;What is the best way to confirm a normal distribution before such tests? Is a qqplot good enough?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r8n0", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7ex5k", "is_robot_indexable": true, "report_reasons": null, "author": "1SageK1", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/rstats/comments/y7ex5k/assumptions_before_performing_tests/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/rstats/comments/y7ex5k/assumptions_before_performing_tests/", "subreddit_subscribers": 67769, "created_utc": 1666117965.0, "num_crossposts": 3, "media": null, "is_video": false}], "created": 1666177732.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.rstats", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/rstats/comments/y7ex5k/assumptions_before_performing_tests/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y7zsrk", "is_robot_indexable": true, "report_reasons": null, "author": "1SageK1", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_y7ex5k", "author_flair_text_color": null, "permalink": "/r/datascience/comments/y7zsrk/assumptions_before_performing_tests/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/rstats/comments/y7ex5k/assumptions_before_performing_tests/", "subreddit_subscribers": 814398, "created_utc": 1666177732.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone! I'm starting to delve into this field and want to know what are the biggest challenges of this topic.", "author_fullname": "t2_lp9fwhgv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the biggest challenges of natural language processing now?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y8cl4u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666209448.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone! I&amp;#39;m starting to delve into this field and want to know what are the biggest challenges of this topic.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y8cl4u", "is_robot_indexable": true, "report_reasons": null, "author": "comrade_pustota", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y8cl4u/what_are_the_biggest_challenges_of_natural/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y8cl4u/what_are_the_biggest_challenges_of_natural/", "subreddit_subscribers": 814398, "created_utc": 1666209448.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}