{"kind": "Listing", "data": {"after": null, "dist": 13, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I will go first. Yesterday I deployed my spark script and it overwrote the table I been loading for a while.\n\nJust started a new project this week and this project use older version of Spark. It was supposed to only overwrite the partition but instead, the whole table was wiped. \n\nWho knows that dynamic partition overwrite only work after spark 2.3\n\nNow I am spending part of the weekend rebuilding the table.", "author_fullname": "t2_c3yqm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What did you screw up this year", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zo4ntl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 38, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 38, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671277602.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I will go first. Yesterday I deployed my spark script and it overwrote the table I been loading for a while.&lt;/p&gt;\n\n&lt;p&gt;Just started a new project this week and this project use older version of Spark. It was supposed to only overwrite the partition but instead, the whole table was wiped. &lt;/p&gt;\n\n&lt;p&gt;Who knows that dynamic partition overwrite only work after spark 2.3&lt;/p&gt;\n\n&lt;p&gt;Now I am spending part of the weekend rebuilding the table.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zo4ntl", "is_robot_indexable": true, "report_reasons": null, "author": "543254447", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zo4ntl/what_did_you_screw_up_this_year/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zo4ntl/what_did_you_screw_up_this_year/", "subreddit_subscribers": 83168, "created_utc": 1671277602.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know that there are so many concepts, but if you are just getting started with data engineering, and you know Python and SQL, what would you recommend learning next to start building a strong data engineering foundation?\n\nWould it be good to start learning how to build pipelines, or should I choose a resource that goes through the entire data engineering cycle, such as data camp?\n\nThank you in advance!", "author_fullname": "t2_4841f127", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What concepts/tools should I learn after Python and SQL basics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_znz3g0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671255087.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know that there are so many concepts, but if you are just getting started with data engineering, and you know Python and SQL, what would you recommend learning next to start building a strong data engineering foundation?&lt;/p&gt;\n\n&lt;p&gt;Would it be good to start learning how to build pipelines, or should I choose a resource that goes through the entire data engineering cycle, such as data camp?&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "znz3g0", "is_robot_indexable": true, "report_reasons": null, "author": "The-Fourth-Hokage", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/znz3g0/what_conceptstools_should_i_learn_after_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/znz3g0/what_conceptstools_should_i_learn_after_python/", "subreddit_subscribers": 83168, "created_utc": 1671255087.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Giving my review of the AWS Cloud Practitioner Certificate, and how useful it is for data engineering. \n\nWhat I didn't like:\n\n\\- 40% of the exam is memorizing acronyms and names of AWS services, as well as cost/billing. \n\nWhat I liked:\n\n\\- It helped me gain general exposure to what cloud computing can do and how it works. Cloud computing is definitely one of the more impactful technologies of the past decade/future decade. \n\n\\- It helped me get general exposure via curriculum to other areas of tech that I wouldn't otherwise have learned about. Namely - Networking, Cybersecurity. \n\n\\- It helped me refresh my knowledge on renting compute/storage, containerization, application integration(kafka, pubsub), databases/datawarehouses. \n\nWould I recommend it for data engineers?\n\nYes, unless you already have &gt;1 of experience managing cloud resources/billing/etc and have some basic exposure to backend engineering. Overall, I think it's a good way to formally learn about the general cloud computing and tech landscape. \n\nWill it help with landing a job?\n\nThe certificate by itself? Definitely no. But I would think of it as a small bonus if I saw it on a candidates resume.", "author_fullname": "t2_8x16rrzg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Review of AWS Cloud Practitioner Certificate", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zny6cb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671251762.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Giving my review of the AWS Cloud Practitioner Certificate, and how useful it is for data engineering. &lt;/p&gt;\n\n&lt;p&gt;What I didn&amp;#39;t like:&lt;/p&gt;\n\n&lt;p&gt;- 40% of the exam is memorizing acronyms and names of AWS services, as well as cost/billing. &lt;/p&gt;\n\n&lt;p&gt;What I liked:&lt;/p&gt;\n\n&lt;p&gt;- It helped me gain general exposure to what cloud computing can do and how it works. Cloud computing is definitely one of the more impactful technologies of the past decade/future decade. &lt;/p&gt;\n\n&lt;p&gt;- It helped me get general exposure via curriculum to other areas of tech that I wouldn&amp;#39;t otherwise have learned about. Namely - Networking, Cybersecurity. &lt;/p&gt;\n\n&lt;p&gt;- It helped me refresh my knowledge on renting compute/storage, containerization, application integration(kafka, pubsub), databases/datawarehouses. &lt;/p&gt;\n\n&lt;p&gt;Would I recommend it for data engineers?&lt;/p&gt;\n\n&lt;p&gt;Yes, unless you already have &amp;gt;1 of experience managing cloud resources/billing/etc and have some basic exposure to backend engineering. Overall, I think it&amp;#39;s a good way to formally learn about the general cloud computing and tech landscape. &lt;/p&gt;\n\n&lt;p&gt;Will it help with landing a job?&lt;/p&gt;\n\n&lt;p&gt;The certificate by itself? Definitely no. But I would think of it as a small bonus if I saw it on a candidates resume.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zny6cb", "is_robot_indexable": true, "report_reasons": null, "author": "Justanotherguy2022", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/zny6cb/review_of_aws_cloud_practitioner_certificate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zny6cb/review_of_aws_cloud_practitioner_certificate/", "subreddit_subscribers": 83168, "created_utc": 1671251762.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m learning Apache Spark through \u201cLearning Spark\u201d book. But I would prefer good video tutorial to learn.  \n\nCan you guys please share good resources to learn how things work under the wood.", "author_fullname": "t2_7lxzxgj0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any good resources to learn Apache spark?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zo7609", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671286523.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m learning Apache Spark through \u201cLearning Spark\u201d book. But I would prefer good video tutorial to learn.  &lt;/p&gt;\n\n&lt;p&gt;Can you guys please share good resources to learn how things work under the wood.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zo7609", "is_robot_indexable": true, "report_reasons": null, "author": "Consistent_Ad5511", "discussion_type": null, "num_comments": 38, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zo7609/any_good_resources_to_learn_apache_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zo7609/any_good_resources_to_learn_apache_spark/", "subreddit_subscribers": 83168, "created_utc": 1671286523.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I can\u2019t seem to think of anything other than Netflix streaming when anyone says the word streaming\u2026", "author_fullname": "t2_a7nec5bo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is streaming in the context of data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zo176l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671263143.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I can\u2019t seem to think of anything other than Netflix streaming when anyone says the word streaming\u2026&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zo176l", "is_robot_indexable": true, "report_reasons": null, "author": "TheCumCopter", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zo176l/what_is_streaming_in_the_context_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zo176l/what_is_streaming_in_the_context_of_data/", "subreddit_subscribers": 83168, "created_utc": 1671263143.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m working on a personal project where I crawl posts, comments, and users from Reddit\u2019s API and store the data in a data warehouse. Every Reddit submission or comment has attributes that can't change over time, such as its url, id, parent subreddit, etc. I plan to fetch more data for the same posts/comments on a set interval and record changes in some of the attributes that *do* change, such as upvotes. \n\nThis is how I\u2019ve designed my [posts schema](https://imgur.com/a/jGqtbC4). On the far right are the static post attributes, which are linked to changing attributes in a details table via a versions table. Each \"version\" represents a different time that I've fetched data from the API for that post, which I will do at a set interval.\n\nThe other tables branch out from the details table since they also may change between crawls.\n\nWhat are some ways I could improve this design, and do you know of any tools that I could use to automate some of the work required in maintaining this? I'm planning to start learning about SQLAlchemy's ORM to see if that can help me.\n\nI should also mention that I prefixed all of the id fields and timestamps that I generated myself (fields that did not come from Reddit) with the word `zen`. This means nothing, I just thought it was a good way to distinguish which fields I generated myself.", "author_fullname": "t2_6gwxih9e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for feedback on my data warehouse schema design for my personal project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_znruh1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1671231979.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m working on a personal project where I crawl posts, comments, and users from Reddit\u2019s API and store the data in a data warehouse. Every Reddit submission or comment has attributes that can&amp;#39;t change over time, such as its url, id, parent subreddit, etc. I plan to fetch more data for the same posts/comments on a set interval and record changes in some of the attributes that &lt;em&gt;do&lt;/em&gt; change, such as upvotes. &lt;/p&gt;\n\n&lt;p&gt;This is how I\u2019ve designed my &lt;a href=\"https://imgur.com/a/jGqtbC4\"&gt;posts schema&lt;/a&gt;. On the far right are the static post attributes, which are linked to changing attributes in a details table via a versions table. Each &amp;quot;version&amp;quot; represents a different time that I&amp;#39;ve fetched data from the API for that post, which I will do at a set interval.&lt;/p&gt;\n\n&lt;p&gt;The other tables branch out from the details table since they also may change between crawls.&lt;/p&gt;\n\n&lt;p&gt;What are some ways I could improve this design, and do you know of any tools that I could use to automate some of the work required in maintaining this? I&amp;#39;m planning to start learning about SQLAlchemy&amp;#39;s ORM to see if that can help me.&lt;/p&gt;\n\n&lt;p&gt;I should also mention that I prefixed all of the id fields and timestamps that I generated myself (fields that did not come from Reddit) with the word &lt;code&gt;zen&lt;/code&gt;. This means nothing, I just thought it was a good way to distinguish which fields I generated myself.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Fq31V7lHOW_-V7n6OnzzxtLaW7XM7Cha7pzXhzRjh7E.jpg?auto=webp&amp;s=9bc71b140d6184607fc75b4ab71979e2675d671f", "width": 2030, "height": 1558}, "resolutions": [{"url": "https://external-preview.redd.it/Fq31V7lHOW_-V7n6OnzzxtLaW7XM7Cha7pzXhzRjh7E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a84ecae3adbfa8f6e1b9f94b28d5f56f1272771a", "width": 108, "height": 82}, {"url": "https://external-preview.redd.it/Fq31V7lHOW_-V7n6OnzzxtLaW7XM7Cha7pzXhzRjh7E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d49e99e2dfddb96c55298145f7c6445ab54e3e09", "width": 216, "height": 165}, {"url": "https://external-preview.redd.it/Fq31V7lHOW_-V7n6OnzzxtLaW7XM7Cha7pzXhzRjh7E.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=53710df9624f40d14d86ae9d00f082810abdef82", "width": 320, "height": 245}, {"url": "https://external-preview.redd.it/Fq31V7lHOW_-V7n6OnzzxtLaW7XM7Cha7pzXhzRjh7E.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3c617a58eaa09b4db14145082bf463b0567d41e1", "width": 640, "height": 491}, {"url": "https://external-preview.redd.it/Fq31V7lHOW_-V7n6OnzzxtLaW7XM7Cha7pzXhzRjh7E.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c2b89a5233dab0f526d263433b39b24f36788162", "width": 960, "height": 736}, {"url": "https://external-preview.redd.it/Fq31V7lHOW_-V7n6OnzzxtLaW7XM7Cha7pzXhzRjh7E.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1101d7b27654ed69f84a3dd2e3e3416d04c86a6b", "width": 1080, "height": 828}], "variants": {}, "id": "wyunczzbIOuQZE-eUcPZYzruYUoObtrKie5Xz4VG_g4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "znruh1", "is_robot_indexable": true, "report_reasons": null, "author": "abelEngineer", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/znruh1/looking_for_feedback_on_my_data_warehouse_schema/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/znruh1/looking_for_feedback_on_my_data_warehouse_schema/", "subreddit_subscribers": 83168, "created_utc": 1671231979.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am trying to start a career as a data engineer. I hold a software engineering degree and have nearly 10 years experience working in software development roles. I have also just gained the Google Cloud Professional Data Engineer Cert.\n\nI have been applying for junior and entry level data engineer jobs but so far having 0 luck. I can only assume it is down to no data engineering experience. I\u2019m not getting to the interview stage\n\nIs there anywhere I can do pro bono data engineering work to gain experience for my applications and will it improve my employment chances?\n\nI am in the UK\n\nThanks.\n\nEdit..\n\nI didn't really want to mention this. My dad became terminally ill in 2018 and I had to look after the property business. Then covid hit. I spent this year learning DE and earning the Google cert and I'm at the point were I feel confident enough to apply for DE roles.\n\nSo as far as my CV goes I have listed property manager from 2018 until now. Whether this is a problem I don't know. I'm 39 by the way if that makes a difference.", "author_fullname": "t2_1wjala", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pro Bono Data Engineering Work For Experience?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_znvgq3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1671297765.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671242604.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to start a career as a data engineer. I hold a software engineering degree and have nearly 10 years experience working in software development roles. I have also just gained the Google Cloud Professional Data Engineer Cert.&lt;/p&gt;\n\n&lt;p&gt;I have been applying for junior and entry level data engineer jobs but so far having 0 luck. I can only assume it is down to no data engineering experience. I\u2019m not getting to the interview stage&lt;/p&gt;\n\n&lt;p&gt;Is there anywhere I can do pro bono data engineering work to gain experience for my applications and will it improve my employment chances?&lt;/p&gt;\n\n&lt;p&gt;I am in the UK&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n\n&lt;p&gt;Edit..&lt;/p&gt;\n\n&lt;p&gt;I didn&amp;#39;t really want to mention this. My dad became terminally ill in 2018 and I had to look after the property business. Then covid hit. I spent this year learning DE and earning the Google cert and I&amp;#39;m at the point were I feel confident enough to apply for DE roles.&lt;/p&gt;\n\n&lt;p&gt;So as far as my CV goes I have listed property manager from 2018 until now. Whether this is a problem I don&amp;#39;t know. I&amp;#39;m 39 by the way if that makes a difference.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "znvgq3", "is_robot_indexable": true, "report_reasons": null, "author": "CJH55", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/znvgq3/pro_bono_data_engineering_work_for_experience/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/znvgq3/pro_bono_data_engineering_work_for_experience/", "subreddit_subscribers": 83168, "created_utc": 1671242604.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I write a lot of Python and Pyspark scrips for the automation and ETL processes for my department and a few others. Majority of the data used comes from APIs and in some cases gets loaded into S3 buckets, Azure Blobs and Salesforce. \n\nAt the moment I have the actual Api keys assigned to a variable in the script so if someone unauthorized gets access to the script then they can get access to the data.\n\nI know this is not right so I want to figure out the appropriate way to do it so that I can update the scripts.\n\nWhat is the correct way to securely pass the APIs keys and other keys in the script?", "author_fullname": "t2_dkq68c2f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to handle Api keys, secret keys and access keys", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zo2vac", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671270192.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I write a lot of Python and Pyspark scrips for the automation and ETL processes for my department and a few others. Majority of the data used comes from APIs and in some cases gets loaded into S3 buckets, Azure Blobs and Salesforce. &lt;/p&gt;\n\n&lt;p&gt;At the moment I have the actual Api keys assigned to a variable in the script so if someone unauthorized gets access to the script then they can get access to the data.&lt;/p&gt;\n\n&lt;p&gt;I know this is not right so I want to figure out the appropriate way to do it so that I can update the scripts.&lt;/p&gt;\n\n&lt;p&gt;What is the correct way to securely pass the APIs keys and other keys in the script?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zo2vac", "is_robot_indexable": true, "report_reasons": null, "author": "MajiYaKuoshaVyombo", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zo2vac/how_to_handle_api_keys_secret_keys_and_access_keys/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zo2vac/how_to_handle_api_keys_secret_keys_and_access_keys/", "subreddit_subscribers": 83168, "created_utc": 1671270192.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was wondering if anyone could give me some insight on what type of series I should get for an Azure VM to host AirByte for our EL use-cases.\n\nOur use-case is to build a robust BI platform for our company's data. Our main two vendors have provided replicas for us to read from so that we can get the data into our own data warehouse.\n\nThe data sources are:\n\n1. Azure SQL Database: 35 million total rows, 8.5gb, and 100,000 upserts daily\n2. AWS RDS SQL Server w/60 Databases: 124 billion total rows, 31tb, and 25 million upserts daily\n\nSo after the initial snapshots of \\~124 billion records, I'll need to then support \\~25.1 million inserts in the EL pipelines daily. I could schedule the replications in AirByte to try to spread out the EL jobs as much as possible.\n\nI was looking at the D, E, and F series VM's in Azure, but I'm not exactly sure which is the best choice. If anyone has any insight so I don't totally mess this up I'd really appreciate it.", "author_fullname": "t2_tql2kvxf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What type of Azure VM to use for AirByte?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_znvoys", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671243316.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was wondering if anyone could give me some insight on what type of series I should get for an Azure VM to host AirByte for our EL use-cases.&lt;/p&gt;\n\n&lt;p&gt;Our use-case is to build a robust BI platform for our company&amp;#39;s data. Our main two vendors have provided replicas for us to read from so that we can get the data into our own data warehouse.&lt;/p&gt;\n\n&lt;p&gt;The data sources are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Azure SQL Database: 35 million total rows, 8.5gb, and 100,000 upserts daily&lt;/li&gt;\n&lt;li&gt;AWS RDS SQL Server w/60 Databases: 124 billion total rows, 31tb, and 25 million upserts daily&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;So after the initial snapshots of ~124 billion records, I&amp;#39;ll need to then support ~25.1 million inserts in the EL pipelines daily. I could schedule the replications in AirByte to try to spread out the EL jobs as much as possible.&lt;/p&gt;\n\n&lt;p&gt;I was looking at the D, E, and F series VM&amp;#39;s in Azure, but I&amp;#39;m not exactly sure which is the best choice. If anyone has any insight so I don&amp;#39;t totally mess this up I&amp;#39;d really appreciate it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "znvoys", "is_robot_indexable": true, "report_reasons": null, "author": "AzureNoob1", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/znvoys/what_type_of_azure_vm_to_use_for_airbyte/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/znvoys/what_type_of_azure_vm_to_use_for_airbyte/", "subreddit_subscribers": 83168, "created_utc": 1671243316.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[DuckDB](https://duckdb.org/) (an in-process SQL OLAP database management system) is gaining a lot of popularity these days. So, we created a new monthly newsletter to keep you updated about the last projects, articles, resources, videos, and everything related to DuckDB. You can read the first issue here:\n\n[https://motherduck.com/blog/duckdb-ecosystem-newsletter-one/](https://motherduck.com/blog/duckdb-ecosystem-newsletter-one/)", "author_fullname": "t2_ugjew", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New monthly newsletter related to DuckDB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zoetye", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1671307527.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://duckdb.org/\"&gt;DuckDB&lt;/a&gt; (an in-process SQL OLAP database management system) is gaining a lot of popularity these days. So, we created a new monthly newsletter to keep you updated about the last projects, articles, resources, videos, and everything related to DuckDB. You can read the first issue here:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://motherduck.com/blog/duckdb-ecosystem-newsletter-one/\"&gt;https://motherduck.com/blog/duckdb-ecosystem-newsletter-one/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/GctXJNpN2X3nQLnJV4YKiGNicM-bQELTDEHwQJ3tLlo.jpg?auto=webp&amp;s=df4fb13c0741919fd9f695ba304cb6d3a1fb56ed", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/GctXJNpN2X3nQLnJV4YKiGNicM-bQELTDEHwQJ3tLlo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5ac7c3882de773b950cd2e3cd83aba08b84d6fa7", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/GctXJNpN2X3nQLnJV4YKiGNicM-bQELTDEHwQJ3tLlo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e011b38bce0303748d54aed1967329a61ba0bf14", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/GctXJNpN2X3nQLnJV4YKiGNicM-bQELTDEHwQJ3tLlo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=28287676b7e382af057ff233ebabb92eb44395da", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/GctXJNpN2X3nQLnJV4YKiGNicM-bQELTDEHwQJ3tLlo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=17a7e3ab4756e9f324d7dfbf41f4877a51c3a790", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/GctXJNpN2X3nQLnJV4YKiGNicM-bQELTDEHwQJ3tLlo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b38599a9c28c8b8760b7158ed21e418d1d88ff32", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/GctXJNpN2X3nQLnJV4YKiGNicM-bQELTDEHwQJ3tLlo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4eaa0d481f6cb0b5bde29d1b7160f655cc8a2cc8", "width": 1080, "height": 567}], "variants": {}, "id": "jWyiaF4Jb7ULQyU8SCl75THeEbJM9dbSQ9YXdauXufk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zoetye", "is_robot_indexable": true, "report_reasons": null, "author": "marcosluis2186", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zoetye/new_monthly_newsletter_related_to_duckdb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zoetye/new_monthly_newsletter_related_to_duckdb/", "subreddit_subscribers": 83168, "created_utc": 1671307527.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I've learned how to use T-SQL in SMSS. I want to get some practise in making a database with raw/unprocessed data. Do such sources exist? What format would they be in as opposed to being organised into tables? Are there any reliable suggestions you can give?\n\nThanks in advance.", "author_fullname": "t2_tv2a43m8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Raw Data Sources for Practise in Building Databases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zog2ic", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671310761.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;ve learned how to use T-SQL in SMSS. I want to get some practise in making a database with raw/unprocessed data. Do such sources exist? What format would they be in as opposed to being organised into tables? Are there any reliable suggestions you can give?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zog2ic", "is_robot_indexable": true, "report_reasons": null, "author": "headrazor", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zog2ic/raw_data_sources_for_practise_in_building/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zog2ic/raw_data_sources_for_practise_in_building/", "subreddit_subscribers": 83168, "created_utc": 1671310761.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, all.\n\nI am new to the C++ SDK. I am trying to list all of the items inside of a s3 subfolder without listing every file in the bucket. The bucket I am trying to view is \"noaa-goes16.\" The sub-folder I want to list the objects in is \"/GLM-L2-LCFA/2021/140/05/\". The code I have currently is this:\n\n\\`\\`\\`\n\nbool ListObjects(const Aws::String&amp; bucketName,\n\nconst Aws::Client::ClientConfiguration&amp; clientConfig) {\n\nAws::S3::S3Client s3\\_client(clientConfig);\n\n&amp;#x200B;\n\nAws::S3::Model::ListObjectsRequest request;\n\nrequest.WithBucket(bucketName);\n\n&amp;#x200B;\n\nauto outcome = s3\\_client.ListObjects(request);\n\n&amp;#x200B;\n\nif (!outcome.IsSuccess()) {\n\nstd::cerr &lt;&lt; \"Error: ListObjects: \" &lt;&lt;\n\noutcome.GetError().GetMessage() &lt;&lt; std::endl;\n\n}\n\nelse {\n\nAws::Vector&lt;Aws::S3::Model::Object&gt; objects =\n\noutcome.GetResult().GetContents();\n\n&amp;#x200B;\n\nfor (Aws::S3::Model::Object&amp; object : objects) {\n\nstd::cout &lt;&lt; object.GetKey() &lt;&lt; std::endl;\n\n}\n\n}\n\nreturn outcome.IsSuccess();\n\n&amp;#x200B;\n\nint main(){\n\nAws::SDKOptions options;\n\nAws::InitAPI(options);\n\nstd::string object = \"noaa-goes16/GLM-L2-LCFA/2021/140/05/\";\n\nListObjects(object, clientConfig);\n\nAws::ShutdownAPI(options);\n\n\\`\\`\\`\n\nThe error returns: \"Error: ListObjects: The specified key does not exist.\"\n\n\\[Here\\]([https://noaa-goes16.s3.amazonaws.com/index.html#GLM-L2-LCFA/2021/140/05/](https://noaa-goes16.s3.amazonaws.com/index.html#GLM-L2-LCFA/2021/140/05/)) is the exact key I am trying to pass.\n\nIs it possible to list only the files in a subfolder with the c++ SDK? Or, is this the wrong way to solve this problem?", "author_fullname": "t2_12d3fk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I list objects in \"subfolder\" of S3 bucket using c++?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zofhnt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671309233.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, all.&lt;/p&gt;\n\n&lt;p&gt;I am new to the C++ SDK. I am trying to list all of the items inside of a s3 subfolder without listing every file in the bucket. The bucket I am trying to view is &amp;quot;noaa-goes16.&amp;quot; The sub-folder I want to list the objects in is &amp;quot;/GLM-L2-LCFA/2021/140/05/&amp;quot;. The code I have currently is this:&lt;/p&gt;\n\n&lt;p&gt;```&lt;/p&gt;\n\n&lt;p&gt;bool ListObjects(const Aws::String&amp;amp; bucketName,&lt;/p&gt;\n\n&lt;p&gt;const Aws::Client::ClientConfiguration&amp;amp; clientConfig) {&lt;/p&gt;\n\n&lt;p&gt;Aws::S3::S3Client s3_client(clientConfig);&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Aws::S3::Model::ListObjectsRequest request;&lt;/p&gt;\n\n&lt;p&gt;request.WithBucket(bucketName);&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;auto outcome = s3_client.ListObjects(request);&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;if (!outcome.IsSuccess()) {&lt;/p&gt;\n\n&lt;p&gt;std::cerr &amp;lt;&amp;lt; &amp;quot;Error: ListObjects: &amp;quot; &amp;lt;&amp;lt;&lt;/p&gt;\n\n&lt;p&gt;outcome.GetError().GetMessage() &amp;lt;&amp;lt; std::endl;&lt;/p&gt;\n\n&lt;p&gt;}&lt;/p&gt;\n\n&lt;p&gt;else {&lt;/p&gt;\n\n&lt;p&gt;Aws::Vector&amp;lt;Aws::S3::Model::Object&amp;gt; objects =&lt;/p&gt;\n\n&lt;p&gt;outcome.GetResult().GetContents();&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;for (Aws::S3::Model::Object&amp;amp; object : objects) {&lt;/p&gt;\n\n&lt;p&gt;std::cout &amp;lt;&amp;lt; object.GetKey() &amp;lt;&amp;lt; std::endl;&lt;/p&gt;\n\n&lt;p&gt;}&lt;/p&gt;\n\n&lt;p&gt;}&lt;/p&gt;\n\n&lt;p&gt;return outcome.IsSuccess();&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;int main(){&lt;/p&gt;\n\n&lt;p&gt;Aws::SDKOptions options;&lt;/p&gt;\n\n&lt;p&gt;Aws::InitAPI(options);&lt;/p&gt;\n\n&lt;p&gt;std::string object = &amp;quot;noaa-goes16/GLM-L2-LCFA/2021/140/05/&amp;quot;;&lt;/p&gt;\n\n&lt;p&gt;ListObjects(object, clientConfig);&lt;/p&gt;\n\n&lt;p&gt;Aws::ShutdownAPI(options);&lt;/p&gt;\n\n&lt;p&gt;```&lt;/p&gt;\n\n&lt;p&gt;The error returns: &amp;quot;Error: ListObjects: The specified key does not exist.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;[Here](&lt;a href=\"https://noaa-goes16.s3.amazonaws.com/index.html#GLM-L2-LCFA/2021/140/05/\"&gt;https://noaa-goes16.s3.amazonaws.com/index.html#GLM-L2-LCFA/2021/140/05/&lt;/a&gt;) is the exact key I am trying to pass.&lt;/p&gt;\n\n&lt;p&gt;Is it possible to list only the files in a subfolder with the c++ SDK? Or, is this the wrong way to solve this problem?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zofhnt", "is_robot_indexable": true, "report_reasons": null, "author": "corey4005", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zofhnt/how_do_i_list_objects_in_subfolder_of_s3_bucket/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zofhnt/how_do_i_list_objects_in_subfolder_of_s3_bucket/", "subreddit_subscribers": 83168, "created_utc": 1671309233.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A few years ago I thought it was dying but sadly tools like dbt seem to mean it's making a resurgence. I prefer a general purpose programming language like Python in all circumstances. A dataframe-style API gives you everything you need for working with data. Discuss.", "author_fullname": "t2_10iqu1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "does anyone else hate SQL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_znqf92", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.27, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1671231985.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671228245.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A few years ago I thought it was dying but sadly tools like dbt seem to mean it&amp;#39;s making a resurgence. I prefer a general purpose programming language like Python in all circumstances. A dataframe-style API gives you everything you need for working with data. Discuss.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "znqf92", "is_robot_indexable": true, "report_reasons": null, "author": "Sister_Ray_", "discussion_type": null, "num_comments": 74, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/znqf92/does_anyone_else_hate_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/znqf92/does_anyone_else_hate_sql/", "subreddit_subscribers": 83168, "created_utc": 1671228245.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}