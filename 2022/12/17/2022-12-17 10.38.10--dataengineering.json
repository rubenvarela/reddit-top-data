{"kind": "Listing", "data": {"after": null, "dist": 19, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**Background about myself:**  \nI spent 5 years doing actuarial consulting where I learned the world is held together by linked Excel pipelines and various languages largely due to turnover. Their one data person only knew VBA, and then another person only knew SQL, so set up a mySQL file that is imported to Excel via VBA and there will be documentation along the lines of \"if excel breaks, do this:)\"\n\nI was spending weeks doing data ingestion into Excel because all we knew were Index/Match to do joins and any file over a million rows would take 50 minutes locking your computer to complete. So I learned R on the side because it was the open source version of SAS and it was gaining ground in the insurance industry.\n\nThings happen and I essentially got pushed out of the actuarial profession and I used that time to self teach data science and then spent 4 years as a Data Science consultant that often got thrown into Data Engineering projects because we'd sell work we didn't have the staff for.  \n\nBecause of project deliverable deadlines, you have limited time to get familiar with the new technology else embarrass yourself in front of the stakeholders and have to claw back the respect. Because of this, my skillsets grew more horizontally from being exposed to various different problems to solve. I'd like to share some of the lessons learned\n\n**Keep Everything In Writing:**  \nThis is mostly a CYA ticket and can help you prepare everything come self review time when you need to list out what you've accomplished and try and quantify the value you provide. No matter where you work, there will be some amount of red tape / politics that go against your every being, but keeping everything in writing will save you in your career. \n\nIf you have a meeting with a manager who gives you a project, instead of taking notes during the meeting, pay attention and ask smart questions so that you have a plan in mind before you hang up the call. Follow that call up in writing with your understanding of the call and your next steps. If there's a \"misunderstanding\" down the line, you have that email to reflect back on to remind you.\n\nYou never know what information will come in handy in the future.\n\n**There's No Shortcuts To Learning**  \nTaking online courses, chasing badges, and getting a Masters will help you get familiar with the topics, but leaves you with a lot of gaps in your knowledge that will be filled in as you get more experienced. Keeping your Ego in check is part of the equation because you don't want to be at the beginning of the Dunning Kruger curve and end up saying something confidently incorrect that loses some credibility.\n\nI approach learning like I approach data: organize it in layers. \n\nMy first approach is going through my content (usually textbooks,lectures , workshops, and documentation) and dumping all my notes into a junk notebook with my personal style of note taking that works best for me.\n\nI then take what I've learned and scope out a plan to apply it to a project, whether it be a personal one or a project I got thrown into and note any programming gotchas in the same junk notebook. \n\nAfter that, I'll watch a few more videos, take some notes, and then condense/rewrite them into a notebook where I have cleaner handwriting and take time to draw nicer visualizations and diagrams.\n\nRinse and repeat as the project develops and I find more gotchas or learn new things. As I'm going, I take note of questions stakeholders ask or think of some questions people may ask, so I can have the answers ready. Finally, once the project is only, I'll recreate my notes digitally, usually in Confluence and use it as an onboarding tool for junior devs.\n\nAs this develops across your project and knowing you should keep everything in writing, this becomes your personal knowledge base and an easy way to refresh yourself on things you've done years ago. Have to tackle MongoDB after not using the syntax for 3 years? Make a Confluence page for it when you're done. Collect your code chunks into libraries that you can use again.\n\n**Know Your Limits**  \nThe data industry is relatively new and over time, roles are becoming more defined over time and has caused a divergence between what a role states in a job and what your day to day will look like. It's grown so fast over the past decade, that inevitably means incompetent leadership is going to exist. The most dangerous form I've seen of this are leaders that have no clue how data actually moves and have no intent to learn. Projects are usually underscoped and developers are the ones always doing the work.\n\nThe onus shouldn't be, but is on the developers to communicate how long things will take because leaders have no idea. When you're inexperienced, it's hard to scope your own projects and you'll end up shooting yourself in the foot if you overestimate your abilities or run into a gotcha that will cause your project to be late.\n\nIt's important to hone that self awareness and ability to scope a project. Ask the proper questions and give a conservative estimate accounting for proper development. If they push back, confirm you believe it will take the initial estimate, and offer additional solutions if you can.\n\nAs things change through out the project, communicate upwards as soon as possible. Send an email with the issue you're facing, your path forward, how long it is estimated to fix, if it's a blocker, and how it will affect the timeline. \n\nThere will inevitably be moments when you're working long hours or get on call to fix an issue that will have material impacts on the company. This is a balancing act and can easily lead to scope creep or your workload piling on top of you. As people learn you get shit done, more people are going to want a piece of you. You'll want to say yes because you're a hard worker, but all the gotchas catch up to you and now you've accumulated tech debt just to get the deliverables out. It happens in every industry and every company. The difference is how the leaders react to this situation. If they're not communicating upwards and leaving you hang to dry, that's were CYA mode comes into play. Hold your ground that you cannot work additional hours because of personal obligations and maintain that stance. It may seem counterintuitive toward your success at the company, but hard work doesn't always pay off.\n\nI personally don't mind working long hours if I'm getting some learning experiences out of it. I hate when I am thrown into situations where the time pressure was avoidable from the beginning. \n\n**Don't Be Afraid To Ask For Help**  \nThis was a big lesson early on in my career. I am the type that likes to figure things out on my own, but sometimes that doesn't align with deadlines. So you have to have self awareness to know you're spinning your wheels and seek out an alternative solution.\n\nAsking for help doesn't mean copy/pasting your traceback errors to coworkers and asking for help. It means, when you've done all the proper searching and debugging yourself, present your issue, what you tried so far, and ask if they've encountered something similar or to take a peek at your code to see if there's anything glaring. It will develop a good personal debugging strategy and soon you'll be the person people go to for issues and it's always a good feeling to help someone else.\n\n**Stand Up For What You Believe In**  \nI've encountered a lot of unethical practices ranging from sexual assault, to CEOs forcing people to work while family was in the hospital, to leaders calling their employees dumb. Just every aspect of a toxic workplace. There's a lot of people that are afraid to speak up in fear of losing their job. People turn a blind eye or come straight out of college and consider it \"business as usual\". A lot of people will just quietly put their two weeks in and get out, but the underlying situation is never fixed. If you witness anything or have something done to you, send it to all the leaders you can in one email that can handle the situation. It's their responsibility to provide a safe workspace. If they do not handle the situation, go one higher up. If nothing gets done and it's affecting your mental health, get a note from your primary care physician, take a mental health FLMA leave (in the US), lawyer up if needed, and get out of there. I've seen companies protect leadership for years just because they brought in a lot of income. \n\nMy personal thing is if I have no one I can look up to at the organization, then there's really no point in me staying. \n\nI hope this all makes sense and is useful to someone. I came from a non traditional background compared to my peers and faced a lot of imposter syndrome. It comes in goes in waves, but instead of thinking I can never be as good as that person, I try and apply the positive things I learn from them.", "author_fullname": "t2_rdm9w1f0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sharing my experiences", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_znluub", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 53, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 53, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671216289.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Background about myself:&lt;/strong&gt;&lt;br/&gt;\nI spent 5 years doing actuarial consulting where I learned the world is held together by linked Excel pipelines and various languages largely due to turnover. Their one data person only knew VBA, and then another person only knew SQL, so set up a mySQL file that is imported to Excel via VBA and there will be documentation along the lines of &amp;quot;if excel breaks, do this:)&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;I was spending weeks doing data ingestion into Excel because all we knew were Index/Match to do joins and any file over a million rows would take 50 minutes locking your computer to complete. So I learned R on the side because it was the open source version of SAS and it was gaining ground in the insurance industry.&lt;/p&gt;\n\n&lt;p&gt;Things happen and I essentially got pushed out of the actuarial profession and I used that time to self teach data science and then spent 4 years as a Data Science consultant that often got thrown into Data Engineering projects because we&amp;#39;d sell work we didn&amp;#39;t have the staff for.  &lt;/p&gt;\n\n&lt;p&gt;Because of project deliverable deadlines, you have limited time to get familiar with the new technology else embarrass yourself in front of the stakeholders and have to claw back the respect. Because of this, my skillsets grew more horizontally from being exposed to various different problems to solve. I&amp;#39;d like to share some of the lessons learned&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Keep Everything In Writing:&lt;/strong&gt;&lt;br/&gt;\nThis is mostly a CYA ticket and can help you prepare everything come self review time when you need to list out what you&amp;#39;ve accomplished and try and quantify the value you provide. No matter where you work, there will be some amount of red tape / politics that go against your every being, but keeping everything in writing will save you in your career. &lt;/p&gt;\n\n&lt;p&gt;If you have a meeting with a manager who gives you a project, instead of taking notes during the meeting, pay attention and ask smart questions so that you have a plan in mind before you hang up the call. Follow that call up in writing with your understanding of the call and your next steps. If there&amp;#39;s a &amp;quot;misunderstanding&amp;quot; down the line, you have that email to reflect back on to remind you.&lt;/p&gt;\n\n&lt;p&gt;You never know what information will come in handy in the future.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;There&amp;#39;s No Shortcuts To Learning&lt;/strong&gt;&lt;br/&gt;\nTaking online courses, chasing badges, and getting a Masters will help you get familiar with the topics, but leaves you with a lot of gaps in your knowledge that will be filled in as you get more experienced. Keeping your Ego in check is part of the equation because you don&amp;#39;t want to be at the beginning of the Dunning Kruger curve and end up saying something confidently incorrect that loses some credibility.&lt;/p&gt;\n\n&lt;p&gt;I approach learning like I approach data: organize it in layers. &lt;/p&gt;\n\n&lt;p&gt;My first approach is going through my content (usually textbooks,lectures , workshops, and documentation) and dumping all my notes into a junk notebook with my personal style of note taking that works best for me.&lt;/p&gt;\n\n&lt;p&gt;I then take what I&amp;#39;ve learned and scope out a plan to apply it to a project, whether it be a personal one or a project I got thrown into and note any programming gotchas in the same junk notebook. &lt;/p&gt;\n\n&lt;p&gt;After that, I&amp;#39;ll watch a few more videos, take some notes, and then condense/rewrite them into a notebook where I have cleaner handwriting and take time to draw nicer visualizations and diagrams.&lt;/p&gt;\n\n&lt;p&gt;Rinse and repeat as the project develops and I find more gotchas or learn new things. As I&amp;#39;m going, I take note of questions stakeholders ask or think of some questions people may ask, so I can have the answers ready. Finally, once the project is only, I&amp;#39;ll recreate my notes digitally, usually in Confluence and use it as an onboarding tool for junior devs.&lt;/p&gt;\n\n&lt;p&gt;As this develops across your project and knowing you should keep everything in writing, this becomes your personal knowledge base and an easy way to refresh yourself on things you&amp;#39;ve done years ago. Have to tackle MongoDB after not using the syntax for 3 years? Make a Confluence page for it when you&amp;#39;re done. Collect your code chunks into libraries that you can use again.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Know Your Limits&lt;/strong&gt;&lt;br/&gt;\nThe data industry is relatively new and over time, roles are becoming more defined over time and has caused a divergence between what a role states in a job and what your day to day will look like. It&amp;#39;s grown so fast over the past decade, that inevitably means incompetent leadership is going to exist. The most dangerous form I&amp;#39;ve seen of this are leaders that have no clue how data actually moves and have no intent to learn. Projects are usually underscoped and developers are the ones always doing the work.&lt;/p&gt;\n\n&lt;p&gt;The onus shouldn&amp;#39;t be, but is on the developers to communicate how long things will take because leaders have no idea. When you&amp;#39;re inexperienced, it&amp;#39;s hard to scope your own projects and you&amp;#39;ll end up shooting yourself in the foot if you overestimate your abilities or run into a gotcha that will cause your project to be late.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s important to hone that self awareness and ability to scope a project. Ask the proper questions and give a conservative estimate accounting for proper development. If they push back, confirm you believe it will take the initial estimate, and offer additional solutions if you can.&lt;/p&gt;\n\n&lt;p&gt;As things change through out the project, communicate upwards as soon as possible. Send an email with the issue you&amp;#39;re facing, your path forward, how long it is estimated to fix, if it&amp;#39;s a blocker, and how it will affect the timeline. &lt;/p&gt;\n\n&lt;p&gt;There will inevitably be moments when you&amp;#39;re working long hours or get on call to fix an issue that will have material impacts on the company. This is a balancing act and can easily lead to scope creep or your workload piling on top of you. As people learn you get shit done, more people are going to want a piece of you. You&amp;#39;ll want to say yes because you&amp;#39;re a hard worker, but all the gotchas catch up to you and now you&amp;#39;ve accumulated tech debt just to get the deliverables out. It happens in every industry and every company. The difference is how the leaders react to this situation. If they&amp;#39;re not communicating upwards and leaving you hang to dry, that&amp;#39;s were CYA mode comes into play. Hold your ground that you cannot work additional hours because of personal obligations and maintain that stance. It may seem counterintuitive toward your success at the company, but hard work doesn&amp;#39;t always pay off.&lt;/p&gt;\n\n&lt;p&gt;I personally don&amp;#39;t mind working long hours if I&amp;#39;m getting some learning experiences out of it. I hate when I am thrown into situations where the time pressure was avoidable from the beginning. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Don&amp;#39;t Be Afraid To Ask For Help&lt;/strong&gt;&lt;br/&gt;\nThis was a big lesson early on in my career. I am the type that likes to figure things out on my own, but sometimes that doesn&amp;#39;t align with deadlines. So you have to have self awareness to know you&amp;#39;re spinning your wheels and seek out an alternative solution.&lt;/p&gt;\n\n&lt;p&gt;Asking for help doesn&amp;#39;t mean copy/pasting your traceback errors to coworkers and asking for help. It means, when you&amp;#39;ve done all the proper searching and debugging yourself, present your issue, what you tried so far, and ask if they&amp;#39;ve encountered something similar or to take a peek at your code to see if there&amp;#39;s anything glaring. It will develop a good personal debugging strategy and soon you&amp;#39;ll be the person people go to for issues and it&amp;#39;s always a good feeling to help someone else.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Stand Up For What You Believe In&lt;/strong&gt;&lt;br/&gt;\nI&amp;#39;ve encountered a lot of unethical practices ranging from sexual assault, to CEOs forcing people to work while family was in the hospital, to leaders calling their employees dumb. Just every aspect of a toxic workplace. There&amp;#39;s a lot of people that are afraid to speak up in fear of losing their job. People turn a blind eye or come straight out of college and consider it &amp;quot;business as usual&amp;quot;. A lot of people will just quietly put their two weeks in and get out, but the underlying situation is never fixed. If you witness anything or have something done to you, send it to all the leaders you can in one email that can handle the situation. It&amp;#39;s their responsibility to provide a safe workspace. If they do not handle the situation, go one higher up. If nothing gets done and it&amp;#39;s affecting your mental health, get a note from your primary care physician, take a mental health FLMA leave (in the US), lawyer up if needed, and get out of there. I&amp;#39;ve seen companies protect leadership for years just because they brought in a lot of income. &lt;/p&gt;\n\n&lt;p&gt;My personal thing is if I have no one I can look up to at the organization, then there&amp;#39;s really no point in me staying. &lt;/p&gt;\n\n&lt;p&gt;I hope this all makes sense and is useful to someone. I came from a non traditional background compared to my peers and faced a lot of imposter syndrome. It comes in goes in waves, but instead of thinking I can never be as good as that person, I try and apply the positive things I learn from them.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 150, "id": "award_88fdcafc-57a0-48db-99cc-76276bfaf28b", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/tcofsbf92md41_PressF.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/tcofsbf92md41_PressF.png?width=16&amp;height=16&amp;auto=webp&amp;s=3481c2a89c2ebe653aae1b8d627c20c10abfc79e", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/tcofsbf92md41_PressF.png?width=32&amp;height=32&amp;auto=webp&amp;s=2bd2b8a9417e7cc18752927c11f98b242c133f2f", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/tcofsbf92md41_PressF.png?width=48&amp;height=48&amp;auto=webp&amp;s=a34e3d83c5dd9f6c731b1375500e4de8d4fee652", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/tcofsbf92md41_PressF.png?width=64&amp;height=64&amp;auto=webp&amp;s=6525899b9a01d5b0c4deea6c34cd8436ee1ff0c7", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/tcofsbf92md41_PressF.png?width=128&amp;height=128&amp;auto=webp&amp;s=c9e094023649693de991fff551a0c9561d11163a", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "To pay respects.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Press F", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/tcofsbf92md41_PressF.png?width=16&amp;height=16&amp;auto=webp&amp;s=3481c2a89c2ebe653aae1b8d627c20c10abfc79e", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/tcofsbf92md41_PressF.png?width=32&amp;height=32&amp;auto=webp&amp;s=2bd2b8a9417e7cc18752927c11f98b242c133f2f", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/tcofsbf92md41_PressF.png?width=48&amp;height=48&amp;auto=webp&amp;s=a34e3d83c5dd9f6c731b1375500e4de8d4fee652", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/tcofsbf92md41_PressF.png?width=64&amp;height=64&amp;auto=webp&amp;s=6525899b9a01d5b0c4deea6c34cd8436ee1ff0c7", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/tcofsbf92md41_PressF.png?width=128&amp;height=128&amp;auto=webp&amp;s=c9e094023649693de991fff551a0c9561d11163a", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/tcofsbf92md41_PressF.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "znluub", "is_robot_indexable": true, "report_reasons": null, "author": "keeney_arcadia", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/znluub/sharing_my_experiences/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/znluub/sharing_my_experiences/", "subreddit_subscribers": 83130, "created_utc": 1671216289.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can someone gauge if [this bootcamp](https://trendytech.in) is good? I saw this on linkedin and I find the content good to kickstart my journey in big data. It is worth $650.\n\nMy other option is to learn each technology individually from udemy and other platforms which will only cost &lt; $150.\n\nThe advantage of buying a bootcamp as a package, is it is structured already and the content has been filtered to just learn the important concepts. So, I\u2019m eyeing that but wuite not sure if $650 for the course is worth it or not.", "author_fullname": "t2_5owlarij", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Bootcamp (worthy or not?)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zni70p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671206842.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can someone gauge if &lt;a href=\"https://trendytech.in\"&gt;this bootcamp&lt;/a&gt; is good? I saw this on linkedin and I find the content good to kickstart my journey in big data. It is worth $650.&lt;/p&gt;\n\n&lt;p&gt;My other option is to learn each technology individually from udemy and other platforms which will only cost &amp;lt; $150.&lt;/p&gt;\n\n&lt;p&gt;The advantage of buying a bootcamp as a package, is it is structured already and the content has been filtered to just learn the important concepts. So, I\u2019m eyeing that but wuite not sure if $650 for the course is worth it or not.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zni70p", "is_robot_indexable": true, "report_reasons": null, "author": "_Dark_mage", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zni70p/data_engineering_bootcamp_worthy_or_not/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zni70p/data_engineering_bootcamp_worthy_or_not/", "subreddit_subscribers": 83130, "created_utc": 1671206842.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have read the book, want to do a Airflow + Kimball Data Modelling on a dataset. Showcase as side project and improve later on. \n\nWhere do I find data where I could create star schema or snowflake schema. Seems all data are already cleaned and normalized.", "author_fullname": "t2_6d53o2nl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do we practice Data Warehouse modelling like Kimball way.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zndo4e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671194137.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have read the book, want to do a Airflow + Kimball Data Modelling on a dataset. Showcase as side project and improve later on. &lt;/p&gt;\n\n&lt;p&gt;Where do I find data where I could create star schema or snowflake schema. Seems all data are already cleaned and normalized.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zndo4e", "is_robot_indexable": true, "report_reasons": null, "author": "EarthlySapien", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zndo4e/how_do_we_practice_data_warehouse_modelling_like/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zndo4e/how_do_we_practice_data_warehouse_modelling_like/", "subreddit_subscribers": 83130, "created_utc": 1671194137.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all!\n\nI have a csv file with known column names of \u201ca\u201d, \u201cb\u201d, \u201cc\u201d, \u201cd\u201d.  I would like to predefine the schema using pyspark to ensure correct data types on read, but the file column order may change without me knowing.\n\nFor example, the csv file may come in the order \u201cd\u201d, \u201ca\u201d, \u201cb\u201d, \u201cc\u201d\n\nHow do I account for this in reading in the file? Is there anyway possible to do this without using inferschema?\n\nEDIT:\n\nFigured out a way to achieve this. Read the file as an rdd, then use a map function to rearrange the columns of the rdd.", "author_fullname": "t2_gge8z8qb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Predefined Schema - Correct Names, Incorrect Order", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_znhwuu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1671209302.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671206141.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all!&lt;/p&gt;\n\n&lt;p&gt;I have a csv file with known column names of \u201ca\u201d, \u201cb\u201d, \u201cc\u201d, \u201cd\u201d.  I would like to predefine the schema using pyspark to ensure correct data types on read, but the file column order may change without me knowing.&lt;/p&gt;\n\n&lt;p&gt;For example, the csv file may come in the order \u201cd\u201d, \u201ca\u201d, \u201cb\u201d, \u201cc\u201d&lt;/p&gt;\n\n&lt;p&gt;How do I account for this in reading in the file? Is there anyway possible to do this without using inferschema?&lt;/p&gt;\n\n&lt;p&gt;EDIT:&lt;/p&gt;\n\n&lt;p&gt;Figured out a way to achieve this. Read the file as an rdd, then use a map function to rearrange the columns of the rdd.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "znhwuu", "is_robot_indexable": true, "report_reasons": null, "author": "No_Professional_9685", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/znhwuu/predefined_schema_correct_names_incorrect_order/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/znhwuu/predefined_schema_correct_names_incorrect_order/", "subreddit_subscribers": 83130, "created_utc": 1671206141.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Giving my review of the AWS Cloud Practitioner Certificate, and how useful it is for data engineering. \n\nWhat I didn't like:\n\n\\- 40% of the exam is memorizing acronyms and names of AWS services, as well as cost/billing. \n\nWhat I liked:\n\n\\- It helped me gain general exposure to what cloud computing can do and how it works. Cloud computing is definitely one of the more impactful technologies of the past decade/future decade. \n\n\\- It helped me get general exposure via curriculum to other areas of tech that I wouldn't otherwise have learned about. Namely - Networking, Cybersecurity. \n\n\\- It helped me refresh my knowledge on renting compute/storage, containerization, application integration(kafka, pubsub), databases/datawarehouses. \n\nWould I recommend it for data engineers?\n\nYes, unless you already have &gt;1 of experience managing cloud resources/billing/etc and have some basic exposure to backend engineering. Overall, I think it's a good way to formally learn about the general cloud computing and tech landscape. \n\nWill it help with landing a job?\n\nThe certificate by itself? Definitely no. But I would think of it as a small bonus if I saw it on a candidates resume.", "author_fullname": "t2_8x16rrzg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Review of AWS Cloud Practitioner Certificate", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zny6cb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671251762.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Giving my review of the AWS Cloud Practitioner Certificate, and how useful it is for data engineering. &lt;/p&gt;\n\n&lt;p&gt;What I didn&amp;#39;t like:&lt;/p&gt;\n\n&lt;p&gt;- 40% of the exam is memorizing acronyms and names of AWS services, as well as cost/billing. &lt;/p&gt;\n\n&lt;p&gt;What I liked:&lt;/p&gt;\n\n&lt;p&gt;- It helped me gain general exposure to what cloud computing can do and how it works. Cloud computing is definitely one of the more impactful technologies of the past decade/future decade. &lt;/p&gt;\n\n&lt;p&gt;- It helped me get general exposure via curriculum to other areas of tech that I wouldn&amp;#39;t otherwise have learned about. Namely - Networking, Cybersecurity. &lt;/p&gt;\n\n&lt;p&gt;- It helped me refresh my knowledge on renting compute/storage, containerization, application integration(kafka, pubsub), databases/datawarehouses. &lt;/p&gt;\n\n&lt;p&gt;Would I recommend it for data engineers?&lt;/p&gt;\n\n&lt;p&gt;Yes, unless you already have &amp;gt;1 of experience managing cloud resources/billing/etc and have some basic exposure to backend engineering. Overall, I think it&amp;#39;s a good way to formally learn about the general cloud computing and tech landscape. &lt;/p&gt;\n\n&lt;p&gt;Will it help with landing a job?&lt;/p&gt;\n\n&lt;p&gt;The certificate by itself? Definitely no. But I would think of it as a small bonus if I saw it on a candidates resume.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zny6cb", "is_robot_indexable": true, "report_reasons": null, "author": "Justanotherguy2022", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/zny6cb/review_of_aws_cloud_practitioner_certificate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zny6cb/review_of_aws_cloud_practitioner_certificate/", "subreddit_subscribers": 83130, "created_utc": 1671251762.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know that there are so many concepts, but if you are just getting started with data engineering, and you know Python and SQL, what would you recommend learning next to start building a strong data engineering foundation?\n\nWould it be good to start learning how to build pipelines, or should I choose a resource that goes through the entire data engineering cycle, such as data camp?\n\nThank you in advance!", "author_fullname": "t2_4841f127", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What concepts/tools should I learn after Python and SQL basics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_znz3g0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671255087.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know that there are so many concepts, but if you are just getting started with data engineering, and you know Python and SQL, what would you recommend learning next to start building a strong data engineering foundation?&lt;/p&gt;\n\n&lt;p&gt;Would it be good to start learning how to build pipelines, or should I choose a resource that goes through the entire data engineering cycle, such as data camp?&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "znz3g0", "is_robot_indexable": true, "report_reasons": null, "author": "The-Fourth-Hokage", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/znz3g0/what_conceptstools_should_i_learn_after_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/znz3g0/what_conceptstools_should_i_learn_after_python/", "subreddit_subscribers": 83130, "created_utc": 1671255087.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m working on a personal project where I crawl posts, comments, and users from Reddit\u2019s API and store the data in a data warehouse. Every Reddit submission or comment has attributes that can't change over time, such as its url, id, parent subreddit, etc. I plan to fetch more data for the same posts/comments on a set interval and record changes in some of the attributes that *do* change, such as upvotes. \n\nThis is how I\u2019ve designed my [posts schema](https://imgur.com/a/jGqtbC4). On the far right are the static post attributes, which are linked to changing attributes in a details table via a versions table. Each \"version\" represents a different time that I've fetched data from the API for that post, which I will do at a set interval.\n\nThe other tables branch out from the details table since they also may change between crawls.\n\nWhat are some ways I could improve this design, and do you know of any tools that I could use to automate some of the work required in maintaining this? I'm planning to start learning about SQLAlchemy's ORM to see if that can help me.\n\nI should also mention that I prefixed all of the id fields and timestamps that I generated myself (fields that did not come from Reddit) with the word `zen`. This means nothing, I just thought it was a good way to distinguish which fields I generated myself.", "author_fullname": "t2_6gwxih9e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for feedback on my data warehouse schema design for my personal project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_znruh1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1671231979.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m working on a personal project where I crawl posts, comments, and users from Reddit\u2019s API and store the data in a data warehouse. Every Reddit submission or comment has attributes that can&amp;#39;t change over time, such as its url, id, parent subreddit, etc. I plan to fetch more data for the same posts/comments on a set interval and record changes in some of the attributes that &lt;em&gt;do&lt;/em&gt; change, such as upvotes. &lt;/p&gt;\n\n&lt;p&gt;This is how I\u2019ve designed my &lt;a href=\"https://imgur.com/a/jGqtbC4\"&gt;posts schema&lt;/a&gt;. On the far right are the static post attributes, which are linked to changing attributes in a details table via a versions table. Each &amp;quot;version&amp;quot; represents a different time that I&amp;#39;ve fetched data from the API for that post, which I will do at a set interval.&lt;/p&gt;\n\n&lt;p&gt;The other tables branch out from the details table since they also may change between crawls.&lt;/p&gt;\n\n&lt;p&gt;What are some ways I could improve this design, and do you know of any tools that I could use to automate some of the work required in maintaining this? I&amp;#39;m planning to start learning about SQLAlchemy&amp;#39;s ORM to see if that can help me.&lt;/p&gt;\n\n&lt;p&gt;I should also mention that I prefixed all of the id fields and timestamps that I generated myself (fields that did not come from Reddit) with the word &lt;code&gt;zen&lt;/code&gt;. This means nothing, I just thought it was a good way to distinguish which fields I generated myself.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Fq31V7lHOW_-V7n6OnzzxtLaW7XM7Cha7pzXhzRjh7E.jpg?auto=webp&amp;s=9bc71b140d6184607fc75b4ab71979e2675d671f", "width": 2030, "height": 1558}, "resolutions": [{"url": "https://external-preview.redd.it/Fq31V7lHOW_-V7n6OnzzxtLaW7XM7Cha7pzXhzRjh7E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a84ecae3adbfa8f6e1b9f94b28d5f56f1272771a", "width": 108, "height": 82}, {"url": "https://external-preview.redd.it/Fq31V7lHOW_-V7n6OnzzxtLaW7XM7Cha7pzXhzRjh7E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d49e99e2dfddb96c55298145f7c6445ab54e3e09", "width": 216, "height": 165}, {"url": "https://external-preview.redd.it/Fq31V7lHOW_-V7n6OnzzxtLaW7XM7Cha7pzXhzRjh7E.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=53710df9624f40d14d86ae9d00f082810abdef82", "width": 320, "height": 245}, {"url": "https://external-preview.redd.it/Fq31V7lHOW_-V7n6OnzzxtLaW7XM7Cha7pzXhzRjh7E.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3c617a58eaa09b4db14145082bf463b0567d41e1", "width": 640, "height": 491}, {"url": "https://external-preview.redd.it/Fq31V7lHOW_-V7n6OnzzxtLaW7XM7Cha7pzXhzRjh7E.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c2b89a5233dab0f526d263433b39b24f36788162", "width": 960, "height": 736}, {"url": "https://external-preview.redd.it/Fq31V7lHOW_-V7n6OnzzxtLaW7XM7Cha7pzXhzRjh7E.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1101d7b27654ed69f84a3dd2e3e3416d04c86a6b", "width": 1080, "height": 828}], "variants": {}, "id": "wyunczzbIOuQZE-eUcPZYzruYUoObtrKie5Xz4VG_g4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "znruh1", "is_robot_indexable": true, "report_reasons": null, "author": "abelEngineer", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/znruh1/looking_for_feedback_on_my_data_warehouse_schema/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/znruh1/looking_for_feedback_on_my_data_warehouse_schema/", "subreddit_subscribers": 83130, "created_utc": 1671231979.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am trying to start a career as a data engineer. I hold a software engineering degree and have nearly 10 years experience working in software development roles. I have also just gained the Google Cloud Professional Data Engineer Cert.\n\nI have been applying for junior and entry level data engineer jobs but so far having 0 luck. I can only assume it is down to no data engineering experience. I\u2019m not getting to the interview stage\n\nIs there anywhere I can do pro bono data engineering work to gain experience for my applications and will it improve my employment chances?\n\nI am in the UK\n\nThanks", "author_fullname": "t2_1wjala", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pro Bono Data Engineering Work For Experience?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_znvgq3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671242604.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to start a career as a data engineer. I hold a software engineering degree and have nearly 10 years experience working in software development roles. I have also just gained the Google Cloud Professional Data Engineer Cert.&lt;/p&gt;\n\n&lt;p&gt;I have been applying for junior and entry level data engineer jobs but so far having 0 luck. I can only assume it is down to no data engineering experience. I\u2019m not getting to the interview stage&lt;/p&gt;\n\n&lt;p&gt;Is there anywhere I can do pro bono data engineering work to gain experience for my applications and will it improve my employment chances?&lt;/p&gt;\n\n&lt;p&gt;I am in the UK&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "znvgq3", "is_robot_indexable": true, "report_reasons": null, "author": "CJH55", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/znvgq3/pro_bono_data_engineering_work_for_experience/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/znvgq3/pro_bono_data_engineering_work_for_experience/", "subreddit_subscribers": 83130, "created_utc": 1671242604.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I can\u2019t seem to think of anything other than Netflix streaming when anyone says the word streaming\u2026", "author_fullname": "t2_a7nec5bo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is streaming in the context of data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zo176l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671263143.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I can\u2019t seem to think of anything other than Netflix streaming when anyone says the word streaming\u2026&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zo176l", "is_robot_indexable": true, "report_reasons": null, "author": "TheCumCopter", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zo176l/what_is_streaming_in_the_context_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zo176l/what_is_streaming_in_the_context_of_data/", "subreddit_subscribers": 83130, "created_utc": 1671263143.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was wondering if anyone could give me some insight on what type of series I should get for an Azure VM to host AirByte for our EL use-cases.\n\nOur use-case is to build a robust BI platform for our company's data. Our main two vendors have provided replicas for us to read from so that we can get the data into our own data warehouse.\n\nThe data sources are:\n\n1. Azure SQL Database: 35 million total rows, 8.5gb, and 100,000 upserts daily\n2. AWS RDS SQL Server w/60 Databases: 124 billion total rows, 31tb, and 25 million upserts daily\n\nSo after the initial snapshots of \\~124 billion records, I'll need to then support \\~25.1 million inserts in the EL pipelines daily. I could schedule the replications in AirByte to try to spread out the EL jobs as much as possible.\n\nI was looking at the D, E, and F series VM's in Azure, but I'm not exactly sure which is the best choice. If anyone has any insight so I don't totally mess this up I'd really appreciate it.", "author_fullname": "t2_tql2kvxf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What type of Azure VM to use for AirByte?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_znvoys", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671243316.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was wondering if anyone could give me some insight on what type of series I should get for an Azure VM to host AirByte for our EL use-cases.&lt;/p&gt;\n\n&lt;p&gt;Our use-case is to build a robust BI platform for our company&amp;#39;s data. Our main two vendors have provided replicas for us to read from so that we can get the data into our own data warehouse.&lt;/p&gt;\n\n&lt;p&gt;The data sources are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Azure SQL Database: 35 million total rows, 8.5gb, and 100,000 upserts daily&lt;/li&gt;\n&lt;li&gt;AWS RDS SQL Server w/60 Databases: 124 billion total rows, 31tb, and 25 million upserts daily&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;So after the initial snapshots of ~124 billion records, I&amp;#39;ll need to then support ~25.1 million inserts in the EL pipelines daily. I could schedule the replications in AirByte to try to spread out the EL jobs as much as possible.&lt;/p&gt;\n\n&lt;p&gt;I was looking at the D, E, and F series VM&amp;#39;s in Azure, but I&amp;#39;m not exactly sure which is the best choice. If anyone has any insight so I don&amp;#39;t totally mess this up I&amp;#39;d really appreciate it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "znvoys", "is_robot_indexable": true, "report_reasons": null, "author": "AzureNoob1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/znvoys/what_type_of_azure_vm_to_use_for_airbyte/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/znvoys/what_type_of_azure_vm_to_use_for_airbyte/", "subreddit_subscribers": 83130, "created_utc": 1671243316.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are building our pipelin in glue and using lambda for trigger based orchestration and logging etc. I have a feeling airflow can make our life easier. If not airflow is there some other orchestration tool that would be better suited?", "author_fullname": "t2_2se32fpj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I use airflow to orchestrate serverless ETL functions on AWS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_znbgg5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671186061.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are building our pipelin in glue and using lambda for trigger based orchestration and logging etc. I have a feeling airflow can make our life easier. If not airflow is there some other orchestration tool that would be better suited?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "znbgg5", "is_robot_indexable": true, "report_reasons": null, "author": "localhost3306", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/znbgg5/how_can_i_use_airflow_to_orchestrate_serverless/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/znbgg5/how_can_i_use_airflow_to_orchestrate_serverless/", "subreddit_subscribers": 83130, "created_utc": 1671186061.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Guys,\n\nHope this message finds you well!\n\nI was thinking to start a project of my own like the website [camelcamelcamel.com](https://camelcamelcamel.com) and I was wondering if you could suggest me on which free tools to use best for this engineering project.\n\nAll help and suggestions are welcome.", "author_fullname": "t2_f3vb1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tool suggestions for a project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zngw4p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1671203534.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Guys,&lt;/p&gt;\n\n&lt;p&gt;Hope this message finds you well!&lt;/p&gt;\n\n&lt;p&gt;I was thinking to start a project of my own like the website &lt;a href=\"https://camelcamelcamel.com\"&gt;camelcamelcamel.com&lt;/a&gt; and I was wondering if you could suggest me on which free tools to use best for this engineering project.&lt;/p&gt;\n\n&lt;p&gt;All help and suggestions are welcome.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/gybnDH0o7u0DLFGJMvKsfG6iJH0O86qWrdQX5RSQol0.jpg?auto=webp&amp;s=76600fa39de0e0befbf71c530cb7b31009ab0088", "width": 1560, "height": 633}, "resolutions": [{"url": "https://external-preview.redd.it/gybnDH0o7u0DLFGJMvKsfG6iJH0O86qWrdQX5RSQol0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=07bf6c406a742d07a4c29f5369d867ece4b14b41", "width": 108, "height": 43}, {"url": "https://external-preview.redd.it/gybnDH0o7u0DLFGJMvKsfG6iJH0O86qWrdQX5RSQol0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=86384f2c356ef0bbea512f77d020164ad5026a70", "width": 216, "height": 87}, {"url": "https://external-preview.redd.it/gybnDH0o7u0DLFGJMvKsfG6iJH0O86qWrdQX5RSQol0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cb9f2adf48e9f24b251c211bc9726c1bb0c7705d", "width": 320, "height": 129}, {"url": "https://external-preview.redd.it/gybnDH0o7u0DLFGJMvKsfG6iJH0O86qWrdQX5RSQol0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2cb71267a634537b31604506b637ff3cf542e91e", "width": 640, "height": 259}, {"url": "https://external-preview.redd.it/gybnDH0o7u0DLFGJMvKsfG6iJH0O86qWrdQX5RSQol0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=09ee49b71c4c81ad786cb153515b17c29e15945d", "width": 960, "height": 389}, {"url": "https://external-preview.redd.it/gybnDH0o7u0DLFGJMvKsfG6iJH0O86qWrdQX5RSQol0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=88d5311af3ee4b21ecac2e20cd5de5ec02b1a121", "width": 1080, "height": 438}], "variants": {}, "id": "4ZccvLKGtqCcJzEz2YEeN_Zvwhd-SZ8SSm6y3DGXZDA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "zngw4p", "is_robot_indexable": true, "report_reasons": null, "author": "olti93", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zngw4p/tool_suggestions_for_a_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zngw4p/tool_suggestions_for_a_project/", "subreddit_subscribers": 83130, "created_utc": 1671203534.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "First of all thank you all for the great content that has been created on this sub. I am not much a Reddit person but have been following up here. \n\nI am in process of creating a good set of assignments for students learning Big Data technologies and looking for a free datasets available online. I have looked at multiple but want your opinions for specific requirement below : \n\n**Data Set Requirement -** \n\n1. Large amount of structured/semi structured data to be used for Batch processing (single batch could have 50-100GB commonly)\n2. Data modelling - I want them to have a good exposure to traditional modelling (although this may fall into Data Lake like architecture) and I am not a warehouse person. So any data that'd allow them to have some chance to model would be good. I understand this is use case/domain specific and not a straight ask but say a 8 column movie DB of 5TB in size may not be greatly helpful. Any parallel sets of large datasets where they can be independently corelated would be good too than a single source.\n3. Continuously generating new data for part Streaming use cases that can be related to the large datasets.\n\n&amp;#x200B;\n\n**Technology Stack Used -**\n\n1. Apache Spark with AWS EMR, Glue\n2. Athena/Presto for Querying\n3. Kinesis suite for streaming\n\n&amp;#x200B;\n\n**Not looking for** \\- \n\n1. Not looking for datasets for any ML modelling\n2. Fully structured data is perfectly fine. But some unstructured data requiring some cleaning is okay too, end goal is to get handle on using Big Data tech, doing data modelling and some performance checks on such piplines in AWS.", "author_fullname": "t2_qg4yidm6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Large sample dataset for data modelling and big data tools exercises", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_znfchs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671199244.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First of all thank you all for the great content that has been created on this sub. I am not much a Reddit person but have been following up here. &lt;/p&gt;\n\n&lt;p&gt;I am in process of creating a good set of assignments for students learning Big Data technologies and looking for a free datasets available online. I have looked at multiple but want your opinions for specific requirement below : &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Data Set Requirement -&lt;/strong&gt; &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Large amount of structured/semi structured data to be used for Batch processing (single batch could have 50-100GB commonly)&lt;/li&gt;\n&lt;li&gt;Data modelling - I want them to have a good exposure to traditional modelling (although this may fall into Data Lake like architecture) and I am not a warehouse person. So any data that&amp;#39;d allow them to have some chance to model would be good. I understand this is use case/domain specific and not a straight ask but say a 8 column movie DB of 5TB in size may not be greatly helpful. Any parallel sets of large datasets where they can be independently corelated would be good too than a single source.&lt;/li&gt;\n&lt;li&gt;Continuously generating new data for part Streaming use cases that can be related to the large datasets.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Technology Stack Used -&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Apache Spark with AWS EMR, Glue&lt;/li&gt;\n&lt;li&gt;Athena/Presto for Querying&lt;/li&gt;\n&lt;li&gt;Kinesis suite for streaming&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Not looking for&lt;/strong&gt; - &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Not looking for datasets for any ML modelling&lt;/li&gt;\n&lt;li&gt;Fully structured data is perfectly fine. But some unstructured data requiring some cleaning is okay too, end goal is to get handle on using Big Data tech, doing data modelling and some performance checks on such piplines in AWS.&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "znfchs", "is_robot_indexable": true, "report_reasons": null, "author": "Other_Cartoonist7071", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/znfchs/large_sample_dataset_for_data_modelling_and_big/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/znfchs/large_sample_dataset_for_data_modelling_and_big/", "subreddit_subscribers": 83130, "created_utc": 1671199244.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I write a lot of Python and Pyspark scrips for the automation and ETL processes for my department and a few others. Majority of the data used comes from APIs and in some cases gets loaded into S3 buckets, Azure Blobs and Salesforce. \n\nAt the moment I have the actual Api keys assigned to a variable in the script so if someone unauthorized gets access to the script then they can get access to the data.\n\nI know this is not right so I want to figure out the appropriate way to do it so that I can update the scripts.\n\nWhat is the correct way to securely pass the APIs keys and other keys in the script?", "author_fullname": "t2_dkq68c2f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to handle Api keys, secret keys and access keys", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zo2vac", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671270192.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I write a lot of Python and Pyspark scrips for the automation and ETL processes for my department and a few others. Majority of the data used comes from APIs and in some cases gets loaded into S3 buckets, Azure Blobs and Salesforce. &lt;/p&gt;\n\n&lt;p&gt;At the moment I have the actual Api keys assigned to a variable in the script so if someone unauthorized gets access to the script then they can get access to the data.&lt;/p&gt;\n\n&lt;p&gt;I know this is not right so I want to figure out the appropriate way to do it so that I can update the scripts.&lt;/p&gt;\n\n&lt;p&gt;What is the correct way to securely pass the APIs keys and other keys in the script?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zo2vac", "is_robot_indexable": true, "report_reasons": null, "author": "MajiYaKuoshaVyombo", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zo2vac/how_to_handle_api_keys_secret_keys_and_access_keys/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zo2vac/how_to_handle_api_keys_secret_keys_and_access_keys/", "subreddit_subscribers": 83130, "created_utc": 1671270192.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a DE/analytics engineer. I do stuff like pulling data from streams (kafka), from product DBs, APIs and from the data lake and load it into my cloud DB after transforming it in my EC2. I also build visuals on the data. \n\nI would like to know where a tool like docker is used in typical DE scope. Do companies (not all ofc) no longer use a dedicated server to run data pipelines and rely on docker for such stuff? Where does the code reside in such cases (it resides in the EC2 hard disk for me)? Also, am i right when i say that when a cloud DB offers a auto scaling feature or when a databricks job can be set up using a machine that spins up only during the job run and shuts up later, they're using docker or similiar tools to offer these services?", "author_fullname": "t2_xap78", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Docker queries", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_znketu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671212537.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a DE/analytics engineer. I do stuff like pulling data from streams (kafka), from product DBs, APIs and from the data lake and load it into my cloud DB after transforming it in my EC2. I also build visuals on the data. &lt;/p&gt;\n\n&lt;p&gt;I would like to know where a tool like docker is used in typical DE scope. Do companies (not all ofc) no longer use a dedicated server to run data pipelines and rely on docker for such stuff? Where does the code reside in such cases (it resides in the EC2 hard disk for me)? Also, am i right when i say that when a cloud DB offers a auto scaling feature or when a databricks job can be set up using a machine that spins up only during the job run and shuts up later, they&amp;#39;re using docker or similiar tools to offer these services?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "znketu", "is_robot_indexable": true, "report_reasons": null, "author": "totalsports1", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/znketu/docker_queries/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/znketu/docker_queries/", "subreddit_subscribers": 83130, "created_utc": 1671212537.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Since google anounces that they will deprecate the Google IoT Core service on 16th August 2023, what alternatives can I manage to collect data from IoT gateways in an industrial environment and send them to Google Cloud Pub/Sub, IoT protocols could be MQTT or OPC UA.", "author_fullname": "t2_sv0s9rab", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to collect IoT data and gather to Google Cloud?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zncyk1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671191838.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Since google anounces that they will deprecate the Google IoT Core service on 16th August 2023, what alternatives can I manage to collect data from IoT gateways in an industrial environment and send them to Google Cloud Pub/Sub, IoT protocols could be MQTT or OPC UA.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zncyk1", "is_robot_indexable": true, "report_reasons": null, "author": "DonDewid", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zncyk1/how_to_collect_iot_data_and_gather_to_google_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zncyk1/how_to_collect_iot_data_and_gather_to_google_cloud/", "subreddit_subscribers": 83130, "created_utc": 1671191838.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Azure has a great guide for naming convention for Azure resources, but I have yet to find an \u201cofficial\u201d guide for Data Factory or Synapse. I\u2019m talking pipelines, data sets, data flows, sources, sinks, etc.\n\nI always have the same challenge with ADF:\n\nWhat looks good in code always gets truncated in the GUI so there\u2019s a trade off. If I shorten the names, I lose descriptive text, but it fits in the GUI.\n\nBut if I use longer names, I get all the identifying text I need, it just makes reading objects in the GUI exceptionally difficult to differentiate from each other.\n\nI\u2019ve read a few blogs with suggestions, but was hoping there was an \u201cofficial\u201d style guide like the main Azure docs, or maybe someone has a recipe they use.\n\nhttps://learn.microsoft.com/en-us/azure/cloud-adoption-framework/ready/azure-best-practices/resource-naming\n\nOr do some of you have cross-cloud / product conventions you use? We need a Terraform for Data Engineering lol\n\nhttps://np.reddit.com/r/dataengineering/comments/tjr4t5/standardization_style_guide_and_naming_convention/", "author_fullname": "t2_t2wl82bi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure Data Factory Naming Convention Guide\uff1f", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_znbbsi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1671185516.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Azure has a great guide for naming convention for Azure resources, but I have yet to find an \u201cofficial\u201d guide for Data Factory or Synapse. I\u2019m talking pipelines, data sets, data flows, sources, sinks, etc.&lt;/p&gt;\n\n&lt;p&gt;I always have the same challenge with ADF:&lt;/p&gt;\n\n&lt;p&gt;What looks good in code always gets truncated in the GUI so there\u2019s a trade off. If I shorten the names, I lose descriptive text, but it fits in the GUI.&lt;/p&gt;\n\n&lt;p&gt;But if I use longer names, I get all the identifying text I need, it just makes reading objects in the GUI exceptionally difficult to differentiate from each other.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve read a few blogs with suggestions, but was hoping there was an \u201cofficial\u201d style guide like the main Azure docs, or maybe someone has a recipe they use.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/ready/azure-best-practices/resource-naming\"&gt;https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/ready/azure-best-practices/resource-naming&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Or do some of you have cross-cloud / product conventions you use? We need a Terraform for Data Engineering lol&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://np.reddit.com/r/dataengineering/comments/tjr4t5/standardization_style_guide_and_naming_convention/\"&gt;https://np.reddit.com/r/dataengineering/comments/tjr4t5/standardization_style_guide_and_naming_convention/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YH8gNap4KoGcFgyFYrNZ86fXmYfRn6pa7uuwIlZkjEE.jpg?auto=webp&amp;s=e62264227377a9581e2e2946169864d130fa3217", "width": 400, "height": 400}, "resolutions": [{"url": "https://external-preview.redd.it/YH8gNap4KoGcFgyFYrNZ86fXmYfRn6pa7uuwIlZkjEE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0b9526a51504048891d5e64783519fd5dc3cd83f", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/YH8gNap4KoGcFgyFYrNZ86fXmYfRn6pa7uuwIlZkjEE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0150bc3ab1c6838c35ff951d69578f3d19ae4ed3", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/YH8gNap4KoGcFgyFYrNZ86fXmYfRn6pa7uuwIlZkjEE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c1e830770227ae4802c5776d22f63d0f6aa71b15", "width": 320, "height": 320}], "variants": {}, "id": "LVmzWMJU1UZwRubzQYJZSar-z-Rq8ntUH65yhQyfxB8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "znbbsi", "is_robot_indexable": true, "report_reasons": null, "author": "generic-d-engineer", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/znbbsi/azure_data_factory_naming_convention_guide/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/znbbsi/azure_data_factory_naming_convention_guide/", "subreddit_subscribers": 83130, "created_utc": 1671185516.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Now that [I got your attention](https://meta.wikimedia.org/wiki/Cunningham%27s_Law), please help me find an extraction software/service that fits my needs.\n\nI am looking for 2 key features in specific:\n\n1. Possibility to connect to a source database (Postgresql) with SSH tunnelling\n2. S3 is a possible destination\n3. Bonus: possibly volume based pricing, we're a small team with small data and have some budget constraints\n\nI was testing Rivery but for some reason I didn't manage to make SSH tunnelling work. Then I tested AirByte with the same configuration. SSH tunnelling works flawlessly there, but God knows why, AirByte puts data in a blob when loading to S3, which adds an unnecessary normalization step that I'd like to avoid.\n\nThrow me a bone?", "author_fullname": "t2_zwbba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fivetran is the best ETL tool out there", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_znd2a7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.3, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1671192402.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671192170.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Now that &lt;a href=\"https://meta.wikimedia.org/wiki/Cunningham%27s_Law\"&gt;I got your attention&lt;/a&gt;, please help me find an extraction software/service that fits my needs.&lt;/p&gt;\n\n&lt;p&gt;I am looking for 2 key features in specific:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Possibility to connect to a source database (Postgresql) with SSH tunnelling&lt;/li&gt;\n&lt;li&gt;S3 is a possible destination&lt;/li&gt;\n&lt;li&gt;Bonus: possibly volume based pricing, we&amp;#39;re a small team with small data and have some budget constraints&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I was testing Rivery but for some reason I didn&amp;#39;t manage to make SSH tunnelling work. Then I tested AirByte with the same configuration. SSH tunnelling works flawlessly there, but God knows why, AirByte puts data in a blob when loading to S3, which adds an unnecessary normalization step that I&amp;#39;d like to avoid.&lt;/p&gt;\n\n&lt;p&gt;Throw me a bone?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "znd2a7", "is_robot_indexable": true, "report_reasons": null, "author": "wtfzambo", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/znd2a7/fivetran_is_the_best_etl_tool_out_there/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/znd2a7/fivetran_is_the_best_etl_tool_out_there/", "subreddit_subscribers": 83130, "created_utc": 1671192170.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A few years ago I thought it was dying but sadly tools like dbt seem to mean it's making a resurgence. I prefer a general purpose programming language like Python in all circumstances. A dataframe-style API gives you everything you need for working with data. Discuss.", "author_fullname": "t2_10iqu1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "does anyone else hate SQL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_znqf92", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.3, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1671231985.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671228245.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A few years ago I thought it was dying but sadly tools like dbt seem to mean it&amp;#39;s making a resurgence. I prefer a general purpose programming language like Python in all circumstances. A dataframe-style API gives you everything you need for working with data. Discuss.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "znqf92", "is_robot_indexable": true, "report_reasons": null, "author": "Sister_Ray_", "discussion_type": null, "num_comments": 67, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/znqf92/does_anyone_else_hate_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/znqf92/does_anyone_else_hate_sql/", "subreddit_subscribers": 83130, "created_utc": 1671228245.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}