{"kind": "Listing", "data": {"after": null, "dist": 20, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For current DEs, what is one thing you were expecting going into the DE field vs what actually occurred?\n\nBoth the good and the bad", "author_fullname": "t2_3p620rl9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Expectations Vs Reality", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zf68rv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 62, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 62, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_1": 1}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670431778.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For current DEs, what is one thing you were expecting going into the DE field vs what actually occurred?&lt;/p&gt;\n\n&lt;p&gt;Both the good and the bad&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 100, "id": "gid_1", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Shows the Silver Award... and that's it.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Silver", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "DE @ Amazon/Lyft/Author of Ace DE Interview", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zf68rv", "is_robot_indexable": true, "report_reasons": null, "author": "chrisgarzon19", "discussion_type": null, "num_comments": 73, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/zf68rv/expectations_vs_reality/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zf68rv/expectations_vs_reality/", "subreddit_subscribers": 82199, "created_utc": 1670431778.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_yeda6sl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cheat sheets on data life cycle, PySpark, dbt, Kafka, BigQuery, Airflow, and Docker.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 84, "top_awarded_type": null, "hide_score": false, "name": "t3_zf01xv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 57, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 57, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/jnAuxFJ7FUK5Iahrv4PaSmv255B5F5x5gonxzbUuD10.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670416431.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "kdnuggets.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.kdnuggets.com/2022/12/7-essential-cheat-sheets-data-engineering.html", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qXKhO1YkZh9VnI_-EHqSiDah-R5MlCadytMq1X88YZI.jpg?auto=webp&amp;s=c9b7cd9c73faba76573308abafdf501ae9f4d32b", "width": 1000, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/qXKhO1YkZh9VnI_-EHqSiDah-R5MlCadytMq1X88YZI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8494f67be4a98a5e99363aca96134d6c359b4046", "width": 108, "height": 64}, {"url": "https://external-preview.redd.it/qXKhO1YkZh9VnI_-EHqSiDah-R5MlCadytMq1X88YZI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bd8a77bba48bd792119d4f6ab606e9ae35316eee", "width": 216, "height": 129}, {"url": "https://external-preview.redd.it/qXKhO1YkZh9VnI_-EHqSiDah-R5MlCadytMq1X88YZI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fdf355ca2a0edbb10234946aa8a567b5676fa9c4", "width": 320, "height": 192}, {"url": "https://external-preview.redd.it/qXKhO1YkZh9VnI_-EHqSiDah-R5MlCadytMq1X88YZI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=10e3e2e2aa447ee1188f0c0af00a3c50bdcb14e1", "width": 640, "height": 384}, {"url": "https://external-preview.redd.it/qXKhO1YkZh9VnI_-EHqSiDah-R5MlCadytMq1X88YZI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9f53a2e0e98e3be44fd7c218ae425fc3725a3e70", "width": 960, "height": 576}], "variants": {}, "id": "fyZAesjAe63njoQYSxc2IjZ_YgDi9aZJ-ZEcfay2d9k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zf01xv", "is_robot_indexable": true, "report_reasons": null, "author": "kingabzpro", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zf01xv/cheat_sheets_on_data_life_cycle_pyspark_dbt_kafka/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.kdnuggets.com/2022/12/7-essential-cheat-sheets-data-engineering.html", "subreddit_subscribers": 82199, "created_utc": 1670416431.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is lambda architecture still the most common big data architecture to follow in 2022 or is it being replaced by kappa or some other architecture?", "author_fullname": "t2_7jt0qboi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lambda architecture status", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zfl2fb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670463674.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is lambda architecture still the most common big data architecture to follow in 2022 or is it being replaced by kappa or some other architecture?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zfl2fb", "is_robot_indexable": true, "report_reasons": null, "author": "omscsdatathrow", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zfl2fb/lambda_architecture_status/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zfl2fb/lambda_architecture_status/", "subreddit_subscribers": 82199, "created_utc": 1670463674.0, "num_crossposts": 2, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Was [reading](https://thenewstack.io/iso-better-scaling-instacart-drops-postgres-for-amazon-dynamodb/) about how Instacart bailed on an AWS EC2 PostgreSQL cluster for DynamoDb. No mention of considering Aurora RDS Serverless for scale out and scale down at night. Instead they accepted the restrictions of no joins in DynamoDb and having to think strictly about write costs.   \n\n\nWhile this could make sense for a state machine for notifications, I wonder about how companies that make this trade off fair down the road. I have found in my experience that the one thing management will never tolerate is having their hands tied.   \n\n\nThey will accept certain things like not being able to store all logs forever (astronomical cost). But I find it hard to believe it would fly to optimize writes with model design such that management can't ask for new (near real time) query use cases without undoing the economic advantage the new model initially offered.  \n\n\nI also find it fascinating that developers would pick a system proclaimed to give them all sorts of model flexibility then have access costs yank that flexibility away from them (no joins, limits to fast access by partition and sort key choices, etc.) because of costs. Kinda kills the whole value proposition of moving away from RDBMS in my mind. There are many ways to skin the RDBMS scale out cat...go find one that works, and at least keep query freedom at the perceived cost of schema evolution inflexibility. \n\nDoes anyone have stories about the cost of access becoming untenable on DynamoDb for new queries not thought of during the initial model design- that couldn't be served in a time or cost efficient manner? How did you solve that? Suck out the data to an RDBMS so you can do proper analytics, which has its own time and hard costs?", "author_fullname": "t2_41z8d4gg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trade offs: DynamoDb vs. RDBMS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zfh7cy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1670454276.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Was &lt;a href=\"https://thenewstack.io/iso-better-scaling-instacart-drops-postgres-for-amazon-dynamodb/\"&gt;reading&lt;/a&gt; about how Instacart bailed on an AWS EC2 PostgreSQL cluster for DynamoDb. No mention of considering Aurora RDS Serverless for scale out and scale down at night. Instead they accepted the restrictions of no joins in DynamoDb and having to think strictly about write costs.   &lt;/p&gt;\n\n&lt;p&gt;While this could make sense for a state machine for notifications, I wonder about how companies that make this trade off fair down the road. I have found in my experience that the one thing management will never tolerate is having their hands tied.   &lt;/p&gt;\n\n&lt;p&gt;They will accept certain things like not being able to store all logs forever (astronomical cost). But I find it hard to believe it would fly to optimize writes with model design such that management can&amp;#39;t ask for new (near real time) query use cases without undoing the economic advantage the new model initially offered.  &lt;/p&gt;\n\n&lt;p&gt;I also find it fascinating that developers would pick a system proclaimed to give them all sorts of model flexibility then have access costs yank that flexibility away from them (no joins, limits to fast access by partition and sort key choices, etc.) because of costs. Kinda kills the whole value proposition of moving away from RDBMS in my mind. There are many ways to skin the RDBMS scale out cat...go find one that works, and at least keep query freedom at the perceived cost of schema evolution inflexibility. &lt;/p&gt;\n\n&lt;p&gt;Does anyone have stories about the cost of access becoming untenable on DynamoDb for new queries not thought of during the initial model design- that couldn&amp;#39;t be served in a time or cost efficient manner? How did you solve that? Suck out the data to an RDBMS so you can do proper analytics, which has its own time and hard costs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/IFixEqOEuIkYsSTDjP2HmelwRuPx_dfDVe8cnb7-1N4.jpg?auto=webp&amp;s=057a27c4c2ffb5c4b4b1c946db9da5be8e8b3614", "width": 623, "height": 350}, "resolutions": [{"url": "https://external-preview.redd.it/IFixEqOEuIkYsSTDjP2HmelwRuPx_dfDVe8cnb7-1N4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=75c75b4cf48111f537000e8f3b01185d3b9829ed", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/IFixEqOEuIkYsSTDjP2HmelwRuPx_dfDVe8cnb7-1N4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=98b680d5dd6bfa7a8246c7fac8624fa2eea98394", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/IFixEqOEuIkYsSTDjP2HmelwRuPx_dfDVe8cnb7-1N4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=eafabea55dc5940c63c3011b36848ab961fcaeb6", "width": 320, "height": 179}], "variants": {}, "id": "b5K0QHYG4hDllykT7ENcPiF757Kr84VbkWZJ2pi4Lgw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zfh7cy", "is_robot_indexable": true, "report_reasons": null, "author": "quickdraw6906", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zfh7cy/trade_offs_dynamodb_vs_rdbms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zfh7cy/trade_offs_dynamodb_vs_rdbms/", "subreddit_subscribers": 82199, "created_utc": 1670454276.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3yleu7rp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How To Measure The ROI Of Your Data Spend?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zf9dob", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1670438048.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "alvin.ai", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.alvin.ai/posts/how-to-measure-the-roi-of-your-data-spend", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zf9dob", "is_robot_indexable": true, "report_reasons": null, "author": "gabsferreiradev", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zf9dob/how_to_measure_the_roi_of_your_data_spend/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.alvin.ai/posts/how-to-measure-the-roi-of-your-data-spend", "subreddit_subscribers": 82199, "created_utc": 1670438048.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "It's honestly really impressive that ChatGPT can solve some Leetcode problems, but does anyone else think this will positively impact the tech interview process?  If interviews historically selected for candidates who pass these technical tests, doesn't it make sense to want to move to a system that an ML model cannot excel at?\n\nI can only see Leetcode still existing in the future to interview entry level engineers, because, what else are you going to ask someone who is just starting out in the field?\n\nBut for anyone with more than a year of experience or moving on to their second job, I'm thinking that interviewers will place much more weight into system design, past experience, and the ability to work well in a team.\n\nChatGPT does show that it's kind of funny to be asking engineers who have graduated several years ago questions from a class they took as first and second year students.", "author_fullname": "t2_3v6ob2bf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How is ChatGPT going to affect the technical interview?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zf0t4r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1670419117.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670418714.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s honestly really impressive that ChatGPT can solve some Leetcode problems, but does anyone else think this will positively impact the tech interview process?  If interviews historically selected for candidates who pass these technical tests, doesn&amp;#39;t it make sense to want to move to a system that an ML model cannot excel at?&lt;/p&gt;\n\n&lt;p&gt;I can only see Leetcode still existing in the future to interview entry level engineers, because, what else are you going to ask someone who is just starting out in the field?&lt;/p&gt;\n\n&lt;p&gt;But for anyone with more than a year of experience or moving on to their second job, I&amp;#39;m thinking that interviewers will place much more weight into system design, past experience, and the ability to work well in a team.&lt;/p&gt;\n\n&lt;p&gt;ChatGPT does show that it&amp;#39;s kind of funny to be asking engineers who have graduated several years ago questions from a class they took as first and second year students.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zf0t4r", "is_robot_indexable": true, "report_reasons": null, "author": "data_preprocessing", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zf0t4r/how_is_chatgpt_going_to_affect_the_technical/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zf0t4r/how_is_chatgpt_going_to_affect_the_technical/", "subreddit_subscribers": 82199, "created_utc": 1670418714.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is a great article that tries to explain [why people everywhere are speaking about Rust](https://www.adventofdata.com/rust-for-data-engineering/). To be honest it feels more like a under the hood thing rather than a full switch to the language and the article depicts this super well.\n\nMainly it says:\n\n* Why Rust: because Rust compiler is strict, easier to use than C/C++ out of JVM\n* When Rust should be used: when you want speed and performance with data, Rust and Arrow are well integrated and with security about your data types\n* When Rust should not be used: sometimes Rust type safety is too rigid for data (hf read a CSV), when you want to go fast or on a new project because the learning curve is steep\n\n*\ud83c\udf84 PS: if you did not see this article is day 8 in the Advent of Data. Advent of Data is a advent calendar, everyday in December a new article about data is published.*", "author_fullname": "t2_6ff333ne", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rust for Data Engineering\u2014what's the hype about? \ud83e\udd80", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zfv38r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1670494708.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a great article that tries to explain &lt;a href=\"https://www.adventofdata.com/rust-for-data-engineering/\"&gt;why people everywhere are speaking about Rust&lt;/a&gt;. To be honest it feels more like a under the hood thing rather than a full switch to the language and the article depicts this super well.&lt;/p&gt;\n\n&lt;p&gt;Mainly it says:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Why Rust: because Rust compiler is strict, easier to use than C/C++ out of JVM&lt;/li&gt;\n&lt;li&gt;When Rust should be used: when you want speed and performance with data, Rust and Arrow are well integrated and with security about your data types&lt;/li&gt;\n&lt;li&gt;When Rust should not be used: sometimes Rust type safety is too rigid for data (hf read a CSV), when you want to go fast or on a new project because the learning curve is steep&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;em&gt;\ud83c\udf84 PS: if you did not see this article is day 8 in the Advent of Data. Advent of Data is a advent calendar, everyday in December a new article about data is published.&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/dfy1pNT5aYWH5BB7NbYgk28jQFEwT3-xD0wHcwfyDWk.jpg?auto=webp&amp;s=9c437378a2b5d672b02ac88971f69099b626776f", "width": 2000, "height": 1125}, "resolutions": [{"url": "https://external-preview.redd.it/dfy1pNT5aYWH5BB7NbYgk28jQFEwT3-xD0wHcwfyDWk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=65555a6ae0661d24ae0ad8c53023901c1f2d44f8", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/dfy1pNT5aYWH5BB7NbYgk28jQFEwT3-xD0wHcwfyDWk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3aae1d1e8dc5458b8656842b4684b5eb9ef0ecbe", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/dfy1pNT5aYWH5BB7NbYgk28jQFEwT3-xD0wHcwfyDWk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=26ca35a4220a2e80d290b4d09af8b5ef45726fd7", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/dfy1pNT5aYWH5BB7NbYgk28jQFEwT3-xD0wHcwfyDWk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=233f41e4c3949c2ff8512bbc75537827ad464cd3", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/dfy1pNT5aYWH5BB7NbYgk28jQFEwT3-xD0wHcwfyDWk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=05d40ec5de5e74701ab1c304a95e86bf7709d69e", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/dfy1pNT5aYWH5BB7NbYgk28jQFEwT3-xD0wHcwfyDWk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fc3a0657a99a76b464eb25626ea42148c1e8ffee", "width": 1080, "height": 607}], "variants": {}, "id": "3D9xZ7JmU9ebYzdjOLAqN7Q7x4rBq_fz9fSuKp80Igk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "I'm the dataman", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zfv38r", "is_robot_indexable": true, "report_reasons": null, "author": "blef__", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/zfv38r/rust_for_data_engineeringwhats_the_hype_about/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zfv38r/rust_for_data_engineeringwhats_the_hype_about/", "subreddit_subscribers": 82199, "created_utc": 1670494708.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I have an in-person interview for a data engineering position next week and I'm prepping for it this week.   \nI'm wanting to know if anyone has had them and what kind of questions you remember/ or people that give interviews, what questions would you ask.   \n\n\nthe hiring manager told me to study: sql, NoSql, Data Warehouse, python scripts, power BI , ETL, Frameworks, and web-scraping.  \n\n\nI do know I will not or it is quite impossible to cram all this in a week but since i have experience in sql and data warehouses, those topics will be a quick review for me.   \nIf anyone can help, that will be fantastic!", "author_fullname": "t2_rntn75xc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview prep", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zfmfp5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670467185.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have an in-person interview for a data engineering position next week and I&amp;#39;m prepping for it this week.&lt;br/&gt;\nI&amp;#39;m wanting to know if anyone has had them and what kind of questions you remember/ or people that give interviews, what questions would you ask.   &lt;/p&gt;\n\n&lt;p&gt;the hiring manager told me to study: sql, NoSql, Data Warehouse, python scripts, power BI , ETL, Frameworks, and web-scraping.  &lt;/p&gt;\n\n&lt;p&gt;I do know I will not or it is quite impossible to cram all this in a week but since i have experience in sql and data warehouses, those topics will be a quick review for me.&lt;br/&gt;\nIf anyone can help, that will be fantastic!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "zfmfp5", "is_robot_indexable": true, "report_reasons": null, "author": "Enough_Classroom_903", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zfmfp5/interview_prep/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zfmfp5/interview_prep/", "subreddit_subscribers": 82199, "created_utc": 1670467185.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm legitimately asking.\n\nI've taken several take-home and live coding challenges over the years. I actually prefer the take-home. More realistic to how I'd solve a problem on the job. \n\nNow I'm a hiring manager using one to screen candidates. But I know people think they suck. I just never felt that way while interviewing, so I'm not 100% sure why.\n\nAny insights?", "author_fullname": "t2_1wezxlo6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Take-Homes: Why do they suck?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zfqr57", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670479233.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m legitimately asking.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve taken several take-home and live coding challenges over the years. I actually prefer the take-home. More realistic to how I&amp;#39;d solve a problem on the job. &lt;/p&gt;\n\n&lt;p&gt;Now I&amp;#39;m a hiring manager using one to screen candidates. But I know people think they suck. I just never felt that way while interviewing, so I&amp;#39;m not 100% sure why.&lt;/p&gt;\n\n&lt;p&gt;Any insights?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zfqr57", "is_robot_indexable": true, "report_reasons": null, "author": "Archbishop_Mo", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zfqr57/takehomes_why_do_they_suck/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zfqr57/takehomes_why_do_they_suck/", "subreddit_subscribers": 82199, "created_utc": 1670479233.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I'm part of a research team at a smaller company which has worked in the field of datamodeling for 20+ yrs.  \n\n\nWe have repeatedly observed that for companies using DataWarehousing, documenting source systems provides a challenge.\n\nIn a small project team we would like to develop new and effective solutions for these problems.\n\nFor anyone with experience in this field, we would be highly grateful for your opinions on the following questions:\n\n1. What challenges do you know of when it comes to documenting a database/source system? \n\n2. What has proven to be especially challenging when documenting CRM systems such as Salesforce?\n\n3. Have you encountered any specific difficulties while documenting ERP systems like SAP?\n\nThank you very much in advance, we're looking forward to hearing from you :)", "author_fullname": "t2_uovnqo6g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Inquiry about Database Documentation &amp; DataWarehousing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zf5auk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670429849.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;m part of a research team at a smaller company which has worked in the field of datamodeling for 20+ yrs.  &lt;/p&gt;\n\n&lt;p&gt;We have repeatedly observed that for companies using DataWarehousing, documenting source systems provides a challenge.&lt;/p&gt;\n\n&lt;p&gt;In a small project team we would like to develop new and effective solutions for these problems.&lt;/p&gt;\n\n&lt;p&gt;For anyone with experience in this field, we would be highly grateful for your opinions on the following questions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;What challenges do you know of when it comes to documenting a database/source system? &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;What has proven to be especially challenging when documenting CRM systems such as Salesforce?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Have you encountered any specific difficulties while documenting ERP systems like SAP?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thank you very much in advance, we&amp;#39;re looking forward to hearing from you :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "zf5auk", "is_robot_indexable": true, "report_reasons": null, "author": "heureka_leo", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zf5auk/inquiry_about_database_documentation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zf5auk/inquiry_about_database_documentation/", "subreddit_subscribers": 82199, "created_utc": 1670429849.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently, our team uses a failure callback (`on_failure_callback`) to trigger an OpsGenie alert that eventually sends a Slack message. However, sometimes Composer (we're on GCP) never initiates the task, which causes the task to be marked as failed but without triggering the callback (and therefore no Slack alert of the failure). In other cases, the k8s pod the task is running on gets evicted in the middle of the run so the Airflow logs just...stop. Again, no callback triggered and no alert.\n\nOne option we've explored is using external monitoring to ensure that one task completes within a certain time of the prior task, but that seems a bit clunky. Are there any configurations within Airflow itself that could be used to send an alert and avoid silent failures?", "author_fullname": "t2_4osay", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you like to alert for Airflow errors?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zf40rw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670427220.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently, our team uses a failure callback (&lt;code&gt;on_failure_callback&lt;/code&gt;) to trigger an OpsGenie alert that eventually sends a Slack message. However, sometimes Composer (we&amp;#39;re on GCP) never initiates the task, which causes the task to be marked as failed but without triggering the callback (and therefore no Slack alert of the failure). In other cases, the k8s pod the task is running on gets evicted in the middle of the run so the Airflow logs just...stop. Again, no callback triggered and no alert.&lt;/p&gt;\n\n&lt;p&gt;One option we&amp;#39;ve explored is using external monitoring to ensure that one task completes within a certain time of the prior task, but that seems a bit clunky. Are there any configurations within Airflow itself that could be used to send an alert and avoid silent failures?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zf40rw", "is_robot_indexable": true, "report_reasons": null, "author": "doom2", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zf40rw/how_do_you_like_to_alert_for_airflow_errors/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zf40rw/how_do_you_like_to_alert_for_airflow_errors/", "subreddit_subscribers": 82199, "created_utc": 1670427220.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been trying to build a simple development environment for PySpark applications, object storage and metastore.\nEach service in a container and everything built in a docker compose yml file.\n\nI\u2019ve managed to build a PySpark image and make it communicate with Minio as an object storage so far.\n\nI\u2019m struggling with the \u201cmetastore\u201d part of my environment. I want to set up a metastore that allow me to spin up and down spark jobs and persist my tables. I\u2019ve looked into hive-standalone-metastore with an postgres instance but couldn\u2019t make it work.\n\nDoes somebody in this sub has any idea how to build something like that?", "author_fullname": "t2_5fmit0v9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PySpark + Minio + Metastore Development Container", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zf5g7v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670430157.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been trying to build a simple development environment for PySpark applications, object storage and metastore.\nEach service in a container and everything built in a docker compose yml file.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve managed to build a PySpark image and make it communicate with Minio as an object storage so far.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m struggling with the \u201cmetastore\u201d part of my environment. I want to set up a metastore that allow me to spin up and down spark jobs and persist my tables. I\u2019ve looked into hive-standalone-metastore with an postgres instance but couldn\u2019t make it work.&lt;/p&gt;\n\n&lt;p&gt;Does somebody in this sub has any idea how to build something like that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zf5g7v", "is_robot_indexable": true, "report_reasons": null, "author": "gabbom_XCII", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zf5g7v/pyspark_minio_metastore_development_container/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zf5g7v/pyspark_minio_metastore_development_container/", "subreddit_subscribers": 82199, "created_utc": 1670430157.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_h44fwr15", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Streaming Explained", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_zf0tz8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/ag9jlVxM_18?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Data Streaming, Explained\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Data Streaming, Explained", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/ag9jlVxM_18?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Data Streaming, Explained\"&gt;&lt;/iframe&gt;", "author_name": "AltexSoft", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/ag9jlVxM_18/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@AltexSoft"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/ag9jlVxM_18?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Data Streaming, Explained\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/zf0tz8", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/oOGEEuWnxyf8fkMRNvztAwyqFBC9SBs_eQ9pn0OeBoY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670418781.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/ag9jlVxM_18", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/FifG7gY_or_z4R5xF-UKZzUPiSAd1Es5m6H31dMg2Tk.jpg?auto=webp&amp;s=ea398fb51ab5fd4301f5a1ced0baa28de126d06a", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/FifG7gY_or_z4R5xF-UKZzUPiSAd1Es5m6H31dMg2Tk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3dffeb7fc1db245b3c51f1ce70aa5bd69471bb56", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/FifG7gY_or_z4R5xF-UKZzUPiSAd1Es5m6H31dMg2Tk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=94bdd7eddfa9d4d7b1862750c42a792d287e2374", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/FifG7gY_or_z4R5xF-UKZzUPiSAd1Es5m6H31dMg2Tk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c83d0f856e9c3d3a791253470b38ad8b04892063", "width": 320, "height": 240}], "variants": {}, "id": "aYyV6MrAht4kceUzbEOZ2eEXsr4R7VjwGQdFF4Gg-4I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zf0tz8", "is_robot_indexable": true, "report_reasons": null, "author": "TomSiderx", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zf0tz8/data_streaming_explained/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/ag9jlVxM_18", "subreddit_subscribers": 82199, "created_utc": 1670418781.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Data Streaming, Explained", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/ag9jlVxM_18?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Data Streaming, Explained\"&gt;&lt;/iframe&gt;", "author_name": "AltexSoft", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/ag9jlVxM_18/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@AltexSoft"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_4w5k4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The top 5 data trends to look out for in 2023 (by Velotix)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_zf10h0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/FCKC4DSuJ3rEs3oRJiqhNV762ulrj16qJzGaQzz-8H0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670419323.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "velotix.ai", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.velotix.ai/resources/blog/top-data-trends/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/RukJi1b-ipV6CDlreAxMEgfXAK8BkjcVXu1zOtMrbro.jpg?auto=webp&amp;s=f6a6fcd59eff984940d3a85ed5a537b57fc18e1f", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/RukJi1b-ipV6CDlreAxMEgfXAK8BkjcVXu1zOtMrbro.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=95b746618bca90d0c6682c8a047a2ce0901f451f", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/RukJi1b-ipV6CDlreAxMEgfXAK8BkjcVXu1zOtMrbro.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8a873fe73c58425a906cf03bf2c56520e12514fb", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/RukJi1b-ipV6CDlreAxMEgfXAK8BkjcVXu1zOtMrbro.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4b30bd008f3a0a0a7d6e8dd74dbcc4c68fa2cfcc", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/RukJi1b-ipV6CDlreAxMEgfXAK8BkjcVXu1zOtMrbro.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3132c3e87483e8edae2a195232d85c7df62cf727", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/RukJi1b-ipV6CDlreAxMEgfXAK8BkjcVXu1zOtMrbro.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=89c0dd19f8043f0560133a1ff2ded812ccff6073", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/RukJi1b-ipV6CDlreAxMEgfXAK8BkjcVXu1zOtMrbro.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5fe8058972fb2f2ddb0bd7ff94b9502bbb0a5575", "width": 1080, "height": 565}], "variants": {}, "id": "pose6bqHwmZc9D-dEY3FCT4KDlRQPDN-dV8Q5QdEGZI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zf10h0", "is_robot_indexable": true, "report_reasons": null, "author": "cobano", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zf10h0/the_top_5_data_trends_to_look_out_for_in_2023_by/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.velotix.ai/resources/blog/top-data-trends/", "subreddit_subscribers": 82199, "created_utc": 1670419323.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I consider myself a data scientist but I want to expand my scope by getting more into the full picture of the data pipeline. Since then I started reading more about MLOps and Data engineering. \n\nSo, is there an Intro courses as good as Andrew's in DE?", "author_fullname": "t2_16t67m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "what is the equivalent of Andrew Ng ML &amp; DL courses in Data Engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zfwkh4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670499814.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I consider myself a data scientist but I want to expand my scope by getting more into the full picture of the data pipeline. Since then I started reading more about MLOps and Data engineering. &lt;/p&gt;\n\n&lt;p&gt;So, is there an Intro courses as good as Andrew&amp;#39;s in DE?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zfwkh4", "is_robot_indexable": true, "report_reasons": null, "author": "Mighty__hammer", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zfwkh4/what_is_the_equivalent_of_andrew_ng_ml_dl_courses/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zfwkh4/what_is_the_equivalent_of_andrew_ng_ml_dl_courses/", "subreddit_subscribers": 82199, "created_utc": 1670499814.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Would like to know any best practices available after a Web page has been scraped using Scrapy or Selenium. Thanks.", "author_fullname": "t2_eozceps7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Checking html file data integrity after scraping", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zf3oo9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670426385.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Would like to know any best practices available after a Web page has been scraped using Scrapy or Selenium. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zf3oo9", "is_robot_indexable": true, "report_reasons": null, "author": "Liily_07", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zf3oo9/checking_html_file_data_integrity_after_scraping/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zf3oo9/checking_html_file_data_integrity_after_scraping/", "subreddit_subscribers": 82199, "created_utc": 1670426385.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious about a few things:\n\n* Mono repo or multi repo?\n* How do you abstract out boilerplate functionality that is common to all (or most) tasks?\n* How do you break down and unit test your transformations? What is the smallest piece of functionality you will unit test? An individual transformation (e.g. new column) or a sequence of related ones?\n* What is the smallest piece of functionality that will form a \"task\" i.e. an individual unit in an orchestration pipeline.\n* Do you prefer functional or object-oriented approach?\n* How do you break up a sequence of common tasks such as, loading some data, transforming it, creating a target table and inserting if it doesn't exist, or upserting if it does.\n* How do you handle &amp; unit test functionality that is only available through the SQL API?\n\nFor context I am currently working with pyspark in databricks. At the moment there's one big mono repo, with a 'task' base class that handles a lot of boilerplate functionality (e.g. spark session set up, reading config, logging). All other tasks inherit from this, there is typically a 'task' for each table, that has extract, transform, load methods etc. Initially this is being orchestrated through databricks workflows but may be moved to airflow as it gets more complex. So far this approach is working OK but I am starting to run into some friction with various aspects", "author_fullname": "t2_18xb5x05", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you structure your pyspark etl tasks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zfw27e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670498123.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious about a few things:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Mono repo or multi repo?&lt;/li&gt;\n&lt;li&gt;How do you abstract out boilerplate functionality that is common to all (or most) tasks?&lt;/li&gt;\n&lt;li&gt;How do you break down and unit test your transformations? What is the smallest piece of functionality you will unit test? An individual transformation (e.g. new column) or a sequence of related ones?&lt;/li&gt;\n&lt;li&gt;What is the smallest piece of functionality that will form a &amp;quot;task&amp;quot; i.e. an individual unit in an orchestration pipeline.&lt;/li&gt;\n&lt;li&gt;Do you prefer functional or object-oriented approach?&lt;/li&gt;\n&lt;li&gt;How do you break up a sequence of common tasks such as, loading some data, transforming it, creating a target table and inserting if it doesn&amp;#39;t exist, or upserting if it does.&lt;/li&gt;\n&lt;li&gt;How do you handle &amp;amp; unit test functionality that is only available through the SQL API?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;For context I am currently working with pyspark in databricks. At the moment there&amp;#39;s one big mono repo, with a &amp;#39;task&amp;#39; base class that handles a lot of boilerplate functionality (e.g. spark session set up, reading config, logging). All other tasks inherit from this, there is typically a &amp;#39;task&amp;#39; for each table, that has extract, transform, load methods etc. Initially this is being orchestrated through databricks workflows but may be moved to airflow as it gets more complex. So far this approach is working OK but I am starting to run into some friction with various aspects&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zfw27e", "is_robot_indexable": true, "report_reasons": null, "author": "the-data-scientist", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zfw27e/how_do_you_structure_your_pyspark_etl_tasks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zfw27e/how_do_you_structure_your_pyspark_etl_tasks/", "subreddit_subscribers": 82199, "created_utc": 1670498123.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Any latest project in python would be great. I request you to support me by suggesting latest python projects. I did my search in the internet and most of the projects are pretty much out dated.\n\nBackground: I have completed basics of python and yet to start NumPy-pandas. Meanwhile I would like to start with a project for my current level in python and later extend it into a bigger project using NumPy-pandas and visualization", "author_fullname": "t2_q60xrlzp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "latest projects in Python relevant for advancement into Data science in the near future.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zfa4uz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670439607.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any latest project in python would be great. I request you to support me by suggesting latest python projects. I did my search in the internet and most of the projects are pretty much out dated.&lt;/p&gt;\n\n&lt;p&gt;Background: I have completed basics of python and yet to start NumPy-pandas. Meanwhile I would like to start with a project for my current level in python and later extend it into a bigger project using NumPy-pandas and visualization&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zfa4uz", "is_robot_indexable": true, "report_reasons": null, "author": "hungry_man13", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zfa4uz/latest_projects_in_python_relevant_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zfa4uz/latest_projects_in_python_relevant_for/", "subreddit_subscribers": 82199, "created_utc": 1670439607.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_7oampu1h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Spark : AQE(Adaptive Query Execution)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 26, "top_awarded_type": null, "hide_score": false, "name": "t3_zfm865", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": "transparent", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/a40Mh9vOWUM13IBQuinnv_nuU0LZrzBSf4paP2Ik5fI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670466648.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/dev-genius/apache-spark-aqe-adaptive-query-execution-d754afff96ba", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/AoGoEqXHw7jm3EeJxzWJFG9W0jpvN_QiG6Of6dKXNWc.jpg?auto=webp&amp;s=0cb6a645711a105ed32f6d3796f26854ba259079", "width": 1200, "height": 230}, "resolutions": [{"url": "https://external-preview.redd.it/AoGoEqXHw7jm3EeJxzWJFG9W0jpvN_QiG6Of6dKXNWc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=63944bb9d8ebc42bd1a79e232e91e2f0f9d08327", "width": 108, "height": 20}, {"url": "https://external-preview.redd.it/AoGoEqXHw7jm3EeJxzWJFG9W0jpvN_QiG6Of6dKXNWc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8bc747e170f969012b83d0b7b032f9df32cf9d67", "width": 216, "height": 41}, {"url": "https://external-preview.redd.it/AoGoEqXHw7jm3EeJxzWJFG9W0jpvN_QiG6Of6dKXNWc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=882247aa5cf78be8d19d8f084f24ece451b1d34d", "width": 320, "height": 61}, {"url": "https://external-preview.redd.it/AoGoEqXHw7jm3EeJxzWJFG9W0jpvN_QiG6Of6dKXNWc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f4a0854949282ead231746d0acf7f83a3ee40db9", "width": 640, "height": 122}, {"url": "https://external-preview.redd.it/AoGoEqXHw7jm3EeJxzWJFG9W0jpvN_QiG6Of6dKXNWc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c017b99d919c40c50323cf7cb57976d369216e94", "width": 960, "height": 184}, {"url": "https://external-preview.redd.it/AoGoEqXHw7jm3EeJxzWJFG9W0jpvN_QiG6Of6dKXNWc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f7ac802570a652a9e866ded1d27b7e97b6f00e98", "width": 1080, "height": 207}], "variants": {}, "id": "igLSvvyzQBR9S3Uw2pSj1GHVUQDibSWwIk7zuYdDcQc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zfm865", "is_robot_indexable": true, "report_reasons": null, "author": "Sidharth_r", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/zfm865/apache_spark_aqeadaptive_query_execution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/dev-genius/apache-spark-aqe-adaptive-query-execution-d754afff96ba", "subreddit_subscribers": 82199, "created_utc": 1670466648.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://youtu.be/sPTERXmYnBs](https://youtu.be/sPTERXmYnBs)", "author_fullname": "t2_b7f9ay9o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to do Data wrangling in Azure Data Factory", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zfd4of", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1670445753.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://youtu.be/sPTERXmYnBs\"&gt;https://youtu.be/sPTERXmYnBs&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6G0ZdkahjmkBRiO5UFYbd1b5nO3RJBhFmdRXiEkgR9A.jpg?auto=webp&amp;s=f26649082272ab50421638418f24f8cc086c180c", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/6G0ZdkahjmkBRiO5UFYbd1b5nO3RJBhFmdRXiEkgR9A.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3a0c989a442df24ea60a519a3b01e460956bf2be", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/6G0ZdkahjmkBRiO5UFYbd1b5nO3RJBhFmdRXiEkgR9A.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2d0178c615faf40c321c5ea2575a11e6c266c03d", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/6G0ZdkahjmkBRiO5UFYbd1b5nO3RJBhFmdRXiEkgR9A.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a58e83f373da2d94a61cc425a9f2133941e318ea", "width": 320, "height": 240}], "variants": {}, "id": "fnGaLGugM-dKpwoivw1QbauQqVOD106EB8CftcXd8_U"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zfd4of", "is_robot_indexable": true, "report_reasons": null, "author": "balramprasad", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zfd4of/how_to_do_data_wrangling_in_azure_data_factory/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zfd4of/how_to_do_data_wrangling_in_azure_data_factory/", "subreddit_subscribers": 82199, "created_utc": 1670445753.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}