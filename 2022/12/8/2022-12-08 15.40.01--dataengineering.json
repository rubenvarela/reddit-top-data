{"kind": "Listing", "data": {"after": null, "dist": 19, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For current DEs, what is one thing you were expecting going into the DE field vs what actually occurred?\n\nBoth the good and the bad", "author_fullname": "t2_3p620rl9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Expectations Vs Reality", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zf68rv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 64, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 64, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_1": 1}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670431778.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For current DEs, what is one thing you were expecting going into the DE field vs what actually occurred?&lt;/p&gt;\n\n&lt;p&gt;Both the good and the bad&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 100, "id": "gid_1", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Shows the Silver Award... and that's it.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Silver", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "DE @ Amazon/Lyft/Author of Ace DE Interview", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zf68rv", "is_robot_indexable": true, "report_reasons": null, "author": "chrisgarzon19", "discussion_type": null, "num_comments": 80, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/zf68rv/expectations_vs_reality/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zf68rv/expectations_vs_reality/", "subreddit_subscribers": 82217, "created_utc": 1670431778.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is a great article that tries to explain [why people everywhere are speaking about Rust](https://www.adventofdata.com/rust-for-data-engineering/). To be honest it feels more like a under the hood thing rather than a full switch to the language and the article depicts this super well.\n\nMainly it says:\n\n* Why Rust: because Rust compiler is strict, easier to use than C/C++ out of JVM\n* When Rust should be used: when you want speed and performance with data, Rust and Arrow are well integrated and with security about your data types\n* When Rust should not be used: sometimes Rust type safety is too rigid for data (hf read a CSV), when you want to go fast or on a new project because the learning curve is steep\n\n*\ud83c\udf84 PS: if you did not see this article is day 8 in the Advent of Data. Advent of Data is a advent calendar, everyday in December a new article about data is published.*", "author_fullname": "t2_6ff333ne", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rust for Data Engineering\u2014what's the hype about? \ud83e\udd80", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zfv38r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1670494708.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a great article that tries to explain &lt;a href=\"https://www.adventofdata.com/rust-for-data-engineering/\"&gt;why people everywhere are speaking about Rust&lt;/a&gt;. To be honest it feels more like a under the hood thing rather than a full switch to the language and the article depicts this super well.&lt;/p&gt;\n\n&lt;p&gt;Mainly it says:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Why Rust: because Rust compiler is strict, easier to use than C/C++ out of JVM&lt;/li&gt;\n&lt;li&gt;When Rust should be used: when you want speed and performance with data, Rust and Arrow are well integrated and with security about your data types&lt;/li&gt;\n&lt;li&gt;When Rust should not be used: sometimes Rust type safety is too rigid for data (hf read a CSV), when you want to go fast or on a new project because the learning curve is steep&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;em&gt;\ud83c\udf84 PS: if you did not see this article is day 8 in the Advent of Data. Advent of Data is a advent calendar, everyday in December a new article about data is published.&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/dfy1pNT5aYWH5BB7NbYgk28jQFEwT3-xD0wHcwfyDWk.jpg?auto=webp&amp;s=9c437378a2b5d672b02ac88971f69099b626776f", "width": 2000, "height": 1125}, "resolutions": [{"url": "https://external-preview.redd.it/dfy1pNT5aYWH5BB7NbYgk28jQFEwT3-xD0wHcwfyDWk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=65555a6ae0661d24ae0ad8c53023901c1f2d44f8", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/dfy1pNT5aYWH5BB7NbYgk28jQFEwT3-xD0wHcwfyDWk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3aae1d1e8dc5458b8656842b4684b5eb9ef0ecbe", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/dfy1pNT5aYWH5BB7NbYgk28jQFEwT3-xD0wHcwfyDWk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=26ca35a4220a2e80d290b4d09af8b5ef45726fd7", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/dfy1pNT5aYWH5BB7NbYgk28jQFEwT3-xD0wHcwfyDWk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=233f41e4c3949c2ff8512bbc75537827ad464cd3", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/dfy1pNT5aYWH5BB7NbYgk28jQFEwT3-xD0wHcwfyDWk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=05d40ec5de5e74701ab1c304a95e86bf7709d69e", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/dfy1pNT5aYWH5BB7NbYgk28jQFEwT3-xD0wHcwfyDWk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fc3a0657a99a76b464eb25626ea42148c1e8ffee", "width": 1080, "height": 607}], "variants": {}, "id": "3D9xZ7JmU9ebYzdjOLAqN7Q7x4rBq_fz9fSuKp80Igk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "I'm the dataman", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zfv38r", "is_robot_indexable": true, "report_reasons": null, "author": "blef__", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/zfv38r/rust_for_data_engineeringwhats_the_hype_about/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zfv38r/rust_for_data_engineeringwhats_the_hype_about/", "subreddit_subscribers": 82217, "created_utc": 1670494708.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is lambda architecture still the most common big data architecture to follow in 2022 or is it being replaced by kappa or some other architecture?", "author_fullname": "t2_7jt0qboi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lambda architecture status", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zfl2fb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670463674.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is lambda architecture still the most common big data architecture to follow in 2022 or is it being replaced by kappa or some other architecture?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zfl2fb", "is_robot_indexable": true, "report_reasons": null, "author": "omscsdatathrow", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zfl2fb/lambda_architecture_status/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zfl2fb/lambda_architecture_status/", "subreddit_subscribers": 82217, "created_utc": 1670463674.0, "num_crossposts": 2, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Was [reading](https://thenewstack.io/iso-better-scaling-instacart-drops-postgres-for-amazon-dynamodb/) about how Instacart bailed on an AWS EC2 PostgreSQL cluster for DynamoDb. No mention of considering Aurora RDS Serverless for scale out and scale down at night. Instead they accepted the restrictions of no joins in DynamoDb and having to think strictly about write costs.   \n\n\nWhile this could make sense for a state machine for notifications, I wonder about how companies that make this trade off fair down the road. I have found in my experience that the one thing management will never tolerate is having their hands tied.   \n\n\nThey will accept certain things like not being able to store all logs forever (astronomical cost). But I find it hard to believe it would fly to optimize writes with model design such that management can't ask for new (near real time) query use cases without undoing the economic advantage the new model initially offered.  \n\n\nI also find it fascinating that developers would pick a system proclaimed to give them all sorts of model flexibility then have access costs yank that flexibility away from them (no joins, limits to fast access by partition and sort key choices, etc.) because of costs. Kinda kills the whole value proposition of moving away from RDBMS in my mind. There are many ways to skin the RDBMS scale out cat...go find one that works, and at least keep query freedom at the perceived cost of schema evolution inflexibility. \n\nDoes anyone have stories about the cost of access becoming untenable on DynamoDb for new queries not thought of during the initial model design- that couldn't be served in a time or cost efficient manner? How did you solve that? Suck out the data to an RDBMS so you can do proper analytics, which has its own time and hard costs?", "author_fullname": "t2_41z8d4gg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trade offs: DynamoDb vs. RDBMS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zfh7cy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1670454276.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Was &lt;a href=\"https://thenewstack.io/iso-better-scaling-instacart-drops-postgres-for-amazon-dynamodb/\"&gt;reading&lt;/a&gt; about how Instacart bailed on an AWS EC2 PostgreSQL cluster for DynamoDb. No mention of considering Aurora RDS Serverless for scale out and scale down at night. Instead they accepted the restrictions of no joins in DynamoDb and having to think strictly about write costs.   &lt;/p&gt;\n\n&lt;p&gt;While this could make sense for a state machine for notifications, I wonder about how companies that make this trade off fair down the road. I have found in my experience that the one thing management will never tolerate is having their hands tied.   &lt;/p&gt;\n\n&lt;p&gt;They will accept certain things like not being able to store all logs forever (astronomical cost). But I find it hard to believe it would fly to optimize writes with model design such that management can&amp;#39;t ask for new (near real time) query use cases without undoing the economic advantage the new model initially offered.  &lt;/p&gt;\n\n&lt;p&gt;I also find it fascinating that developers would pick a system proclaimed to give them all sorts of model flexibility then have access costs yank that flexibility away from them (no joins, limits to fast access by partition and sort key choices, etc.) because of costs. Kinda kills the whole value proposition of moving away from RDBMS in my mind. There are many ways to skin the RDBMS scale out cat...go find one that works, and at least keep query freedom at the perceived cost of schema evolution inflexibility. &lt;/p&gt;\n\n&lt;p&gt;Does anyone have stories about the cost of access becoming untenable on DynamoDb for new queries not thought of during the initial model design- that couldn&amp;#39;t be served in a time or cost efficient manner? How did you solve that? Suck out the data to an RDBMS so you can do proper analytics, which has its own time and hard costs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/IFixEqOEuIkYsSTDjP2HmelwRuPx_dfDVe8cnb7-1N4.jpg?auto=webp&amp;s=057a27c4c2ffb5c4b4b1c946db9da5be8e8b3614", "width": 623, "height": 350}, "resolutions": [{"url": "https://external-preview.redd.it/IFixEqOEuIkYsSTDjP2HmelwRuPx_dfDVe8cnb7-1N4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=75c75b4cf48111f537000e8f3b01185d3b9829ed", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/IFixEqOEuIkYsSTDjP2HmelwRuPx_dfDVe8cnb7-1N4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=98b680d5dd6bfa7a8246c7fac8624fa2eea98394", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/IFixEqOEuIkYsSTDjP2HmelwRuPx_dfDVe8cnb7-1N4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=eafabea55dc5940c63c3011b36848ab961fcaeb6", "width": 320, "height": 179}], "variants": {}, "id": "b5K0QHYG4hDllykT7ENcPiF757Kr84VbkWZJ2pi4Lgw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zfh7cy", "is_robot_indexable": true, "report_reasons": null, "author": "quickdraw6906", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zfh7cy/trade_offs_dynamodb_vs_rdbms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zfh7cy/trade_offs_dynamodb_vs_rdbms/", "subreddit_subscribers": 82217, "created_utc": 1670454276.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3yleu7rp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How To Measure The ROI Of Your Data Spend?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zf9dob", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1670438048.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "alvin.ai", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.alvin.ai/posts/how-to-measure-the-roi-of-your-data-spend", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zf9dob", "is_robot_indexable": true, "report_reasons": null, "author": "gabsferreiradev", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zf9dob/how_to_measure_the_roi_of_your_data_spend/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.alvin.ai/posts/how-to-measure-the-roi-of-your-data-spend", "subreddit_subscribers": 82217, "created_utc": 1670438048.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I have an in-person interview for a data engineering position next week and I'm prepping for it this week.   \nI'm wanting to know if anyone has had them and what kind of questions you remember/ or people that give interviews, what questions would you ask.   \n\n\nthe hiring manager told me to study: sql, NoSql, Data Warehouse, python scripts, power BI , ETL, Frameworks, and web-scraping.  \n\n\nI do know I will not or it is quite impossible to cram all this in a week but since i have experience in sql and data warehouses, those topics will be a quick review for me.   \nIf anyone can help, that will be fantastic!", "author_fullname": "t2_rntn75xc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview prep", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zfmfp5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670467185.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have an in-person interview for a data engineering position next week and I&amp;#39;m prepping for it this week.&lt;br/&gt;\nI&amp;#39;m wanting to know if anyone has had them and what kind of questions you remember/ or people that give interviews, what questions would you ask.   &lt;/p&gt;\n\n&lt;p&gt;the hiring manager told me to study: sql, NoSql, Data Warehouse, python scripts, power BI , ETL, Frameworks, and web-scraping.  &lt;/p&gt;\n\n&lt;p&gt;I do know I will not or it is quite impossible to cram all this in a week but since i have experience in sql and data warehouses, those topics will be a quick review for me.&lt;br/&gt;\nIf anyone can help, that will be fantastic!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "zfmfp5", "is_robot_indexable": true, "report_reasons": null, "author": "Enough_Classroom_903", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zfmfp5/interview_prep/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zfmfp5/interview_prep/", "subreddit_subscribers": 82217, "created_utc": 1670467185.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm legitimately asking.\n\nI've taken several take-home and live coding challenges over the years. I actually prefer the take-home. More realistic to how I'd solve a problem on the job. \n\nNow I'm a hiring manager using one to screen candidates. But I know people think they suck. I just never felt that way while interviewing, so I'm not 100% sure why.\n\nAny insights?", "author_fullname": "t2_1wezxlo6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Take-Homes: Why do they suck?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zfqr57", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670479233.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m legitimately asking.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve taken several take-home and live coding challenges over the years. I actually prefer the take-home. More realistic to how I&amp;#39;d solve a problem on the job. &lt;/p&gt;\n\n&lt;p&gt;Now I&amp;#39;m a hiring manager using one to screen candidates. But I know people think they suck. I just never felt that way while interviewing, so I&amp;#39;m not 100% sure why.&lt;/p&gt;\n\n&lt;p&gt;Any insights?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zfqr57", "is_robot_indexable": true, "report_reasons": null, "author": "Archbishop_Mo", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zfqr57/takehomes_why_do_they_suck/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zfqr57/takehomes_why_do_they_suck/", "subreddit_subscribers": 82217, "created_utc": 1670479233.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I consider myself a data scientist but I want to expand my scope by getting more into the full picture of the data pipeline. Since then I started reading more about MLOps and Data engineering. \n\nSo, is there an Intro courses as good as Andrew's in DE?", "author_fullname": "t2_16t67m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "what is the equivalent of Andrew Ng ML &amp; DL courses in Data Engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zfwkh4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670499814.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I consider myself a data scientist but I want to expand my scope by getting more into the full picture of the data pipeline. Since then I started reading more about MLOps and Data engineering. &lt;/p&gt;\n\n&lt;p&gt;So, is there an Intro courses as good as Andrew&amp;#39;s in DE?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zfwkh4", "is_robot_indexable": true, "report_reasons": null, "author": "Mighty__hammer", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zfwkh4/what_is_the_equivalent_of_andrew_ng_ml_dl_courses/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zfwkh4/what_is_the_equivalent_of_andrew_ng_ml_dl_courses/", "subreddit_subscribers": 82217, "created_utc": 1670499814.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious about a few things:\n\n* Mono repo or multi repo?\n* How do you abstract out boilerplate functionality that is common to all (or most) tasks?\n* How do you break down and unit test your transformations? What is the smallest piece of functionality you will unit test? An individual transformation (e.g. new column) or a sequence of related ones?\n* What is the smallest piece of functionality that will form a \"task\" i.e. an individual unit in an orchestration pipeline.\n* Do you prefer functional or object-oriented approach?\n* How do you break up a sequence of common tasks such as, loading some data, transforming it, creating a target table and inserting if it doesn't exist, or upserting if it does.\n* How do you handle &amp; unit test functionality that is only available through the SQL API?\n\nFor context I am currently working with pyspark in databricks. At the moment there's one big mono repo, with a 'task' base class that handles a lot of boilerplate functionality (e.g. spark session set up, reading config, logging). All other tasks inherit from this, there is typically a 'task' for each table, that has extract, transform, load methods etc. Initially this is being orchestrated through databricks workflows but may be moved to airflow as it gets more complex. So far this approach is working OK but I am starting to run into some friction with various aspects", "author_fullname": "t2_18xb5x05", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you structure your pyspark etl tasks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zfw27e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670498123.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious about a few things:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Mono repo or multi repo?&lt;/li&gt;\n&lt;li&gt;How do you abstract out boilerplate functionality that is common to all (or most) tasks?&lt;/li&gt;\n&lt;li&gt;How do you break down and unit test your transformations? What is the smallest piece of functionality you will unit test? An individual transformation (e.g. new column) or a sequence of related ones?&lt;/li&gt;\n&lt;li&gt;What is the smallest piece of functionality that will form a &amp;quot;task&amp;quot; i.e. an individual unit in an orchestration pipeline.&lt;/li&gt;\n&lt;li&gt;Do you prefer functional or object-oriented approach?&lt;/li&gt;\n&lt;li&gt;How do you break up a sequence of common tasks such as, loading some data, transforming it, creating a target table and inserting if it doesn&amp;#39;t exist, or upserting if it does.&lt;/li&gt;\n&lt;li&gt;How do you handle &amp;amp; unit test functionality that is only available through the SQL API?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;For context I am currently working with pyspark in databricks. At the moment there&amp;#39;s one big mono repo, with a &amp;#39;task&amp;#39; base class that handles a lot of boilerplate functionality (e.g. spark session set up, reading config, logging). All other tasks inherit from this, there is typically a &amp;#39;task&amp;#39; for each table, that has extract, transform, load methods etc. Initially this is being orchestrated through databricks workflows but may be moved to airflow as it gets more complex. So far this approach is working OK but I am starting to run into some friction with various aspects&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zfw27e", "is_robot_indexable": true, "report_reasons": null, "author": "the-data-scientist", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zfw27e/how_do_you_structure_your_pyspark_etl_tasks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zfw27e/how_do_you_structure_your_pyspark_etl_tasks/", "subreddit_subscribers": 82217, "created_utc": 1670498123.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been trying to build a simple development environment for PySpark applications, object storage and metastore.\nEach service in a container and everything built in a docker compose yml file.\n\nI\u2019ve managed to build a PySpark image and make it communicate with Minio as an object storage so far.\n\nI\u2019m struggling with the \u201cmetastore\u201d part of my environment. I want to set up a metastore that allow me to spin up and down spark jobs and persist my tables. I\u2019ve looked into hive-standalone-metastore with an postgres instance but couldn\u2019t make it work.\n\nDoes somebody in this sub has any idea how to build something like that?", "author_fullname": "t2_5fmit0v9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PySpark + Minio + Metastore Development Container", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zf5g7v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670430157.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been trying to build a simple development environment for PySpark applications, object storage and metastore.\nEach service in a container and everything built in a docker compose yml file.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve managed to build a PySpark image and make it communicate with Minio as an object storage so far.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m struggling with the \u201cmetastore\u201d part of my environment. I want to set up a metastore that allow me to spin up and down spark jobs and persist my tables. I\u2019ve looked into hive-standalone-metastore with an postgres instance but couldn\u2019t make it work.&lt;/p&gt;\n\n&lt;p&gt;Does somebody in this sub has any idea how to build something like that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zf5g7v", "is_robot_indexable": true, "report_reasons": null, "author": "gabbom_XCII", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zf5g7v/pyspark_minio_metastore_development_container/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zf5g7v/pyspark_minio_metastore_development_container/", "subreddit_subscribers": 82217, "created_utc": 1670430157.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I'm part of a research team at a smaller company which has worked in the field of datamodeling for 20+ yrs.  \n\n\nWe have repeatedly observed that for companies using DataWarehousing, documenting source systems provides a challenge.\n\nIn a small project team we would like to develop new and effective solutions for these problems.\n\nFor anyone with experience in this field, we would be highly grateful for your opinions on the following questions:\n\n1. What challenges do you know of when it comes to documenting a database/source system? \n\n2. What has proven to be especially challenging when documenting CRM systems such as Salesforce?\n\n3. Have you encountered any specific difficulties while documenting ERP systems like SAP?\n\nThank you very much in advance, we're looking forward to hearing from you :)", "author_fullname": "t2_uovnqo6g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Inquiry about Database Documentation &amp; DataWarehousing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zf5auk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670429849.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;m part of a research team at a smaller company which has worked in the field of datamodeling for 20+ yrs.  &lt;/p&gt;\n\n&lt;p&gt;We have repeatedly observed that for companies using DataWarehousing, documenting source systems provides a challenge.&lt;/p&gt;\n\n&lt;p&gt;In a small project team we would like to develop new and effective solutions for these problems.&lt;/p&gt;\n\n&lt;p&gt;For anyone with experience in this field, we would be highly grateful for your opinions on the following questions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;What challenges do you know of when it comes to documenting a database/source system? &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;What has proven to be especially challenging when documenting CRM systems such as Salesforce?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Have you encountered any specific difficulties while documenting ERP systems like SAP?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thank you very much in advance, we&amp;#39;re looking forward to hearing from you :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "zf5auk", "is_robot_indexable": true, "report_reasons": null, "author": "heureka_leo", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zf5auk/inquiry_about_database_documentation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zf5auk/inquiry_about_database_documentation/", "subreddit_subscribers": 82217, "created_utc": 1670429849.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently, our team uses a failure callback (`on_failure_callback`) to trigger an OpsGenie alert that eventually sends a Slack message. However, sometimes Composer (we're on GCP) never initiates the task, which causes the task to be marked as failed but without triggering the callback (and therefore no Slack alert of the failure). In other cases, the k8s pod the task is running on gets evicted in the middle of the run so the Airflow logs just...stop. Again, no callback triggered and no alert.\n\nOne option we've explored is using external monitoring to ensure that one task completes within a certain time of the prior task, but that seems a bit clunky. Are there any configurations within Airflow itself that could be used to send an alert and avoid silent failures?", "author_fullname": "t2_4osay", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you like to alert for Airflow errors?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zf40rw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670427220.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently, our team uses a failure callback (&lt;code&gt;on_failure_callback&lt;/code&gt;) to trigger an OpsGenie alert that eventually sends a Slack message. However, sometimes Composer (we&amp;#39;re on GCP) never initiates the task, which causes the task to be marked as failed but without triggering the callback (and therefore no Slack alert of the failure). In other cases, the k8s pod the task is running on gets evicted in the middle of the run so the Airflow logs just...stop. Again, no callback triggered and no alert.&lt;/p&gt;\n\n&lt;p&gt;One option we&amp;#39;ve explored is using external monitoring to ensure that one task completes within a certain time of the prior task, but that seems a bit clunky. Are there any configurations within Airflow itself that could be used to send an alert and avoid silent failures?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zf40rw", "is_robot_indexable": true, "report_reasons": null, "author": "doom2", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zf40rw/how_do_you_like_to_alert_for_airflow_errors/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zf40rw/how_do_you_like_to_alert_for_airflow_errors/", "subreddit_subscribers": 82217, "created_utc": 1670427220.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Would like to know any best practices available after a Web page has been scraped using Scrapy or Selenium. Thanks.", "author_fullname": "t2_eozceps7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Checking html file data integrity after scraping", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zf3oo9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670426385.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Would like to know any best practices available after a Web page has been scraped using Scrapy or Selenium. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zf3oo9", "is_robot_indexable": true, "report_reasons": null, "author": "Liily_07", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zf3oo9/checking_html_file_data_integrity_after_scraping/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zf3oo9/checking_html_file_data_integrity_after_scraping/", "subreddit_subscribers": 82217, "created_utc": 1670426385.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Everyone, we are using SSIS as our primary ETL tool, it's been great so far but I believe it's time to say goodbye to our old friend SSIS  (atleast for a few important pipelines )\n\nOne of the major pipeline has this functionality (Entirely metadata driven)\n\n* Fetch incremental data for a 1000 tables from point A using linked servers (Batch processing)\n* Stage the acquired data in point B\n* Do upsert and deletion of corresponding point B tables using staged tables/data \n* Trigger datamarts and a bunch of other processes \n* Refresh/update reports using data from datamarts/processes from last step\n\nIt's been running fine until now but now due to the following reasons, we would like to move away from SSIS\n\n1. Our data is constantly growing i.e. for a few tables, incremental records may go up to 5-10 million per day  \n2. DS/Analytics team keep asking for ingestion of new tables meaning more and more data that needs to be processes daily\n3. Some of the processes have complex pre-requisite conditions, they can be implemented in SSIS but I believe a coded solution/pipeline would give us much more control than SSIS\n4. Our important pipelines use linked servers, lately they have been pain in the ass and we would like to ditch them that would require an entire overhaul in any case\n5. Debugging can get tricky sometimes\n6. A lot of simple things usually require way arounds in SSIS\n\nPlus a few other reservations, now we'd like to slowly move away from SSIS and opt some other solution, would really appreciate any feedback to what should we switch over to? Would prefer to code the pipelines instead of low-code/no-code solutions.", "author_fullname": "t2_2xpdiv8k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help required in moving away from SSIS to another solution", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zfzfdg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670507286.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Everyone, we are using SSIS as our primary ETL tool, it&amp;#39;s been great so far but I believe it&amp;#39;s time to say goodbye to our old friend SSIS  (atleast for a few important pipelines )&lt;/p&gt;\n\n&lt;p&gt;One of the major pipeline has this functionality (Entirely metadata driven)&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Fetch incremental data for a 1000 tables from point A using linked servers (Batch processing)&lt;/li&gt;\n&lt;li&gt;Stage the acquired data in point B&lt;/li&gt;\n&lt;li&gt;Do upsert and deletion of corresponding point B tables using staged tables/data &lt;/li&gt;\n&lt;li&gt;Trigger datamarts and a bunch of other processes &lt;/li&gt;\n&lt;li&gt;Refresh/update reports using data from datamarts/processes from last step&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;It&amp;#39;s been running fine until now but now due to the following reasons, we would like to move away from SSIS&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Our data is constantly growing i.e. for a few tables, incremental records may go up to 5-10 million per day&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;DS/Analytics team keep asking for ingestion of new tables meaning more and more data that needs to be processes daily&lt;/li&gt;\n&lt;li&gt;Some of the processes have complex pre-requisite conditions, they can be implemented in SSIS but I believe a coded solution/pipeline would give us much more control than SSIS&lt;/li&gt;\n&lt;li&gt;Our important pipelines use linked servers, lately they have been pain in the ass and we would like to ditch them that would require an entire overhaul in any case&lt;/li&gt;\n&lt;li&gt;Debugging can get tricky sometimes&lt;/li&gt;\n&lt;li&gt;A lot of simple things usually require way arounds in SSIS&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Plus a few other reservations, now we&amp;#39;d like to slowly move away from SSIS and opt some other solution, would really appreciate any feedback to what should we switch over to? Would prefer to code the pipelines instead of low-code/no-code solutions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zfzfdg", "is_robot_indexable": true, "report_reasons": null, "author": "_whitezetsu", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zfzfdg/help_required_in_moving_away_from_ssis_to_another/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zfzfdg/help_required_in_moving_away_from_ssis_to_another/", "subreddit_subscribers": 82217, "created_utc": 1670507286.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So we are trying to figure out how to use DLT properly. \n\n* Are they supposed to be used for bronze, silver, gold transformations? My company doesn't want bronze and silver tables in the metastore, only to have the bronze and silver data stored in Delta format in the storage account... DLT seems to automatically create table in the metastore, but perhaps there's an option to disable it for a specific DLT table?\n* Are we supposed to develop DLT pipelines by first writing normal, interactive pyspark transformations, then afterwards adding all the DLT decorators everywhere? One way to do it seems to be create all the functions (one function per dataset) without DLT decorators in one notebook, then import this into another notebook where decorators are added (and DLT pipeline is run from this latter notebook)\n* Are we supposed to go into the DLT pipeline config to limit the job clusters that can be created? Use policies for this? I don't like that DLT supposedly manages everything, feel like I lose control. \n* Are we supposed to put bronze, silver gold transformations in DLT? We want lineage for all our data eventually, but right now it seems too much of a hassle when we can't develop it interactively. Is there another way to do this?\n* Are DLT pipelines supposed to replace normal workflows/jobs without DLT? Or are they intended for different purposes? \n\nAlso some general Databricks questions while I'm at it: \n\n* How do you all manage permissions? I've seen examples of running SQL notebooks with GRANT statements, but also using Terraform for the same thing. I guess the latter may be the approach of a bigger, more mature company? \n* We haven't started using Unity Catalog yet, but would using it make me NOT have to manage secrets for ADLS Gen2 storage? Currently I either have to run a cell in a notebook to configure spark with proper credentials, or set the config on launch of a cluster (also probably have to configure this for DLT pipelines but haven't gotten around to it yet) \n* Does dbt do pretty much exactly what DLT pipelines do? But perhaps in a smoother, more awesome interface? \n\nI'm quite junior still, so apologies for any dumb questions. \n\nThanks a lot for this super useful community.", "author_fullname": "t2_4ov075m4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I don't understand how Delta Live Table pipelines in Databricks are supposed to be used", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zfyhvy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670505053.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So we are trying to figure out how to use DLT properly. &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Are they supposed to be used for bronze, silver, gold transformations? My company doesn&amp;#39;t want bronze and silver tables in the metastore, only to have the bronze and silver data stored in Delta format in the storage account... DLT seems to automatically create table in the metastore, but perhaps there&amp;#39;s an option to disable it for a specific DLT table?&lt;/li&gt;\n&lt;li&gt;Are we supposed to develop DLT pipelines by first writing normal, interactive pyspark transformations, then afterwards adding all the DLT decorators everywhere? One way to do it seems to be create all the functions (one function per dataset) without DLT decorators in one notebook, then import this into another notebook where decorators are added (and DLT pipeline is run from this latter notebook)&lt;/li&gt;\n&lt;li&gt;Are we supposed to go into the DLT pipeline config to limit the job clusters that can be created? Use policies for this? I don&amp;#39;t like that DLT supposedly manages everything, feel like I lose control. &lt;/li&gt;\n&lt;li&gt;Are we supposed to put bronze, silver gold transformations in DLT? We want lineage for all our data eventually, but right now it seems too much of a hassle when we can&amp;#39;t develop it interactively. Is there another way to do this?&lt;/li&gt;\n&lt;li&gt;Are DLT pipelines supposed to replace normal workflows/jobs without DLT? Or are they intended for different purposes? &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Also some general Databricks questions while I&amp;#39;m at it: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;How do you all manage permissions? I&amp;#39;ve seen examples of running SQL notebooks with GRANT statements, but also using Terraform for the same thing. I guess the latter may be the approach of a bigger, more mature company? &lt;/li&gt;\n&lt;li&gt;We haven&amp;#39;t started using Unity Catalog yet, but would using it make me NOT have to manage secrets for ADLS Gen2 storage? Currently I either have to run a cell in a notebook to configure spark with proper credentials, or set the config on launch of a cluster (also probably have to configure this for DLT pipelines but haven&amp;#39;t gotten around to it yet) &lt;/li&gt;\n&lt;li&gt;Does dbt do pretty much exactly what DLT pipelines do? But perhaps in a smoother, more awesome interface? &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m quite junior still, so apologies for any dumb questions. &lt;/p&gt;\n\n&lt;p&gt;Thanks a lot for this super useful community.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zfyhvy", "is_robot_indexable": true, "report_reasons": null, "author": "HealthyDoggos4Life", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zfyhvy/i_dont_understand_how_delta_live_table_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zfyhvy/i_dont_understand_how_delta_live_table_pipelines/", "subreddit_subscribers": 82217, "created_utc": 1670505053.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi data folks, \n\nSo I want to develop a product Recommendation feature for my ecommerce site. We have our table which has successfull cart orders by customers. Table looks like ( cart_id , product_id , category_id , product_name). Now I want to develop a product Recommendation model using this data. What are various product Recommendation models (similar to Amazon)(production usecase) that I can explore and study ? Can someone send me production examples with sample code that I can start a POC with ?", "author_fullname": "t2_57e44nxs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Product Recommendation Algorithm", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zfyhiz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670505029.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi data folks, &lt;/p&gt;\n\n&lt;p&gt;So I want to develop a product Recommendation feature for my ecommerce site. We have our table which has successfull cart orders by customers. Table looks like ( cart_id , product_id , category_id , product_name). Now I want to develop a product Recommendation model using this data. What are various product Recommendation models (similar to Amazon)(production usecase) that I can explore and study ? Can someone send me production examples with sample code that I can start a POC with ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zfyhiz", "is_robot_indexable": true, "report_reasons": null, "author": "RstarPhoneix", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zfyhiz/product_recommendation_algorithm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zfyhiz/product_recommendation_algorithm/", "subreddit_subscribers": 82217, "created_utc": 1670505029.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_7oampu1h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Spark : AQE(Adaptive Query Execution)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 26, "top_awarded_type": null, "hide_score": false, "name": "t3_zfm865", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": "transparent", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/a40Mh9vOWUM13IBQuinnv_nuU0LZrzBSf4paP2Ik5fI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670466648.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/dev-genius/apache-spark-aqe-adaptive-query-execution-d754afff96ba", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/AoGoEqXHw7jm3EeJxzWJFG9W0jpvN_QiG6Of6dKXNWc.jpg?auto=webp&amp;s=0cb6a645711a105ed32f6d3796f26854ba259079", "width": 1200, "height": 230}, "resolutions": [{"url": "https://external-preview.redd.it/AoGoEqXHw7jm3EeJxzWJFG9W0jpvN_QiG6Of6dKXNWc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=63944bb9d8ebc42bd1a79e232e91e2f0f9d08327", "width": 108, "height": 20}, {"url": "https://external-preview.redd.it/AoGoEqXHw7jm3EeJxzWJFG9W0jpvN_QiG6Of6dKXNWc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8bc747e170f969012b83d0b7b032f9df32cf9d67", "width": 216, "height": 41}, {"url": "https://external-preview.redd.it/AoGoEqXHw7jm3EeJxzWJFG9W0jpvN_QiG6Of6dKXNWc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=882247aa5cf78be8d19d8f084f24ece451b1d34d", "width": 320, "height": 61}, {"url": "https://external-preview.redd.it/AoGoEqXHw7jm3EeJxzWJFG9W0jpvN_QiG6Of6dKXNWc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f4a0854949282ead231746d0acf7f83a3ee40db9", "width": 640, "height": 122}, {"url": "https://external-preview.redd.it/AoGoEqXHw7jm3EeJxzWJFG9W0jpvN_QiG6Of6dKXNWc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c017b99d919c40c50323cf7cb57976d369216e94", "width": 960, "height": 184}, {"url": "https://external-preview.redd.it/AoGoEqXHw7jm3EeJxzWJFG9W0jpvN_QiG6Of6dKXNWc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f7ac802570a652a9e866ded1d27b7e97b6f00e98", "width": 1080, "height": 207}], "variants": {}, "id": "igLSvvyzQBR9S3Uw2pSj1GHVUQDibSWwIk7zuYdDcQc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zfm865", "is_robot_indexable": true, "report_reasons": null, "author": "Sidharth_r", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/zfm865/apache_spark_aqeadaptive_query_execution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/dev-genius/apache-spark-aqe-adaptive-query-execution-d754afff96ba", "subreddit_subscribers": 82217, "created_utc": 1670466648.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Any latest project in python would be great. I request you to support me by suggesting latest python projects. I did my search in the internet and most of the projects are pretty much out dated.\n\nBackground: I have completed basics of python and yet to start NumPy-pandas. Meanwhile I would like to start with a project for my current level in python and later extend it into a bigger project using NumPy-pandas and visualization", "author_fullname": "t2_q60xrlzp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "latest projects in Python relevant for advancement into Data science in the near future.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zfa4uz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670439607.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any latest project in python would be great. I request you to support me by suggesting latest python projects. I did my search in the internet and most of the projects are pretty much out dated.&lt;/p&gt;\n\n&lt;p&gt;Background: I have completed basics of python and yet to start NumPy-pandas. Meanwhile I would like to start with a project for my current level in python and later extend it into a bigger project using NumPy-pandas and visualization&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zfa4uz", "is_robot_indexable": true, "report_reasons": null, "author": "hungry_man13", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zfa4uz/latest_projects_in_python_relevant_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zfa4uz/latest_projects_in_python_relevant_for/", "subreddit_subscribers": 82217, "created_utc": 1670439607.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://youtu.be/sPTERXmYnBs](https://youtu.be/sPTERXmYnBs)", "author_fullname": "t2_b7f9ay9o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to do Data wrangling in Azure Data Factory", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zfd4of", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1670445753.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://youtu.be/sPTERXmYnBs\"&gt;https://youtu.be/sPTERXmYnBs&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6G0ZdkahjmkBRiO5UFYbd1b5nO3RJBhFmdRXiEkgR9A.jpg?auto=webp&amp;s=f26649082272ab50421638418f24f8cc086c180c", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/6G0ZdkahjmkBRiO5UFYbd1b5nO3RJBhFmdRXiEkgR9A.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3a0c989a442df24ea60a519a3b01e460956bf2be", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/6G0ZdkahjmkBRiO5UFYbd1b5nO3RJBhFmdRXiEkgR9A.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2d0178c615faf40c321c5ea2575a11e6c266c03d", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/6G0ZdkahjmkBRiO5UFYbd1b5nO3RJBhFmdRXiEkgR9A.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a58e83f373da2d94a61cc425a9f2133941e318ea", "width": 320, "height": 240}], "variants": {}, "id": "fnGaLGugM-dKpwoivw1QbauQqVOD106EB8CftcXd8_U"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zfd4of", "is_robot_indexable": true, "report_reasons": null, "author": "balramprasad", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zfd4of/how_to_do_data_wrangling_in_azure_data_factory/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zfd4of/how_to_do_data_wrangling_in_azure_data_factory/", "subreddit_subscribers": 82217, "created_utc": 1670445753.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}