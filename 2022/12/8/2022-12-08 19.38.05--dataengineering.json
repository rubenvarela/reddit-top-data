{"kind": "Listing", "data": {"after": null, "dist": 21, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is a great article that tries to explain [why people everywhere are speaking about Rust](https://www.adventofdata.com/rust-for-data-engineering/). To be honest it feels more like a under the hood thing rather than a full switch to the language and the article depicts this super well.\n\nMainly it says:\n\n* Why Rust: because Rust compiler is strict, easier to use than C/C++ out of JVM\n* When Rust should be used: when you want speed and performance with data, Rust and Arrow are well integrated and with security about your data types\n* When Rust should not be used: sometimes Rust type safety is too rigid for data (hf read a CSV), when you want to go fast or on a new project because the learning curve is steep\n\n*\ud83c\udf84 PS: if you did not see this article is day 8 in the Advent of Data. Advent of Data is a advent calendar, everyday in December a new article about data is published.*", "author_fullname": "t2_6ff333ne", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rust for Data Engineering\u2014what's the hype about? \ud83e\udd80", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zfv38r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 59, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 59, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1670494708.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a great article that tries to explain &lt;a href=\"https://www.adventofdata.com/rust-for-data-engineering/\"&gt;why people everywhere are speaking about Rust&lt;/a&gt;. To be honest it feels more like a under the hood thing rather than a full switch to the language and the article depicts this super well.&lt;/p&gt;\n\n&lt;p&gt;Mainly it says:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Why Rust: because Rust compiler is strict, easier to use than C/C++ out of JVM&lt;/li&gt;\n&lt;li&gt;When Rust should be used: when you want speed and performance with data, Rust and Arrow are well integrated and with security about your data types&lt;/li&gt;\n&lt;li&gt;When Rust should not be used: sometimes Rust type safety is too rigid for data (hf read a CSV), when you want to go fast or on a new project because the learning curve is steep&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;em&gt;\ud83c\udf84 PS: if you did not see this article is day 8 in the Advent of Data. Advent of Data is a advent calendar, everyday in December a new article about data is published.&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/dfy1pNT5aYWH5BB7NbYgk28jQFEwT3-xD0wHcwfyDWk.jpg?auto=webp&amp;s=9c437378a2b5d672b02ac88971f69099b626776f", "width": 2000, "height": 1125}, "resolutions": [{"url": "https://external-preview.redd.it/dfy1pNT5aYWH5BB7NbYgk28jQFEwT3-xD0wHcwfyDWk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=65555a6ae0661d24ae0ad8c53023901c1f2d44f8", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/dfy1pNT5aYWH5BB7NbYgk28jQFEwT3-xD0wHcwfyDWk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3aae1d1e8dc5458b8656842b4684b5eb9ef0ecbe", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/dfy1pNT5aYWH5BB7NbYgk28jQFEwT3-xD0wHcwfyDWk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=26ca35a4220a2e80d290b4d09af8b5ef45726fd7", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/dfy1pNT5aYWH5BB7NbYgk28jQFEwT3-xD0wHcwfyDWk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=233f41e4c3949c2ff8512bbc75537827ad464cd3", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/dfy1pNT5aYWH5BB7NbYgk28jQFEwT3-xD0wHcwfyDWk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=05d40ec5de5e74701ab1c304a95e86bf7709d69e", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/dfy1pNT5aYWH5BB7NbYgk28jQFEwT3-xD0wHcwfyDWk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fc3a0657a99a76b464eb25626ea42148c1e8ffee", "width": 1080, "height": 607}], "variants": {}, "id": "3D9xZ7JmU9ebYzdjOLAqN7Q7x4rBq_fz9fSuKp80Igk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "I'm the dataman", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zfv38r", "is_robot_indexable": true, "report_reasons": null, "author": "blef__", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/zfv38r/rust_for_data_engineeringwhats_the_hype_about/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zfv38r/rust_for_data_engineeringwhats_the_hype_about/", "subreddit_subscribers": 82256, "created_utc": 1670494708.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey r/dataengineering,\n\nI'm a data scientist at Monte Carlo. I do some work on root cause analysis for data failures, like ETL job failures, timeouts, pipeline delays, etc. I think there's a lot that can be done from a data science perspective to automate RCA, or provide better insights into data pipeline problems (both within our own product and in general).\n\nI put together this blog post, showing how an orchestration DAG (like a dbt schedule DAG) can be converted into a Bayesian network. You can then ask causal attribution questions in the form of conditional probability queries against the BN.\n\nThe idea is still pretty basic / preliminary, but I think it could be extended in all sorts of interesting ways e.g. attributing bad row-level data to upstream transformations, etc. Generally there are just a lot of graphical structures in data eng that make causal inference / attribution really interesting. Would be keen to hear what people think\n\n[https://www.montecarlodata.com/how-elt-schedules-can-improve-root-cause-analysis-for-data-engineers/](https://www.montecarlodata.com/how-elt-schedules-can-improve-root-cause-analysis-for-data-engineers/)\n\nApologies for the vendor content! Not a product showcase", "author_fullname": "t2_8a0clpvb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How ELT Schedules Can Improve Root Cause Analysis For Data Engineers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zg2gyy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1670514079.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt;,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a data scientist at Monte Carlo. I do some work on root cause analysis for data failures, like ETL job failures, timeouts, pipeline delays, etc. I think there&amp;#39;s a lot that can be done from a data science perspective to automate RCA, or provide better insights into data pipeline problems (both within our own product and in general).&lt;/p&gt;\n\n&lt;p&gt;I put together this blog post, showing how an orchestration DAG (like a dbt schedule DAG) can be converted into a Bayesian network. You can then ask causal attribution questions in the form of conditional probability queries against the BN.&lt;/p&gt;\n\n&lt;p&gt;The idea is still pretty basic / preliminary, but I think it could be extended in all sorts of interesting ways e.g. attributing bad row-level data to upstream transformations, etc. Generally there are just a lot of graphical structures in data eng that make causal inference / attribution really interesting. Would be keen to hear what people think&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.montecarlodata.com/how-elt-schedules-can-improve-root-cause-analysis-for-data-engineers/\"&gt;https://www.montecarlodata.com/how-elt-schedules-can-improve-root-cause-analysis-for-data-engineers/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Apologies for the vendor content! Not a product showcase&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/lLuQCiON0_Cx_cPMZQUS8mww-eVFaFQOUcN9F9byfzA.jpg?auto=webp&amp;s=46d1c14a61654b1f92e3f89e73ef305f8eb95195", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/lLuQCiON0_Cx_cPMZQUS8mww-eVFaFQOUcN9F9byfzA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c19e0f95eae9bb949134a70fbf0646dab674784e", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/lLuQCiON0_Cx_cPMZQUS8mww-eVFaFQOUcN9F9byfzA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f9828d08f9ca7d2b6b05f849de32579671819a15", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/lLuQCiON0_Cx_cPMZQUS8mww-eVFaFQOUcN9F9byfzA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=94e0b261a96b0a47ab1796cf3bcfa7b84d67841c", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/lLuQCiON0_Cx_cPMZQUS8mww-eVFaFQOUcN9F9byfzA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5dc93989cf8a4b4c6f23f52a48883008d388acf9", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/lLuQCiON0_Cx_cPMZQUS8mww-eVFaFQOUcN9F9byfzA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a241617e7b6a125dd8ee3bae1a5814764d6f8474", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/lLuQCiON0_Cx_cPMZQUS8mww-eVFaFQOUcN9F9byfzA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=675845d44836d28512d2f8c8cf2b61e4303285e6", "width": 1080, "height": 567}], "variants": {}, "id": "2Ifj-_uAmtsnulLH2vMwIzsKIBt-dbWRTjxini4yErI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zg2gyy", "is_robot_indexable": true, "report_reasons": null, "author": "monacodev", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zg2gyy/how_elt_schedules_can_improve_root_cause_analysis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zg2gyy/how_elt_schedules_can_improve_root_cause_analysis/", "subreddit_subscribers": 82256, "created_utc": 1670514079.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is lambda architecture still the most common big data architecture to follow in 2022 or is it being replaced by kappa or some other architecture?", "author_fullname": "t2_7jt0qboi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lambda architecture status", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zfl2fb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670463674.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is lambda architecture still the most common big data architecture to follow in 2022 or is it being replaced by kappa or some other architecture?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zfl2fb", "is_robot_indexable": true, "report_reasons": null, "author": "omscsdatathrow", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zfl2fb/lambda_architecture_status/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zfl2fb/lambda_architecture_status/", "subreddit_subscribers": 82256, "created_utc": 1670463674.0, "num_crossposts": 2, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Was [reading](https://thenewstack.io/iso-better-scaling-instacart-drops-postgres-for-amazon-dynamodb/) about how Instacart bailed on an AWS EC2 PostgreSQL cluster for DynamoDb. No mention of considering Aurora RDS Serverless for scale out and scale down at night. Instead they accepted the restrictions of no joins in DynamoDb and having to think strictly about write costs.   \n\n\nWhile this could make sense for a state machine for notifications, I wonder about how companies that make this trade off fair down the road. I have found in my experience that the one thing management will never tolerate is having their hands tied.   \n\n\nThey will accept certain things like not being able to store all logs forever (astronomical cost). But I find it hard to believe it would fly to optimize writes with model design such that management can't ask for new (near real time) query use cases without undoing the economic advantage the new model initially offered.  \n\n\nI also find it fascinating that developers would pick a system proclaimed to give them all sorts of model flexibility then have access costs yank that flexibility away from them (no joins, limits to fast access by partition and sort key choices, etc.) because of costs. Kinda kills the whole value proposition of moving away from RDBMS in my mind. There are many ways to skin the RDBMS scale out cat...go find one that works, and at least keep query freedom at the perceived cost of schema evolution inflexibility. \n\nDoes anyone have stories about the cost of access becoming untenable on DynamoDb for new queries not thought of during the initial model design- that couldn't be served in a time or cost efficient manner? How did you solve that? Suck out the data to an RDBMS so you can do proper analytics, which has its own time and hard costs?", "author_fullname": "t2_41z8d4gg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trade offs: DynamoDb vs. RDBMS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zfh7cy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1670454276.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Was &lt;a href=\"https://thenewstack.io/iso-better-scaling-instacart-drops-postgres-for-amazon-dynamodb/\"&gt;reading&lt;/a&gt; about how Instacart bailed on an AWS EC2 PostgreSQL cluster for DynamoDb. No mention of considering Aurora RDS Serverless for scale out and scale down at night. Instead they accepted the restrictions of no joins in DynamoDb and having to think strictly about write costs.   &lt;/p&gt;\n\n&lt;p&gt;While this could make sense for a state machine for notifications, I wonder about how companies that make this trade off fair down the road. I have found in my experience that the one thing management will never tolerate is having their hands tied.   &lt;/p&gt;\n\n&lt;p&gt;They will accept certain things like not being able to store all logs forever (astronomical cost). But I find it hard to believe it would fly to optimize writes with model design such that management can&amp;#39;t ask for new (near real time) query use cases without undoing the economic advantage the new model initially offered.  &lt;/p&gt;\n\n&lt;p&gt;I also find it fascinating that developers would pick a system proclaimed to give them all sorts of model flexibility then have access costs yank that flexibility away from them (no joins, limits to fast access by partition and sort key choices, etc.) because of costs. Kinda kills the whole value proposition of moving away from RDBMS in my mind. There are many ways to skin the RDBMS scale out cat...go find one that works, and at least keep query freedom at the perceived cost of schema evolution inflexibility. &lt;/p&gt;\n\n&lt;p&gt;Does anyone have stories about the cost of access becoming untenable on DynamoDb for new queries not thought of during the initial model design- that couldn&amp;#39;t be served in a time or cost efficient manner? How did you solve that? Suck out the data to an RDBMS so you can do proper analytics, which has its own time and hard costs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/IFixEqOEuIkYsSTDjP2HmelwRuPx_dfDVe8cnb7-1N4.jpg?auto=webp&amp;s=057a27c4c2ffb5c4b4b1c946db9da5be8e8b3614", "width": 623, "height": 350}, "resolutions": [{"url": "https://external-preview.redd.it/IFixEqOEuIkYsSTDjP2HmelwRuPx_dfDVe8cnb7-1N4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=75c75b4cf48111f537000e8f3b01185d3b9829ed", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/IFixEqOEuIkYsSTDjP2HmelwRuPx_dfDVe8cnb7-1N4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=98b680d5dd6bfa7a8246c7fac8624fa2eea98394", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/IFixEqOEuIkYsSTDjP2HmelwRuPx_dfDVe8cnb7-1N4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=eafabea55dc5940c63c3011b36848ab961fcaeb6", "width": 320, "height": 179}], "variants": {}, "id": "b5K0QHYG4hDllykT7ENcPiF757Kr84VbkWZJ2pi4Lgw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zfh7cy", "is_robot_indexable": true, "report_reasons": null, "author": "quickdraw6906", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zfh7cy/trade_offs_dynamodb_vs_rdbms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zfh7cy/trade_offs_dynamodb_vs_rdbms/", "subreddit_subscribers": 82256, "created_utc": 1670454276.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I consider myself a data scientist but I want to expand my scope by getting more into the full picture of the data pipeline. Since then I started reading more about MLOps and Data engineering. \n\nSo, is there an Intro courses as good as Andrew's in DE?", "author_fullname": "t2_16t67m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "what is the equivalent of Andrew Ng ML &amp; DL courses in Data Engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zfwkh4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670499814.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I consider myself a data scientist but I want to expand my scope by getting more into the full picture of the data pipeline. Since then I started reading more about MLOps and Data engineering. &lt;/p&gt;\n\n&lt;p&gt;So, is there an Intro courses as good as Andrew&amp;#39;s in DE?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zfwkh4", "is_robot_indexable": true, "report_reasons": null, "author": "Mighty__hammer", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zfwkh4/what_is_the_equivalent_of_andrew_ng_ml_dl_courses/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zfwkh4/what_is_the_equivalent_of_andrew_ng_ml_dl_courses/", "subreddit_subscribers": 82256, "created_utc": 1670499814.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm legitimately asking.\n\nI've taken several take-home and live coding challenges over the years. I actually prefer the take-home. More realistic to how I'd solve a problem on the job. \n\nNow I'm a hiring manager using one to screen candidates. But I know people think they suck. I just never felt that way while interviewing, so I'm not 100% sure why.\n\nAny insights?", "author_fullname": "t2_1wezxlo6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Take-Homes: Why do they suck?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zfqr57", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670479233.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m legitimately asking.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve taken several take-home and live coding challenges over the years. I actually prefer the take-home. More realistic to how I&amp;#39;d solve a problem on the job. &lt;/p&gt;\n\n&lt;p&gt;Now I&amp;#39;m a hiring manager using one to screen candidates. But I know people think they suck. I just never felt that way while interviewing, so I&amp;#39;m not 100% sure why.&lt;/p&gt;\n\n&lt;p&gt;Any insights?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zfqr57", "is_robot_indexable": true, "report_reasons": null, "author": "Archbishop_Mo", "discussion_type": null, "num_comments": 45, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zfqr57/takehomes_why_do_they_suck/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zfqr57/takehomes_why_do_they_suck/", "subreddit_subscribers": 82256, "created_utc": 1670479233.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I have an in-person interview for a data engineering position next week and I'm prepping for it this week.   \nI'm wanting to know if anyone has had them and what kind of questions you remember/ or people that give interviews, what questions would you ask.   \n\n\nthe hiring manager told me to study: sql, NoSql, Data Warehouse, python scripts, power BI , ETL, Frameworks, and web-scraping.  \n\n\nI do know I will not or it is quite impossible to cram all this in a week but since i have experience in sql and data warehouses, those topics will be a quick review for me.   \nIf anyone can help, that will be fantastic!", "author_fullname": "t2_rntn75xc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview prep", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zfmfp5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670467185.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have an in-person interview for a data engineering position next week and I&amp;#39;m prepping for it this week.&lt;br/&gt;\nI&amp;#39;m wanting to know if anyone has had them and what kind of questions you remember/ or people that give interviews, what questions would you ask.   &lt;/p&gt;\n\n&lt;p&gt;the hiring manager told me to study: sql, NoSql, Data Warehouse, python scripts, power BI , ETL, Frameworks, and web-scraping.  &lt;/p&gt;\n\n&lt;p&gt;I do know I will not or it is quite impossible to cram all this in a week but since i have experience in sql and data warehouses, those topics will be a quick review for me.&lt;br/&gt;\nIf anyone can help, that will be fantastic!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "zfmfp5", "is_robot_indexable": true, "report_reasons": null, "author": "Enough_Classroom_903", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zfmfp5/interview_prep/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zfmfp5/interview_prep/", "subreddit_subscribers": 82256, "created_utc": 1670467185.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious about a few things:\n\n* Mono repo or multi repo?\n* How do you abstract out boilerplate functionality that is common to all (or most) tasks?\n* How do you break down and unit test your transformations? What is the smallest piece of functionality you will unit test? An individual transformation (e.g. new column) or a sequence of related ones?\n* What is the smallest piece of functionality that will form a \"task\" i.e. an individual unit in an orchestration pipeline.\n* Do you prefer functional or object-oriented approach?\n* How do you break up a sequence of common tasks such as, loading some data, transforming it, creating a target table and inserting if it doesn't exist, or upserting if it does.\n* How do you handle &amp; unit test functionality that is only available through the SQL API?\n\nFor context I am currently working with pyspark in databricks. At the moment there's one big mono repo, with a 'task' base class that handles a lot of boilerplate functionality (e.g. spark session set up, reading config, logging). All other tasks inherit from this, there is typically a 'task' for each table, that has extract, transform, load methods etc. Initially this is being orchestrated through databricks workflows but may be moved to airflow as it gets more complex. So far this approach is working OK but I am starting to run into some friction with various aspects", "author_fullname": "t2_18xb5x05", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you structure your pyspark etl tasks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zfw27e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670498123.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious about a few things:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Mono repo or multi repo?&lt;/li&gt;\n&lt;li&gt;How do you abstract out boilerplate functionality that is common to all (or most) tasks?&lt;/li&gt;\n&lt;li&gt;How do you break down and unit test your transformations? What is the smallest piece of functionality you will unit test? An individual transformation (e.g. new column) or a sequence of related ones?&lt;/li&gt;\n&lt;li&gt;What is the smallest piece of functionality that will form a &amp;quot;task&amp;quot; i.e. an individual unit in an orchestration pipeline.&lt;/li&gt;\n&lt;li&gt;Do you prefer functional or object-oriented approach?&lt;/li&gt;\n&lt;li&gt;How do you break up a sequence of common tasks such as, loading some data, transforming it, creating a target table and inserting if it doesn&amp;#39;t exist, or upserting if it does.&lt;/li&gt;\n&lt;li&gt;How do you handle &amp;amp; unit test functionality that is only available through the SQL API?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;For context I am currently working with pyspark in databricks. At the moment there&amp;#39;s one big mono repo, with a &amp;#39;task&amp;#39; base class that handles a lot of boilerplate functionality (e.g. spark session set up, reading config, logging). All other tasks inherit from this, there is typically a &amp;#39;task&amp;#39; for each table, that has extract, transform, load methods etc. Initially this is being orchestrated through databricks workflows but may be moved to airflow as it gets more complex. So far this approach is working OK but I am starting to run into some friction with various aspects&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zfw27e", "is_robot_indexable": true, "report_reasons": null, "author": "the-data-scientist", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zfw27e/how_do_you_structure_your_pyspark_etl_tasks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zfw27e/how_do_you_structure_your_pyspark_etl_tasks/", "subreddit_subscribers": 82256, "created_utc": 1670498123.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey\u2026 often people at the beginning of their journey have many questions and nobody to ask them. It was most certainly the case for me. I often felt overwhelmed and was looking for some guidance\u2026 fortunately at some point, I found someone to who I could talk.\n\nSo I wanted to make the following offer: I will try to answer the questions that you might have about the work life of a software engineer, skills, struggles,\u2026 and so on :-) \u2026but please don\u2019t post code or homework or things like that\u2026\n\nMaybe some short background about myself, so that you at least have some context about who you ask and what questions I might give you insight into.\n\n* Working in Software Development for about 15 years\n* mainly web backend development but occasionally also Fullstack\n* switched to data-related topics about 4 years ago\n* currently working as a senior data engineer\n* self-employed freelancer for about 7 years\n* bachelor\u2019s degree in business informatics\n* master\u2019s degree in data science\n\nI won\u2019t link my LinkedIn profile, since this is not about self-promotion.\n\nAlso to be completely open and honest\u2026 since most actions people do\u2026 even those which might help others\u2026 are selfish. And I do this because I have a youtube channel and try to understand better the struggles students and juniors go through\u2026 So that I can maybe also create some videos around those topics.", "author_fullname": "t2_ulqqm7pl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ask a senior software engineer anything\u2026", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zg2vwv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670514983.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey\u2026 often people at the beginning of their journey have many questions and nobody to ask them. It was most certainly the case for me. I often felt overwhelmed and was looking for some guidance\u2026 fortunately at some point, I found someone to who I could talk.&lt;/p&gt;\n\n&lt;p&gt;So I wanted to make the following offer: I will try to answer the questions that you might have about the work life of a software engineer, skills, struggles,\u2026 and so on :-) \u2026but please don\u2019t post code or homework or things like that\u2026&lt;/p&gt;\n\n&lt;p&gt;Maybe some short background about myself, so that you at least have some context about who you ask and what questions I might give you insight into.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Working in Software Development for about 15 years&lt;/li&gt;\n&lt;li&gt;mainly web backend development but occasionally also Fullstack&lt;/li&gt;\n&lt;li&gt;switched to data-related topics about 4 years ago&lt;/li&gt;\n&lt;li&gt;currently working as a senior data engineer&lt;/li&gt;\n&lt;li&gt;self-employed freelancer for about 7 years&lt;/li&gt;\n&lt;li&gt;bachelor\u2019s degree in business informatics&lt;/li&gt;\n&lt;li&gt;master\u2019s degree in data science&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I won\u2019t link my LinkedIn profile, since this is not about self-promotion.&lt;/p&gt;\n\n&lt;p&gt;Also to be completely open and honest\u2026 since most actions people do\u2026 even those which might help others\u2026 are selfish. And I do this because I have a youtube channel and try to understand better the struggles students and juniors go through\u2026 So that I can maybe also create some videos around those topics.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zg2vwv", "is_robot_indexable": true, "report_reasons": null, "author": "JohannesFrey", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zg2vwv/ask_a_senior_software_engineer_anything/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zg2vwv/ask_a_senior_software_engineer_anything/", "subreddit_subscribers": 82256, "created_utc": 1670514983.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have multiple years experience in Python and SQL. Right now I want to get into data engineering. After some research online, I saw a lot of people mentioned Azure. However, there are so many things in Azure and I am not sure where to start from. Can someone please guide me.", "author_fullname": "t2_imktgzwy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What should I start learning in Azure first", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zg5vyw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670521605.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have multiple years experience in Python and SQL. Right now I want to get into data engineering. After some research online, I saw a lot of people mentioned Azure. However, there are so many things in Azure and I am not sure where to start from. Can someone please guide me.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zg5vyw", "is_robot_indexable": true, "report_reasons": null, "author": "Acrobatic-Mobile-221", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zg5vyw/what_should_i_start_learning_in_azure_first/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zg5vyw/what_should_i_start_learning_in_azure_first/", "subreddit_subscribers": 82256, "created_utc": 1670521605.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So we are trying to figure out how to use DLT properly. \n\n* Are they supposed to be used for bronze, silver, gold transformations? My company doesn't want bronze and silver tables in the metastore, only to have the bronze and silver data stored in Delta format in the storage account... DLT seems to automatically create table in the metastore, but perhaps there's an option to disable it for a specific DLT table?\n* Are we supposed to develop DLT pipelines by first writing normal, interactive pyspark transformations, then afterwards adding all the DLT decorators everywhere? One way to do it seems to be create all the functions (one function per dataset) without DLT decorators in one notebook, then import this into another notebook where decorators are added (and DLT pipeline is run from this latter notebook)\n* Are we supposed to go into the DLT pipeline config to limit the job clusters that can be created? Use policies for this? I don't like that DLT supposedly manages everything, feel like I lose control. \n* Are we supposed to put bronze, silver gold transformations in DLT? We want lineage for all our data eventually, but right now it seems too much of a hassle when we can't develop it interactively. Is there another way to do this?\n* Are DLT pipelines supposed to replace normal workflows/jobs without DLT? Or are they intended for different purposes? \n\nAlso some general Databricks questions while I'm at it: \n\n* How do you all manage permissions? I've seen examples of running SQL notebooks with GRANT statements, but also using Terraform for the same thing. I guess the latter may be the approach of a bigger, more mature company? \n* We haven't started using Unity Catalog yet, but would using it make me NOT have to manage secrets for ADLS Gen2 storage? Currently I either have to run a cell in a notebook to configure spark with proper credentials, or set the config on launch of a cluster (also probably have to configure this for DLT pipelines but haven't gotten around to it yet) \n* Does dbt do pretty much exactly what DLT pipelines do? But perhaps in a smoother, more awesome interface? \n\nI'm quite junior still, so apologies for any dumb questions. \n\nThanks a lot for this super useful community.", "author_fullname": "t2_4ov075m4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I don't understand how Delta Live Table pipelines in Databricks are supposed to be used", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zfyhvy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670505053.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So we are trying to figure out how to use DLT properly. &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Are they supposed to be used for bronze, silver, gold transformations? My company doesn&amp;#39;t want bronze and silver tables in the metastore, only to have the bronze and silver data stored in Delta format in the storage account... DLT seems to automatically create table in the metastore, but perhaps there&amp;#39;s an option to disable it for a specific DLT table?&lt;/li&gt;\n&lt;li&gt;Are we supposed to develop DLT pipelines by first writing normal, interactive pyspark transformations, then afterwards adding all the DLT decorators everywhere? One way to do it seems to be create all the functions (one function per dataset) without DLT decorators in one notebook, then import this into another notebook where decorators are added (and DLT pipeline is run from this latter notebook)&lt;/li&gt;\n&lt;li&gt;Are we supposed to go into the DLT pipeline config to limit the job clusters that can be created? Use policies for this? I don&amp;#39;t like that DLT supposedly manages everything, feel like I lose control. &lt;/li&gt;\n&lt;li&gt;Are we supposed to put bronze, silver gold transformations in DLT? We want lineage for all our data eventually, but right now it seems too much of a hassle when we can&amp;#39;t develop it interactively. Is there another way to do this?&lt;/li&gt;\n&lt;li&gt;Are DLT pipelines supposed to replace normal workflows/jobs without DLT? Or are they intended for different purposes? &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Also some general Databricks questions while I&amp;#39;m at it: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;How do you all manage permissions? I&amp;#39;ve seen examples of running SQL notebooks with GRANT statements, but also using Terraform for the same thing. I guess the latter may be the approach of a bigger, more mature company? &lt;/li&gt;\n&lt;li&gt;We haven&amp;#39;t started using Unity Catalog yet, but would using it make me NOT have to manage secrets for ADLS Gen2 storage? Currently I either have to run a cell in a notebook to configure spark with proper credentials, or set the config on launch of a cluster (also probably have to configure this for DLT pipelines but haven&amp;#39;t gotten around to it yet) &lt;/li&gt;\n&lt;li&gt;Does dbt do pretty much exactly what DLT pipelines do? But perhaps in a smoother, more awesome interface? &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m quite junior still, so apologies for any dumb questions. &lt;/p&gt;\n\n&lt;p&gt;Thanks a lot for this super useful community.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zfyhvy", "is_robot_indexable": true, "report_reasons": null, "author": "HealthyDoggos4Life", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zfyhvy/i_dont_understand_how_delta_live_table_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zfyhvy/i_dont_understand_how_delta_live_table_pipelines/", "subreddit_subscribers": 82256, "created_utc": 1670505053.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there folks!\n\nI'm looking for open source tools to visualize column/field level lineage. I'm interested in the visualization piece only. The tools/solutions I've found determine column level lineage from SQL queries, and they bundle visualization with lineage. What I'm doing is determining column level lineage without access to underlying code - blackbox lineage, so I have a custom implementation that I'm developing. I would like the output of my process to feed a visualization-only tool. Ideally, I'd be able to select columns from tables, and be shown links to other columns from which the selected column was derived.\n\nIs anyone aware of such a tool? \n\nThanks!", "author_fullname": "t2_u4cfmc2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Visualizing column-level lineage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zg2fgj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670513986.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there folks!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for open source tools to visualize column/field level lineage. I&amp;#39;m interested in the visualization piece only. The tools/solutions I&amp;#39;ve found determine column level lineage from SQL queries, and they bundle visualization with lineage. What I&amp;#39;m doing is determining column level lineage without access to underlying code - blackbox lineage, so I have a custom implementation that I&amp;#39;m developing. I would like the output of my process to feed a visualization-only tool. Ideally, I&amp;#39;d be able to select columns from tables, and be shown links to other columns from which the selected column was derived.&lt;/p&gt;\n\n&lt;p&gt;Is anyone aware of such a tool? &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zg2fgj", "is_robot_indexable": true, "report_reasons": null, "author": "nuges01", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zg2fgj/visualizing_columnlevel_lineage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zg2fgj/visualizing_columnlevel_lineage/", "subreddit_subscribers": 82256, "created_utc": 1670513986.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Everyone, we are using SSIS as our primary ETL tool, it's been great so far but I believe it's time to say goodbye to our old friend SSIS  (atleast for a few important pipelines )\n\nOne of the major pipeline has this functionality (Entirely metadata driven)\n\n* Fetch incremental data for a 1000 tables from point A using linked servers (Batch processing)\n* Stage the acquired data in point B\n* Do upsert and deletion of corresponding point B tables using staged tables/data \n* Trigger datamarts and a bunch of other processes \n* Refresh/update reports using data from datamarts/processes from last step\n\nIt's been running fine until now but now due to the following reasons, we would like to move away from SSIS\n\n1. Our data is constantly growing i.e. for a few tables, incremental records may go up to 5-10 million per day  \n2. DS/Analytics team keep asking for ingestion of new tables meaning more and more data that needs to be processes daily\n3. Some of the processes have complex pre-requisite conditions, they can be implemented in SSIS but I believe a coded solution/pipeline would give us much more control than SSIS\n4. Our important pipelines use linked servers, lately they have been pain in the ass and we would like to ditch them that would require an entire overhaul in any case\n5. Debugging can get tricky sometimes\n6. A lot of simple things usually require way arounds in SSIS\n\nPlus a few other reservations, now we'd like to slowly move away from SSIS and opt some other solution, would really appreciate any feedback to what should we switch over to? Would prefer to code the pipelines instead of low-code/no-code solutions.", "author_fullname": "t2_2xpdiv8k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help required in moving away from SSIS to another solution", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zfzfdg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670507286.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Everyone, we are using SSIS as our primary ETL tool, it&amp;#39;s been great so far but I believe it&amp;#39;s time to say goodbye to our old friend SSIS  (atleast for a few important pipelines )&lt;/p&gt;\n\n&lt;p&gt;One of the major pipeline has this functionality (Entirely metadata driven)&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Fetch incremental data for a 1000 tables from point A using linked servers (Batch processing)&lt;/li&gt;\n&lt;li&gt;Stage the acquired data in point B&lt;/li&gt;\n&lt;li&gt;Do upsert and deletion of corresponding point B tables using staged tables/data &lt;/li&gt;\n&lt;li&gt;Trigger datamarts and a bunch of other processes &lt;/li&gt;\n&lt;li&gt;Refresh/update reports using data from datamarts/processes from last step&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;It&amp;#39;s been running fine until now but now due to the following reasons, we would like to move away from SSIS&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Our data is constantly growing i.e. for a few tables, incremental records may go up to 5-10 million per day&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;DS/Analytics team keep asking for ingestion of new tables meaning more and more data that needs to be processes daily&lt;/li&gt;\n&lt;li&gt;Some of the processes have complex pre-requisite conditions, they can be implemented in SSIS but I believe a coded solution/pipeline would give us much more control than SSIS&lt;/li&gt;\n&lt;li&gt;Our important pipelines use linked servers, lately they have been pain in the ass and we would like to ditch them that would require an entire overhaul in any case&lt;/li&gt;\n&lt;li&gt;Debugging can get tricky sometimes&lt;/li&gt;\n&lt;li&gt;A lot of simple things usually require way arounds in SSIS&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Plus a few other reservations, now we&amp;#39;d like to slowly move away from SSIS and opt some other solution, would really appreciate any feedback to what should we switch over to? Would prefer to code the pipelines instead of low-code/no-code solutions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zfzfdg", "is_robot_indexable": true, "report_reasons": null, "author": "_whitezetsu", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zfzfdg/help_required_in_moving_away_from_ssis_to_another/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zfzfdg/help_required_in_moving_away_from_ssis_to_another/", "subreddit_subscribers": 82256, "created_utc": 1670507286.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I am curious about what people think is the better route for me at this point.  I get contacted by a lot of recruiters with contract (6+ month) positions but I always shy away from these and tell them I only want full-time, direct-hire roles.  \n\n\nI think I just don't want to deal with extra paperwork (taxes), get my own medical, and have any downtime in between where I have no income.\n\nI like contracting, right now I work for a consulting firm but am a full-time employee, for the exposure to different technologies.  I have 20 years of experience with data engineering type work and 2 years with more modern cloud tech (spark, python, snowflake).\n\n&amp;#x200B;\n\nCurious if people have better experiences and make more money in the contracting roles and have other reasons why contracting would be preferred?  What's your take on direct hire vs contract roles?  \n\n\nThanks", "author_fullname": "t2_32fqu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Full-Time Direct Hire vs Contract Positions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zg76jp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670524434.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am curious about what people think is the better route for me at this point.  I get contacted by a lot of recruiters with contract (6+ month) positions but I always shy away from these and tell them I only want full-time, direct-hire roles.  &lt;/p&gt;\n\n&lt;p&gt;I think I just don&amp;#39;t want to deal with extra paperwork (taxes), get my own medical, and have any downtime in between where I have no income.&lt;/p&gt;\n\n&lt;p&gt;I like contracting, right now I work for a consulting firm but am a full-time employee, for the exposure to different technologies.  I have 20 years of experience with data engineering type work and 2 years with more modern cloud tech (spark, python, snowflake).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Curious if people have better experiences and make more money in the contracting roles and have other reasons why contracting would be preferred?  What&amp;#39;s your take on direct hire vs contract roles?  &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zg76jp", "is_robot_indexable": true, "report_reasons": null, "author": "chiefster", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zg76jp/fulltime_direct_hire_vs_contract_positions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zg76jp/fulltime_direct_hire_vs_contract_positions/", "subreddit_subscribers": 82256, "created_utc": 1670524434.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Wondering if people model raw data slightly before computing batch views for the serving layer\u2026\n\nMostly thinking if you load a bunch of raw data from sources without doing anything, is there a modeling paradigm to make computing batch views easier than just working on raw data?\n\nJust recently heard about outbox tables and bronze/silver/gold tiers in data lakes as possibilities, but still doesn\u2019t answer the question of how these tables should be modeled", "author_fullname": "t2_7jt0qboi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data modeling before transformation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zg4zu5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1670527805.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670519530.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wondering if people model raw data slightly before computing batch views for the serving layer\u2026&lt;/p&gt;\n\n&lt;p&gt;Mostly thinking if you load a bunch of raw data from sources without doing anything, is there a modeling paradigm to make computing batch views easier than just working on raw data?&lt;/p&gt;\n\n&lt;p&gt;Just recently heard about outbox tables and bronze/silver/gold tiers in data lakes as possibilities, but still doesn\u2019t answer the question of how these tables should be modeled&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zg4zu5", "is_robot_indexable": true, "report_reasons": null, "author": "omscsdatathrow", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zg4zu5/data_modeling_before_transformation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zg4zu5/data_modeling_before_transformation/", "subreddit_subscribers": 82256, "created_utc": 1670519530.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nThe following is a question about salary in France as a junior data engineer.\nIt\u2019s written in French for simplicity as it is targeted towards French speakers :\n\nSalut \u00e0 tous,\n\nJe suis \u00e9tudiant en 5eme ann\u00e9e d\u2019\u00e9cole d\u2019ing\u00e9nieur en informatique et j\u2019ai un stage dans une grosse ESN fran\u00e7aise (qui me proposera probablement un CDI par la suite) en tant que data engineer.\n\n\u00c9tant contact\u00e9 par pas mal d\u2019entreprises sur LinkedIn par rapport \u00e0 un CDI suite au stage, je me pose la question du salaire et de la n\u00e9gociation. \n\nSi je me trompe de subreddit, n\u2019h\u00e9sitez pas \u00e0 me le dire et \u00e9ventuellement me rediriger !\n\nCe qui est difficile pour moi, c\u2019est de savoir \u00e0 quel salaire je peux pr\u00e9tendre pour un premier emploi dans la data, sp\u00e9cifiquement en tant que data engineer (ing\u00e9nieur de donn\u00e9es).\n\nInformations sur ma situation : \n\n-stage development web (2,5 mois)\n\n-stage recherche op\u00e9rationnelle (2 mois)\n\n-stage data engineer (6 mois en 2023)\n\n-\u00e9cole plut\u00f4t bas du classement car r\u00e9orientation en informatique, mais dans les meilleurs (voir major selon le semestre) de promo\n\nSachant que je cherche hors r\u00e9gion parisienne, avez-vous des id\u00e9es du salaire auquel je peux pr\u00e9tendre ou des conseils pour la n\u00e9gociation ?\n\nQuand je cherche sur internet (Glassdoor, par exemple) je trouve des estimations de moyennes autour de 40k-41k/an, voire 45k, pour 0 \u00e0 1 an d\u2019exp\u00e9rience. Toutefois, je doute de la fiabilit\u00e9 de ce que je trouve sachant que j\u2019entends pas mal d\u2019offres pour d\u2019autres \u00e9tudiants en informatique de 32-35k pour un premier CDI. \n\n41k me para\u00eet un peut-\u00eatre haut pour un salaire hors r\u00e9gion parisienne mais 32-35k me para\u00eet quand m\u00eame bas pour un m\u00e9tier qui est cens\u00e9 \u00eatre parmi les plus r\u00e9mun\u00e9r\u00e9s dans la tech en France.\n\nEn tout cas, j\u2019appr\u00e9cie toute aide, notamment si vous \u00eates dans le milieu de la data.", "author_fullname": "t2_9a5zvrr4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Salary in France", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zg3711", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1670526408.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670515629.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;The following is a question about salary in France as a junior data engineer.\nIt\u2019s written in French for simplicity as it is targeted towards French speakers :&lt;/p&gt;\n\n&lt;p&gt;Salut \u00e0 tous,&lt;/p&gt;\n\n&lt;p&gt;Je suis \u00e9tudiant en 5eme ann\u00e9e d\u2019\u00e9cole d\u2019ing\u00e9nieur en informatique et j\u2019ai un stage dans une grosse ESN fran\u00e7aise (qui me proposera probablement un CDI par la suite) en tant que data engineer.&lt;/p&gt;\n\n&lt;p&gt;\u00c9tant contact\u00e9 par pas mal d\u2019entreprises sur LinkedIn par rapport \u00e0 un CDI suite au stage, je me pose la question du salaire et de la n\u00e9gociation. &lt;/p&gt;\n\n&lt;p&gt;Si je me trompe de subreddit, n\u2019h\u00e9sitez pas \u00e0 me le dire et \u00e9ventuellement me rediriger !&lt;/p&gt;\n\n&lt;p&gt;Ce qui est difficile pour moi, c\u2019est de savoir \u00e0 quel salaire je peux pr\u00e9tendre pour un premier emploi dans la data, sp\u00e9cifiquement en tant que data engineer (ing\u00e9nieur de donn\u00e9es).&lt;/p&gt;\n\n&lt;p&gt;Informations sur ma situation : &lt;/p&gt;\n\n&lt;p&gt;-stage development web (2,5 mois)&lt;/p&gt;\n\n&lt;p&gt;-stage recherche op\u00e9rationnelle (2 mois)&lt;/p&gt;\n\n&lt;p&gt;-stage data engineer (6 mois en 2023)&lt;/p&gt;\n\n&lt;p&gt;-\u00e9cole plut\u00f4t bas du classement car r\u00e9orientation en informatique, mais dans les meilleurs (voir major selon le semestre) de promo&lt;/p&gt;\n\n&lt;p&gt;Sachant que je cherche hors r\u00e9gion parisienne, avez-vous des id\u00e9es du salaire auquel je peux pr\u00e9tendre ou des conseils pour la n\u00e9gociation ?&lt;/p&gt;\n\n&lt;p&gt;Quand je cherche sur internet (Glassdoor, par exemple) je trouve des estimations de moyennes autour de 40k-41k/an, voire 45k, pour 0 \u00e0 1 an d\u2019exp\u00e9rience. Toutefois, je doute de la fiabilit\u00e9 de ce que je trouve sachant que j\u2019entends pas mal d\u2019offres pour d\u2019autres \u00e9tudiants en informatique de 32-35k pour un premier CDI. &lt;/p&gt;\n\n&lt;p&gt;41k me para\u00eet un peut-\u00eatre haut pour un salaire hors r\u00e9gion parisienne mais 32-35k me para\u00eet quand m\u00eame bas pour un m\u00e9tier qui est cens\u00e9 \u00eatre parmi les plus r\u00e9mun\u00e9r\u00e9s dans la tech en France.&lt;/p&gt;\n\n&lt;p&gt;En tout cas, j\u2019appr\u00e9cie toute aide, notamment si vous \u00eates dans le milieu de la data.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zg3711", "is_robot_indexable": true, "report_reasons": null, "author": "No_Storm_1500", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zg3711/salary_in_france/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zg3711/salary_in_france/", "subreddit_subscribers": 82256, "created_utc": 1670515629.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi data folks, \n\nSo I want to develop a product Recommendation feature for my ecommerce site. We have our table which has successfull cart orders by customers. Table looks like ( cart_id , product_id , category_id , product_name). Now I want to develop a product Recommendation model using this data. What are various product Recommendation models (similar to Amazon)(production usecase) that I can explore and study ? Can someone send me production examples with sample code that I can start a POC with ?", "author_fullname": "t2_57e44nxs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Product Recommendation Algorithm", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zfyhiz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670505029.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi data folks, &lt;/p&gt;\n\n&lt;p&gt;So I want to develop a product Recommendation feature for my ecommerce site. We have our table which has successfull cart orders by customers. Table looks like ( cart_id , product_id , category_id , product_name). Now I want to develop a product Recommendation model using this data. What are various product Recommendation models (similar to Amazon)(production usecase) that I can explore and study ? Can someone send me production examples with sample code that I can start a POC with ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zfyhiz", "is_robot_indexable": true, "report_reasons": null, "author": "RstarPhoneix", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zfyhiz/product_recommendation_algorithm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zfyhiz/product_recommendation_algorithm/", "subreddit_subscribers": 82256, "created_utc": 1670505029.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_7oampu1h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Spark : AQE(Adaptive Query Execution)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 26, "top_awarded_type": null, "hide_score": false, "name": "t3_zfm865", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": "transparent", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/a40Mh9vOWUM13IBQuinnv_nuU0LZrzBSf4paP2Ik5fI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670466648.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/dev-genius/apache-spark-aqe-adaptive-query-execution-d754afff96ba", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/AoGoEqXHw7jm3EeJxzWJFG9W0jpvN_QiG6Of6dKXNWc.jpg?auto=webp&amp;s=0cb6a645711a105ed32f6d3796f26854ba259079", "width": 1200, "height": 230}, "resolutions": [{"url": "https://external-preview.redd.it/AoGoEqXHw7jm3EeJxzWJFG9W0jpvN_QiG6Of6dKXNWc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=63944bb9d8ebc42bd1a79e232e91e2f0f9d08327", "width": 108, "height": 20}, {"url": "https://external-preview.redd.it/AoGoEqXHw7jm3EeJxzWJFG9W0jpvN_QiG6Of6dKXNWc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8bc747e170f969012b83d0b7b032f9df32cf9d67", "width": 216, "height": 41}, {"url": "https://external-preview.redd.it/AoGoEqXHw7jm3EeJxzWJFG9W0jpvN_QiG6Of6dKXNWc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=882247aa5cf78be8d19d8f084f24ece451b1d34d", "width": 320, "height": 61}, {"url": "https://external-preview.redd.it/AoGoEqXHw7jm3EeJxzWJFG9W0jpvN_QiG6Of6dKXNWc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f4a0854949282ead231746d0acf7f83a3ee40db9", "width": 640, "height": 122}, {"url": "https://external-preview.redd.it/AoGoEqXHw7jm3EeJxzWJFG9W0jpvN_QiG6Of6dKXNWc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c017b99d919c40c50323cf7cb57976d369216e94", "width": 960, "height": 184}, {"url": "https://external-preview.redd.it/AoGoEqXHw7jm3EeJxzWJFG9W0jpvN_QiG6Of6dKXNWc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f7ac802570a652a9e866ded1d27b7e97b6f00e98", "width": 1080, "height": 207}], "variants": {}, "id": "igLSvvyzQBR9S3Uw2pSj1GHVUQDibSWwIk7zuYdDcQc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zfm865", "is_robot_indexable": true, "report_reasons": null, "author": "Sidharth_r", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/zfm865/apache_spark_aqeadaptive_query_execution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/dev-genius/apache-spark-aqe-adaptive-query-execution-d754afff96ba", "subreddit_subscribers": 82256, "created_utc": 1670466648.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "is it a shoutout to dremio? looks a lot like that", "author_fullname": "t2_1bnm3ugs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "reddit recap narwhal", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zg5f79", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670520535.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;is it a shoutout to dremio? looks a lot like that&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "zg5f79", "is_robot_indexable": true, "report_reasons": null, "author": "A27_97", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zg5f79/reddit_recap_narwhal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zg5f79/reddit_recap_narwhal/", "subreddit_subscribers": 82256, "created_utc": 1670520535.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "After a lot of hard work in developing the \"security in runtime\" feature, we're ready for you to try it and tell us your thoughts.\n\n(Our OTel instrumentation identifies modules with vulnerabilities in your code including its dependencies in runtime),\n\nWe'd love for you to try the security feature and tell us your thoughts:) [sprkl.dev](https://sprkl.dev)", "author_fullname": "t2_hissmiq8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Security in runtime: Getting reached vulnerabilities leveraging distributed tracing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zg1lqx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1670512186.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After a lot of hard work in developing the &amp;quot;security in runtime&amp;quot; feature, we&amp;#39;re ready for you to try it and tell us your thoughts.&lt;/p&gt;\n\n&lt;p&gt;(Our OTel instrumentation identifies modules with vulnerabilities in your code including its dependencies in runtime),&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;d love for you to try the security feature and tell us your thoughts:) &lt;a href=\"https://sprkl.dev\"&gt;sprkl.dev&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/na0QakHGPYr7wGgR8kcWq_QMraWiC63_AXJZawfqR5s.jpg?auto=webp&amp;s=b84bb8860ba325d0d852055684965c6f8a0be0da", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/na0QakHGPYr7wGgR8kcWq_QMraWiC63_AXJZawfqR5s.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cd07c567eb40445c7b0dae7c32ac07bf2d687714", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/na0QakHGPYr7wGgR8kcWq_QMraWiC63_AXJZawfqR5s.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=182cd7a04da01fbb2330899563d80e79a7ce287f", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/na0QakHGPYr7wGgR8kcWq_QMraWiC63_AXJZawfqR5s.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f4926ffdd9f31d62bc7e43c02ff1dd825780eb87", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/na0QakHGPYr7wGgR8kcWq_QMraWiC63_AXJZawfqR5s.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ac8b3338519dfaf6d2689f64f5eddcc6e51f71f2", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/na0QakHGPYr7wGgR8kcWq_QMraWiC63_AXJZawfqR5s.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f9fd9809ad0183ea78eddcacb4c6f7764bf389f5", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/na0QakHGPYr7wGgR8kcWq_QMraWiC63_AXJZawfqR5s.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=60d59d289a2c4c345bf05ac448b26b0c0fe4bf8a", "width": 1080, "height": 567}], "variants": {}, "id": "JoWS26qq9r4QM5zkrrMH3d-Tmv56zgruB220rWYnO5g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zg1lqx", "is_robot_indexable": true, "report_reasons": null, "author": "Nice_Score_7552", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zg1lqx/security_in_runtime_getting_reached/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zg1lqx/security_in_runtime_getting_reached/", "subreddit_subscribers": 82256, "created_utc": 1670512186.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://youtu.be/sPTERXmYnBs](https://youtu.be/sPTERXmYnBs)", "author_fullname": "t2_b7f9ay9o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to do Data wrangling in Azure Data Factory", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zfd4of", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1670445753.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://youtu.be/sPTERXmYnBs\"&gt;https://youtu.be/sPTERXmYnBs&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6G0ZdkahjmkBRiO5UFYbd1b5nO3RJBhFmdRXiEkgR9A.jpg?auto=webp&amp;s=f26649082272ab50421638418f24f8cc086c180c", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/6G0ZdkahjmkBRiO5UFYbd1b5nO3RJBhFmdRXiEkgR9A.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3a0c989a442df24ea60a519a3b01e460956bf2be", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/6G0ZdkahjmkBRiO5UFYbd1b5nO3RJBhFmdRXiEkgR9A.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2d0178c615faf40c321c5ea2575a11e6c266c03d", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/6G0ZdkahjmkBRiO5UFYbd1b5nO3RJBhFmdRXiEkgR9A.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a58e83f373da2d94a61cc425a9f2133941e318ea", "width": 320, "height": 240}], "variants": {}, "id": "fnGaLGugM-dKpwoivw1QbauQqVOD106EB8CftcXd8_U"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zfd4of", "is_robot_indexable": true, "report_reasons": null, "author": "balramprasad", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zfd4of/how_to_do_data_wrangling_in_azure_data_factory/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zfd4of/how_to_do_data_wrangling_in_azure_data_factory/", "subreddit_subscribers": 82256, "created_utc": 1670445753.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}