{"kind": "Listing", "data": {"after": null, "dist": 15, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I got a job as a data engineer. I am comfortable in SQL and python. But, no aws exposure. My upcoming team lead emphasised on learning cloud services. From where do I start? and what is the scope?", "author_fullname": "t2_7amqb26y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zy8lrb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 78, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 78, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672329166.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I got a job as a data engineer. I am comfortable in SQL and python. But, no aws exposure. My upcoming team lead emphasised on learning cloud services. From where do I start? and what is the scope?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zy8lrb", "is_robot_indexable": true, "report_reasons": null, "author": "Tousif_11", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zy8lrb/aws/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zy8lrb/aws/", "subreddit_subscribers": 84628, "created_utc": 1672329166.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi I am a \u201cbackend engineer\u201d but truthfully I am more akin to a data engineer. My dumpster fire of a job has made me a de facto SQL, ETL, and SSIS/SSRS expert. Given that all my current experience in my current job is related to data engineering, I wanna make a shift to data engineering but I have no idea what to expect from these kind of job interviews\n\nAny advice or tips would be appreciated. My educational background is Computer Science software development so I am curious how similar data engineering job interviews are to software engineering job interviews", "author_fullname": "t2_bcn25", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do data engineering interviews work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zy7q2n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 58, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 58, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672326873.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi I am a \u201cbackend engineer\u201d but truthfully I am more akin to a data engineer. My dumpster fire of a job has made me a de facto SQL, ETL, and SSIS/SSRS expert. Given that all my current experience in my current job is related to data engineering, I wanna make a shift to data engineering but I have no idea what to expect from these kind of job interviews&lt;/p&gt;\n\n&lt;p&gt;Any advice or tips would be appreciated. My educational background is Computer Science software development so I am curious how similar data engineering job interviews are to software engineering job interviews&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zy7q2n", "is_robot_indexable": true, "report_reasons": null, "author": "Dats_Russia", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zy7q2n/how_do_data_engineering_interviews_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zy7q2n/how_do_data_engineering_interviews_work/", "subreddit_subscribers": 84628, "created_utc": 1672326873.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Please suggest any grammatical mistake, if I constructed sentences poorly. Thank you for all the help!", "author_fullname": "t2_1dlki6j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Part 2 - Requesting experienced folks to suggest edits to my resume.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_zyirsj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": "transparent", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/yKgvrn0XC141dyrPN_XqSzQ8hpKnmz7lcvAW5GnHZlA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1672353324.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Please suggest any grammatical mistake, if I constructed sentences poorly. Thank you for all the help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/gyro15m1hy8a1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/gyro15m1hy8a1.jpg?auto=webp&amp;s=cbdcb8d7c13994a1143701813b1946fe5ac645cc", "width": 1125, "height": 1427}, "resolutions": [{"url": "https://preview.redd.it/gyro15m1hy8a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1f93fcc1f7346829161f48597e28f9295525db41", "width": 108, "height": 136}, {"url": "https://preview.redd.it/gyro15m1hy8a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=843d4ecdd6875362ea121711c7cfbccd302ca4fe", "width": 216, "height": 273}, {"url": "https://preview.redd.it/gyro15m1hy8a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6a0c2679d6c54acc563d4efe266272485a26a71c", "width": 320, "height": 405}, {"url": "https://preview.redd.it/gyro15m1hy8a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=65a9607fa16e428c44160f471d56c5c5f1eabe0d", "width": 640, "height": 811}, {"url": "https://preview.redd.it/gyro15m1hy8a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=25ca34f915ede02ab516a64b2411213e5038849e", "width": 960, "height": 1217}, {"url": "https://preview.redd.it/gyro15m1hy8a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cb78f270de3518b987fc4edfbcb81f46044ed91e", "width": 1080, "height": 1369}], "variants": {}, "id": "pszzA85DHIpMQ3HCdGSE8Ot3rVrAvNDg8qfjWYPdZ64"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "zyirsj", "is_robot_indexable": true, "report_reasons": null, "author": "musicplay313", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/zyirsj/part_2_requesting_experienced_folks_to_suggest/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/gyro15m1hy8a1.jpg", "subreddit_subscribers": 84628, "created_utc": 1672353324.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm really having a hard time understanding what delta live tables are. Whats their purpose?. I would appreciate if anyone could explain me in simple words. Thanks.", "author_fullname": "t2_e8k9c3l7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is DLT?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zytlbf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672382893.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m really having a hard time understanding what delta live tables are. Whats their purpose?. I would appreciate if anyone could explain me in simple words. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zytlbf", "is_robot_indexable": true, "report_reasons": null, "author": "SignalCrew739", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zytlbf/what_is_dlt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zytlbf/what_is_dlt/", "subreddit_subscribers": 84628, "created_utc": 1672382893.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi.\n\nWhat would you recommend to setup on prem for a team of data analysts to use Spark?\n\nIdeally, it should be something like databricks, but on prem, that connects to HDFS or S3, running on kubernetes, having user based access control over notebooks and resource quotas.\n\nIs it possible to correctly use Zeppelin/Jupyter for that purposes?", "author_fullname": "t2_dwipmn93", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Multiuser Spark analytics environment setup on prem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zybaz6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672335836.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi.&lt;/p&gt;\n\n&lt;p&gt;What would you recommend to setup on prem for a team of data analysts to use Spark?&lt;/p&gt;\n\n&lt;p&gt;Ideally, it should be something like databricks, but on prem, that connects to HDFS or S3, running on kubernetes, having user based access control over notebooks and resource quotas.&lt;/p&gt;\n\n&lt;p&gt;Is it possible to correctly use Zeppelin/Jupyter for that purposes?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zybaz6", "is_robot_indexable": true, "report_reasons": null, "author": "knkydud", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zybaz6/multiuser_spark_analytics_environment_setup_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zybaz6/multiuser_spark_analytics_environment_setup_on/", "subreddit_subscribers": 84628, "created_utc": 1672335836.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We've recently run into the issue of hitting Redshift's [table limit](https://docs.aws.amazon.com/redshift/latest/mgmt/amazon-redshift-limits.html) (20k for xplus clusters). That may sound like an absurd amount of tables, but it's because we split tenants by schema. There are plans to change this down the line, but it ain't happening anytime soon.\n\nThe production DB is Postgres and we use Fivetran to get the data from a read replica into Redshift. In Redshift, we do some transformations via dbt to consolidate the schemas into one.\n\nI'm thinking about moving the consolidation logic more upstream (i.e. in the Postgres read replica), but it's not an easy lift.\n\nHas anyone else had to deal with this issue? What's a good work-around that doesn't involve beefing up the cluster? (100k tables looks to be the absolute max and even that isn't sustainable.)", "author_fullname": "t2_56bczqdd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Redshift table limit", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zy6tvv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672324475.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;ve recently run into the issue of hitting Redshift&amp;#39;s &lt;a href=\"https://docs.aws.amazon.com/redshift/latest/mgmt/amazon-redshift-limits.html\"&gt;table limit&lt;/a&gt; (20k for xplus clusters). That may sound like an absurd amount of tables, but it&amp;#39;s because we split tenants by schema. There are plans to change this down the line, but it ain&amp;#39;t happening anytime soon.&lt;/p&gt;\n\n&lt;p&gt;The production DB is Postgres and we use Fivetran to get the data from a read replica into Redshift. In Redshift, we do some transformations via dbt to consolidate the schemas into one.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking about moving the consolidation logic more upstream (i.e. in the Postgres read replica), but it&amp;#39;s not an easy lift.&lt;/p&gt;\n\n&lt;p&gt;Has anyone else had to deal with this issue? What&amp;#39;s a good work-around that doesn&amp;#39;t involve beefing up the cluster? (100k tables looks to be the absolute max and even that isn&amp;#39;t sustainable.)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zy6tvv", "is_robot_indexable": true, "report_reasons": null, "author": "script_sibi", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zy6tvv/redshift_table_limit/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zy6tvv/redshift_table_limit/", "subreddit_subscribers": 84628, "created_utc": 1672324475.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_10v76s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data catalogs are the most expensive data integration systems you never intended to build. Data Catalog as a passive web portal to display metadata requires significant rethinking to adopt modern data workflow, not just adding \u201cmodern\u201d in its prefix.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zyol6t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1672367851.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dataengineeringweekly.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.dataengineeringweekly.com/p/data-cata", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zyol6t", "is_robot_indexable": true, "report_reasons": null, "author": "vananth22", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zyol6t/data_catalogs_are_the_most_expensive_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.dataengineeringweekly.com/p/data-cata", "subreddit_subscribers": 84628, "created_utc": 1672367851.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone, I\u2019m looking into data transformation solutions and am leaning towards using dbt (cli) combined with dbt python models (my company uses snowflake). My understanding is that under the hood dbt will compile a python model into a snowflake stored procedure. I was wondering if this setup supports non-public libraries such as modules published in a AWS code artifact, plus if it supports connecting to a third party service (e.g. google maps api).", "author_fullname": "t2_172kp8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dbt and python modules", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zygdm7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672347801.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I\u2019m looking into data transformation solutions and am leaning towards using dbt (cli) combined with dbt python models (my company uses snowflake). My understanding is that under the hood dbt will compile a python model into a snowflake stored procedure. I was wondering if this setup supports non-public libraries such as modules published in a AWS code artifact, plus if it supports connecting to a third party service (e.g. google maps api).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zygdm7", "is_robot_indexable": true, "report_reasons": null, "author": "princess-rainbows666", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zygdm7/dbt_and_python_modules/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zygdm7/dbt_and_python_modules/", "subreddit_subscribers": 84628, "created_utc": 1672347801.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks\n\nRecently, I've started trying to write some technical articles on Medium to help share my knowledge but also refine some of the things I already know by \"teaching\" them to others.\n\nI've been following this subreddit for a long time now, and there's some great opinions thrown around. I thought I'd do a shameless plug to see whether I could get some feedback from peers who are in the field.\n\nThe articles are focused specifically at Python for Data Engineering with a heavy bias towards GCP (I'm a GCP engineer).\n\nThe target audience are people with a working knowledge of Python already, but who may be wanting to understand how some concepts apply in the real-world as opposed to theoretical, or simply helping people move from writing scripts that work, to code that can be used in production.\n\nIt would be great to hear if you think there's any topics I haven't covered which would be useful, or how the writing style is (Too complex? Too much content/get bored? Hard to follow etc.).\n\nThe link to the main article is here which can link you through to the rest.\n\nLooking forward to hearing some opinions :)\n\nThanks\n\n[https://medium.com/@danilo.drobac/real-world-python-for-data-engineering-a-series-77ed689859a0](https://medium.com/@danilo.drobac/real-world-python-for-data-engineering-a-series-77ed689859a0)", "author_fullname": "t2_x0jju", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I've started getting into technical blog writing on Medium (feedback please)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zyvq3w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1672390392.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks&lt;/p&gt;\n\n&lt;p&gt;Recently, I&amp;#39;ve started trying to write some technical articles on Medium to help share my knowledge but also refine some of the things I already know by &amp;quot;teaching&amp;quot; them to others.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been following this subreddit for a long time now, and there&amp;#39;s some great opinions thrown around. I thought I&amp;#39;d do a shameless plug to see whether I could get some feedback from peers who are in the field.&lt;/p&gt;\n\n&lt;p&gt;The articles are focused specifically at Python for Data Engineering with a heavy bias towards GCP (I&amp;#39;m a GCP engineer).&lt;/p&gt;\n\n&lt;p&gt;The target audience are people with a working knowledge of Python already, but who may be wanting to understand how some concepts apply in the real-world as opposed to theoretical, or simply helping people move from writing scripts that work, to code that can be used in production.&lt;/p&gt;\n\n&lt;p&gt;It would be great to hear if you think there&amp;#39;s any topics I haven&amp;#39;t covered which would be useful, or how the writing style is (Too complex? Too much content/get bored? Hard to follow etc.).&lt;/p&gt;\n\n&lt;p&gt;The link to the main article is here which can link you through to the rest.&lt;/p&gt;\n\n&lt;p&gt;Looking forward to hearing some opinions :)&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@danilo.drobac/real-world-python-for-data-engineering-a-series-77ed689859a0\"&gt;https://medium.com/@danilo.drobac/real-world-python-for-data-engineering-a-series-77ed689859a0&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/f9G0vpIDzPYg7hxwMTU4gcL_VvI-VrCsmzN3uRIzSJ4.jpg?auto=webp&amp;s=c2738a6087017848b89136ad55b892ae3c673644", "width": 1200, "height": 676}, "resolutions": [{"url": "https://external-preview.redd.it/f9G0vpIDzPYg7hxwMTU4gcL_VvI-VrCsmzN3uRIzSJ4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ba9deec2f9936c245d03e10900a50615aac13cf2", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/f9G0vpIDzPYg7hxwMTU4gcL_VvI-VrCsmzN3uRIzSJ4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a0567d93e1a8fe185bafe1155510ca465d0c628e", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/f9G0vpIDzPYg7hxwMTU4gcL_VvI-VrCsmzN3uRIzSJ4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=24ae38352f67eabe28dee8031eeeb208b77f2b19", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/f9G0vpIDzPYg7hxwMTU4gcL_VvI-VrCsmzN3uRIzSJ4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=85b69cf27171aa383b5b4957b033b32b8188f78c", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/f9G0vpIDzPYg7hxwMTU4gcL_VvI-VrCsmzN3uRIzSJ4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5aa429f07417ada382c3f5487a7aa484d9d12ff6", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/f9G0vpIDzPYg7hxwMTU4gcL_VvI-VrCsmzN3uRIzSJ4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=06816cfac1fc0a22c71b898fc0f2665f8cbae109", "width": 1080, "height": 608}], "variants": {}, "id": "FpPz9mDcG4PWEmUxGuR3FY7owHw22EMD3iv2uQnPe8Q"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "zyvq3w", "is_robot_indexable": true, "report_reasons": null, "author": "theDro54", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zyvq3w/ive_started_getting_into_technical_blog_writing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zyvq3w/ive_started_getting_into_technical_blog_writing/", "subreddit_subscribers": 84628, "created_utc": 1672390392.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Data noob here: looking to hourly fetch some bank transactions and insert them into a SQL table that I can query (points if I can query the SQL through a web UI). Was thinking Postgres for storage, but I don\u2019t know what web viewers are available. When I worked at Google we had something called PLX, which was nice and kind of what I\u2019m looking for.\n\nPeople online are telling me that I want to use some ETL service. I\u2019d like to avoid manually implementing defensive logic to guard against inserting duplicate transactions and worry about delivery guarantees (if I can avoid it).\n\nThis is for a personal project. Someone recommended benthos.dev. Anyone agree with that recommendation? Any other recommendations?\n\nAgain: big noob here.", "author_fullname": "t2_3iu12ph8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL recommendations? (personal project)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zyqltl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672373622.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data noob here: looking to hourly fetch some bank transactions and insert them into a SQL table that I can query (points if I can query the SQL through a web UI). Was thinking Postgres for storage, but I don\u2019t know what web viewers are available. When I worked at Google we had something called PLX, which was nice and kind of what I\u2019m looking for.&lt;/p&gt;\n\n&lt;p&gt;People online are telling me that I want to use some ETL service. I\u2019d like to avoid manually implementing defensive logic to guard against inserting duplicate transactions and worry about delivery guarantees (if I can avoid it).&lt;/p&gt;\n\n&lt;p&gt;This is for a personal project. Someone recommended benthos.dev. Anyone agree with that recommendation? Any other recommendations?&lt;/p&gt;\n\n&lt;p&gt;Again: big noob here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zyqltl", "is_robot_indexable": true, "report_reasons": null, "author": "wpcarroll", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zyqltl/etl_recommendations_personal_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zyqltl/etl_recommendations_personal_project/", "subreddit_subscribers": 84628, "created_utc": 1672373622.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello friends! I am quite new in this field, I have worked for roughly 2 years as a developer and since Fall this year I am pursuing a career in data engineering and recently got certified in AWS cloud architect associate. Apart from some spare time reading and making my hands dirty with spark using AWS glue and the Databricks community edition I have little experience, although I am currently working in a related project. In order to get more attention by potential customers on freelance platforms, would you suggest becoming certified in Azure aswell or rather be more specific and do certs in eg Databricks?", "author_fullname": "t2_1cs2nim6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zybzmu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672337472.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello friends! I am quite new in this field, I have worked for roughly 2 years as a developer and since Fall this year I am pursuing a career in data engineering and recently got certified in AWS cloud architect associate. Apart from some spare time reading and making my hands dirty with spark using AWS glue and the Databricks community edition I have little experience, although I am currently working in a related project. In order to get more attention by potential customers on freelance platforms, would you suggest becoming certified in Azure aswell or rather be more specific and do certs in eg Databricks?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zybzmu", "is_robot_indexable": true, "report_reasons": null, "author": "whoisvad", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zybzmu/looking_for_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zybzmu/looking_for_advice/", "subreddit_subscribers": 84628, "created_utc": 1672337472.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Everyone hope ya'll are having a great day,  I'm an \"In-development\" Data Analyst, so I'm currently in the works of getting into the field. I've so far learned Python, R basics, NumPy, Pandas, Tableau, Excel, Google Analytics, and SQL as my tools for the field, as well as statistical testing. I know the basics of all of them and with a little help from google I can work my way around most of them pretty fluently. \n\n  \nI also understand learning the tools is not the only thing to do, so I've also completed the Meta Marketing Analytics Certification, &amp; the Google Data Analytics Certification; while I'm also about halfway to completing the IBM Data Analytics Certification. \n\n  \nFollowing these 3 certifications I'm looking at completing the IBM Data Science Certification, The IBM Cybersecurity Analytics Certification, along with doing Googles Into To Data Structures And Algorithms course, and Harvards CS50: Introduction to Computer Science course. \n\n  \nI want to do these and maybe after this Analytics certification by IBM get into a Analytics role, and then after the Harvard course go and try my hands at a Data Science Position, as I don't doubt my ability to network once in the industry.  \n\nEven so with my current standing point I've been putting out applications left and right this past month with no avail; I try to make the habit of doing an hour of applications a day. I figured with my basic understanding of data structure, good communication skill from my current position in my teams leadership, and the skills and certifications I've built up in the past 7 months I would have some sort of chance in a junior remote analytics role, but I feel as I'm doing something wrong, whether that's looking at the wrong salaries(70k-80k) or looking for remote positions, ect. If anyone has any recommendations or any sort of advice I'm all ears!   \n\n\nP.S. I've also been thinking of using Pathrise as a way of getting my foot in the door, but I'm hesitant due to some poor reviews I've seen. If anyone has any experience with them please chime in! It would be greatly appreciated.", "author_fullname": "t2_va7imejq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career Path", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zya21t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672332797.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Everyone hope ya&amp;#39;ll are having a great day,  I&amp;#39;m an &amp;quot;In-development&amp;quot; Data Analyst, so I&amp;#39;m currently in the works of getting into the field. I&amp;#39;ve so far learned Python, R basics, NumPy, Pandas, Tableau, Excel, Google Analytics, and SQL as my tools for the field, as well as statistical testing. I know the basics of all of them and with a little help from google I can work my way around most of them pretty fluently. &lt;/p&gt;\n\n&lt;p&gt;I also understand learning the tools is not the only thing to do, so I&amp;#39;ve also completed the Meta Marketing Analytics Certification, &amp;amp; the Google Data Analytics Certification; while I&amp;#39;m also about halfway to completing the IBM Data Analytics Certification. &lt;/p&gt;\n\n&lt;p&gt;Following these 3 certifications I&amp;#39;m looking at completing the IBM Data Science Certification, The IBM Cybersecurity Analytics Certification, along with doing Googles Into To Data Structures And Algorithms course, and Harvards CS50: Introduction to Computer Science course. &lt;/p&gt;\n\n&lt;p&gt;I want to do these and maybe after this Analytics certification by IBM get into a Analytics role, and then after the Harvard course go and try my hands at a Data Science Position, as I don&amp;#39;t doubt my ability to network once in the industry.  &lt;/p&gt;\n\n&lt;p&gt;Even so with my current standing point I&amp;#39;ve been putting out applications left and right this past month with no avail; I try to make the habit of doing an hour of applications a day. I figured with my basic understanding of data structure, good communication skill from my current position in my teams leadership, and the skills and certifications I&amp;#39;ve built up in the past 7 months I would have some sort of chance in a junior remote analytics role, but I feel as I&amp;#39;m doing something wrong, whether that&amp;#39;s looking at the wrong salaries(70k-80k) or looking for remote positions, ect. If anyone has any recommendations or any sort of advice I&amp;#39;m all ears!   &lt;/p&gt;\n\n&lt;p&gt;P.S. I&amp;#39;ve also been thinking of using Pathrise as a way of getting my foot in the door, but I&amp;#39;m hesitant due to some poor reviews I&amp;#39;ve seen. If anyone has any experience with them please chime in! It would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zya21t", "is_robot_indexable": true, "report_reasons": null, "author": "Jeffrey08ww", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zya21t/career_path/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zya21t/career_path/", "subreddit_subscribers": 84628, "created_utc": 1672332797.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all!  \n\n\nI'm currently analyzing some solutions for moving our in-house Ingres database(vector) to an Azure cloud solution. We're working with large datasets for mapping/geographic applications. We're looking to atleast keep the same performance as we currently have.   \n\n\nI'm currently looking at the following solutions:\n\n* Azure SQL Hyperscale\n* Azure CosmoDB\n* Azure Synapse\n* Azure Databricks\n\nWould any of you have any other suggestions that would be worth looking into? or any pitfalls I could run into?  \n\n\nI'm currently working on a performance analysis with a subset of the data (capped at 200k rows per table), will that give me a honest view of what to expect from these solutions in terms of performance? or am I working on a bad assumption? Should I use a larger dataset?\n\n  \nThis is a new job (2 weeks in) and I am coming from a full stack dev position, so I'm not up to date on the data management aspects of our collective field. Any pointers would be much appreciated!", "author_fullname": "t2_4e7gu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "In-house Actian database to Azure solution", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zy60sg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672322233.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all!  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently analyzing some solutions for moving our in-house Ingres database(vector) to an Azure cloud solution. We&amp;#39;re working with large datasets for mapping/geographic applications. We&amp;#39;re looking to atleast keep the same performance as we currently have.   &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently looking at the following solutions:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Azure SQL Hyperscale&lt;/li&gt;\n&lt;li&gt;Azure CosmoDB&lt;/li&gt;\n&lt;li&gt;Azure Synapse&lt;/li&gt;\n&lt;li&gt;Azure Databricks&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Would any of you have any other suggestions that would be worth looking into? or any pitfalls I could run into?  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working on a performance analysis with a subset of the data (capped at 200k rows per table), will that give me a honest view of what to expect from these solutions in terms of performance? or am I working on a bad assumption? Should I use a larger dataset?&lt;/p&gt;\n\n&lt;p&gt;This is a new job (2 weeks in) and I am coming from a full stack dev position, so I&amp;#39;m not up to date on the data management aspects of our collective field. Any pointers would be much appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zy60sg", "is_robot_indexable": true, "report_reasons": null, "author": "Native136", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zy60sg/inhouse_actian_database_to_azure_solution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zy60sg/inhouse_actian_database_to_azure_solution/", "subreddit_subscribers": 84628, "created_utc": 1672322233.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI have an AWS Glue Start job State in Step function. In case of the Glue job failed status would like to publish a message to SNS. I tried several methods such as using a Get job State, Lamda function etc. but no luck.\n\nCan someone help me on how to check the Glue job run status in a Step function and send that status as an input to choice State to make the decision.", "author_fullname": "t2_mspamalq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Glue job status in AWS Step Functions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zypwxw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672371597.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I have an AWS Glue Start job State in Step function. In case of the Glue job failed status would like to publish a message to SNS. I tried several methods such as using a Get job State, Lamda function etc. but no luck.&lt;/p&gt;\n\n&lt;p&gt;Can someone help me on how to check the Glue job run status in a Step function and send that status as an input to choice State to make the decision.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zypwxw", "is_robot_indexable": true, "report_reasons": null, "author": "Awsmason", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zypwxw/glue_job_status_in_aws_step_functions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zypwxw/glue_job_status_in_aws_step_functions/", "subreddit_subscribers": 84628, "created_utc": 1672371597.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nFor a client I am creating a data warehouse in which we have some slowly changing dimensions (or facts if that is even a thing?). For example we want to report the annually recurring revenue (ARR) for subscriptions and we want to have both the currently active and the expired subscriptions in there. So that we can see the ARR over a timeline. \n\nThe data we retrieve looks like this: \n\n&amp;#x200B;\n\n|subscription\\_id|account\\_id|ARR|start\\_date|end\\_date|\n|:-|:-|:-|:-|:-|\n|1|1|10|01-01-2022|31-03-2022|\n|2|2|20|01-01-2022|31-12-2022|\n|3|1|5|01-04-2022|31-11-2022|\n\nSo in this case the same account (account\\_id 1) renewed a subscription at the 01-04-2022. In the report of 2022 we want to see the ARR for all months in 2022. I've looked into slowly changing dimensions, however something I can not really see in that concept is how to report both the currently active license and the history in a dashboard. If we for example want to visualize the ARR in all of 2022 per month in a dashboarding tool we want to see both subscriptions for account\\_id 1 over the course of the year, not just the currently active one. This seems to be very tricky to do in most dashboarding tools. \n\nTo overcome this I've done the following. I created a calendar table with an interval of 1 month and I cross join it with the table above to generate a fact table. The end result would look like:\n\n&amp;#x200B;\n\n|timestamp|account\\_id|ARR|\n|:-|:-|:-|\n|01-01-2022|1|10|\n|01-01-2022|2|20|\n|01-02-2022|1|10|\n|...|...|...|\n|01-11-2022|1|10|\n|01-11-2022|2|20|\n|01-12-2022|2|20|\n\nThis makes it really easy for the user of the reporting tool to filter on a specific month and show the ARR between the dates and over multiple subscriptions. It does however generate a lot of extra data, but at the moment the storage space is not an issue. And it makes it more of a transactional style table, but the ARR is not really a transaction (i.e. it is not really a sold product on a specific date). \n\nMy question is: Are there better ways of generating a fact table where the source data contains a date range?", "author_fullname": "t2_ipra12z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Creating a fact table from slowly changing data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zy6k1l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672323728.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For a client I am creating a data warehouse in which we have some slowly changing dimensions (or facts if that is even a thing?). For example we want to report the annually recurring revenue (ARR) for subscriptions and we want to have both the currently active and the expired subscriptions in there. So that we can see the ARR over a timeline. &lt;/p&gt;\n\n&lt;p&gt;The data we retrieve looks like this: &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;subscription_id&lt;/th&gt;\n&lt;th align=\"left\"&gt;account_id&lt;/th&gt;\n&lt;th align=\"left\"&gt;ARR&lt;/th&gt;\n&lt;th align=\"left\"&gt;start_date&lt;/th&gt;\n&lt;th align=\"left\"&gt;end_date&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;10&lt;/td&gt;\n&lt;td align=\"left\"&gt;01-01-2022&lt;/td&gt;\n&lt;td align=\"left\"&gt;31-03-2022&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;2&lt;/td&gt;\n&lt;td align=\"left\"&gt;2&lt;/td&gt;\n&lt;td align=\"left\"&gt;20&lt;/td&gt;\n&lt;td align=\"left\"&gt;01-01-2022&lt;/td&gt;\n&lt;td align=\"left\"&gt;31-12-2022&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;3&lt;/td&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;5&lt;/td&gt;\n&lt;td align=\"left\"&gt;01-04-2022&lt;/td&gt;\n&lt;td align=\"left\"&gt;31-11-2022&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;So in this case the same account (account_id 1) renewed a subscription at the 01-04-2022. In the report of 2022 we want to see the ARR for all months in 2022. I&amp;#39;ve looked into slowly changing dimensions, however something I can not really see in that concept is how to report both the currently active license and the history in a dashboard. If we for example want to visualize the ARR in all of 2022 per month in a dashboarding tool we want to see both subscriptions for account_id 1 over the course of the year, not just the currently active one. This seems to be very tricky to do in most dashboarding tools. &lt;/p&gt;\n\n&lt;p&gt;To overcome this I&amp;#39;ve done the following. I created a calendar table with an interval of 1 month and I cross join it with the table above to generate a fact table. The end result would look like:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;timestamp&lt;/th&gt;\n&lt;th align=\"left\"&gt;account_id&lt;/th&gt;\n&lt;th align=\"left\"&gt;ARR&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;01-01-2022&lt;/td&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;10&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;01-01-2022&lt;/td&gt;\n&lt;td align=\"left\"&gt;2&lt;/td&gt;\n&lt;td align=\"left\"&gt;20&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;01-02-2022&lt;/td&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;10&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;...&lt;/td&gt;\n&lt;td align=\"left\"&gt;...&lt;/td&gt;\n&lt;td align=\"left\"&gt;...&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;01-11-2022&lt;/td&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;10&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;01-11-2022&lt;/td&gt;\n&lt;td align=\"left\"&gt;2&lt;/td&gt;\n&lt;td align=\"left\"&gt;20&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;01-12-2022&lt;/td&gt;\n&lt;td align=\"left\"&gt;2&lt;/td&gt;\n&lt;td align=\"left\"&gt;20&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;This makes it really easy for the user of the reporting tool to filter on a specific month and show the ARR between the dates and over multiple subscriptions. It does however generate a lot of extra data, but at the moment the storage space is not an issue. And it makes it more of a transactional style table, but the ARR is not really a transaction (i.e. it is not really a sold product on a specific date). &lt;/p&gt;\n\n&lt;p&gt;My question is: Are there better ways of generating a fact table where the source data contains a date range?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zy6k1l", "is_robot_indexable": true, "report_reasons": null, "author": "starslet93", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zy6k1l/creating_a_fact_table_from_slowly_changing_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zy6k1l/creating_a_fact_table_from_slowly_changing_data/", "subreddit_subscribers": 84628, "created_utc": 1672323728.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}