{"kind": "Listing", "data": {"after": "t3_zyx9pc", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The 73 Apple internal ISO images that I uploaded last week are now downloadable on Macintosh Garden - links in comments", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 94, "top_awarded_type": null, "hide_score": false, "name": "t3_zymgbg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 543, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_2m8yzgkv", "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 543, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://a.thumbs.redditmedia.com/JUQJilZobItGounaUH7GPpaS6NBq-YTyzGXD9anv-r4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "VintageApple", "selftext": "", "author_fullname": "t2_2m8yzgkv", "saved": false, "mod_reason_title": null, "gilded": 1, "clicked": false, "title": "The 73 Apple internal ISO images that I uploaded last week are now downloadable on Macintosh Garden - links in comments", "link_flair_richtext": [], "subreddit_name_prefixed": "r/VintageApple", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 94, "top_awarded_type": null, "hide_score": false, "name": "t3_zykfnj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 212, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 212, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://a.thumbs.redditmedia.com/JUQJilZobItGounaUH7GPpaS6NBq-YTyzGXD9anv-r4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_2": 1}, "post_hint": "image", "content_categories": null, "is_self": false, "mod_note": null, "created": 1672357300.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/dec1h2fvsy8a1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/dec1h2fvsy8a1.jpg?auto=webp&amp;s=e5660ca762272c2d62bdb8ea399cf45590d2c3d0", "width": 760, "height": 514}, "resolutions": [{"url": "https://preview.redd.it/dec1h2fvsy8a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=04cf8b4ce7fe1ace81a82f011d373f02601aac4d", "width": 108, "height": 73}, {"url": "https://preview.redd.it/dec1h2fvsy8a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=940f311b3367f4d5d2e8fb0072f9788bdeccebdf", "width": 216, "height": 146}, {"url": "https://preview.redd.it/dec1h2fvsy8a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ba8168a7482f14f75e2ea6f7ae393a4e1b139211", "width": 320, "height": 216}, {"url": "https://preview.redd.it/dec1h2fvsy8a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=18189eea07fe104d58f7ad967923ca3b985261a4", "width": 640, "height": 432}], "variants": {}, "id": "UT0YNTPqSJQso9mYdZZpIEOWSAehu6DIDw-f6Eg5Wec"}], "enabled": true}, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 500, "id": "gid_2", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 100, "icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png", "days_of_premium": 7, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Gives 100 Reddit Coins and a week of r/lounge access and ad-free browsing.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Gold", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png"}], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x4u1", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zykfnj", "is_robot_indexable": true, "report_reasons": null, "author": "MrFahrenheit_451", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/VintageApple/comments/zykfnj/the_73_apple_internal_iso_images_that_i_uploaded/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/dec1h2fvsy8a1.jpg", "subreddit_subscribers": 45347, "created_utc": 1672357300.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1672362288.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/dec1h2fvsy8a1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/dec1h2fvsy8a1.jpg?auto=webp&amp;s=e5660ca762272c2d62bdb8ea399cf45590d2c3d0", "width": 760, "height": 514}, "resolutions": [{"url": "https://preview.redd.it/dec1h2fvsy8a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=04cf8b4ce7fe1ace81a82f011d373f02601aac4d", "width": 108, "height": 73}, {"url": "https://preview.redd.it/dec1h2fvsy8a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=940f311b3367f4d5d2e8fb0072f9788bdeccebdf", "width": 216, "height": 146}, {"url": "https://preview.redd.it/dec1h2fvsy8a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ba8168a7482f14f75e2ea6f7ae393a4e1b139211", "width": 320, "height": 216}, {"url": "https://preview.redd.it/dec1h2fvsy8a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=18189eea07fe104d58f7ad967923ca3b985261a4", "width": 640, "height": 432}], "variants": {}, "id": "UT0YNTPqSJQso9mYdZZpIEOWSAehu6DIDw-f6Eg5Wec"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zymgbg", "is_robot_indexable": true, "report_reasons": null, "author": "MrFahrenheit_451", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_zykfnj", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zymgbg/the_73_apple_internal_iso_images_that_i_uploaded/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/dec1h2fvsy8a1.jpg", "subreddit_subscribers": 662785, "created_utc": 1672362288.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_fzwj4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "20TB WD Elements $309.99 at AMAZON USA", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "sale", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zye85o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 135, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Sale", "can_mod_post": false, "score": 135, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "default", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1672342685.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "amazon.com", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.amazon.com/dp/B09VCXWPQG", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ef8232de-b94e-11eb-ba29-0ed106a6f983", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "1TB = 0.909495TiB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zye85o", "is_robot_indexable": true, "report_reasons": null, "author": "HTWingNut", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/zye85o/20tb_wd_elements_30999_at_amazon_usa/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.amazon.com/dp/B09VCXWPQG", "subreddit_subscribers": 662785, "created_utc": 1672342685.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "You can download it from [Xowa](http://xowa.org/) or [Kiwix](https://kiwix.org).\n\nThey allow you to download specific language, or even specific wiki, such as Movies' topics or Medicine, or Computer or top 50,000 entries (check other selections at [Kiwix library page](https://library.kiwix.org/?lang=eng&amp;category=wikipedia)).\n\nOnce you have the database (wiki set) you just need the application (launcher) which is available in Windows, Mac, Android, Linux formats. The size varies from 1-90GB. You can choose between no-pic, no-video, or full (maxi).", "author_fullname": "t2_kkjbi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hoarders, Remember, no library is complete unless you have Wikipedia for offline access!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zyq5vw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672372318.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;You can download it from &lt;a href=\"http://xowa.org/\"&gt;Xowa&lt;/a&gt; or &lt;a href=\"https://kiwix.org\"&gt;Kiwix&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;They allow you to download specific language, or even specific wiki, such as Movies&amp;#39; topics or Medicine, or Computer or top 50,000 entries (check other selections at &lt;a href=\"https://library.kiwix.org/?lang=eng&amp;amp;category=wikipedia\"&gt;Kiwix library page&lt;/a&gt;).&lt;/p&gt;\n\n&lt;p&gt;Once you have the database (wiki set) you just need the application (launcher) which is available in Windows, Mac, Android, Linux formats. The size varies from 1-90GB. You can choose between no-pic, no-video, or full (maxi).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "60TB @ GDrive oo", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zyq5vw", "is_robot_indexable": true, "report_reasons": null, "author": "tecepeipe", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/zyq5vw/hoarders_remember_no_library_is_complete_unless/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zyq5vw/hoarders_remember_no_library_is_complete_unless/", "subreddit_subscribers": 662785, "created_utc": 1672372318.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Bit of context: we have 2 computer at home that we use for running a business, some simple video editing, graphic design, etc. and we need to share and keep a few folders of commissioned arts, short videos, assets and projects synced or accessible between these 2 computers to make it easy to work with. These 2 computers are plugged into our provided combo router/modem provided by our ISP (it doesn\u2019t have any other ports sadly)\n\nWhile acquiring or building a NAS sounds fun in a geeky way, I am looking into the best value option to handle this task, even if it mean using built-in Windows features.", "author_fullname": "t2_157y7obb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cheapest way to share documents between 2 computers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zyh49h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672349514.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Bit of context: we have 2 computer at home that we use for running a business, some simple video editing, graphic design, etc. and we need to share and keep a few folders of commissioned arts, short videos, assets and projects synced or accessible between these 2 computers to make it easy to work with. These 2 computers are plugged into our provided combo router/modem provided by our ISP (it doesn\u2019t have any other ports sadly)&lt;/p&gt;\n\n&lt;p&gt;While acquiring or building a NAS sounds fun in a geeky way, I am looking into the best value option to handle this task, even if it mean using built-in Windows features.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zyh49h", "is_robot_indexable": true, "report_reasons": null, "author": "StereoMissile", "discussion_type": null, "num_comments": 41, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zyh49h/cheapest_way_to_share_documents_between_2/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zyh49h/cheapest_way_to_share_documents_between_2/", "subreddit_subscribers": 662785, "created_utc": 1672349514.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I know I can view and rename a file. \n\nI know I can view and add tags into file properties in Windows Explorer.\n\n.\n\nThose all take a lot of time for hundreds if not thousands of files.\n\n.\n\nCan I have a self-hosted web interface where I am presented videos/pdf/jpg and I can just type in,  \"red car California road mountain\" press enter and move onto the next file, a PDF. \"electric bill January 2021 NYSEG\" press enter. a JPG pops up and I click a button and it sends the image to Google for a quick reverse image search in case I need help with Keywords or want a better resolution. \n\nDoes this exist? Do I need to make it? Do I need to sell it? I've done a decent search but can't find one that has Google reverse image and is fast and does PDF's and videos and just assults my eyes with media. I have to click on each file with my mouse...", "author_fullname": "t2_8bsui", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking to become an Organized Hoarder, need some help with tagging videos/PDFs/JPGs.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zy7dvs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672325997.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know I can view and rename a file. &lt;/p&gt;\n\n&lt;p&gt;I know I can view and add tags into file properties in Windows Explorer.&lt;/p&gt;\n\n&lt;p&gt;.&lt;/p&gt;\n\n&lt;p&gt;Those all take a lot of time for hundreds if not thousands of files.&lt;/p&gt;\n\n&lt;p&gt;.&lt;/p&gt;\n\n&lt;p&gt;Can I have a self-hosted web interface where I am presented videos/pdf/jpg and I can just type in,  &amp;quot;red car California road mountain&amp;quot; press enter and move onto the next file, a PDF. &amp;quot;electric bill January 2021 NYSEG&amp;quot; press enter. a JPG pops up and I click a button and it sends the image to Google for a quick reverse image search in case I need help with Keywords or want a better resolution. &lt;/p&gt;\n\n&lt;p&gt;Does this exist? Do I need to make it? Do I need to sell it? I&amp;#39;ve done a decent search but can&amp;#39;t find one that has Google reverse image and is fast and does PDF&amp;#39;s and videos and just assults my eyes with media. I have to click on each file with my mouse...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zy7dvs", "is_robot_indexable": true, "report_reasons": null, "author": "rileymorgan", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zy7dvs/looking_to_become_an_organized_hoarder_need_some/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zy7dvs/looking_to_become_an_organized_hoarder_need_some/", "subreddit_subscribers": 662785, "created_utc": 1672325997.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Was supposed to have lifetime unlimited GDrive from my uni, but Google is ending their contracts with UK schools in 2023. A NAS is not an option for me for various reasons, so I'm looking for cloud storage to replace gdrive.\n\nHow I intend to use it is to have all my files on several external SSDs and to back those up. I can't use a service where the backup has to reflect the files on my computer, as I use a desktop and laptop.\n\nLooking for about 4TB minimum. Able to spend about \u00a310 a month. Anyone have any suggestions?", "author_fullname": "t2_beeisf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Decent cloud storage right now?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zycivv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672338782.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Was supposed to have lifetime unlimited GDrive from my uni, but Google is ending their contracts with UK schools in 2023. A NAS is not an option for me for various reasons, so I&amp;#39;m looking for cloud storage to replace gdrive.&lt;/p&gt;\n\n&lt;p&gt;How I intend to use it is to have all my files on several external SSDs and to back those up. I can&amp;#39;t use a service where the backup has to reflect the files on my computer, as I use a desktop and laptop.&lt;/p&gt;\n\n&lt;p&gt;Looking for about 4TB minimum. Able to spend about \u00a310 a month. Anyone have any suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zycivv", "is_robot_indexable": true, "report_reasons": null, "author": "dysfunctionalbrat", "discussion_type": null, "num_comments": 51, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zycivv/decent_cloud_storage_right_now/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zycivv/decent_cloud_storage_right_now/", "subreddit_subscribers": 662785, "created_utc": 1672338782.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking for a backup solution for 100TB of data. I only have one 60TB server available at the moment, but am planning to add more storage, the only problem is that it's going to be on a separate server. What would be the best way to make sure both servers are backed up, preferably separate drives for off site backups or something similar. Is there any way to easily keep track of the data and make backups, what's the best practice in this instance to keep the data safe?", "author_fullname": "t2_36feki92", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Proper way to keep backups of multiple servers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zya4jo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672332973.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for a backup solution for 100TB of data. I only have one 60TB server available at the moment, but am planning to add more storage, the only problem is that it&amp;#39;s going to be on a separate server. What would be the best way to make sure both servers are backed up, preferably separate drives for off site backups or something similar. Is there any way to easily keep track of the data and make backups, what&amp;#39;s the best practice in this instance to keep the data safe?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zya4jo", "is_robot_indexable": true, "report_reasons": null, "author": "ElementaryZX", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zya4jo/proper_way_to_keep_backups_of_multiple_servers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zya4jo/proper_way_to_keep_backups_of_multiple_servers/", "subreddit_subscribers": 662785, "created_utc": 1672332973.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Im curious if you guys just wait for the drive to just die on you or you guys have a threshold like if it goes below 20-30% left you just backup everything and throw it away", "author_fullname": "t2_8uunh0jy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "At what percent left of an SSD's lifetime do you guys throw it away?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zy884q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672328185.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im curious if you guys just wait for the drive to just die on you or you guys have a threshold like if it goes below 20-30% left you just backup everything and throw it away&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zy884q", "is_robot_indexable": true, "report_reasons": null, "author": "i0bzdnahw0lz", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zy884q/at_what_percent_left_of_an_ssds_lifetime_do_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zy884q/at_what_percent_left_of_an_ssds_lifetime_do_you/", "subreddit_subscribers": 662785, "created_utc": 1672328185.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I didn't really know where to share this but I thought I should mention.\n\nSo when one of the big problems I have with western comic books in comparison to manga is that I just don't know where to start. I'd like to read the in universe collection I just don't know how to.\n\nAnd this is where this reading order comes in.\n\nhttps://comicbookreadingorders.com/\n\nI've compiled the entire list in several cbz for a more seamless experience. \n\nI have done marvel master reading order part 1-10,Marvel Now, all new all different marvel, Marvel Legacy, A Fresh Start.\n\nand for Dc master reading order part 1-7, The new 52, DC you, rebirth.\n\nMarvel's has many more comics and is monstrously larger than DC. \n\nI don't want you guys to think that I'm asking to archive it for me to use later. I have my own digital archive. I am keeping it careful. But i thought I should mention it for the comic book fans that are interested.\n\nIts on Torrentgalaxy.", "author_fullname": "t2_10x51w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A Master Reading order I have compiled of western comic books.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zykujf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672358294.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I didn&amp;#39;t really know where to share this but I thought I should mention.&lt;/p&gt;\n\n&lt;p&gt;So when one of the big problems I have with western comic books in comparison to manga is that I just don&amp;#39;t know where to start. I&amp;#39;d like to read the in universe collection I just don&amp;#39;t know how to.&lt;/p&gt;\n\n&lt;p&gt;And this is where this reading order comes in.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://comicbookreadingorders.com/\"&gt;https://comicbookreadingorders.com/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve compiled the entire list in several cbz for a more seamless experience. &lt;/p&gt;\n\n&lt;p&gt;I have done marvel master reading order part 1-10,Marvel Now, all new all different marvel, Marvel Legacy, A Fresh Start.&lt;/p&gt;\n\n&lt;p&gt;and for Dc master reading order part 1-7, The new 52, DC you, rebirth.&lt;/p&gt;\n\n&lt;p&gt;Marvel&amp;#39;s has many more comics and is monstrously larger than DC. &lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t want you guys to think that I&amp;#39;m asking to archive it for me to use later. I have my own digital archive. I am keeping it careful. But i thought I should mention it for the comic book fans that are interested.&lt;/p&gt;\n\n&lt;p&gt;Its on Torrentgalaxy.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "zykujf", "is_robot_indexable": true, "report_reasons": null, "author": "shellshock321", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zykujf/a_master_reading_order_i_have_compiled_of_western/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zykujf/a_master_reading_order_i_have_compiled_of_western/", "subreddit_subscribers": 662785, "created_utc": 1672358294.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_d5sfz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are these \"enterprise\" hitachis suitable for worm backups, or are they like nas or surveillance drives that only work well for their intended purpose?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_zy66q6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Fw1EE5wyfcbzMdZNezu_ELdjJQFacVyqDPCC3LzQyic.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1672322681.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "ebay.com.au", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.ebay.com.au/itm/364080222693", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Kyv8zj0FDIAgPoLdHoDIhTU1xjqr7uC1DlNOoovgbds.jpg?auto=webp&amp;s=bd28394263444baf71844a42b589f944a4dd8034", "width": 400, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/Kyv8zj0FDIAgPoLdHoDIhTU1xjqr7uC1DlNOoovgbds.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d896c9fc349f3ce2096de5c5248ca74d66aecd70", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/Kyv8zj0FDIAgPoLdHoDIhTU1xjqr7uC1DlNOoovgbds.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=14a2f15bbd4cb4e0e4ee9ff822c1642af9383e9d", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/Kyv8zj0FDIAgPoLdHoDIhTU1xjqr7uC1DlNOoovgbds.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ef59b05a1b70dddfddd9473bbafad7804275d5a7", "width": 320, "height": 240}], "variants": {}, "id": "I-JrK177CrcRxDpCenJ5GJzYQB8igY8wnOoI0VskFn4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zy66q6", "is_robot_indexable": true, "report_reasons": null, "author": "bluejeans90210", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zy66q6/are_these_enterprise_hitachis_suitable_for_worm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.ebay.com.au/itm/364080222693", "subreddit_subscribers": 662785, "created_utc": 1672322681.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My backup have gotten out of hand.  I have multiple hard drives with multiple locations for same file.  Did an backup, then started to clean up, then backup, then clean up... trying to put them all back on one drive, however I would have multiple of same in different file locations.... is there any software that can go thru and auto organize?  If I went thru manually it would take more patience that I have (and how I got to this place)", "author_fullname": "t2_2auzbuih", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "organizing software?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zyonef", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672368028.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My backup have gotten out of hand.  I have multiple hard drives with multiple locations for same file.  Did an backup, then started to clean up, then backup, then clean up... trying to put them all back on one drive, however I would have multiple of same in different file locations.... is there any software that can go thru and auto organize?  If I went thru manually it would take more patience that I have (and how I got to this place)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zyonef", "is_robot_indexable": true, "report_reasons": null, "author": "ShyOstrich", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zyonef/organizing_software/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zyonef/organizing_software/", "subreddit_subscribers": 662785, "created_utc": 1672368028.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Elon Musk orders closure of \"one of Twitter's 3 main computing storage facilities\". Where might the gear resurface?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zz112y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_3udph", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "sysadmin", "selftext": "Fron NYT: [link](https://www.nytimes.com/2022/12/29/technology/twitter-elon-musk.html)  \n\n\nElon Musk\u2019s orders were clear: Close the data center.\n\nEarly on Christmas Eve, members of the billionaire\u2019s staff flew to Sacramento \u2014 the site of [one of Twitter\u2019s three main computing storage facilities](https://www.nytimes.com/2022/11/18/technology/elon-musk-twitter-workers-quit.html)  \u2014 to disconnect servers that had kept the social network running  smoothly. Some employees were worried that losing those servers could  cause problems, but saving money was the priority, according to two  people who were familiar with the move but not authorized to talk about  it.\n\nThe data center shutdown was one  of many drastic steps Mr. Musk has undertaken to stabilize Twitter\u2019s  finances. Over the past few weeks, Twitter had stopped paying millions  of dollars in rent and services, and Mr. Musk had told his subordinates  to renegotiate those agreements or simply end them. The company has  stopped paying rent at its Seattle office, leading it to face eviction,  two people familiar with the matter said. Janitorial and security  services have been cut, and in some cases employees have resorted to  bringing their own toilet paper to the office.\n\nMr. Musk [bought the social network for $44 billion](https://www.nytimes.com/2022/11/11/technology/elon-musk-twitter-takeover.html) in late October, saddling it with debt that will require him to pay about [$1 billion in interest](https://www.nytimes.com/2022/10/30/technology/elon-musk-twitter-debt.html) annually. Speaking on [a live forum on Twitter](https://www.youtube.com/watch?v=QVDUIyzeJn8)  last week, Mr. Musk compared the company to a \u201cplane that is headed  towards the ground at high speed with the engines on fire and the  controls don\u2019t work.\u201d Twitter was on track to have a \u201cnegative cash flow  situation\u201d of about $3 billion in 2023, he said, citing a depressed  advertising environment and increased costs, like the debt payments.\n\n\u201cThat\u2019s why I spent the last five weeks cutting costs like crazy,\u201d he said.\n\nThose cuts may be yielding consequences. On Wednesday, users around the world reported [service interruptions with Twitter](https://www.nytimes.com/2022/12/28/technology/twitter-outages.html).  Some were logged out, while others encountered error messages while  visiting the website. Twitter has not explained what caused the  temporary outage. Three people familiar with the company\u2019s  infrastructure said that if the Sacramento facility had still been  operating, it could have helped alleviate the problem by providing  backup computing capacity when other data centers failed.\n\nTwitter, which has eliminated its communications department, and Mr. Musk did not respond to a request for comment.\n\nAlthough he has said he will [appoint a new chief executive](https://www.nytimes.com/2022/12/20/technology/elon-musk-twitter-resign.html) at Twitter, Mr. Musk remains closely involved at the social networking firm even as problems crop up at his [electric vehicle company, Tesla](https://www.nytimes.com/2022/12/21/business/tesla-elon-musk.html).  And his tight control of the daily management of Twitter calls into  question just how much power he would cede to a new chief, who would  inherit a bare-bones business that he still owns.\n\nSince  early November, Mr. Musk has sought to save about $500 million in  nonlabor costs, according to an internal document seen by The New York  Times. He has also laid off or fired nearly 75 percent of the company\u2019s  work force since completing the purchase.", "author_fullname": "t2_t0csvrcz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Elon Musk\u2019s orders were clear: Close the data center. Any thoughts ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/sysadmin", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zywe7y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 88, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 88, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1672392723.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.sysadmin", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Fron NYT: &lt;a href=\"https://www.nytimes.com/2022/12/29/technology/twitter-elon-musk.html\"&gt;link&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;Elon Musk\u2019s orders were clear: Close the data center.&lt;/p&gt;\n\n&lt;p&gt;Early on Christmas Eve, members of the billionaire\u2019s staff flew to Sacramento \u2014 the site of &lt;a href=\"https://www.nytimes.com/2022/11/18/technology/elon-musk-twitter-workers-quit.html\"&gt;one of Twitter\u2019s three main computing storage facilities&lt;/a&gt;  \u2014 to disconnect servers that had kept the social network running  smoothly. Some employees were worried that losing those servers could  cause problems, but saving money was the priority, according to two  people who were familiar with the move but not authorized to talk about  it.&lt;/p&gt;\n\n&lt;p&gt;The data center shutdown was one  of many drastic steps Mr. Musk has undertaken to stabilize Twitter\u2019s  finances. Over the past few weeks, Twitter had stopped paying millions  of dollars in rent and services, and Mr. Musk had told his subordinates  to renegotiate those agreements or simply end them. The company has  stopped paying rent at its Seattle office, leading it to face eviction,  two people familiar with the matter said. Janitorial and security  services have been cut, and in some cases employees have resorted to  bringing their own toilet paper to the office.&lt;/p&gt;\n\n&lt;p&gt;Mr. Musk &lt;a href=\"https://www.nytimes.com/2022/11/11/technology/elon-musk-twitter-takeover.html\"&gt;bought the social network for $44 billion&lt;/a&gt; in late October, saddling it with debt that will require him to pay about &lt;a href=\"https://www.nytimes.com/2022/10/30/technology/elon-musk-twitter-debt.html\"&gt;$1 billion in interest&lt;/a&gt; annually. Speaking on &lt;a href=\"https://www.youtube.com/watch?v=QVDUIyzeJn8\"&gt;a live forum on Twitter&lt;/a&gt;  last week, Mr. Musk compared the company to a \u201cplane that is headed  towards the ground at high speed with the engines on fire and the  controls don\u2019t work.\u201d Twitter was on track to have a \u201cnegative cash flow  situation\u201d of about $3 billion in 2023, he said, citing a depressed  advertising environment and increased costs, like the debt payments.&lt;/p&gt;\n\n&lt;p&gt;\u201cThat\u2019s why I spent the last five weeks cutting costs like crazy,\u201d he said.&lt;/p&gt;\n\n&lt;p&gt;Those cuts may be yielding consequences. On Wednesday, users around the world reported &lt;a href=\"https://www.nytimes.com/2022/12/28/technology/twitter-outages.html\"&gt;service interruptions with Twitter&lt;/a&gt;.  Some were logged out, while others encountered error messages while  visiting the website. Twitter has not explained what caused the  temporary outage. Three people familiar with the company\u2019s  infrastructure said that if the Sacramento facility had still been  operating, it could have helped alleviate the problem by providing  backup computing capacity when other data centers failed.&lt;/p&gt;\n\n&lt;p&gt;Twitter, which has eliminated its communications department, and Mr. Musk did not respond to a request for comment.&lt;/p&gt;\n\n&lt;p&gt;Although he has said he will &lt;a href=\"https://www.nytimes.com/2022/12/20/technology/elon-musk-twitter-resign.html\"&gt;appoint a new chief executive&lt;/a&gt; at Twitter, Mr. Musk remains closely involved at the social networking firm even as problems crop up at his &lt;a href=\"https://www.nytimes.com/2022/12/21/business/tesla-elon-musk.html\"&gt;electric vehicle company, Tesla&lt;/a&gt;.  And his tight control of the daily management of Twitter calls into  question just how much power he would cede to a new chief, who would  inherit a bare-bones business that he still owns.&lt;/p&gt;\n\n&lt;p&gt;Since  early November, Mr. Musk has sought to save about $500 million in  nonlabor costs, according to an internal document seen by The New York  Times. He has also laid off or fired nearly 75 percent of the company\u2019s  work force since completing the purchase.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hQaBTilr7KyaQ6gqI_Yml2_A2iSVj8WQQaIcNk9x8yE.jpg?auto=webp&amp;s=323a827f9d8c2de2c2a5cbee6b34d8acdec82337", "width": 1050, "height": 550}, "resolutions": [{"url": "https://external-preview.redd.it/hQaBTilr7KyaQ6gqI_Yml2_A2iSVj8WQQaIcNk9x8yE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9c00ed381bbda1e4f8437beecf86706518c26293", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/hQaBTilr7KyaQ6gqI_Yml2_A2iSVj8WQQaIcNk9x8yE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f73b8517d8c3d058679d55ed1b70675939b06d05", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/hQaBTilr7KyaQ6gqI_Yml2_A2iSVj8WQQaIcNk9x8yE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=07e15ce58d4e6ff876d9ecd45a6aa5fa6b091cc3", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/hQaBTilr7KyaQ6gqI_Yml2_A2iSVj8WQQaIcNk9x8yE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=877411bf1213606b2c8ed6658dae97524c5cb611", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/hQaBTilr7KyaQ6gqI_Yml2_A2iSVj8WQQaIcNk9x8yE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1305b81976ee2beb524b6f1b7c415f3e4de33deb", "width": 960, "height": 502}], "variants": {}, "id": "lcnmaitsATRy93Pa04p9qvDs3dKbxzmJyuVKfzukvCg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qnp7", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zywe7y", "is_robot_indexable": true, "report_reasons": null, "author": "vaultRadon", "discussion_type": null, "num_comments": 143, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/sysadmin/comments/zywe7y/elon_musks_orders_were_clear_close_the_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/sysadmin/comments/zywe7y/elon_musks_orders_were_clear_close_the_data/", "subreddit_subscribers": 761736, "created_utc": 1672392723.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1672408275.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.sysadmin", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/sysadmin/comments/zywe7y/elon_musks_orders_were_clear_close_the_data/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hQaBTilr7KyaQ6gqI_Yml2_A2iSVj8WQQaIcNk9x8yE.jpg?auto=webp&amp;s=323a827f9d8c2de2c2a5cbee6b34d8acdec82337", "width": 1050, "height": 550}, "resolutions": [{"url": "https://external-preview.redd.it/hQaBTilr7KyaQ6gqI_Yml2_A2iSVj8WQQaIcNk9x8yE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9c00ed381bbda1e4f8437beecf86706518c26293", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/hQaBTilr7KyaQ6gqI_Yml2_A2iSVj8WQQaIcNk9x8yE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f73b8517d8c3d058679d55ed1b70675939b06d05", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/hQaBTilr7KyaQ6gqI_Yml2_A2iSVj8WQQaIcNk9x8yE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=07e15ce58d4e6ff876d9ecd45a6aa5fa6b091cc3", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/hQaBTilr7KyaQ6gqI_Yml2_A2iSVj8WQQaIcNk9x8yE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=877411bf1213606b2c8ed6658dae97524c5cb611", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/hQaBTilr7KyaQ6gqI_Yml2_A2iSVj8WQQaIcNk9x8yE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1305b81976ee2beb524b6f1b7c415f3e4de33deb", "width": 960, "height": 502}], "variants": {}, "id": "lcnmaitsATRy93Pa04p9qvDs3dKbxzmJyuVKfzukvCg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "zz112y", "is_robot_indexable": true, "report_reasons": null, "author": "GimmeSomeSugar", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_zywe7y", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zz112y/elon_musk_orders_closure_of_one_of_twitters_3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/sysadmin/comments/zywe7y/elon_musks_orders_were_clear_close_the_data/", "subreddit_subscribers": 662785, "created_utc": 1672408275.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Howdy all! Junior Data Hoarder here, I've collected a little less than 2 TB of various data over 30\\~ years and have mostly been sloppily copying them to various external hard drives, going up in size over the years as needed. Most recent upgrade was a few years back with a 2 TB external and last time I tried to plug it into my laptop after moving it didn't recognize it and it made me extremely nervous that I'd lost everything. RAID and external offsite backup has been niggling at the back of my head since an old computer we had died and we lost lots of photos that had to be pulled from facebook, which of course came with a quality loss, (luckily found a script/utility to help with bulk picture extraction) but with my biggest hard drive potentially trying to crap out (I haven't tried any troubleshooting / recovery / other computer yet) I'm finally motivated to dive into proper redundant data hoarding.  \n\n\nSo I'm thinking of getting this case: \\[\\[Oyen Digital Mobius Pro 2C 2-Bay USB-C RAID Hard Drive Enclosure (3R2-2C-M)\\]\\]([https://www.amazon.com/Mobius-2-Bay-USB-C-Drive-Enclosure/dp/B07TYRTNKS/ref=sr\\_1\\_11?keywords=raid%2Bhard%2Bdrive&amp;qid=1672301786&amp;sr=8-11&amp;ufe=app\\_do%3Aamzn1.fos.f5122f16-c3e8-4386-bf32-63e904010ad0&amp;th=1](https://www.amazon.com/Mobius-2-Bay-USB-C-Drive-Enclosure/dp/B07TYRTNKS/ref=sr_1_11?keywords=raid%2Bhard%2Bdrive&amp;qid=1672301786&amp;sr=8-11&amp;ufe=app_do%3Aamzn1.fos.f5122f16-c3e8-4386-bf32-63e904010ad0&amp;th=1))\n\n&amp;#x200B;\n\nAnd 2 of these \\[Seagate IronWolf 4TB NAS Internal Hard Drive HDD \u2013 CMR 3.5 Inch SATA 6Gb/s 5900 RPM 64MB Cache for RAID Network Attached Storage\\]([https://www.amazon.com/Seagate-IronWolf-5900RPM-Internal-3-5-Inch/dp/B07H289S79/ref=sr\\_1\\_3?crid=Y1IN5OZ1DXVK&amp;keywords=5%2Btb%2Bnas&amp;qid=1672302296&amp;sprefix=5%2Btb%2Bnas%2Caps%2C154&amp;sr=8-3&amp;ufe=app\\_do%3Aamzn1.fos.006c50ae-5d4c-4777-9bc0-4513d670b6bc&amp;th=1](https://www.amazon.com/Seagate-IronWolf-5900RPM-Internal-3-5-Inch/dp/B07H289S79/ref=sr_1_3?crid=Y1IN5OZ1DXVK&amp;keywords=5%2Btb%2Bnas&amp;qid=1672302296&amp;sprefix=5%2Btb%2Bnas%2Caps%2C154&amp;sr=8-3&amp;ufe=app_do%3Aamzn1.fos.006c50ae-5d4c-4777-9bc0-4513d670b6bc&amp;th=1)).\n\nAnd getting a Backblaze account to back all that up as well.\n\nThe only thing I'm not clear on is the controller, it looks like if I'm understanding correctly since this is an amateur operation I should be ok with a software RAID controller setup instead of a hardware one. Any beginner RAID software recommendations for this kind of simple setup, preferably one that could work well with a laptop?  \n\n\nThanks in advance for the guidance, it's much appreciated and this has been a long time coming.", "author_fullname": "t2_64n3u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Newbie setup questions, guidance appreciated", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zyrcbd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672375853.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Howdy all! Junior Data Hoarder here, I&amp;#39;ve collected a little less than 2 TB of various data over 30~ years and have mostly been sloppily copying them to various external hard drives, going up in size over the years as needed. Most recent upgrade was a few years back with a 2 TB external and last time I tried to plug it into my laptop after moving it didn&amp;#39;t recognize it and it made me extremely nervous that I&amp;#39;d lost everything. RAID and external offsite backup has been niggling at the back of my head since an old computer we had died and we lost lots of photos that had to be pulled from facebook, which of course came with a quality loss, (luckily found a script/utility to help with bulk picture extraction) but with my biggest hard drive potentially trying to crap out (I haven&amp;#39;t tried any troubleshooting / recovery / other computer yet) I&amp;#39;m finally motivated to dive into proper redundant data hoarding.  &lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;m thinking of getting this case: [[Oyen Digital Mobius Pro 2C 2-Bay USB-C RAID Hard Drive Enclosure (3R2-2C-M)]](&lt;a href=\"https://www.amazon.com/Mobius-2-Bay-USB-C-Drive-Enclosure/dp/B07TYRTNKS/ref=sr_1_11?keywords=raid%2Bhard%2Bdrive&amp;amp;qid=1672301786&amp;amp;sr=8-11&amp;amp;ufe=app_do%3Aamzn1.fos.f5122f16-c3e8-4386-bf32-63e904010ad0&amp;amp;th=1\"&gt;https://www.amazon.com/Mobius-2-Bay-USB-C-Drive-Enclosure/dp/B07TYRTNKS/ref=sr_1_11?keywords=raid%2Bhard%2Bdrive&amp;amp;qid=1672301786&amp;amp;sr=8-11&amp;amp;ufe=app_do%3Aamzn1.fos.f5122f16-c3e8-4386-bf32-63e904010ad0&amp;amp;th=1&lt;/a&gt;)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;And 2 of these [Seagate IronWolf 4TB NAS Internal Hard Drive HDD \u2013 CMR 3.5 Inch SATA 6Gb/s 5900 RPM 64MB Cache for RAID Network Attached Storage](&lt;a href=\"https://www.amazon.com/Seagate-IronWolf-5900RPM-Internal-3-5-Inch/dp/B07H289S79/ref=sr_1_3?crid=Y1IN5OZ1DXVK&amp;amp;keywords=5%2Btb%2Bnas&amp;amp;qid=1672302296&amp;amp;sprefix=5%2Btb%2Bnas%2Caps%2C154&amp;amp;sr=8-3&amp;amp;ufe=app_do%3Aamzn1.fos.006c50ae-5d4c-4777-9bc0-4513d670b6bc&amp;amp;th=1\"&gt;https://www.amazon.com/Seagate-IronWolf-5900RPM-Internal-3-5-Inch/dp/B07H289S79/ref=sr_1_3?crid=Y1IN5OZ1DXVK&amp;amp;keywords=5%2Btb%2Bnas&amp;amp;qid=1672302296&amp;amp;sprefix=5%2Btb%2Bnas%2Caps%2C154&amp;amp;sr=8-3&amp;amp;ufe=app_do%3Aamzn1.fos.006c50ae-5d4c-4777-9bc0-4513d670b6bc&amp;amp;th=1&lt;/a&gt;).&lt;/p&gt;\n\n&lt;p&gt;And getting a Backblaze account to back all that up as well.&lt;/p&gt;\n\n&lt;p&gt;The only thing I&amp;#39;m not clear on is the controller, it looks like if I&amp;#39;m understanding correctly since this is an amateur operation I should be ok with a software RAID controller setup instead of a hardware one. Any beginner RAID software recommendations for this kind of simple setup, preferably one that could work well with a laptop?  &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for the guidance, it&amp;#39;s much appreciated and this has been a long time coming.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zyrcbd", "is_robot_indexable": true, "report_reasons": null, "author": "tubeyes", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zyrcbd/newbie_setup_questions_guidance_appreciated/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zyrcbd/newbie_setup_questions_guidance_appreciated/", "subreddit_subscribers": 662785, "created_utc": 1672375853.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking for something to help keep up with downloading youtube videos. Optimally, I'd like something that can:\n\n* Monitor youtube channels for new uploads\n* Give me an option to download the videos\n\nThat's basically all I need it to do, it's just hard to keep up with the videos I want to download otherwise. Anyone know of something like this?", "author_fullname": "t2_mumr6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Youtube managers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zyqdsh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672372962.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for something to help keep up with downloading youtube videos. Optimally, I&amp;#39;d like something that can:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Monitor youtube channels for new uploads&lt;/li&gt;\n&lt;li&gt;Give me an option to download the videos&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;That&amp;#39;s basically all I need it to do, it&amp;#39;s just hard to keep up with the videos I want to download otherwise. Anyone know of something like this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "6TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zyqdsh", "is_robot_indexable": true, "report_reasons": null, "author": "Georgia_Ball", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/zyqdsh/youtube_managers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zyqdsh/youtube_managers/", "subreddit_subscribers": 662785, "created_utc": 1672372962.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I searched on Google and looked on Youtube and I couldn't find an answer so I'm hoping maybe you guys can help. I know I have emails with pictures I either never downloaded or downloaded and lost and I want to get them now but I don't want to sort through thousands of emails. Is there an easy way to do this?", "author_fullname": "t2_v9opjyxe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to extract all your photos from gmail at once?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zyliyw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672359907.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I searched on Google and looked on Youtube and I couldn&amp;#39;t find an answer so I&amp;#39;m hoping maybe you guys can help. I know I have emails with pictures I either never downloaded or downloaded and lost and I want to get them now but I don&amp;#39;t want to sort through thousands of emails. Is there an easy way to do this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zyliyw", "is_robot_indexable": true, "report_reasons": null, "author": "iamwhoiwasnow", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zyliyw/is_it_possible_to_extract_all_your_photos_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zyliyw/is_it_possible_to_extract_all_your_photos_from/", "subreddit_subscribers": 662785, "created_utc": 1672359907.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey guys,\n\nThis sub has been very good to me giving me advice for my first server build. Well I am back and in true DataHorder style, I'm out of space on that server so I'm in the process of planning my new NAS/Server and need your advice again.\n\n**My current setup:**\n\n* Its is a custom built Hyper-V server with a big storage pool and a few VMs on it (including Plex).\n* The pool is a triple mirror pool with about 45TB effective capacity.\n* VMs run Centos (in case that matters).\n\n**What I'm looking for:**\n\n* \\~200TB effective storage\n* 2 disk redundancy (meaning I can lose 2 disks and not loose the pool). I am open to a 'raid-6' config or similar for efficiency.\n* don't need a lot of horsepower here to run VMs as that is and will be handled on my existing server.\n* Minimum- Storage needs to be fast enough to stream 4K HDR movies (about 200Mbps) but ideally would like it to be able to handle gigabit read and writes.\n\n**Option 1: Buy a NAS**\n\n* I was considering buying a Synology 12 bay unit and filling it with (12) 20TB Exos drives but know they made a change recently where their NAS's only support their Synology branded drives and these 20TB drives wouldn't fit that. Not sure how advisable it is to run non-supported drives on these units. Also not sure if I would bump up against the Maximum Volume size. I think I would need the DS3622XS+ due to said limit.\n* I'm also open to other manufacturers if you have one to recommend.\n\n**Option 2: Build a NAS**\n\n* The other option is to build my own. Admittedly I will need some help with this specifically with software and hardware recommendations. I'm not sure how much hardware horsepower ill need to handle this much storage. With regard to software, what's the preferred choice for a pool of this size?\n\nI am very open to any info or feedback that you have and am happy to provide any more details.\n\nThanks in advance!\n\nJM", "author_fullname": "t2_4tsgl0pt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building (or buying) new NAS 200TB+", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zy7ojw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672326757.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,&lt;/p&gt;\n\n&lt;p&gt;This sub has been very good to me giving me advice for my first server build. Well I am back and in true DataHorder style, I&amp;#39;m out of space on that server so I&amp;#39;m in the process of planning my new NAS/Server and need your advice again.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;My current setup:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Its is a custom built Hyper-V server with a big storage pool and a few VMs on it (including Plex).&lt;/li&gt;\n&lt;li&gt;The pool is a triple mirror pool with about 45TB effective capacity.&lt;/li&gt;\n&lt;li&gt;VMs run Centos (in case that matters).&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;What I&amp;#39;m looking for:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;~200TB effective storage&lt;/li&gt;\n&lt;li&gt;2 disk redundancy (meaning I can lose 2 disks and not loose the pool). I am open to a &amp;#39;raid-6&amp;#39; config or similar for efficiency.&lt;/li&gt;\n&lt;li&gt;don&amp;#39;t need a lot of horsepower here to run VMs as that is and will be handled on my existing server.&lt;/li&gt;\n&lt;li&gt;Minimum- Storage needs to be fast enough to stream 4K HDR movies (about 200Mbps) but ideally would like it to be able to handle gigabit read and writes.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Option 1: Buy a NAS&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I was considering buying a Synology 12 bay unit and filling it with (12) 20TB Exos drives but know they made a change recently where their NAS&amp;#39;s only support their Synology branded drives and these 20TB drives wouldn&amp;#39;t fit that. Not sure how advisable it is to run non-supported drives on these units. Also not sure if I would bump up against the Maximum Volume size. I think I would need the DS3622XS+ due to said limit.&lt;/li&gt;\n&lt;li&gt;I&amp;#39;m also open to other manufacturers if you have one to recommend.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Option 2: Build a NAS&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The other option is to build my own. Admittedly I will need some help with this specifically with software and hardware recommendations. I&amp;#39;m not sure how much hardware horsepower ill need to handle this much storage. With regard to software, what&amp;#39;s the preferred choice for a pool of this size?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I am very open to any info or feedback that you have and am happy to provide any more details.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n\n&lt;p&gt;JM&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "41TB Triple Mirror - Storage Spaces", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zy7ojw", "is_robot_indexable": true, "report_reasons": null, "author": "awildjm", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/zy7ojw/building_or_buying_new_nas_200tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zy7ojw/building_or_buying_new_nas_200tb/", "subreddit_subscribers": 662785, "created_utc": 1672326757.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Self Hosted Digital Library", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zyqqb3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_yy2bcm3", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Does anyone know of a self-hosted digital library solution?  I came across a site called hoopla that offers a service similar for brick and mortar libraries, [https://www.hoopladigital.com/](https://www.hoopladigital.com/)  It allows the user to access ebooks, audiobooks, movies, tv shows, comics, and music.  \n\nI would love to be able to combine all my media into a single source for my family.  One website where they can view or listen to everything.  Is there a similar open-source self-hosted solution for those that want to host all their media on a single platform?  Something that has similar functionality to calibre/calibre-web, jellyfin/plex, subsonic, all in a single app?", "author_fullname": "t2_yy2bcm3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Self Hosted Digital Library", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zyqo0u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672373799.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone know of a self-hosted digital library solution?  I came across a site called hoopla that offers a service similar for brick and mortar libraries, &lt;a href=\"https://www.hoopladigital.com/\"&gt;https://www.hoopladigital.com/&lt;/a&gt;  It allows the user to access ebooks, audiobooks, movies, tv shows, comics, and music.  &lt;/p&gt;\n\n&lt;p&gt;I would love to be able to combine all my media into a single source for my family.  One website where they can view or listen to everything.  Is there a similar open-source self-hosted solution for those that want to host all their media on a single platform?  Something that has similar functionality to calibre/calibre-web, jellyfin/plex, subsonic, all in a single app?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zyqo0u", "is_robot_indexable": true, "report_reasons": null, "author": "L7nx", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/zyqo0u/self_hosted_digital_library/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/zyqo0u/self_hosted_digital_library/", "subreddit_subscribers": 220578, "created_utc": 1672373799.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1672373993.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/selfhosted/comments/zyqo0u/self_hosted_digital_library/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zyqqb3", "is_robot_indexable": true, "report_reasons": null, "author": "L7nx", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_zyqo0u", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zyqqb3/self_hosted_digital_library/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/selfhosted/comments/zyqo0u/self_hosted_digital_library/", "subreddit_subscribers": 662785, "created_utc": 1672373993.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I also moved from mdadm to ZFS RAID, so it's possible that this RAIDZv1 array idles more than the RAID10 array I used to have with the same four disks and I am noticing the spindown now vs before.\n\n I don't understand why the drives are spinning down. I've used hdparm to set the -B value to 255 but it gets reset to 20 after a while. I set it in a udev rule so its set at boot up, but again, after a while, it's back at 20.\n\nI don't have TLP or any other power management script/tool that I know of. The logs don't show anything interesting. I've tried searching but there's not a lot of info about not wanting the drives to sleep, usually it's the opposite.\n\nI've tried setitng -S 0 along with -B 255 with hdparm. I updated /etc/hdparm.conf to set the APM value to 255 for each of my spinning drives. \n\nIs there something else I'm missing that is changing the APM value of the drives?", "author_fullname": "t2_gcapk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WD Red drives sleeping after moving them to LSI HBA on Ubuntu 22.04", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zymivp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672362467.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I also moved from mdadm to ZFS RAID, so it&amp;#39;s possible that this RAIDZv1 array idles more than the RAID10 array I used to have with the same four disks and I am noticing the spindown now vs before.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t understand why the drives are spinning down. I&amp;#39;ve used hdparm to set the -B value to 255 but it gets reset to 20 after a while. I set it in a udev rule so its set at boot up, but again, after a while, it&amp;#39;s back at 20.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have TLP or any other power management script/tool that I know of. The logs don&amp;#39;t show anything interesting. I&amp;#39;ve tried searching but there&amp;#39;s not a lot of info about not wanting the drives to sleep, usually it&amp;#39;s the opposite.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried setitng -S 0 along with -B 255 with hdparm. I updated /etc/hdparm.conf to set the APM value to 255 for each of my spinning drives. &lt;/p&gt;\n\n&lt;p&gt;Is there something else I&amp;#39;m missing that is changing the APM value of the drives?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zymivp", "is_robot_indexable": true, "report_reasons": null, "author": "motoridersd", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zymivp/wd_red_drives_sleeping_after_moving_them_to_lsi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zymivp/wd_red_drives_sleeping_after_moving_them_to_lsi/", "subreddit_subscribers": 662785, "created_utc": 1672362467.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I still use optical media for certain things and the one thing that I've never been able to find for sale but always use are the paper inserts that go into jewel cases, especially the front one (or the only one if you're using slim jewel cases).  I'm not a fan of making my own so I was wondering if anyone has ever come across nice lined jewel case inserts for sale (the slightly glossy ones like what you would get if you're buying Verbatim DVD-R discs individually packaged in jewel cases)?", "author_fullname": "t2_mgmtm9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Buy Jewel Case Inserts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zykyph", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672358545.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I still use optical media for certain things and the one thing that I&amp;#39;ve never been able to find for sale but always use are the paper inserts that go into jewel cases, especially the front one (or the only one if you&amp;#39;re using slim jewel cases).  I&amp;#39;m not a fan of making my own so I was wondering if anyone has ever come across nice lined jewel case inserts for sale (the slightly glossy ones like what you would get if you&amp;#39;re buying Verbatim DVD-R discs individually packaged in jewel cases)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zykyph", "is_robot_indexable": true, "report_reasons": null, "author": "HarryMuscle", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zykyph/buy_jewel_case_inserts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zykyph/buy_jewel_case_inserts/", "subreddit_subscribers": 662785, "created_utc": 1672358545.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Wondering if anyone has worked with a scraper for specifically TikTok Live streams. Looking to get as much as I can on donations, viewers, stream length, etc. Working on a school project on micro-tipping and the creator economy, been watching hours of TikTok live streams and cataloging all this manually. There's gotta be a better way right?", "author_fullname": "t2_178haw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "TikTok Live Scraper", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zyhtj1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672351172.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wondering if anyone has worked with a scraper for specifically TikTok Live streams. Looking to get as much as I can on donations, viewers, stream length, etc. Working on a school project on micro-tipping and the creator economy, been watching hours of TikTok live streams and cataloging all this manually. There&amp;#39;s gotta be a better way right?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zyhtj1", "is_robot_indexable": true, "report_reasons": null, "author": "mvthxw", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zyhtj1/tiktok_live_scraper/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zyhtj1/tiktok_live_scraper/", "subreddit_subscribers": 662785, "created_utc": 1672351172.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Im a bit new to data hoarding(this is my week's project while I am off work for the holiday), so please bear with me.  Generally my issue is the title. In my research I found a few threads in this sub that mentioned that MergerFS is generally better to be using than MhddFS - however those were from 4+ years ago.  Generally tho, I'm hoping theres something I can do to address the issue before attempting to get MergerFS working(unless theres a more preferred method without having to use RAID)\n\nThis system's aim is to both manage my media library, run Radarr/Sonarr, and run my emby server.  This is the system that I have to facilitate this - as well as a few other things, but im mostly focused on the media storage aspect right now.\n\n    $ neofetch\n           _,met$$$$$gg.          media@debian-desktop \n        ,g$$$$$$$$$$$$$$$P.       -------------------- \n      ,g$$P\"     \"\"\"Y$$.\".        OS: Debian GNU/Linux 11 (bullseye) x86_64 \n     ,$$P'              `$$$.     Host: Z97M-DS3H \n    ',$$P       ,ggs.     `$$b:   Kernel: 5.10.0-20-amd64 \n    `d$$'     ,$P\"'   .    $$$    Uptime: 1 day, 13 hours, 49 mins \n     $$P      d$'     ,    $$P    Packages: 1713 (dpkg) \n     $$:      $$.   -    ,d$$'    Shell: bash 5.1.4 \n     $$;      Y$b._   _,d$P'      Terminal: /dev/pts/0 \n     Y$$.    `.`\"Y$$$$P\"'         CPU: Intel i7-4790K (8) @ 4.400GHz \n     `$$b      \"-.__              GPU: Intel HD Graphics \n      `Y$$                        GPU: NVIDIA GeForce GTX 970 \n       `Y$$.                      Memory: 3383MiB / 31973MiB \n         `$$b.\n           `Y$$b.                                         \n              `\"Y$b._                                     \n                  `\"\"\"\n\nI currently have 4 drives that I have linked together using MhddFS:\n\n1. **1TB\\_a**\n2. **1TB\\_b**\n3. **5TB\\_a**\n4. **6TB\\_a**\n\nthese are the labels for each drive so I can add/replace/expand it later while representing the space they hold.  They are all NAS HDDs formatted to ext4. This is my fstab to mount them all to /media/storage\n\n    # 1TB(984G)\n    UUID=176d2030-96c7-4caa-9ffb-2662215565fc /media/media/1tb_a ext4 rw,user,exec 0 0\n    \n    # 1TB(984G)\n    UUID=6ea54fc3-0fd1-4fba-8754-5a71032e7f68 /media/media/1tb_b ext4 rw,user,exec 0 0\n    \n    # 5TB\n    UUID=e67b89c4-2399-48f2-b86f-81cf59fe4999 /media/media/5tb_a ext4 rw,user,exec 0 0\n    \n    # 6TB\n    UUID=0c111a21-7557-4291-a6df-fcee2deca935 /media/media/6tb_a ext4 rw,user,exec 0 0\n    \n    # use mhddfs to join all the /media/media/* drives into /media/storage\n    mhddfs#/media/media/1tb_a,/media/media/1tb_b,/media/media/5tb_a,/media/media/6tb_a /media/storage fuse defaults,default_permissions,allow_other 0 0\n\n^(I  regret having my main mount folder be /media AND having the \"media\" user be the owner of these mounts, but thats besides my issue(and its too late for me to bother changing it).)\n\nCurrently only **5TB\\_a** has any data(its 98% full) and the rest are empty because I abandoned parts of my chia farm^((what a waste of time that was hahaha)) to obtain the use of the 2 1TB drives and the 6TB drive in order to expand my storage.\n\nThis is where my issue comes in.  **5TB\\_a** holds my ./Movies and ./TV folders for my media collection for my emby server.  These folders gets filled either by manually backing up my blurays, or from Radarr/Sonarr + NZBGet.  I have the destination folders all set to be /media/storage/\\* thinking that if **5TB\\_a** gets full, the empty \"Movies\"/\"TV\" folder I have on **6TB\\_a** should then become the destination for file copies, but thats not the case.  Instead I get unrar errors inside NZBGet because the destination drive is full(I have downloads and repairs done on a different, faster, drive and then extracted directly to the /media/storage destination).\n\nFrom my understanding MhddFS should switch what drive its storing data in, but that seems to not be the case and so any help will be greatly appreciated!", "author_fullname": "t2_b55gf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Im using MhddFS but im getting write errors when one drive is full but others are free", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zyhnzk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1672351014.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672350809.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im a bit new to data hoarding(this is my week&amp;#39;s project while I am off work for the holiday), so please bear with me.  Generally my issue is the title. In my research I found a few threads in this sub that mentioned that MergerFS is generally better to be using than MhddFS - however those were from 4+ years ago.  Generally tho, I&amp;#39;m hoping theres something I can do to address the issue before attempting to get MergerFS working(unless theres a more preferred method without having to use RAID)&lt;/p&gt;\n\n&lt;p&gt;This system&amp;#39;s aim is to both manage my media library, run Radarr/Sonarr, and run my emby server.  This is the system that I have to facilitate this - as well as a few other things, but im mostly focused on the media storage aspect right now.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;$ neofetch\n       _,met$$$$$gg.          media@debian-desktop \n    ,g$$$$$$$$$$$$$$$P.       -------------------- \n  ,g$$P&amp;quot;     &amp;quot;&amp;quot;&amp;quot;Y$$.&amp;quot;.        OS: Debian GNU/Linux 11 (bullseye) x86_64 \n ,$$P&amp;#39;              `$$$.     Host: Z97M-DS3H \n&amp;#39;,$$P       ,ggs.     `$$b:   Kernel: 5.10.0-20-amd64 \n`d$$&amp;#39;     ,$P&amp;quot;&amp;#39;   .    $$$    Uptime: 1 day, 13 hours, 49 mins \n $$P      d$&amp;#39;     ,    $$P    Packages: 1713 (dpkg) \n $$:      $$.   -    ,d$$&amp;#39;    Shell: bash 5.1.4 \n $$;      Y$b._   _,d$P&amp;#39;      Terminal: /dev/pts/0 \n Y$$.    `.`&amp;quot;Y$$$$P&amp;quot;&amp;#39;         CPU: Intel i7-4790K (8) @ 4.400GHz \n `$$b      &amp;quot;-.__              GPU: Intel HD Graphics \n  `Y$$                        GPU: NVIDIA GeForce GTX 970 \n   `Y$$.                      Memory: 3383MiB / 31973MiB \n     `$$b.\n       `Y$$b.                                         \n          `&amp;quot;Y$b._                                     \n              `&amp;quot;&amp;quot;&amp;quot;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I currently have 4 drives that I have linked together using MhddFS:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;1TB_a&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;1TB_b&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;5TB_a&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;6TB_a&lt;/strong&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;these are the labels for each drive so I can add/replace/expand it later while representing the space they hold.  They are all NAS HDDs formatted to ext4. This is my fstab to mount them all to /media/storage&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;# 1TB(984G)\nUUID=176d2030-96c7-4caa-9ffb-2662215565fc /media/media/1tb_a ext4 rw,user,exec 0 0\n\n# 1TB(984G)\nUUID=6ea54fc3-0fd1-4fba-8754-5a71032e7f68 /media/media/1tb_b ext4 rw,user,exec 0 0\n\n# 5TB\nUUID=e67b89c4-2399-48f2-b86f-81cf59fe4999 /media/media/5tb_a ext4 rw,user,exec 0 0\n\n# 6TB\nUUID=0c111a21-7557-4291-a6df-fcee2deca935 /media/media/6tb_a ext4 rw,user,exec 0 0\n\n# use mhddfs to join all the /media/media/* drives into /media/storage\nmhddfs#/media/media/1tb_a,/media/media/1tb_b,/media/media/5tb_a,/media/media/6tb_a /media/storage fuse defaults,default_permissions,allow_other 0 0\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;sup&gt;I  regret having my main mount folder be /media AND having the &amp;quot;media&amp;quot; user be the owner of these mounts, but thats besides my issue(and its too late for me to bother changing it&lt;/sup&gt;.)&lt;/p&gt;\n\n&lt;p&gt;Currently only &lt;strong&gt;5TB_a&lt;/strong&gt; has any data(its 98% full) and the rest are empty because I abandoned parts of my chia farm&lt;sup&gt;(what a waste of time that was hahaha&lt;/sup&gt;) to obtain the use of the 2 1TB drives and the 6TB drive in order to expand my storage.&lt;/p&gt;\n\n&lt;p&gt;This is where my issue comes in.  &lt;strong&gt;5TB_a&lt;/strong&gt; holds my ./Movies and ./TV folders for my media collection for my emby server.  These folders gets filled either by manually backing up my blurays, or from Radarr/Sonarr + NZBGet.  I have the destination folders all set to be /media/storage/* thinking that if &lt;strong&gt;5TB_a&lt;/strong&gt; gets full, the empty &amp;quot;Movies&amp;quot;/&amp;quot;TV&amp;quot; folder I have on &lt;strong&gt;6TB_a&lt;/strong&gt; should then become the destination for file copies, but thats not the case.  Instead I get unrar errors inside NZBGet because the destination drive is full(I have downloads and repairs done on a different, faster, drive and then extracted directly to the /media/storage destination).&lt;/p&gt;\n\n&lt;p&gt;From my understanding MhddFS should switch what drive its storing data in, but that seems to not be the case and so any help will be greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zyhnzk", "is_robot_indexable": true, "report_reasons": null, "author": "RetroZelda", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zyhnzk/im_using_mhddfs_but_im_getting_write_errors_when/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zyhnzk/im_using_mhddfs_but_im_getting_write_errors_when/", "subreddit_subscribers": 662785, "created_utc": 1672350809.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello i tried downloading a sub reddit with wget and I think it started downloading all of reddit subs lmao, can give me a tool that will work on linux?", "author_fullname": "t2_7b9dfds8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "can you tell me of a tool that will download a whole sub", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zygvcx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1672349720.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672348943.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello i tried downloading a sub reddit with wget and I think it started downloading all of reddit subs lmao, can give me a tool that will work on linux?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zygvcx", "is_robot_indexable": true, "report_reasons": null, "author": "Tempestofchoas", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zygvcx/can_you_tell_me_of_a_tool_that_will_download_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zygvcx/can_you_tell_me_of_a_tool_that_will_download_a/", "subreddit_subscribers": 662785, "created_utc": 1672348943.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I did a search of the sub and every post that talks about archiving floppy disks talks about making images but the only software I've found mentioned is $60 (us) (or making images by reading magnetic flux directly with hardware).\n     \nIs there an open source windows app to do this or should I just install linux on a box and use dd?\n\nThanks\n\nEDIT: \nargh... lerge is somewhere between 1 and 4 k", "author_fullname": "t2_7568a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help please? I want to image a lerge number of msdos/win floppies, I have hardware and need software advice.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zyelqw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1672343760.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672343564.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I did a search of the sub and every post that talks about archiving floppy disks talks about making images but the only software I&amp;#39;ve found mentioned is $60 (us) (or making images by reading magnetic flux directly with hardware).&lt;/p&gt;\n\n&lt;p&gt;Is there an open source windows app to do this or should I just install linux on a box and use dd?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n\n&lt;p&gt;EDIT: \nargh... lerge is somewhere between 1 and 4 k&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zyelqw", "is_robot_indexable": true, "report_reasons": null, "author": "Captain_Patchy", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zyelqw/help_please_i_want_to_image_a_lerge_number_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zyelqw/help_please_i_want_to_image_a_lerge_number_of/", "subreddit_subscribers": 662785, "created_utc": 1672343564.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I own a Panasonic dmr-eh545 and I don\u00b4t want to burn 30 DVDs.\nDoes anybody know how I can transfer files on the recorder's hard drive directly to a PC/External HDD?\n\nOr is it only possible to first burn to (multiple) DVDs and then again from the DVD to the PC?", "author_fullname": "t2_rvf40mz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Panasonic dmr-eh545 direktly to external HDD / PC?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zy66qu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672322682.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I own a Panasonic dmr-eh545 and I don\u00b4t want to burn 30 DVDs.\nDoes anybody know how I can transfer files on the recorder&amp;#39;s hard drive directly to a PC/External HDD?&lt;/p&gt;\n\n&lt;p&gt;Or is it only possible to first burn to (multiple) DVDs and then again from the DVD to the PC?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zy66qu", "is_robot_indexable": true, "report_reasons": null, "author": "Daidalos99", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zy66qu/panasonic_dmreh545_direktly_to_external_hdd_pc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zy66qu/panasonic_dmreh545_direktly_to_external_hdd_pc/", "subreddit_subscribers": 662785, "created_utc": 1672322682.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019m pretty lost with all the different HDD\u2019s to choose from\u2026 atm I hav a mid 2015 MacBook Pro which is compatible with USB A, but I\u2019m looking to upgrade to a M1 MacBook Pro in the future which supports USB C, so I\u2019m looking for a HDD which supports both.\n\nI jus need a reliable one, not too expensive, has password encryption, decent read/write, portable size. (I have a Samsung T7 SSD for active storage, but I need a HDD for whole system storage backups/Time machine on the MacBook)\n\nI was looking at - Seagate Ultra Touch, is this any good? It looks like it has everything I need, but recent reviews are mixed on Amazon\u2026\n\nAny help wud be much appreciated", "author_fullname": "t2_2n0pokm1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What would u recommend for a backup storage External HDD?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zyx9pc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672395974.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m pretty lost with all the different HDD\u2019s to choose from\u2026 atm I hav a mid 2015 MacBook Pro which is compatible with USB A, but I\u2019m looking to upgrade to a M1 MacBook Pro in the future which supports USB C, so I\u2019m looking for a HDD which supports both.&lt;/p&gt;\n\n&lt;p&gt;I jus need a reliable one, not too expensive, has password encryption, decent read/write, portable size. (I have a Samsung T7 SSD for active storage, but I need a HDD for whole system storage backups/Time machine on the MacBook)&lt;/p&gt;\n\n&lt;p&gt;I was looking at - Seagate Ultra Touch, is this any good? It looks like it has everything I need, but recent reviews are mixed on Amazon\u2026&lt;/p&gt;\n\n&lt;p&gt;Any help wud be much appreciated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zyx9pc", "is_robot_indexable": true, "report_reasons": null, "author": "2Naughtyy", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zyx9pc/what_would_u_recommend_for_a_backup_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zyx9pc/what_would_u_recommend_for_a_backup_storage/", "subreddit_subscribers": 662785, "created_utc": 1672395974.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}