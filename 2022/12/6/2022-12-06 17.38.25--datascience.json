{"kind": "Listing", "data": {"after": null, "dist": 22, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My company did a layoff recently, and DS teams were heavily affected, so understandably most people around me are very pessimistic about the current market and whether data science will even continue to exist in the future. I'm thinking of leaving the company, since it seems like a sinking ship (with one possible successful strategy, which is not certain and I don't think it's worth getting into details), but I'm afraid of going somewhere else and not surviving a second layoff. Moreover, I've been hearing more and more about people trying to switch to roles that seem more stable such as PM or software engineering.\n\nI like my current role, which is basically a well paid data analyst with statistical rigour, if possible I wouldn't want to pivot to another path, but I would like to hear other people's opinion whether this kind of role will even exist in the future and if it's worth looking for other jobs in the current market.", "author_fullname": "t2_usateyld", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you feel about the current job market and the future of data science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zdmah6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 95, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 95, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670279512.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company did a layoff recently, and DS teams were heavily affected, so understandably most people around me are very pessimistic about the current market and whether data science will even continue to exist in the future. I&amp;#39;m thinking of leaving the company, since it seems like a sinking ship (with one possible successful strategy, which is not certain and I don&amp;#39;t think it&amp;#39;s worth getting into details), but I&amp;#39;m afraid of going somewhere else and not surviving a second layoff. Moreover, I&amp;#39;ve been hearing more and more about people trying to switch to roles that seem more stable such as PM or software engineering.&lt;/p&gt;\n\n&lt;p&gt;I like my current role, which is basically a well paid data analyst with statistical rigour, if possible I wouldn&amp;#39;t want to pivot to another path, but I would like to hear other people&amp;#39;s opinion whether this kind of role will even exist in the future and if it&amp;#39;s worth looking for other jobs in the current market.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 150, "id": "award_f44611f1-b89e-46dc-97fe-892280b13b82", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Thank you stranger. Shows the award.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Helpful", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zdmah6", "is_robot_indexable": true, "report_reasons": null, "author": "layoffthrowawayds", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zdmah6/how_do_you_feel_about_the_current_job_market_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zdmah6/how_do_you_feel_about_the_current_job_market_and/", "subreddit_subscribers": 824144, "created_utc": 1670279512.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm consulting for biotech company that basically wants me to connect their clinical database and a couple public databases to a new database, a dashboarding program and develop some basic metrics/ML capability. They want this done within 6 weeks.\n\nI said fine, my plan is to stand up a bunch of docker pipelines in kubernetes connected to a cloud DB in azure.\n\nThey gave me an 8 core ubuntu vm with admin access and told me to use that. They refuse to give me any access keys or create any specific roles or resource groups. I don't/can't manage the VM.\n\nI had most of the pipelines and dashboard working locally via docker images. Now I've spent 2 days trying to move the VM mySQL database to an attached drive that has weird permissions. I'm particularly worried I'll have to redo everything if the VM goes down rather than taking a modern infrastructure as code approach. \n\nShould I push back here or am I being picky?", "author_fullname": "t2_blel3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to push back on client making poor infrastructure decisions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zdgg10", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 82, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 82, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670267750.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m consulting for biotech company that basically wants me to connect their clinical database and a couple public databases to a new database, a dashboarding program and develop some basic metrics/ML capability. They want this done within 6 weeks.&lt;/p&gt;\n\n&lt;p&gt;I said fine, my plan is to stand up a bunch of docker pipelines in kubernetes connected to a cloud DB in azure.&lt;/p&gt;\n\n&lt;p&gt;They gave me an 8 core ubuntu vm with admin access and told me to use that. They refuse to give me any access keys or create any specific roles or resource groups. I don&amp;#39;t/can&amp;#39;t manage the VM.&lt;/p&gt;\n\n&lt;p&gt;I had most of the pipelines and dashboard working locally via docker images. Now I&amp;#39;ve spent 2 days trying to move the VM mySQL database to an attached drive that has weird permissions. I&amp;#39;m particularly worried I&amp;#39;ll have to redo everything if the VM goes down rather than taking a modern infrastructure as code approach. &lt;/p&gt;\n\n&lt;p&gt;Should I push back here or am I being picky?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zdgg10", "is_robot_indexable": true, "report_reasons": null, "author": "po-handz", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zdgg10/how_to_push_back_on_client_making_poor/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zdgg10/how_to_push_back_on_client_making_poor/", "subreddit_subscribers": 824144, "created_utc": 1670267750.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "About a year ago, I started the Data Engineering path for the dataquest course using Python. Unfortunately I only got half way through before I had to stop due to a new job and some personal things that kept me occupied. \n\nNow as I'm trying to go back, I find it that I have forgotten a lot of it. And I've noticed that this has happened a lot to me unfortunately. Because I don't have a job that requires me to actually use anything I've learned, as soon as I stop getting exposures to it much, I begin to forget. \n\nAny suggestions on how to keep my knowledge up? I tried to use codewars but I found the site to be confusing and didn't know how to use it.", "author_fullname": "t2_mths17na", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommen dations for keeping your knowledge when not using it often?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zdlwmg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670278733.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;About a year ago, I started the Data Engineering path for the dataquest course using Python. Unfortunately I only got half way through before I had to stop due to a new job and some personal things that kept me occupied. &lt;/p&gt;\n\n&lt;p&gt;Now as I&amp;#39;m trying to go back, I find it that I have forgotten a lot of it. And I&amp;#39;ve noticed that this has happened a lot to me unfortunately. Because I don&amp;#39;t have a job that requires me to actually use anything I&amp;#39;ve learned, as soon as I stop getting exposures to it much, I begin to forget. &lt;/p&gt;\n\n&lt;p&gt;Any suggestions on how to keep my knowledge up? I tried to use codewars but I found the site to be confusing and didn&amp;#39;t know how to use it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zdlwmg", "is_robot_indexable": true, "report_reasons": null, "author": "iguesswhatevs", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zdlwmg/recommen_dations_for_keeping_your_knowledge_when/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zdlwmg/recommen_dations_for_keeping_your_knowledge_when/", "subreddit_subscribers": 824144, "created_utc": 1670278733.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I think it would serve as some motivation for those still unsure about this field.", "author_fullname": "t2_hdzfjl9d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some cool projects/tasks you got to do as a data scientist/analyst?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ze7o1g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670335576.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I think it would serve as some motivation for those still unsure about this field.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ze7o1g", "is_robot_indexable": true, "report_reasons": null, "author": "atom-bit", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ze7o1g/what_are_some_cool_projectstasks_you_got_to_do_as/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ze7o1g/what_are_some_cool_projectstasks_you_got_to_do_as/", "subreddit_subscribers": 824144, "created_utc": 1670335576.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello all,\n\nFor educational purposes, I want to build a model for the automatic generation of insights from a multi-dimensional dataset. Something similar to what Google Analytics v4 and Microsoft Power BI already have as a built-in feature. To identify interesting dependencies, identify patterns.\n\nI understand that there can be a complex architecture here (ranking insights by importance, and creating a narrative). I want to start and build at least a core processing and pattern retrieval.\n\nAre there any ready-made/half-ready libraries for this?  \nAny tips would be appreciated\n\nReferences:\n\n&amp;#x200B;\n\nhttps://preview.redd.it/8p9ua029v94a1.png?width=2672&amp;format=png&amp;auto=webp&amp;s=5728f462aebf0fba0e063151cfcc277730f39418\n\nhttps://preview.redd.it/qc6sywm9v94a1.png?width=499&amp;format=png&amp;auto=webp&amp;s=810c4dc0b553753e18790a95be669971df352c6c", "author_fullname": "t2_i6fbtzj3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "to develop a system that automatically extracts insights from a dataset?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 71, "top_awarded_type": null, "hide_score": false, "media_metadata": {"8p9ua029v94a1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 55, "x": 108, "u": "https://preview.redd.it/8p9ua029v94a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=70b87a508f8d9683ee79b70705933e6d130234a5"}, {"y": 110, "x": 216, "u": "https://preview.redd.it/8p9ua029v94a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b9a7b21caa73c19b79cc0e1b238029cec3f4eeaa"}, {"y": 163, "x": 320, "u": "https://preview.redd.it/8p9ua029v94a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=1e7525aeeb08c020e7e3219411c8d862e588a7cf"}, {"y": 326, "x": 640, "u": "https://preview.redd.it/8p9ua029v94a1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=61d4cd18daa708bedc9753d43e57b84bb0d25e29"}, {"y": 489, "x": 960, "u": "https://preview.redd.it/8p9ua029v94a1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e3fcd192438325a9bda1c9db8267f2e2579e7371"}, {"y": 550, "x": 1080, "u": "https://preview.redd.it/8p9ua029v94a1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=26bcc53cc111e7b8b24fe42744a0eeeed6ec8a25"}], "s": {"y": 1362, "x": 2672, "u": "https://preview.redd.it/8p9ua029v94a1.png?width=2672&amp;format=png&amp;auto=webp&amp;s=5728f462aebf0fba0e063151cfcc277730f39418"}, "id": "8p9ua029v94a1"}, "qc6sywm9v94a1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 141, "x": 108, "u": "https://preview.redd.it/qc6sywm9v94a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=46a999b8d0203ec5f03c132aa27b7fa67004bc6b"}, {"y": 283, "x": 216, "u": "https://preview.redd.it/qc6sywm9v94a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0f57899162c9819f8323a0cbd8f63df70046f792"}, {"y": 420, "x": 320, "u": "https://preview.redd.it/qc6sywm9v94a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b2db74ca89eac4e91ce8e503effb243525c05315"}], "s": {"y": 656, "x": 499, "u": "https://preview.redd.it/qc6sywm9v94a1.png?width=499&amp;format=png&amp;auto=webp&amp;s=810c4dc0b553753e18790a95be669971df352c6c"}, "id": "qc6sywm9v94a1"}}, "name": "t3_ze5kky", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Zc88lXRi79vBro0fJt6PwC-YxggmSdW9kCGvckcUefQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670330066.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;For educational purposes, I want to build a model for the automatic generation of insights from a multi-dimensional dataset. Something similar to what Google Analytics v4 and Microsoft Power BI already have as a built-in feature. To identify interesting dependencies, identify patterns.&lt;/p&gt;\n\n&lt;p&gt;I understand that there can be a complex architecture here (ranking insights by importance, and creating a narrative). I want to start and build at least a core processing and pattern retrieval.&lt;/p&gt;\n\n&lt;p&gt;Are there any ready-made/half-ready libraries for this?&lt;br/&gt;\nAny tips would be appreciated&lt;/p&gt;\n\n&lt;p&gt;References:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/8p9ua029v94a1.png?width=2672&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5728f462aebf0fba0e063151cfcc277730f39418\"&gt;https://preview.redd.it/8p9ua029v94a1.png?width=2672&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5728f462aebf0fba0e063151cfcc277730f39418&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/qc6sywm9v94a1.png?width=499&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=810c4dc0b553753e18790a95be669971df352c6c\"&gt;https://preview.redd.it/qc6sywm9v94a1.png?width=499&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=810c4dc0b553753e18790a95be669971df352c6c&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ze5kky", "is_robot_indexable": true, "report_reasons": null, "author": "TwoJust2961", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ze5kky/to_develop_a_system_that_automatically_extracts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ze5kky/to_develop_a_system_that_automatically_extracts/", "subreddit_subscribers": 824144, "created_utc": 1670330066.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi! I'm not experienced in data analysis and was wondering if I could find ideas on how to solve a problem from here. Basically, I want to compare the accuracy of two predictors. Me and my flatmate started watching a reality show and we're trying to guess the order in which the participants are eliminated. We both ranked the participants in the order we think they'll be eliminated. I need a tool for comparing which of us did better in the end and it needs to be accurate because the stakes are very high (we made a bet). I guess I could do Spearman's correlation but is there a better way to compare our accuracies? We agreed that you get additional points for correctly guessing 1st and 2nd place. Otherwise I think it would make sense to assign points for each correct guess. But what if neither of us get any placing exactly right, is there then a way to model how close to accurate we were? I hope this makes sense. I was hoping to use Matlab for this (just because I'm trying to learn it). Many thanks in advance!", "author_fullname": "t2_t0j9ehgn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to compare predictive accuracy?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ze2n1e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1670322413.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670321903.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I&amp;#39;m not experienced in data analysis and was wondering if I could find ideas on how to solve a problem from here. Basically, I want to compare the accuracy of two predictors. Me and my flatmate started watching a reality show and we&amp;#39;re trying to guess the order in which the participants are eliminated. We both ranked the participants in the order we think they&amp;#39;ll be eliminated. I need a tool for comparing which of us did better in the end and it needs to be accurate because the stakes are very high (we made a bet). I guess I could do Spearman&amp;#39;s correlation but is there a better way to compare our accuracies? We agreed that you get additional points for correctly guessing 1st and 2nd place. Otherwise I think it would make sense to assign points for each correct guess. But what if neither of us get any placing exactly right, is there then a way to model how close to accurate we were? I hope this makes sense. I was hoping to use Matlab for this (just because I&amp;#39;m trying to learn it). Many thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ze2n1e", "is_robot_indexable": true, "report_reasons": null, "author": "jojovaan", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ze2n1e/how_to_compare_predictive_accuracy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ze2n1e/how_to_compare_predictive_accuracy/", "subreddit_subscribers": 824144, "created_utc": 1670321903.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a new grad who went through the hiring process for multiple companies.\n\nDuring my application cycle I have received an offer from a consulting firm. The role is okay, and is a good position as a DS.\n\nThat being said I have also interviewed with another company and have made it past the 3 rounds of interviews. \n\nIn the first round I worked with the senior DS manager and passed the live code test and business case.\n\nIn the second case I have presented a solution to a use case. They only wanted ideas but I have went above and beyond and gave them a proof of concept for how I would solve a problem without access to their data. They were very interested and they said it is in line with what they actually do. Since they were interested I have given them an MVP solution dashboard that is build on the data extraction pipeline I have built for better sources of data. (I have interned with them and know the ins and out of using apis for data extraction with emphasis on how IT handles requests as well).\n\nSo far so good,\n\n\nIn the third round however the director gives me a bad vibe saying that while my professional experience was in time-series I am not really worked with their algorithms. I have worked with the algorithms and passed the technical portion tho,and have the qualifications but despite this he doesn\u2019t consider that all my experience is not real experience as its not identical to everything they do. Despite the fact I have built everything and have an extensive portfolio about the stuff. Wouldn\u2019t it be possible to learn whatever Im missing as I already know the base and I can learn the fine details with training? The senior manager said that in the first interview that I can learn the rest?\n\nIm not really sure, but I am thinking if it is possible to leverage my already existing offer to make them more proactive.\n\n\nHave you dealt with this before and how would you handle this.", "author_fullname": "t2_2sm7vahg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dealing with nontechnical bosses and putting pressure on employers for offers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zdoi1n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670284053.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a new grad who went through the hiring process for multiple companies.&lt;/p&gt;\n\n&lt;p&gt;During my application cycle I have received an offer from a consulting firm. The role is okay, and is a good position as a DS.&lt;/p&gt;\n\n&lt;p&gt;That being said I have also interviewed with another company and have made it past the 3 rounds of interviews. &lt;/p&gt;\n\n&lt;p&gt;In the first round I worked with the senior DS manager and passed the live code test and business case.&lt;/p&gt;\n\n&lt;p&gt;In the second case I have presented a solution to a use case. They only wanted ideas but I have went above and beyond and gave them a proof of concept for how I would solve a problem without access to their data. They were very interested and they said it is in line with what they actually do. Since they were interested I have given them an MVP solution dashboard that is build on the data extraction pipeline I have built for better sources of data. (I have interned with them and know the ins and out of using apis for data extraction with emphasis on how IT handles requests as well).&lt;/p&gt;\n\n&lt;p&gt;So far so good,&lt;/p&gt;\n\n&lt;p&gt;In the third round however the director gives me a bad vibe saying that while my professional experience was in time-series I am not really worked with their algorithms. I have worked with the algorithms and passed the technical portion tho,and have the qualifications but despite this he doesn\u2019t consider that all my experience is not real experience as its not identical to everything they do. Despite the fact I have built everything and have an extensive portfolio about the stuff. Wouldn\u2019t it be possible to learn whatever Im missing as I already know the base and I can learn the fine details with training? The senior manager said that in the first interview that I can learn the rest?&lt;/p&gt;\n\n&lt;p&gt;Im not really sure, but I am thinking if it is possible to leverage my already existing offer to make them more proactive.&lt;/p&gt;\n\n&lt;p&gt;Have you dealt with this before and how would you handle this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zdoi1n", "is_robot_indexable": true, "report_reasons": null, "author": "Tarneks", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zdoi1n/dealing_with_nontechnical_bosses_and_putting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zdoi1n/dealing_with_nontechnical_bosses_and_putting/", "subreddit_subscribers": 824144, "created_utc": 1670284053.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Being confronted with a clustering task at work, I'm facing the multitude of clustering methods over there. I'm wondering if it exists a R package or Python library that, for a given dataset, computes different clustering methods and return clustering validation metrics for each method.  \nOr am I meant to try them all to find the one that best suits my data? ", "author_fullname": "t2_p0k4n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Comparing clustering algorithms", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ze7iv4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670335211.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Being confronted with a clustering task at work, I&amp;#39;m facing the multitude of clustering methods over there. I&amp;#39;m wondering if it exists a R package or Python library that, for a given dataset, computes different clustering methods and return clustering validation metrics for each method.&lt;br/&gt;\nOr am I meant to try them all to find the one that best suits my data? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ze7iv4", "is_robot_indexable": true, "report_reasons": null, "author": "Dashtikazar", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ze7iv4/comparing_clustering_algorithms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ze7iv4/comparing_clustering_algorithms/", "subreddit_subscribers": 824144, "created_utc": 1670335211.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,\n\nAs the title describes, I have been given an opportunity to work on developing a Knowledge Graph project and wanted to understand how this skill can help me grow. Is this something that is in a lot of demand? I am planning to take up the project nevertheless because its just so cool; but wanted to understand from a career point of view. \n\n&amp;#x200B;\n\nThanks!", "author_fullname": "t2_123jiosa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Q] Is working with Neo4J and Cypher (knowledge graph) a really good skill to have if you want to grow as a NLP data scientist?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ze6pbv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670332984.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;As the title describes, I have been given an opportunity to work on developing a Knowledge Graph project and wanted to understand how this skill can help me grow. Is this something that is in a lot of demand? I am planning to take up the project nevertheless because its just so cool; but wanted to understand from a career point of view. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ze6pbv", "is_robot_indexable": true, "report_reasons": null, "author": "Dump7", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ze6pbv/q_is_working_with_neo4j_and_cypher_knowledge/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ze6pbv/q_is_working_with_neo4j_and_cypher_knowledge/", "subreddit_subscribers": 824144, "created_utc": 1670332984.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey y\u2019all! \nI\u2019m writing scientific paper for my university and am interested in learning more about how people go about annotating their data for further model training. \n\n1. How do you do data labelling? (Tools, approaches)\n2. What do you find hard?\n3. How often you have to do it?\n4. Why is it so important to you / your company?    \n5. Have you tried solving this problem yourself? \n\nThanks! \ud83d\udd1d", "author_fullname": "t2_8mctjrtd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you go about labelling your data? Do you find it easy or hard?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ze487x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670326484.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey y\u2019all! \nI\u2019m writing scientific paper for my university and am interested in learning more about how people go about annotating their data for further model training. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;How do you do data labelling? (Tools, approaches)&lt;/li&gt;\n&lt;li&gt;What do you find hard?&lt;/li&gt;\n&lt;li&gt;How often you have to do it?&lt;/li&gt;\n&lt;li&gt;Why is it so important to you / your company?&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;Have you tried solving this problem yourself? &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thanks! \ud83d\udd1d&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ze487x", "is_robot_indexable": true, "report_reasons": null, "author": "Dull-Low-6618", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ze487x/how_do_you_go_about_labelling_your_data_do_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ze487x/how_do_you_go_about_labelling_your_data_do_you/", "subreddit_subscribers": 824144, "created_utc": 1670326484.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I have about 1m data set with 25 attributes. I wanted to know how can I either segment the data or can i take 1% or 10% of the dataset. Like how do i tell which approach to go to? Target is a simple 3 state classification model and the dataset mostly contains  numerical data.", "author_fullname": "t2_amimzgo5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to segment data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zdzv7s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670313453.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have about 1m data set with 25 attributes. I wanted to know how can I either segment the data or can i take 1% or 10% of the dataset. Like how do i tell which approach to go to? Target is a simple 3 state classification model and the dataset mostly contains  numerical data.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zdzv7s", "is_robot_indexable": true, "report_reasons": null, "author": "Old_Stick_9560", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zdzv7s/how_to_segment_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zdzv7s/how_to_segment_data/", "subreddit_subscribers": 824144, "created_utc": 1670313453.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi! I like to branch out to data science/AI proprietary based systems in supply chain industry.\n\nBut coming from a background that is used to do mostly coding, naturally I find complete black box/click and drop solutions to be not so interesting.\n\nIf I check Gartner for supply chain systems, some names come up like Kinaxis, Blue Yonder, O9, etc. But these seems to be dedicated or designed for non data science users.\n\nSo are there supply chain systems/softwares build mainly for data science audience?\n\nIdeally these platforms still allow certain level of coding as well. Certification path is also interesting.", "author_fullname": "t2_4bix301o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the top proprietary systems for supply chain applying AI/Data Science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zdxt1p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670307553.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I like to branch out to data science/AI proprietary based systems in supply chain industry.&lt;/p&gt;\n\n&lt;p&gt;But coming from a background that is used to do mostly coding, naturally I find complete black box/click and drop solutions to be not so interesting.&lt;/p&gt;\n\n&lt;p&gt;If I check Gartner for supply chain systems, some names come up like Kinaxis, Blue Yonder, O9, etc. But these seems to be dedicated or designed for non data science users.&lt;/p&gt;\n\n&lt;p&gt;So are there supply chain systems/softwares build mainly for data science audience?&lt;/p&gt;\n\n&lt;p&gt;Ideally these platforms still allow certain level of coding as well. Certification path is also interesting.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zdxt1p", "is_robot_indexable": true, "report_reasons": null, "author": "levenshteinn", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zdxt1p/what_are_the_top_proprietary_systems_for_supply/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zdxt1p/what_are_the_top_proprietary_systems_for_supply/", "subreddit_subscribers": 824144, "created_utc": 1670307553.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have daily/monthly sales data spanning a couple of years. \n\nI am trying to develop a running 4 month forecast for demand planning.  \n\nObviously, if there is no inventory due to a problem in logistics for a specific month, the forecast will be way off, and when the inventory problem is solved, the sales for the next month dramatically increase because of freed up inventory.  \n\nExample: My model is forecasting a higher amount for November 2022 because in November 2021 we received stuck inventory and my model is now thinking we'll have similar sales when in fact it was simply because of \"freed up inventory\". \n\nDoes simply adding the inventory levels help the model adjust to this variable?", "author_fullname": "t2_pgekz9xq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Adding inventory levels regressor to Prophet to forecast sales", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zdm4j8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670279179.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have daily/monthly sales data spanning a couple of years. &lt;/p&gt;\n\n&lt;p&gt;I am trying to develop a running 4 month forecast for demand planning.  &lt;/p&gt;\n\n&lt;p&gt;Obviously, if there is no inventory due to a problem in logistics for a specific month, the forecast will be way off, and when the inventory problem is solved, the sales for the next month dramatically increase because of freed up inventory.  &lt;/p&gt;\n\n&lt;p&gt;Example: My model is forecasting a higher amount for November 2022 because in November 2021 we received stuck inventory and my model is now thinking we&amp;#39;ll have similar sales when in fact it was simply because of &amp;quot;freed up inventory&amp;quot;. &lt;/p&gt;\n\n&lt;p&gt;Does simply adding the inventory levels help the model adjust to this variable?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zdm4j8", "is_robot_indexable": true, "report_reasons": null, "author": "realbigflavor", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zdm4j8/adding_inventory_levels_regressor_to_prophet_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zdm4j8/adding_inventory_levels_regressor_to_prophet_to/", "subreddit_subscribers": 824144, "created_utc": 1670279179.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\nI work for a product based company as a data analyst. My manager wants me to find out a benchmark  of how to plan our paid marketing campaigns with Influencers on YouTube and Instagram.\n\nMy manager wants me tell him an **ideal number of followers and cost** we should we invest based on some historical data that we have. Example of data is below.\n\nI want to know creating a number/benchmark is even possible?\n\nI think this problem can be solved if we make a custom function and use our desired results as inputs and outputs should be Cost and Followers. But how to even approach that? \n\nAnd I know obv this can be solved through ML but have very little knowledge about that. Im pretty good at pandas though. If someone can guide me how to solve this would be really helpful.\n\nAny kind of help is really appreciated. Thanks!\n\nhttps://preview.redd.it/6rno8usk444a1.png?width=3023&amp;format=png&amp;auto=webp&amp;s=21bf2daaae5add876e81478ac6084728922e8730", "author_fullname": "t2_cim5rbri", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Difficult business problem from my manager", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 15, "top_awarded_type": null, "hide_score": false, "media_metadata": {"6rno8usk444a1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 12, "x": 108, "u": "https://preview.redd.it/6rno8usk444a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d6daebf7694e43722fa1d61be2a6ff017d7158e4"}, {"y": 24, "x": 216, "u": "https://preview.redd.it/6rno8usk444a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=bbc864ca5a19afc239e1f889aabb934b4f234c0e"}, {"y": 36, "x": 320, "u": "https://preview.redd.it/6rno8usk444a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=819589cbc7966012afb895f82ce3a9b51d9c31ea"}, {"y": 73, "x": 640, "u": "https://preview.redd.it/6rno8usk444a1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7d563bb533f485a06318daddc3b38ca240d980fe"}, {"y": 109, "x": 960, "u": "https://preview.redd.it/6rno8usk444a1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=cd8db0ff7776bf6bb52b24e9cee911af967827a7"}, {"y": 123, "x": 1080, "u": "https://preview.redd.it/6rno8usk444a1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1028991d24497fa5b8ed839d6eaf7f62f266f293"}], "s": {"y": 345, "x": 3023, "u": "https://preview.redd.it/6rno8usk444a1.png?width=3023&amp;format=png&amp;auto=webp&amp;s=21bf2daaae5add876e81478ac6084728922e8730"}, "id": "6rno8usk444a1"}}, "name": "t3_zdd6ea", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/bwvtYt4OVwZWwzaqGZM4h10zeu8toVmuOGZDq0L2ANQ.jpg", "edited": 1670268932.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1670261128.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I work for a product based company as a data analyst. My manager wants me to find out a benchmark  of how to plan our paid marketing campaigns with Influencers on YouTube and Instagram.&lt;/p&gt;\n\n&lt;p&gt;My manager wants me tell him an &lt;strong&gt;ideal number of followers and cost&lt;/strong&gt; we should we invest based on some historical data that we have. Example of data is below.&lt;/p&gt;\n\n&lt;p&gt;I want to know creating a number/benchmark is even possible?&lt;/p&gt;\n\n&lt;p&gt;I think this problem can be solved if we make a custom function and use our desired results as inputs and outputs should be Cost and Followers. But how to even approach that? &lt;/p&gt;\n\n&lt;p&gt;And I know obv this can be solved through ML but have very little knowledge about that. Im pretty good at pandas though. If someone can guide me how to solve this would be really helpful.&lt;/p&gt;\n\n&lt;p&gt;Any kind of help is really appreciated. Thanks!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/6rno8usk444a1.png?width=3023&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=21bf2daaae5add876e81478ac6084728922e8730\"&gt;https://preview.redd.it/6rno8usk444a1.png?width=3023&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=21bf2daaae5add876e81478ac6084728922e8730&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/CZZHEQDcSZXyl_gJ5LHBr4TogsA0RO3U8jkSHEACOWw.png?auto=webp&amp;s=891dadd2e532597aa7296fae761d5ec351a23a96", "width": 3023, "height": 345}, "resolutions": [{"url": "https://external-preview.redd.it/CZZHEQDcSZXyl_gJ5LHBr4TogsA0RO3U8jkSHEACOWw.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1ac5989c6dc32455c61b9fa51de23d2384f945ab", "width": 108, "height": 12}, {"url": "https://external-preview.redd.it/CZZHEQDcSZXyl_gJ5LHBr4TogsA0RO3U8jkSHEACOWw.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2e2a52da04ee6e6118f4d89433e5457eb9d3d466", "width": 216, "height": 24}, {"url": "https://external-preview.redd.it/CZZHEQDcSZXyl_gJ5LHBr4TogsA0RO3U8jkSHEACOWw.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4044eba3b73b94a24b4baa4b56c70d8d9b744e93", "width": 320, "height": 36}, {"url": "https://external-preview.redd.it/CZZHEQDcSZXyl_gJ5LHBr4TogsA0RO3U8jkSHEACOWw.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=82fba01f440304c072e679c4dfb89496e08655c5", "width": 640, "height": 73}, {"url": "https://external-preview.redd.it/CZZHEQDcSZXyl_gJ5LHBr4TogsA0RO3U8jkSHEACOWw.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=c4675ab5df9c60a9a6252d16a349c9e75e1928f8", "width": 960, "height": 109}, {"url": "https://external-preview.redd.it/CZZHEQDcSZXyl_gJ5LHBr4TogsA0RO3U8jkSHEACOWw.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=66044e87c7d96c147c2a9c62dcc2a40f312714ee", "width": 1080, "height": 123}], "variants": {}, "id": "ouPZzDj4usgFNDnM4MUcwsDT3FH6bK09KSDZgSr0jDU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "zdd6ea", "is_robot_indexable": true, "report_reasons": null, "author": "meis_xry", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zdd6ea/difficult_business_problem_from_my_manager/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zdd6ea/difficult_business_problem_from_my_manager/", "subreddit_subscribers": 824144, "created_utc": 1670261128.0, "num_crossposts": 2, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_jxndm14v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Open Source Hospital Price Transparency", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": true, "name": "t3_zeb1w2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/9IXTjCXxAyjzoGhwO_4yFVetT33lnyrsmZGunXSL0Hw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670344112.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dolthub.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.dolthub.com/blog/2022-12-02-open-source-hospital-price-transparency/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0dpFtSkSjOcph3tuhWw-QSu5RFRwp-NSQesdpuHBDjI.jpg?auto=webp&amp;s=40cda3e4a7cbb78c9e288ed4c5fa215914cb13d7", "width": 624, "height": 326}, "resolutions": [{"url": "https://external-preview.redd.it/0dpFtSkSjOcph3tuhWw-QSu5RFRwp-NSQesdpuHBDjI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bbfa16abf570d0c656f72b687724ffb971adb51f", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/0dpFtSkSjOcph3tuhWw-QSu5RFRwp-NSQesdpuHBDjI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e729e95765eb679becedc95ed02a543286ff3047", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/0dpFtSkSjOcph3tuhWw-QSu5RFRwp-NSQesdpuHBDjI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ced529b21eeecb4686d3ede64f780c8e7d106e9e", "width": 320, "height": 167}], "variants": {}, "id": "UHAlocF6rzwDxoLR2tO9THwm5Q7JplXss5LPQSP_qII"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "zeb1w2", "is_robot_indexable": true, "report_reasons": null, "author": "alecs-dolt", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zeb1w2/open_source_hospital_price_transparency/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.dolthub.com/blog/2022-12-02-open-source-hospital-price-transparency/", "subreddit_subscribers": 824144, "created_utc": 1670344112.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, I have a basic question here.  I want to know how large a test population needs to be to provide a meaningful response back to another team.  \n\nLet's say we have observed 30 million devices and they have a particular failure rate.  The proposal is to change something about the delivery process to determine if it has an impact on the failure rate.  How many devices would have to be delivered this new way to provide a meaningful sample?\n\nI have found power calculators online, but I don't know if this example is a 1-sided, 2-sided, means or proportion, etc\n\nThanks in advance", "author_fullname": "t2_4cpzn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Proper way to calculate statistical power", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zeb07r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670343998.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I have a basic question here.  I want to know how large a test population needs to be to provide a meaningful response back to another team.  &lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s say we have observed 30 million devices and they have a particular failure rate.  The proposal is to change something about the delivery process to determine if it has an impact on the failure rate.  How many devices would have to be delivered this new way to provide a meaningful sample?&lt;/p&gt;\n\n&lt;p&gt;I have found power calculators online, but I don&amp;#39;t know if this example is a 1-sided, 2-sided, means or proportion, etc&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zeb07r", "is_robot_indexable": true, "report_reasons": null, "author": "perfectm", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zeb07r/proper_way_to_calculate_statistical_power/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zeb07r/proper_way_to_calculate_statistical_power/", "subreddit_subscribers": 824144, "created_utc": 1670343998.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been parsing json files in R and creating a large RDS. The files keep coming and I am expecting it will eventually hit the TB mark. Wondering if there is a good db/warehouse/lake solution that can either handle the processed/parsed data in an efficient way, or, better yet, a solution that can handle the json files without me having to pre-process/parse them first (maybe something like documentdb)? Any thoughts?", "author_fullname": "t2_aa663", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on a queryable data storage solution for terabytes of json files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zeaxe4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670343813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been parsing json files in R and creating a large RDS. The files keep coming and I am expecting it will eventually hit the TB mark. Wondering if there is a good db/warehouse/lake solution that can either handle the processed/parsed data in an efficient way, or, better yet, a solution that can handle the json files without me having to pre-process/parse them first (maybe something like documentdb)? Any thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zeaxe4", "is_robot_indexable": true, "report_reasons": null, "author": "PBandJammm", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zeaxe4/advice_on_a_queryable_data_storage_solution_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zeaxe4/advice_on_a_queryable_data_storage_solution_for/", "subreddit_subscribers": 824144, "created_utc": 1670343813.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What are the average salaries of DS, senior DS, and principal/staff DS within the pharma industry?", "author_fullname": "t2_17d42esw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Salary of data scientists in the pharma industry?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zeax3a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670343793.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the average salaries of DS, senior DS, and principal/staff DS within the pharma industry?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "zeax3a", "is_robot_indexable": true, "report_reasons": null, "author": "Guyserbun007", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zeax3a/salary_of_data_scientists_in_the_pharma_industry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zeax3a/salary_of_data_scientists_in_the_pharma_industry/", "subreddit_subscribers": 824144, "created_utc": 1670343793.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been a SWE (ML) for the past 3.5 years and its been a pretty hectic ride. Although, there were a lot of sweet moments, its a mind exhausting journey especially after being a product lead. To any data scientists out there? Is your role less exhausting than a SWE ?", "author_fullname": "t2_7ao0u2en", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "is Data Scientist role considered a less pressure job compared to SWE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ze5dfw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670329532.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been a SWE (ML) for the past 3.5 years and its been a pretty hectic ride. Although, there were a lot of sweet moments, its a mind exhausting journey especially after being a product lead. To any data scientists out there? Is your role less exhausting than a SWE ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ze5dfw", "is_robot_indexable": true, "report_reasons": null, "author": "the_scientist-7367", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ze5dfw/is_data_scientist_role_considered_a_less_pressure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ze5dfw/is_data_scientist_role_considered_a_less_pressure/", "subreddit_subscribers": 824144, "created_utc": 1670329532.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, I have to proof Lemma 7.11 in a similar way as 7.7. Is it correct what I'm doing in the proof? As I am not sure if the multiplications I do are in the correct order for getting the answer.\n\n[Exercise](https://preview.redd.it/xz4jkacm464a1.png?width=1132&amp;format=png&amp;auto=webp&amp;s=3f51fe6c645dfa8a5d9fa36c6c49d0b7a6f57945)\n\n&amp;#x200B;\n\n[Proof](https://preview.redd.it/7e1s2shq464a1.png?width=1131&amp;format=png&amp;auto=webp&amp;s=d40a631b527174e3d9d23c21f91734ac374ce75a)", "author_fullname": "t2_q6pkgcql", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Non homogeneous Markov chains", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"xz4jkacm464a1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 142, "x": 108, "u": "https://preview.redd.it/xz4jkacm464a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=dffcb2e9007b76320a57f934351de595c6dd78eb"}, {"y": 285, "x": 216, "u": "https://preview.redd.it/xz4jkacm464a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ab1ddd775a36df838b7433d6fd761624de645ecc"}, {"y": 422, "x": 320, "u": "https://preview.redd.it/xz4jkacm464a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2505bf7fc5cce00e33d4674c79af0e2e13a14129"}, {"y": 845, "x": 640, "u": "https://preview.redd.it/xz4jkacm464a1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0ad2cef467088723b73bc355efe5b90c8c5a330c"}, {"y": 1267, "x": 960, "u": "https://preview.redd.it/xz4jkacm464a1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=4c080d05c8f8201098b3e07585e9b959f6f2b431"}, {"y": 1426, "x": 1080, "u": "https://preview.redd.it/xz4jkacm464a1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=99f273f37bb5c6f7ea9d4e13aad908c3e27cb0a7"}], "s": {"y": 1495, "x": 1132, "u": "https://preview.redd.it/xz4jkacm464a1.png?width=1132&amp;format=png&amp;auto=webp&amp;s=3f51fe6c645dfa8a5d9fa36c6c49d0b7a6f57945"}, "id": "xz4jkacm464a1"}, "7e1s2shq464a1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 53, "x": 108, "u": "https://preview.redd.it/7e1s2shq464a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a80d5c7ceb0812a4eb104425f2e94bded45d6c4d"}, {"y": 107, "x": 216, "u": "https://preview.redd.it/7e1s2shq464a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0cfb56d52bfaf6f286fd6ea8ce8a70ee3836d66f"}, {"y": 159, "x": 320, "u": "https://preview.redd.it/7e1s2shq464a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d0b3521e705356869d7fae1f9feac1864169df38"}, {"y": 319, "x": 640, "u": "https://preview.redd.it/7e1s2shq464a1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a90fdf4c9be15fb2e8f6551598c961e23b759fe1"}, {"y": 479, "x": 960, "u": "https://preview.redd.it/7e1s2shq464a1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=1c46e674556d58e07b5fac43c37cb2c761699fe7"}, {"y": 539, "x": 1080, "u": "https://preview.redd.it/7e1s2shq464a1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1cc9518dc5d934afc4405756ee0f818d13f74e15"}], "s": {"y": 565, "x": 1131, "u": "https://preview.redd.it/7e1s2shq464a1.png?width=1131&amp;format=png&amp;auto=webp&amp;s=d40a631b527174e3d9d23c21f91734ac374ce75a"}, "id": "7e1s2shq464a1"}}, "name": "t3_zdow4c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.3, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/0w2ap3RB1--B17eOcS47tbsb3ojfEjFRj8pgw1uxuEg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670284903.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I have to proof Lemma 7.11 in a similar way as 7.7. Is it correct what I&amp;#39;m doing in the proof? As I am not sure if the multiplications I do are in the correct order for getting the answer.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/xz4jkacm464a1.png?width=1132&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3f51fe6c645dfa8a5d9fa36c6c49d0b7a6f57945\"&gt;Exercise&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/7e1s2shq464a1.png?width=1131&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d40a631b527174e3d9d23c21f91734ac374ce75a\"&gt;Proof&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zdow4c", "is_robot_indexable": true, "report_reasons": null, "author": "Visual-Arm-7375", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zdow4c/non_homogeneous_markov_chains/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zdow4c/non_homogeneous_markov_chains/", "subreddit_subscribers": 824144, "created_utc": 1670284903.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "hello! i\u2019m new in this subreddit and i\u2019m new in learning data mining as well. i would like to ask if you guys know any algorithm or tools used in sentiment analysis that only show positive or negative outputs? thank you!", "author_fullname": "t2_5tjuxlla", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SENTIMENT ANALYSIS ALGORITHM", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ze26gu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.17, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670320522.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hello! i\u2019m new in this subreddit and i\u2019m new in learning data mining as well. i would like to ask if you guys know any algorithm or tools used in sentiment analysis that only show positive or negative outputs? thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ze26gu", "is_robot_indexable": true, "report_reasons": null, "author": "cultfounder", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ze26gu/sentiment_analysis_algorithm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ze26gu/sentiment_analysis_algorithm/", "subreddit_subscribers": 824144, "created_utc": 1670320522.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "How do I actually make one? I go on github and its really confusing\n\nmoreover, will employers be ok if your analysis and visualiation is super simple? what if it was a simple as age, number of customers and purchases at a store?\n\nor do you need to answer some question?\n\nthanks", "author_fullname": "t2_thtu44cz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone know how to make a data analyst portfolio and would employers be ok with basic stuff?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zdzqt5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.36, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670313088.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do I actually make one? I go on github and its really confusing&lt;/p&gt;\n\n&lt;p&gt;moreover, will employers be ok if your analysis and visualiation is super simple? what if it was a simple as age, number of customers and purchases at a store?&lt;/p&gt;\n\n&lt;p&gt;or do you need to answer some question?&lt;/p&gt;\n\n&lt;p&gt;thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zdzqt5", "is_robot_indexable": true, "report_reasons": null, "author": "TraditionUnable9770", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zdzqt5/does_anyone_know_how_to_make_a_data_analyst/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zdzqt5/does_anyone_know_how_to_make_a_data_analyst/", "subreddit_subscribers": 824144, "created_utc": 1670313088.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}