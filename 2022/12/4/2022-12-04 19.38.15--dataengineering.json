{"kind": "Listing", "data": {"after": null, "dist": 21, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Basically title - I've been thinking about this a lot lately and am curious to hear others' thoughts.\n\nSo far my main thought patterns have been along the lines of:\n\n1) Ways of working. In organisations I've been exposed to the ways of working for data teams have been all over the shop. Some are trending towards working more like SWE teams, some act as project teams, and some (most common IME) seem to exist on their own island inside an organisation. Does this create a risk that teams will by and large be working non-optimally?\n\n2) Businesses not knowing what they want out of their data. This I feel is pretty self-explanatory - if the business doesn't know what they want is there risk of decision-makers opting not to utilise the data, making data work redundant?\n\n3) Technology crossover and ambiguity. There is seemingly an unlimited number of technologies that can be utilized for various functions, with no clear use cases for which is best in what situations. Also, as technologies have expanded they have sought to expand functionality into other use cases, which further increases the permutations possible. Per examplur, for data orchestration there is ADF, Step Functions, Airflow, DBT, Flyte, Cloud Functions, Luigi, etc., etc. How can a business case be made for any of them without thorough testing, which is expensive and time-consuming?", "author_fullname": "t2_b3hw6tq1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some of the big problems Data Engineering currently faces / will face in the next 5-10 years?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zc6lvq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 50, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 50, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_1": 1}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670150717.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically title - I&amp;#39;ve been thinking about this a lot lately and am curious to hear others&amp;#39; thoughts.&lt;/p&gt;\n\n&lt;p&gt;So far my main thought patterns have been along the lines of:&lt;/p&gt;\n\n&lt;p&gt;1) Ways of working. In organisations I&amp;#39;ve been exposed to the ways of working for data teams have been all over the shop. Some are trending towards working more like SWE teams, some act as project teams, and some (most common IME) seem to exist on their own island inside an organisation. Does this create a risk that teams will by and large be working non-optimally?&lt;/p&gt;\n\n&lt;p&gt;2) Businesses not knowing what they want out of their data. This I feel is pretty self-explanatory - if the business doesn&amp;#39;t know what they want is there risk of decision-makers opting not to utilise the data, making data work redundant?&lt;/p&gt;\n\n&lt;p&gt;3) Technology crossover and ambiguity. There is seemingly an unlimited number of technologies that can be utilized for various functions, with no clear use cases for which is best in what situations. Also, as technologies have expanded they have sought to expand functionality into other use cases, which further increases the permutations possible. Per examplur, for data orchestration there is ADF, Step Functions, Airflow, DBT, Flyte, Cloud Functions, Luigi, etc., etc. How can a business case be made for any of them without thorough testing, which is expensive and time-consuming?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 100, "id": "gid_1", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Shows the Silver Award... and that's it.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Silver", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zc6lvq", "is_robot_indexable": true, "report_reasons": null, "author": "elevatebi", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zc6lvq/what_are_some_of_the_big_problems_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zc6lvq/what_are_some_of_the_big_problems_data/", "subreddit_subscribers": 81830, "created_utc": 1670150717.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I have built a simple ETL pipeline using Apache Airflow which is running locally for now. Now I wanted to deploy it to AWS. What would be the best way to do that? Do I just need to build container using docker and then deploy that to EC2? My goal is to run scheduler on daily basis to migrate data from source to destination.\n\nPS: I am just a beginner in data engineering so please ignore any mistake.", "author_fullname": "t2_udvutrbv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Etl pipeline deployment on AWS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zbs64g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670105178.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I have built a simple ETL pipeline using Apache Airflow which is running locally for now. Now I wanted to deploy it to AWS. What would be the best way to do that? Do I just need to build container using docker and then deploy that to EC2? My goal is to run scheduler on daily basis to migrate data from source to destination.&lt;/p&gt;\n\n&lt;p&gt;PS: I am just a beginner in data engineering so please ignore any mistake.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zbs64g", "is_robot_indexable": true, "report_reasons": null, "author": "Usamacheema12345", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zbs64g/etl_pipeline_deployment_on_aws/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zbs64g/etl_pipeline_deployment_on_aws/", "subreddit_subscribers": 81830, "created_utc": 1670105178.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve inherited a new project and my Airflow knowledge is rusty. From what I\u2019ve gathered so far, a lot of the tasks are doing some heavy lifting. E.g\n\nFirst task -&gt; Exports from external DB to GCS\n\nSecond task -&gt; Download file (can be up to 100mb) from GCS, parses file and saves as JSON. Uploads JSOn to GCS\n\nthis second DAG seems to be doing a lot of work, my understanding is that with Airflow the philosophy is for each task to only trigger external services. \n\nThoughts? I\u2019d rather not have to refactor this if it\u2019s commonly acceptable \ud83e\udd14", "author_fullname": "t2_htptc13q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you run Airflow purely as an orchestrator?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zbv3vk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670112704.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve inherited a new project and my Airflow knowledge is rusty. From what I\u2019ve gathered so far, a lot of the tasks are doing some heavy lifting. E.g&lt;/p&gt;\n\n&lt;p&gt;First task -&amp;gt; Exports from external DB to GCS&lt;/p&gt;\n\n&lt;p&gt;Second task -&amp;gt; Download file (can be up to 100mb) from GCS, parses file and saves as JSON. Uploads JSOn to GCS&lt;/p&gt;\n\n&lt;p&gt;this second DAG seems to be doing a lot of work, my understanding is that with Airflow the philosophy is for each task to only trigger external services. &lt;/p&gt;\n\n&lt;p&gt;Thoughts? I\u2019d rather not have to refactor this if it\u2019s commonly acceptable \ud83e\udd14&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zbv3vk", "is_robot_indexable": true, "report_reasons": null, "author": "Main_Tap_1256", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zbv3vk/do_you_run_airflow_purely_as_an_orchestrator/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zbv3vk/do_you_run_airflow_purely_as_an_orchestrator/", "subreddit_subscribers": 81830, "created_utc": 1670112704.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi.. I've seen the resources at the wiki page. But I feel if maybe I get a training through bootcamp or any other learning platforms, I might be able to learn data engineering better. I checked online came across Simplilearn. Has anyone taken the course there or any other better platforms. I can only learn Part Time due to my full time job. Thanks....", "author_fullname": "t2_np3evoin", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Online Learning platforms", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zbvuxe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670114784.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi.. I&amp;#39;ve seen the resources at the wiki page. But I feel if maybe I get a training through bootcamp or any other learning platforms, I might be able to learn data engineering better. I checked online came across Simplilearn. Has anyone taken the course there or any other better platforms. I can only learn Part Time due to my full time job. Thanks....&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zbvuxe", "is_robot_indexable": true, "report_reasons": null, "author": "naruzum", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zbvuxe/online_learning_platforms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zbvuxe/online_learning_platforms/", "subreddit_subscribers": 81830, "created_utc": 1670114784.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Let's say we are moving a table from a database to a data warehouse. The flow of the pipeline is table in RDS exported to S3 then Coud Storage and then Bigquery. The team has decided that this pipeline runs daily since reporting needs is only once a day. So the table can either contain additional rows or modified version of the existing rows. So my question is, would it be better to: 1) overwrite the whole table during daily update; or 2) just append the new rows and update the existing rows which got modified.\n\nThank you!", "author_fullname": "t2_6jogidac", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you handle daily update of table?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zc0f1m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670128216.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s say we are moving a table from a database to a data warehouse. The flow of the pipeline is table in RDS exported to S3 then Coud Storage and then Bigquery. The team has decided that this pipeline runs daily since reporting needs is only once a day. So the table can either contain additional rows or modified version of the existing rows. So my question is, would it be better to: 1) overwrite the whole table during daily update; or 2) just append the new rows and update the existing rows which got modified.&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zc0f1m", "is_robot_indexable": true, "report_reasons": null, "author": "_barnuts", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zc0f1m/how_do_you_handle_daily_update_of_table/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zc0f1m/how_do_you_handle_daily_update_of_table/", "subreddit_subscribers": 81830, "created_utc": 1670128216.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've recently left my full time role as a Data Engineer and I'm looking for some advice.\n\nI want to spend some time away from the 9-5 for many reasons, but I would like to keep my hand in so to speak. Ideally I would work maybe 2 or 3 days a week with flexible hours, using my data skills, but not on anything high pressured or full on.\n\nAny ideas on what sorts of roles I could look for? Or what sorts of companies? \n\nI have thought about some kind of SQL migration work- I love writing migration scripts. But not sure what this is called- does it come under DBA responsibilities? \nI'm also good at optimizing SQL queries, happy to rewrite stored procedures etc. \nAgain, not sure what this role would be called.\n\nI do also have backend engineering experience, am quite familiar with AWS tools, and also snowflake.", "author_fullname": "t2_5n8mvd7p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Part time roles? Ideas of what to look for", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zbxhcr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670119496.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve recently left my full time role as a Data Engineer and I&amp;#39;m looking for some advice.&lt;/p&gt;\n\n&lt;p&gt;I want to spend some time away from the 9-5 for many reasons, but I would like to keep my hand in so to speak. Ideally I would work maybe 2 or 3 days a week with flexible hours, using my data skills, but not on anything high pressured or full on.&lt;/p&gt;\n\n&lt;p&gt;Any ideas on what sorts of roles I could look for? Or what sorts of companies? &lt;/p&gt;\n\n&lt;p&gt;I have thought about some kind of SQL migration work- I love writing migration scripts. But not sure what this is called- does it come under DBA responsibilities? \nI&amp;#39;m also good at optimizing SQL queries, happy to rewrite stored procedures etc. \nAgain, not sure what this role would be called.&lt;/p&gt;\n\n&lt;p&gt;I do also have backend engineering experience, am quite familiar with AWS tools, and also snowflake.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zbxhcr", "is_robot_indexable": true, "report_reasons": null, "author": "kaiso_gunkan", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zbxhcr/part_time_roles_ideas_of_what_to_look_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zbxhcr/part_time_roles_ideas_of_what_to_look_for/", "subreddit_subscribers": 81830, "created_utc": 1670119496.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When you get overwhelmed with project complexity and uncertainty, and progress slows or stalls, what do you do?\n\nWhat is your approach?  What should I keep in mind?\n\nAnything you've discovered that has really affected your thinking about this?  Books, articles, or wise words from a mentor, etc.\n\nI feel like I need to upgrade my mental model/framework/mindset.", "author_fullname": "t2_6fifg4n4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When ambitious projects stall -- looking for general advice on regaining traction", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zbo40a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670095149.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When you get overwhelmed with project complexity and uncertainty, and progress slows or stalls, what do you do?&lt;/p&gt;\n\n&lt;p&gt;What is your approach?  What should I keep in mind?&lt;/p&gt;\n\n&lt;p&gt;Anything you&amp;#39;ve discovered that has really affected your thinking about this?  Books, articles, or wise words from a mentor, etc.&lt;/p&gt;\n\n&lt;p&gt;I feel like I need to upgrade my mental model/framework/mindset.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zbo40a", "is_robot_indexable": true, "report_reasons": null, "author": "icysandstone", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zbo40a/when_ambitious_projects_stall_looking_for_general/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zbo40a/when_ambitious_projects_stall_looking_for_general/", "subreddit_subscribers": 81830, "created_utc": 1670095149.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m new to Python and trying to wrap my brain around how these work together in practice. I feel like it\u2019d be really helpful to look at an example. Doesn\u2019t have to be these exact tools. \n\nThanks!", "author_fullname": "t2_88x87", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone have an example of a project where a handful of the more popular Python tools are used? (E.g. airbyte, airflow, dbt, and pandas)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zcdnel", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670170254.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m new to Python and trying to wrap my brain around how these work together in practice. I feel like it\u2019d be really helpful to look at an example. Doesn\u2019t have to be these exact tools. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zcdnel", "is_robot_indexable": true, "report_reasons": null, "author": "dicotyledon", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zcdnel/anyone_have_an_example_of_a_project_where_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zcdnel/anyone_have_an_example_of_a_project_where_a/", "subreddit_subscribers": 81830, "created_utc": 1670170254.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m wondering if anyone has any advice or experience working as a data engineer when leadership / architects do not have a data background. \n\nOur leadership team has very strong SWE backgrounds but they don\u2019t seem to recognize data engineering as it\u2019s own speciality and so we\u2019ve had to go through a lot of reinventing the wheel. In many cases I already know about the wheel, but I have not found an effective way to communicate that they are trying to solve well known problems and that there are standard solutions. \n\nFor instance the other day they were trying to solve the canonical use case for lambda architecture and I couldn\u2019t convince them to use it or that they were falling into the anti patterns it was designed against. \n\nHave you all faced something similar in your organizations? How were you able to navigate the issues?", "author_fullname": "t2_f3dj7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Working as a data engineer where leadership does not have a data background", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zcgwt9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670177547.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m wondering if anyone has any advice or experience working as a data engineer when leadership / architects do not have a data background. &lt;/p&gt;\n\n&lt;p&gt;Our leadership team has very strong SWE backgrounds but they don\u2019t seem to recognize data engineering as it\u2019s own speciality and so we\u2019ve had to go through a lot of reinventing the wheel. In many cases I already know about the wheel, but I have not found an effective way to communicate that they are trying to solve well known problems and that there are standard solutions. &lt;/p&gt;\n\n&lt;p&gt;For instance the other day they were trying to solve the canonical use case for lambda architecture and I couldn\u2019t convince them to use it or that they were falling into the anti patterns it was designed against. &lt;/p&gt;\n\n&lt;p&gt;Have you all faced something similar in your organizations? How were you able to navigate the issues?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zcgwt9", "is_robot_indexable": true, "report_reasons": null, "author": "gummnutt", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zcgwt9/working_as_a_data_engineer_where_leadership_does/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zcgwt9/working_as_a_data_engineer_where_leadership_does/", "subreddit_subscribers": 81830, "created_utc": 1670177547.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi. Curious to hear the communities approach to modelling a fact table which represents reports involving varying party counts. \n\nReporting needs are to see counts of incidents, people involved in various events and the reporter(s) of the event. \n\nBasically it\u2019s a factless fact table to represent an incident, which might have 1,2,3\u2026,n people involved. Parallel might be an invoice roll up, but in this case there isn\u2019t numbers, the count is the incident that\u2019s being reported on. \n\nI don\u2019t think that throwing it in columns is the right approach due to the variability in people counts, so I think duplicating each row and varying the people ID for each row, which is tied to a degenerate dimension against the incident number.\n\nI guess my uncertain is I\u2019ll need to keep the text block, but that\u2019ll balloon my model size. Other part is the users will need to be aware that there is duplication. \n\nHow would you folks approach this? Aggregate fact table for the incident with a column of count, paired with a second detailed level one that excludes the text block? All in one table? If I duplicate the tables I\u2019ll need to extract my incident ID to a dimension that only has the ID which also feels incorrect. \n\nExtension is one or more people might also report on this too, which would create even more duplication!\n\nThanks!", "author_fullname": "t2_ahu1o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Modelling investigation fact table with varying people counts", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zcc9qg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670167020.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi. Curious to hear the communities approach to modelling a fact table which represents reports involving varying party counts. &lt;/p&gt;\n\n&lt;p&gt;Reporting needs are to see counts of incidents, people involved in various events and the reporter(s) of the event. &lt;/p&gt;\n\n&lt;p&gt;Basically it\u2019s a factless fact table to represent an incident, which might have 1,2,3\u2026,n people involved. Parallel might be an invoice roll up, but in this case there isn\u2019t numbers, the count is the incident that\u2019s being reported on. &lt;/p&gt;\n\n&lt;p&gt;I don\u2019t think that throwing it in columns is the right approach due to the variability in people counts, so I think duplicating each row and varying the people ID for each row, which is tied to a degenerate dimension against the incident number.&lt;/p&gt;\n\n&lt;p&gt;I guess my uncertain is I\u2019ll need to keep the text block, but that\u2019ll balloon my model size. Other part is the users will need to be aware that there is duplication. &lt;/p&gt;\n\n&lt;p&gt;How would you folks approach this? Aggregate fact table for the incident with a column of count, paired with a second detailed level one that excludes the text block? All in one table? If I duplicate the tables I\u2019ll need to extract my incident ID to a dimension that only has the ID which also feels incorrect. &lt;/p&gt;\n\n&lt;p&gt;Extension is one or more people might also report on this too, which would create even more duplication!&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zcc9qg", "is_robot_indexable": true, "report_reasons": null, "author": "Namur007", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zcc9qg/modelling_investigation_fact_table_with_varying/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zcc9qg/modelling_investigation_fact_table_with_varying/", "subreddit_subscribers": 81830, "created_utc": 1670167020.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys,\n\nI'm currently working on power bi and SQL outputting reports for a health care. How do I transition to a date engineering role. \nIf you may please explain how did you get started, transformed. \nHow did you get interview calls. \nDid you attend any course, was this the first role you got after your Univ. \nI'm looking for a more positive story because. After 5 years in civil industry, I've changed role into an analyst. But getting calls for data engineering seems to be tough. \nRight now I have nearly 1 year experience as an analyst\n \nAll/any response will be very much appreciated.", "author_fullname": "t2_11ivtgn5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get started in a data engineering role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zc9s4i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670160374.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working on power bi and SQL outputting reports for a health care. How do I transition to a date engineering role. \nIf you may please explain how did you get started, transformed. \nHow did you get interview calls. \nDid you attend any course, was this the first role you got after your Univ. \nI&amp;#39;m looking for a more positive story because. After 5 years in civil industry, I&amp;#39;ve changed role into an analyst. But getting calls for data engineering seems to be tough. \nRight now I have nearly 1 year experience as an analyst&lt;/p&gt;\n\n&lt;p&gt;All/any response will be very much appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zc9s4i", "is_robot_indexable": true, "report_reasons": null, "author": "westisnoteast", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zc9s4i/how_to_get_started_in_a_data_engineering_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zc9s4i/how_to_get_started_in_a_data_engineering_role/", "subreddit_subscribers": 81830, "created_utc": 1670160374.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are the best tools to provision a database schema and are there programmatic ones?\n\nCurrently I am looking at SQL type databases", "author_fullname": "t2_172g1e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Provision Database Schema", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zc4pbg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670143593.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the best tools to provision a database schema and are there programmatic ones?&lt;/p&gt;\n\n&lt;p&gt;Currently I am looking at SQL type databases&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zc4pbg", "is_robot_indexable": true, "report_reasons": null, "author": "stevecrox0914", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zc4pbg/provision_database_schema/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zc4pbg/provision_database_schema/", "subreddit_subscribers": 81830, "created_utc": 1670143593.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have analytics data in postgres since Segment will automatically export there and our app runs off of MySQL. There are certain characteristics that can be joined between the two, but are not formally related in our models. Are there tools to allow us to explore this data? I imagine these fall under BI tools. I've heard of Snowflake, but I'm looking for something opensource/free that I can try to see if this would be valuable for my team.", "author_fullname": "t2_qlblw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Free Tools for exploring data between a postgres Database and a MySQL database", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zbowdj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670097168.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have analytics data in postgres since Segment will automatically export there and our app runs off of MySQL. There are certain characteristics that can be joined between the two, but are not formally related in our models. Are there tools to allow us to explore this data? I imagine these fall under BI tools. I&amp;#39;ve heard of Snowflake, but I&amp;#39;m looking for something opensource/free that I can try to see if this would be valuable for my team.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zbowdj", "is_robot_indexable": true, "report_reasons": null, "author": "Jlkid225", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zbowdj/free_tools_for_exploring_data_between_a_postgres/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zbowdj/free_tools_for_exploring_data_between_a_postgres/", "subreddit_subscribers": 81830, "created_utc": 1670097168.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've got to set-up a very simple data pipeline :\n\n1.1 - Run a job to hit API every 30mins, compress and save file to S3. Total job will hit 9 endpoints and will complete within 15mins easily, more like &lt;3min for all 9 if I add a throttle \n\n1.2- send email potentially, depending on content of response\n\n2.0 - move files from S3 to snowflake (will use external stage)\n\nNot much to it and I'm confident in how to do it. What I'm not confident in though, is the best way to do it. The files are small, there will be a maximum of 10files on each run\n\nI wanted to use Airflow, but after setting this up and testing successfully (locally), frankly it just seems like overkill to use a tool like that for such a small amount of data - there also is the issue of deployment. Running it locally on docker, my device sounds like it wants to kick the bucket. Options: \n\n1) The managed services on AWS (e g MWAA) seem expensive (again, why pay so much for such a small task)\n\n2) Kubernetes on something like EKS - more appealing but seems like severe overkill now\n\n3) deploy on EC2, using Docker in production would be fine in this use case so could do this - but I've read that using VMs in the cloud generally means you're not using it the cloud properly (hence my question on best practices)\n\n4) others?\n\nThis can be done with a Cron job, I'm more tempted to bin off these fancy tools, set-up a cron job and have this run on a free tier EC2, or use AWS Lambda \n\nIn summary, I'm looking for advice on the best practice when it comes to deployment\n\nAny advice is welcome", "author_fullname": "t2_1w1o79i7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to get API responses to S3", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zch4cg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1670178953.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670178012.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got to set-up a very simple data pipeline :&lt;/p&gt;\n\n&lt;p&gt;1.1 - Run a job to hit API every 30mins, compress and save file to S3. Total job will hit 9 endpoints and will complete within 15mins easily, more like &amp;lt;3min for all 9 if I add a throttle &lt;/p&gt;\n\n&lt;p&gt;1.2- send email potentially, depending on content of response&lt;/p&gt;\n\n&lt;p&gt;2.0 - move files from S3 to snowflake (will use external stage)&lt;/p&gt;\n\n&lt;p&gt;Not much to it and I&amp;#39;m confident in how to do it. What I&amp;#39;m not confident in though, is the best way to do it. The files are small, there will be a maximum of 10files on each run&lt;/p&gt;\n\n&lt;p&gt;I wanted to use Airflow, but after setting this up and testing successfully (locally), frankly it just seems like overkill to use a tool like that for such a small amount of data - there also is the issue of deployment. Running it locally on docker, my device sounds like it wants to kick the bucket. Options: &lt;/p&gt;\n\n&lt;p&gt;1) The managed services on AWS (e g MWAA) seem expensive (again, why pay so much for such a small task)&lt;/p&gt;\n\n&lt;p&gt;2) Kubernetes on something like EKS - more appealing but seems like severe overkill now&lt;/p&gt;\n\n&lt;p&gt;3) deploy on EC2, using Docker in production would be fine in this use case so could do this - but I&amp;#39;ve read that using VMs in the cloud generally means you&amp;#39;re not using it the cloud properly (hence my question on best practices)&lt;/p&gt;\n\n&lt;p&gt;4) others?&lt;/p&gt;\n\n&lt;p&gt;This can be done with a Cron job, I&amp;#39;m more tempted to bin off these fancy tools, set-up a cron job and have this run on a free tier EC2, or use AWS Lambda &lt;/p&gt;\n\n&lt;p&gt;In summary, I&amp;#39;m looking for advice on the best practice when it comes to deployment&lt;/p&gt;\n\n&lt;p&gt;Any advice is welcome&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zch4cg", "is_robot_indexable": true, "report_reasons": null, "author": "tea_horse", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zch4cg/best_way_to_get_api_responses_to_s3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zch4cg/best_way_to_get_api_responses_to_s3/", "subreddit_subscribers": 81830, "created_utc": 1670178012.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,  I am having trouble to parse html source code as there is no definitive template maintained in the portal and seems like it's written in free-hand version. Tried Beautifulsoup to extract the particular part required from the page as below:\n\n`required_data = soup.find(\"div\", {\"id\": \"divExpectedResults\"})`\n\nAs I mentioned earlier, there is no clear definitive template inside this class for me extract data further. Hence not be able to add many rules to entirely extract the way I want. Basically want to extract as we read from the web pages but not able to do so.   \nAlong the way, I managed to find some 3rd party tools like Doxillion etc which almost generates what we need and could massage a bit to extract very easily. Anyone has used such packages?\n\nDo we have any other html parsers which can parse exactly how we see the web page?", "author_fullname": "t2_eozceps7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Available packages for html parsing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zc58ro", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670145677.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,  I am having trouble to parse html source code as there is no definitive template maintained in the portal and seems like it&amp;#39;s written in free-hand version. Tried Beautifulsoup to extract the particular part required from the page as below:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;required_data = soup.find(&amp;quot;div&amp;quot;, {&amp;quot;id&amp;quot;: &amp;quot;divExpectedResults&amp;quot;})&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;As I mentioned earlier, there is no clear definitive template inside this class for me extract data further. Hence not be able to add many rules to entirely extract the way I want. Basically want to extract as we read from the web pages but not able to do so.&lt;br/&gt;\nAlong the way, I managed to find some 3rd party tools like Doxillion etc which almost generates what we need and could massage a bit to extract very easily. Anyone has used such packages?&lt;/p&gt;\n\n&lt;p&gt;Do we have any other html parsers which can parse exactly how we see the web page?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zc58ro", "is_robot_indexable": true, "report_reasons": null, "author": "Liily_07", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zc58ro/available_packages_for_html_parsing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zc58ro/available_packages_for_html_parsing/", "subreddit_subscribers": 81830, "created_utc": 1670145677.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a web developer for a small agency. So low funds to spend and we're not working with a ton of data. Yet I'm hoping to tackle some data engineering for a client to add to my resume and possibly create a new 'data engineering' revenue stream for the agency. \n\nWe have a mobile app that is in dire need of automating and combining a few data sources. The current destination for data is simply a Google sheet...lulz. I'm open to suggestions but at a minimum the new data destination could simply be a PostGres DB.\n\n I'd prefer to use free and/or open sources tools as this is a trial run for data engineering services. The goal would be to extract the data from a few different sources, then some light transformation of the data for business decisions.\n\n The data sources so far are: \n-app itself (backend is Nest.js w/ Postgres DB)\n-vimeo videos (vimeo API?)\n-app stores (downloads, country data) \n\nI'm looking for suggestions and tools to use and any advice on the approach to make this a success for my agency and client. My limited research and knowledge has led me to think maybe Airbyte + dbt might be good tools for the job. Is there anything simpler/better I should look into to create a solution? \n\nThanks!", "author_fullname": "t2_5xpiw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I have a chance to tackle some data engineering to build my resume, possibly build a new revenue stream for my web dev agency.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zbqryi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670101793.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a web developer for a small agency. So low funds to spend and we&amp;#39;re not working with a ton of data. Yet I&amp;#39;m hoping to tackle some data engineering for a client to add to my resume and possibly create a new &amp;#39;data engineering&amp;#39; revenue stream for the agency. &lt;/p&gt;\n\n&lt;p&gt;We have a mobile app that is in dire need of automating and combining a few data sources. The current destination for data is simply a Google sheet...lulz. I&amp;#39;m open to suggestions but at a minimum the new data destination could simply be a PostGres DB.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d prefer to use free and/or open sources tools as this is a trial run for data engineering services. The goal would be to extract the data from a few different sources, then some light transformation of the data for business decisions.&lt;/p&gt;\n\n&lt;p&gt;The data sources so far are: \n-app itself (backend is Nest.js w/ Postgres DB)\n-vimeo videos (vimeo API?)\n-app stores (downloads, country data) &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for suggestions and tools to use and any advice on the approach to make this a success for my agency and client. My limited research and knowledge has led me to think maybe Airbyte + dbt might be good tools for the job. Is there anything simpler/better I should look into to create a solution? &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zbqryi", "is_robot_indexable": true, "report_reasons": null, "author": "Kramix", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zbqryi/i_have_a_chance_to_tackle_some_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zbqryi/i_have_a_chance_to_tackle_some_data_engineering/", "subreddit_subscribers": 81830, "created_utc": 1670101793.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For context, I work at a company who collect citizen data from town halls, to clean/normalize it and do some BI's on it.\nData can come in many many ways (from a plain txt/CSV to a mySQL/mongoDB) but they are information is always the same (Social Security number, name, address).\n\nI'm fairly new to the company (and to programming/data engineering as a whole, for that matter, worked on finances before) but the way they work with data seems archaic (Talend), and I found myself losing so much time to ingest these data to the company standard postgresDB schema (which, after that first ingestion, everything is automatized to clean and do the BI's. It's not the best but def not the concern right now).\n\nI'm good at python and the company is open to new ways to work with the ETL, so I was wondering, how would you guys handle this kind of stuff?", "author_fullname": "t2_uqv37xia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's your way to handle To/From problems?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zbyf9c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670122238.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For context, I work at a company who collect citizen data from town halls, to clean/normalize it and do some BI&amp;#39;s on it.\nData can come in many many ways (from a plain txt/CSV to a mySQL/mongoDB) but they are information is always the same (Social Security number, name, address).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m fairly new to the company (and to programming/data engineering as a whole, for that matter, worked on finances before) but the way they work with data seems archaic (Talend), and I found myself losing so much time to ingest these data to the company standard postgresDB schema (which, after that first ingestion, everything is automatized to clean and do the BI&amp;#39;s. It&amp;#39;s not the best but def not the concern right now).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m good at python and the company is open to new ways to work with the ETL, so I was wondering, how would you guys handle this kind of stuff?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zbyf9c", "is_robot_indexable": true, "report_reasons": null, "author": "DataThatGraph", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zbyf9c/whats_your_way_to_handle_tofrom_problems/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zbyf9c/whats_your_way_to_handle_tofrom_problems/", "subreddit_subscribers": 81830, "created_utc": 1670122238.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hello, data engineering folks, \n\nI was learning Kinesis right now and while doing so I stumbled upon KPL &amp; KCL libraries which are written exclusively in Java, my Java is kinda rusty and I wanted to ask if is it worth it to learn the KPL and KCL libraries in Java for most use cases or does the AWS SDK provide enough to cover most use cases?", "author_fullname": "t2_64nmnknh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kinesis KPL &amp; KCL vs using AWS SDK", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zca4al", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670161474.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hello, data engineering folks, &lt;/p&gt;\n\n&lt;p&gt;I was learning Kinesis right now and while doing so I stumbled upon KPL &amp;amp; KCL libraries which are written exclusively in Java, my Java is kinda rusty and I wanted to ask if is it worth it to learn the KPL and KCL libraries in Java for most use cases or does the AWS SDK provide enough to cover most use cases?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zca4al", "is_robot_indexable": true, "report_reasons": null, "author": "SnooDoggos5883", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zca4al/kinesis_kpl_kcl_vs_using_aws_sdk/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zca4al/kinesis_kpl_kcl_vs_using_aws_sdk/", "subreddit_subscribers": 81830, "created_utc": 1670161474.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! I'm currently studying about different distributed file systems! I got stuck in distinguishing between Hadoop FS and Ceph FS. The only difference that I got is the way that each of them stores data (HDFS seems to store files at random, whereas Ceph is based on CRUSH algorithm, resembling consistent hashing). I would like to have more differences and if possible, some benchmarks between these two file storage. Thank you in advance!", "author_fullname": "t2_2uelc2i1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the difference between HDFS and CephFS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zc6zi4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670151917.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I&amp;#39;m currently studying about different distributed file systems! I got stuck in distinguishing between Hadoop FS and Ceph FS. The only difference that I got is the way that each of them stores data (HDFS seems to store files at random, whereas Ceph is based on CRUSH algorithm, resembling consistent hashing). I would like to have more differences and if possible, some benchmarks between these two file storage. Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zc6zi4", "is_robot_indexable": true, "report_reasons": null, "author": "minhrongcon2000", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zc6zi4/what_is_the_difference_between_hdfs_and_cephfs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zc6zi4/what_is_the_difference_between_hdfs_and_cephfs/", "subreddit_subscribers": 81830, "created_utc": 1670151917.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_9hx6wnnb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New AWS D&amp;A Features announced by Swami Sivasubramanian (VP of Data &amp; Machine Learning) during his keynote (feature summary video)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_zbqhfn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/nQVQmbC9_jE?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"AWS re:Invent 2022  Swami Sivasubramanian Keynote for Data &amp;amp; Analytics (New Features &amp;amp; Services)\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "AWS re:Invent 2022  Swami Sivasubramanian Keynote for Data &amp; Analytics (New Features &amp; Services)", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/nQVQmbC9_jE?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"AWS re:Invent 2022  Swami Sivasubramanian Keynote for Data &amp;amp; Analytics (New Features &amp;amp; Services)\"&gt;&lt;/iframe&gt;", "author_name": "DataEng Uncomplicated", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/nQVQmbC9_jE/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@DataEngUncomplicated"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/nQVQmbC9_jE?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"AWS re:Invent 2022  Swami Sivasubramanian Keynote for Data &amp;amp; Analytics (New Features &amp;amp; Services)\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/zbqhfn", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/9aJkDfbMxbFU3Mw_apDBTmzq3Ay-2K0YtN3U49naBkQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670101088.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/nQVQmbC9_jE", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/txtus-K1eOPZAabofXsd9XSBc7AUH79TVT9kvWSKt90.jpg?auto=webp&amp;s=c159e037d96f99d518a37ad9f51066b2d262b65f", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/txtus-K1eOPZAabofXsd9XSBc7AUH79TVT9kvWSKt90.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=341fd3f5f91642d3f1cad1e0820c8f42ce92b675", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/txtus-K1eOPZAabofXsd9XSBc7AUH79TVT9kvWSKt90.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b9d0eacbfb98c49b07a9ee7f8323e2cf9baff297", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/txtus-K1eOPZAabofXsd9XSBc7AUH79TVT9kvWSKt90.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1a17573a5779ae09127c79bc26d018698248f375", "width": 320, "height": 240}], "variants": {}, "id": "F_LL5KKmvuqYBKHaT_ho9YIjY4HYyHtfI6jtx2h2kpU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zbqhfn", "is_robot_indexable": true, "report_reasons": null, "author": "DataEngUncomplicated", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zbqhfn/new_aws_da_features_announced_by_swami/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/nQVQmbC9_jE", "subreddit_subscribers": 81830, "created_utc": 1670101088.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "AWS re:Invent 2022  Swami Sivasubramanian Keynote for Data &amp; Analytics (New Features &amp; Services)", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/nQVQmbC9_jE?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"AWS re:Invent 2022  Swami Sivasubramanian Keynote for Data &amp;amp; Analytics (New Features &amp;amp; Services)\"&gt;&lt;/iframe&gt;", "author_name": "DataEng Uncomplicated", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/nQVQmbC9_jE/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@DataEngUncomplicated"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have my GCP Professional data engineer exam on 27 Dec. I know most of the services and have high level understanding, but i lack indepth knowledge. Please share some tips to get it done.", "author_fullname": "t2_cyv1vd80", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GCP PDE on 27. Need Help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zcg6b6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670175960.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have my GCP Professional data engineer exam on 27 Dec. I know most of the services and have high level understanding, but i lack indepth knowledge. Please share some tips to get it done.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zcg6b6", "is_robot_indexable": true, "report_reasons": null, "author": "dummymum", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zcg6b6/gcp_pde_on_27_need_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zcg6b6/gcp_pde_on_27_need_help/", "subreddit_subscribers": 81830, "created_utc": 1670175960.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}