{"kind": "Listing", "data": {"after": null, "dist": 24, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Basically title - I've been thinking about this a lot lately and am curious to hear others' thoughts.\n\nSo far my main thought patterns have been along the lines of:\n\n1) Ways of working. In organisations I've been exposed to the ways of working for data teams have been all over the shop. Some are trending towards working more like SWE teams, some act as project teams, and some (most common IME) seem to exist on their own island inside an organisation. Does this create a risk that teams will by and large be working non-optimally?\n\n2) Businesses not knowing what they want out of their data. This I feel is pretty self-explanatory - if the business doesn't know what they want is there risk of decision-makers opting not to utilise the data, making data work redundant?\n\n3) Technology crossover and ambiguity. There is seemingly an unlimited number of technologies that can be utilized for various functions, with no clear use cases for which is best in what situations. Also, as technologies have expanded they have sought to expand functionality into other use cases, which further increases the permutations possible. Per examplur, for data orchestration there is ADF, Step Functions, Airflow, DBT, Flyte, Cloud Functions, Luigi, etc., etc. How can a business case be made for any of them without thorough testing, which is expensive and time-consuming?", "author_fullname": "t2_b3hw6tq1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some of the big problems Data Engineering currently faces / will face in the next 5-10 years?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zc6lvq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 61, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 61, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_1": 1}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670150717.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically title - I&amp;#39;ve been thinking about this a lot lately and am curious to hear others&amp;#39; thoughts.&lt;/p&gt;\n\n&lt;p&gt;So far my main thought patterns have been along the lines of:&lt;/p&gt;\n\n&lt;p&gt;1) Ways of working. In organisations I&amp;#39;ve been exposed to the ways of working for data teams have been all over the shop. Some are trending towards working more like SWE teams, some act as project teams, and some (most common IME) seem to exist on their own island inside an organisation. Does this create a risk that teams will by and large be working non-optimally?&lt;/p&gt;\n\n&lt;p&gt;2) Businesses not knowing what they want out of their data. This I feel is pretty self-explanatory - if the business doesn&amp;#39;t know what they want is there risk of decision-makers opting not to utilise the data, making data work redundant?&lt;/p&gt;\n\n&lt;p&gt;3) Technology crossover and ambiguity. There is seemingly an unlimited number of technologies that can be utilized for various functions, with no clear use cases for which is best in what situations. Also, as technologies have expanded they have sought to expand functionality into other use cases, which further increases the permutations possible. Per examplur, for data orchestration there is ADF, Step Functions, Airflow, DBT, Flyte, Cloud Functions, Luigi, etc., etc. How can a business case be made for any of them without thorough testing, which is expensive and time-consuming?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 100, "id": "gid_1", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Shows the Silver Award... and that's it.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Silver", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zc6lvq", "is_robot_indexable": true, "report_reasons": null, "author": "elevatebi", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zc6lvq/what_are_some_of_the_big_problems_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zc6lvq/what_are_some_of_the_big_problems_data/", "subreddit_subscribers": 81844, "created_utc": 1670150717.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m wondering if anyone has any advice or experience working as a data engineer when leadership / architects do not have a data background. \n\nOur leadership team has very strong SWE backgrounds but they don\u2019t seem to recognize data engineering as it\u2019s own speciality and so we\u2019ve had to go through a lot of reinventing the wheel. In many cases I already know about the wheel, but I have not found an effective way to communicate that they are trying to solve well known problems and that there are standard solutions. \n\nFor instance the other day they were trying to solve the canonical use case for lambda architecture and I couldn\u2019t convince them to use it or that they were falling into the anti patterns it was designed against. \n\nHave you all faced something similar in your organizations? How were you able to navigate the issues?", "author_fullname": "t2_f3dj7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Working as a data engineer where leadership does not have a data background", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zcgwt9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670177547.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m wondering if anyone has any advice or experience working as a data engineer when leadership / architects do not have a data background. &lt;/p&gt;\n\n&lt;p&gt;Our leadership team has very strong SWE backgrounds but they don\u2019t seem to recognize data engineering as it\u2019s own speciality and so we\u2019ve had to go through a lot of reinventing the wheel. In many cases I already know about the wheel, but I have not found an effective way to communicate that they are trying to solve well known problems and that there are standard solutions. &lt;/p&gt;\n\n&lt;p&gt;For instance the other day they were trying to solve the canonical use case for lambda architecture and I couldn\u2019t convince them to use it or that they were falling into the anti patterns it was designed against. &lt;/p&gt;\n\n&lt;p&gt;Have you all faced something similar in your organizations? How were you able to navigate the issues?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zcgwt9", "is_robot_indexable": true, "report_reasons": null, "author": "gummnutt", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zcgwt9/working_as_a_data_engineer_where_leadership_does/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zcgwt9/working_as_a_data_engineer_where_leadership_does/", "subreddit_subscribers": 81844, "created_utc": 1670177547.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I have built a simple ETL pipeline using Apache Airflow which is running locally for now. Now I wanted to deploy it to AWS. What would be the best way to do that? Do I just need to build container using docker and then deploy that to EC2? My goal is to run scheduler on daily basis to migrate data from source to destination.\n\nPS: I am just a beginner in data engineering so please ignore any mistake.", "author_fullname": "t2_udvutrbv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Etl pipeline deployment on AWS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zbs64g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670105178.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I have built a simple ETL pipeline using Apache Airflow which is running locally for now. Now I wanted to deploy it to AWS. What would be the best way to do that? Do I just need to build container using docker and then deploy that to EC2? My goal is to run scheduler on daily basis to migrate data from source to destination.&lt;/p&gt;\n\n&lt;p&gt;PS: I am just a beginner in data engineering so please ignore any mistake.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zbs64g", "is_robot_indexable": true, "report_reasons": null, "author": "Usamacheema12345", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zbs64g/etl_pipeline_deployment_on_aws/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zbs64g/etl_pipeline_deployment_on_aws/", "subreddit_subscribers": 81844, "created_utc": 1670105178.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve inherited a new project and my Airflow knowledge is rusty. From what I\u2019ve gathered so far, a lot of the tasks are doing some heavy lifting. E.g\n\nFirst task -&gt; Exports from external DB to GCS\n\nSecond task -&gt; Download file (can be up to 100mb) from GCS, parses file and saves as JSON. Uploads JSOn to GCS\n\nthis second DAG seems to be doing a lot of work, my understanding is that with Airflow the philosophy is for each task to only trigger external services. \n\nThoughts? I\u2019d rather not have to refactor this if it\u2019s commonly acceptable \ud83e\udd14", "author_fullname": "t2_htptc13q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you run Airflow purely as an orchestrator?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zbv3vk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670112704.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve inherited a new project and my Airflow knowledge is rusty. From what I\u2019ve gathered so far, a lot of the tasks are doing some heavy lifting. E.g&lt;/p&gt;\n\n&lt;p&gt;First task -&amp;gt; Exports from external DB to GCS&lt;/p&gt;\n\n&lt;p&gt;Second task -&amp;gt; Download file (can be up to 100mb) from GCS, parses file and saves as JSON. Uploads JSOn to GCS&lt;/p&gt;\n\n&lt;p&gt;this second DAG seems to be doing a lot of work, my understanding is that with Airflow the philosophy is for each task to only trigger external services. &lt;/p&gt;\n\n&lt;p&gt;Thoughts? I\u2019d rather not have to refactor this if it\u2019s commonly acceptable \ud83e\udd14&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zbv3vk", "is_robot_indexable": true, "report_reasons": null, "author": "Main_Tap_1256", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zbv3vk/do_you_run_airflow_purely_as_an_orchestrator/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zbv3vk/do_you_run_airflow_purely_as_an_orchestrator/", "subreddit_subscribers": 81844, "created_utc": 1670112704.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m new to Python and trying to wrap my brain around how these work together in practice. I feel like it\u2019d be really helpful to look at an example. Doesn\u2019t have to be these exact tools. \n\nThanks!", "author_fullname": "t2_88x87", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone have an example of a project where a handful of the more popular Python tools are used? (E.g. airbyte, airflow, dbt, and pandas)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zcdnel", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670170254.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m new to Python and trying to wrap my brain around how these work together in practice. I feel like it\u2019d be really helpful to look at an example. Doesn\u2019t have to be these exact tools. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zcdnel", "is_robot_indexable": true, "report_reasons": null, "author": "dicotyledon", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zcdnel/anyone_have_an_example_of_a_project_where_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zcdnel/anyone_have_an_example_of_a_project_where_a/", "subreddit_subscribers": 81844, "created_utc": 1670170254.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi.. I've seen the resources at the wiki page. But I feel if maybe I get a training through bootcamp or any other learning platforms, I might be able to learn data engineering better. I checked online came across Simplilearn. Has anyone taken the course there or any other better platforms. I can only learn Part Time due to my full time job. Thanks....", "author_fullname": "t2_np3evoin", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Online Learning platforms", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zbvuxe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670114784.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi.. I&amp;#39;ve seen the resources at the wiki page. But I feel if maybe I get a training through bootcamp or any other learning platforms, I might be able to learn data engineering better. I checked online came across Simplilearn. Has anyone taken the course there or any other better platforms. I can only learn Part Time due to my full time job. Thanks....&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zbvuxe", "is_robot_indexable": true, "report_reasons": null, "author": "naruzum", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zbvuxe/online_learning_platforms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zbvuxe/online_learning_platforms/", "subreddit_subscribers": 81844, "created_utc": 1670114784.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Let's say we are moving a table from a database to a data warehouse. The flow of the pipeline is table in RDS exported to S3 then Coud Storage and then Bigquery. The team has decided that this pipeline runs daily since reporting needs is only once a day. So the table can either contain additional rows or modified version of the existing rows. So my question is, would it be better to: 1) overwrite the whole table during daily update; or 2) just append the new rows and update the existing rows which got modified.\n\nThank you!", "author_fullname": "t2_6jogidac", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you handle daily update of table?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zc0f1m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670128216.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s say we are moving a table from a database to a data warehouse. The flow of the pipeline is table in RDS exported to S3 then Coud Storage and then Bigquery. The team has decided that this pipeline runs daily since reporting needs is only once a day. So the table can either contain additional rows or modified version of the existing rows. So my question is, would it be better to: 1) overwrite the whole table during daily update; or 2) just append the new rows and update the existing rows which got modified.&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zc0f1m", "is_robot_indexable": true, "report_reasons": null, "author": "_barnuts", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zc0f1m/how_do_you_handle_daily_update_of_table/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zc0f1m/how_do_you_handle_daily_update_of_table/", "subreddit_subscribers": 81844, "created_utc": 1670128216.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've recently left my full time role as a Data Engineer and I'm looking for some advice.\n\nI want to spend some time away from the 9-5 for many reasons, but I would like to keep my hand in so to speak. Ideally I would work maybe 2 or 3 days a week with flexible hours, using my data skills, but not on anything high pressured or full on.\n\nAny ideas on what sorts of roles I could look for? Or what sorts of companies? \n\nI have thought about some kind of SQL migration work- I love writing migration scripts. But not sure what this is called- does it come under DBA responsibilities? \nI'm also good at optimizing SQL queries, happy to rewrite stored procedures etc. \nAgain, not sure what this role would be called.\n\nI do also have backend engineering experience, am quite familiar with AWS tools, and also snowflake.", "author_fullname": "t2_5n8mvd7p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Part time roles? Ideas of what to look for", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zbxhcr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670119496.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve recently left my full time role as a Data Engineer and I&amp;#39;m looking for some advice.&lt;/p&gt;\n\n&lt;p&gt;I want to spend some time away from the 9-5 for many reasons, but I would like to keep my hand in so to speak. Ideally I would work maybe 2 or 3 days a week with flexible hours, using my data skills, but not on anything high pressured or full on.&lt;/p&gt;\n\n&lt;p&gt;Any ideas on what sorts of roles I could look for? Or what sorts of companies? &lt;/p&gt;\n\n&lt;p&gt;I have thought about some kind of SQL migration work- I love writing migration scripts. But not sure what this is called- does it come under DBA responsibilities? \nI&amp;#39;m also good at optimizing SQL queries, happy to rewrite stored procedures etc. \nAgain, not sure what this role would be called.&lt;/p&gt;\n\n&lt;p&gt;I do also have backend engineering experience, am quite familiar with AWS tools, and also snowflake.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zbxhcr", "is_robot_indexable": true, "report_reasons": null, "author": "kaiso_gunkan", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zbxhcr/part_time_roles_ideas_of_what_to_look_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zbxhcr/part_time_roles_ideas_of_what_to_look_for/", "subreddit_subscribers": 81844, "created_utc": 1670119496.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys,\n\nI'm currently working on power bi and SQL outputting reports for a health care. How do I transition to a date engineering role. \nIf you may please explain how did you get started, transformed. \nHow did you get interview calls. \nDid you attend any course, was this the first role you got after your Univ. \nI'm looking for a more positive story because. After 5 years in civil industry, I've changed role into an analyst. But getting calls for data engineering seems to be tough. \nRight now I have nearly 1 year experience as an analyst\n \nAll/any response will be very much appreciated.", "author_fullname": "t2_11ivtgn5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get started in a data engineering role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zc9s4i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670160374.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working on power bi and SQL outputting reports for a health care. How do I transition to a date engineering role. \nIf you may please explain how did you get started, transformed. \nHow did you get interview calls. \nDid you attend any course, was this the first role you got after your Univ. \nI&amp;#39;m looking for a more positive story because. After 5 years in civil industry, I&amp;#39;ve changed role into an analyst. But getting calls for data engineering seems to be tough. \nRight now I have nearly 1 year experience as an analyst&lt;/p&gt;\n\n&lt;p&gt;All/any response will be very much appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zc9s4i", "is_robot_indexable": true, "report_reasons": null, "author": "westisnoteast", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zc9s4i/how_to_get_started_in_a_data_engineering_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zc9s4i/how_to_get_started_in_a_data_engineering_role/", "subreddit_subscribers": 81844, "created_utc": 1670160374.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've got to set-up a very simple data pipeline :\n\n1.1 - Run a job to hit API every 30mins, compress and save file to S3. Total job will hit 9 endpoints and will complete within 15mins easily, more like &lt;3min for all 9 if I add a throttle \n\n1.2- send email potentially, depending on content of response\n\n2.0 - move files from S3 to snowflake (will use external stage)\n\nNot much to it and I'm confident in how to do it. What I'm not confident in though, is the best way to do it. The files are small, there will be a maximum of 10files on each run\n\nI wanted to use Airflow, but after setting this up and testing successfully (locally), frankly it just seems like overkill to use a tool like that for such a small amount of data - there also is the issue of deployment. Running it locally on docker, my device sounds like it wants to kick the bucket. Options: \n\n1) The managed services on AWS (e g MWAA) seem expensive (again, why pay so much for such a small task)\n\n2) Kubernetes on something like EKS - more appealing but seems like severe overkill now\n\n3) deploy on EC2, using Docker in production would be fine in this use case so could do this - but I've read that using VMs in the cloud generally means you're not using it the cloud properly (hence my question on best practices)\n\n4) others?\n\nThis can be done with a Cron job, I'm more tempted to bin off these fancy tools, set-up a cron job and have this run on a free tier EC2, or use AWS Lambda \n\nIn summary, I'm looking for advice on the best practice when it comes to deployment\n\nAny advice is welcome", "author_fullname": "t2_1w1o79i7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to get API responses to S3", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zch4cg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1670178953.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670178012.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got to set-up a very simple data pipeline :&lt;/p&gt;\n\n&lt;p&gt;1.1 - Run a job to hit API every 30mins, compress and save file to S3. Total job will hit 9 endpoints and will complete within 15mins easily, more like &amp;lt;3min for all 9 if I add a throttle &lt;/p&gt;\n\n&lt;p&gt;1.2- send email potentially, depending on content of response&lt;/p&gt;\n\n&lt;p&gt;2.0 - move files from S3 to snowflake (will use external stage)&lt;/p&gt;\n\n&lt;p&gt;Not much to it and I&amp;#39;m confident in how to do it. What I&amp;#39;m not confident in though, is the best way to do it. The files are small, there will be a maximum of 10files on each run&lt;/p&gt;\n\n&lt;p&gt;I wanted to use Airflow, but after setting this up and testing successfully (locally), frankly it just seems like overkill to use a tool like that for such a small amount of data - there also is the issue of deployment. Running it locally on docker, my device sounds like it wants to kick the bucket. Options: &lt;/p&gt;\n\n&lt;p&gt;1) The managed services on AWS (e g MWAA) seem expensive (again, why pay so much for such a small task)&lt;/p&gt;\n\n&lt;p&gt;2) Kubernetes on something like EKS - more appealing but seems like severe overkill now&lt;/p&gt;\n\n&lt;p&gt;3) deploy on EC2, using Docker in production would be fine in this use case so could do this - but I&amp;#39;ve read that using VMs in the cloud generally means you&amp;#39;re not using it the cloud properly (hence my question on best practices)&lt;/p&gt;\n\n&lt;p&gt;4) others?&lt;/p&gt;\n\n&lt;p&gt;This can be done with a Cron job, I&amp;#39;m more tempted to bin off these fancy tools, set-up a cron job and have this run on a free tier EC2, or use AWS Lambda &lt;/p&gt;\n\n&lt;p&gt;In summary, I&amp;#39;m looking for advice on the best practice when it comes to deployment&lt;/p&gt;\n\n&lt;p&gt;Any advice is welcome&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zch4cg", "is_robot_indexable": true, "report_reasons": null, "author": "tea_horse", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zch4cg/best_way_to_get_api_responses_to_s3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zch4cg/best_way_to_get_api_responses_to_s3/", "subreddit_subscribers": 81844, "created_utc": 1670178012.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi. Curious to hear the communities approach to modelling a fact table which represents reports involving varying party counts. \n\nReporting needs are to see counts of incidents, people involved in various events and the reporter(s) of the event. \n\nBasically it\u2019s a factless fact table to represent an incident, which might have 1,2,3\u2026,n people involved. Parallel might be an invoice roll up, but in this case there isn\u2019t numbers, the count is the incident that\u2019s being reported on. \n\nI don\u2019t think that throwing it in columns is the right approach due to the variability in people counts, so I think duplicating each row and varying the people ID for each row, which is tied to a degenerate dimension against the incident number.\n\nI guess my uncertain is I\u2019ll need to keep the text block, but that\u2019ll balloon my model size. Other part is the users will need to be aware that there is duplication. \n\nHow would you folks approach this? Aggregate fact table for the incident with a column of count, paired with a second detailed level one that excludes the text block? All in one table? If I duplicate the tables I\u2019ll need to extract my incident ID to a dimension that only has the ID which also feels incorrect. \n\nExtension is one or more people might also report on this too, which would create even more duplication!\n\nThanks!", "author_fullname": "t2_ahu1o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Modelling investigation fact table with varying people counts", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zcc9qg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670167020.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi. Curious to hear the communities approach to modelling a fact table which represents reports involving varying party counts. &lt;/p&gt;\n\n&lt;p&gt;Reporting needs are to see counts of incidents, people involved in various events and the reporter(s) of the event. &lt;/p&gt;\n\n&lt;p&gt;Basically it\u2019s a factless fact table to represent an incident, which might have 1,2,3\u2026,n people involved. Parallel might be an invoice roll up, but in this case there isn\u2019t numbers, the count is the incident that\u2019s being reported on. &lt;/p&gt;\n\n&lt;p&gt;I don\u2019t think that throwing it in columns is the right approach due to the variability in people counts, so I think duplicating each row and varying the people ID for each row, which is tied to a degenerate dimension against the incident number.&lt;/p&gt;\n\n&lt;p&gt;I guess my uncertain is I\u2019ll need to keep the text block, but that\u2019ll balloon my model size. Other part is the users will need to be aware that there is duplication. &lt;/p&gt;\n\n&lt;p&gt;How would you folks approach this? Aggregate fact table for the incident with a column of count, paired with a second detailed level one that excludes the text block? All in one table? If I duplicate the tables I\u2019ll need to extract my incident ID to a dimension that only has the ID which also feels incorrect. &lt;/p&gt;\n\n&lt;p&gt;Extension is one or more people might also report on this too, which would create even more duplication!&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zcc9qg", "is_robot_indexable": true, "report_reasons": null, "author": "Namur007", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zcc9qg/modelling_investigation_fact_table_with_varying/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zcc9qg/modelling_investigation_fact_table_with_varying/", "subreddit_subscribers": 81844, "created_utc": 1670167020.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are the best tools to provision a database schema and are there programmatic ones?\n\nCurrently I am looking at SQL type databases", "author_fullname": "t2_172g1e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Provision Database Schema", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zc4pbg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670143593.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the best tools to provision a database schema and are there programmatic ones?&lt;/p&gt;\n\n&lt;p&gt;Currently I am looking at SQL type databases&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zc4pbg", "is_robot_indexable": true, "report_reasons": null, "author": "stevecrox0914", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zc4pbg/provision_database_schema/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zc4pbg/provision_database_schema/", "subreddit_subscribers": 81844, "created_utc": 1670143593.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is not a job for me question. I\u2019ve just noticed that there seems to be a trend with data science where literally everything data-related is thrown under data science. I wonder how much of the projected growth rate from the BLS will be data science jobs vs things like data engineering. Or if the two roles will just combine into some \u201cfull stack\u201d abomination", "author_fullname": "t2_mheiuet5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much of Data Science\u2019s projected 36% growth rate over the next 10 years do you think will actually be DE instead?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zclj15", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670187670.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is not a job for me question. I\u2019ve just noticed that there seems to be a trend with data science where literally everything data-related is thrown under data science. I wonder how much of the projected growth rate from the BLS will be data science jobs vs things like data engineering. Or if the two roles will just combine into some \u201cfull stack\u201d abomination&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zclj15", "is_robot_indexable": true, "report_reasons": null, "author": "anonString", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zclj15/how_much_of_data_sciences_projected_36_growth/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zclj15/how_much_of_data_sciences_projected_36_growth/", "subreddit_subscribers": 81844, "created_utc": 1670187670.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "And why are there not efforts to modernize and centralize gov systems? For example when the amount of unemployment happened during lockdown, the state of New Jersey (I think) couldn\u2019t handle it and the website/system broke.. but it was created in such an old, unused coding language that literally only a handful of people *on earth* still know how to use it, and they had to pull them out from retirement to help fix it. So I guess it was secure like that, but, yanno.\n\nWhat would it take to modernize these systems? Why don\u2019t government entities see the value in updating their systems and consolidating info to make it easier to do things? Why do a lot of gov websites look like they were made by a high schooler in a web design class in 2007? \n\nIs it going to take certain people getting into certain positions of power? What\u2019s the holdup?", "author_fullname": "t2_1hpr2sqq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why are government systems so awful?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zckzwm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670186526.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;And why are there not efforts to modernize and centralize gov systems? For example when the amount of unemployment happened during lockdown, the state of New Jersey (I think) couldn\u2019t handle it and the website/system broke.. but it was created in such an old, unused coding language that literally only a handful of people &lt;em&gt;on earth&lt;/em&gt; still know how to use it, and they had to pull them out from retirement to help fix it. So I guess it was secure like that, but, yanno.&lt;/p&gt;\n\n&lt;p&gt;What would it take to modernize these systems? Why don\u2019t government entities see the value in updating their systems and consolidating info to make it easier to do things? Why do a lot of gov websites look like they were made by a high schooler in a web design class in 2007? &lt;/p&gt;\n\n&lt;p&gt;Is it going to take certain people getting into certain positions of power? What\u2019s the holdup?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zckzwm", "is_robot_indexable": true, "report_reasons": null, "author": "i-lik-the-bred", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zckzwm/why_are_government_systems_so_awful/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zckzwm/why_are_government_systems_so_awful/", "subreddit_subscribers": 81844, "created_utc": 1670186526.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,  I am having trouble to parse html source code as there is no definitive template maintained in the portal and seems like it's written in free-hand version. Tried Beautifulsoup to extract the particular part required from the page as below:\n\n`required_data = soup.find(\"div\", {\"id\": \"divExpectedResults\"})`\n\nAs I mentioned earlier, there is no clear definitive template inside this class for me extract data further. Hence not be able to add many rules to entirely extract the way I want. Basically want to extract as we read from the web pages but not able to do so.   \nAlong the way, I managed to find some 3rd party tools like Doxillion etc which almost generates what we need and could massage a bit to extract very easily. Anyone has used such packages?\n\nDo we have any other html parsers which can parse exactly how we see the web page?", "author_fullname": "t2_eozceps7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Available packages for html parsing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zc58ro", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670145677.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,  I am having trouble to parse html source code as there is no definitive template maintained in the portal and seems like it&amp;#39;s written in free-hand version. Tried Beautifulsoup to extract the particular part required from the page as below:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;required_data = soup.find(&amp;quot;div&amp;quot;, {&amp;quot;id&amp;quot;: &amp;quot;divExpectedResults&amp;quot;})&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;As I mentioned earlier, there is no clear definitive template inside this class for me extract data further. Hence not be able to add many rules to entirely extract the way I want. Basically want to extract as we read from the web pages but not able to do so.&lt;br/&gt;\nAlong the way, I managed to find some 3rd party tools like Doxillion etc which almost generates what we need and could massage a bit to extract very easily. Anyone has used such packages?&lt;/p&gt;\n\n&lt;p&gt;Do we have any other html parsers which can parse exactly how we see the web page?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zc58ro", "is_robot_indexable": true, "report_reasons": null, "author": "Liily_07", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zc58ro/available_packages_for_html_parsing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zc58ro/available_packages_for_html_parsing/", "subreddit_subscribers": 81844, "created_utc": 1670145677.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey! Folks. Just trying to put these two together cost wise.\n\nA small audit firm is conflicted between the two. Please note that they have only one analyst so far to query the data. I am trying to decide between the two.\n\nMy question is I know snowflake is better. But need an estimated figure. The data is quite not as large. \n\nHow much will they be looking at? X plus in redshift which is vcpu 4 and memory 32 is about $922. \n\nHow much will this be on snowflake? I know it might be hard to judge but what is a possible estimate?\n\nAlso will x plus on redshift be enough while we build out the infrastructure??? Or de we do the 4x large?\n\nThey don\u2019t deal with a very high amount of data. I don\u2019t think they deal with more than 10million rows. They still use excel pretty much.", "author_fullname": "t2_3w9dfvgr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Redshift vs Snowflake Cost", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zcmvsb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670190575.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey! Folks. Just trying to put these two together cost wise.&lt;/p&gt;\n\n&lt;p&gt;A small audit firm is conflicted between the two. Please note that they have only one analyst so far to query the data. I am trying to decide between the two.&lt;/p&gt;\n\n&lt;p&gt;My question is I know snowflake is better. But need an estimated figure. The data is quite not as large. &lt;/p&gt;\n\n&lt;p&gt;How much will they be looking at? X plus in redshift which is vcpu 4 and memory 32 is about $922. &lt;/p&gt;\n\n&lt;p&gt;How much will this be on snowflake? I know it might be hard to judge but what is a possible estimate?&lt;/p&gt;\n\n&lt;p&gt;Also will x plus on redshift be enough while we build out the infrastructure??? Or de we do the 4x large?&lt;/p&gt;\n\n&lt;p&gt;They don\u2019t deal with a very high amount of data. I don\u2019t think they deal with more than 10million rows. They still use excel pretty much.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zcmvsb", "is_robot_indexable": true, "report_reasons": null, "author": "mrmilata", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zcmvsb/redshift_vs_snowflake_cost/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zcmvsb/redshift_vs_snowflake_cost/", "subreddit_subscribers": 81844, "created_utc": 1670190575.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am quite new to Apache Airflow and I am building a data pipeline that extract batch data from different APIs.\n\nThe way I am doing it is by creating a different task node for each source to extract the data and store it into s3, then a few parallel nodes to transform the data and finally some other nodes to load those object into some tables.\n\nThe problem that I am facing is that I read that the code inside each node should be really simple, so in each one I am calling a ECSOperator to run my conde in a separate ECS container each, however some of the nodes (like the extract one) are quite simple so I am not sure if the code should run in the Airflow worker itself or not.\n\nSo what I am asking is what should I consider to put into an ECS container and what should run in the Airflow worker itself?", "author_fullname": "t2_whbx6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How simple should be an Airflow task node?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zcmpxz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670190224.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am quite new to Apache Airflow and I am building a data pipeline that extract batch data from different APIs.&lt;/p&gt;\n\n&lt;p&gt;The way I am doing it is by creating a different task node for each source to extract the data and store it into s3, then a few parallel nodes to transform the data and finally some other nodes to load those object into some tables.&lt;/p&gt;\n\n&lt;p&gt;The problem that I am facing is that I read that the code inside each node should be really simple, so in each one I am calling a ECSOperator to run my conde in a separate ECS container each, however some of the nodes (like the extract one) are quite simple so I am not sure if the code should run in the Airflow worker itself or not.&lt;/p&gt;\n\n&lt;p&gt;So what I am asking is what should I consider to put into an ECS container and what should run in the Airflow worker itself?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zcmpxz", "is_robot_indexable": true, "report_reasons": null, "author": "koalo_", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zcmpxz/how_simple_should_be_an_airflow_task_node/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zcmpxz/how_simple_should_be_an_airflow_task_node/", "subreddit_subscribers": 81844, "created_utc": 1670190224.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all, I'm curious as to how you guys build your ETL pipelines. \n\n1. Do you have 1 dedicated pipeline for every table with specific extraction and transformation procedures only for that table?\n2. Or do you build 1 massive pipeline extracting all tables with transformation procedures for all the tables?\n3. Or do you do a combination of both?\n\nThanks a lot again for the help.", "author_fullname": "t2_6jogidac", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A pipeline for every table or not", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zckdwm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670185181.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all, I&amp;#39;m curious as to how you guys build your ETL pipelines. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Do you have 1 dedicated pipeline for every table with specific extraction and transformation procedures only for that table?&lt;/li&gt;\n&lt;li&gt;Or do you build 1 massive pipeline extracting all tables with transformation procedures for all the tables?&lt;/li&gt;\n&lt;li&gt;Or do you do a combination of both?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thanks a lot again for the help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zckdwm", "is_robot_indexable": true, "report_reasons": null, "author": "_barnuts", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zckdwm/a_pipeline_for_every_table_or_not/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zckdwm/a_pipeline_for_every_table_or_not/", "subreddit_subscribers": 81844, "created_utc": 1670185181.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys I'm currently evaluating the use of Azure Synapse for a DW project. I am fairly clear on how to get the data from the source systems to Azure SQL Pools in Synapse using pipelines. \n\nWhat I'm not so clear on is what the best method is to expose the data in the warehouse to business users for analysis. I have looked at Power BI datasets, however I'm not entirely sure what the process is for loading and keeping the data updated in those datasets.\n\nAnalysts will typically consume the data via Power BI or Excel. \n\nAdvice would be really appreciated.", "author_fullname": "t2_nhdew", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practice for data in Azure Synapse to business analysts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zciitk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670181070.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys I&amp;#39;m currently evaluating the use of Azure Synapse for a DW project. I am fairly clear on how to get the data from the source systems to Azure SQL Pools in Synapse using pipelines. &lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m not so clear on is what the best method is to expose the data in the warehouse to business users for analysis. I have looked at Power BI datasets, however I&amp;#39;m not entirely sure what the process is for loading and keeping the data updated in those datasets.&lt;/p&gt;\n\n&lt;p&gt;Analysts will typically consume the data via Power BI or Excel. &lt;/p&gt;\n\n&lt;p&gt;Advice would be really appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zciitk", "is_robot_indexable": true, "report_reasons": null, "author": "MonkeyMaster64", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zciitk/best_practice_for_data_in_azure_synapse_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zciitk/best_practice_for_data_in_azure_synapse_to/", "subreddit_subscribers": 81844, "created_utc": 1670181070.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For context, I work at a company who collect citizen data from town halls, to clean/normalize it and do some BI's on it.\nData can come in many many ways (from a plain txt/CSV to a mySQL/mongoDB) but they are information is always the same (Social Security number, name, address).\n\nI'm fairly new to the company (and to programming/data engineering as a whole, for that matter, worked on finances before) but the way they work with data seems archaic (Talend), and I found myself losing so much time to ingest these data to the company standard postgresDB schema (which, after that first ingestion, everything is automatized to clean and do the BI's. It's not the best but def not the concern right now).\n\nI'm good at python and the company is open to new ways to work with the ETL, so I was wondering, how would you guys handle this kind of stuff?", "author_fullname": "t2_uqv37xia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's your way to handle To/From problems?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zbyf9c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670122238.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For context, I work at a company who collect citizen data from town halls, to clean/normalize it and do some BI&amp;#39;s on it.\nData can come in many many ways (from a plain txt/CSV to a mySQL/mongoDB) but they are information is always the same (Social Security number, name, address).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m fairly new to the company (and to programming/data engineering as a whole, for that matter, worked on finances before) but the way they work with data seems archaic (Talend), and I found myself losing so much time to ingest these data to the company standard postgresDB schema (which, after that first ingestion, everything is automatized to clean and do the BI&amp;#39;s. It&amp;#39;s not the best but def not the concern right now).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m good at python and the company is open to new ways to work with the ETL, so I was wondering, how would you guys handle this kind of stuff?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zbyf9c", "is_robot_indexable": true, "report_reasons": null, "author": "DataThatGraph", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zbyf9c/whats_your_way_to_handle_tofrom_problems/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zbyf9c/whats_your_way_to_handle_tofrom_problems/", "subreddit_subscribers": 81844, "created_utc": 1670122238.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does there exist a way to take the Microsoft certification DP-203 exam for free?", "author_fullname": "t2_7a8qzc12", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Microsoft certification DP-203 for free", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zcmomg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670190142.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does there exist a way to take the Microsoft certification DP-203 exam for free?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zcmomg", "is_robot_indexable": true, "report_reasons": null, "author": "vroemboem", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zcmomg/microsoft_certification_dp203_for_free/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zcmomg/microsoft_certification_dp203_for_free/", "subreddit_subscribers": 81844, "created_utc": 1670190142.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hello, data engineering folks, \n\nI was learning Kinesis right now and while doing so I stumbled upon KPL &amp; KCL libraries which are written exclusively in Java, my Java is kinda rusty and I wanted to ask if is it worth it to learn the KPL and KCL libraries in Java for most use cases or does the AWS SDK provide enough to cover most use cases?", "author_fullname": "t2_64nmnknh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kinesis KPL &amp; KCL vs using AWS SDK", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zca4al", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670161474.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hello, data engineering folks, &lt;/p&gt;\n\n&lt;p&gt;I was learning Kinesis right now and while doing so I stumbled upon KPL &amp;amp; KCL libraries which are written exclusively in Java, my Java is kinda rusty and I wanted to ask if is it worth it to learn the KPL and KCL libraries in Java for most use cases or does the AWS SDK provide enough to cover most use cases?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zca4al", "is_robot_indexable": true, "report_reasons": null, "author": "SnooDoggos5883", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zca4al/kinesis_kpl_kcl_vs_using_aws_sdk/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zca4al/kinesis_kpl_kcl_vs_using_aws_sdk/", "subreddit_subscribers": 81844, "created_utc": 1670161474.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! I'm currently studying about different distributed file systems! I got stuck in distinguishing between Hadoop FS and Ceph FS. The only difference that I got is the way that each of them stores data (HDFS seems to store files at random, whereas Ceph is based on CRUSH algorithm, resembling consistent hashing). I would like to have more differences and if possible, some benchmarks between these two file storage. Thank you in advance!", "author_fullname": "t2_2uelc2i1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the difference between HDFS and CephFS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zc6zi4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670151917.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I&amp;#39;m currently studying about different distributed file systems! I got stuck in distinguishing between Hadoop FS and Ceph FS. The only difference that I got is the way that each of them stores data (HDFS seems to store files at random, whereas Ceph is based on CRUSH algorithm, resembling consistent hashing). I would like to have more differences and if possible, some benchmarks between these two file storage. Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zc6zi4", "is_robot_indexable": true, "report_reasons": null, "author": "minhrongcon2000", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zc6zi4/what_is_the_difference_between_hdfs_and_cephfs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zc6zi4/what_is_the_difference_between_hdfs_and_cephfs/", "subreddit_subscribers": 81844, "created_utc": 1670151917.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have my GCP Professional data engineer exam on 27 Dec. I know most of the services and have high level understanding, but i lack indepth knowledge. Please share some tips to get it done.", "author_fullname": "t2_cyv1vd80", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GCP PDE on 27. Need Help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zcg6b6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670175960.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have my GCP Professional data engineer exam on 27 Dec. I know most of the services and have high level understanding, but i lack indepth knowledge. Please share some tips to get it done.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zcg6b6", "is_robot_indexable": true, "report_reasons": null, "author": "dummymum", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zcg6b6/gcp_pde_on_27_need_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zcg6b6/gcp_pde_on_27_need_help/", "subreddit_subscribers": 81844, "created_utc": 1670175960.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}