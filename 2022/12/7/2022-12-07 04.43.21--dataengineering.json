{"kind": "Listing", "data": {"after": "t3_ze3kgz", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, fellow data engineers! \n\n  \nI've built a tool to find the best resources shared on r/dataengineering as well as other subreddits.   \nHere is the link: [https://www.gembase.ai/articles?search=dataengineering](https://www.gembase.ai/articles?search=dataengineering)  \n\n\n**Architecture**\n\nI gathered all the archive data from Reddit.\n\n* Then extracted URLs with Go on a big EC2 machine. \n* The screenshots and titles were scraped using Python + Playwright hosted on \\~1000 ECS tasks. \n* The recommendations were offline computed with R + Tidyverse.\n\nI hope you will enjoy it. Feedback and questions are really appreciated.", "author_fullname": "t2_21q5bign", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The most shared resources from r/dataengineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zebb3o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 102, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 102, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670344725.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, fellow data engineers! &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve built a tool to find the best resources shared on &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt; as well as other subreddits.&lt;br/&gt;\nHere is the link: &lt;a href=\"https://www.gembase.ai/articles?search=dataengineering\"&gt;https://www.gembase.ai/articles?search=dataengineering&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Architecture&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I gathered all the archive data from Reddit.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Then extracted URLs with Go on a big EC2 machine. &lt;/li&gt;\n&lt;li&gt;The screenshots and titles were scraped using Python + Playwright hosted on ~1000 ECS tasks. &lt;/li&gt;\n&lt;li&gt;The recommendations were offline computed with R + Tidyverse.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I hope you will enjoy it. Feedback and questions are really appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zebb3o", "is_robot_indexable": true, "report_reasons": null, "author": "flpezet", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zebb3o/the_most_shared_resources_from_rdataengineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zebb3o/the_most_shared_resources_from_rdataengineering/", "subreddit_subscribers": 82076, "created_utc": 1670344725.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI was asked this question for a Senior Data Engineer interview. A cycling race is composed of many legs. Each leg goes from one city(A) to another(B). Cyclists then rest for the night and start the next leg of journey from (B) to (C). If the legs are represented by Tuples (A,B), (B,C), (C,D)...and given a list of tuples out of order example \\[(C,D),(A,B),(B,C)...\\] can you print out the correct order of cities in the race (example \"A B C D..\")\n\nExample \\[(A C) (B D) (C B)\\]\n\noutput: A C B D \\[(C B) (D C) (B E) (A D)\\] output A D C B E.\n\nI was supposed to write code in C#. I was unable to solve this. This was my thought process. Treat it like linked list. If List-&gt; next is null then it's the end of race and if List-&gt;prev is null it's the Start of race.\n\nCan anyone guide me with the coding part?", "author_fullname": "t2_gp13ce3a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview coding question that I couldn't solve", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ze798y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 63, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 63, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670334511.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I was asked this question for a Senior Data Engineer interview. A cycling race is composed of many legs. Each leg goes from one city(A) to another(B). Cyclists then rest for the night and start the next leg of journey from (B) to (C). If the legs are represented by Tuples (A,B), (B,C), (C,D)...and given a list of tuples out of order example [(C,D),(A,B),(B,C)...] can you print out the correct order of cities in the race (example &amp;quot;A B C D..&amp;quot;)&lt;/p&gt;\n\n&lt;p&gt;Example [(A C) (B D) (C B)]&lt;/p&gt;\n\n&lt;p&gt;output: A C B D [(C B) (D C) (B E) (A D)] output A D C B E.&lt;/p&gt;\n\n&lt;p&gt;I was supposed to write code in C#. I was unable to solve this. This was my thought process. Treat it like linked list. If List-&amp;gt; next is null then it&amp;#39;s the end of race and if List-&amp;gt;prev is null it&amp;#39;s the Start of race.&lt;/p&gt;\n\n&lt;p&gt;Can anyone guide me with the coding part?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "ze798y", "is_robot_indexable": true, "report_reasons": null, "author": "meridian_12", "discussion_type": null, "num_comments": 47, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ze798y/interview_coding_question_that_i_couldnt_solve/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ze798y/interview_coding_question_that_i_couldnt_solve/", "subreddit_subscribers": 82076, "created_utc": 1670334511.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Not sure if Analytics engineers is the correct term. I'm referring to the position that essentially transforms business oriented questions into queries and dashboards. ChatGPT seems to wipe the floor with such tasks and my manager is already hyping us to build something on top of it. \n\nI'm interested in hearing your opinions, as I'm rather green in the field.\n\nThanks!", "author_fullname": "t2_xptd9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Analytics engineering with ChatGPT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zefba4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670354270.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not sure if Analytics engineers is the correct term. I&amp;#39;m referring to the position that essentially transforms business oriented questions into queries and dashboards. ChatGPT seems to wipe the floor with such tasks and my manager is already hyping us to build something on top of it. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m interested in hearing your opinions, as I&amp;#39;m rather green in the field.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zefba4", "is_robot_indexable": true, "report_reasons": null, "author": "UltimateHorse", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zefba4/analytics_engineering_with_chatgpt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zefba4/analytics_engineering_with_chatgpt/", "subreddit_subscribers": 82076, "created_utc": 1670354270.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So basically the title. It seems like most companies went on rampage to hire data scientists, and now they're searching for 1-2 data engineers. There's no hierarchy that I know of for data engineers, and I have 3 offers from big companies to do their data engineering work in the cloud. In my present company we are a much bigger team, but we're paid shit.\n\nIn these big companies the pay is huge (3x to what I'm paid now) but the backdrop is I'll have to do most of the stuff along with another person to make a warehouse for their analysts/data scientists. Should I jump ship or stay here?", "author_fullname": "t2_l35gwhuh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is It Bad To Be the Only Data Engineer Hired in a Company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zegx37", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670358043.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So basically the title. It seems like most companies went on rampage to hire data scientists, and now they&amp;#39;re searching for 1-2 data engineers. There&amp;#39;s no hierarchy that I know of for data engineers, and I have 3 offers from big companies to do their data engineering work in the cloud. In my present company we are a much bigger team, but we&amp;#39;re paid shit.&lt;/p&gt;\n\n&lt;p&gt;In these big companies the pay is huge (3x to what I&amp;#39;m paid now) but the backdrop is I&amp;#39;ll have to do most of the stuff along with another person to make a warehouse for their analysts/data scientists. Should I jump ship or stay here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zegx37", "is_robot_indexable": true, "report_reasons": null, "author": "Senior_Anteater4688", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zegx37/is_it_bad_to_be_the_only_data_engineer_hired_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zegx37/is_it_bad_to_be_the_only_data_engineer_hired_in_a/", "subreddit_subscribers": 82076, "created_utc": 1670358043.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So, i just got hired as a data analyst, for a job that uses Excel most of the time, sometimes SQL and Power BI.\n\nBut i really want to get in the D.E area, and was wondering if this job experience could help me with that, because i came from a different field (laboratory analysis on chemicals). I'm aware it'll take time, i'm planning to stay on this job for at least 1-2 years, and studying to get in D.E for like 2hours/day that i have some free time.", "author_fullname": "t2_vordwax", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does experience in D.A help to get a job in D.E?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ze7pmz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670335695.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, i just got hired as a data analyst, for a job that uses Excel most of the time, sometimes SQL and Power BI.&lt;/p&gt;\n\n&lt;p&gt;But i really want to get in the D.E area, and was wondering if this job experience could help me with that, because i came from a different field (laboratory analysis on chemicals). I&amp;#39;m aware it&amp;#39;ll take time, i&amp;#39;m planning to stay on this job for at least 1-2 years, and studying to get in D.E for like 2hours/day that i have some free time.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ze7pmz", "is_robot_indexable": true, "report_reasons": null, "author": "Utopya96", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ze7pmz/does_experience_in_da_help_to_get_a_job_in_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ze7pmz/does_experience_in_da_help_to_get_a_job_in_de/", "subreddit_subscribers": 82076, "created_utc": 1670335695.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi redditors,\n\nThis is an interview question in Spark which has had me going into rabbithole of spark and yet I'm unable to find an answer. \n\nSo the question is, once you have submitted a spark job and see that it is running slow, how do you increase the cores/resources on the fly( without stopping and re running the job with increased resources). Is this even possible?", "author_fullname": "t2_98w2eb47", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview question in Spark yet to be solved", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zeg4nm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670356236.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi redditors,&lt;/p&gt;\n\n&lt;p&gt;This is an interview question in Spark which has had me going into rabbithole of spark and yet I&amp;#39;m unable to find an answer. &lt;/p&gt;\n\n&lt;p&gt;So the question is, once you have submitted a spark job and see that it is running slow, how do you increase the cores/resources on the fly( without stopping and re running the job with increased resources). Is this even possible?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "zeg4nm", "is_robot_indexable": true, "report_reasons": null, "author": "cherryblossomslove", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zeg4nm/interview_question_in_spark_yet_to_be_solved/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zeg4nm/interview_question_in_spark_yet_to_be_solved/", "subreddit_subscribers": 82076, "created_utc": 1670356236.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI do not waste your time with self-promoting content so that it will be really quick. I just want to share with you that I started my publication \"data news\" a few months ago to deliver only technical topics from the data world. \n\nIf you are interested in such a topic, you can jump into it: [https://patrikbraborec.substack.com/p/data-news-8](https://patrikbraborec.substack.com/p/data-news-8)", "author_fullname": "t2_kyoi486i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[ALERT - SELF PROMOTION] data news - once a week (Monday), I deliver only technical topics from the data world", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ze179z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1670317505.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I do not waste your time with self-promoting content so that it will be really quick. I just want to share with you that I started my publication &amp;quot;data news&amp;quot; a few months ago to deliver only technical topics from the data world. &lt;/p&gt;\n\n&lt;p&gt;If you are interested in such a topic, you can jump into it: &lt;a href=\"https://patrikbraborec.substack.com/p/data-news-8\"&gt;https://patrikbraborec.substack.com/p/data-news-8&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/nX8DFgun-PrZlrPCHXIu2dQA2qvK1Cs8-UUZfDViVEI.jpg?auto=webp&amp;s=721a623acbd9fb835d10682b169fad9a2da9e1c6", "width": 600, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/nX8DFgun-PrZlrPCHXIu2dQA2qvK1Cs8-UUZfDViVEI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=91d5399bb2dd970b2620668c636687deccb52480", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/nX8DFgun-PrZlrPCHXIu2dQA2qvK1Cs8-UUZfDViVEI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ab4ab253f24fb98ba75f08cdde72a3bd51ffb3ba", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/nX8DFgun-PrZlrPCHXIu2dQA2qvK1Cs8-UUZfDViVEI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a760ed6ad5f3eb990c529b5d0e9c5ed12a2c8a27", "width": 320, "height": 320}], "variants": {}, "id": "2GsgzdTtw1tkfhox8VCQA0TnQxlykT9zhDp86g8Vuic"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "ze179z", "is_robot_indexable": true, "report_reasons": null, "author": "AmphibianInfamous574", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ze179z/alert_self_promotion_data_news_once_a_week_monday/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ze179z/alert_self_promotion_data_news_once_a_week_monday/", "subreddit_subscribers": 82076, "created_utc": 1670317505.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a data engineer at a mid sized company.  Our current efforts are only in Azure using technologies like data factory and Synapse.\n\nI see a lot of talk on here about AWS, dbt, airflow, and many other tools that we don't use and I won't get to use given our workflows. With this trajectory, have I shot myself in the foot for future DE jobs if the direction of data engineering doesnt lie in the Azure space?", "author_fullname": "t2_1iuqwzgb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zejv8f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670364985.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a data engineer at a mid sized company.  Our current efforts are only in Azure using technologies like data factory and Synapse.&lt;/p&gt;\n\n&lt;p&gt;I see a lot of talk on here about AWS, dbt, airflow, and many other tools that we don&amp;#39;t use and I won&amp;#39;t get to use given our workflows. With this trajectory, have I shot myself in the foot for future DE jobs if the direction of data engineering doesnt lie in the Azure space?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zejv8f", "is_robot_indexable": true, "report_reasons": null, "author": "rennja", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zejv8f/azure_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zejv8f/azure_de/", "subreddit_subscribers": 82076, "created_utc": 1670364985.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I work as a Junior Data Engineer for a sports team, one year out of college. I am likely to get a promotion in the early part of next year. My boss doesn't believe in handing out titles willy-nilly and believes that the Data Engineer title comes from more experience.\n\nI do have other interests besides just data engineering that I have plans to explore (HTML, Java, basically web design) and was curious if you all had seen/heard of any titles that may be a good transition into either a Data Engineer or some sort of full-stack developer. I aim to suggest a title that aligns with the data engineering track that leaves the door open to move into development, if there is one. Maybe something like ETL Developer... can't really come up with much else.\n\n I should mention that I am studying to take Snowflake's Advanced Data Engineer course, but the completion of that will likely come after the promotion. Thanks for your help!", "author_fullname": "t2_28pdy33m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job Title early on in career?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zeep00", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670352809.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I work as a Junior Data Engineer for a sports team, one year out of college. I am likely to get a promotion in the early part of next year. My boss doesn&amp;#39;t believe in handing out titles willy-nilly and believes that the Data Engineer title comes from more experience.&lt;/p&gt;\n\n&lt;p&gt;I do have other interests besides just data engineering that I have plans to explore (HTML, Java, basically web design) and was curious if you all had seen/heard of any titles that may be a good transition into either a Data Engineer or some sort of full-stack developer. I aim to suggest a title that aligns with the data engineering track that leaves the door open to move into development, if there is one. Maybe something like ETL Developer... can&amp;#39;t really come up with much else.&lt;/p&gt;\n\n&lt;p&gt;I should mention that I am studying to take Snowflake&amp;#39;s Advanced Data Engineer course, but the completion of that will likely come after the promotion. Thanks for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zeep00", "is_robot_indexable": true, "report_reasons": null, "author": "seandog107", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zeep00/job_title_early_on_in_career/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zeep00/job_title_early_on_in_career/", "subreddit_subscribers": 82076, "created_utc": 1670352809.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Please let me know if this isnt the right sub!\n\n&amp;#x200B;\n\nI have quite a boring reporting task at my new job that takes a lot of time. Im want to get into data engineering / data science, so i am trying to automate this tasks.\n\nUnfortunatelyI got stuck and was hoping for ideas and inspiration.\n\n&amp;#x200B;\n\n**The task when I started:**\n\nThe tasks consists of getting survey responses from a website in form of excel sheets, then cleaning those (manually), copying it into an excel master sheet with premade figures/graphs and then visualize the result in a powerpoint presentation. The powerpoint presentation is linked to the master excel sheet, so after I copied the data into the excel master and make sure everything is fine with it (involves adding some of the clients information manually). Finally I update a powerpoint file, make a copy and the presentation is done. (There are several different types of presentations that have to be created, however, this in essence is the task.\n\nThis has to be repeated multiple times a day, for different clients, 5 times a week).\n\n&amp;#x200B;\n\n**What I tried (and failed):**\n\nI tried replicating the charts in R and producing powerpoints. The script works fine, however, the design is quite elaborate and the graphs dont look like the excel charts. Also I dont know how to batch produce them.\n\nMaybe this would work better in python?\n\n&amp;#x200B;\n\n**What I am doing now:**\n\nI work mainly with R. The website of the data has an API which I\u00b4m calling, I get the raw data and put it in tidy form. Then I wrote a script for cleaning and aggregating the data. I do this once a day and save created files locally, so I dont have to call the API over and over again. Then I use the locally saved data to filter the survey responses for the client ID that I need, and copy them into the excel master sheet using the XLConnect package.\n\n&amp;#x200B;\n\nWhen I update the powerpoint now, the task is done. Then I repeat for the next client.\n\n&amp;#x200B;\n\n**I would like to automate this process so that I dont have to do one client ID at a time (sequentially), rather, do it in batches.**\n\nThe problem here is that there is only one excel master workbook that visualizes the results. Copying the master workbook is possible, however, the powerpoint output presentations do not get linked to any copies of the master workbook. That means that I would have to connect the copies manually, which takes more time than doing the the process sequentially.\n\n&amp;#x200B;\n\nIs there a way to do this in batches?\n\nAnd if not, do you think it would be possible to automate updating the powerpoint presentation automatically and saving it?\n\nThe Problem: due to office politics, I cannot pivot from using excel and powerpoint (i know, its pain).\n\nI am sure all this would work better with other software (Im very interested what would be a perfect \"tech stack\" for this process, so do let me know. Unfortunately, I have to solve it with excel and powerpoint in this case).\n\nMaybe someone has a similiar workflow and some experience on how to make this smooth and feel less clunky. I would love to have a discussion on how to make this as efficient as possible. I would also appreciate any resources or anything you could point me to that might help.\n\nI know, Excel and Powerpoint sucks but it is my first job and I needed a way into the field of all things data (im coming from a different field).\n\nPlease also let me know if you need more information to understand this task.\n\nThanks!\n\n&amp;#x200B;\n\nTL:DR: Im looking for a way to generate multiple powerpoints with differently filtered data (its from the same source) with excel style graphs and a fancy layout.", "author_fullname": "t2_1n0kkip", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help Automating Excel &amp; Powerpoint", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zeda62", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1670357742.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670349486.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Please let me know if this isnt the right sub!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I have quite a boring reporting task at my new job that takes a lot of time. Im want to get into data engineering / data science, so i am trying to automate this tasks.&lt;/p&gt;\n\n&lt;p&gt;UnfortunatelyI got stuck and was hoping for ideas and inspiration.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The task when I started:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;The tasks consists of getting survey responses from a website in form of excel sheets, then cleaning those (manually), copying it into an excel master sheet with premade figures/graphs and then visualize the result in a powerpoint presentation. The powerpoint presentation is linked to the master excel sheet, so after I copied the data into the excel master and make sure everything is fine with it (involves adding some of the clients information manually). Finally I update a powerpoint file, make a copy and the presentation is done. (There are several different types of presentations that have to be created, however, this in essence is the task.&lt;/p&gt;\n\n&lt;p&gt;This has to be repeated multiple times a day, for different clients, 5 times a week).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What I tried (and failed):&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I tried replicating the charts in R and producing powerpoints. The script works fine, however, the design is quite elaborate and the graphs dont look like the excel charts. Also I dont know how to batch produce them.&lt;/p&gt;\n\n&lt;p&gt;Maybe this would work better in python?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What I am doing now:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I work mainly with R. The website of the data has an API which I\u00b4m calling, I get the raw data and put it in tidy form. Then I wrote a script for cleaning and aggregating the data. I do this once a day and save created files locally, so I dont have to call the API over and over again. Then I use the locally saved data to filter the survey responses for the client ID that I need, and copy them into the excel master sheet using the XLConnect package.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;When I update the powerpoint now, the task is done. Then I repeat for the next client.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;I would like to automate this process so that I dont have to do one client ID at a time (sequentially), rather, do it in batches.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;The problem here is that there is only one excel master workbook that visualizes the results. Copying the master workbook is possible, however, the powerpoint output presentations do not get linked to any copies of the master workbook. That means that I would have to connect the copies manually, which takes more time than doing the the process sequentially.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Is there a way to do this in batches?&lt;/p&gt;\n\n&lt;p&gt;And if not, do you think it would be possible to automate updating the powerpoint presentation automatically and saving it?&lt;/p&gt;\n\n&lt;p&gt;The Problem: due to office politics, I cannot pivot from using excel and powerpoint (i know, its pain).&lt;/p&gt;\n\n&lt;p&gt;I am sure all this would work better with other software (Im very interested what would be a perfect &amp;quot;tech stack&amp;quot; for this process, so do let me know. Unfortunately, I have to solve it with excel and powerpoint in this case).&lt;/p&gt;\n\n&lt;p&gt;Maybe someone has a similiar workflow and some experience on how to make this smooth and feel less clunky. I would love to have a discussion on how to make this as efficient as possible. I would also appreciate any resources or anything you could point me to that might help.&lt;/p&gt;\n\n&lt;p&gt;I know, Excel and Powerpoint sucks but it is my first job and I needed a way into the field of all things data (im coming from a different field).&lt;/p&gt;\n\n&lt;p&gt;Please also let me know if you need more information to understand this task.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;TL:DR: Im looking for a way to generate multiple powerpoints with differently filtered data (its from the same source) with excel style graphs and a fancy layout.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zeda62", "is_robot_indexable": true, "report_reasons": null, "author": "mtzzzzz", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zeda62/help_automating_excel_powerpoint/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zeda62/help_automating_excel_powerpoint/", "subreddit_subscribers": 82076, "created_utc": 1670349486.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently writing an article on how the economic downturn is impacting data engineers and their data team. \n\nWhat have you experienced so far? Have you experienced a change in expectations/workload? Have you experienced layoffs? Were these layoffs more prominent in data professions than non-data professions? Has nothing changed (work as usual)?\n\nI'd love to hear from you!", "author_fullname": "t2_nkrhcqia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How is the economic downturn impacting you/ your data team?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zeef26", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670352151.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently writing an article on how the economic downturn is impacting data engineers and their data team. &lt;/p&gt;\n\n&lt;p&gt;What have you experienced so far? Have you experienced a change in expectations/workload? Have you experienced layoffs? Were these layoffs more prominent in data professions than non-data professions? Has nothing changed (work as usual)?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to hear from you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zeef26", "is_robot_indexable": true, "report_reasons": null, "author": "JParkerRogers", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zeef26/how_is_the_economic_downturn_impacting_you_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zeef26/how_is_the_economic_downturn_impacting_you_your/", "subreddit_subscribers": 82076, "created_utc": 1670352151.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_31ilk7t8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Analyzing queries with the Snowflake Query Profile", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 62, "top_awarded_type": null, "hide_score": false, "name": "t3_ze7o24", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/zMm7ode8xLW_LIBnC-lZieYnrdCGsWYroQz3sY13OCI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670335578.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "select.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://select.dev/posts/snowflake-query-profile", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xpjeZWCOseTGr7RKXV3xbx1Tvjvaj3tOhG2toDjKPoQ.jpg?auto=webp&amp;s=72eb39598961bf84af4a0b9352b5472c21a36c3f", "width": 1200, "height": 533}, "resolutions": [{"url": "https://external-preview.redd.it/xpjeZWCOseTGr7RKXV3xbx1Tvjvaj3tOhG2toDjKPoQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=eddb342fce1f44f2639a64485e5cd6362967e1b5", "width": 108, "height": 47}, {"url": "https://external-preview.redd.it/xpjeZWCOseTGr7RKXV3xbx1Tvjvaj3tOhG2toDjKPoQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0eb1de1d7f75d7b1f78f8bbfa39db5d916605a3f", "width": 216, "height": 95}, {"url": "https://external-preview.redd.it/xpjeZWCOseTGr7RKXV3xbx1Tvjvaj3tOhG2toDjKPoQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=dc346599a84125c0bced05526e2c17b6ff2bc885", "width": 320, "height": 142}, {"url": "https://external-preview.redd.it/xpjeZWCOseTGr7RKXV3xbx1Tvjvaj3tOhG2toDjKPoQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4ad41f47d2b9bfec321f969388dac8a4603a71b9", "width": 640, "height": 284}, {"url": "https://external-preview.redd.it/xpjeZWCOseTGr7RKXV3xbx1Tvjvaj3tOhG2toDjKPoQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6a8d354394f85db6670e22a92f61a73407c1796f", "width": 960, "height": 426}, {"url": "https://external-preview.redd.it/xpjeZWCOseTGr7RKXV3xbx1Tvjvaj3tOhG2toDjKPoQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a0d4afe49a1e19ae51bb77dfa4f94c8980677404", "width": 1080, "height": 479}], "variants": {}, "id": "oZ2zgEDhY9siXYJGzAENLMWJCUmtG9kyevTl745DiMQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "ze7o24", "is_robot_indexable": true, "report_reasons": null, "author": "ian-whitestone", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ze7o24/analyzing_queries_with_the_snowflake_query_profile/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://select.dev/posts/snowflake-query-profile", "subreddit_subscribers": 82076, "created_utc": 1670335578.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need to use a graph database for one project. I'm new to this GDBMS world. The requirements that were put in front of me were:\n\n1. Must have a free version so that it can be tested\n2. Must be able to run on our servers or to be deployed to the cloud\n3. If we decide to go for managed cloud it doesn't need to be free\n4. Must support Open Cypher query language\n\nI've taken a look at [https://opencypher.org/projects/](https://opencypher.org/projects/) to see which databases support Open Cypher. It seems to me that half of those projects are dead.\n\nIf you have used any of the Cypher-based graph databases, can you tell me how did you decide on one?\n\nAre there some that should be avoided? Are there any special pain points that you just needed to accept that were not solvable?", "author_fullname": "t2_tyl6qdc4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to choose the right graph database?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zdysfr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670310298.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need to use a graph database for one project. I&amp;#39;m new to this GDBMS world. The requirements that were put in front of me were:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Must have a free version so that it can be tested&lt;/li&gt;\n&lt;li&gt;Must be able to run on our servers or to be deployed to the cloud&lt;/li&gt;\n&lt;li&gt;If we decide to go for managed cloud it doesn&amp;#39;t need to be free&lt;/li&gt;\n&lt;li&gt;Must support Open Cypher query language&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;ve taken a look at &lt;a href=\"https://opencypher.org/projects/\"&gt;https://opencypher.org/projects/&lt;/a&gt; to see which databases support Open Cypher. It seems to me that half of those projects are dead.&lt;/p&gt;\n\n&lt;p&gt;If you have used any of the Cypher-based graph databases, can you tell me how did you decide on one?&lt;/p&gt;\n\n&lt;p&gt;Are there some that should be avoided? Are there any special pain points that you just needed to accept that were not solvable?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zdysfr", "is_robot_indexable": true, "report_reasons": null, "author": "Zealousideal_Plan591", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zdysfr/how_to_choose_the_right_graph_database/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zdysfr/how_to_choose_the_right_graph_database/", "subreddit_subscribers": 82076, "created_utc": 1670310298.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks,\n\nThis year, I'm doing the challenges in postgresql select statements. I'm quite enjoying this as what would be quite simple in other languages require me to reach for less commonly used functionality found in postgresql.\n\nFeedback always welcome! \n\n&amp;#x200B;\n\n\\[spoilers ahead\\]: \\_If you're also solving the puzzles, don't click on the link, as the repo contains solutions\\_\n\n[https://github.com/haleemur/advent-of-code-2022](https://github.com/haleemur/advent-of-code-2022)", "author_fullname": "t2_4ekasbko", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advent of Code 2022: postgresql", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zekcwl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "spoiler", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1670366161.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks,&lt;/p&gt;\n\n&lt;p&gt;This year, I&amp;#39;m doing the challenges in postgresql select statements. I&amp;#39;m quite enjoying this as what would be quite simple in other languages require me to reach for less commonly used functionality found in postgresql.&lt;/p&gt;\n\n&lt;p&gt;Feedback always welcome! &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;[spoilers ahead]: _If you&amp;#39;re also solving the puzzles, don&amp;#39;t click on the link, as the repo contains solutions_&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/haleemur/advent-of-code-2022\"&gt;https://github.com/haleemur/advent-of-code-2022&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/GsZpCtCz1KOWkDaqjdibAY6WYR32NDR-Qwdl61ga0-U.jpg?auto=webp&amp;s=caa2320c0b39e1e21541996c1c7a6cb2207ce60c", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/GsZpCtCz1KOWkDaqjdibAY6WYR32NDR-Qwdl61ga0-U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=50b6c4bed72729b860f4a284f2a87a2691a575b8", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/GsZpCtCz1KOWkDaqjdibAY6WYR32NDR-Qwdl61ga0-U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=daf45427f8b9606c07ba74d8c423fb6dbe51ea81", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/GsZpCtCz1KOWkDaqjdibAY6WYR32NDR-Qwdl61ga0-U.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9c30fe6eaa6d3d77802b40d43d46ec4fdab94793", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/GsZpCtCz1KOWkDaqjdibAY6WYR32NDR-Qwdl61ga0-U.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f7cd08c555c415c70e6a7c9f1601249e539d6c01", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/GsZpCtCz1KOWkDaqjdibAY6WYR32NDR-Qwdl61ga0-U.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=42b7b31d851ecbece66405a5895d435474ae4928", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/GsZpCtCz1KOWkDaqjdibAY6WYR32NDR-Qwdl61ga0-U.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d5832f396c79886ec271772b23ad1e887f4cc221", "width": 1080, "height": 540}], "variants": {"obfuscated": {"source": {"url": "https://external-preview.redd.it/GsZpCtCz1KOWkDaqjdibAY6WYR32NDR-Qwdl61ga0-U.jpg?blur=40&amp;format=pjpg&amp;auto=webp&amp;s=0662d45cdb93a240e3a3557e6141b7000d958873", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/GsZpCtCz1KOWkDaqjdibAY6WYR32NDR-Qwdl61ga0-U.jpg?width=108&amp;crop=smart&amp;blur=10&amp;format=pjpg&amp;auto=webp&amp;s=85eb167cf3ed33c7d46a0ccbcba3e564417499a0", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/GsZpCtCz1KOWkDaqjdibAY6WYR32NDR-Qwdl61ga0-U.jpg?width=216&amp;crop=smart&amp;blur=21&amp;format=pjpg&amp;auto=webp&amp;s=c718e2a72120593085a510a241723d8c028cb2b5", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/GsZpCtCz1KOWkDaqjdibAY6WYR32NDR-Qwdl61ga0-U.jpg?width=320&amp;crop=smart&amp;blur=32&amp;format=pjpg&amp;auto=webp&amp;s=883fe69e4a7781f742eea7e03af411aa568a9a25", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/GsZpCtCz1KOWkDaqjdibAY6WYR32NDR-Qwdl61ga0-U.jpg?width=640&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=089ec0434da7e7bb39d80169087eb34da780fbfe", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/GsZpCtCz1KOWkDaqjdibAY6WYR32NDR-Qwdl61ga0-U.jpg?width=960&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=8e5e52894225f018b2431af59ffbad8b5673d807", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/GsZpCtCz1KOWkDaqjdibAY6WYR32NDR-Qwdl61ga0-U.jpg?width=1080&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=f4a8b96602bc274a1516f427e90d194e22a05be8", "width": 1080, "height": 540}]}}, "id": "S8A3J0BS8lrnHzv3560K2xI4ngDSySrpLsLqHvwsZ_Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": true, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "zekcwl", "is_robot_indexable": true, "report_reasons": null, "author": "haaaaaal", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zekcwl/advent_of_code_2022_postgresql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zekcwl/advent_of_code_2022_postgresql/", "subreddit_subscribers": 82076, "created_utc": 1670366161.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is Apache ranger still the de facto choice, or are there major shortcomings that other tools have addressed?", "author_fullname": "t2_eajtr4nz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which governance tools do you currently use? Are there any that you particularly recommend, even if you're not using them atm?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zdzjvy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670312491.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is Apache ranger still the de facto choice, or are there major shortcomings that other tools have addressed?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zdzjvy", "is_robot_indexable": true, "report_reasons": null, "author": "alneuman", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zdzjvy/which_governance_tools_do_you_currently_use_are/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zdzjvy/which_governance_tools_do_you_currently_use_are/", "subreddit_subscribers": 82076, "created_utc": 1670312491.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For those who do their transformations with SQL, how does your deployment pipeline work?\n\nDo you have powers to deploy the procedures, views, etc to production?  \nIf you need to handoff your code, how does that work?\nDo you check-in your code to a source control system?", "author_fullname": "t2_bdzq3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Deploying SQL transformations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zeorv2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670377691.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For those who do their transformations with SQL, how does your deployment pipeline work?&lt;/p&gt;\n\n&lt;p&gt;Do you have powers to deploy the procedures, views, etc to production?&lt;br/&gt;\nIf you need to handoff your code, how does that work?\nDo you check-in your code to a source control system?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zeorv2", "is_robot_indexable": true, "report_reasons": null, "author": "Acewox", "discussion_type": null, "num_comments": 5, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zeorv2/deploying_sql_transformations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zeorv2/deploying_sql_transformations/", "subreddit_subscribers": 82076, "created_utc": 1670377691.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi experts,\n\nWe have a test Airflow (actually Google Composer) cluster that consumes DAGs through a single repo and show the updates in Airflow web UI.\n\nBasically, whenever someone merges feature branches into `test` branch, a Jenkins job copies/pastes the whole repo into the appropriate Google bucket, which is used by the Composer cluster. This creates an obvious issue that one developer's merge will remove all changes of other developers, if they still need to test on `test` branch and have not merged into `master` yet.\n\nWhen the team is small, this is a non-issue. We rarely had conflicts. Now that the team is big enough, I'm thinking about making some changes. Here is the plan I'm considering:\n\nInstead of simply copying/pasting everything into the bucket, I'd write a GitHub Action that picks the files modified and only copy/paste those. Does it make sense? How would you approach the problem?", "author_fullname": "t2_ldvtxo0c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you manage single repo Airflow test environment?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zeonf6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670377327.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi experts,&lt;/p&gt;\n\n&lt;p&gt;We have a test Airflow (actually Google Composer) cluster that consumes DAGs through a single repo and show the updates in Airflow web UI.&lt;/p&gt;\n\n&lt;p&gt;Basically, whenever someone merges feature branches into &lt;code&gt;test&lt;/code&gt; branch, a Jenkins job copies/pastes the whole repo into the appropriate Google bucket, which is used by the Composer cluster. This creates an obvious issue that one developer&amp;#39;s merge will remove all changes of other developers, if they still need to test on &lt;code&gt;test&lt;/code&gt; branch and have not merged into &lt;code&gt;master&lt;/code&gt; yet.&lt;/p&gt;\n\n&lt;p&gt;When the team is small, this is a non-issue. We rarely had conflicts. Now that the team is big enough, I&amp;#39;m thinking about making some changes. Here is the plan I&amp;#39;m considering:&lt;/p&gt;\n\n&lt;p&gt;Instead of simply copying/pasting everything into the bucket, I&amp;#39;d write a GitHub Action that picks the files modified and only copy/paste those. Does it make sense? How would you approach the problem?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zeonf6", "is_robot_indexable": true, "report_reasons": null, "author": "throwaway20220231", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zeonf6/how_do_you_manage_single_repo_airflow_test/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zeonf6/how_do_you_manage_single_repo_airflow_test/", "subreddit_subscribers": 82076, "created_utc": 1670377327.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Looking for some advice on how to move my companies stack forward in an on prem environment, without any plans of moving to the cloud. \n\nWe are running SSIS for everything right now but ideally would like to move towards a more modern stack, but not sure what direction. Airflow, ADF, etc. \n\nI joined more recently and have a python/DS background and honestly prefer that world over SSIS, but the rest of the team is more classic ETL/SQL Server based, but willing to grow. the vibe is basically \u201cWhat best for future proofing, talent attraction, etc\u201d.\n\nNo real K8 infra but run VXrails, so potentially deployable. \n\nOnly hard stop is gotta keep the old on prem SQL Server. \ud83d\ude1e\n\nAppreciate the help!", "author_fullname": "t2_3sioksrx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to move stack forward On- Prem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zer9b3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670385105.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for some advice on how to move my companies stack forward in an on prem environment, without any plans of moving to the cloud. &lt;/p&gt;\n\n&lt;p&gt;We are running SSIS for everything right now but ideally would like to move towards a more modern stack, but not sure what direction. Airflow, ADF, etc. &lt;/p&gt;\n\n&lt;p&gt;I joined more recently and have a python/DS background and honestly prefer that world over SSIS, but the rest of the team is more classic ETL/SQL Server based, but willing to grow. the vibe is basically \u201cWhat best for future proofing, talent attraction, etc\u201d.&lt;/p&gt;\n\n&lt;p&gt;No real K8 infra but run VXrails, so potentially deployable. &lt;/p&gt;\n\n&lt;p&gt;Only hard stop is gotta keep the old on prem SQL Server. \ud83d\ude1e&lt;/p&gt;\n\n&lt;p&gt;Appreciate the help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zer9b3", "is_robot_indexable": true, "report_reasons": null, "author": "Remote-Stay", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zer9b3/how_to_move_stack_forward_on_prem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zer9b3/how_to_move_stack_forward_on_prem/", "subreddit_subscribers": 82076, "created_utc": 1670385105.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What does DevOps mean to you? Is it useful to DE?\n\nI've been on many teams - in a previous career doing production support and then analytics the past few years. But now I ended up on a DevOps team. \n\nWhat this team does, for example:\n\n* Agile, including two week sprints and daily stand-up\n* CI/CD pipeline\n* Checking morning emails for job failures, then sending another email to an audience on the success/failure of all jobs. \n* Fielding and prioritizing user requests.\n* Formal release process, inform users what's going in Friday night. \n* Building ETLs with Datastage (federal agency with old tech)\n* Document, and document more. Government loves documents! \n\nI could go on, but I'm not here to complain. I just want to get an idea of what DevOps looks like for data engineers.", "author_fullname": "t2_2o0q5m4h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What does DevOps look like on your team?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zemo3o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670371698.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What does DevOps mean to you? Is it useful to DE?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been on many teams - in a previous career doing production support and then analytics the past few years. But now I ended up on a DevOps team. &lt;/p&gt;\n\n&lt;p&gt;What this team does, for example:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Agile, including two week sprints and daily stand-up&lt;/li&gt;\n&lt;li&gt;CI/CD pipeline&lt;/li&gt;\n&lt;li&gt;Checking morning emails for job failures, then sending another email to an audience on the success/failure of all jobs. &lt;/li&gt;\n&lt;li&gt;Fielding and prioritizing user requests.&lt;/li&gt;\n&lt;li&gt;Formal release process, inform users what&amp;#39;s going in Friday night. &lt;/li&gt;\n&lt;li&gt;Building ETLs with Datastage (federal agency with old tech)&lt;/li&gt;\n&lt;li&gt;Document, and document more. Government loves documents! &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I could go on, but I&amp;#39;m not here to complain. I just want to get an idea of what DevOps looks like for data engineers.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zemo3o", "is_robot_indexable": true, "report_reasons": null, "author": "rotterdamn8", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zemo3o/what_does_devops_look_like_on_your_team/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zemo3o/what_does_devops_look_like_on_your_team/", "subreddit_subscribers": 82076, "created_utc": 1670371698.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Erlang is used to develop high-available, reliable, concurrent and scalable systems, it seems the language is used mostly in telecom systems. There is the amazing [WhatsApp case](https://blog.whatsapp.com/1-million-is-so-2011) using it to scale the number of simultaneous connections per server that show us the power of the language and the model it is build on. So why is it not widely used in Data Engineering at all?", "author_fullname": "t2_moqo59rs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why is not functional programming languages as Erlang or Elixir extensively used in Data Engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zek84k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1670365845.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Erlang is used to develop high-available, reliable, concurrent and scalable systems, it seems the language is used mostly in telecom systems. There is the amazing &lt;a href=\"https://blog.whatsapp.com/1-million-is-so-2011\"&gt;WhatsApp case&lt;/a&gt; using it to scale the number of simultaneous connections per server that show us the power of the language and the model it is build on. So why is it not widely used in Data Engineering at all?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Uq8iY6_RDS2pyrlqJzbV6rrFEi04sgPJYYilt0exvgY.jpg?auto=webp&amp;s=92aa12260415317a691bfb8d0bd74801ed6fd437", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/Uq8iY6_RDS2pyrlqJzbV6rrFEi04sgPJYYilt0exvgY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=78e2e5b5a7261b381d21a7814a6ecf296e720309", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Uq8iY6_RDS2pyrlqJzbV6rrFEi04sgPJYYilt0exvgY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=19c607dac10bfe95d52be640ecd138856a888b1f", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Uq8iY6_RDS2pyrlqJzbV6rrFEi04sgPJYYilt0exvgY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=89c206e2ccc504eb45d10ae2661c0c10411411c1", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/Uq8iY6_RDS2pyrlqJzbV6rrFEi04sgPJYYilt0exvgY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b5f65a4f0462967cf9bc738aac66d1017c0040de", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/Uq8iY6_RDS2pyrlqJzbV6rrFEi04sgPJYYilt0exvgY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=41feb45fd60d1ca671414401fe9743645e4f58be", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/Uq8iY6_RDS2pyrlqJzbV6rrFEi04sgPJYYilt0exvgY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=117ae682267f03e21dd55f1a9687523c130cbe72", "width": 1080, "height": 567}], "variants": {}, "id": "ptnDQ1fv_7VR0hWhaFloBxw_rEWyBVOzcyTHVYFTOJU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zek84k", "is_robot_indexable": true, "report_reasons": null, "author": "gato_noir", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zek84k/why_is_not_functional_programming_languages_as/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zek84k/why_is_not_functional_programming_languages_as/", "subreddit_subscribers": 82076, "created_utc": 1670365845.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys, \n\nI'm pretty new to Data Engineering, and I got asked to capture user changes to the datawarehouse.\n\nI'm working on a project where the source table (Users) can change info (User changes city) or the data (row) disappears because User deletes the data.  \n\nI've looked around for articles, books (kimball) and this subreddit, and I have been reading that SCD Type 2 is the right one to implement in this case. \n\nProblem is, the source implements hard deletes on data, which means that I have to check all the rows and see if there's any deleted rows  and try to capture that deletion in the SCD 2 table.\n\nTLDR:\n\nSituation:\n\n\\- I have a source database that can have data changes or data deletes\n\nTask:\n\n\\- To track these changes or deletions in the DWH\n\nAction:\n\n\\- Implement Slowly Changing Dimensions Type 2?\n\n&amp;#x200B;\n\nPlease guide me :)", "author_fullname": "t2_5th3ljh1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to implement SCD 2 with hard deleted rows", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zeir6j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670362357.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m pretty new to Data Engineering, and I got asked to capture user changes to the datawarehouse.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working on a project where the source table (Users) can change info (User changes city) or the data (row) disappears because User deletes the data.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve looked around for articles, books (kimball) and this subreddit, and I have been reading that SCD Type 2 is the right one to implement in this case. &lt;/p&gt;\n\n&lt;p&gt;Problem is, the source implements hard deletes on data, which means that I have to check all the rows and see if there&amp;#39;s any deleted rows  and try to capture that deletion in the SCD 2 table.&lt;/p&gt;\n\n&lt;p&gt;TLDR:&lt;/p&gt;\n\n&lt;p&gt;Situation:&lt;/p&gt;\n\n&lt;p&gt;- I have a source database that can have data changes or data deletes&lt;/p&gt;\n\n&lt;p&gt;Task:&lt;/p&gt;\n\n&lt;p&gt;- To track these changes or deletions in the DWH&lt;/p&gt;\n\n&lt;p&gt;Action:&lt;/p&gt;\n\n&lt;p&gt;- Implement Slowly Changing Dimensions Type 2?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Please guide me :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zeir6j", "is_robot_indexable": true, "report_reasons": null, "author": "Bored_Gunner", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zeir6j/how_to_implement_scd_2_with_hard_deleted_rows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zeir6j/how_to_implement_scd_2_with_hard_deleted_rows/", "subreddit_subscribers": 82076, "created_utc": 1670362357.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Quick pseudo-research question.  Say you have a data pipeline, and it goes into production and runs for some time, then fails.  In your experience, what are the most frequent causes?  What changed?", "author_fullname": "t2_pl4q8ng7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why do your pipelines fail?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zei5r1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670360949.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Quick pseudo-research question.  Say you have a data pipeline, and it goes into production and runs for some time, then fails.  In your experience, what are the most frequent causes?  What changed?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zei5r1", "is_robot_indexable": true, "report_reasons": null, "author": "droppedorphan", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zei5r1/why_do_your_pipelines_fail/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zei5r1/why_do_your_pipelines_fail/", "subreddit_subscribers": 82076, "created_utc": 1670360949.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everybody, in my organisation we stream verius of types of data from multiple (identical) data sources that uploaded to one endpoint.\n\nThe data types include group of videos/texts/images that need to come together, in example:\nA list of images, and metadata for all the group.\n\nWe want to pacakge it all together and send it to the server.\n\nWe tried to think maybe zip or avro format but we want to enable lazy open each file we extract\n\nFor example we want the option to read the video insude in bulks of 0.5mb\n\nDo you know any data format that can anwer this specific case? I hope that someone had that too.", "author_fullname": "t2_b1ocecnn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Right data format", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zehb48", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670358949.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everybody, in my organisation we stream verius of types of data from multiple (identical) data sources that uploaded to one endpoint.&lt;/p&gt;\n\n&lt;p&gt;The data types include group of videos/texts/images that need to come together, in example:\nA list of images, and metadata for all the group.&lt;/p&gt;\n\n&lt;p&gt;We want to pacakge it all together and send it to the server.&lt;/p&gt;\n\n&lt;p&gt;We tried to think maybe zip or avro format but we want to enable lazy open each file we extract&lt;/p&gt;\n\n&lt;p&gt;For example we want the option to read the video insude in bulks of 0.5mb&lt;/p&gt;\n\n&lt;p&gt;Do you know any data format that can anwer this specific case? I hope that someone had that too.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zehb48", "is_robot_indexable": true, "report_reasons": null, "author": "Suspicious-Tour-2798", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zehb48/right_data_format/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zehb48/right_data_format/", "subreddit_subscribers": 82076, "created_utc": 1670358949.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Basically the headline. What have you experienced so far? \n\nWhat is different to, say, Tidal?", "author_fullname": "t2_4fb1g9yu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is anybody using Databricks Workflows on a highly scaled level?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zed9ya", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670349471.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically the headline. What have you experienced so far? &lt;/p&gt;\n\n&lt;p&gt;What is different to, say, Tidal?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zed9ya", "is_robot_indexable": true, "report_reasons": null, "author": "cptstoneee", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zed9ya/is_anybody_using_databricks_workflows_on_a_highly/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zed9ya/is_anybody_using_databricks_workflows_on_a_highly/", "subreddit_subscribers": 82076, "created_utc": 1670349471.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_ulqqm7pl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Book Review: Pythonic Programming", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_ze3kgz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/XvQ_ZbJK1pI?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Book Review: Pythonic Programming | Python Book Review\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Book Review: Pythonic Programming | Python Book Review", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/XvQ_ZbJK1pI?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Book Review: Pythonic Programming | Python Book Review\"&gt;&lt;/iframe&gt;", "author_name": "Johannes Frey", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/XvQ_ZbJK1pI/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@JohannesFrey"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/XvQ_ZbJK1pI?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Book Review: Pythonic Programming | Python Book Review\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/ze3kgz", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/bROW-nlZfBErjND0JURqXI6U4CT9eA829yfZGfz60pk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670324647.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/XvQ_ZbJK1pI", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_5oVnDevzuRDXk7aEVghr2cX4Xo3q46CFe1OsokrgxA.jpg?auto=webp&amp;s=c0f6f8a146a0bbe7776b475281ae561a74c012a9", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/_5oVnDevzuRDXk7aEVghr2cX4Xo3q46CFe1OsokrgxA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8ae136fe2e9bbc816ed8d629363394591037ae9b", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/_5oVnDevzuRDXk7aEVghr2cX4Xo3q46CFe1OsokrgxA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3058d6df09b5a1c15a8168d082eda377f3687486", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/_5oVnDevzuRDXk7aEVghr2cX4Xo3q46CFe1OsokrgxA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9f3790338a95416627de4e250a819ea532eede23", "width": 320, "height": 240}], "variants": {}, "id": "Z_H0u60B9I6HB6uoHTHgVZbboWFBhth19ixthVqTZDo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "ze3kgz", "is_robot_indexable": true, "report_reasons": null, "author": "JohannesFrey", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ze3kgz/book_review_pythonic_programming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/XvQ_ZbJK1pI", "subreddit_subscribers": 82076, "created_utc": 1670324647.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Book Review: Pythonic Programming | Python Book Review", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/XvQ_ZbJK1pI?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Book Review: Pythonic Programming | Python Book Review\"&gt;&lt;/iframe&gt;", "author_name": "Johannes Frey", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/XvQ_ZbJK1pI/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@JohannesFrey"}}, "is_video": false}}], "before": null}}