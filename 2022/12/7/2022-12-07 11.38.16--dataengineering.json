{"kind": "Listing", "data": {"after": "t3_zeir6j", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, fellow data engineers! \n\n  \nI've built a tool to find the best resources shared on r/dataengineering as well as other subreddits.   \nHere is the link: [https://www.gembase.ai/articles?search=dataengineering](https://www.gembase.ai/articles?search=dataengineering)  \n\n\n**Architecture**\n\nI gathered all the archive data from Reddit.\n\n* Then extracted URLs with Go on a big EC2 machine. \n* The screenshots and titles were scraped using Python + Playwright hosted on \\~1000 ECS tasks. \n* The recommendations were offline computed with R + Tidyverse.\n\nI hope you will enjoy it. Feedback and questions are really appreciated.", "author_fullname": "t2_21q5bign", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The most shared resources from r/dataengineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zebb3o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 131, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 131, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670344725.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, fellow data engineers! &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve built a tool to find the best resources shared on &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt; as well as other subreddits.&lt;br/&gt;\nHere is the link: &lt;a href=\"https://www.gembase.ai/articles?search=dataengineering\"&gt;https://www.gembase.ai/articles?search=dataengineering&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Architecture&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I gathered all the archive data from Reddit.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Then extracted URLs with Go on a big EC2 machine. &lt;/li&gt;\n&lt;li&gt;The screenshots and titles were scraped using Python + Playwright hosted on ~1000 ECS tasks. &lt;/li&gt;\n&lt;li&gt;The recommendations were offline computed with R + Tidyverse.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I hope you will enjoy it. Feedback and questions are really appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zebb3o", "is_robot_indexable": true, "report_reasons": null, "author": "flpezet", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zebb3o/the_most_shared_resources_from_rdataengineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zebb3o/the_most_shared_resources_from_rdataengineering/", "subreddit_subscribers": 82109, "created_utc": 1670344725.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI was asked this question for a Senior Data Engineer interview. A cycling race is composed of many legs. Each leg goes from one city(A) to another(B). Cyclists then rest for the night and start the next leg of journey from (B) to (C). If the legs are represented by Tuples (A,B), (B,C), (C,D)...and given a list of tuples out of order example \\[(C,D),(A,B),(B,C)...\\] can you print out the correct order of cities in the race (example \"A B C D..\")\n\nExample \\[(A C) (B D) (C B)\\]\n\noutput: A C B D \\[(C B) (D C) (B E) (A D)\\] output A D C B E.\n\nI was supposed to write code in C#. I was unable to solve this. This was my thought process. Treat it like linked list. If List-&gt; next is null then it's the end of race and if List-&gt;prev is null it's the Start of race.\n\nCan anyone guide me with the coding part?", "author_fullname": "t2_gp13ce3a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview coding question that I couldn't solve", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ze798y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 73, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 73, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670334511.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I was asked this question for a Senior Data Engineer interview. A cycling race is composed of many legs. Each leg goes from one city(A) to another(B). Cyclists then rest for the night and start the next leg of journey from (B) to (C). If the legs are represented by Tuples (A,B), (B,C), (C,D)...and given a list of tuples out of order example [(C,D),(A,B),(B,C)...] can you print out the correct order of cities in the race (example &amp;quot;A B C D..&amp;quot;)&lt;/p&gt;\n\n&lt;p&gt;Example [(A C) (B D) (C B)]&lt;/p&gt;\n\n&lt;p&gt;output: A C B D [(C B) (D C) (B E) (A D)] output A D C B E.&lt;/p&gt;\n\n&lt;p&gt;I was supposed to write code in C#. I was unable to solve this. This was my thought process. Treat it like linked list. If List-&amp;gt; next is null then it&amp;#39;s the end of race and if List-&amp;gt;prev is null it&amp;#39;s the Start of race.&lt;/p&gt;\n\n&lt;p&gt;Can anyone guide me with the coding part?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "ze798y", "is_robot_indexable": true, "report_reasons": null, "author": "meridian_12", "discussion_type": null, "num_comments": 54, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ze798y/interview_coding_question_that_i_couldnt_solve/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ze798y/interview_coding_question_that_i_couldnt_solve/", "subreddit_subscribers": 82109, "created_utc": 1670334511.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Not sure if Analytics engineers is the correct term. I'm referring to the position that essentially transforms business oriented questions into queries and dashboards. ChatGPT seems to wipe the floor with such tasks and my manager is already hyping us to build something on top of it. \n\nI'm interested in hearing your opinions, as I'm rather green in the field.\n\nThanks!", "author_fullname": "t2_xptd9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Analytics engineering with ChatGPT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zefba4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670354270.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not sure if Analytics engineers is the correct term. I&amp;#39;m referring to the position that essentially transforms business oriented questions into queries and dashboards. ChatGPT seems to wipe the floor with such tasks and my manager is already hyping us to build something on top of it. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m interested in hearing your opinions, as I&amp;#39;m rather green in the field.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zefba4", "is_robot_indexable": true, "report_reasons": null, "author": "UltimateHorse", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zefba4/analytics_engineering_with_chatgpt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zefba4/analytics_engineering_with_chatgpt/", "subreddit_subscribers": 82109, "created_utc": 1670354270.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So basically the title. It seems like most companies went on rampage to hire data scientists, and now they're searching for 1-2 data engineers. There's no hierarchy that I know of for data engineers, and I have 3 offers from big companies to do their data engineering work in the cloud. In my present company we are a much bigger team, but we're paid shit.\n\nIn these big companies the pay is huge (3x to what I'm paid now) but the backdrop is I'll have to do most of the stuff along with another person to make a warehouse for their analysts/data scientists. Should I jump ship or stay here?", "author_fullname": "t2_l35gwhuh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is It Bad To Be the Only Data Engineer Hired in a Company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zegx37", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670358043.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So basically the title. It seems like most companies went on rampage to hire data scientists, and now they&amp;#39;re searching for 1-2 data engineers. There&amp;#39;s no hierarchy that I know of for data engineers, and I have 3 offers from big companies to do their data engineering work in the cloud. In my present company we are a much bigger team, but we&amp;#39;re paid shit.&lt;/p&gt;\n\n&lt;p&gt;In these big companies the pay is huge (3x to what I&amp;#39;m paid now) but the backdrop is I&amp;#39;ll have to do most of the stuff along with another person to make a warehouse for their analysts/data scientists. Should I jump ship or stay here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zegx37", "is_robot_indexable": true, "report_reasons": null, "author": "Senior_Anteater4688", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zegx37/is_it_bad_to_be_the_only_data_engineer_hired_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zegx37/is_it_bad_to_be_the_only_data_engineer_hired_in_a/", "subreddit_subscribers": 82109, "created_utc": 1670358043.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So, i just got hired as a data analyst, for a job that uses Excel most of the time, sometimes SQL and Power BI.\n\nBut i really want to get in the D.E area, and was wondering if this job experience could help me with that, because i came from a different field (laboratory analysis on chemicals). I'm aware it'll take time, i'm planning to stay on this job for at least 1-2 years, and studying to get in D.E for like 2hours/day that i have some free time.", "author_fullname": "t2_vordwax", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does experience in D.A help to get a job in D.E?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ze7pmz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670335695.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, i just got hired as a data analyst, for a job that uses Excel most of the time, sometimes SQL and Power BI.&lt;/p&gt;\n\n&lt;p&gt;But i really want to get in the D.E area, and was wondering if this job experience could help me with that, because i came from a different field (laboratory analysis on chemicals). I&amp;#39;m aware it&amp;#39;ll take time, i&amp;#39;m planning to stay on this job for at least 1-2 years, and studying to get in D.E for like 2hours/day that i have some free time.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ze7pmz", "is_robot_indexable": true, "report_reasons": null, "author": "Utopya96", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ze7pmz/does_experience_in_da_help_to_get_a_job_in_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ze7pmz/does_experience_in_da_help_to_get_a_job_in_de/", "subreddit_subscribers": 82109, "created_utc": 1670335695.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi redditors,\n\nThis is an interview question in Spark which has had me going into rabbithole of spark and yet I'm unable to find an answer. \n\nSo the question is, once you have submitted a spark job and see that it is running slow, how do you increase the cores/resources on the fly( without stopping and re running the job with increased resources). Is this even possible?", "author_fullname": "t2_98w2eb47", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview question in Spark yet to be solved", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zeg4nm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670356236.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi redditors,&lt;/p&gt;\n\n&lt;p&gt;This is an interview question in Spark which has had me going into rabbithole of spark and yet I&amp;#39;m unable to find an answer. &lt;/p&gt;\n\n&lt;p&gt;So the question is, once you have submitted a spark job and see that it is running slow, how do you increase the cores/resources on the fly( without stopping and re running the job with increased resources). Is this even possible?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "zeg4nm", "is_robot_indexable": true, "report_reasons": null, "author": "cherryblossomslove", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zeg4nm/interview_question_in_spark_yet_to_be_solved/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zeg4nm/interview_question_in_spark_yet_to_be_solved/", "subreddit_subscribers": 82109, "created_utc": 1670356236.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a data engineer at a mid sized company.  Our current efforts are only in Azure using technologies like data factory and Synapse.\n\nI see a lot of talk on here about AWS, dbt, airflow, and many other tools that we don't use and I won't get to use given our workflows. With this trajectory, have I shot myself in the foot for future DE jobs if the direction of data engineering doesnt lie in the Azure space?", "author_fullname": "t2_1iuqwzgb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zejv8f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670364985.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a data engineer at a mid sized company.  Our current efforts are only in Azure using technologies like data factory and Synapse.&lt;/p&gt;\n\n&lt;p&gt;I see a lot of talk on here about AWS, dbt, airflow, and many other tools that we don&amp;#39;t use and I won&amp;#39;t get to use given our workflows. With this trajectory, have I shot myself in the foot for future DE jobs if the direction of data engineering doesnt lie in the Azure space?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zejv8f", "is_robot_indexable": true, "report_reasons": null, "author": "rennja", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zejv8f/azure_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zejv8f/azure_de/", "subreddit_subscribers": 82109, "created_utc": 1670364985.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I work as a Junior Data Engineer for a sports team, one year out of college. I am likely to get a promotion in the early part of next year. My boss doesn't believe in handing out titles willy-nilly and believes that the Data Engineer title comes from more experience.\n\nI do have other interests besides just data engineering that I have plans to explore (HTML, Java, basically web design) and was curious if you all had seen/heard of any titles that may be a good transition into either a Data Engineer or some sort of full-stack developer. I aim to suggest a title that aligns with the data engineering track that leaves the door open to move into development, if there is one. Maybe something like ETL Developer... can't really come up with much else.\n\n I should mention that I am studying to take Snowflake's Advanced Data Engineer course, but the completion of that will likely come after the promotion. Thanks for your help!", "author_fullname": "t2_28pdy33m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job Title early on in career?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zeep00", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670352809.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I work as a Junior Data Engineer for a sports team, one year out of college. I am likely to get a promotion in the early part of next year. My boss doesn&amp;#39;t believe in handing out titles willy-nilly and believes that the Data Engineer title comes from more experience.&lt;/p&gt;\n\n&lt;p&gt;I do have other interests besides just data engineering that I have plans to explore (HTML, Java, basically web design) and was curious if you all had seen/heard of any titles that may be a good transition into either a Data Engineer or some sort of full-stack developer. I aim to suggest a title that aligns with the data engineering track that leaves the door open to move into development, if there is one. Maybe something like ETL Developer... can&amp;#39;t really come up with much else.&lt;/p&gt;\n\n&lt;p&gt;I should mention that I am studying to take Snowflake&amp;#39;s Advanced Data Engineer course, but the completion of that will likely come after the promotion. Thanks for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zeep00", "is_robot_indexable": true, "report_reasons": null, "author": "seandog107", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zeep00/job_title_early_on_in_career/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zeep00/job_title_early_on_in_career/", "subreddit_subscribers": 82109, "created_utc": 1670352809.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks,\n\nThis year, I'm doing the challenges in postgresql select statements. I'm quite enjoying this as what would be quite simple in other languages require me to reach for less commonly used functionality found in postgresql.\n\nFeedback always welcome! \n\n&amp;#x200B;\n\n\\[spoilers ahead\\]: \\_If you're also solving the puzzles, don't click on the link, as the repo contains solutions\\_\n\n[https://github.com/haleemur/advent-of-code-2022](https://github.com/haleemur/advent-of-code-2022)", "author_fullname": "t2_4ekasbko", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advent of Code 2022: postgresql", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zekcwl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "spoiler", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1670366161.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks,&lt;/p&gt;\n\n&lt;p&gt;This year, I&amp;#39;m doing the challenges in postgresql select statements. I&amp;#39;m quite enjoying this as what would be quite simple in other languages require me to reach for less commonly used functionality found in postgresql.&lt;/p&gt;\n\n&lt;p&gt;Feedback always welcome! &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;[spoilers ahead]: _If you&amp;#39;re also solving the puzzles, don&amp;#39;t click on the link, as the repo contains solutions_&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/haleemur/advent-of-code-2022\"&gt;https://github.com/haleemur/advent-of-code-2022&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/GsZpCtCz1KOWkDaqjdibAY6WYR32NDR-Qwdl61ga0-U.jpg?auto=webp&amp;s=caa2320c0b39e1e21541996c1c7a6cb2207ce60c", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/GsZpCtCz1KOWkDaqjdibAY6WYR32NDR-Qwdl61ga0-U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=50b6c4bed72729b860f4a284f2a87a2691a575b8", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/GsZpCtCz1KOWkDaqjdibAY6WYR32NDR-Qwdl61ga0-U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=daf45427f8b9606c07ba74d8c423fb6dbe51ea81", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/GsZpCtCz1KOWkDaqjdibAY6WYR32NDR-Qwdl61ga0-U.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9c30fe6eaa6d3d77802b40d43d46ec4fdab94793", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/GsZpCtCz1KOWkDaqjdibAY6WYR32NDR-Qwdl61ga0-U.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f7cd08c555c415c70e6a7c9f1601249e539d6c01", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/GsZpCtCz1KOWkDaqjdibAY6WYR32NDR-Qwdl61ga0-U.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=42b7b31d851ecbece66405a5895d435474ae4928", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/GsZpCtCz1KOWkDaqjdibAY6WYR32NDR-Qwdl61ga0-U.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d5832f396c79886ec271772b23ad1e887f4cc221", "width": 1080, "height": 540}], "variants": {"obfuscated": {"source": {"url": "https://external-preview.redd.it/GsZpCtCz1KOWkDaqjdibAY6WYR32NDR-Qwdl61ga0-U.jpg?blur=40&amp;format=pjpg&amp;auto=webp&amp;s=0662d45cdb93a240e3a3557e6141b7000d958873", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/GsZpCtCz1KOWkDaqjdibAY6WYR32NDR-Qwdl61ga0-U.jpg?width=108&amp;crop=smart&amp;blur=10&amp;format=pjpg&amp;auto=webp&amp;s=85eb167cf3ed33c7d46a0ccbcba3e564417499a0", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/GsZpCtCz1KOWkDaqjdibAY6WYR32NDR-Qwdl61ga0-U.jpg?width=216&amp;crop=smart&amp;blur=21&amp;format=pjpg&amp;auto=webp&amp;s=c718e2a72120593085a510a241723d8c028cb2b5", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/GsZpCtCz1KOWkDaqjdibAY6WYR32NDR-Qwdl61ga0-U.jpg?width=320&amp;crop=smart&amp;blur=32&amp;format=pjpg&amp;auto=webp&amp;s=883fe69e4a7781f742eea7e03af411aa568a9a25", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/GsZpCtCz1KOWkDaqjdibAY6WYR32NDR-Qwdl61ga0-U.jpg?width=640&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=089ec0434da7e7bb39d80169087eb34da780fbfe", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/GsZpCtCz1KOWkDaqjdibAY6WYR32NDR-Qwdl61ga0-U.jpg?width=960&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=8e5e52894225f018b2431af59ffbad8b5673d807", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/GsZpCtCz1KOWkDaqjdibAY6WYR32NDR-Qwdl61ga0-U.jpg?width=1080&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=f4a8b96602bc274a1516f427e90d194e22a05be8", "width": 1080, "height": 540}]}}, "id": "S8A3J0BS8lrnHzv3560K2xI4ngDSySrpLsLqHvwsZ_Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": true, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "zekcwl", "is_robot_indexable": true, "report_reasons": null, "author": "haaaaaal", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zekcwl/advent_of_code_2022_postgresql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zekcwl/advent_of_code_2022_postgresql/", "subreddit_subscribers": 82109, "created_utc": 1670366161.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Please let me know if this isnt the right sub!\n\n&amp;#x200B;\n\nI have quite a boring reporting task at my new job that takes a lot of time. Im want to get into data engineering / data science, so i am trying to automate this tasks.\n\nUnfortunatelyI got stuck and was hoping for ideas and inspiration.\n\n&amp;#x200B;\n\n**The task when I started:**\n\nThe tasks consists of getting survey responses from a website in form of excel sheets, then cleaning those (manually), copying it into an excel master sheet with premade figures/graphs and then visualize the result in a powerpoint presentation. The powerpoint presentation is linked to the master excel sheet, so after I copied the data into the excel master and make sure everything is fine with it (involves adding some of the clients information manually). Finally I update a powerpoint file, make a copy and the presentation is done. (There are several different types of presentations that have to be created, however, this in essence is the task.\n\nThis has to be repeated multiple times a day, for different clients, 5 times a week).\n\n&amp;#x200B;\n\n**What I tried (and failed):**\n\nI tried replicating the charts in R and producing powerpoints. The script works fine, however, the design is quite elaborate and the graphs dont look like the excel charts. Also I dont know how to batch produce them.\n\nMaybe this would work better in python?\n\n&amp;#x200B;\n\n**What I am doing now:**\n\nI work mainly with R. The website of the data has an API which I\u00b4m calling, I get the raw data and put it in tidy form. Then I wrote a script for cleaning and aggregating the data. I do this once a day and save created files locally, so I dont have to call the API over and over again. Then I use the locally saved data to filter the survey responses for the client ID that I need, and copy them into the excel master sheet using the XLConnect package.\n\n&amp;#x200B;\n\nWhen I update the powerpoint now, the task is done. Then I repeat for the next client.\n\n&amp;#x200B;\n\n**I would like to automate this process so that I dont have to do one client ID at a time (sequentially), rather, do it in batches.**\n\nThe problem here is that there is only one excel master workbook that visualizes the results. Copying the master workbook is possible, however, the powerpoint output presentations do not get linked to any copies of the master workbook. That means that I would have to connect the copies manually, which takes more time than doing the the process sequentially.\n\n&amp;#x200B;\n\nIs there a way to do this in batches?\n\nAnd if not, do you think it would be possible to automate updating the powerpoint presentation automatically and saving it?\n\nThe Problem: due to office politics, I cannot pivot from using excel and powerpoint (i know, its pain).\n\nI am sure all this would work better with other software (Im very interested what would be a perfect \"tech stack\" for this process, so do let me know. Unfortunately, I have to solve it with excel and powerpoint in this case).\n\nMaybe someone has a similiar workflow and some experience on how to make this smooth and feel less clunky. I would love to have a discussion on how to make this as efficient as possible. I would also appreciate any resources or anything you could point me to that might help.\n\nI know, Excel and Powerpoint sucks but it is my first job and I needed a way into the field of all things data (im coming from a different field).\n\nPlease also let me know if you need more information to understand this task.\n\nThanks!\n\n&amp;#x200B;\n\nTL:DR: Im looking for a way to generate multiple powerpoints with differently filtered data (its from the same source) with excel style graphs and a fancy layout.", "author_fullname": "t2_1n0kkip", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help Automating Excel &amp; Powerpoint", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zeda62", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1670357742.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670349486.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Please let me know if this isnt the right sub!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I have quite a boring reporting task at my new job that takes a lot of time. Im want to get into data engineering / data science, so i am trying to automate this tasks.&lt;/p&gt;\n\n&lt;p&gt;UnfortunatelyI got stuck and was hoping for ideas and inspiration.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The task when I started:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;The tasks consists of getting survey responses from a website in form of excel sheets, then cleaning those (manually), copying it into an excel master sheet with premade figures/graphs and then visualize the result in a powerpoint presentation. The powerpoint presentation is linked to the master excel sheet, so after I copied the data into the excel master and make sure everything is fine with it (involves adding some of the clients information manually). Finally I update a powerpoint file, make a copy and the presentation is done. (There are several different types of presentations that have to be created, however, this in essence is the task.&lt;/p&gt;\n\n&lt;p&gt;This has to be repeated multiple times a day, for different clients, 5 times a week).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What I tried (and failed):&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I tried replicating the charts in R and producing powerpoints. The script works fine, however, the design is quite elaborate and the graphs dont look like the excel charts. Also I dont know how to batch produce them.&lt;/p&gt;\n\n&lt;p&gt;Maybe this would work better in python?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What I am doing now:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I work mainly with R. The website of the data has an API which I\u00b4m calling, I get the raw data and put it in tidy form. Then I wrote a script for cleaning and aggregating the data. I do this once a day and save created files locally, so I dont have to call the API over and over again. Then I use the locally saved data to filter the survey responses for the client ID that I need, and copy them into the excel master sheet using the XLConnect package.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;When I update the powerpoint now, the task is done. Then I repeat for the next client.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;I would like to automate this process so that I dont have to do one client ID at a time (sequentially), rather, do it in batches.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;The problem here is that there is only one excel master workbook that visualizes the results. Copying the master workbook is possible, however, the powerpoint output presentations do not get linked to any copies of the master workbook. That means that I would have to connect the copies manually, which takes more time than doing the the process sequentially.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Is there a way to do this in batches?&lt;/p&gt;\n\n&lt;p&gt;And if not, do you think it would be possible to automate updating the powerpoint presentation automatically and saving it?&lt;/p&gt;\n\n&lt;p&gt;The Problem: due to office politics, I cannot pivot from using excel and powerpoint (i know, its pain).&lt;/p&gt;\n\n&lt;p&gt;I am sure all this would work better with other software (Im very interested what would be a perfect &amp;quot;tech stack&amp;quot; for this process, so do let me know. Unfortunately, I have to solve it with excel and powerpoint in this case).&lt;/p&gt;\n\n&lt;p&gt;Maybe someone has a similiar workflow and some experience on how to make this smooth and feel less clunky. I would love to have a discussion on how to make this as efficient as possible. I would also appreciate any resources or anything you could point me to that might help.&lt;/p&gt;\n\n&lt;p&gt;I know, Excel and Powerpoint sucks but it is my first job and I needed a way into the field of all things data (im coming from a different field).&lt;/p&gt;\n\n&lt;p&gt;Please also let me know if you need more information to understand this task.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;TL:DR: Im looking for a way to generate multiple powerpoints with differently filtered data (its from the same source) with excel style graphs and a fancy layout.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zeda62", "is_robot_indexable": true, "report_reasons": null, "author": "mtzzzzz", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zeda62/help_automating_excel_powerpoint/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zeda62/help_automating_excel_powerpoint/", "subreddit_subscribers": 82109, "created_utc": 1670349486.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_31ilk7t8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Analyzing queries with the Snowflake Query Profile", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 62, "top_awarded_type": null, "hide_score": false, "name": "t3_ze7o24", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/zMm7ode8xLW_LIBnC-lZieYnrdCGsWYroQz3sY13OCI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670335578.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "select.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://select.dev/posts/snowflake-query-profile", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xpjeZWCOseTGr7RKXV3xbx1Tvjvaj3tOhG2toDjKPoQ.jpg?auto=webp&amp;s=72eb39598961bf84af4a0b9352b5472c21a36c3f", "width": 1200, "height": 533}, "resolutions": [{"url": "https://external-preview.redd.it/xpjeZWCOseTGr7RKXV3xbx1Tvjvaj3tOhG2toDjKPoQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=eddb342fce1f44f2639a64485e5cd6362967e1b5", "width": 108, "height": 47}, {"url": "https://external-preview.redd.it/xpjeZWCOseTGr7RKXV3xbx1Tvjvaj3tOhG2toDjKPoQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0eb1de1d7f75d7b1f78f8bbfa39db5d916605a3f", "width": 216, "height": 95}, {"url": "https://external-preview.redd.it/xpjeZWCOseTGr7RKXV3xbx1Tvjvaj3tOhG2toDjKPoQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=dc346599a84125c0bced05526e2c17b6ff2bc885", "width": 320, "height": 142}, {"url": "https://external-preview.redd.it/xpjeZWCOseTGr7RKXV3xbx1Tvjvaj3tOhG2toDjKPoQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4ad41f47d2b9bfec321f969388dac8a4603a71b9", "width": 640, "height": 284}, {"url": "https://external-preview.redd.it/xpjeZWCOseTGr7RKXV3xbx1Tvjvaj3tOhG2toDjKPoQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6a8d354394f85db6670e22a92f61a73407c1796f", "width": 960, "height": 426}, {"url": "https://external-preview.redd.it/xpjeZWCOseTGr7RKXV3xbx1Tvjvaj3tOhG2toDjKPoQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a0d4afe49a1e19ae51bb77dfa4f94c8980677404", "width": 1080, "height": 479}], "variants": {}, "id": "oZ2zgEDhY9siXYJGzAENLMWJCUmtG9kyevTl745DiMQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "ze7o24", "is_robot_indexable": true, "report_reasons": null, "author": "ian-whitestone", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ze7o24/analyzing_queries_with_the_snowflake_query_profile/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://select.dev/posts/snowflake-query-profile", "subreddit_subscribers": 82109, "created_utc": 1670335578.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Basically I\u2019m wondering if there\u2019s a columnar or other NOSQL equivalent lightweight database that could be used for small pipelines in a pinch. Is that basically what parquet files are used for? Is there a way to bundle parquet files together into more of a database rather than standalone tables?", "author_fullname": "t2_1gyiwuuv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQLite NOSQL Alternatives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zevwlz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670401591.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically I\u2019m wondering if there\u2019s a columnar or other NOSQL equivalent lightweight database that could be used for small pipelines in a pinch. Is that basically what parquet files are used for? Is there a way to bundle parquet files together into more of a database rather than standalone tables?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zevwlz", "is_robot_indexable": true, "report_reasons": null, "author": "trianglesteve", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zevwlz/sqlite_nosql_alternatives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zevwlz/sqlite_nosql_alternatives/", "subreddit_subscribers": 82109, "created_utc": 1670401591.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently writing an article on how the economic downturn is impacting data engineers and their data team. \n\nWhat have you experienced so far? Have you experienced a change in expectations/workload? Have you experienced layoffs? Were these layoffs more prominent in data professions than non-data professions? Has nothing changed (work as usual)?\n\nI'd love to hear from you!", "author_fullname": "t2_nkrhcqia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How is the economic downturn impacting you/ your data team?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zeef26", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670352151.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently writing an article on how the economic downturn is impacting data engineers and their data team. &lt;/p&gt;\n\n&lt;p&gt;What have you experienced so far? Have you experienced a change in expectations/workload? Have you experienced layoffs? Were these layoffs more prominent in data professions than non-data professions? Has nothing changed (work as usual)?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to hear from you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zeef26", "is_robot_indexable": true, "report_reasons": null, "author": "JParkerRogers", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zeef26/how_is_the_economic_downturn_impacting_you_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zeef26/how_is_the_economic_downturn_impacting_you_your/", "subreddit_subscribers": 82109, "created_utc": 1670352151.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Looking for some advice on how to move my companies stack forward in an on prem environment, without any plans of moving to the cloud. \n\nWe are running SSIS for everything right now but ideally would like to move towards a more modern stack, but not sure what direction. Airflow, ADF, etc. \n\nI joined more recently and have a python/DS background and honestly prefer that world over SSIS, but the rest of the team is more classic ETL/SQL Server based, but willing to grow. the vibe is basically \u201cWhat best for future proofing, talent attraction, etc\u201d.\n\nNo real K8 infra but run VXrails, so potentially deployable. \n\nOnly hard stop is gotta keep the old on prem SQL Server. \ud83d\ude1e\n\nAppreciate the help!", "author_fullname": "t2_3sioksrx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to move stack forward On- Prem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zer9b3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670385105.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for some advice on how to move my companies stack forward in an on prem environment, without any plans of moving to the cloud. &lt;/p&gt;\n\n&lt;p&gt;We are running SSIS for everything right now but ideally would like to move towards a more modern stack, but not sure what direction. Airflow, ADF, etc. &lt;/p&gt;\n\n&lt;p&gt;I joined more recently and have a python/DS background and honestly prefer that world over SSIS, but the rest of the team is more classic ETL/SQL Server based, but willing to grow. the vibe is basically \u201cWhat best for future proofing, talent attraction, etc\u201d.&lt;/p&gt;\n\n&lt;p&gt;No real K8 infra but run VXrails, so potentially deployable. &lt;/p&gt;\n\n&lt;p&gt;Only hard stop is gotta keep the old on prem SQL Server. \ud83d\ude1e&lt;/p&gt;\n\n&lt;p&gt;Appreciate the help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zer9b3", "is_robot_indexable": true, "report_reasons": null, "author": "Remote-Stay", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zer9b3/how_to_move_stack_forward_on_prem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zer9b3/how_to_move_stack_forward_on_prem/", "subreddit_subscribers": 82109, "created_utc": 1670385105.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Are there any things you wished you had done during your first few weeks at your current job?\n\nI know I would have started earlier with a list of all the acronyms used in the data team. That would have saved me a headache later!", "author_fullname": "t2_3cfsa44", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Starting a new Data Engineering job (mid level)- what would you do?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zewn9t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670404620.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are there any things you wished you had done during your first few weeks at your current job?&lt;/p&gt;\n\n&lt;p&gt;I know I would have started earlier with a list of all the acronyms used in the data team. That would have saved me a headache later!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zewn9t", "is_robot_indexable": true, "report_reasons": null, "author": "squaricle", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zewn9t/starting_a_new_data_engineering_job_mid_level/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zewn9t/starting_a_new_data_engineering_job_mid_level/", "subreddit_subscribers": 82109, "created_utc": 1670404620.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nIn my company I have been assigned the task to create a data streaming pipeline to move data from mysql to a datalake.\n\nTo achieve this task, I have created a pipeline using Debezium, Kafka and Spark Structured Streaming.\n\nDebezium writes all the events to a single kafka topic.\n\nThe Spark job uses the \\`forEachBatch\\` function, it reads events, divides them by table, and makes sure to upsert events in each corresponding table using Delta.\n\nOne tough requirement to implement is that this data should be directly queried by data consumers, it is a tough requirement because due to grouping upserts by table I am changing the events order (performing upserts in an ordered way for each individual transaction would be extremely inefficient). This could lead to potential data inconsistencies because during the batch processing time some tables are more updated than others.\n\nOne way to mitigate this issue I came up with is to let users access these tables only through athena/snowflake, this way I can decouple what data I am showing from what data is actually inside the table by using the [symlink manifest files](https://docs.delta.io/latest/presto-integration.html#set-up-the-presto-trino-or-athena-to-delta-lake-integration-and-query-delta-tables). This is a workaround and not a definitive solution, because it reduces the time tables are inconsistent to the time it takes to refresh all the manifests.\n\nIs there any better way to achieve consistency between tables in a streaming system?\n\nI am also tempted to reduce inconsistency by minimizing latency , creating append-only tables, but I am afraid these tables will start growing exponentially.", "author_fullname": "t2_do2bj7xa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Streaming Jobs and tables consistency", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zewhcj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "08789422-ac9d-11eb-aade-0e32c0bdd4fb", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1670406352.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670403957.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;In my company I have been assigned the task to create a data streaming pipeline to move data from mysql to a datalake.&lt;/p&gt;\n\n&lt;p&gt;To achieve this task, I have created a pipeline using Debezium, Kafka and Spark Structured Streaming.&lt;/p&gt;\n\n&lt;p&gt;Debezium writes all the events to a single kafka topic.&lt;/p&gt;\n\n&lt;p&gt;The Spark job uses the `forEachBatch` function, it reads events, divides them by table, and makes sure to upsert events in each corresponding table using Delta.&lt;/p&gt;\n\n&lt;p&gt;One tough requirement to implement is that this data should be directly queried by data consumers, it is a tough requirement because due to grouping upserts by table I am changing the events order (performing upserts in an ordered way for each individual transaction would be extremely inefficient). This could lead to potential data inconsistencies because during the batch processing time some tables are more updated than others.&lt;/p&gt;\n\n&lt;p&gt;One way to mitigate this issue I came up with is to let users access these tables only through athena/snowflake, this way I can decouple what data I am showing from what data is actually inside the table by using the &lt;a href=\"https://docs.delta.io/latest/presto-integration.html#set-up-the-presto-trino-or-athena-to-delta-lake-integration-and-query-delta-tables\"&gt;symlink manifest files&lt;/a&gt;. This is a workaround and not a definitive solution, because it reduces the time tables are inconsistent to the time it takes to refresh all the manifests.&lt;/p&gt;\n\n&lt;p&gt;Is there any better way to achieve consistency between tables in a streaming system?&lt;/p&gt;\n\n&lt;p&gt;I am also tempted to reduce inconsistency by minimizing latency , creating append-only tables, but I am afraid these tables will start growing exponentially.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Big Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zewhcj", "is_robot_indexable": true, "report_reasons": null, "author": "somerandomdataeng", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/zewhcj/streaming_jobs_and_tables_consistency/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zewhcj/streaming_jobs_and_tables_consistency/", "subreddit_subscribers": 82109, "created_utc": 1670403957.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In my experience as a data engineer in a big tech, I wrote a mock data library that creates data based on the schema and Dtype you configure and have used it pretty extensively for testing pipelines. Never tested on production data, because anonymizing it and copying it out of prod workflow was not approved by data governance and legal teams :/    \n\n\nI'm curious how you folks in the industry do it!\n\n[View Poll](https://www.reddit.com/poll/zetwd0)", "author_fullname": "t2_msviuy1p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you get the right data to test your ETL pipelines?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zetwd0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670393769.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my experience as a data engineer in a big tech, I wrote a mock data library that creates data based on the schema and Dtype you configure and have used it pretty extensively for testing pipelines. Never tested on production data, because anonymizing it and copying it out of prod workflow was not approved by data governance and legal teams :/    &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m curious how you folks in the industry do it!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/zetwd0\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zetwd0", "is_robot_indexable": true, "report_reasons": null, "author": "vino_and_data", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1670998569803, "options": [{"text": "Mock data", "id": "20235477"}, {"text": "Copy production data to staging/test env", "id": "20235478"}, {"text": "Copy anonymized production data to staging", "id": "20235479"}, {"text": "Use data versioning tool to mirror prod env", "id": "20235480"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 85, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zetwd0/how_do_you_get_the_right_data_to_test_your_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/zetwd0/how_do_you_get_the_right_data_to_test_your_etl/", "subreddit_subscribers": 82109, "created_utc": 1670393769.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For those who do their transformations with SQL, how does your deployment pipeline work?\n\nDo you have powers to deploy the procedures, views, etc to production?  \nIf you need to handoff your code, how does that work?\nDo you check-in your code to a source control system?", "author_fullname": "t2_bdzq3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Deploying SQL transformations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zeorv2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670377691.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For those who do their transformations with SQL, how does your deployment pipeline work?&lt;/p&gt;\n\n&lt;p&gt;Do you have powers to deploy the procedures, views, etc to production?&lt;br/&gt;\nIf you need to handoff your code, how does that work?\nDo you check-in your code to a source control system?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zeorv2", "is_robot_indexable": true, "report_reasons": null, "author": "Acewox", "discussion_type": null, "num_comments": 6, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zeorv2/deploying_sql_transformations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zeorv2/deploying_sql_transformations/", "subreddit_subscribers": 82109, "created_utc": 1670377691.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi experts,\n\nWe have a test Airflow (actually Google Composer) cluster that consumes DAGs through a single repo and show the updates in Airflow web UI.\n\nBasically, whenever someone merges feature branches into `test` branch, a Jenkins job copies/pastes the whole repo into the appropriate Google bucket, which is used by the Composer cluster. This creates an obvious issue that one developer's merge will remove all changes of other developers, if they still need to test on `test` branch and have not merged into `master` yet.\n\nWhen the team is small, this is a non-issue. We rarely had conflicts. Now that the team is big enough, I'm thinking about making some changes. Here is the plan I'm considering:\n\nInstead of simply copying/pasting everything into the bucket, I'd write a GitHub Action that picks the files modified and only copy/paste those. Does it make sense? How would you approach the problem?", "author_fullname": "t2_ldvtxo0c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you manage single repo Airflow test environment?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zeonf6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670377327.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi experts,&lt;/p&gt;\n\n&lt;p&gt;We have a test Airflow (actually Google Composer) cluster that consumes DAGs through a single repo and show the updates in Airflow web UI.&lt;/p&gt;\n\n&lt;p&gt;Basically, whenever someone merges feature branches into &lt;code&gt;test&lt;/code&gt; branch, a Jenkins job copies/pastes the whole repo into the appropriate Google bucket, which is used by the Composer cluster. This creates an obvious issue that one developer&amp;#39;s merge will remove all changes of other developers, if they still need to test on &lt;code&gt;test&lt;/code&gt; branch and have not merged into &lt;code&gt;master&lt;/code&gt; yet.&lt;/p&gt;\n\n&lt;p&gt;When the team is small, this is a non-issue. We rarely had conflicts. Now that the team is big enough, I&amp;#39;m thinking about making some changes. Here is the plan I&amp;#39;m considering:&lt;/p&gt;\n\n&lt;p&gt;Instead of simply copying/pasting everything into the bucket, I&amp;#39;d write a GitHub Action that picks the files modified and only copy/paste those. Does it make sense? How would you approach the problem?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zeonf6", "is_robot_indexable": true, "report_reasons": null, "author": "throwaway20220231", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zeonf6/how_do_you_manage_single_repo_airflow_test/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zeonf6/how_do_you_manage_single_repo_airflow_test/", "subreddit_subscribers": 82109, "created_utc": 1670377327.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Erlang is used to develop high-available, reliable, concurrent and scalable systems, it seems the language is used mostly in telecom systems. There is the amazing [WhatsApp case](https://blog.whatsapp.com/1-million-is-so-2011) using it to scale the number of simultaneous connections per server that show us the power of the language and the model it is build on. So why is it not widely used in Data Engineering at all?", "author_fullname": "t2_moqo59rs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why is not functional programming languages as Erlang or Elixir extensively used in Data Engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zek84k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1670365845.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Erlang is used to develop high-available, reliable, concurrent and scalable systems, it seems the language is used mostly in telecom systems. There is the amazing &lt;a href=\"https://blog.whatsapp.com/1-million-is-so-2011\"&gt;WhatsApp case&lt;/a&gt; using it to scale the number of simultaneous connections per server that show us the power of the language and the model it is build on. So why is it not widely used in Data Engineering at all?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Uq8iY6_RDS2pyrlqJzbV6rrFEi04sgPJYYilt0exvgY.jpg?auto=webp&amp;s=92aa12260415317a691bfb8d0bd74801ed6fd437", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/Uq8iY6_RDS2pyrlqJzbV6rrFEi04sgPJYYilt0exvgY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=78e2e5b5a7261b381d21a7814a6ecf296e720309", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Uq8iY6_RDS2pyrlqJzbV6rrFEi04sgPJYYilt0exvgY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=19c607dac10bfe95d52be640ecd138856a888b1f", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Uq8iY6_RDS2pyrlqJzbV6rrFEi04sgPJYYilt0exvgY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=89c206e2ccc504eb45d10ae2661c0c10411411c1", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/Uq8iY6_RDS2pyrlqJzbV6rrFEi04sgPJYYilt0exvgY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b5f65a4f0462967cf9bc738aac66d1017c0040de", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/Uq8iY6_RDS2pyrlqJzbV6rrFEi04sgPJYYilt0exvgY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=41feb45fd60d1ca671414401fe9743645e4f58be", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/Uq8iY6_RDS2pyrlqJzbV6rrFEi04sgPJYYilt0exvgY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=117ae682267f03e21dd55f1a9687523c130cbe72", "width": 1080, "height": 567}], "variants": {}, "id": "ptnDQ1fv_7VR0hWhaFloBxw_rEWyBVOzcyTHVYFTOJU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zek84k", "is_robot_indexable": true, "report_reasons": null, "author": "gato_noir", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zek84k/why_is_not_functional_programming_languages_as/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zek84k/why_is_not_functional_programming_languages_as/", "subreddit_subscribers": 82109, "created_utc": 1670365845.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In my experience, I have done exception handling via populating NoSQL Database for exception and using that as source for notification trigger.\n\nAlternatively, I have also tried defining error codes for known exceptions, use that in notifications.\n\nCan you share the approaches you  follow in your Data Pipeline for Exception Handling and how do you use it for notification purpose.", "author_fullname": "t2_rxkr4y1n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Exception Handling in Data Pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zexr7j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670408767.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my experience, I have done exception handling via populating NoSQL Database for exception and using that as source for notification trigger.&lt;/p&gt;\n\n&lt;p&gt;Alternatively, I have also tried defining error codes for known exceptions, use that in notifications.&lt;/p&gt;\n\n&lt;p&gt;Can you share the approaches you  follow in your Data Pipeline for Exception Handling and how do you use it for notification purpose.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zexr7j", "is_robot_indexable": true, "report_reasons": null, "author": "SoggyAbalone7392", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zexr7j/exception_handling_in_data_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zexr7j/exception_handling_in_data_pipeline/", "subreddit_subscribers": 82109, "created_utc": 1670408767.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey data folks, I have a question for all of you. I have received an offer as a senior data modeler for a mid size company ( reputed than my current company ) where in I will be working on Oracle and Netezza data modeling. Whereas currently I am working as senior data engineer working on Snowflake, ETL and modern data stack. I have 10+ years of experience (both on data engineering + modeling ). I appeared for data modeling interview as I thought it would be a senior role involving both DE + modelling and working in a more reputed company . But turns out , it's just data modeling. Should I join new company or continue in my current job ? Really confused, please tell your opinion.", "author_fullname": "t2_68lzz4hm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question on Data Modeler Offer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zexp0r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670408559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey data folks, I have a question for all of you. I have received an offer as a senior data modeler for a mid size company ( reputed than my current company ) where in I will be working on Oracle and Netezza data modeling. Whereas currently I am working as senior data engineer working on Snowflake, ETL and modern data stack. I have 10+ years of experience (both on data engineering + modeling ). I appeared for data modeling interview as I thought it would be a senior role involving both DE + modelling and working in a more reputed company . But turns out , it&amp;#39;s just data modeling. Should I join new company or continue in my current job ? Really confused, please tell your opinion.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zexp0r", "is_robot_indexable": true, "report_reasons": null, "author": "1aumron", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zexp0r/question_on_data_modeler_offer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zexp0r/question_on_data_modeler_offer/", "subreddit_subscribers": 82109, "created_utc": 1670408559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone!\n\nWe have a second instrument to our lab which was installed about 6 months ago. The previous instrument has been here for 2 years. The old instrument has been feeding data to a server however the new instrument has been storing data on a local db.\n\nWe have collected quite a bit of data on the local database but are now transitioning the second machine to server the first machine is hooked up to. I have a back up of the local db but how do I merge it with the existing server db? There are about 50 tables with a mixture of integer ID\u2019s and GUIDs.\n\nI saw a YouTube video on transferring data via an autogenerated sql server script and was considering that as an option. I would not be able to manually add due to the size of the data.\n\nThanks!", "author_fullname": "t2_624odrt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Merging two data sources ideas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zetrlv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "nsfw", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670393306.0, "link_flair_type": "text", "wls": 3, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone!&lt;/p&gt;\n\n&lt;p&gt;We have a second instrument to our lab which was installed about 6 months ago. The previous instrument has been here for 2 years. The old instrument has been feeding data to a server however the new instrument has been storing data on a local db.&lt;/p&gt;\n\n&lt;p&gt;We have collected quite a bit of data on the local database but are now transitioning the second machine to server the first machine is hooked up to. I have a back up of the local db but how do I merge it with the existing server db? There are about 50 tables with a mixture of integer ID\u2019s and GUIDs.&lt;/p&gt;\n\n&lt;p&gt;I saw a YouTube video on transferring data via an autogenerated sql server script and was considering that as an option. I would not be able to manually add due to the size of the data.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": true, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zetrlv", "is_robot_indexable": true, "report_reasons": null, "author": "Helium0205", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "promo_adult_nsfw", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zetrlv/merging_two_data_sources_ideas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zetrlv/merging_two_data_sources_ideas/", "subreddit_subscribers": 82109, "created_utc": 1670393306.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What does DevOps mean to you? Is it useful to DE?\n\nI've been on many teams - in a previous career doing production support and then analytics the past few years. But now I ended up on a DevOps team. \n\nWhat this team does, for example:\n\n* Agile, including two week sprints and daily stand-up\n* CI/CD pipeline\n* Checking morning emails for job failures, then sending another email to an audience on the success/failure of all jobs. \n* Fielding and prioritizing user requests.\n* Formal release process, inform users what's going in Friday night. \n* Building ETLs with Datastage (federal agency with old tech)\n* Document, and document more. Government loves documents! \n\nI could go on, but I'm not here to complain. I just want to get an idea of what DevOps looks like for data engineers.", "author_fullname": "t2_2o0q5m4h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What does DevOps look like on your team?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zemo3o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670371698.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What does DevOps mean to you? Is it useful to DE?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been on many teams - in a previous career doing production support and then analytics the past few years. But now I ended up on a DevOps team. &lt;/p&gt;\n\n&lt;p&gt;What this team does, for example:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Agile, including two week sprints and daily stand-up&lt;/li&gt;\n&lt;li&gt;CI/CD pipeline&lt;/li&gt;\n&lt;li&gt;Checking morning emails for job failures, then sending another email to an audience on the success/failure of all jobs. &lt;/li&gt;\n&lt;li&gt;Fielding and prioritizing user requests.&lt;/li&gt;\n&lt;li&gt;Formal release process, inform users what&amp;#39;s going in Friday night. &lt;/li&gt;\n&lt;li&gt;Building ETLs with Datastage (federal agency with old tech)&lt;/li&gt;\n&lt;li&gt;Document, and document more. Government loves documents! &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I could go on, but I&amp;#39;m not here to complain. I just want to get an idea of what DevOps looks like for data engineers.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zemo3o", "is_robot_indexable": true, "report_reasons": null, "author": "rotterdamn8", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zemo3o/what_does_devops_look_like_on_your_team/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zemo3o/what_does_devops_look_like_on_your_team/", "subreddit_subscribers": 82109, "created_utc": 1670371698.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys, \n\nI'm pretty new to Data Engineering, and I got asked to capture user changes to the datawarehouse.\n\nI'm working on a project where the source table (Users) can change info (User changes city) or the data (row) disappears because User deletes the data.  \n\nI've looked around for articles, books (kimball) and this subreddit, and I have been reading that SCD Type 2 is the right one to implement in this case. \n\nProblem is, the source implements hard deletes on data, which means that I have to check all the rows and see if there's any deleted rows  and try to capture that deletion in the SCD 2 table.\n\nTLDR:\n\nSituation:\n\n\\- I have a source database that can have data changes or data deletes\n\nTask:\n\n\\- To track these changes or deletions in the DWH\n\nAction:\n\n\\- Implement Slowly Changing Dimensions Type 2?\n\n&amp;#x200B;\n\nPlease guide me :)", "author_fullname": "t2_5th3ljh1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to implement SCD 2 with hard deleted rows", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zeir6j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670362357.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m pretty new to Data Engineering, and I got asked to capture user changes to the datawarehouse.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working on a project where the source table (Users) can change info (User changes city) or the data (row) disappears because User deletes the data.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve looked around for articles, books (kimball) and this subreddit, and I have been reading that SCD Type 2 is the right one to implement in this case. &lt;/p&gt;\n\n&lt;p&gt;Problem is, the source implements hard deletes on data, which means that I have to check all the rows and see if there&amp;#39;s any deleted rows  and try to capture that deletion in the SCD 2 table.&lt;/p&gt;\n\n&lt;p&gt;TLDR:&lt;/p&gt;\n\n&lt;p&gt;Situation:&lt;/p&gt;\n\n&lt;p&gt;- I have a source database that can have data changes or data deletes&lt;/p&gt;\n\n&lt;p&gt;Task:&lt;/p&gt;\n\n&lt;p&gt;- To track these changes or deletions in the DWH&lt;/p&gt;\n\n&lt;p&gt;Action:&lt;/p&gt;\n\n&lt;p&gt;- Implement Slowly Changing Dimensions Type 2?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Please guide me :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zeir6j", "is_robot_indexable": true, "report_reasons": null, "author": "Bored_Gunner", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zeir6j/how_to_implement_scd_2_with_hard_deleted_rows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zeir6j/how_to_implement_scd_2_with_hard_deleted_rows/", "subreddit_subscribers": 82109, "created_utc": 1670362357.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}