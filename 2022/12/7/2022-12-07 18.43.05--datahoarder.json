{"kind": "Listing", "data": {"after": "t3_zelg4f", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_ck2fr5mv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\u2018Nintendo Power\u2019 Scans Disappeared From The Internet Archive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_zeseu3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": null, "ups": 781, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "265b199a-b98c-11e2-8300-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 781, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/67RknqOAH-XaHm9TAV7ezrNIcZDpBsGvrX9ZJOLvhuw.jpg", "edited": false, "author_flair_css_class": "cloud", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670388762.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "techdirt.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.techdirt.com/2022/12/06/nintendo-power-scans-disappeared-from-the-internet-archive/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/SN1XpROtvB93NOJjW-GbKE8jFEtMifcFMYK3SbRuekA.jpg?auto=webp&amp;s=e3d2e624576871ac1282ee75a9064e8fd20baa6f", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/SN1XpROtvB93NOJjW-GbKE8jFEtMifcFMYK3SbRuekA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cc245f718ee26f44bcec58a3523e7742f5d86788", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/SN1XpROtvB93NOJjW-GbKE8jFEtMifcFMYK3SbRuekA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e3c4f1010352c999df8be6d90d155f272c72c214", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/SN1XpROtvB93NOJjW-GbKE8jFEtMifcFMYK3SbRuekA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=591dedea8a6c2463a336191b16fdb4596f31a566", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/SN1XpROtvB93NOJjW-GbKE8jFEtMifcFMYK3SbRuekA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0b7454378d0254e6c4d462e0439766673ae0f044", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/SN1XpROtvB93NOJjW-GbKE8jFEtMifcFMYK3SbRuekA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b4ab0484921de253ce917e525c0b17acd293774a", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/SN1XpROtvB93NOJjW-GbKE8jFEtMifcFMYK3SbRuekA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7cb96466b8c6ab2d4ec8e94375c0313cb46b6d71", "width": 1080, "height": 567}], "variants": {}, "id": "86PGtE2qmX3coS9Htmb8TUfXMSg2HaYO4Rk8A0YbGow"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "To the Cloud!", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zeseu3", "is_robot_indexable": true, "report_reasons": null, "author": "AbolishDisney", "discussion_type": null, "num_comments": 142, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/zeseu3/nintendo_power_scans_disappeared_from_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.techdirt.com/2022/12/06/nintendo-power-scans-disappeared-from-the-internet-archive/", "subreddit_subscribers": 657857, "created_utc": 1670388762.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_7ks1s2c8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What power connector is this? Found this Quantum 8 LTO-5 drive at the dump.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_zejoxg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "ups": 52, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 52, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/62qDzuI30MJ9ILyhYSye3tTvTmAihhkyJD-Mma2KyHI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670364563.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/dg4rzu0xpc4a1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/dg4rzu0xpc4a1.jpg?auto=webp&amp;s=4a058ed9224dd75b2a875ec29d83cb9d52967500", "width": 4080, "height": 3072}, "resolutions": [{"url": "https://preview.redd.it/dg4rzu0xpc4a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fa8553f0f0cef5290109df80542c97951b4cdf6f", "width": 108, "height": 81}, {"url": "https://preview.redd.it/dg4rzu0xpc4a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3a99bebc7461a29fafc89dc24e90d3e313e57c8f", "width": 216, "height": 162}, {"url": "https://preview.redd.it/dg4rzu0xpc4a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=77c659cfddf0036da55f144da01ee3bf86f0c64c", "width": 320, "height": 240}, {"url": "https://preview.redd.it/dg4rzu0xpc4a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e1a6492270a280cdeb262e42266042db4d8dc3ee", "width": 640, "height": 481}, {"url": "https://preview.redd.it/dg4rzu0xpc4a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=15ac07311e9d802da22dc4bc77e39f4f807c2b0a", "width": 960, "height": 722}, {"url": "https://preview.redd.it/dg4rzu0xpc4a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=894716f9b7dd07a5ce882ccab4529fa4ab91c77a", "width": 1080, "height": 813}], "variants": {}, "id": "FfhULOD7SkUAhFnVgnAPFZQ2smAHHeYA6VnzDMZTl2k"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zejoxg", "is_robot_indexable": true, "report_reasons": null, "author": "Osiris834", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zejoxg/what_power_connector_is_this_found_this_quantum_8/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/dg4rzu0xpc4a1.jpg", "subreddit_subscribers": 657857, "created_utc": 1670364563.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_v2a9t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Archiving official documents as an act of radical journalism - By Maria Bustillos", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_zee9aq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "ups": 52, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 52, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/uwQvkmwFDM_yxCjaV0fk7WEyxr760Jup1Gk_-6sh4qA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670351778.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "cjr.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.cjr.org/business_of_news/archiving-official-documents-as-an-act-of-radical-journalism.php", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/c5tgqEUoYNUKkXMl3bPfHUu1g81BANHSaiJC2QEOm8o.jpg?auto=webp&amp;s=68ea02111fddcf53bca5e502969df4a814079fa2", "width": 600, "height": 314}, "resolutions": [{"url": "https://external-preview.redd.it/c5tgqEUoYNUKkXMl3bPfHUu1g81BANHSaiJC2QEOm8o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=95b361380a3b7cf9a6aa38bc8d4c2c41c088e7af", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/c5tgqEUoYNUKkXMl3bPfHUu1g81BANHSaiJC2QEOm8o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=14dc1e71cd3947477deec883eafd1745417048fe", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/c5tgqEUoYNUKkXMl3bPfHUu1g81BANHSaiJC2QEOm8o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=225d713f5210d2df662c9a361d769dac980f513e", "width": 320, "height": 167}], "variants": {}, "id": "As4g_dvQ6QWS5z1WHj0TBZpSEPESlVNVwvg8LLtfzGM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zee9aq", "is_robot_indexable": true, "report_reasons": null, "author": "Crazy-Red-Fox", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zee9aq/archiving_official_documents_as_an_act_of_radical/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.cjr.org/business_of_news/archiving-official-documents-as-an-act-of-radical-journalism.php", "subreddit_subscribers": 657857, "created_utc": 1670351778.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "[https://www.reddit.com/r/DataHoarder/comments/zea4ge/what\\_is\\_better\\_for\\_storage\\_reliability\\_for/](https://www.reddit.com/r/DataHoarder/comments/zea4ge/what_is_better_for_storage_reliability_for/)\n\nI am building a small home server.  Budget it about $700.  Its main uses will be Plex, a general file server, a place to hold important data (wedding videos, youtube raw footage) and run a Valheim dedicated server.  \n\nI had originally planned on using one 8TB HDD as the storage drive for Plex movies.  I was then going to store important data on two mirrored 1TB SSDs.  But following my previous post I feel that these 1TB SSDs are a waste since if I delete a file, the mirrored will also be deleted.  I could return them to free up budget for another 8TB HDD (16TB total).  \n\nShould I just get two HDDs, put everything on them, then backup important stuff in cloud storage, and/or an external location?  Or stick with the original plan with the 1TB mirrored SSDs/8TB HDD?", "author_fullname": "t2_kz70b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Follow Up: Should I just get two HDDs, put everything on them, then backup important stuff in cloud storage, and/or an external location? Or use 1TB mirrored SSDs/8TB HDD for general storage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zem53b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670370327.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/zea4ge/what_is_better_for_storage_reliability_for/\"&gt;https://www.reddit.com/r/DataHoarder/comments/zea4ge/what_is_better_for_storage_reliability_for/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I am building a small home server.  Budget it about $700.  Its main uses will be Plex, a general file server, a place to hold important data (wedding videos, youtube raw footage) and run a Valheim dedicated server.  &lt;/p&gt;\n\n&lt;p&gt;I had originally planned on using one 8TB HDD as the storage drive for Plex movies.  I was then going to store important data on two mirrored 1TB SSDs.  But following my previous post I feel that these 1TB SSDs are a waste since if I delete a file, the mirrored will also be deleted.  I could return them to free up budget for another 8TB HDD (16TB total).  &lt;/p&gt;\n\n&lt;p&gt;Should I just get two HDDs, put everything on them, then backup important stuff in cloud storage, and/or an external location?  Or stick with the original plan with the 1TB mirrored SSDs/8TB HDD?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zem53b", "is_robot_indexable": true, "report_reasons": null, "author": "thefreymaster", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zem53b/follow_up_should_i_just_get_two_hdds_put/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zem53b/follow_up_should_i_just_get_two_hdds_put/", "subreddit_subscribers": 657857, "created_utc": 1670370327.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_735tdxy6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I got a cheap Crucial SSD for OS about 1 or 2 years back, and it appears I churned through a lot of it's health in this short time. Any idea how long my SSD would be working for? It's only holding OS for a PC I use as a mass storage unit that stays powered on almost 24/7 (I run VMs there too)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_zezdld", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/NkecV0P30DKxPtjfa_fNbu4Sc35fsF8FEy8tBKcnyY8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670414319.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/cet21u0jsg4a1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/cet21u0jsg4a1.png?auto=webp&amp;s=b7c0f724f0db4bace82ead4806ecc9b671d56de8", "width": 838, "height": 862}, "resolutions": [{"url": "https://preview.redd.it/cet21u0jsg4a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3fabb8a9a2311e2c5a88b031579ab4175c6a2baa", "width": 108, "height": 111}, {"url": "https://preview.redd.it/cet21u0jsg4a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1f9eea63f43653d085e9a90c03c25d4faea20811", "width": 216, "height": 222}, {"url": "https://preview.redd.it/cet21u0jsg4a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=6a85ad8bfa4afe4f8ea06785e4fe12701c84414f", "width": 320, "height": 329}, {"url": "https://preview.redd.it/cet21u0jsg4a1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=626dba821126bea8bd06f3412523239295f9beae", "width": 640, "height": 658}], "variants": {}, "id": "qnbpJ6NKRrqLZnAck8uzj-xdtjWj4qarriS7dPugnzo"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zezdld", "is_robot_indexable": true, "report_reasons": null, "author": "samforelli", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zezdld/i_got_a_cheap_crucial_ssd_for_os_about_1_or_2/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/cet21u0jsg4a1.png", "subreddit_subscribers": 657857, "created_utc": 1670414319.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello Data Hoarders,\n\nI am looking to supplement my current home lab with storage to store media, backups, etc. My biggest use case is storage of 4k movies and have the ability to stream them to devices in the home. My question is would this be a better job for a NAS or should I add DAS to my current server and leverage a VM to provide these services?\n\nThanks!", "author_fullname": "t2_5y1dc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking to store 4k movies and stream", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zepsow", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670380683.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Data Hoarders,&lt;/p&gt;\n\n&lt;p&gt;I am looking to supplement my current home lab with storage to store media, backups, etc. My biggest use case is storage of 4k movies and have the ability to stream them to devices in the home. My question is would this be a better job for a NAS or should I add DAS to my current server and leverage a VM to provide these services?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "zepsow", "is_robot_indexable": true, "report_reasons": null, "author": "kopaka89", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zepsow/looking_to_store_4k_movies_and_stream/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zepsow/looking_to_store_4k_movies_and_stream/", "subreddit_subscribers": 657857, "created_utc": 1670380683.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So say you ve bought a WD HDD from Amazon but afterwards it seems to have been opened and replaces by another drive \n\nCould this also happen if you buy it straight from WD? Say you just bought a drive new but someone shucked it in the past. Could you return it if you bought it? Or would WD confiscate it and say it has been tampered with.", "author_fullname": "t2_jzdc2b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible for WD to sell used products?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zepmvg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670380198.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So say you ve bought a WD HDD from Amazon but afterwards it seems to have been opened and replaces by another drive &lt;/p&gt;\n\n&lt;p&gt;Could this also happen if you buy it straight from WD? Say you just bought a drive new but someone shucked it in the past. Could you return it if you bought it? Or would WD confiscate it and say it has been tampered with.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zepmvg", "is_robot_indexable": true, "report_reasons": null, "author": "CMDVN", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zepmvg/is_it_possible_for_wd_to_sell_used_products/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zepmvg/is_it_possible_for_wd_to_sell_used_products/", "subreddit_subscribers": 657857, "created_utc": 1670380198.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi there,\n\nI have about 12TB of data on my local NAS. Just purchased an 18TB drive to have that data backed up locally. For my third copy, after researching cloud providers (cost, speed, and reliability), I've come to the conclusion that it's best to set up another NAS/server that I will plug in at a friend's place.\n\nI have two things I would like feedback on:\n\n1. Encryption: what do you recommend to encrypt my data off-site? Assuming the server is always connected to the internet when on, is there a way to make it so that when the computer starts up, the encrypted data is not accessible, where I get an email or notification to do somehow remotely unlock the data? What I'm trying to guard against is someone taking the server and accessing my private data. Assuming it gets stolen, I'd like to know that the data is encrypted and not accessible.\n\n2. Syncing: given this data size (12TB now, 20TB in 5 years), is it best to keep the data in sync using Syncthing? Or would the size cause issues for Syncthing? If so, I would just have a daily Cron job to rsync the data.\n\nWelcome any insights you all are willing to share. Thanks.", "author_fullname": "t2_3zlpu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Off-site backup at friend: encryption and syncing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zehu4q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670360178.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there,&lt;/p&gt;\n\n&lt;p&gt;I have about 12TB of data on my local NAS. Just purchased an 18TB drive to have that data backed up locally. For my third copy, after researching cloud providers (cost, speed, and reliability), I&amp;#39;ve come to the conclusion that it&amp;#39;s best to set up another NAS/server that I will plug in at a friend&amp;#39;s place.&lt;/p&gt;\n\n&lt;p&gt;I have two things I would like feedback on:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Encryption: what do you recommend to encrypt my data off-site? Assuming the server is always connected to the internet when on, is there a way to make it so that when the computer starts up, the encrypted data is not accessible, where I get an email or notification to do somehow remotely unlock the data? What I&amp;#39;m trying to guard against is someone taking the server and accessing my private data. Assuming it gets stolen, I&amp;#39;d like to know that the data is encrypted and not accessible.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Syncing: given this data size (12TB now, 20TB in 5 years), is it best to keep the data in sync using Syncthing? Or would the size cause issues for Syncthing? If so, I would just have a daily Cron job to rsync the data.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Welcome any insights you all are willing to share. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zehu4q", "is_robot_indexable": true, "report_reasons": null, "author": "vinhdizzo", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zehu4q/offsite_backup_at_friend_encryption_and_syncing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zehu4q/offsite_backup_at_friend_encryption_and_syncing/", "subreddit_subscribers": 657857, "created_utc": 1670360178.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I used to use Tdarr, but I'm currently trying Unmanic because it seems a bit simpler and easier to configure. However, whilst there are lots of installation write-ups, there isn't any plugin/job/process/test setup tutorials for 'standard' configurations that people might want to use. Anyone got any sources for these?\n\nI'm basically wanting to set it up to:\n\n1. Use the intel quicksync plugin\n2. Only process files &gt; 5GB\n3. Transcode to reduce them down using h264, but at a lower bitrate etc so aiming to get about 1GB/hour\n4. Only run processing/transcoding between certain hours (e.g., 1am =&gt; 5am)\n\nI've added the plugin, a worker, and the filesize test (which I think does #2) but just want to see if somebody else has written up their settings so I can make sure I've got it right before I point it at my library. :)\n\nRunning it on a Synology via Docker, although I don't think that's relevant for this question.", "author_fullname": "t2_3tq8w00m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unmanic Starter Setup?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zf3yd7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670427060.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I used to use Tdarr, but I&amp;#39;m currently trying Unmanic because it seems a bit simpler and easier to configure. However, whilst there are lots of installation write-ups, there isn&amp;#39;t any plugin/job/process/test setup tutorials for &amp;#39;standard&amp;#39; configurations that people might want to use. Anyone got any sources for these?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m basically wanting to set it up to:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Use the intel quicksync plugin&lt;/li&gt;\n&lt;li&gt;Only process files &amp;gt; 5GB&lt;/li&gt;\n&lt;li&gt;Transcode to reduce them down using h264, but at a lower bitrate etc so aiming to get about 1GB/hour&lt;/li&gt;\n&lt;li&gt;Only run processing/transcoding between certain hours (e.g., 1am =&amp;gt; 5am)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;ve added the plugin, a worker, and the filesize test (which I think does #2) but just want to see if somebody else has written up their settings so I can make sure I&amp;#39;ve got it right before I point it at my library. :)&lt;/p&gt;\n\n&lt;p&gt;Running it on a Synology via Docker, although I don&amp;#39;t think that&amp;#39;s relevant for this question.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "33TB Syno + B2", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zf3yd7", "is_robot_indexable": true, "report_reasons": null, "author": "botterway", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/zf3yd7/unmanic_starter_setup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zf3yd7/unmanic_starter_setup/", "subreddit_subscribers": 657857, "created_utc": 1670427060.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So here is my situation. I have an 8 bay Syba enclosure (non-raid) connected to my windows 10 machine and I'm keeping an even number of hard drives so that each hard drive has another one it can be copied to. Right now I have four Seagate Exos x18 18tb hdd. I have heard that error checking works differently on enterprise grade drives since they are meant for raid storage. Regardless, I want some kind of error checking program that does something a little specific.\n\nSo let's call drive 1 and 2 drive A, and 3 and 4 drive B. I want this program to generate a hash (or crc/checksum/sha256/whatever is best) of every file, and store a folder of those hashes anywhere like a separate storage unit (so I can keep copies anywhere I want). Then as I copy files over from A to B, I can have the program use those hashes to confirm what I copied is good, and on occasion reconfirm that everything looks good on both drives when I deem it's time to error check again. If a file goes bad on either A or B, when I run a scan the program will use those hashes to decide which drive has the good file, and copy it over to the bad one.  If it's possible, I wish to account for cases where drive A has more data than drive B, but the program will only check the files that are only on both A and B. And obviously if a file is bad on both drives it'll just let me pick which one to keep and generate a new hash for me.\n\nI think GoodSync is either close to or exactly what I need, but looks subscription based and the limits on the free version make it useless to me. I think Teracopy has some of the features I need but I believe not all? I don't need it to be free, but if it isn't I prefer one time payment.\n\nThings to note, the four drives are empty still, drive A will be used daily, drive B will only be manually turned on monthly.", "author_fullname": "t2_iphb2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with data integrity across mirrored drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zeyrpx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1670413491.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670412257.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So here is my situation. I have an 8 bay Syba enclosure (non-raid) connected to my windows 10 machine and I&amp;#39;m keeping an even number of hard drives so that each hard drive has another one it can be copied to. Right now I have four Seagate Exos x18 18tb hdd. I have heard that error checking works differently on enterprise grade drives since they are meant for raid storage. Regardless, I want some kind of error checking program that does something a little specific.&lt;/p&gt;\n\n&lt;p&gt;So let&amp;#39;s call drive 1 and 2 drive A, and 3 and 4 drive B. I want this program to generate a hash (or crc/checksum/sha256/whatever is best) of every file, and store a folder of those hashes anywhere like a separate storage unit (so I can keep copies anywhere I want). Then as I copy files over from A to B, I can have the program use those hashes to confirm what I copied is good, and on occasion reconfirm that everything looks good on both drives when I deem it&amp;#39;s time to error check again. If a file goes bad on either A or B, when I run a scan the program will use those hashes to decide which drive has the good file, and copy it over to the bad one.  If it&amp;#39;s possible, I wish to account for cases where drive A has more data than drive B, but the program will only check the files that are only on both A and B. And obviously if a file is bad on both drives it&amp;#39;ll just let me pick which one to keep and generate a new hash for me.&lt;/p&gt;\n\n&lt;p&gt;I think GoodSync is either close to or exactly what I need, but looks subscription based and the limits on the free version make it useless to me. I think Teracopy has some of the features I need but I believe not all? I don&amp;#39;t need it to be free, but if it isn&amp;#39;t I prefer one time payment.&lt;/p&gt;\n\n&lt;p&gt;Things to note, the four drives are empty still, drive A will be used daily, drive B will only be manually turned on monthly.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zeyrpx", "is_robot_indexable": true, "report_reasons": null, "author": "xScopeLess", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zeyrpx/help_with_data_integrity_across_mirrored_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zeyrpx/help_with_data_integrity_across_mirrored_drives/", "subreddit_subscribers": 657857, "created_utc": 1670412257.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I want to replace my storage setup with one new big boy, please help me decide!\n\nCurrent Build:\n\nCompute:\n\n* DL380 G10 24x SFF, 2x 4114 Xeon, 256GB RAM + iodrives in PCIe Slots\n* DL380 G9 12x LFF, 2x 2667v4, 256GB RAM + iodrives in PCIe Slots\n\nStorage:\n\n* DL380 G9 12x LFF, 2x 2650v4, 192GB RAM (Fully filled with WD Golds)\n* MSA 2040 12x LFF filled with some shucked and some wd drives\n\n&amp;#x200B;\n\ncurrently i run some minor vm's and the main debian zfs vm on the dl380g9(storage)\n\ni got esxi installed and im passing through the controllers needed to see my disks in the vm directly\n\n&amp;#x200B;\n\nCurrent options:\n\nA: Selfbuild new Server with an SM or Chenbro case (24/36x LFF) and either barebone debian or passthrough with controller again\n\nB: used SAN like the 3par 8000 and giving it an vm on the compute cluster\n\n&amp;#x200B;\n\nMain concern is future upgrades and power as im currently at 0,83\u20ac per kw/h also soonish switching from vmware to xen or proxmox whatever fits me better after testing\n\n&amp;#x200B;\n\nmay the hoarding help!", "author_fullname": "t2_w5886", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Storage advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zf7rnq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670434862.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to replace my storage setup with one new big boy, please help me decide!&lt;/p&gt;\n\n&lt;p&gt;Current Build:&lt;/p&gt;\n\n&lt;p&gt;Compute:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;DL380 G10 24x SFF, 2x 4114 Xeon, 256GB RAM + iodrives in PCIe Slots&lt;/li&gt;\n&lt;li&gt;DL380 G9 12x LFF, 2x 2667v4, 256GB RAM + iodrives in PCIe Slots&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Storage:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;DL380 G9 12x LFF, 2x 2650v4, 192GB RAM (Fully filled with WD Golds)&lt;/li&gt;\n&lt;li&gt;MSA 2040 12x LFF filled with some shucked and some wd drives&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;currently i run some minor vm&amp;#39;s and the main debian zfs vm on the dl380g9(storage)&lt;/p&gt;\n\n&lt;p&gt;i got esxi installed and im passing through the controllers needed to see my disks in the vm directly&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Current options:&lt;/p&gt;\n\n&lt;p&gt;A: Selfbuild new Server with an SM or Chenbro case (24/36x LFF) and either barebone debian or passthrough with controller again&lt;/p&gt;\n\n&lt;p&gt;B: used SAN like the 3par 8000 and giving it an vm on the compute cluster&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Main concern is future upgrades and power as im currently at 0,83\u20ac per kw/h also soonish switching from vmware to xen or proxmox whatever fits me better after testing&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;may the hoarding help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zf7rnq", "is_robot_indexable": true, "report_reasons": null, "author": "thalooka", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zf7rnq/storage_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zf7rnq/storage_advice/", "subreddit_subscribers": 657857, "created_utc": 1670434862.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm trying to move years of photos from an iphone to a WD Easystore and it just not working. I've tried with two different model iphones and on both, using file explorer every time I copy a folder from the iphone it will be missing more than half the photos. \n\nDoes anyone know how to transfer photos from an iphone to an external hard drive through a pc?\n\nMany years ago this was easy and quick but now it simply won't work.", "author_fullname": "t2_1kavow3y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Iphone photos to WD Easystore through PC", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zf76c7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670433661.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to move years of photos from an iphone to a WD Easystore and it just not working. I&amp;#39;ve tried with two different model iphones and on both, using file explorer every time I copy a folder from the iphone it will be missing more than half the photos. &lt;/p&gt;\n\n&lt;p&gt;Does anyone know how to transfer photos from an iphone to an external hard drive through a pc?&lt;/p&gt;\n\n&lt;p&gt;Many years ago this was easy and quick but now it simply won&amp;#39;t work.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zf76c7", "is_robot_indexable": true, "report_reasons": null, "author": "DatasTemporalLobe", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zf76c7/iphone_photos_to_wd_easystore_through_pc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zf76c7/iphone_photos_to_wd_easystore_through_pc/", "subreddit_subscribers": 657857, "created_utc": 1670433661.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all. I have Windows 10 and for the longest time I've wanted to know if there's anything I can do differently or better to maintain my drives. I have mixed SATA SSDs, NVMes and HDDs, 12 total.\n\nI know Windows does TRIM on SSDs, but I don't know...there's something satisfying about running a command or a maintenance cycle that I can see working and see the results of, if you know what I mean.\n\nDo you run maintenance on your drives regularly? Any recommendations of what I can do to keep them running well? Lastly, do you set Windows to turn off your drives after X amount of minutes in power options, and do you use hibernate? Does hibernate harm SSDs with the writes?", "author_fullname": "t2_t1yb6joj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SSD/HDD maintenance questions.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zf65fx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670431594.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all. I have Windows 10 and for the longest time I&amp;#39;ve wanted to know if there&amp;#39;s anything I can do differently or better to maintain my drives. I have mixed SATA SSDs, NVMes and HDDs, 12 total.&lt;/p&gt;\n\n&lt;p&gt;I know Windows does TRIM on SSDs, but I don&amp;#39;t know...there&amp;#39;s something satisfying about running a command or a maintenance cycle that I can see working and see the results of, if you know what I mean.&lt;/p&gt;\n\n&lt;p&gt;Do you run maintenance on your drives regularly? Any recommendations of what I can do to keep them running well? Lastly, do you set Windows to turn off your drives after X amount of minutes in power options, and do you use hibernate? Does hibernate harm SSDs with the writes?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zf65fx", "is_robot_indexable": true, "report_reasons": null, "author": "kingofallnorway", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zf65fx/ssdhdd_maintenance_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zf65fx/ssdhdd_maintenance_questions/", "subreddit_subscribers": 657857, "created_utc": 1670431594.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Are there any clear instructions on how to create filters in DownThemAll? (Firefox ver)\n\nI need to create a filter that selects all urls with this structure: serverXX.sampleurl.net/  With XX being a completely random number between 0 an 999.\n\nWhat method is DownThemAll using for filters?, are there any good instructions for it?, and is this possible?\n\nThanks in advance!", "author_fullname": "t2_52qu40au", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do i create filters in DownThemAll ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zf586c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670429702.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are there any clear instructions on how to create filters in DownThemAll? (Firefox ver)&lt;/p&gt;\n\n&lt;p&gt;I need to create a filter that selects all urls with this structure: serverXX.sampleurl.net/  With XX being a completely random number between 0 an 999.&lt;/p&gt;\n\n&lt;p&gt;What method is DownThemAll using for filters?, are there any good instructions for it?, and is this possible?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zf586c", "is_robot_indexable": true, "report_reasons": null, "author": "mactep66", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zf586c/how_do_i_create_filters_in_downthemall/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zf586c/how_do_i_create_filters_in_downthemall/", "subreddit_subscribers": 657857, "created_utc": 1670429702.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi guys.\n\nI got few To of music and photos I'd like to backup to my cloud service of choice (icedrive) which supports webdav.\n\nIs there a good software alternative to schedule my backups from my PC to my cloud ?\n\nI've been searching on the net, and the few solutions I found don't inspire me with confidence...", "author_fullname": "t2_jsq9e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scheduled Webdav Backup on Windows", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zf4xtn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670429120.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys.&lt;/p&gt;\n\n&lt;p&gt;I got few To of music and photos I&amp;#39;d like to backup to my cloud service of choice (icedrive) which supports webdav.&lt;/p&gt;\n\n&lt;p&gt;Is there a good software alternative to schedule my backups from my PC to my cloud ?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been searching on the net, and the few solutions I found don&amp;#39;t inspire me with confidence...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zf4xtn", "is_robot_indexable": true, "report_reasons": null, "author": "Tiritibambix", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zf4xtn/scheduled_webdav_backup_on_windows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zf4xtn/scheduled_webdav_backup_on_windows/", "subreddit_subscribers": 657857, "created_utc": 1670429120.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I use to run an extremely large unRAID server back in my younger days but I downsized and got rid of it. Currently I'm looking to buy something a bit more practical than a whole second computer running 24/7 in my house. This will be for a backup, so it doesn't need to be any faster than 100MB/s or so, but it'd be nice. I am thinking an external NAS of some sort but not sure. I don't really trust throwing 2-3 internals HDDs in raid 1/5 and using my motherboard.\n\nBudget is about $1k. I was thinking of just grabbing 2x 20TB WD Reds or 2x 20TB IronWolf Pros and just throwing them in Raid 1 in a NAS (Maybe a DS220+)? Comes out to about $1100.\n\nAny ideas?", "author_fullname": "t2_gvj0nvfr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'd like ~20TB of usable data with at least a single drive failure protection", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zf18tm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1670420726.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670419997.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I use to run an extremely large unRAID server back in my younger days but I downsized and got rid of it. Currently I&amp;#39;m looking to buy something a bit more practical than a whole second computer running 24/7 in my house. This will be for a backup, so it doesn&amp;#39;t need to be any faster than 100MB/s or so, but it&amp;#39;d be nice. I am thinking an external NAS of some sort but not sure. I don&amp;#39;t really trust throwing 2-3 internals HDDs in raid 1/5 and using my motherboard.&lt;/p&gt;\n\n&lt;p&gt;Budget is about $1k. I was thinking of just grabbing 2x 20TB WD Reds or 2x 20TB IronWolf Pros and just throwing them in Raid 1 in a NAS (Maybe a DS220+)? Comes out to about $1100.&lt;/p&gt;\n\n&lt;p&gt;Any ideas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zf18tm", "is_robot_indexable": true, "report_reasons": null, "author": "Lyioux", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zf18tm/id_like_20tb_of_usable_data_with_at_least_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zf18tm/id_like_20tb_of_usable_data_with_at_least_a/", "subreddit_subscribers": 657857, "created_utc": 1670419997.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey Reddit,\n\nI'm wondering what the best compression format is for creating whole drive backups.\n\nI have already made a 1.5TB TAR archive of one of my portable hard drives and copied it into my computer\n\nWhich compression format (7z, gzip, xz, etc...) would be the best for compressing this TAR file in the shortest amount of time? Compression ratio isn't really important, preferably below 90% though.\n\n Thank you", "author_fullname": "t2_3ngwm9jc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best archival/compression format for whole hard drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zeqk8f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670382971.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Reddit,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering what the best compression format is for creating whole drive backups.&lt;/p&gt;\n\n&lt;p&gt;I have already made a 1.5TB TAR archive of one of my portable hard drives and copied it into my computer&lt;/p&gt;\n\n&lt;p&gt;Which compression format (7z, gzip, xz, etc...) would be the best for compressing this TAR file in the shortest amount of time? Compression ratio isn&amp;#39;t really important, preferably below 90% though.&lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "20TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zeqk8f", "is_robot_indexable": true, "report_reasons": null, "author": "LolDude9876789", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/zeqk8f/best_archivalcompression_format_for_whole_hard/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zeqk8f/best_archivalcompression_format_for_whole_hard/", "subreddit_subscribers": 657857, "created_utc": 1670382971.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm currently looking for a way to compress some BD50 movies and I've read se good things about BD Rebuilder, does anyone else use this and what settings in general are best to use? Cheers", "author_fullname": "t2_5dkgegkg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "BD Rebuilder? Anyone use the program?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zf75qj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670433629.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently looking for a way to compress some BD50 movies and I&amp;#39;ve read se good things about BD Rebuilder, does anyone else use this and what settings in general are best to use? Cheers&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "zf75qj", "is_robot_indexable": true, "report_reasons": null, "author": "craftywizard1983", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zf75qj/bd_rebuilder_anyone_use_the_program/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zf75qj/bd_rebuilder_anyone_use_the_program/", "subreddit_subscribers": 657857, "created_utc": 1670433629.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "i have 4 external usb drive with the following letters in Win10: O P Q R.  DupeGuru was great for scanning duplicates for movies. usually it would find around 10 duplicates. i verify the dupes myself, mark for deletion, and move dupes to trash.\n\n2 days ago, i mounted these drives as folders instead in Disk Management. so these drives dont show up in \"This PC.\"  instead they can be found in something like \"C:\\\\drive O\"\n\n&amp;#x200B;\n\nhttps://preview.redd.it/dtlveilqeh4a1.png?width=292&amp;format=png&amp;auto=webp&amp;s=a61a8d8d0ed783f32431fc0f1aaf09bfe033cfae\n\nused DupeGuru on these folders and it found 4000+ duplicates!!! also, took over 4 days instead of the usual 10hours for scanning dupes. i dont know why i didnt manually verify the dupes, i just marked and moved them straight to the trash and empty.  now, i found out i lost these files completely, ZERO copies found on my drives.  luckily i still have them on BackBlaze backups but it's annoying and now looking for an alternative to DupeGuru.  love to hear what you guys are using.", "author_fullname": "t2_duy2j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "a better alternative to DupeGuru?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 15, "top_awarded_type": null, "hide_score": false, "media_metadata": {"dtlveilqeh4a1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 12, "x": 108, "u": "https://preview.redd.it/dtlveilqeh4a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=cfddfa67cc1845b3bbd0db9e49e42c8c6e2eae8e"}, {"y": 24, "x": 216, "u": "https://preview.redd.it/dtlveilqeh4a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=22092546b29949cf76a414be8be7d8318b2307ea"}], "s": {"y": 33, "x": 292, "u": "https://preview.redd.it/dtlveilqeh4a1.png?width=292&amp;format=png&amp;auto=webp&amp;s=a61a8d8d0ed783f32431fc0f1aaf09bfe033cfae"}, "id": "dtlveilqeh4a1"}}, "name": "t3_zf1us1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/YpGVOaJsrZJsuAY2jCFEQvZvdcodD_uDNx9mOTXP7V4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670421734.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i have 4 external usb drive with the following letters in Win10: O P Q R.  DupeGuru was great for scanning duplicates for movies. usually it would find around 10 duplicates. i verify the dupes myself, mark for deletion, and move dupes to trash.&lt;/p&gt;\n\n&lt;p&gt;2 days ago, i mounted these drives as folders instead in Disk Management. so these drives dont show up in &amp;quot;This PC.&amp;quot;  instead they can be found in something like &amp;quot;C:\\drive O&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/dtlveilqeh4a1.png?width=292&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a61a8d8d0ed783f32431fc0f1aaf09bfe033cfae\"&gt;https://preview.redd.it/dtlveilqeh4a1.png?width=292&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a61a8d8d0ed783f32431fc0f1aaf09bfe033cfae&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;used DupeGuru on these folders and it found 4000+ duplicates!!! also, took over 4 days instead of the usual 10hours for scanning dupes. i dont know why i didnt manually verify the dupes, i just marked and moved them straight to the trash and empty.  now, i found out i lost these files completely, ZERO copies found on my drives.  luckily i still have them on BackBlaze backups but it&amp;#39;s annoying and now looking for an alternative to DupeGuru.  love to hear what you guys are using.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zf1us1", "is_robot_indexable": true, "report_reasons": null, "author": "tungvu256", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zf1us1/a_better_alternative_to_dupeguru/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zf1us1/a_better_alternative_to_dupeguru/", "subreddit_subscribers": 657857, "created_utc": 1670421734.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Okay, so, I have a \"friend\" who recently discovered JAV videos, and turns out this files are like 4-7gb per video, i cant afford 60 gbs in my hdd for porn, nor do I want. I would like to reduce the files to maybe 500mb-1gb per video. What's the best tool for this? This videos are like 2hr long each, so It's a hassle but they are also rare to find.", "author_fullname": "t2_ifr1c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What tool would you recommend to compress long quantities of videos?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zf0j70", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670417922.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Okay, so, I have a &amp;quot;friend&amp;quot; who recently discovered JAV videos, and turns out this files are like 4-7gb per video, i cant afford 60 gbs in my hdd for porn, nor do I want. I would like to reduce the files to maybe 500mb-1gb per video. What&amp;#39;s the best tool for this? This videos are like 2hr long each, so It&amp;#39;s a hassle but they are also rare to find.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zf0j70", "is_robot_indexable": true, "report_reasons": null, "author": "Gammagori", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zf0j70/what_tool_would_you_recommend_to_compress_long/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zf0j70/what_tool_would_you_recommend_to_compress_long/", "subreddit_subscribers": 657857, "created_utc": 1670417922.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Let\u2019s just say you\u2019ve ran out of SATA ports on mobo, sure there\u2019s PCI expansions for more sata potds but what if you ran out of power cords too? You know these black yellow red ribbons", "author_fullname": "t2_umytgvvj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you do when your PC ran out internal HDD cables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zetdto", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670391996.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let\u2019s just say you\u2019ve ran out of SATA ports on mobo, sure there\u2019s PCI expansions for more sata potds but what if you ran out of power cords too? You know these black yellow red ribbons&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "zetdto", "is_robot_indexable": true, "report_reasons": null, "author": "ElonTastical", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zetdto/what_do_you_do_when_your_pc_ran_out_internal_hdd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zetdto/what_do_you_do_when_your_pc_ran_out_internal_hdd/", "subreddit_subscribers": 657857, "created_utc": 1670391996.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "1. I can't find a step by step guide and different sites say different things. Some use softwares like SiteSucker. Some use jq and wget. Some only wget or curl.\n2. How to download WARC with uBlockOrigin to reduce it's size as it will block ad ads and remove their JavaScript and HTML?\n3. How do I view WARC?\n4. Should I convert WARC to ZIM?\n5. How to download subset of a site like [https://www.billboard.com/charts/hot-100/](https://www.billboard.com/charts/hot-100/)?", "author_fullname": "t2_4jurunac", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to download Website as WARC ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zf0zpw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1670419260.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;ol&gt;\n&lt;li&gt;I can&amp;#39;t find a step by step guide and different sites say different things. Some use softwares like SiteSucker. Some use jq and wget. Some only wget or curl.&lt;/li&gt;\n&lt;li&gt;How to download WARC with uBlockOrigin to reduce it&amp;#39;s size as it will block ad ads and remove their JavaScript and HTML?&lt;/li&gt;\n&lt;li&gt;How do I view WARC?&lt;/li&gt;\n&lt;li&gt;Should I convert WARC to ZIM?&lt;/li&gt;\n&lt;li&gt;How to download subset of a site like &lt;a href=\"https://www.billboard.com/charts/hot-100/\"&gt;https://www.billboard.com/charts/hot-100/&lt;/a&gt;?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YkumNsa2Ovz4hOKaQci508c_LVXTzydMD5Z1O6A9kgI.jpg?auto=webp&amp;s=1e6cd6c904bd5d1d776b41e1ef2cfb9ed51f6d42", "width": 512, "height": 512}, "resolutions": [{"url": "https://external-preview.redd.it/YkumNsa2Ovz4hOKaQci508c_LVXTzydMD5Z1O6A9kgI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7e68b64596f16f6eeb8ac367452d6c2907f0ee7c", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/YkumNsa2Ovz4hOKaQci508c_LVXTzydMD5Z1O6A9kgI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b8a24a0b92741007d51d9737b709fd276779399c", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/YkumNsa2Ovz4hOKaQci508c_LVXTzydMD5Z1O6A9kgI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b6d127f5fe942d6f8718065efebf4d596bdb8098", "width": 320, "height": 320}], "variants": {}, "id": "YaMd8FwcKqOuciaaEEgpVbvD7x-FmkcEKbBwkVWnj7Q"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zf0zpw", "is_robot_indexable": true, "report_reasons": null, "author": "RedditNoobie777", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zf0zpw/how_to_download_website_as_warc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zf0zpw/how_to_download_website_as_warc/", "subreddit_subscribers": 657857, "created_utc": 1670419260.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "What program can I use to determine the total amount of hours an SSD or HDD has been used and what sort of numbers should I look out for in order to try to prevent potential sudden deaths ?\n\nTrying to learn, thank you.", "author_fullname": "t2_3luaynwv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SSD/HDD hours of operation and guidelines questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zevnqe", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670400583.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What program can I use to determine the total amount of hours an SSD or HDD has been used and what sort of numbers should I look out for in order to try to prevent potential sudden deaths ?&lt;/p&gt;\n\n&lt;p&gt;Trying to learn, thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zevnqe", "is_robot_indexable": true, "report_reasons": null, "author": "LightDarkCloud", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zevnqe/ssdhdd_hours_of_operation_and_guidelines_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zevnqe/ssdhdd_hours_of_operation_and_guidelines_questions/", "subreddit_subscribers": 657857, "created_utc": 1670400583.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I want to store videos in the hdd in a quality standard. So I\u2019m trying to understand the specs which MediaInfo shows.\n\n&amp;#x200B;\n\nMediaInfo shows for a particular video;\n\n**Overall Bitrate :** 42.5\n\n**Maximum Bitrate :** 32\n\nHow is overall (average) bitrate 42.5 while maximum bitrate is 32? (Maximum bitrate has to be higher than overall bitrate)\n\n???", "author_fullname": "t2_4rs6ei0p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MediaInfo - Maximum BitRate Vs Overall Bitrate", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zeuydk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670397746.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to store videos in the hdd in a quality standard. So I\u2019m trying to understand the specs which MediaInfo shows.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;MediaInfo shows for a particular video;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Overall Bitrate :&lt;/strong&gt; 42.5&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Maximum Bitrate :&lt;/strong&gt; 32&lt;/p&gt;\n\n&lt;p&gt;How is overall (average) bitrate 42.5 while maximum bitrate is 32? (Maximum bitrate has to be higher than overall bitrate)&lt;/p&gt;\n\n&lt;p&gt;???&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zeuydk", "is_robot_indexable": true, "report_reasons": null, "author": "mainecoon364", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zeuydk/mediainfo_maximum_bitrate_vs_overall_bitrate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zeuydk/mediainfo_maximum_bitrate_vs_overall_bitrate/", "subreddit_subscribers": 657857, "created_utc": 1670397746.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Just wanted you smart folks' opinion. I don't hoard anything super important. The few important things I do store, I have multiple backups of. With that out of the way, how would you set up 8 total drives on TrueNAS? I'm thinking 4x4TB in vdev, and 4x10TB in another vdev, both in the same pool- with raidZ1 setup. I watch the stuff I hoard sometimes, by streaming through jellyfin. I'm relatively new to the scene so very grateful for your input.", "author_fullname": "t2_3dlnjxvx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you set up 4x4TB + 4x10TB on TrueNAS Core?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zelg4f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670368669.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just wanted you smart folks&amp;#39; opinion. I don&amp;#39;t hoard anything super important. The few important things I do store, I have multiple backups of. With that out of the way, how would you set up 8 total drives on TrueNAS? I&amp;#39;m thinking 4x4TB in vdev, and 4x10TB in another vdev, both in the same pool- with raidZ1 setup. I watch the stuff I hoard sometimes, by streaming through jellyfin. I&amp;#39;m relatively new to the scene so very grateful for your input.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zelg4f", "is_robot_indexable": true, "report_reasons": null, "author": "ProximtyCoverageOnly", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zelg4f/how_would_you_set_up_4x4tb_4x10tb_on_truenas_core/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zelg4f/how_would_you_set_up_4x4tb_4x10tb_on_truenas_core/", "subreddit_subscribers": 657857, "created_utc": 1670368669.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}