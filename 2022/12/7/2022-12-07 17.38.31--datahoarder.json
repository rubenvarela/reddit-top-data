{"kind": "Listing", "data": {"after": "t3_zelg4f", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_ck2fr5mv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\u2018Nintendo Power\u2019 Scans Disappeared From The Internet Archive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_zeseu3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": null, "ups": 733, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "265b199a-b98c-11e2-8300-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 733, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/67RknqOAH-XaHm9TAV7ezrNIcZDpBsGvrX9ZJOLvhuw.jpg", "edited": false, "author_flair_css_class": "cloud", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670388762.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "techdirt.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.techdirt.com/2022/12/06/nintendo-power-scans-disappeared-from-the-internet-archive/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/SN1XpROtvB93NOJjW-GbKE8jFEtMifcFMYK3SbRuekA.jpg?auto=webp&amp;s=e3d2e624576871ac1282ee75a9064e8fd20baa6f", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/SN1XpROtvB93NOJjW-GbKE8jFEtMifcFMYK3SbRuekA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cc245f718ee26f44bcec58a3523e7742f5d86788", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/SN1XpROtvB93NOJjW-GbKE8jFEtMifcFMYK3SbRuekA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e3c4f1010352c999df8be6d90d155f272c72c214", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/SN1XpROtvB93NOJjW-GbKE8jFEtMifcFMYK3SbRuekA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=591dedea8a6c2463a336191b16fdb4596f31a566", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/SN1XpROtvB93NOJjW-GbKE8jFEtMifcFMYK3SbRuekA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0b7454378d0254e6c4d462e0439766673ae0f044", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/SN1XpROtvB93NOJjW-GbKE8jFEtMifcFMYK3SbRuekA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b4ab0484921de253ce917e525c0b17acd293774a", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/SN1XpROtvB93NOJjW-GbKE8jFEtMifcFMYK3SbRuekA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7cb96466b8c6ab2d4ec8e94375c0313cb46b6d71", "width": 1080, "height": 567}], "variants": {}, "id": "86PGtE2qmX3coS9Htmb8TUfXMSg2HaYO4Rk8A0YbGow"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "To the Cloud!", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zeseu3", "is_robot_indexable": true, "report_reasons": null, "author": "AbolishDisney", "discussion_type": null, "num_comments": 131, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/zeseu3/nintendo_power_scans_disappeared_from_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.techdirt.com/2022/12/06/nintendo-power-scans-disappeared-from-the-internet-archive/", "subreddit_subscribers": 657849, "created_utc": 1670388762.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_7ks1s2c8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What power connector is this? Found this Quantum 8 LTO-5 drive at the dump.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_zejoxg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "ups": 50, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 50, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/62qDzuI30MJ9ILyhYSye3tTvTmAihhkyJD-Mma2KyHI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670364563.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/dg4rzu0xpc4a1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/dg4rzu0xpc4a1.jpg?auto=webp&amp;s=4a058ed9224dd75b2a875ec29d83cb9d52967500", "width": 4080, "height": 3072}, "resolutions": [{"url": "https://preview.redd.it/dg4rzu0xpc4a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fa8553f0f0cef5290109df80542c97951b4cdf6f", "width": 108, "height": 81}, {"url": "https://preview.redd.it/dg4rzu0xpc4a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3a99bebc7461a29fafc89dc24e90d3e313e57c8f", "width": 216, "height": 162}, {"url": "https://preview.redd.it/dg4rzu0xpc4a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=77c659cfddf0036da55f144da01ee3bf86f0c64c", "width": 320, "height": 240}, {"url": "https://preview.redd.it/dg4rzu0xpc4a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e1a6492270a280cdeb262e42266042db4d8dc3ee", "width": 640, "height": 481}, {"url": "https://preview.redd.it/dg4rzu0xpc4a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=15ac07311e9d802da22dc4bc77e39f4f807c2b0a", "width": 960, "height": 722}, {"url": "https://preview.redd.it/dg4rzu0xpc4a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=894716f9b7dd07a5ce882ccab4529fa4ab91c77a", "width": 1080, "height": 813}], "variants": {}, "id": "FfhULOD7SkUAhFnVgnAPFZQ2smAHHeYA6VnzDMZTl2k"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zejoxg", "is_robot_indexable": true, "report_reasons": null, "author": "Osiris834", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zejoxg/what_power_connector_is_this_found_this_quantum_8/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/dg4rzu0xpc4a1.jpg", "subreddit_subscribers": 657849, "created_utc": 1670364563.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_v2a9t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Archiving official documents as an act of radical journalism - By Maria Bustillos", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_zee9aq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "ups": 53, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 53, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/uwQvkmwFDM_yxCjaV0fk7WEyxr760Jup1Gk_-6sh4qA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670351778.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "cjr.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.cjr.org/business_of_news/archiving-official-documents-as-an-act-of-radical-journalism.php", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/c5tgqEUoYNUKkXMl3bPfHUu1g81BANHSaiJC2QEOm8o.jpg?auto=webp&amp;s=68ea02111fddcf53bca5e502969df4a814079fa2", "width": 600, "height": 314}, "resolutions": [{"url": "https://external-preview.redd.it/c5tgqEUoYNUKkXMl3bPfHUu1g81BANHSaiJC2QEOm8o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=95b361380a3b7cf9a6aa38bc8d4c2c41c088e7af", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/c5tgqEUoYNUKkXMl3bPfHUu1g81BANHSaiJC2QEOm8o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=14dc1e71cd3947477deec883eafd1745417048fe", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/c5tgqEUoYNUKkXMl3bPfHUu1g81BANHSaiJC2QEOm8o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=225d713f5210d2df662c9a361d769dac980f513e", "width": 320, "height": 167}], "variants": {}, "id": "As4g_dvQ6QWS5z1WHj0TBZpSEPESlVNVwvg8LLtfzGM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zee9aq", "is_robot_indexable": true, "report_reasons": null, "author": "Crazy-Red-Fox", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zee9aq/archiving_official_documents_as_an_act_of_radical/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.cjr.org/business_of_news/archiving-official-documents-as-an-act-of-radical-journalism.php", "subreddit_subscribers": 657849, "created_utc": 1670351778.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "[https://www.reddit.com/r/DataHoarder/comments/zea4ge/what\\_is\\_better\\_for\\_storage\\_reliability\\_for/](https://www.reddit.com/r/DataHoarder/comments/zea4ge/what_is_better_for_storage_reliability_for/)\n\nI am building a small home server.  Budget it about $700.  Its main uses will be Plex, a general file server, a place to hold important data (wedding videos, youtube raw footage) and run a Valheim dedicated server.  \n\nI had originally planned on using one 8TB HDD as the storage drive for Plex movies.  I was then going to store important data on two mirrored 1TB SSDs.  But following my previous post I feel that these 1TB SSDs are a waste since if I delete a file, the mirrored will also be deleted.  I could return them to free up budget for another 8TB HDD (16TB total).  \n\nShould I just get two HDDs, put everything on them, then backup important stuff in cloud storage, and/or an external location?  Or stick with the original plan with the 1TB mirrored SSDs/8TB HDD?", "author_fullname": "t2_kz70b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Follow Up: Should I just get two HDDs, put everything on them, then backup important stuff in cloud storage, and/or an external location? Or use 1TB mirrored SSDs/8TB HDD for general storage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zem53b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670370327.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/zea4ge/what_is_better_for_storage_reliability_for/\"&gt;https://www.reddit.com/r/DataHoarder/comments/zea4ge/what_is_better_for_storage_reliability_for/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I am building a small home server.  Budget it about $700.  Its main uses will be Plex, a general file server, a place to hold important data (wedding videos, youtube raw footage) and run a Valheim dedicated server.  &lt;/p&gt;\n\n&lt;p&gt;I had originally planned on using one 8TB HDD as the storage drive for Plex movies.  I was then going to store important data on two mirrored 1TB SSDs.  But following my previous post I feel that these 1TB SSDs are a waste since if I delete a file, the mirrored will also be deleted.  I could return them to free up budget for another 8TB HDD (16TB total).  &lt;/p&gt;\n\n&lt;p&gt;Should I just get two HDDs, put everything on them, then backup important stuff in cloud storage, and/or an external location?  Or stick with the original plan with the 1TB mirrored SSDs/8TB HDD?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zem53b", "is_robot_indexable": true, "report_reasons": null, "author": "thefreymaster", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zem53b/follow_up_should_i_just_get_two_hdds_put/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zem53b/follow_up_should_i_just_get_two_hdds_put/", "subreddit_subscribers": 657849, "created_utc": 1670370327.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello Data Hoarders,\n\nI am looking to supplement my current home lab with storage to store media, backups, etc. My biggest use case is storage of 4k movies and have the ability to stream them to devices in the home. My question is would this be a better job for a NAS or should I add DAS to my current server and leverage a VM to provide these services?\n\nThanks!", "author_fullname": "t2_5y1dc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking to store 4k movies and stream", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zepsow", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670380683.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Data Hoarders,&lt;/p&gt;\n\n&lt;p&gt;I am looking to supplement my current home lab with storage to store media, backups, etc. My biggest use case is storage of 4k movies and have the ability to stream them to devices in the home. My question is would this be a better job for a NAS or should I add DAS to my current server and leverage a VM to provide these services?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "zepsow", "is_robot_indexable": true, "report_reasons": null, "author": "kopaka89", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zepsow/looking_to_store_4k_movies_and_stream/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zepsow/looking_to_store_4k_movies_and_stream/", "subreddit_subscribers": 657849, "created_utc": 1670380683.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_735tdxy6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I got a cheap Crucial SSD for OS about 1 or 2 years back, and it appears I churned through a lot of it's health in this short time. Any idea how long my SSD would be working for? It's only holding OS for a PC I use as a mass storage unit that stays powered on almost 24/7 (I run VMs there too)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_zezdld", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/NkecV0P30DKxPtjfa_fNbu4Sc35fsF8FEy8tBKcnyY8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670414319.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/cet21u0jsg4a1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/cet21u0jsg4a1.png?auto=webp&amp;s=b7c0f724f0db4bace82ead4806ecc9b671d56de8", "width": 838, "height": 862}, "resolutions": [{"url": "https://preview.redd.it/cet21u0jsg4a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3fabb8a9a2311e2c5a88b031579ab4175c6a2baa", "width": 108, "height": 111}, {"url": "https://preview.redd.it/cet21u0jsg4a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1f9eea63f43653d085e9a90c03c25d4faea20811", "width": 216, "height": 222}, {"url": "https://preview.redd.it/cet21u0jsg4a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=6a85ad8bfa4afe4f8ea06785e4fe12701c84414f", "width": 320, "height": 329}, {"url": "https://preview.redd.it/cet21u0jsg4a1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=626dba821126bea8bd06f3412523239295f9beae", "width": 640, "height": 658}], "variants": {}, "id": "qnbpJ6NKRrqLZnAck8uzj-xdtjWj4qarriS7dPugnzo"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zezdld", "is_robot_indexable": true, "report_reasons": null, "author": "samforelli", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zezdld/i_got_a_cheap_crucial_ssd_for_os_about_1_or_2/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/cet21u0jsg4a1.png", "subreddit_subscribers": 657849, "created_utc": 1670414319.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So say you ve bought a WD HDD from Amazon but afterwards it seems to have been opened and replaces by another drive \n\nCould this also happen if you buy it straight from WD? Say you just bought a drive new but someone shucked it in the past. Could you return it if you bought it? Or would WD confiscate it and say it has been tampered with.", "author_fullname": "t2_jzdc2b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible for WD to sell used products?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zepmvg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670380198.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So say you ve bought a WD HDD from Amazon but afterwards it seems to have been opened and replaces by another drive &lt;/p&gt;\n\n&lt;p&gt;Could this also happen if you buy it straight from WD? Say you just bought a drive new but someone shucked it in the past. Could you return it if you bought it? Or would WD confiscate it and say it has been tampered with.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zepmvg", "is_robot_indexable": true, "report_reasons": null, "author": "CMDVN", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zepmvg/is_it_possible_for_wd_to_sell_used_products/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zepmvg/is_it_possible_for_wd_to_sell_used_products/", "subreddit_subscribers": 657849, "created_utc": 1670380198.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi there,\n\nI have about 12TB of data on my local NAS. Just purchased an 18TB drive to have that data backed up locally. For my third copy, after researching cloud providers (cost, speed, and reliability), I've come to the conclusion that it's best to set up another NAS/server that I will plug in at a friend's place.\n\nI have two things I would like feedback on:\n\n1. Encryption: what do you recommend to encrypt my data off-site? Assuming the server is always connected to the internet when on, is there a way to make it so that when the computer starts up, the encrypted data is not accessible, where I get an email or notification to do somehow remotely unlock the data? What I'm trying to guard against is someone taking the server and accessing my private data. Assuming it gets stolen, I'd like to know that the data is encrypted and not accessible.\n\n2. Syncing: given this data size (12TB now, 20TB in 5 years), is it best to keep the data in sync using Syncthing? Or would the size cause issues for Syncthing? If so, I would just have a daily Cron job to rsync the data.\n\nWelcome any insights you all are willing to share. Thanks.", "author_fullname": "t2_3zlpu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Off-site backup at friend: encryption and syncing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zehu4q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670360178.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there,&lt;/p&gt;\n\n&lt;p&gt;I have about 12TB of data on my local NAS. Just purchased an 18TB drive to have that data backed up locally. For my third copy, after researching cloud providers (cost, speed, and reliability), I&amp;#39;ve come to the conclusion that it&amp;#39;s best to set up another NAS/server that I will plug in at a friend&amp;#39;s place.&lt;/p&gt;\n\n&lt;p&gt;I have two things I would like feedback on:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Encryption: what do you recommend to encrypt my data off-site? Assuming the server is always connected to the internet when on, is there a way to make it so that when the computer starts up, the encrypted data is not accessible, where I get an email or notification to do somehow remotely unlock the data? What I&amp;#39;m trying to guard against is someone taking the server and accessing my private data. Assuming it gets stolen, I&amp;#39;d like to know that the data is encrypted and not accessible.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Syncing: given this data size (12TB now, 20TB in 5 years), is it best to keep the data in sync using Syncthing? Or would the size cause issues for Syncthing? If so, I would just have a daily Cron job to rsync the data.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Welcome any insights you all are willing to share. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zehu4q", "is_robot_indexable": true, "report_reasons": null, "author": "vinhdizzo", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zehu4q/offsite_backup_at_friend_encryption_and_syncing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zehu4q/offsite_backup_at_friend_encryption_and_syncing/", "subreddit_subscribers": 657849, "created_utc": 1670360178.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So here is my situation. I have an 8 bay Syba enclosure (non-raid) connected to my windows 10 machine and I'm keeping an even number of hard drives so that each hard drive has another one it can be copied to. Right now I have four Seagate Exos x18 18tb hdd. I have heard that error checking works differently on enterprise grade drives since they are meant for raid storage. Regardless, I want some kind of error checking program that does something a little specific.\n\nSo let's call drive 1 and 2 drive A, and 3 and 4 drive B. I want this program to generate a hash (or crc/checksum/sha256/whatever is best) of every file, and store a folder of those hashes anywhere like a separate storage unit (so I can keep copies anywhere I want). Then as I copy files over from A to B, I can have the program use those hashes to confirm what I copied is good, and on occasion reconfirm that everything looks good on both drives when I deem it's time to error check again. If a file goes bad on either A or B, when I run a scan the program will use those hashes to decide which drive has the good file, and copy it over to the bad one.  If it's possible, I wish to account for cases where drive A has more data than drive B, but the program will only check the files that are only on both A and B. And obviously if a file is bad on both drives it'll just let me pick which one to keep and generate a new hash for me.\n\nI think GoodSync is either close to or exactly what I need, but looks subscription based and the limits on the free version make it useless to me. I think Teracopy has some of the features I need but I believe not all? I don't need it to be free, but if it isn't I prefer one time payment.\n\nThings to note, the four drives are empty still, drive A will be used daily, drive B will only be manually turned on monthly.", "author_fullname": "t2_iphb2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with data integrity across mirrored drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zeyrpx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1670413491.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670412257.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So here is my situation. I have an 8 bay Syba enclosure (non-raid) connected to my windows 10 machine and I&amp;#39;m keeping an even number of hard drives so that each hard drive has another one it can be copied to. Right now I have four Seagate Exos x18 18tb hdd. I have heard that error checking works differently on enterprise grade drives since they are meant for raid storage. Regardless, I want some kind of error checking program that does something a little specific.&lt;/p&gt;\n\n&lt;p&gt;So let&amp;#39;s call drive 1 and 2 drive A, and 3 and 4 drive B. I want this program to generate a hash (or crc/checksum/sha256/whatever is best) of every file, and store a folder of those hashes anywhere like a separate storage unit (so I can keep copies anywhere I want). Then as I copy files over from A to B, I can have the program use those hashes to confirm what I copied is good, and on occasion reconfirm that everything looks good on both drives when I deem it&amp;#39;s time to error check again. If a file goes bad on either A or B, when I run a scan the program will use those hashes to decide which drive has the good file, and copy it over to the bad one.  If it&amp;#39;s possible, I wish to account for cases where drive A has more data than drive B, but the program will only check the files that are only on both A and B. And obviously if a file is bad on both drives it&amp;#39;ll just let me pick which one to keep and generate a new hash for me.&lt;/p&gt;\n\n&lt;p&gt;I think GoodSync is either close to or exactly what I need, but looks subscription based and the limits on the free version make it useless to me. I think Teracopy has some of the features I need but I believe not all? I don&amp;#39;t need it to be free, but if it isn&amp;#39;t I prefer one time payment.&lt;/p&gt;\n\n&lt;p&gt;Things to note, the four drives are empty still, drive A will be used daily, drive B will only be manually turned on monthly.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zeyrpx", "is_robot_indexable": true, "report_reasons": null, "author": "xScopeLess", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zeyrpx/help_with_data_integrity_across_mirrored_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zeyrpx/help_with_data_integrity_across_mirrored_drives/", "subreddit_subscribers": 657849, "created_utc": 1670412257.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all. I have Windows 10 and for the longest time I've wanted to know if there's anything I can do differently or better to maintain my drives. I have mixed SATA SSDs, NVMes and HDDs, 12 total.\n\nI know Windows does TRIM on SSDs, but I don't know...there's something satisfying about running a command or a maintenance cycle that I can see working and see the results of, if you know what I mean.\n\nDo you run maintenance on your drives regularly? Any recommendations of what I can do to keep them running well? Lastly, do you set Windows to turn off your drives after X amount of minutes in power options, and do you use hibernate? Does hibernate harm SSDs with the writes?", "author_fullname": "t2_t1yb6joj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SSD/HDD maintenance questions.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zf65fx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670431594.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all. I have Windows 10 and for the longest time I&amp;#39;ve wanted to know if there&amp;#39;s anything I can do differently or better to maintain my drives. I have mixed SATA SSDs, NVMes and HDDs, 12 total.&lt;/p&gt;\n\n&lt;p&gt;I know Windows does TRIM on SSDs, but I don&amp;#39;t know...there&amp;#39;s something satisfying about running a command or a maintenance cycle that I can see working and see the results of, if you know what I mean.&lt;/p&gt;\n\n&lt;p&gt;Do you run maintenance on your drives regularly? Any recommendations of what I can do to keep them running well? Lastly, do you set Windows to turn off your drives after X amount of minutes in power options, and do you use hibernate? Does hibernate harm SSDs with the writes?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zf65fx", "is_robot_indexable": true, "report_reasons": null, "author": "kingofallnorway", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zf65fx/ssdhdd_maintenance_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zf65fx/ssdhdd_maintenance_questions/", "subreddit_subscribers": 657849, "created_utc": 1670431594.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Are there any clear instructions on how to create filters in DownThemAll? (Firefox ver)\n\nI need to create a filter that selects all urls with this structure: serverXX.sampleurl.net/  With XX being a completely random number between 0 an 999.\n\nWhat method is DownThemAll using for filters?, are there any good instructions for it?, and is this possible?\n\nThanks in advance!", "author_fullname": "t2_52qu40au", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do i create filters in DownThemAll ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zf586c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670429702.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are there any clear instructions on how to create filters in DownThemAll? (Firefox ver)&lt;/p&gt;\n\n&lt;p&gt;I need to create a filter that selects all urls with this structure: serverXX.sampleurl.net/  With XX being a completely random number between 0 an 999.&lt;/p&gt;\n\n&lt;p&gt;What method is DownThemAll using for filters?, are there any good instructions for it?, and is this possible?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zf586c", "is_robot_indexable": true, "report_reasons": null, "author": "mactep66", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zf586c/how_do_i_create_filters_in_downthemall/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zf586c/how_do_i_create_filters_in_downthemall/", "subreddit_subscribers": 657849, "created_utc": 1670429702.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi guys.\n\nI got few To of music and photos I'd like to backup to my cloud service of choice (icedrive) which supports webdav.\n\nIs there a good software alternative to schedule my backups from my PC to my cloud ?\n\nI've been searching on the net, and the few solutions I found don't inspire me with confidence...", "author_fullname": "t2_jsq9e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scheduled Webdav Backup on Windows", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zf4xtn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670429120.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys.&lt;/p&gt;\n\n&lt;p&gt;I got few To of music and photos I&amp;#39;d like to backup to my cloud service of choice (icedrive) which supports webdav.&lt;/p&gt;\n\n&lt;p&gt;Is there a good software alternative to schedule my backups from my PC to my cloud ?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been searching on the net, and the few solutions I found don&amp;#39;t inspire me with confidence...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zf4xtn", "is_robot_indexable": true, "report_reasons": null, "author": "Tiritibambix", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zf4xtn/scheduled_webdav_backup_on_windows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zf4xtn/scheduled_webdav_backup_on_windows/", "subreddit_subscribers": 657849, "created_utc": 1670429120.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I used to use Tdarr, but I'm currently trying Unmanic because it seems a bit simpler and easier to configure. However, whilst there are lots of installation write-ups, there isn't any plugin/job/process/test setup tutorials for 'standard' configurations that people might want to use. Anyone got any sources for these?\n\nI'm basically wanting to set it up to:\n\n1. Use the intel quicksync plugin\n2. Only process files &gt; 5GB\n3. Transcode to reduce them down using h264, but at a lower bitrate etc so aiming to get about 1GB/hour\n4. Only run processing/transcoding between certain hours (e.g., 1am =&gt; 5am)\n\nI've added the plugin, a worker, and the filesize test (which I think does #2) but just want to see if somebody else has written up their settings so I can make sure I've got it right before I point it at my library. :)\n\nRunning it on a Synology via Docker, although I don't think that's relevant for this question.", "author_fullname": "t2_3tq8w00m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unmanic Starter Setup?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zf3yd7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670427060.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I used to use Tdarr, but I&amp;#39;m currently trying Unmanic because it seems a bit simpler and easier to configure. However, whilst there are lots of installation write-ups, there isn&amp;#39;t any plugin/job/process/test setup tutorials for &amp;#39;standard&amp;#39; configurations that people might want to use. Anyone got any sources for these?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m basically wanting to set it up to:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Use the intel quicksync plugin&lt;/li&gt;\n&lt;li&gt;Only process files &amp;gt; 5GB&lt;/li&gt;\n&lt;li&gt;Transcode to reduce them down using h264, but at a lower bitrate etc so aiming to get about 1GB/hour&lt;/li&gt;\n&lt;li&gt;Only run processing/transcoding between certain hours (e.g., 1am =&amp;gt; 5am)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;ve added the plugin, a worker, and the filesize test (which I think does #2) but just want to see if somebody else has written up their settings so I can make sure I&amp;#39;ve got it right before I point it at my library. :)&lt;/p&gt;\n\n&lt;p&gt;Running it on a Synology via Docker, although I don&amp;#39;t think that&amp;#39;s relevant for this question.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "33TB Syno + B2", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zf3yd7", "is_robot_indexable": true, "report_reasons": null, "author": "botterway", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/zf3yd7/unmanic_starter_setup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zf3yd7/unmanic_starter_setup/", "subreddit_subscribers": 657849, "created_utc": 1670427060.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "i have 4 external usb drive with the following letters in Win10: O P Q R.  DupeGuru was great for scanning duplicates for movies. usually it would find around 10 duplicates. i verify the dupes myself, mark for deletion, and move dupes to trash.\n\n2 days ago, i mounted these drives as folders instead in Disk Management. so these drives dont show up in \"This PC.\"  instead they can be found in something like \"C:\\\\drive O\"\n\n&amp;#x200B;\n\nhttps://preview.redd.it/dtlveilqeh4a1.png?width=292&amp;format=png&amp;auto=webp&amp;s=a61a8d8d0ed783f32431fc0f1aaf09bfe033cfae\n\nused DupeGuru on these folders and it found 4000+ duplicates!!! also, took over 4 days instead of the usual 10hours for scanning dupes. i dont know why i didnt manually verify the dupes, i just marked and moved them straight to the trash and empty.  now, i found out i lost these files completely, ZERO copies found on my drives.  luckily i still have them on BackBlaze backups but it's annoying and now looking for an alternative to DupeGuru.  love to hear what you guys are using.", "author_fullname": "t2_duy2j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "a better alternative to DupeGuru?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 15, "top_awarded_type": null, "hide_score": false, "media_metadata": {"dtlveilqeh4a1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 12, "x": 108, "u": "https://preview.redd.it/dtlveilqeh4a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=cfddfa67cc1845b3bbd0db9e49e42c8c6e2eae8e"}, {"y": 24, "x": 216, "u": "https://preview.redd.it/dtlveilqeh4a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=22092546b29949cf76a414be8be7d8318b2307ea"}], "s": {"y": 33, "x": 292, "u": "https://preview.redd.it/dtlveilqeh4a1.png?width=292&amp;format=png&amp;auto=webp&amp;s=a61a8d8d0ed783f32431fc0f1aaf09bfe033cfae"}, "id": "dtlveilqeh4a1"}}, "name": "t3_zf1us1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/YpGVOaJsrZJsuAY2jCFEQvZvdcodD_uDNx9mOTXP7V4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670421734.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i have 4 external usb drive with the following letters in Win10: O P Q R.  DupeGuru was great for scanning duplicates for movies. usually it would find around 10 duplicates. i verify the dupes myself, mark for deletion, and move dupes to trash.&lt;/p&gt;\n\n&lt;p&gt;2 days ago, i mounted these drives as folders instead in Disk Management. so these drives dont show up in &amp;quot;This PC.&amp;quot;  instead they can be found in something like &amp;quot;C:\\drive O&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/dtlveilqeh4a1.png?width=292&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a61a8d8d0ed783f32431fc0f1aaf09bfe033cfae\"&gt;https://preview.redd.it/dtlveilqeh4a1.png?width=292&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a61a8d8d0ed783f32431fc0f1aaf09bfe033cfae&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;used DupeGuru on these folders and it found 4000+ duplicates!!! also, took over 4 days instead of the usual 10hours for scanning dupes. i dont know why i didnt manually verify the dupes, i just marked and moved them straight to the trash and empty.  now, i found out i lost these files completely, ZERO copies found on my drives.  luckily i still have them on BackBlaze backups but it&amp;#39;s annoying and now looking for an alternative to DupeGuru.  love to hear what you guys are using.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zf1us1", "is_robot_indexable": true, "report_reasons": null, "author": "tungvu256", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zf1us1/a_better_alternative_to_dupeguru/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zf1us1/a_better_alternative_to_dupeguru/", "subreddit_subscribers": 657849, "created_utc": 1670421734.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I use to run an extremely large unRAID server back in my younger days but I downsized and got rid of it. Currently I'm looking to buy something a bit more practical than a whole second computer running 24/7 in my house. This will be for a backup, so it doesn't need to be any faster than 100MB/s or so, but it'd be nice. I am thinking an external NAS of some sort but not sure. I don't really trust throwing 2-3 internals HDDs in raid 1/5 and using my motherboard.\n\nBudget is about $1k. I was thinking of just grabbing 2x 20TB WD Reds or 2x 20TB IronWolf Pros and just throwing them in Raid 1 in a NAS (Maybe a DS220+)? Comes out to about $1100.\n\nAny ideas?", "author_fullname": "t2_gvj0nvfr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'd like ~20TB of usable data with at least a single drive failure protection", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zf18tm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1670420726.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670419997.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I use to run an extremely large unRAID server back in my younger days but I downsized and got rid of it. Currently I&amp;#39;m looking to buy something a bit more practical than a whole second computer running 24/7 in my house. This will be for a backup, so it doesn&amp;#39;t need to be any faster than 100MB/s or so, but it&amp;#39;d be nice. I am thinking an external NAS of some sort but not sure. I don&amp;#39;t really trust throwing 2-3 internals HDDs in raid 1/5 and using my motherboard.&lt;/p&gt;\n\n&lt;p&gt;Budget is about $1k. I was thinking of just grabbing 2x 20TB WD Reds or 2x 20TB IronWolf Pros and just throwing them in Raid 1 in a NAS (Maybe a DS220+)? Comes out to about $1100.&lt;/p&gt;\n\n&lt;p&gt;Any ideas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zf18tm", "is_robot_indexable": true, "report_reasons": null, "author": "Lyioux", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zf18tm/id_like_20tb_of_usable_data_with_at_least_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zf18tm/id_like_20tb_of_usable_data_with_at_least_a/", "subreddit_subscribers": 657849, "created_utc": 1670419997.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey Reddit,\n\nI'm wondering what the best compression format is for creating whole drive backups.\n\nI have already made a 1.5TB TAR archive of one of my portable hard drives and copied it into my computer\n\nWhich compression format (7z, gzip, xz, etc...) would be the best for compressing this TAR file in the shortest amount of time? Compression ratio isn't really important, preferably below 90% though.\n\n Thank you", "author_fullname": "t2_3ngwm9jc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best archival/compression format for whole hard drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zeqk8f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670382971.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Reddit,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering what the best compression format is for creating whole drive backups.&lt;/p&gt;\n\n&lt;p&gt;I have already made a 1.5TB TAR archive of one of my portable hard drives and copied it into my computer&lt;/p&gt;\n\n&lt;p&gt;Which compression format (7z, gzip, xz, etc...) would be the best for compressing this TAR file in the shortest amount of time? Compression ratio isn&amp;#39;t really important, preferably below 90% though.&lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "20TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zeqk8f", "is_robot_indexable": true, "report_reasons": null, "author": "LolDude9876789", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/zeqk8f/best_archivalcompression_format_for_whole_hard/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zeqk8f/best_archivalcompression_format_for_whole_hard/", "subreddit_subscribers": 657849, "created_utc": 1670382971.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Long time follower of this subreddit and first time poster. I\u2019m fairly new to DAS.\n\nI was wondering if anyone else has experience similar issues with their Terramaster D5-300 DAS and shucked  WD 20TB WD2000EDGZ drives.\n\nI\u2019m not using this in RAID, just default single disk mode. \n\nI recently bought both and have began the install process and powering it on. I\u2019ve noticed the 2x 20TB causes the lights to turn solid orange and repeated beeping. (All drives have been formatted already for Mac OS Extended Journaled ahead of installation.) This happens in any slot I put either 20TB drives in and both when they\u2019re both in. I\u2019ve pulled the drives out and connected the 20TB drives using a USB to SATA cable and they are recognized and works fine.\n\nHowever, my 2x 14TB WD140EDGZ drives and 1x 10TB WD100EMAZ can be placed in any slot and are recognized and works as intended. When all 5 drives are in, only the 20TBs exhibit the orange light and beeping from the DAS.\n\nThere isn\u2019t much documentation about this online or on their forums and thought to ask the community if they had similar experiences as I wait for a response from their support. Any insights or advice would be appreciated, thanks in advance.", "author_fullname": "t2_28at3bt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone experienced issues with Terramaster D5-300 and shucked WD 20TB WD2000EDGZ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zec3vd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670346625.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Long time follower of this subreddit and first time poster. I\u2019m fairly new to DAS.&lt;/p&gt;\n\n&lt;p&gt;I was wondering if anyone else has experience similar issues with their Terramaster D5-300 DAS and shucked  WD 20TB WD2000EDGZ drives.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m not using this in RAID, just default single disk mode. &lt;/p&gt;\n\n&lt;p&gt;I recently bought both and have began the install process and powering it on. I\u2019ve noticed the 2x 20TB causes the lights to turn solid orange and repeated beeping. (All drives have been formatted already for Mac OS Extended Journaled ahead of installation.) This happens in any slot I put either 20TB drives in and both when they\u2019re both in. I\u2019ve pulled the drives out and connected the 20TB drives using a USB to SATA cable and they are recognized and works fine.&lt;/p&gt;\n\n&lt;p&gt;However, my 2x 14TB WD140EDGZ drives and 1x 10TB WD100EMAZ can be placed in any slot and are recognized and works as intended. When all 5 drives are in, only the 20TBs exhibit the orange light and beeping from the DAS.&lt;/p&gt;\n\n&lt;p&gt;There isn\u2019t much documentation about this online or on their forums and thought to ask the community if they had similar experiences as I wait for a response from their support. Any insights or advice would be appreciated, thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zec3vd", "is_robot_indexable": true, "report_reasons": null, "author": "RayRCircle", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zec3vd/has_anyone_experienced_issues_with_terramaster/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zec3vd/has_anyone_experienced_issues_with_terramaster/", "subreddit_subscribers": 657849, "created_utc": 1670346625.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Okay, so, I have a \"friend\" who recently discovered JAV videos, and turns out this files are like 4-7gb per video, i cant afford 60 gbs in my hdd for porn, nor do I want. I would like to reduce the files to maybe 500mb-1gb per video. What's the best tool for this? This videos are like 2hr long each, so It's a hassle but they are also rare to find.", "author_fullname": "t2_ifr1c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What tool would you recommend to compress long quantities of videos?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zf0j70", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670417922.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Okay, so, I have a &amp;quot;friend&amp;quot; who recently discovered JAV videos, and turns out this files are like 4-7gb per video, i cant afford 60 gbs in my hdd for porn, nor do I want. I would like to reduce the files to maybe 500mb-1gb per video. What&amp;#39;s the best tool for this? This videos are like 2hr long each, so It&amp;#39;s a hassle but they are also rare to find.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zf0j70", "is_robot_indexable": true, "report_reasons": null, "author": "Gammagori", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zf0j70/what_tool_would_you_recommend_to_compress_long/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zf0j70/what_tool_would_you_recommend_to_compress_long/", "subreddit_subscribers": 657849, "created_utc": 1670417922.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I bought Google Drive 2 TB.\n\nI use windows 10 and have 1 tb local ssd. I installed google drive desktop, and it makes virtual drive. But it has limit my local harddisk(so 1 tb). So it's disturbing. I think, if i will exceed, it will be problem. \n\nI know that rclone is alternative. But i dont want it, i satisfied with own google drive desktop app. Because upload rate is good. \n\nHow can i bypass this annoying situation? Can i increase fakely local harddisk storage? If yes, how? So, virtual google's drive will increase?", "author_fullname": "t2_7qf2od4g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bypass \"google drive's virtual drive size equals harddisk capacity?\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zez1oq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670413202.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I bought Google Drive 2 TB.&lt;/p&gt;\n\n&lt;p&gt;I use windows 10 and have 1 tb local ssd. I installed google drive desktop, and it makes virtual drive. But it has limit my local harddisk(so 1 tb). So it&amp;#39;s disturbing. I think, if i will exceed, it will be problem. &lt;/p&gt;\n\n&lt;p&gt;I know that rclone is alternative. But i dont want it, i satisfied with own google drive desktop app. Because upload rate is good. &lt;/p&gt;\n\n&lt;p&gt;How can i bypass this annoying situation? Can i increase fakely local harddisk storage? If yes, how? So, virtual google&amp;#39;s drive will increase?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zez1oq", "is_robot_indexable": true, "report_reasons": null, "author": "birisix", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zez1oq/bypass_google_drives_virtual_drive_size_equals/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zez1oq/bypass_google_drives_virtual_drive_size_equals/", "subreddit_subscribers": 657849, "created_utc": 1670413202.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a WD 2TB 5400RPM HDD which I bought a few weeks back. Files were being transferred around 100Mbps. But yesterday, it dropped to 50Mbps.\n\nI checked CrystalDiskMark and posted the results here. It is plugged into a USB3.0 Port. If there is anything to help bring it back to speed, let me know. Thanks.\n\n&amp;#x200B;\n\n[This was on 11\\/27](https://preview.redd.it/q336dd4v1g4a1.png?width=482&amp;format=png&amp;auto=webp&amp;s=6172f8e2cf1c169aa1ade4d0ba9a8f88a5a2dc9a)\n\n&amp;#x200B;\n\n[This is today](https://preview.redd.it/x2owfaow1g4a1.png?width=482&amp;format=png&amp;auto=webp&amp;s=285c84e8fabf7a8b49f326073ac714a9aa5e366f)", "author_fullname": "t2_2fallq1b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WD My Passport External HDD has slower read/write speeds", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 102, "top_awarded_type": null, "hide_score": false, "media_metadata": {"x2owfaow1g4a1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 78, "x": 108, "u": "https://preview.redd.it/x2owfaow1g4a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=20ab247d5a0f87ae063acbc54f75c31a0979e4d5"}, {"y": 157, "x": 216, "u": "https://preview.redd.it/x2owfaow1g4a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1283f8e3333762d6a7dfae5804f7d512ff5f3bb6"}, {"y": 233, "x": 320, "u": "https://preview.redd.it/x2owfaow1g4a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=9f557347dfa14634fc1316a0a413de2dfa26e025"}], "s": {"y": 352, "x": 482, "u": "https://preview.redd.it/x2owfaow1g4a1.png?width=482&amp;format=png&amp;auto=webp&amp;s=285c84e8fabf7a8b49f326073ac714a9aa5e366f"}, "id": "x2owfaow1g4a1"}, "q336dd4v1g4a1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 78, "x": 108, "u": "https://preview.redd.it/q336dd4v1g4a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f1857883be9e82acba8c33851c6acd30eb1657f0"}, {"y": 157, "x": 216, "u": "https://preview.redd.it/q336dd4v1g4a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b9f879a4caa8a712db867eab902d5e2846c0f3f2"}, {"y": 233, "x": 320, "u": "https://preview.redd.it/q336dd4v1g4a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=6c0267d57a3871c900859bbc1c18126a0d9c45c1"}], "s": {"y": 352, "x": 482, "u": "https://preview.redd.it/q336dd4v1g4a1.png?width=482&amp;format=png&amp;auto=webp&amp;s=6172f8e2cf1c169aa1ade4d0ba9a8f88a5a2dc9a"}, "id": "q336dd4v1g4a1"}}, "name": "t3_zewpjn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Gy-WKAaGcihd4LStKA6LK3ZAkAEiNs30tyjZnoe134Q.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670404874.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a WD 2TB 5400RPM HDD which I bought a few weeks back. Files were being transferred around 100Mbps. But yesterday, it dropped to 50Mbps.&lt;/p&gt;\n\n&lt;p&gt;I checked CrystalDiskMark and posted the results here. It is plugged into a USB3.0 Port. If there is anything to help bring it back to speed, let me know. Thanks.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/q336dd4v1g4a1.png?width=482&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=6172f8e2cf1c169aa1ade4d0ba9a8f88a5a2dc9a\"&gt;This was on 11/27&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/x2owfaow1g4a1.png?width=482&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=285c84e8fabf7a8b49f326073ac714a9aa5e366f\"&gt;This is today&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zewpjn", "is_robot_indexable": true, "report_reasons": null, "author": "arieszx", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zewpjn/wd_my_passport_external_hdd_has_slower_readwrite/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zewpjn/wd_my_passport_external_hdd_has_slower_readwrite/", "subreddit_subscribers": 657849, "created_utc": 1670404874.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Running 3 drives in my nas (truenas build). All new drives: 8TB Ironwolf x2 and 8TB Toshiba.\n\nAverage temps according to Truenas Scale os: 48, 48, 45 (C).\n\nConcerned this is way too high (its winter here!) so ambient is around 20c. Should I be concerned or is this aceptable? I'd like to look after my new drives for some years to come!", "author_fullname": "t2_d2ja9fnm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mean drive temp qu - too high?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zew9rp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670403115.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Running 3 drives in my nas (truenas build). All new drives: 8TB Ironwolf x2 and 8TB Toshiba.&lt;/p&gt;\n\n&lt;p&gt;Average temps according to Truenas Scale os: 48, 48, 45 (C).&lt;/p&gt;\n\n&lt;p&gt;Concerned this is way too high (its winter here!) so ambient is around 20c. Should I be concerned or is this aceptable? I&amp;#39;d like to look after my new drives for some years to come!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zew9rp", "is_robot_indexable": true, "report_reasons": null, "author": "Maximum-Warning-4186", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zew9rp/mean_drive_temp_qu_too_high/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zew9rp/mean_drive_temp_qu_too_high/", "subreddit_subscribers": 657849, "created_utc": 1670403115.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "What program can I use to determine the total amount of hours an SSD or HDD has been used and what sort of numbers should I look out for in order to try to prevent potential sudden deaths ?\n\nTrying to learn, thank you.", "author_fullname": "t2_3luaynwv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SSD/HDD hours of operation and guidelines questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zevnqe", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670400583.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What program can I use to determine the total amount of hours an SSD or HDD has been used and what sort of numbers should I look out for in order to try to prevent potential sudden deaths ?&lt;/p&gt;\n\n&lt;p&gt;Trying to learn, thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zevnqe", "is_robot_indexable": true, "report_reasons": null, "author": "LightDarkCloud", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zevnqe/ssdhdd_hours_of_operation_and_guidelines_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zevnqe/ssdhdd_hours_of_operation_and_guidelines_questions/", "subreddit_subscribers": 657849, "created_utc": 1670400583.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I want to store videos in the hdd in a quality standard. So I\u2019m trying to understand the specs which MediaInfo shows.\n\n&amp;#x200B;\n\nMediaInfo shows for a particular video;\n\n**Overall Bitrate :** 42.5\n\n**Maximum Bitrate :** 32\n\nHow is overall (average) bitrate 42.5 while maximum bitrate is 32? (Maximum bitrate has to be higher than overall bitrate)\n\n???", "author_fullname": "t2_4rs6ei0p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MediaInfo - Maximum BitRate Vs Overall Bitrate", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zeuydk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670397746.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to store videos in the hdd in a quality standard. So I\u2019m trying to understand the specs which MediaInfo shows.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;MediaInfo shows for a particular video;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Overall Bitrate :&lt;/strong&gt; 42.5&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Maximum Bitrate :&lt;/strong&gt; 32&lt;/p&gt;\n\n&lt;p&gt;How is overall (average) bitrate 42.5 while maximum bitrate is 32? (Maximum bitrate has to be higher than overall bitrate)&lt;/p&gt;\n\n&lt;p&gt;???&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zeuydk", "is_robot_indexable": true, "report_reasons": null, "author": "mainecoon364", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zeuydk/mediainfo_maximum_bitrate_vs_overall_bitrate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zeuydk/mediainfo_maximum_bitrate_vs_overall_bitrate/", "subreddit_subscribers": 657849, "created_utc": 1670397746.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Let\u2019s just say you\u2019ve ran out of SATA ports on mobo, sure there\u2019s PCI expansions for more sata potds but what if you ran out of power cords too? You know these black yellow red ribbons", "author_fullname": "t2_umytgvvj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you do when your PC ran out internal HDD cables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zetdto", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670391996.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let\u2019s just say you\u2019ve ran out of SATA ports on mobo, sure there\u2019s PCI expansions for more sata potds but what if you ran out of power cords too? You know these black yellow red ribbons&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "zetdto", "is_robot_indexable": true, "report_reasons": null, "author": "ElonTastical", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zetdto/what_do_you_do_when_your_pc_ran_out_internal_hdd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zetdto/what_do_you_do_when_your_pc_ran_out_internal_hdd/", "subreddit_subscribers": 657849, "created_utc": 1670391996.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Just wanted you smart folks' opinion. I don't hoard anything super important. The few important things I do store, I have multiple backups of. With that out of the way, how would you set up 8 total drives on TrueNAS? I'm thinking 4x4TB in vdev, and 4x10TB in another vdev, both in the same pool- with raidZ1 setup. I watch the stuff I hoard sometimes, by streaming through jellyfin. I'm relatively new to the scene so very grateful for your input.", "author_fullname": "t2_3dlnjxvx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you set up 4x4TB + 4x10TB on TrueNAS Core?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zelg4f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670368669.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just wanted you smart folks&amp;#39; opinion. I don&amp;#39;t hoard anything super important. The few important things I do store, I have multiple backups of. With that out of the way, how would you set up 8 total drives on TrueNAS? I&amp;#39;m thinking 4x4TB in vdev, and 4x10TB in another vdev, both in the same pool- with raidZ1 setup. I watch the stuff I hoard sometimes, by streaming through jellyfin. I&amp;#39;m relatively new to the scene so very grateful for your input.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zelg4f", "is_robot_indexable": true, "report_reasons": null, "author": "ProximtyCoverageOnly", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zelg4f/how_would_you_set_up_4x4tb_4x10tb_on_truenas_core/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zelg4f/how_would_you_set_up_4x4tb_4x10tb_on_truenas_core/", "subreddit_subscribers": 657849, "created_utc": 1670368669.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}