{"kind": "Listing", "data": {"after": null, "dist": 22, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My manager has tasked me with setting up Airflow on AWS. Depending on the cost I guess my options range from ECS, MWAA or simply deploying it on EC2. In any case my question relates to writing DAGs: Airflow is merely a scheduler and is not supposed to perform the actual ETL work. I want to deploy Airflow and write DAGs in a way that will be scalable and isn't going to incur unnecessary costs, so with that in mind, are there any tips/best practices to keep in mind when writing DAGs? Any operators I should avoid in keeping with the principle that Airflow shouldn't be performing the business logic?\n\nAs an aside, where do you typically store connection credentials in prod? Is the Airflow UI sufficient or is it better to use environment variables?\n\nAppreciate the help.", "author_fullname": "t2_sv9s22ti", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you use Airflow 'properly'?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zn35zt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 73, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 73, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671156133.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My manager has tasked me with setting up Airflow on AWS. Depending on the cost I guess my options range from ECS, MWAA or simply deploying it on EC2. In any case my question relates to writing DAGs: Airflow is merely a scheduler and is not supposed to perform the actual ETL work. I want to deploy Airflow and write DAGs in a way that will be scalable and isn&amp;#39;t going to incur unnecessary costs, so with that in mind, are there any tips/best practices to keep in mind when writing DAGs? Any operators I should avoid in keeping with the principle that Airflow shouldn&amp;#39;t be performing the business logic?&lt;/p&gt;\n\n&lt;p&gt;As an aside, where do you typically store connection credentials in prod? Is the Airflow UI sufficient or is it better to use environment variables?&lt;/p&gt;\n\n&lt;p&gt;Appreciate the help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zn35zt", "is_robot_indexable": true, "report_reasons": null, "author": "Timely-Section-9951", "discussion_type": null, "num_comments": 40, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zn35zt/how_do_you_use_airflow_properly/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zn35zt/how_do_you_use_airflow_properly/", "subreddit_subscribers": 83094, "created_utc": 1671156133.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have read the book, want to do a Airflow + Kimball Data Modelling on a dataset. Showcase as side project and improve later on. \n\nWhere do I find data where I could create star schema or snowflake schema. Seems all data are already cleaned and normalized.", "author_fullname": "t2_6d53o2nl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do we practice Data Warehouse modelling like Kimball way.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zndo4e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671194137.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have read the book, want to do a Airflow + Kimball Data Modelling on a dataset. Showcase as side project and improve later on. &lt;/p&gt;\n\n&lt;p&gt;Where do I find data where I could create star schema or snowflake schema. Seems all data are already cleaned and normalized.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zndo4e", "is_robot_indexable": true, "report_reasons": null, "author": "EarthlySapien", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zndo4e/how_do_we_practice_data_warehouse_modelling_like/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zndo4e/how_do_we_practice_data_warehouse_modelling_like/", "subreddit_subscribers": 83094, "created_utc": 1671194137.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My team owns a single repo for all of our Spark jobs, and each pipeline is fairly large. Some are 1000+ lines of code and most of the input datasets are 20-50 columns wide. This makes select statements really ugly and bloats the code even more.\n\n\nSome of the input datasets are shared between multiple pipelines, and some of the pipelines consume the output of other pipelines (in our repo). This means we would ideally like to share some code between them (e.g. reading a common dataset &amp; the schema).\n\n\nHow would you structure this? Are there any example projects that do something similar? It seems like all the example projects I've found are usually just a single pipleline, ~100 lines of code total, and with smaller input datasets. What about when it gets bigger and you want to break some pipelines into multiple files and reuse schemas &amp; reader classes between pipelines?", "author_fullname": "t2_229opcl2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you structure a repo with 10+ ETL pipelines and shared code?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zn8m07", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671174222.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My team owns a single repo for all of our Spark jobs, and each pipeline is fairly large. Some are 1000+ lines of code and most of the input datasets are 20-50 columns wide. This makes select statements really ugly and bloats the code even more.&lt;/p&gt;\n\n&lt;p&gt;Some of the input datasets are shared between multiple pipelines, and some of the pipelines consume the output of other pipelines (in our repo). This means we would ideally like to share some code between them (e.g. reading a common dataset &amp;amp; the schema).&lt;/p&gt;\n\n&lt;p&gt;How would you structure this? Are there any example projects that do something similar? It seems like all the example projects I&amp;#39;ve found are usually just a single pipleline, ~100 lines of code total, and with smaller input datasets. What about when it gets bigger and you want to break some pipelines into multiple files and reuse schemas &amp;amp; reader classes between pipelines?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zn8m07", "is_robot_indexable": true, "report_reasons": null, "author": "y8MAC", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zn8m07/how_would_you_structure_a_repo_with_10_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zn8m07/how_would_you_structure_a_repo_with_10_etl/", "subreddit_subscribers": 83094, "created_utc": 1671174222.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**Background about myself:**  \nI spent 5 years doing actuarial consulting where I learned the world is held together by linked Excel pipelines and various languages largely due to turnover. Their one data person only knew VBA, and then another person only knew SQL, so set up a mySQL file that is imported to Excel via VBA and there will be documentation along the lines of \"if excel breaks, do this:)\"\n\nI was spending weeks doing data ingestion into Excel because all we knew were Index/Match to do joins and any file over a million rows would take 50 minutes locking your computer to complete. So I learned R on the side because it was the open source version of SAS and it was gaining ground in the insurance industry.\n\nThings happen and I essentially got pushed out of the actuarial profession and I used that time to self teach data science and then spent 4 years as a Data Science consultant that often got thrown into Data Engineering projects because we'd sell work we didn't have the staff for.  \n\nBecause of project deliverable deadlines, you have limited time to get familiar with the new technology else embarrass yourself in front of the stakeholders and have to claw back the respect. Because of this, my skillsets grew more horizontally from being exposed to various different problems to solve. I'd like to share some of the lessons learned\n\n**Keep Everything In Writing:**  \nThis is mostly a CYA ticket and can help you prepare everything come self review time when you need to list out what you've accomplished and try and quantify the value you provide. No matter where you work, there will be some amount of red tape / politics that go against your every being, but keeping everything in writing will save you in your career. \n\nIf you have a meeting with a manager who gives you a project, instead of taking notes during the meeting, pay attention and ask smart questions so that you have a plan in mind before you hang up the call. Follow that call up in writing with your understanding of the call and your next steps. If there's a \"misunderstanding\" down the line, you have that email to reflect back on to remind you.\n\nYou never know what information will come in handy in the future.\n\n**There's No Shortcuts To Learning**  \nTaking online courses, chasing badges, and getting a Masters will help you get familiar with the topics, but leaves you with a lot of gaps in your knowledge that will be filled in as you get more experienced. Keeping your Ego in check is part of the equation because you don't want to be at the beginning of the Dunning Kruger curve and end up saying something confidently incorrect that loses some credibility.\n\nI approach learning like I approach data: organize it in layers. \n\nMy first approach is going through my content (usually textbooks,lectures , workshops, and documentation) and dumping all my notes into a junk notebook with my personal style of note taking that works best for me.\n\nI then take what I've learned and scope out a plan to apply it to a project, whether it be a personal one or a project I got thrown into and note any programming gotchas in the same junk notebook. \n\nAfter that, I'll watch a few more videos, take some notes, and then condense/rewrite them into a notebook where I have cleaner handwriting and take time to draw nicer visualizations and diagrams.\n\nRinse and repeat as the project develops and I find more gotchas or learn new things. As I'm going, I take note of questions stakeholders ask or think of some questions people may ask, so I can have the answers ready. Finally, once the project is only, I'll recreate my notes digitally, usually in Confluence and use it as an onboarding tool for junior devs.\n\nAs this develops across your project and knowing you should keep everything in writing, this becomes your personal knowledge base and an easy way to refresh yourself on things you've done years ago. Have to tackle MongoDB after not using the syntax for 3 years? Make a Confluence page for it when you're done. Collect your code chunks into libraries that you can use again.\n\n**Know Your Limits**  \nThe data industry is relatively new and over time, roles are becoming more defined over time and has caused a divergence between what a role states in a job and what your day to day will look like. It's grown so fast over the past decade, that inevitably means incompetent leadership is going to exist. The most dangerous form I've seen of this are leaders that have no clue how data actually moves and have no intent to learn. Projects are usually underscoped and developers are the ones always doing the work.\n\nThe onus shouldn't be, but is on the developers to communicate how long things will take because leaders have no idea. When you're inexperienced, it's hard to scope your own projects and you'll end up shooting yourself in the foot if you overestimate your abilities or run into a gotcha that will cause your project to be late.\n\nIt's important to hone that self awareness and ability to scope a project. Ask the proper questions and give a conservative estimate accounting for proper development. If they push back, confirm you believe it will take the initial estimate, and offer additional solutions if you can.\n\nAs things change through out the project, communicate upwards as soon as possible. Send an email with the issue you're facing, your path forward, how long it is estimated to fix, if it's a blocker, and how it will affect the timeline. \n\nThere will inevitably be moments when you're working long hours or get on call to fix an issue that will have material impacts on the company. This is a balancing act and can easily lead to scope creep or your workload piling on top of you. As people learn you get shit done, more people are going to want a piece of you. You'll want to say yes because you're a hard worker, but all the gotchas catch up to you and now you've accumulated tech debt just to get the deliverables out. It happens in every industry and every company. The difference is how the leaders react to this situation. If they're not communicating upwards and leaving you hang to dry, that's were CYA mode comes into play. Hold your ground that you cannot work additional hours because of personal obligations and maintain that stance. It may seem counterintuitive toward your success at the company, but hard work doesn't always pay off.\n\nI personally don't mind working long hours if I'm getting some learning experiences out of it. I hate when I am thrown into situations where the time pressure was avoidable from the beginning. \n\n**Don't Be Afraid To Ask For Help**  \nThis was a big lesson early on in my career. I am the type that likes to figure things out on my own, but sometimes that doesn't align with deadlines. So you have to have self awareness to know you're spinning your wheels and seek out an alternative solution.\n\nAsking for help doesn't mean copy/pasting your traceback errors to coworkers and asking for help. It means, when you've done all the proper searching and debugging yourself, present your issue, what you tried so far, and ask if they've encountered something similar or to take a peek at your code to see if there's anything glaring. It will develop a good personal debugging strategy and soon you'll be the person people go to for issues and it's always a good feeling to help someone else.\n\n**Stand Up For What You Believe In**  \nI've encountered a lot of unethical practices ranging from sexual assault, to CEOs forcing people to work while family was in the hospital, to leaders calling their employees dumb. Just every aspect of a toxic workplace. There's a lot of people that are afraid to speak up in fear of losing their job. People turn a blind eye or come straight out of college and consider it \"business as usual\". A lot of people will just quietly put their two weeks in and get out, but the underlying situation is never fixed. If you witness anything or have something done to you, send it to all the leaders you can in one email that can handle the situation. It's their responsibility to provide a safe workspace. If they do not handle the situation, go one higher up. If nothing gets done and it's affecting your mental health, get a note from your primary care physician, take a mental health FLMA leave (in the US), lawyer up if needed, and get out of there. I've seen companies protect leadership for years just because they brought in a lot of income. \n\nMy personal thing is if I have no one I can look up to at the organization, then there's really no point in me staying. \n\nI hope this all makes sense and is useful to someone. I came from a non traditional background compared to my peers and faced a lot of imposter syndrome. It comes in goes in waves, but instead of thinking I can never be as good as that person, I try and apply the positive things I learn from them.", "author_fullname": "t2_rdm9w1f0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sharing my experiences", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_znluub", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671216289.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Background about myself:&lt;/strong&gt;&lt;br/&gt;\nI spent 5 years doing actuarial consulting where I learned the world is held together by linked Excel pipelines and various languages largely due to turnover. Their one data person only knew VBA, and then another person only knew SQL, so set up a mySQL file that is imported to Excel via VBA and there will be documentation along the lines of &amp;quot;if excel breaks, do this:)&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;I was spending weeks doing data ingestion into Excel because all we knew were Index/Match to do joins and any file over a million rows would take 50 minutes locking your computer to complete. So I learned R on the side because it was the open source version of SAS and it was gaining ground in the insurance industry.&lt;/p&gt;\n\n&lt;p&gt;Things happen and I essentially got pushed out of the actuarial profession and I used that time to self teach data science and then spent 4 years as a Data Science consultant that often got thrown into Data Engineering projects because we&amp;#39;d sell work we didn&amp;#39;t have the staff for.  &lt;/p&gt;\n\n&lt;p&gt;Because of project deliverable deadlines, you have limited time to get familiar with the new technology else embarrass yourself in front of the stakeholders and have to claw back the respect. Because of this, my skillsets grew more horizontally from being exposed to various different problems to solve. I&amp;#39;d like to share some of the lessons learned&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Keep Everything In Writing:&lt;/strong&gt;&lt;br/&gt;\nThis is mostly a CYA ticket and can help you prepare everything come self review time when you need to list out what you&amp;#39;ve accomplished and try and quantify the value you provide. No matter where you work, there will be some amount of red tape / politics that go against your every being, but keeping everything in writing will save you in your career. &lt;/p&gt;\n\n&lt;p&gt;If you have a meeting with a manager who gives you a project, instead of taking notes during the meeting, pay attention and ask smart questions so that you have a plan in mind before you hang up the call. Follow that call up in writing with your understanding of the call and your next steps. If there&amp;#39;s a &amp;quot;misunderstanding&amp;quot; down the line, you have that email to reflect back on to remind you.&lt;/p&gt;\n\n&lt;p&gt;You never know what information will come in handy in the future.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;There&amp;#39;s No Shortcuts To Learning&lt;/strong&gt;&lt;br/&gt;\nTaking online courses, chasing badges, and getting a Masters will help you get familiar with the topics, but leaves you with a lot of gaps in your knowledge that will be filled in as you get more experienced. Keeping your Ego in check is part of the equation because you don&amp;#39;t want to be at the beginning of the Dunning Kruger curve and end up saying something confidently incorrect that loses some credibility.&lt;/p&gt;\n\n&lt;p&gt;I approach learning like I approach data: organize it in layers. &lt;/p&gt;\n\n&lt;p&gt;My first approach is going through my content (usually textbooks,lectures , workshops, and documentation) and dumping all my notes into a junk notebook with my personal style of note taking that works best for me.&lt;/p&gt;\n\n&lt;p&gt;I then take what I&amp;#39;ve learned and scope out a plan to apply it to a project, whether it be a personal one or a project I got thrown into and note any programming gotchas in the same junk notebook. &lt;/p&gt;\n\n&lt;p&gt;After that, I&amp;#39;ll watch a few more videos, take some notes, and then condense/rewrite them into a notebook where I have cleaner handwriting and take time to draw nicer visualizations and diagrams.&lt;/p&gt;\n\n&lt;p&gt;Rinse and repeat as the project develops and I find more gotchas or learn new things. As I&amp;#39;m going, I take note of questions stakeholders ask or think of some questions people may ask, so I can have the answers ready. Finally, once the project is only, I&amp;#39;ll recreate my notes digitally, usually in Confluence and use it as an onboarding tool for junior devs.&lt;/p&gt;\n\n&lt;p&gt;As this develops across your project and knowing you should keep everything in writing, this becomes your personal knowledge base and an easy way to refresh yourself on things you&amp;#39;ve done years ago. Have to tackle MongoDB after not using the syntax for 3 years? Make a Confluence page for it when you&amp;#39;re done. Collect your code chunks into libraries that you can use again.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Know Your Limits&lt;/strong&gt;&lt;br/&gt;\nThe data industry is relatively new and over time, roles are becoming more defined over time and has caused a divergence between what a role states in a job and what your day to day will look like. It&amp;#39;s grown so fast over the past decade, that inevitably means incompetent leadership is going to exist. The most dangerous form I&amp;#39;ve seen of this are leaders that have no clue how data actually moves and have no intent to learn. Projects are usually underscoped and developers are the ones always doing the work.&lt;/p&gt;\n\n&lt;p&gt;The onus shouldn&amp;#39;t be, but is on the developers to communicate how long things will take because leaders have no idea. When you&amp;#39;re inexperienced, it&amp;#39;s hard to scope your own projects and you&amp;#39;ll end up shooting yourself in the foot if you overestimate your abilities or run into a gotcha that will cause your project to be late.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s important to hone that self awareness and ability to scope a project. Ask the proper questions and give a conservative estimate accounting for proper development. If they push back, confirm you believe it will take the initial estimate, and offer additional solutions if you can.&lt;/p&gt;\n\n&lt;p&gt;As things change through out the project, communicate upwards as soon as possible. Send an email with the issue you&amp;#39;re facing, your path forward, how long it is estimated to fix, if it&amp;#39;s a blocker, and how it will affect the timeline. &lt;/p&gt;\n\n&lt;p&gt;There will inevitably be moments when you&amp;#39;re working long hours or get on call to fix an issue that will have material impacts on the company. This is a balancing act and can easily lead to scope creep or your workload piling on top of you. As people learn you get shit done, more people are going to want a piece of you. You&amp;#39;ll want to say yes because you&amp;#39;re a hard worker, but all the gotchas catch up to you and now you&amp;#39;ve accumulated tech debt just to get the deliverables out. It happens in every industry and every company. The difference is how the leaders react to this situation. If they&amp;#39;re not communicating upwards and leaving you hang to dry, that&amp;#39;s were CYA mode comes into play. Hold your ground that you cannot work additional hours because of personal obligations and maintain that stance. It may seem counterintuitive toward your success at the company, but hard work doesn&amp;#39;t always pay off.&lt;/p&gt;\n\n&lt;p&gt;I personally don&amp;#39;t mind working long hours if I&amp;#39;m getting some learning experiences out of it. I hate when I am thrown into situations where the time pressure was avoidable from the beginning. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Don&amp;#39;t Be Afraid To Ask For Help&lt;/strong&gt;&lt;br/&gt;\nThis was a big lesson early on in my career. I am the type that likes to figure things out on my own, but sometimes that doesn&amp;#39;t align with deadlines. So you have to have self awareness to know you&amp;#39;re spinning your wheels and seek out an alternative solution.&lt;/p&gt;\n\n&lt;p&gt;Asking for help doesn&amp;#39;t mean copy/pasting your traceback errors to coworkers and asking for help. It means, when you&amp;#39;ve done all the proper searching and debugging yourself, present your issue, what you tried so far, and ask if they&amp;#39;ve encountered something similar or to take a peek at your code to see if there&amp;#39;s anything glaring. It will develop a good personal debugging strategy and soon you&amp;#39;ll be the person people go to for issues and it&amp;#39;s always a good feeling to help someone else.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Stand Up For What You Believe In&lt;/strong&gt;&lt;br/&gt;\nI&amp;#39;ve encountered a lot of unethical practices ranging from sexual assault, to CEOs forcing people to work while family was in the hospital, to leaders calling their employees dumb. Just every aspect of a toxic workplace. There&amp;#39;s a lot of people that are afraid to speak up in fear of losing their job. People turn a blind eye or come straight out of college and consider it &amp;quot;business as usual&amp;quot;. A lot of people will just quietly put their two weeks in and get out, but the underlying situation is never fixed. If you witness anything or have something done to you, send it to all the leaders you can in one email that can handle the situation. It&amp;#39;s their responsibility to provide a safe workspace. If they do not handle the situation, go one higher up. If nothing gets done and it&amp;#39;s affecting your mental health, get a note from your primary care physician, take a mental health FLMA leave (in the US), lawyer up if needed, and get out of there. I&amp;#39;ve seen companies protect leadership for years just because they brought in a lot of income. &lt;/p&gt;\n\n&lt;p&gt;My personal thing is if I have no one I can look up to at the organization, then there&amp;#39;s really no point in me staying. &lt;/p&gt;\n\n&lt;p&gt;I hope this all makes sense and is useful to someone. I came from a non traditional background compared to my peers and faced a lot of imposter syndrome. It comes in goes in waves, but instead of thinking I can never be as good as that person, I try and apply the positive things I learn from them.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "znluub", "is_robot_indexable": true, "report_reasons": null, "author": "keeney_arcadia", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/znluub/sharing_my_experiences/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/znluub/sharing_my_experiences/", "subreddit_subscribers": 83094, "created_utc": 1671216289.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all!\n\nI have a csv file with known column names of \u201ca\u201d, \u201cb\u201d, \u201cc\u201d, \u201cd\u201d.  I would like to predefine the schema using pyspark to ensure correct data types on read, but the file column order may change without me knowing.\n\nFor example, the csv file may come in the order \u201cd\u201d, \u201ca\u201d, \u201cb\u201d, \u201cc\u201d\n\nHow do I account for this in reading in the file? Is there anyway possible to do this without using inferschema?\n\nEDIT:\n\nFigured out a way to achieve this. Read the file as an rdd, then use a map function to rearrange the columns of the rdd.", "author_fullname": "t2_gge8z8qb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Predefined Schema - Correct Names, Incorrect Order", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_znhwuu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1671209302.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671206141.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all!&lt;/p&gt;\n\n&lt;p&gt;I have a csv file with known column names of \u201ca\u201d, \u201cb\u201d, \u201cc\u201d, \u201cd\u201d.  I would like to predefine the schema using pyspark to ensure correct data types on read, but the file column order may change without me knowing.&lt;/p&gt;\n\n&lt;p&gt;For example, the csv file may come in the order \u201cd\u201d, \u201ca\u201d, \u201cb\u201d, \u201cc\u201d&lt;/p&gt;\n\n&lt;p&gt;How do I account for this in reading in the file? Is there anyway possible to do this without using inferschema?&lt;/p&gt;\n\n&lt;p&gt;EDIT:&lt;/p&gt;\n\n&lt;p&gt;Figured out a way to achieve this. Read the file as an rdd, then use a map function to rearrange the columns of the rdd.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "znhwuu", "is_robot_indexable": true, "report_reasons": null, "author": "No_Professional_9685", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/znhwuu/predefined_schema_correct_names_incorrect_order/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/znhwuu/predefined_schema_correct_names_incorrect_order/", "subreddit_subscribers": 83094, "created_utc": 1671206141.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can someone gauge if [this bootcamp](https://trendytech.in) is good? I saw this on linkedin and I find the content good to kickstart my journey in big data. It is worth $650.\n\nMy other option is to learn each technology individually from udemy and other platforms which will only cost &lt; $150.\n\nThe advantage of buying a bootcamp as a package, is it is structured already and the content has been filtered to just learn the important concepts. So, I\u2019m eyeing that but wuite not sure if $650 for the course is worth it or not.", "author_fullname": "t2_5owlarij", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Bootcamp (worthy or not?)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zni70p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671206842.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can someone gauge if &lt;a href=\"https://trendytech.in\"&gt;this bootcamp&lt;/a&gt; is good? I saw this on linkedin and I find the content good to kickstart my journey in big data. It is worth $650.&lt;/p&gt;\n\n&lt;p&gt;My other option is to learn each technology individually from udemy and other platforms which will only cost &amp;lt; $150.&lt;/p&gt;\n\n&lt;p&gt;The advantage of buying a bootcamp as a package, is it is structured already and the content has been filtered to just learn the important concepts. So, I\u2019m eyeing that but wuite not sure if $650 for the course is worth it or not.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zni70p", "is_robot_indexable": true, "report_reasons": null, "author": "_Dark_mage", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zni70p/data_engineering_bootcamp_worthy_or_not/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zni70p/data_engineering_bootcamp_worthy_or_not/", "subreddit_subscribers": 83094, "created_utc": 1671206842.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a set of Tableau dashboards linked to datamarts on Bigquery.\nI work with Hyper extracts to get my data from Bigquery to Tableau.\nMy workbooks contain filters for business logic and date range filters to compare data between two date ranges.\n\nI also have a user logic. Which means that my Bigquery tables have a row for each user and in Tableau views I apply user filter to have the data that is only linked to that specific user. \n\nThe problem is that my dashboards are loading very slowly. Sometimes it could take to 10mins for loading a workbook. Which is not good for user experience.\n\n\nThe size of my Bigquery Tables : 2 to 4 Tb\nNumber of tableau users : ~ 400 users\n\nHave you faced such a situation when working with Tableau ? If so what are your advices to reducing the loading time of my dashboards ? Or could you tell how do you use Tableau in a large scale ?\n\nThank you", "author_fullname": "t2_98269xyy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My Tableau Dashboards are slow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zn0c5t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671148065.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a set of Tableau dashboards linked to datamarts on Bigquery.\nI work with Hyper extracts to get my data from Bigquery to Tableau.\nMy workbooks contain filters for business logic and date range filters to compare data between two date ranges.&lt;/p&gt;\n\n&lt;p&gt;I also have a user logic. Which means that my Bigquery tables have a row for each user and in Tableau views I apply user filter to have the data that is only linked to that specific user. &lt;/p&gt;\n\n&lt;p&gt;The problem is that my dashboards are loading very slowly. Sometimes it could take to 10mins for loading a workbook. Which is not good for user experience.&lt;/p&gt;\n\n&lt;p&gt;The size of my Bigquery Tables : 2 to 4 Tb\nNumber of tableau users : ~ 400 users&lt;/p&gt;\n\n&lt;p&gt;Have you faced such a situation when working with Tableau ? If so what are your advices to reducing the loading time of my dashboards ? Or could you tell how do you use Tableau in a large scale ?&lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zn0c5t", "is_robot_indexable": true, "report_reasons": null, "author": "Electronic-Mountain9", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zn0c5t/my_tableau_dashboards_are_slow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zn0c5t/my_tableau_dashboards_are_slow/", "subreddit_subscribers": 83094, "created_utc": 1671148065.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://adventofcode.com/](https://adventofcode.com/)\n\nAnyone else did/doing this?\n\nDid you find it difficult?\n\nIt's basically a programming puzzle for every day on the \"advent calendar\"", "author_fullname": "t2_8chdw7c4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advent of Code", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zn11ds", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671149904.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://adventofcode.com/\"&gt;https://adventofcode.com/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Anyone else did/doing this?&lt;/p&gt;\n\n&lt;p&gt;Did you find it difficult?&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s basically a programming puzzle for every day on the &amp;quot;advent calendar&amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zn11ds", "is_robot_indexable": true, "report_reasons": null, "author": "pdxtechnologist", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zn11ds/advent_of_code/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zn11ds/advent_of_code/", "subreddit_subscribers": 83094, "created_utc": 1671149904.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "First of all thank you all for the great content that has been created on this sub. I am not much a Reddit person but have been following up here. \n\nI am in process of creating a good set of assignments for students learning Big Data technologies and looking for a free datasets available online. I have looked at multiple but want your opinions for specific requirement below : \n\n**Data Set Requirement -** \n\n1. Large amount of structured/semi structured data to be used for Batch processing (single batch could have 50-100GB commonly)\n2. Data modelling - I want them to have a good exposure to traditional modelling (although this may fall into Data Lake like architecture) and I am not a warehouse person. So any data that'd allow them to have some chance to model would be good. I understand this is use case/domain specific and not a straight ask but say a 8 column movie DB of 5TB in size may not be greatly helpful. Any parallel sets of large datasets where they can be independently corelated would be good too than a single source.\n3. Continuously generating new data for part Streaming use cases that can be related to the large datasets.\n\n&amp;#x200B;\n\n**Technology Stack Used -**\n\n1. Apache Spark with AWS EMR, Glue\n2. Athena/Presto for Querying\n3. Kinesis suite for streaming\n\n&amp;#x200B;\n\n**Not looking for** \\- \n\n1. Not looking for datasets for any ML modelling\n2. Fully structured data is perfectly fine. But some unstructured data requiring some cleaning is okay too, end goal is to get handle on using Big Data tech, doing data modelling and some performance checks on such piplines in AWS.", "author_fullname": "t2_qg4yidm6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Large sample dataset for data modelling and big data tools exercises", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_znfchs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671199244.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First of all thank you all for the great content that has been created on this sub. I am not much a Reddit person but have been following up here. &lt;/p&gt;\n\n&lt;p&gt;I am in process of creating a good set of assignments for students learning Big Data technologies and looking for a free datasets available online. I have looked at multiple but want your opinions for specific requirement below : &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Data Set Requirement -&lt;/strong&gt; &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Large amount of structured/semi structured data to be used for Batch processing (single batch could have 50-100GB commonly)&lt;/li&gt;\n&lt;li&gt;Data modelling - I want them to have a good exposure to traditional modelling (although this may fall into Data Lake like architecture) and I am not a warehouse person. So any data that&amp;#39;d allow them to have some chance to model would be good. I understand this is use case/domain specific and not a straight ask but say a 8 column movie DB of 5TB in size may not be greatly helpful. Any parallel sets of large datasets where they can be independently corelated would be good too than a single source.&lt;/li&gt;\n&lt;li&gt;Continuously generating new data for part Streaming use cases that can be related to the large datasets.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Technology Stack Used -&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Apache Spark with AWS EMR, Glue&lt;/li&gt;\n&lt;li&gt;Athena/Presto for Querying&lt;/li&gt;\n&lt;li&gt;Kinesis suite for streaming&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Not looking for&lt;/strong&gt; - &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Not looking for datasets for any ML modelling&lt;/li&gt;\n&lt;li&gt;Fully structured data is perfectly fine. But some unstructured data requiring some cleaning is okay too, end goal is to get handle on using Big Data tech, doing data modelling and some performance checks on such piplines in AWS.&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "znfchs", "is_robot_indexable": true, "report_reasons": null, "author": "Other_Cartoonist7071", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/znfchs/large_sample_dataset_for_data_modelling_and_big/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/znfchs/large_sample_dataset_for_data_modelling_and_big/", "subreddit_subscribers": 83094, "created_utc": 1671199244.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hopefully a quick one.\n\nHow far down /opt/airflow/dags folder structure does Airflow go looking for dag.py files? Do they need to be right there, or could they be scattered in subdirectories below this?", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow path question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zmzw2t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671146991.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hopefully a quick one.&lt;/p&gt;\n\n&lt;p&gt;How far down /opt/airflow/dags folder structure does Airflow go looking for dag.py files? Do they need to be right there, or could they be scattered in subdirectories below this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zmzw2t", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zmzw2t/airflow_path_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zmzw2t/airflow_path_question/", "subreddit_subscribers": 83094, "created_utc": 1671146991.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Guys,\n\nHope this message finds you well!\n\nI was thinking to start a project of my own like the website [camelcamelcamel.com](https://camelcamelcamel.com) and I was wondering if you could suggest me on which free tools to use best for this engineering project.\n\nAll help and suggestions are welcome.", "author_fullname": "t2_f3vb1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tool suggestions for a project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zngw4p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1671203534.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Guys,&lt;/p&gt;\n\n&lt;p&gt;Hope this message finds you well!&lt;/p&gt;\n\n&lt;p&gt;I was thinking to start a project of my own like the website &lt;a href=\"https://camelcamelcamel.com\"&gt;camelcamelcamel.com&lt;/a&gt; and I was wondering if you could suggest me on which free tools to use best for this engineering project.&lt;/p&gt;\n\n&lt;p&gt;All help and suggestions are welcome.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/gybnDH0o7u0DLFGJMvKsfG6iJH0O86qWrdQX5RSQol0.jpg?auto=webp&amp;s=76600fa39de0e0befbf71c530cb7b31009ab0088", "width": 1560, "height": 633}, "resolutions": [{"url": "https://external-preview.redd.it/gybnDH0o7u0DLFGJMvKsfG6iJH0O86qWrdQX5RSQol0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=07bf6c406a742d07a4c29f5369d867ece4b14b41", "width": 108, "height": 43}, {"url": "https://external-preview.redd.it/gybnDH0o7u0DLFGJMvKsfG6iJH0O86qWrdQX5RSQol0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=86384f2c356ef0bbea512f77d020164ad5026a70", "width": 216, "height": 87}, {"url": "https://external-preview.redd.it/gybnDH0o7u0DLFGJMvKsfG6iJH0O86qWrdQX5RSQol0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cb9f2adf48e9f24b251c211bc9726c1bb0c7705d", "width": 320, "height": 129}, {"url": "https://external-preview.redd.it/gybnDH0o7u0DLFGJMvKsfG6iJH0O86qWrdQX5RSQol0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2cb71267a634537b31604506b637ff3cf542e91e", "width": 640, "height": 259}, {"url": "https://external-preview.redd.it/gybnDH0o7u0DLFGJMvKsfG6iJH0O86qWrdQX5RSQol0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=09ee49b71c4c81ad786cb153515b17c29e15945d", "width": 960, "height": 389}, {"url": "https://external-preview.redd.it/gybnDH0o7u0DLFGJMvKsfG6iJH0O86qWrdQX5RSQol0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=88d5311af3ee4b21ecac2e20cd5de5ec02b1a121", "width": 1080, "height": 438}], "variants": {}, "id": "4ZccvLKGtqCcJzEz2YEeN_Zvwhd-SZ8SSm6y3DGXZDA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "zngw4p", "is_robot_indexable": true, "report_reasons": null, "author": "olti93", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zngw4p/tool_suggestions_for_a_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zngw4p/tool_suggestions_for_a_project/", "subreddit_subscribers": 83094, "created_utc": 1671203534.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are building our pipelin in glue and using lambda for trigger based orchestration and logging etc. I have a feeling airflow can make our life easier. If not airflow is there some other orchestration tool that would be better suited?", "author_fullname": "t2_2se32fpj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I use airflow to orchestrate serverless ETL functions on AWS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_znbgg5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671186061.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are building our pipelin in glue and using lambda for trigger based orchestration and logging etc. I have a feeling airflow can make our life easier. If not airflow is there some other orchestration tool that would be better suited?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "znbgg5", "is_robot_indexable": true, "report_reasons": null, "author": "localhost3306", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/znbgg5/how_can_i_use_airflow_to_orchestrate_serverless/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/znbgg5/how_can_i_use_airflow_to_orchestrate_serverless/", "subreddit_subscribers": 83094, "created_utc": 1671186061.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Trying to find a best practice for handling some pipelines with DBT + Delta in Dagster.\n\nFor example:\n\n- Pipeline for automatically loading Delta with DBT and reverting back to last version (time travel)\n\n\n\nWe're currently using S3 + Delta, so we're manually writing loading for Delta into DBT. (e.g. select * from delta.filename)\n\nPerhaps external tables would be better for this use case?", "author_fullname": "t2_5yeb5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Request] Any good examples of using DBT + Dagster + Delta?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_znal53", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671182414.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Trying to find a best practice for handling some pipelines with DBT + Delta in Dagster.&lt;/p&gt;\n\n&lt;p&gt;For example:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Pipeline for automatically loading Delta with DBT and reverting back to last version (time travel)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;We&amp;#39;re currently using S3 + Delta, so we&amp;#39;re manually writing loading for Delta into DBT. (e.g. select * from delta.filename)&lt;/p&gt;\n\n&lt;p&gt;Perhaps external tables would be better for this use case?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "znal53", "is_robot_indexable": true, "report_reasons": null, "author": "entinthemountains", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/znal53/request_any_good_examples_of_using_dbt_dagster/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/znal53/request_any_good_examples_of_using_dbt_dagster/", "subreddit_subscribers": 83094, "created_utc": 1671182414.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a DE/analytics engineer. I do stuff like pulling data from streams (kafka), from product DBs, APIs and from the data lake and load it into my cloud DB after transforming it in my EC2. I also build visuals on the data. \n\nI would like to know where a tool like docker is used in typical DE scope. Do companies (not all ofc) no longer use a dedicated server to run data pipelines and rely on docker for such stuff? Where does the code reside in such cases (it resides in the EC2 hard disk for me)? Also, am i right when i say that when a cloud DB offers a auto scaling feature or when a databricks job can be set up using a machine that spins up only during the job run and shuts up later, they're using docker or similiar tools to offer these services?", "author_fullname": "t2_xap78", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Docker queries", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_znketu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671212537.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a DE/analytics engineer. I do stuff like pulling data from streams (kafka), from product DBs, APIs and from the data lake and load it into my cloud DB after transforming it in my EC2. I also build visuals on the data. &lt;/p&gt;\n\n&lt;p&gt;I would like to know where a tool like docker is used in typical DE scope. Do companies (not all ofc) no longer use a dedicated server to run data pipelines and rely on docker for such stuff? Where does the code reside in such cases (it resides in the EC2 hard disk for me)? Also, am i right when i say that when a cloud DB offers a auto scaling feature or when a databricks job can be set up using a machine that spins up only during the job run and shuts up later, they&amp;#39;re using docker or similiar tools to offer these services?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "znketu", "is_robot_indexable": true, "report_reasons": null, "author": "totalsports1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/znketu/docker_queries/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/znketu/docker_queries/", "subreddit_subscribers": 83094, "created_utc": 1671212537.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Since google anounces that they will deprecate the Google IoT Core service on 16th August 2023, what alternatives can I manage to collect data from IoT gateways in an industrial environment and send them to Google Cloud Pub/Sub, IoT protocols could be MQTT or OPC UA.", "author_fullname": "t2_sv0s9rab", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to collect IoT data and gather to Google Cloud?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zncyk1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671191838.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Since google anounces that they will deprecate the Google IoT Core service on 16th August 2023, what alternatives can I manage to collect data from IoT gateways in an industrial environment and send them to Google Cloud Pub/Sub, IoT protocols could be MQTT or OPC UA.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zncyk1", "is_robot_indexable": true, "report_reasons": null, "author": "DonDewid", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zncyk1/how_to_collect_iot_data_and_gather_to_google_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zncyk1/how_to_collect_iot_data_and_gather_to_google_cloud/", "subreddit_subscribers": 83094, "created_utc": 1671191838.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Azure has a great guide for naming convention for Azure resources, but I have yet to find an \u201cofficial\u201d guide for Data Factory or Synapse. I\u2019m talking pipelines, data sets, data flows, sources, sinks, etc.\n\nI always have the same challenge with ADF:\n\nWhat looks good in code always gets truncated in the GUI so there\u2019s a trade off. If I shorten the names, I lose descriptive text, but it fits in the GUI.\n\nBut if I use longer names, I get all the identifying text I need, it just makes reading objects in the GUI exceptionally difficult to differentiate from each other.\n\nI\u2019ve read a few blogs with suggestions, but was hoping there was an \u201cofficial\u201d style guide like the main Azure docs, or maybe someone has a recipe they use.\n\nhttps://learn.microsoft.com/en-us/azure/cloud-adoption-framework/ready/azure-best-practices/resource-naming\n\nOr do some of you have cross-cloud / product conventions you use? We need a Terraform for Data Engineering lol\n\nhttps://np.reddit.com/r/dataengineering/comments/tjr4t5/standardization_style_guide_and_naming_convention/", "author_fullname": "t2_t2wl82bi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure Data Factory Naming Convention Guide\uff1f", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_znbbsi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1671185516.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Azure has a great guide for naming convention for Azure resources, but I have yet to find an \u201cofficial\u201d guide for Data Factory or Synapse. I\u2019m talking pipelines, data sets, data flows, sources, sinks, etc.&lt;/p&gt;\n\n&lt;p&gt;I always have the same challenge with ADF:&lt;/p&gt;\n\n&lt;p&gt;What looks good in code always gets truncated in the GUI so there\u2019s a trade off. If I shorten the names, I lose descriptive text, but it fits in the GUI.&lt;/p&gt;\n\n&lt;p&gt;But if I use longer names, I get all the identifying text I need, it just makes reading objects in the GUI exceptionally difficult to differentiate from each other.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve read a few blogs with suggestions, but was hoping there was an \u201cofficial\u201d style guide like the main Azure docs, or maybe someone has a recipe they use.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/ready/azure-best-practices/resource-naming\"&gt;https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/ready/azure-best-practices/resource-naming&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Or do some of you have cross-cloud / product conventions you use? We need a Terraform for Data Engineering lol&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://np.reddit.com/r/dataengineering/comments/tjr4t5/standardization_style_guide_and_naming_convention/\"&gt;https://np.reddit.com/r/dataengineering/comments/tjr4t5/standardization_style_guide_and_naming_convention/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YH8gNap4KoGcFgyFYrNZ86fXmYfRn6pa7uuwIlZkjEE.jpg?auto=webp&amp;s=e62264227377a9581e2e2946169864d130fa3217", "width": 400, "height": 400}, "resolutions": [{"url": "https://external-preview.redd.it/YH8gNap4KoGcFgyFYrNZ86fXmYfRn6pa7uuwIlZkjEE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0b9526a51504048891d5e64783519fd5dc3cd83f", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/YH8gNap4KoGcFgyFYrNZ86fXmYfRn6pa7uuwIlZkjEE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0150bc3ab1c6838c35ff951d69578f3d19ae4ed3", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/YH8gNap4KoGcFgyFYrNZ86fXmYfRn6pa7uuwIlZkjEE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c1e830770227ae4802c5776d22f63d0f6aa71b15", "width": 320, "height": 320}], "variants": {}, "id": "LVmzWMJU1UZwRubzQYJZSar-z-Rq8ntUH65yhQyfxB8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "znbbsi", "is_robot_indexable": true, "report_reasons": null, "author": "generic-d-engineer", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/znbbsi/azure_data_factory_naming_convention_guide/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/znbbsi/azure_data_factory_naming_convention_guide/", "subreddit_subscribers": 83094, "created_utc": 1671185516.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey,\nCan anyone please help me with  the compensation(base, bonus, stocks) details for Walmart?\n\nAlso, how is the work life balance for Walmart New Ventures team for USA and Canada locations?\n\nAny insight is appreciated.", "author_fullname": "t2_eizebsp9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Walmart compensation and wlb?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_znae3d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671181622.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey,\nCan anyone please help me with  the compensation(base, bonus, stocks) details for Walmart?&lt;/p&gt;\n\n&lt;p&gt;Also, how is the work life balance for Walmart New Ventures team for USA and Canada locations?&lt;/p&gt;\n\n&lt;p&gt;Any insight is appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "znae3d", "is_robot_indexable": true, "report_reasons": null, "author": "_DarthVader__", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/znae3d/walmart_compensation_and_wlb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/znae3d/walmart_compensation_and_wlb/", "subreddit_subscribers": 83094, "created_utc": 1671181622.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\n&amp;#x200B;\n\nI currently work in a Microsoft SQL Server environment. I'm working on my resume right now so I can start applying for entry-level data engineer positions.\n\nCurrently, I extract data from the SQL database, implement them into Power BI, clean up the data(null values, bad data), add new columns if necessary, export to CSV and insert them back into the database.\n\nI'm not sure if this method would be considered ETL which is why I'm asking you guys. If it's considered ETL, then I have some experience where it might put me over the edge and give me more interviews. \n\nLooking for advice and I don't mind any blunt answers.\n\n&amp;#x200B;\n\nThank you!", "author_fullname": "t2_7gkhxmgl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Would this method be considered ETL and is it worth putting on my resume?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zn8vv9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671175306.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I currently work in a Microsoft SQL Server environment. I&amp;#39;m working on my resume right now so I can start applying for entry-level data engineer positions.&lt;/p&gt;\n\n&lt;p&gt;Currently, I extract data from the SQL database, implement them into Power BI, clean up the data(null values, bad data), add new columns if necessary, export to CSV and insert them back into the database.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not sure if this method would be considered ETL which is why I&amp;#39;m asking you guys. If it&amp;#39;s considered ETL, then I have some experience where it might put me over the edge and give me more interviews. &lt;/p&gt;\n\n&lt;p&gt;Looking for advice and I don&amp;#39;t mind any blunt answers.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zn8vv9", "is_robot_indexable": true, "report_reasons": null, "author": "SnooWalruses7164", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zn8vv9/would_this_method_be_considered_etl_and_is_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zn8vv9/would_this_method_be_considered_etl_and_is_it/", "subreddit_subscribers": 83094, "created_utc": 1671175306.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, I know I am one of those people that had to create another DE bootcamp thread but I would love to get some advice on which DE bootcamp that would suit me the best for my next steps in my career.\n\nI am currently working full time as a Business Analysis Manager at a Fortune 500 tech company in the Bay Area for the last five years. In this role, I have been acting as a Swiss Army Knife of sorts being a half-PM and a half-DA specializing in developing data quality, integration, and automation solutions that I then pass onto a BI or a DS team to actually develop in production for us. Most of the data is related to sales and is often anchored by our CRM (SFDC) and with no-code intermediate solutions (such as LeanData or SFDC Flows). From time to time, I do prototype out custom scripts that could be used to fulfill some functionality (like connecting to Snowflake and SAP), but ultimately the ETL solutions I draft are pushed to actual DE's and Dev's to fully build out. I also maintain reports and dashboards on our data health and do the typical update meetings to our stakeholders.\n\nHowever in the past half a year, I have been wanting to go more towards the path of being a pure BI Analyst, AE, or DE. I have SQL and Tableau knowledge (as I still have to do analysis and prototyping) and some Python knowledge, but not enough to be a reliable scripter. Furthermore, I have no hands-on knowledge of deeper things like Data Lakehouses or Data Orchestration as my job does not require me to use those directly (again we got DE's and Dev's for that). Therefore, I am considering a bootcamp to help fill those gaps and hopefully get me caught up on the technical stack of my skills and sharp enough to pass technical interviews for future BI roles.\n\nCurrently, I am looking at three in particular, but each of them has a different approach to how they teach:\n\n1. Jigsaw Labs\n2. Data Engineering Camp\n3. WeCloudData\n\nJigsaw Labs: \n\nA six month course that teaches 'Data Engineering' from a SWE perspective of knowing how to write efficient and well designed Python and SQL code to properly do large-scale ETL processes and only in the second half of the course to focus on Cloud Computing (AWS) and Data Pipelines using Airflow, Fivetran and DBT. According to some of my friends in the DE and Data Infra space that this course is the most useful as the key to being a solid BI/AE/DE is knowing how to write effective Python code and SQL queries that follows a good data design and everything from there should come naturally.\n\nThis course is also the most expensive of the three and also includes an externship that you can work with an actual company or non-profit to apply the taught skills to build a real-world applied project and gives an additional nine months of post-course support, especially in sharpening your Python/SQL LC practice for those interviews.\n\nHowever, the course does not cover anything with Data Lakehouses or Data Streaming, I feel like the most you will be out of the course is a solid BI Analyst, but you will still need to cover the gaps of the rest on your own, which makes me question how much worth I will be for my career switch in the future to like an AE.\n\nData Engineering Camp:\n\nThey have been touted pretty well in this subreddit and the course founder is pretty active on this subreddit as well. His course is the shortest of the three and he seems to cover all of the key bits in the DE toolbox and expectations including Lakehouses (Spark, Databricks) and Streaming (Kafka). However, I am not sure all of this coverage would make me come out of it effective enough to be taken seriously for a career change without further supplementation. It sounds it is great if I wanted to be like a TPM that would work more with an AE/DE team though.\n\nAlso from a instruction POV, I will have to take classes between 2AM to 5AM since I am in the West Coast US and they are being taught from Australia.\n\nWeCloudData:\n\nThis one seems to be in the middle of Jigsaw Labs and DEC. It is six months and seems to cover all of the basis that Jigsaw and DEC is doing, but not in the detail on the Python/SQL front like Jigsaw. Therefore, I feel like this one will get me the good grasp of what I need to know as an AE/DE, but I am leery if it still lacks the best approach to give me the core foundations needed for my Python/SQL chops. They also provide six months of mentorship and career prep after the course but not externship if you do the part-time program.\n\nTherefore, I am torn if I trade off the philosophy of Jigsaw Labs to teach you the true fundamentals but at the expense of learning the higher-level tools/processes that is also needed, or do a more comprehensive curriculum like DEC or WeCloudData coming from my own experience and aspirations.\n\nAny suggestions is appreciated as I want to do the best bootcamp that would yield me the best foot forward for my next career move. I know a good number of you would tell me to don't bother with any of them and just self-learn (cheaper), but trust me, I learn the best by being instructed, especially if I want to be taught the foundations correctly.\n\nThx!", "author_fullname": "t2_b7b2g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best DE Bootcamp based on my experience and objectives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zn1vhc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671152263.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I know I am one of those people that had to create another DE bootcamp thread but I would love to get some advice on which DE bootcamp that would suit me the best for my next steps in my career.&lt;/p&gt;\n\n&lt;p&gt;I am currently working full time as a Business Analysis Manager at a Fortune 500 tech company in the Bay Area for the last five years. In this role, I have been acting as a Swiss Army Knife of sorts being a half-PM and a half-DA specializing in developing data quality, integration, and automation solutions that I then pass onto a BI or a DS team to actually develop in production for us. Most of the data is related to sales and is often anchored by our CRM (SFDC) and with no-code intermediate solutions (such as LeanData or SFDC Flows). From time to time, I do prototype out custom scripts that could be used to fulfill some functionality (like connecting to Snowflake and SAP), but ultimately the ETL solutions I draft are pushed to actual DE&amp;#39;s and Dev&amp;#39;s to fully build out. I also maintain reports and dashboards on our data health and do the typical update meetings to our stakeholders.&lt;/p&gt;\n\n&lt;p&gt;However in the past half a year, I have been wanting to go more towards the path of being a pure BI Analyst, AE, or DE. I have SQL and Tableau knowledge (as I still have to do analysis and prototyping) and some Python knowledge, but not enough to be a reliable scripter. Furthermore, I have no hands-on knowledge of deeper things like Data Lakehouses or Data Orchestration as my job does not require me to use those directly (again we got DE&amp;#39;s and Dev&amp;#39;s for that). Therefore, I am considering a bootcamp to help fill those gaps and hopefully get me caught up on the technical stack of my skills and sharp enough to pass technical interviews for future BI roles.&lt;/p&gt;\n\n&lt;p&gt;Currently, I am looking at three in particular, but each of them has a different approach to how they teach:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Jigsaw Labs&lt;/li&gt;\n&lt;li&gt;Data Engineering Camp&lt;/li&gt;\n&lt;li&gt;WeCloudData&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Jigsaw Labs: &lt;/p&gt;\n\n&lt;p&gt;A six month course that teaches &amp;#39;Data Engineering&amp;#39; from a SWE perspective of knowing how to write efficient and well designed Python and SQL code to properly do large-scale ETL processes and only in the second half of the course to focus on Cloud Computing (AWS) and Data Pipelines using Airflow, Fivetran and DBT. According to some of my friends in the DE and Data Infra space that this course is the most useful as the key to being a solid BI/AE/DE is knowing how to write effective Python code and SQL queries that follows a good data design and everything from there should come naturally.&lt;/p&gt;\n\n&lt;p&gt;This course is also the most expensive of the three and also includes an externship that you can work with an actual company or non-profit to apply the taught skills to build a real-world applied project and gives an additional nine months of post-course support, especially in sharpening your Python/SQL LC practice for those interviews.&lt;/p&gt;\n\n&lt;p&gt;However, the course does not cover anything with Data Lakehouses or Data Streaming, I feel like the most you will be out of the course is a solid BI Analyst, but you will still need to cover the gaps of the rest on your own, which makes me question how much worth I will be for my career switch in the future to like an AE.&lt;/p&gt;\n\n&lt;p&gt;Data Engineering Camp:&lt;/p&gt;\n\n&lt;p&gt;They have been touted pretty well in this subreddit and the course founder is pretty active on this subreddit as well. His course is the shortest of the three and he seems to cover all of the key bits in the DE toolbox and expectations including Lakehouses (Spark, Databricks) and Streaming (Kafka). However, I am not sure all of this coverage would make me come out of it effective enough to be taken seriously for a career change without further supplementation. It sounds it is great if I wanted to be like a TPM that would work more with an AE/DE team though.&lt;/p&gt;\n\n&lt;p&gt;Also from a instruction POV, I will have to take classes between 2AM to 5AM since I am in the West Coast US and they are being taught from Australia.&lt;/p&gt;\n\n&lt;p&gt;WeCloudData:&lt;/p&gt;\n\n&lt;p&gt;This one seems to be in the middle of Jigsaw Labs and DEC. It is six months and seems to cover all of the basis that Jigsaw and DEC is doing, but not in the detail on the Python/SQL front like Jigsaw. Therefore, I feel like this one will get me the good grasp of what I need to know as an AE/DE, but I am leery if it still lacks the best approach to give me the core foundations needed for my Python/SQL chops. They also provide six months of mentorship and career prep after the course but not externship if you do the part-time program.&lt;/p&gt;\n\n&lt;p&gt;Therefore, I am torn if I trade off the philosophy of Jigsaw Labs to teach you the true fundamentals but at the expense of learning the higher-level tools/processes that is also needed, or do a more comprehensive curriculum like DEC or WeCloudData coming from my own experience and aspirations.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions is appreciated as I want to do the best bootcamp that would yield me the best foot forward for my next career move. I know a good number of you would tell me to don&amp;#39;t bother with any of them and just self-learn (cheaper), but trust me, I learn the best by being instructed, especially if I want to be taught the foundations correctly.&lt;/p&gt;\n\n&lt;p&gt;Thx!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zn1vhc", "is_robot_indexable": true, "report_reasons": null, "author": "StrikeSaber47", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zn1vhc/best_de_bootcamp_based_on_my_experience_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zn1vhc/best_de_bootcamp_based_on_my_experience_and/", "subreddit_subscribers": 83094, "created_utc": 1671152263.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A few years ago I thought it was dying but sadly tools like dbt seem to mean it's making a resurgence. I prefer a general purpose programming language like Python in all circumstances. A dataframe-style API gives you everything you need for working with data. Discuss.", "author_fullname": "t2_10iqu1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "does anyone else hate SQL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_znqf92", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.41, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1671231985.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671228245.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A few years ago I thought it was dying but sadly tools like dbt seem to mean it&amp;#39;s making a resurgence. I prefer a general purpose programming language like Python in all circumstances. A dataframe-style API gives you everything you need for working with data. Discuss.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "znqf92", "is_robot_indexable": true, "report_reasons": null, "author": "Sister_Ray_", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/znqf92/does_anyone_else_hate_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/znqf92/does_anyone_else_hate_sql/", "subreddit_subscribers": 83094, "created_utc": 1671228245.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "You can detect fraud or other irregularities in your data warehousing by looking for patterns in the data that don't seem to make sense, such as if a company is seeing a lot of orders from a certain country, but the orders do not seem to be legitimate. Another way to detect fraud is to look for sudden changes in the data: if a company's sales suddenly increase by a large amount, this could be a sign that someone is trying to fraudulently inflate the company's sales figures. Finally, you can use data warehousing to detect fraud by comparing the data from different sources: if your accounting system reports that your sales figures are higher than they actually are, but your data warehouse shows them lower than they actually are\u2014or vice versa\u2014this could be a sign of fraud.", "author_fullname": "t2_gk917caz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Detecting fraud or other irregularities with Data Warehousing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zn0mgd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.17, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671148815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;You can detect fraud or other irregularities in your data warehousing by looking for patterns in the data that don&amp;#39;t seem to make sense, such as if a company is seeing a lot of orders from a certain country, but the orders do not seem to be legitimate. Another way to detect fraud is to look for sudden changes in the data: if a company&amp;#39;s sales suddenly increase by a large amount, this could be a sign that someone is trying to fraudulently inflate the company&amp;#39;s sales figures. Finally, you can use data warehousing to detect fraud by comparing the data from different sources: if your accounting system reports that your sales figures are higher than they actually are, but your data warehouse shows them lower than they actually are\u2014or vice versa\u2014this could be a sign of fraud.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zn0mgd", "is_robot_indexable": true, "report_reasons": null, "author": "joyful_reader", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zn0mgd/detecting_fraud_or_other_irregularities_with_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zn0mgd/detecting_fraud_or_other_irregularities_with_data/", "subreddit_subscribers": 83094, "created_utc": 1671148815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Now that [I got your attention](https://meta.wikimedia.org/wiki/Cunningham%27s_Law), please help me find an extraction software/service that fits my needs.\n\nI am looking for 2 key features in specific:\n\n1. Possibility to connect to a source database (Postgresql) with SSH tunnelling\n2. S3 is a possible destination\n3. Bonus: possibly volume based pricing, we're a small team with small data and have some budget constraints\n\nI was testing Rivery but for some reason I didn't manage to make SSH tunnelling work. Then I tested AirByte with the same configuration. SSH tunnelling works flawlessly there, but God knows why, AirByte puts data in a blob when loading to S3, which adds an unnecessary normalization step that I'd like to avoid.\n\nThrow me a bone?", "author_fullname": "t2_zwbba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fivetran is the best ETL tool out there", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_znd2a7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1671192402.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671192170.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Now that &lt;a href=\"https://meta.wikimedia.org/wiki/Cunningham%27s_Law\"&gt;I got your attention&lt;/a&gt;, please help me find an extraction software/service that fits my needs.&lt;/p&gt;\n\n&lt;p&gt;I am looking for 2 key features in specific:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Possibility to connect to a source database (Postgresql) with SSH tunnelling&lt;/li&gt;\n&lt;li&gt;S3 is a possible destination&lt;/li&gt;\n&lt;li&gt;Bonus: possibly volume based pricing, we&amp;#39;re a small team with small data and have some budget constraints&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I was testing Rivery but for some reason I didn&amp;#39;t manage to make SSH tunnelling work. Then I tested AirByte with the same configuration. SSH tunnelling works flawlessly there, but God knows why, AirByte puts data in a blob when loading to S3, which adds an unnecessary normalization step that I&amp;#39;d like to avoid.&lt;/p&gt;\n\n&lt;p&gt;Throw me a bone?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "znd2a7", "is_robot_indexable": true, "report_reasons": null, "author": "wtfzambo", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/znd2a7/fivetran_is_the_best_etl_tool_out_there/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/znd2a7/fivetran_is_the_best_etl_tool_out_there/", "subreddit_subscribers": 83094, "created_utc": 1671192170.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}