{"kind": "Listing", "data": {"after": "t3_zbzdwn", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_4pdfnevq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "It ain\u2019t much but it\u2019s my first big boy storage drive. Question: I always run a full error scan on new HDD\u2019s with HD Tune, is this necessary to ensure a full working drive or is it overkill? Should I just check SMART attributes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 131, "top_awarded_type": null, "hide_score": false, "name": "t3_zbwgvx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 352, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 352, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/7ft42o2OWVVk0FtqVgueHnuiThbRe9UxVA7XKluRyGs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670116527.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/zw7rk3gwpt3a1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/zw7rk3gwpt3a1.jpg?auto=webp&amp;s=e97b5aafd00bd941ba02381a65fc914e7bc9bf64", "width": 3230, "height": 3023}, "resolutions": [{"url": "https://preview.redd.it/zw7rk3gwpt3a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f159d24e45a01001664e369166245b9e4a772a46", "width": 108, "height": 101}, {"url": "https://preview.redd.it/zw7rk3gwpt3a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0d7ab40bcc0d6c048d16a84f1610e70a25fdf98a", "width": 216, "height": 202}, {"url": "https://preview.redd.it/zw7rk3gwpt3a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=62a8adb7a082bc89cc7e6a0a733b92afcd27a1fd", "width": 320, "height": 299}, {"url": "https://preview.redd.it/zw7rk3gwpt3a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e345b8f89e9e3a68afd68fe4b5f4df13279f5fb1", "width": 640, "height": 598}, {"url": "https://preview.redd.it/zw7rk3gwpt3a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3ff5ce3629084f5b39ef48b839f8c5daefe8c7d5", "width": 960, "height": 898}, {"url": "https://preview.redd.it/zw7rk3gwpt3a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4e74645d34dbbf9ba54ec09955c1ec780f4f18c1", "width": 1080, "height": 1010}], "variants": {}, "id": "Gp4u_8kPc6aAjHGiIxzVH_2Y6Ej3bwlFsPyeOTLCAzQ"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zbwgvx", "is_robot_indexable": true, "report_reasons": null, "author": "Valor_X", "discussion_type": null, "num_comments": 83, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zbwgvx/it_aint_much_but_its_my_first_big_boy_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/zw7rk3gwpt3a1.jpg", "subreddit_subscribers": 657492, "created_utc": 1670116527.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "What's your set up, specs, your process and what titles?  Curious.", "author_fullname": "t2_tk9orzbm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is anyone scanning print magazines?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zcpens", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 42, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 42, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670196224.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What&amp;#39;s your set up, specs, your process and what titles?  Curious.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "zcpens", "is_robot_indexable": true, "report_reasons": null, "author": "cdnrtrt", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zcpens/is_anyone_scanning_print_magazines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zcpens/is_anyone_scanning_print_magazines/", "subreddit_subscribers": 657492, "created_utc": 1670196224.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "If I'd like to backup important files to a 2TB external SSD that is stored safely regarding humidity and temperature.  Can I expect that drive to remain functional and the data intact for the long term, say 10+ years?", "author_fullname": "t2_8y2c4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is an SSD reliable long term storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zcfujb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670175218.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If I&amp;#39;d like to backup important files to a 2TB external SSD that is stored safely regarding humidity and temperature.  Can I expect that drive to remain functional and the data intact for the long term, say 10+ years?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zcfujb", "is_robot_indexable": true, "report_reasons": null, "author": "x0y0z0", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zcfujb/is_an_ssd_reliable_long_term_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zcfujb/is_an_ssd_reliable_long_term_storage/", "subreddit_subscribers": 657492, "created_utc": 1670175218.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I essentially need a software that would download webpages on my pc in a viewable format, just like The Wayback Machine does, and would also download the embedded videos. I tried out Singlefile, but it saved the webpages in a different format from the originals, while i want to preserve the webpages with their original look and interface.", "author_fullname": "t2_13vklp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I wish to make my own webarchive, that would store webpages on my pc. What's the software that i should use?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zc9qu7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670160257.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I essentially need a software that would download webpages on my pc in a viewable format, just like The Wayback Machine does, and would also download the embedded videos. I tried out Singlefile, but it saved the webpages in a different format from the originals, while i want to preserve the webpages with their original look and interface.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zc9qu7", "is_robot_indexable": true, "report_reasons": null, "author": "BadWi-Fi", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zc9qu7/i_wish_to_make_my_own_webarchive_that_would_store/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zc9qu7/i_wish_to_make_my_own_webarchive_that_would_store/", "subreddit_subscribers": 657492, "created_utc": 1670160257.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "On windows explorer when I go searching through my hdd, theres a long pause on every folder as it scans and builds a directory file tree from scratch every single time. \n\nThese folders haven\u2019t changed in months, maybe years, theres no need to rebuild it so often.\n\nIs there a software / hardware combo that will place all the filenames and directories on a dedicated NVME for instant browsing? And then do a minor delta update as things change?\n\nI\u2019m ok with the actual hdd files themselves being slow and taking a while to load.\n\nThanks in advance", "author_fullname": "t2_3mjejfmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Software/hardware to cache filenames &amp; directories for instantaneous windows explorer browsing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zbx5wq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1670119702.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670118561.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;On windows explorer when I go searching through my hdd, theres a long pause on every folder as it scans and builds a directory file tree from scratch every single time. &lt;/p&gt;\n\n&lt;p&gt;These folders haven\u2019t changed in months, maybe years, theres no need to rebuild it so often.&lt;/p&gt;\n\n&lt;p&gt;Is there a software / hardware combo that will place all the filenames and directories on a dedicated NVME for instant browsing? And then do a minor delta update as things change?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m ok with the actual hdd files themselves being slow and taking a while to load.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zbx5wq", "is_robot_indexable": true, "report_reasons": null, "author": "freshairproject", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zbx5wq/softwarehardware_to_cache_filenames_directories/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zbx5wq/softwarehardware_to_cache_filenames_directories/", "subreddit_subscribers": 657492, "created_utc": 1670118561.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am a newbie and I am planning on building a self-hosted NAS system for home use for the first time. After some research, I am thinking of buying a **RaspberryPi4 (4GB)**, attaching an external SSD via USB, and installing **OpenMediaVault** on it. These are my requirements:\n\n1. I need *data durability*\n2. I need *data encryption*\n3. I need to read/write data from various OSes (*Windows, MacOS, Linux*)\n\nWould this setup cover all my points above? I am mostly worried about data durability. I guess I can plug in a secondary SSD and backup my data every now and then. But how do I prevent data corruption/bitrot in the long run? Please also let me know if you would recommend different hardware/software.\n\nFor the sake of completeness: I don\u2019t need to stream movies, I don\u2019t need to store a lot of data (256GB is more than enough), and I don\u2019t need high availability (in fact, I only intend to boot the system every now and then).\n\nThanks!", "author_fullname": "t2_urev629d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building a NAS system for the first time", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zclww6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670188484.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a newbie and I am planning on building a self-hosted NAS system for home use for the first time. After some research, I am thinking of buying a &lt;strong&gt;RaspberryPi4 (4GB)&lt;/strong&gt;, attaching an external SSD via USB, and installing &lt;strong&gt;OpenMediaVault&lt;/strong&gt; on it. These are my requirements:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I need &lt;em&gt;data durability&lt;/em&gt;&lt;/li&gt;\n&lt;li&gt;I need &lt;em&gt;data encryption&lt;/em&gt;&lt;/li&gt;\n&lt;li&gt;I need to read/write data from various OSes (&lt;em&gt;Windows, MacOS, Linux&lt;/em&gt;)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Would this setup cover all my points above? I am mostly worried about data durability. I guess I can plug in a secondary SSD and backup my data every now and then. But how do I prevent data corruption/bitrot in the long run? Please also let me know if you would recommend different hardware/software.&lt;/p&gt;\n\n&lt;p&gt;For the sake of completeness: I don\u2019t need to stream movies, I don\u2019t need to store a lot of data (256GB is more than enough), and I don\u2019t need high availability (in fact, I only intend to boot the system every now and then).&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zclww6", "is_robot_indexable": true, "report_reasons": null, "author": "Responsible-Dig-7540", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zclww6/building_a_nas_system_for_the_first_time/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zclww6/building_a_nas_system_for_the_first_time/", "subreddit_subscribers": 657492, "created_utc": 1670188484.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I finally installed the new Google Drive app. It's definitely an improvement over the old Backup and Sync, however there's one thing I am unclear on, and I can't find the answer anywhere.\n\nYou have the option to mirror certain folders from your computer. All Google says is that it will keep files and folders the same in both places. What I interpret this to mean is, while syncing is happening, it will keep track of where changes are made and then make the same changes in the other place. If you add a file on your computer, it adds it to the cloud. If you delete a file in the cloud, it deletes it from your computer. It knows where the change is made, and makes the same change in the other place.\n\nBut what if I turn off syncing for 2 months, then I delete 2 files from my computer's folder, then 3 months later I turn on syncing again. How is Google Drive going to know whether files have been deleted from my local storage or added to Drive? Is it going to add the files back to my local storage or is it going to delete them from Drive? What will it use as reference?\n\nIn the old Backup and Sync, there were options where you could tell it what to do in these scenarios. I messed up once and after moving a whole bunch of files from a mirrored folder while it wasn't being synced, I then resubscribed to Drive and it re-added all of those files, and now that folder is a complete mess, 2 years later I still haven't fixed it. I wanna make sure this doesn't happen again, but in the new app there are no settings to set a behavior for when it discovers changes that were made while syncing was off.\n\nThanks, any input is appreciated.", "author_fullname": "t2_7bllpt0q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does Google Drive mirroring know where changes have been made when syncing is turned off?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zcbxrf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670166223.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I finally installed the new Google Drive app. It&amp;#39;s definitely an improvement over the old Backup and Sync, however there&amp;#39;s one thing I am unclear on, and I can&amp;#39;t find the answer anywhere.&lt;/p&gt;\n\n&lt;p&gt;You have the option to mirror certain folders from your computer. All Google says is that it will keep files and folders the same in both places. What I interpret this to mean is, while syncing is happening, it will keep track of where changes are made and then make the same changes in the other place. If you add a file on your computer, it adds it to the cloud. If you delete a file in the cloud, it deletes it from your computer. It knows where the change is made, and makes the same change in the other place.&lt;/p&gt;\n\n&lt;p&gt;But what if I turn off syncing for 2 months, then I delete 2 files from my computer&amp;#39;s folder, then 3 months later I turn on syncing again. How is Google Drive going to know whether files have been deleted from my local storage or added to Drive? Is it going to add the files back to my local storage or is it going to delete them from Drive? What will it use as reference?&lt;/p&gt;\n\n&lt;p&gt;In the old Backup and Sync, there were options where you could tell it what to do in these scenarios. I messed up once and after moving a whole bunch of files from a mirrored folder while it wasn&amp;#39;t being synced, I then resubscribed to Drive and it re-added all of those files, and now that folder is a complete mess, 2 years later I still haven&amp;#39;t fixed it. I wanna make sure this doesn&amp;#39;t happen again, but in the new app there are no settings to set a behavior for when it discovers changes that were made while syncing was off.&lt;/p&gt;\n\n&lt;p&gt;Thanks, any input is appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zcbxrf", "is_robot_indexable": true, "report_reasons": null, "author": "Qbccd", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zcbxrf/how_does_google_drive_mirroring_know_where/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zcbxrf/how_does_google_drive_mirroring_know_where/", "subreddit_subscribers": 657492, "created_utc": 1670166223.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey was told to come here for help on YouTube archiving. Was wondering if anyone could help or already archived a specific channel that\u2019s about to whip most of their videos for obvious reasons. [WTT](https://youtube.com/@FilmColossus) . I just want some help archiving this somehow. \n\nSide question: any website that can hold up a pretty decent amount of storage? Im currently digitally saving all the music I have such as cds and digital copies and using a 36 gig usb to contain everything. As of rn though it\u2019s halfway full and I\u2019m not half way done ripping every cd I got or storing everything. They\u2019re all also just 360k MP3\u2019s not even flacs. Was just curious if any websites other than google drive and megaz can carry about a terabyte", "author_fullname": "t2_2vchdsgo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dumb questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zcku2b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1670186162.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey was told to come here for help on YouTube archiving. Was wondering if anyone could help or already archived a specific channel that\u2019s about to whip most of their videos for obvious reasons. &lt;a href=\"https://youtube.com/@FilmColossus\"&gt;WTT&lt;/a&gt; . I just want some help archiving this somehow. &lt;/p&gt;\n\n&lt;p&gt;Side question: any website that can hold up a pretty decent amount of storage? Im currently digitally saving all the music I have such as cds and digital copies and using a 36 gig usb to contain everything. As of rn though it\u2019s halfway full and I\u2019m not half way done ripping every cd I got or storing everything. They\u2019re all also just 360k MP3\u2019s not even flacs. Was just curious if any websites other than google drive and megaz can carry about a terabyte&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/LcLRsBy2f4xzshFq9WPZ9rpVSGdE4dtMGxjP8ydXizM.jpg?auto=webp&amp;s=66de85dc9604e602cfb79d997b2a05d3b70fe90e", "width": 900, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/LcLRsBy2f4xzshFq9WPZ9rpVSGdE4dtMGxjP8ydXizM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2260eb23365093d92d8ccd6a7ed57c7094e38ff0", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/LcLRsBy2f4xzshFq9WPZ9rpVSGdE4dtMGxjP8ydXizM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=569b9f5921e61054b7ee00f64db0b637e5d118b2", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/LcLRsBy2f4xzshFq9WPZ9rpVSGdE4dtMGxjP8ydXizM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=165b94ceabb3e46c01b6f6831ee7df0fcd5a0c4c", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/LcLRsBy2f4xzshFq9WPZ9rpVSGdE4dtMGxjP8ydXizM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7755ea2a37b59d2713e16732d7ad9fe5a8ede944", "width": 640, "height": 640}], "variants": {}, "id": "_acT_NFugCHwq5oT8VW0QMgmpy_lBvfhcjc79_zvfUw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zcku2b", "is_robot_indexable": true, "report_reasons": null, "author": "I_A_M_N_O_B_O_D_Y", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zcku2b/dumb_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zcku2b/dumb_questions/", "subreddit_subscribers": 657492, "created_utc": 1670186162.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_ur0l2j2w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Deal Alert] Seagate Exos X14 12TB HDD (Renewed) for $130", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "sale", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zc4j5h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Sale", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1670142915.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "amazon.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.amazon.com/dp/B07W869RZ3", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ef8232de-b94e-11eb-ba29-0ed106a6f983", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zc4j5h", "is_robot_indexable": true, "report_reasons": null, "author": "willie_style", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zc4j5h/deal_alert_seagate_exos_x14_12tb_hdd_renewed_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.amazon.com/dp/B07W869RZ3", "subreddit_subscribers": 657492, "created_utc": 1670142915.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "A friend of mine picked up several hundred 250gb m.2 SSDs in the wake of a business closing down, and I'm trying to think of potential uses for them. Are there any relatively cheap / efficient ways to connect them in a large storage array, RAID or otherwise?", "author_fullname": "t2_6qrxw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to use a large amount of m.2 drives for data storage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zbwl8p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670116870.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A friend of mine picked up several hundred 250gb m.2 SSDs in the wake of a business closing down, and I&amp;#39;m trying to think of potential uses for them. Are there any relatively cheap / efficient ways to connect them in a large storage array, RAID or otherwise?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zbwl8p", "is_robot_indexable": true, "report_reasons": null, "author": "atrere", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zbwl8p/how_to_use_a_large_amount_of_m2_drives_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zbwl8p/how_to_use_a_large_amount_of_m2_drives_for_data/", "subreddit_subscribers": 657492, "created_utc": 1670116870.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Customers hand us their insurance cards on their cell phones.  Sure, we could have them send us a screenshot and connect it later, but does anyone have a TWAIN/WIA piece of hardware (like a flatbed scanner) that will work?  The FI-65f scanner definitely doesn't have the refresh rate necessary.", "author_fullname": "t2_104dn8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Flatbed scanner to capture image from cellphone screen", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zcq49z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670197839.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Customers hand us their insurance cards on their cell phones.  Sure, we could have them send us a screenshot and connect it later, but does anyone have a TWAIN/WIA piece of hardware (like a flatbed scanner) that will work?  The FI-65f scanner definitely doesn&amp;#39;t have the refresh rate necessary.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zcq49z", "is_robot_indexable": true, "report_reasons": null, "author": "spittlbm", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zcq49z/flatbed_scanner_to_capture_image_from_cellphone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zcq49z/flatbed_scanner_to_capture_image_from_cellphone/", "subreddit_subscribers": 657492, "created_utc": 1670197839.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I recently aquired a small box of photo disks that have various family (and extended) members on them. I am looking for a solution for copying, storing, and hosting these phtotos. Some of these disks have a folder with the photos, others are from a photo lab and contain some kind of EXE file and a folder with the photos.\n\nWhat is the best way to copy these disks? Copy paste the files?then for stoage and hosting what would you recomend ( r/selfhosted is probably the better place to ask this). I was thinking of using photoprism, I am not sure if there is somthing better for this.", "author_fullname": "t2_secy5xku", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Solution for copying, storing, and hosting personal photo disks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zcpxwn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670197428.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently aquired a small box of photo disks that have various family (and extended) members on them. I am looking for a solution for copying, storing, and hosting these phtotos. Some of these disks have a folder with the photos, others are from a photo lab and contain some kind of EXE file and a folder with the photos.&lt;/p&gt;\n\n&lt;p&gt;What is the best way to copy these disks? Copy paste the files?then for stoage and hosting what would you recomend ( &lt;a href=\"/r/selfhosted\"&gt;r/selfhosted&lt;/a&gt; is probably the better place to ask this). I was thinking of using photoprism, I am not sure if there is somthing better for this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zcpxwn", "is_robot_indexable": true, "report_reasons": null, "author": "Downtown_Relief810", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zcpxwn/solution_for_copying_storing_and_hosting_personal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zcpxwn/solution_for_copying_storing_and_hosting_personal/", "subreddit_subscribers": 657492, "created_utc": 1670197428.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I work in the electric refurbishment business and found this HBA card. I want to connect it to my NetApp DS2246, but I just cant figure out how many drives this card supportes. When I google it, it shows me the internel sas Version.", "author_fullname": "t2_1byfvjam", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How many Drives can be connected to a Dell Perc h200e 12dnw HBA Card?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zcitfq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670181725.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work in the electric refurbishment business and found this HBA card. I want to connect it to my NetApp DS2246, but I just cant figure out how many drives this card supportes. When I google it, it shows me the internel sas Version.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zcitfq", "is_robot_indexable": true, "report_reasons": null, "author": "PhantomSlicer", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zcitfq/how_many_drives_can_be_connected_to_a_dell_perc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zcitfq/how_many_drives_can_be_connected_to_a_dell_perc/", "subreddit_subscribers": 657492, "created_utc": 1670181725.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Let's say 10 TB that I have in Azure", "author_fullname": "t2_xnkh1lx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "This cloud is getting expensive. But I have some TB that I need to share with my colleagues. Should I move to a NAS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zccb5h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670167112.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s say 10 TB that I have in Azure&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zccb5h", "is_robot_indexable": true, "report_reasons": null, "author": "rlopez7", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zccb5h/this_cloud_is_getting_expensive_but_i_have_some/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zccb5h/this_cloud_is_getting_expensive_but_i_have_some/", "subreddit_subscribers": 657492, "created_utc": 1670167112.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Multiple Cloud Sync Task only one will run other says \"Locking local path\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zcq754", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_3q045jle", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "truenas", "selftext": "I am running TrueNAS core on a Dell r710 with a md1200 connected with a 9200e in IT mode. I have one pool with 2 vdevs. I'm currently trying to make a backup of a MinIO server. I have SYNC tasks for each bucket and only one will run at a time. Any others say \" Locking local path\". Also I have tried a few things to speed up the transfer. Currently I hover between 10-25 Megabits/is. The files are unzipped and there are millions of small files. I have tried to increase parrell transfers and after 15 the speed starts to slow dow. Using fast listing seemed to help a bit. Curious if there are any thoughts on ways to speed this up. I'm backing up around 30tb.", "author_fullname": "t2_3q045jle", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Multiple Cloud Sync Task only one will run other says \"Locking local path\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/truenas", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zckx5c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "CORE", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670186356.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.truenas", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am running TrueNAS core on a Dell r710 with a md1200 connected with a 9200e in IT mode. I have one pool with 2 vdevs. I&amp;#39;m currently trying to make a backup of a MinIO server. I have SYNC tasks for each bucket and only one will run at a time. Any others say &amp;quot; Locking local path&amp;quot;. Also I have tried a few things to speed up the transfer. Currently I hover between 10-25 Megabits/is. The files are unzipped and there are millions of small files. I have tried to increase parrell transfers and after 15 the speed starts to slow dow. Using fast listing seemed to help a bit. Curious if there are any thoughts on ways to speed this up. I&amp;#39;m backing up around 30tb.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "812170a6-012a-11ec-9a02-322033ef4031", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_zna4k", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#00d0d6", "id": "zckx5c", "is_robot_indexable": true, "report_reasons": null, "author": "kylewizerd15", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/truenas/comments/zckx5c/multiple_cloud_sync_task_only_one_will_run_other/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/truenas/comments/zckx5c/multiple_cloud_sync_task_only_one_will_run_other/", "subreddit_subscribers": 17440, "created_utc": 1670186356.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1670198024.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.truenas", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/truenas/comments/zckx5c/multiple_cloud_sync_task_only_one_will_run_other/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zcq754", "is_robot_indexable": true, "report_reasons": null, "author": "kylewizerd15", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_zckx5c", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zcq754/multiple_cloud_sync_task_only_one_will_run_other/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/truenas/comments/zckx5c/multiple_cloud_sync_task_only_one_will_run_other/", "subreddit_subscribers": 657492, "created_utc": 1670198024.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I was copying files from one drive to the Seagate drive in question (so I don't care about getting the data from *that* \\- I just want it working so then I can copy to it again). My computer completely froze (I was doing another copy with 2 other drives at the same time - those ones are fine though, funnily enough) and had no choice but to restart it during the copy.\n\nThe main source drive was fine (thank goodness!) but the Segate 5TB not so much. I don't think it's a mechanical failure (in the platter / read/write head sense) - it spins fine, no beeping or any unusual sounds. But when I plug it in, it disconnects after a few seconds. When opening disk management on windows, it shows \"Unknown Not initialized\" for a split second. Given the circumstances of the failure, faulty cables wouldn't be a thing - although I tried different ones anyway to be doubly sure. So clearly some hardware issue, but I doubt mechanical - so I opened up the ensure (without snapping the clips somehow, lol).\n\nI put the hard drive inside a spare enclosure. Plugged it in - it didn't disconnect, but it wasn't showing up normally. I go on disk management, and I can see again \"Unknown Not initialized\". Again, I don't care about getting data from this, so I right-clicked on \"initialize\". It says \"The request failed due to a fatal device hardware error.\" So definitely software will not work whatsoever. This leads me to believe I fried the control board / PCB, which provides an interface for the mechanical drive to communicate with the computer. Thus, I can't access the drive.\n\nThe model of the PCB is 100721570 REV E.\n\nAm I correct in surmising that this is a PCB failure, and that I simply need to buy a replacement ([AliExpress](https://www.aliexpress.com/item/1005003221829198.html) seems to be the only place I can buy this)? And apparently I need to copy the BIOS firmware from my original PCB to the replacement - is that true?\n\nOr is it really a mechanical failure?", "author_fullname": "t2_6ol01vwr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seagate Expansion Desktop 5TB External Hard Drive (ST5000DM000) spins fine, connects but then disconnects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zcp1ja", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670195332.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was copying files from one drive to the Seagate drive in question (so I don&amp;#39;t care about getting the data from &lt;em&gt;that&lt;/em&gt; - I just want it working so then I can copy to it again). My computer completely froze (I was doing another copy with 2 other drives at the same time - those ones are fine though, funnily enough) and had no choice but to restart it during the copy.&lt;/p&gt;\n\n&lt;p&gt;The main source drive was fine (thank goodness!) but the Segate 5TB not so much. I don&amp;#39;t think it&amp;#39;s a mechanical failure (in the platter / read/write head sense) - it spins fine, no beeping or any unusual sounds. But when I plug it in, it disconnects after a few seconds. When opening disk management on windows, it shows &amp;quot;Unknown Not initialized&amp;quot; for a split second. Given the circumstances of the failure, faulty cables wouldn&amp;#39;t be a thing - although I tried different ones anyway to be doubly sure. So clearly some hardware issue, but I doubt mechanical - so I opened up the ensure (without snapping the clips somehow, lol).&lt;/p&gt;\n\n&lt;p&gt;I put the hard drive inside a spare enclosure. Plugged it in - it didn&amp;#39;t disconnect, but it wasn&amp;#39;t showing up normally. I go on disk management, and I can see again &amp;quot;Unknown Not initialized&amp;quot;. Again, I don&amp;#39;t care about getting data from this, so I right-clicked on &amp;quot;initialize&amp;quot;. It says &amp;quot;The request failed due to a fatal device hardware error.&amp;quot; So definitely software will not work whatsoever. This leads me to believe I fried the control board / PCB, which provides an interface for the mechanical drive to communicate with the computer. Thus, I can&amp;#39;t access the drive.&lt;/p&gt;\n\n&lt;p&gt;The model of the PCB is 100721570 REV E.&lt;/p&gt;\n\n&lt;p&gt;Am I correct in surmising that this is a PCB failure, and that I simply need to buy a replacement (&lt;a href=\"https://www.aliexpress.com/item/1005003221829198.html\"&gt;AliExpress&lt;/a&gt; seems to be the only place I can buy this)? And apparently I need to copy the BIOS firmware from my original PCB to the replacement - is that true?&lt;/p&gt;\n\n&lt;p&gt;Or is it really a mechanical failure?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zcp1ja", "is_robot_indexable": true, "report_reasons": null, "author": "craxing", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zcp1ja/seagate_expansion_desktop_5tb_external_hard_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zcp1ja/seagate_expansion_desktop_5tb_external_hard_drive/", "subreddit_subscribers": 657492, "created_utc": 1670195332.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Anyone bought any used HGST drives? How was your experience?\n\nA local shop has these used HGST 6TB HUS726060ALA640 drives for $40 a piece. The power on time shows around 2500 days and health 100%.\n\nThe use case would be a TrueNAS server and the drives would be in ZFS RAID 6 or raidz2 (whatever they call it). I would have another backup of the files stored on another machine on 2 larger drives in mirror.\n\nI am wondering if this is a good deal or if I should stay away? What would you do?", "author_fullname": "t2_13pkdc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Used HGST drives - 6TB HUS726060ALA640", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zckh9t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1670186985.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670185386.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone bought any used HGST drives? How was your experience?&lt;/p&gt;\n\n&lt;p&gt;A local shop has these used HGST 6TB HUS726060ALA640 drives for $40 a piece. The power on time shows around 2500 days and health 100%.&lt;/p&gt;\n\n&lt;p&gt;The use case would be a TrueNAS server and the drives would be in ZFS RAID 6 or raidz2 (whatever they call it). I would have another backup of the files stored on another machine on 2 larger drives in mirror.&lt;/p&gt;\n\n&lt;p&gt;I am wondering if this is a good deal or if I should stay away? What would you do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zckh9t", "is_robot_indexable": true, "report_reasons": null, "author": "newpain01", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zckh9t/used_hgst_drives_6tb_hus726060ala640/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zckh9t/used_hgst_drives_6tb_hus726060ala640/", "subreddit_subscribers": 657492, "created_utc": 1670185386.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, \n\nI have a **crashplan for small business** subscription and I need help in understanding the difference in sizes of my backup sets as they are presented in the:\n\n\\- Windows App\n\n\\- web application\n\nOn windows App I see the \"predefined\" backup set occupying 3.1 TB while on the web application I see the (I guess) overall size at 2.4 TB (with a Selected at 2.9 TB that I don't know the meaning).\n\nDo you know why?\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n[on windows application](https://preview.redd.it/izt8bls6hw3a1.png?width=569&amp;format=png&amp;auto=webp&amp;s=d7bd6e5cb3e92e5a9ba694cfe2848ef97477c5c8)\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n[on web application](https://preview.redd.it/ytxyyuokhw3a1.png?width=798&amp;format=png&amp;auto=webp&amp;s=80401d7e8bbf8848cc3d1bb32a7188827a4227a2)\n\n&amp;#x200B;\n\nSecond question: I bought a new bigger drive since the one where a part of my \"predefined\" backup set of Crashplan is filling up.\n\nOf course i need to migrate the files without reuploading everything to the cloud.  \nMay I safely refer to the guide here under the \"Replace a drive\" section?\n\n[https://support.crashplan.com/hc/en-us/articles/8887084769037-Back-up-external-hard-drives-using-CrashPlan-for-Small-Business](https://support.crashplan.com/hc/en-us/articles/8887084769037-Back-up-external-hard-drives-using-CrashPlan-for-Small-Business)\n\nI found it not very clear for such a life critical task.\n\nDo anyone knows what I have to after connecting the new (empty) drive (a 6TB wd red)?\n\n  \n\n\n  \n\n\nThanks", "author_fullname": "t2_c5fwn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Crashplan (a couple questions about backup size and data migration)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ytxyyuokhw3a1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 44, "x": 108, "u": "https://preview.redd.it/ytxyyuokhw3a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1cb6f7dbaffdd31c5576a85fbd9fd3873e8aba24"}, {"y": 89, "x": 216, "u": "https://preview.redd.it/ytxyyuokhw3a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7968eb6bcc9f4b99725711f3751dc1c480cee158"}, {"y": 132, "x": 320, "u": "https://preview.redd.it/ytxyyuokhw3a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=02049126e1aa9a989c9b08ac5268f504f210e105"}, {"y": 264, "x": 640, "u": "https://preview.redd.it/ytxyyuokhw3a1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=3f42a06423d7ea56100e28c3a85ecbd0450db49c"}], "s": {"y": 330, "x": 798, "u": "https://preview.redd.it/ytxyyuokhw3a1.png?width=798&amp;format=png&amp;auto=webp&amp;s=80401d7e8bbf8848cc3d1bb32a7188827a4227a2"}, "id": "ytxyyuokhw3a1"}, "izt8bls6hw3a1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 128, "x": 108, "u": "https://preview.redd.it/izt8bls6hw3a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=75a72563db1419b955b71f243419ea068f9a4e19"}, {"y": 256, "x": 216, "u": "https://preview.redd.it/izt8bls6hw3a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6923699fc948f2d506fbc33878fb94f1fb7e3396"}, {"y": 380, "x": 320, "u": "https://preview.redd.it/izt8bls6hw3a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=cc0726664f11ef9dae201d564847262110732cd8"}], "s": {"y": 677, "x": 569, "u": "https://preview.redd.it/izt8bls6hw3a1.png?width=569&amp;format=png&amp;auto=webp&amp;s=d7bd6e5cb3e92e5a9ba694cfe2848ef97477c5c8"}, "id": "izt8bls6hw3a1"}}, "name": "t3_zcdf1r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.53, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ZcPe0NIvppKj7Q0nQBpK5e9yiGxiY9UiHhLoGoENDxg.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670169734.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, &lt;/p&gt;\n\n&lt;p&gt;I have a &lt;strong&gt;crashplan for small business&lt;/strong&gt; subscription and I need help in understanding the difference in sizes of my backup sets as they are presented in the:&lt;/p&gt;\n\n&lt;p&gt;- Windows App&lt;/p&gt;\n\n&lt;p&gt;- web application&lt;/p&gt;\n\n&lt;p&gt;On windows App I see the &amp;quot;predefined&amp;quot; backup set occupying 3.1 TB while on the web application I see the (I guess) overall size at 2.4 TB (with a Selected at 2.9 TB that I don&amp;#39;t know the meaning).&lt;/p&gt;\n\n&lt;p&gt;Do you know why?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/izt8bls6hw3a1.png?width=569&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d7bd6e5cb3e92e5a9ba694cfe2848ef97477c5c8\"&gt;on windows application&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ytxyyuokhw3a1.png?width=798&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=80401d7e8bbf8848cc3d1bb32a7188827a4227a2\"&gt;on web application&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Second question: I bought a new bigger drive since the one where a part of my &amp;quot;predefined&amp;quot; backup set of Crashplan is filling up.&lt;/p&gt;\n\n&lt;p&gt;Of course i need to migrate the files without reuploading everything to the cloud.&lt;br/&gt;\nMay I safely refer to the guide here under the &amp;quot;Replace a drive&amp;quot; section?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://support.crashplan.com/hc/en-us/articles/8887084769037-Back-up-external-hard-drives-using-CrashPlan-for-Small-Business\"&gt;https://support.crashplan.com/hc/en-us/articles/8887084769037-Back-up-external-hard-drives-using-CrashPlan-for-Small-Business&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I found it not very clear for such a life critical task.&lt;/p&gt;\n\n&lt;p&gt;Do anyone knows what I have to after connecting the new (empty) drive (a 6TB wd red)?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "8TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zcdf1r", "is_robot_indexable": true, "report_reasons": null, "author": "frankieta83", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/zcdf1r/crashplan_a_couple_questions_about_backup_size/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zcdf1r/crashplan_a_couple_questions_about_backup_size/", "subreddit_subscribers": 657492, "created_utc": 1670169734.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "How do I image Windows OS for recovery ? I currently know about macrium reflect but it does not support cloud backup. The laptop has active internet connection but lacks in storage space so I prefer to backup directly to cloud. Restoring won't be an issue as I will use 2nd PC to download the backup prior to restore. Any suggestions ?", "author_fullname": "t2_cy5bcth2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Image windows laptop for recovery", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zc9zzq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.61, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670161090.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do I image Windows OS for recovery ? I currently know about macrium reflect but it does not support cloud backup. The laptop has active internet connection but lacks in storage space so I prefer to backup directly to cloud. Restoring won&amp;#39;t be an issue as I will use 2nd PC to download the backup prior to restore. Any suggestions ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zc9zzq", "is_robot_indexable": true, "report_reasons": null, "author": "user655362020", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zc9zzq/image_windows_laptop_for_recovery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zc9zzq/image_windows_laptop_for_recovery/", "subreddit_subscribers": 657492, "created_utc": 1670161090.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Map of 18,237 files. More than 22 years of writing in text files. Plus OneNote to Markdown conversion.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 85, "top_awarded_type": null, "hide_score": false, "name": "t3_zbz2ob", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_5u03lo0g", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/0wRYgfL0sWiH27_64zi0ODCb5PGKnYSo0spWcyL7j70.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "ObsidianMD", "selftext": "More than 22 years of writing in text files, plus OneNote to Markdown conversion. Obsidian is a champion.\n\n&amp;#x200B;\n\n[Map of 18,237 files. More than 22 years of writing in text files. Plus OneNote to Markdown conversion.](https://preview.redd.it/dddbj34hbl3a1.png?width=1576&amp;format=png&amp;auto=webp&amp;s=4a9806d682cee92822545c05d0c3fd3e2f6b5d42)\n\nMany of these files were in LaTex, TeX, plain text, or Markdown. I wrote a script to add YAML front matter, then fed them to my Obsidian vault.\n\nObsidian synchronizes between four work computers via GitHub. I can even use Obsidian on my iPad.  I'm particular about having my writing accessible.\n\nVisual Studio Code helps with the cleanup of format and structure. My editor and assistant can access the GitHub repository.\n\nIn DOCX I have another eight thousand articles, marketing campaigns, and research. I will be using pandoc to convert, but I can search for them on Windows.\n\nWhat Obsidian has helped me do is write a book in 26 days. Now it's helping me with diagrams using LaTeX TikZ.\n\nMy workflow identified three prospect books (idea clusters). Obsidian helped me find a 22,000-word manuscript from 1998 plus a related 12-part newsletter series.\n\nI use a Kanban of my Work In Progress (WIP) and Editorial Status to pipeline deliverables. The focus now is finishing publications.\n\nTurns out I've been using Zettelkasten and commonplace books for years. But I won't be migrating my five thousand index cards and file cabinets soon.\n\nYet, I can reference engineering notebooks, card catalogs, and materials using tags. My physical records management already has tags I can search for in Obsidian.\n\nI have subject matter expertise in knowledge management, research methods, and publishing. Are you a knowledge worker who wants to be more productive? **Ask me anything.**", "author_fullname": "t2_5u03lo0g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Map of 18,237 files. More than 22 years of writing in text files. Plus OneNote to Markdown conversion.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/ObsidianMD", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 85, "top_awarded_type": null, "hide_score": false, "media_metadata": {"dddbj34hbl3a1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 65, "x": 108, "u": "https://preview.redd.it/dddbj34hbl3a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9ec0eab940de6a595bc386321f44e677396d161f"}, {"y": 131, "x": 216, "u": "https://preview.redd.it/dddbj34hbl3a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=00d90dddd6431b34247cce6234387e9fc6ac457c"}, {"y": 195, "x": 320, "u": "https://preview.redd.it/dddbj34hbl3a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=97e926854763517b2fd09a8ef66367286fc69d8a"}, {"y": 390, "x": 640, "u": "https://preview.redd.it/dddbj34hbl3a1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9fd08930d7566bd96c9279fa860105ce5a5bec35"}, {"y": 585, "x": 960, "u": "https://preview.redd.it/dddbj34hbl3a1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ed26bd48b8bf0fd90b296ed3d8a0796760c772e2"}, {"y": 658, "x": 1080, "u": "https://preview.redd.it/dddbj34hbl3a1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6cf85c22b2943c8b9f486c344c54bd67154530e2"}], "s": {"y": 961, "x": 1576, "u": "https://preview.redd.it/dddbj34hbl3a1.png?width=1576&amp;format=png&amp;auto=webp&amp;s=4a9806d682cee92822545c05d0c3fd3e2f6b5d42"}, "id": "dddbj34hbl3a1"}}, "name": "t3_zb4okr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 116, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 116, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/0wRYgfL0sWiH27_64zi0ODCb5PGKnYSo0spWcyL7j70.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670032787.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.ObsidianMD", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;More than 22 years of writing in text files, plus OneNote to Markdown conversion. Obsidian is a champion.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/dddbj34hbl3a1.png?width=1576&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4a9806d682cee92822545c05d0c3fd3e2f6b5d42\"&gt;Map of 18,237 files. More than 22 years of writing in text files. Plus OneNote to Markdown conversion.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Many of these files were in LaTex, TeX, plain text, or Markdown. I wrote a script to add YAML front matter, then fed them to my Obsidian vault.&lt;/p&gt;\n\n&lt;p&gt;Obsidian synchronizes between four work computers via GitHub. I can even use Obsidian on my iPad.  I&amp;#39;m particular about having my writing accessible.&lt;/p&gt;\n\n&lt;p&gt;Visual Studio Code helps with the cleanup of format and structure. My editor and assistant can access the GitHub repository.&lt;/p&gt;\n\n&lt;p&gt;In DOCX I have another eight thousand articles, marketing campaigns, and research. I will be using pandoc to convert, but I can search for them on Windows.&lt;/p&gt;\n\n&lt;p&gt;What Obsidian has helped me do is write a book in 26 days. Now it&amp;#39;s helping me with diagrams using LaTeX TikZ.&lt;/p&gt;\n\n&lt;p&gt;My workflow identified three prospect books (idea clusters). Obsidian helped me find a 22,000-word manuscript from 1998 plus a related 12-part newsletter series.&lt;/p&gt;\n\n&lt;p&gt;I use a Kanban of my Work In Progress (WIP) and Editorial Status to pipeline deliverables. The focus now is finishing publications.&lt;/p&gt;\n\n&lt;p&gt;Turns out I&amp;#39;ve been using Zettelkasten and commonplace books for years. But I won&amp;#39;t be migrating my five thousand index cards and file cabinets soon.&lt;/p&gt;\n\n&lt;p&gt;Yet, I can reference engineering notebooks, card catalogs, and materials using tags. My physical records management already has tags I can search for in Obsidian.&lt;/p&gt;\n\n&lt;p&gt;I have subject matter expertise in knowledge management, research methods, and publishing. Are you a knowledge worker who wants to be more productive? &lt;strong&gt;Ask me anything.&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2mz3dr", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zb4okr", "is_robot_indexable": true, "report_reasons": null, "author": "jwhco", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/ObsidianMD/comments/zb4okr/map_of_18237_files_more_than_22_years_of_writing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/ObsidianMD/comments/zb4okr/map_of_18237_files_more_than_22_years_of_writing/", "subreddit_subscribers": 51518, "created_utc": 1670032787.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1670124107.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.ObsidianMD", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/ObsidianMD/comments/zb4okr/map_of_18237_files_more_than_22_years_of_writing/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zbz2ob", "is_robot_indexable": true, "report_reasons": null, "author": "jwhco", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_zb4okr", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zbz2ob/map_of_18237_files_more_than_22_years_of_writing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/ObsidianMD/comments/zb4okr/map_of_18237_files_more_than_22_years_of_writing/", "subreddit_subscribers": 657492, "created_utc": 1670124107.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "&amp;#x200B;\n\nhttps://preview.redd.it/n316zki2yx3a1.png?width=1139&amp;format=png&amp;auto=webp&amp;s=6b9539dbef78a4f61f32841ebd4b7b974e492d78", "author_fullname": "t2_cajg81c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can't beat that value!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"n316zki2yx3a1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 158, "x": 108, "u": "https://preview.redd.it/n316zki2yx3a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3b103690a8d3934d65e3e59fdf96aeb3be2d2a99"}, {"y": 316, "x": 216, "u": "https://preview.redd.it/n316zki2yx3a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4b1b047065db8379bcf031dcccbb24c0aaaf1c73"}, {"y": 469, "x": 320, "u": "https://preview.redd.it/n316zki2yx3a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=dd3e33bc13fa7430eb2f6556d00794789acd0f3c"}, {"y": 938, "x": 640, "u": "https://preview.redd.it/n316zki2yx3a1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=3c681ac726c00ba5e7c1a3af53d81edf6d864b4e"}, {"y": 1407, "x": 960, "u": "https://preview.redd.it/n316zki2yx3a1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ce1eadd71f47c8424ea55b1f7476f22236f52e07"}, {"y": 1583, "x": 1080, "u": "https://preview.redd.it/n316zki2yx3a1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cc5fefe6949f02332ed973ad6ed47ddffb86d242"}], "s": {"y": 1670, "x": 1139, "u": "https://preview.redd.it/n316zki2yx3a1.png?width=1139&amp;format=png&amp;auto=webp&amp;s=6b9539dbef78a4f61f32841ebd4b7b974e492d78"}, "id": "n316zki2yx3a1"}}, "name": "t3_zcknv3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Darn diggity dog!", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/PKs8k2rF75ijyDWMvfDwoctP_R-c9BdYP5zPq6k751Q.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670185794.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/n316zki2yx3a1.png?width=1139&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=6b9539dbef78a4f61f32841ebd4b7b974e492d78\"&gt;https://preview.redd.it/n316zki2yx3a1.png?width=1139&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=6b9539dbef78a4f61f32841ebd4b7b974e492d78&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "zcknv3", "is_robot_indexable": true, "report_reasons": null, "author": "umairshariff23", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zcknv3/cant_beat_that_value/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zcknv3/cant_beat_that_value/", "subreddit_subscribers": 657492, "created_utc": 1670185794.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Aspiring data hoarder flirting with different raid config ideas.  Maybe software raid but leaning towards enclosure or  hardware raid controller in tower.", "author_fullname": "t2_6l2op3dg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can a raid array via external disk enclosure be moved to and from other PCs with different hardware configurations? For the sake of data access is why I ask.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zc102n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670130058.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Aspiring data hoarder flirting with different raid config ideas.  Maybe software raid but leaning towards enclosure or  hardware raid controller in tower.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zc102n", "is_robot_indexable": true, "report_reasons": null, "author": "History_guy2018", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zc102n/can_a_raid_array_via_external_disk_enclosure_be/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zc102n/can_a_raid_array_via_external_disk_enclosure_be/", "subreddit_subscribers": 657492, "created_utc": 1670130058.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just purchased some HGST SN200 U.2 SSD\u2019s. While installing them I noticed they have what looks like a micro usb port on the opposite side of the U.2 connected. After searching the internet I can\u2019t find any reference to these ports. Does anyone know what they\u2019re used for?", "author_fullname": "t2_ru1of", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HGST SN200 USB Port?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zc0qzp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670129265.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just purchased some HGST SN200 U.2 SSD\u2019s. While installing them I noticed they have what looks like a micro usb port on the opposite side of the U.2 connected. After searching the internet I can\u2019t find any reference to these ports. Does anyone know what they\u2019re used for?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zc0qzp", "is_robot_indexable": true, "report_reasons": null, "author": "EricDArneson", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zc0qzp/hgst_sn200_usb_port/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zc0qzp/hgst_sn200_usb_port/", "subreddit_subscribers": 657492, "created_utc": 1670129265.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello--\n\nNot sure if any of the other folks from the wetshaving or wicked_edge subreddits have stopped by, but it looks like a beloved website used by a lot of folks on those subs is going to be going offline around Dec 31 of this year.  Is there any tool that I could use to back up the contents of this website?  There are a lot of pages of descriptions of soaps/aftershaves/colognes that are no longer up on their respective vendors' websites anymore, so when https://trythatsoap.com/ goes offline, that information will be gone.\n\nI've got some extra TBs I can store the data in, but I'm not sure how to back up the site's contents.\n\nIn general I'm mainly concerned about the portion of the site dealing with Brand/product/description.  This [page](https://trythatsoap.com/collection/95/?product_type=soap) for example is a record of Stirling Soap's Executive Man shave soap-- which still happens to be up on Stirling's website, but lots and lots of scents from lots and lots of vendors aren't.. so this is just an example of what I'd like to be able to save for posterity.\n\nThanks in advance for any help that I could be pointed to.", "author_fullname": "t2_7ddwu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Options to backup https://trythatsoap.com/?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zc0huu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.45, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1670129000.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670128443.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello--&lt;/p&gt;\n\n&lt;p&gt;Not sure if any of the other folks from the wetshaving or wicked_edge subreddits have stopped by, but it looks like a beloved website used by a lot of folks on those subs is going to be going offline around Dec 31 of this year.  Is there any tool that I could use to back up the contents of this website?  There are a lot of pages of descriptions of soaps/aftershaves/colognes that are no longer up on their respective vendors&amp;#39; websites anymore, so when &lt;a href=\"https://trythatsoap.com/\"&gt;https://trythatsoap.com/&lt;/a&gt; goes offline, that information will be gone.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve got some extra TBs I can store the data in, but I&amp;#39;m not sure how to back up the site&amp;#39;s contents.&lt;/p&gt;\n\n&lt;p&gt;In general I&amp;#39;m mainly concerned about the portion of the site dealing with Brand/product/description.  This &lt;a href=\"https://trythatsoap.com/collection/95/?product_type=soap\"&gt;page&lt;/a&gt; for example is a record of Stirling Soap&amp;#39;s Executive Man shave soap-- which still happens to be up on Stirling&amp;#39;s website, but lots and lots of scents from lots and lots of vendors aren&amp;#39;t.. so this is just an example of what I&amp;#39;d like to be able to save for posterity.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for any help that I could be pointed to.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zc0huu", "is_robot_indexable": true, "report_reasons": null, "author": "grock1722", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zc0huu/options_to_backup_httpstrythatsoapcom/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zc0huu/options_to_backup_httpstrythatsoapcom/", "subreddit_subscribers": 657492, "created_utc": 1670128443.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello fellow hoarders! I have a feeling I'm going to use some of these words wrong so please excuse that and feel free to correct me. I've been a data hoarder for as long as I can remember but only recently ran into issues. From what I've learned online, I'm experiencing issues with fragmentation and it's causing my external HDD to be super slow. I'm a graphic designer and I regularly download large compressed folders of multiple file types only to keep one specific format (keeping like 100MB of a 1GB download). It was so bad I couldn't get Windows defrag, Defraggler, or UltraDefrag to get more than 1% defragged in like a 24 hour period. So I moved all the files from my Seagate HDD to my laptop's SSD and formatted my Seagate. I started adding things back and began with one 55GB folder that had 94% fragmentation. Defraggler has been doing a \"quick\" defrag for about 45 minutes and is still at 0%. Here are my questions:\n\n* Should I try transferring stuff over in smaller clusters, like 5GB at a time and then defragging them? \n* How can I prevent data fragging in this circumstance? Prep the download and what not on my laptop and then transfer only the files I was keeping? \n\nThank you so much for taking the time to read this! Have a great weekend :)", "author_fullname": "t2_87yliers", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Defrag tips for large downloads?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zbzdwn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670125056.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow hoarders! I have a feeling I&amp;#39;m going to use some of these words wrong so please excuse that and feel free to correct me. I&amp;#39;ve been a data hoarder for as long as I can remember but only recently ran into issues. From what I&amp;#39;ve learned online, I&amp;#39;m experiencing issues with fragmentation and it&amp;#39;s causing my external HDD to be super slow. I&amp;#39;m a graphic designer and I regularly download large compressed folders of multiple file types only to keep one specific format (keeping like 100MB of a 1GB download). It was so bad I couldn&amp;#39;t get Windows defrag, Defraggler, or UltraDefrag to get more than 1% defragged in like a 24 hour period. So I moved all the files from my Seagate HDD to my laptop&amp;#39;s SSD and formatted my Seagate. I started adding things back and began with one 55GB folder that had 94% fragmentation. Defraggler has been doing a &amp;quot;quick&amp;quot; defrag for about 45 minutes and is still at 0%. Here are my questions:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Should I try transferring stuff over in smaller clusters, like 5GB at a time and then defragging them? &lt;/li&gt;\n&lt;li&gt;How can I prevent data fragging in this circumstance? Prep the download and what not on my laptop and then transfer only the files I was keeping? &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thank you so much for taking the time to read this! Have a great weekend :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zbzdwn", "is_robot_indexable": true, "report_reasons": null, "author": "lezzuhlss", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zbzdwn/defrag_tips_for_large_downloads/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zbzdwn/defrag_tips_for_large_downloads/", "subreddit_subscribers": 657492, "created_utc": 1670125056.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}