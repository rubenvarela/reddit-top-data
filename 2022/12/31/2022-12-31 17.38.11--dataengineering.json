{"kind": "Listing", "data": {"after": null, "dist": 14, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have quite a lot of experience with GCP but no experience of any other cloud platform. I\u2019m curious about the general opinion on which (of the big three) platforms you prefer to work with. I have considered going into contracting and knowing that GCP has the lowest market share of the three I realize I need to extend my skillset to at least include another cloud platform. \n\nWhich do you think is more fun to work with between AWS and Azure?\nPros and cons?", "author_fullname": "t2_91wtm7y0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google Cloud vs Azure vs AWS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zzqo79", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1672484182.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672480693.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have quite a lot of experience with GCP but no experience of any other cloud platform. I\u2019m curious about the general opinion on which (of the big three) platforms you prefer to work with. I have considered going into contracting and knowing that GCP has the lowest market share of the three I realize I need to extend my skillset to at least include another cloud platform. &lt;/p&gt;\n\n&lt;p&gt;Which do you think is more fun to work with between AWS and Azure?\nPros and cons?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zzqo79", "is_robot_indexable": true, "report_reasons": null, "author": "Gueule-Debois", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zzqo79/google_cloud_vs_azure_vs_aws/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zzqo79/google_cloud_vs_azure_vs_aws/", "subreddit_subscribers": 84755, "created_utc": 1672480693.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am looking to implement Delta format storage on my data lake in s3. Data is generated as parquet files from previous iterations. \n\nMy goal is to eventually run incremental jobs to handle upsert/delete operations from the source stream (which is partitioned hourly, and hence I can these incremental jobs at hourly cadence). \n\nCurrently exploring Delta format operations on AWS EMR by importing open source Delta. [Here](https://github.com/aws-samples/emr-studio-notebook-examples/blob/0842dbb6cef4eb9c0130c04affadf950726b2b83/examples/deltalake-example-notebook-pyspark.ipynb) is an example of what I've been working through as my first steps. I would like to know if someone has done similar implementation and anything to watch out with this path.\n\nAnother obvious way - pick up a vendor like Databricks and go with package solution. I want to vet the available OSS solutions to make an informed choice here. \n\nTY", "author_fullname": "t2_j1zb3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "OSS Delta format implementation on AWS EMR for Incremental load jobs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zzfxdu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1672445434.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking to implement Delta format storage on my data lake in s3. Data is generated as parquet files from previous iterations. &lt;/p&gt;\n\n&lt;p&gt;My goal is to eventually run incremental jobs to handle upsert/delete operations from the source stream (which is partitioned hourly, and hence I can these incremental jobs at hourly cadence). &lt;/p&gt;\n\n&lt;p&gt;Currently exploring Delta format operations on AWS EMR by importing open source Delta. &lt;a href=\"https://github.com/aws-samples/emr-studio-notebook-examples/blob/0842dbb6cef4eb9c0130c04affadf950726b2b83/examples/deltalake-example-notebook-pyspark.ipynb\"&gt;Here&lt;/a&gt; is an example of what I&amp;#39;ve been working through as my first steps. I would like to know if someone has done similar implementation and anything to watch out with this path.&lt;/p&gt;\n\n&lt;p&gt;Another obvious way - pick up a vendor like Databricks and go with package solution. I want to vet the available OSS solutions to make an informed choice here. &lt;/p&gt;\n\n&lt;p&gt;TY&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/P_yFb3BZdMGAwgGUW_--rPIl0gF-ot2OdkqDTX5qD9U.jpg?auto=webp&amp;s=8fb8e465da1bd049a52e0b6c7307689ee56ab2f8", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/P_yFb3BZdMGAwgGUW_--rPIl0gF-ot2OdkqDTX5qD9U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b49b29becbc5fa3649914ec382b7014e8c7648a1", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/P_yFb3BZdMGAwgGUW_--rPIl0gF-ot2OdkqDTX5qD9U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=80ba700cc6854f9097206ee1344de70dbdec93ac", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/P_yFb3BZdMGAwgGUW_--rPIl0gF-ot2OdkqDTX5qD9U.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=af9f61cfdb2c338717e6583139240c3e81939505", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/P_yFb3BZdMGAwgGUW_--rPIl0gF-ot2OdkqDTX5qD9U.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bbfde569b14241942e7e072105d00677602468d3", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/P_yFb3BZdMGAwgGUW_--rPIl0gF-ot2OdkqDTX5qD9U.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6b9e0d900d8def22cc1d4a71816264f5e4ffa990", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/P_yFb3BZdMGAwgGUW_--rPIl0gF-ot2OdkqDTX5qD9U.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=afc8b1307f8a8ecbe1ed9fea4ba55ae45dd98002", "width": 1080, "height": 540}], "variants": {}, "id": "OcYzVm-Iahld81YZjctN_TWTsY-DCy61RAEjnwVj_Fw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "zzfxdu", "is_robot_indexable": true, "report_reasons": null, "author": "abhi5025", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zzfxdu/oss_delta_format_implementation_on_aws_emr_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zzfxdu/oss_delta_format_implementation_on_aws_emr_for/", "subreddit_subscribers": 84755, "created_utc": 1672445434.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently heard Elon Musk talk about the Views feature at Twitter on the All-In podcast and how it processes about 5 Million TPS. \n\nDoes anyone have any ideas for how the architecture behind something like this works? \n\nIf they exist, I would love to read any resources covering advanced topics like this.", "author_fullname": "t2_ij7c2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Views feature at Twitter, 5 Million TPS - how?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zzk4ib", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672457183.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently heard Elon Musk talk about the Views feature at Twitter on the All-In podcast and how it processes about 5 Million TPS. &lt;/p&gt;\n\n&lt;p&gt;Does anyone have any ideas for how the architecture behind something like this works? &lt;/p&gt;\n\n&lt;p&gt;If they exist, I would love to read any resources covering advanced topics like this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zzk4ib", "is_robot_indexable": true, "report_reasons": null, "author": "TehMightyDuk", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zzk4ib/views_feature_at_twitter_5_million_tps_how/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zzk4ib/views_feature_at_twitter_5_million_tps_how/", "subreddit_subscribers": 84755, "created_utc": 1672457183.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_sppgx30r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GitHub Actions Explained and Complete Course", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_zz89td", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 12, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/ylHfetX3QlU?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Master GitHub Actions in 3 Hours | Full GitHub Actions CI/CD Course 2023 | DevOps Docker Tutorial\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Master GitHub Actions in 3 Hours | Full GitHub Actions CI/CD Course 2023 | DevOps Docker Tutorial", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/ylHfetX3QlU?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Master GitHub Actions in 3 Hours | Full GitHub Actions CI/CD Course 2023 | DevOps Docker Tutorial\"&gt;&lt;/iframe&gt;", "author_name": " Code with Scaler", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/ylHfetX3QlU/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@CodewithScaler"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/ylHfetX3QlU?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Master GitHub Actions in 3 Hours | Full GitHub Actions CI/CD Course 2023 | DevOps Docker Tutorial\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/zz89td", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/-cdp_Yvd7RKGi9D_Q51T-furYZSmGB94IQ_evvq07AQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1672426402.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/ylHfetX3QlU", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/LbzO4FRuh13NkE279XlsQdQabq3GUuKN3JXmFQs3zYc.jpg?auto=webp&amp;s=6c524d273c1751fb37eba83174fc3d431d8997b3", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/LbzO4FRuh13NkE279XlsQdQabq3GUuKN3JXmFQs3zYc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f636b5b512cea0a4324105a20ba4da376b6a7ff5", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/LbzO4FRuh13NkE279XlsQdQabq3GUuKN3JXmFQs3zYc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0fb0169c80297cdb9d33bfa99a52b00422d17350", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/LbzO4FRuh13NkE279XlsQdQabq3GUuKN3JXmFQs3zYc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=15c819bcd7316e7b338f49628c7abfb3d05f8474", "width": 320, "height": 240}], "variants": {}, "id": "7eCMRrgjaUFm2a0Ws51O1BARpdU5SQXC9BlCdi4UR7M"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zz89td", "is_robot_indexable": true, "report_reasons": null, "author": "thetech_learner", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zz89td/github_actions_explained_and_complete_course/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/ylHfetX3QlU", "subreddit_subscribers": 84755, "created_utc": 1672426402.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Master GitHub Actions in 3 Hours | Full GitHub Actions CI/CD Course 2023 | DevOps Docker Tutorial", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/ylHfetX3QlU?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Master GitHub Actions in 3 Hours | Full GitHub Actions CI/CD Course 2023 | DevOps Docker Tutorial\"&gt;&lt;/iframe&gt;", "author_name": " Code with Scaler", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/ylHfetX3QlU/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@CodewithScaler"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "There is an event by the Seattle Data Guy on 3rd January or 8th.  Anybody here joining it? I wanted to know if we could network on it. I'm looking for Summer 2023 internships as a Data engineer intern or Data Analyst intern", "author_fullname": "t2_iascmrib", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone attending The State of Data Infra 2023?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zznsdq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672469156.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There is an event by the Seattle Data Guy on 3rd January or 8th.  Anybody here joining it? I wanted to know if we could network on it. I&amp;#39;m looking for Summer 2023 internships as a Data engineer intern or Data Analyst intern&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zznsdq", "is_robot_indexable": true, "report_reasons": null, "author": "catchereye22", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zznsdq/anyone_attending_the_state_of_data_infra_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zznsdq/anyone_attending_the_state_of_data_infra_2023/", "subreddit_subscribers": 84755, "created_utc": 1672469156.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_4679pe1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Free \"dbt for beginners\" course", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_zzvb1o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/RaeQZ3P2tYb6Uzky98mgMcGSEYnZe_2P2PGi2ZL1_0I.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1672497046.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dataschool.alterclass.school", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://dataschool.alterclass.school/courses/dbt-for-beginners-352402536678818389", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/zEMvJPBk4kdPN433ba1kQoxVwWrm9TOOktRKWDVPNv0.jpg?auto=webp&amp;s=baf90ba8b8331dbe0a54f56970a40fbee254d0d3", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/zEMvJPBk4kdPN433ba1kQoxVwWrm9TOOktRKWDVPNv0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f1eee62f1ff2693057acbc26c5838f81bed8afb2", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/zEMvJPBk4kdPN433ba1kQoxVwWrm9TOOktRKWDVPNv0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=dd688adda11f8d0ed4f29c4540239966db48e283", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/zEMvJPBk4kdPN433ba1kQoxVwWrm9TOOktRKWDVPNv0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2121c2644d5cf365e27dcbf3190bc7d3fc3ea672", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/zEMvJPBk4kdPN433ba1kQoxVwWrm9TOOktRKWDVPNv0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=cb3356a792502f6658b7e28089c0d4f8aa1dab65", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/zEMvJPBk4kdPN433ba1kQoxVwWrm9TOOktRKWDVPNv0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7d0691ce36096bf99ca7eb3fbea27b6c84f7324b", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/zEMvJPBk4kdPN433ba1kQoxVwWrm9TOOktRKWDVPNv0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=781b594238bb083681f62321b55522d0afc496db", "width": 1080, "height": 607}], "variants": {}, "id": "iwMa9Qo4xqw27g3bFxQt8ELlV6OYhY0ykbzvaZze_gw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zzvb1o", "is_robot_indexable": true, "report_reasons": null, "author": "oleg_agapov", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zzvb1o/free_dbt_for_beginners_course/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dataschool.alterclass.school/courses/dbt-for-beginners-352402536678818389", "subreddit_subscribers": 84755, "created_utc": 1672497046.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Search as I might, I\u2019m unable to find what I\u2019m looking for. Hoping someone could point me in the right direction.\n\nI want to build a docker-compose for home use to \u2018try out\u2019 a data lakehouse.\n\nI was figuring on using the below stack:\n\n- localstack S3\n- Delta Lake\n- PySpark \n- Presto\n- dbt\n- Airflow\n\nIs this achievable? Is there a component (or more) that I\u2019m missing? I can\u2019t find any guides, or even a docker-compose for Delta Lake. Is anyone aware of anything?\n\nAt work we use S3, Airflow, dbt and Snowflake, hence wanting to keep some of the things I\u2019m familiar with.\n\nAny direction would be appreciated.", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trying Delta Lake at home", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zzqn5r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672480563.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Search as I might, I\u2019m unable to find what I\u2019m looking for. Hoping someone could point me in the right direction.&lt;/p&gt;\n\n&lt;p&gt;I want to build a docker-compose for home use to \u2018try out\u2019 a data lakehouse.&lt;/p&gt;\n\n&lt;p&gt;I was figuring on using the below stack:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;localstack S3&lt;/li&gt;\n&lt;li&gt;Delta Lake&lt;/li&gt;\n&lt;li&gt;PySpark &lt;/li&gt;\n&lt;li&gt;Presto&lt;/li&gt;\n&lt;li&gt;dbt&lt;/li&gt;\n&lt;li&gt;Airflow&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Is this achievable? Is there a component (or more) that I\u2019m missing? I can\u2019t find any guides, or even a docker-compose for Delta Lake. Is anyone aware of anything?&lt;/p&gt;\n\n&lt;p&gt;At work we use S3, Airflow, dbt and Snowflake, hence wanting to keep some of the things I\u2019m familiar with.&lt;/p&gt;\n\n&lt;p&gt;Any direction would be appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zzqn5r", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zzqn5r/trying_delta_lake_at_home/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zzqn5r/trying_delta_lake_at_home/", "subreddit_subscribers": 84755, "created_utc": 1672480563.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I have been working as a Quality Assurance professional for about 10 years now and last 5 of which I was solely dedicated myself as a Test Automation Engineer. Although I love what I do, it is kind of getting dry. I tried switching the industry but last couple of years, this field has become overtly competitive. Being asked leetcode DSA type questions are kind of a norm now and I\u2019m quite bad at it. These questions might be related to what I do but honestly I have never needed to use them in any of my automation frameworks that I\u2019ve built.\n\nAnyway, coming back to my original topic, I\u2019m looking to switch my career. I\u2019m at my early 30s. Data Engineering is interesting and seems very tool specific. I might be wrong but would love to know your opinions on it. I\u2019m personally looking for something, where I won\u2019t be facing those dreadful leetcode type questions in the interview. As long as the questions asked are role specific, I think I will be fine. I\u2019m a quick learner and love to solve puzzles or any kind of problems. I love workin with data a lot as well. I\u2019m very proficient at SQL and most of QA roles has been related to Data Integrity. Do you think at this stage changing my career to DE makes any sense?", "author_fullname": "t2_166pek", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Switching career from QA to Data Engineering, need advice.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zzbozk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672434786.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I have been working as a Quality Assurance professional for about 10 years now and last 5 of which I was solely dedicated myself as a Test Automation Engineer. Although I love what I do, it is kind of getting dry. I tried switching the industry but last couple of years, this field has become overtly competitive. Being asked leetcode DSA type questions are kind of a norm now and I\u2019m quite bad at it. These questions might be related to what I do but honestly I have never needed to use them in any of my automation frameworks that I\u2019ve built.&lt;/p&gt;\n\n&lt;p&gt;Anyway, coming back to my original topic, I\u2019m looking to switch my career. I\u2019m at my early 30s. Data Engineering is interesting and seems very tool specific. I might be wrong but would love to know your opinions on it. I\u2019m personally looking for something, where I won\u2019t be facing those dreadful leetcode type questions in the interview. As long as the questions asked are role specific, I think I will be fine. I\u2019m a quick learner and love to solve puzzles or any kind of problems. I love workin with data a lot as well. I\u2019m very proficient at SQL and most of QA roles has been related to Data Integrity. Do you think at this stage changing my career to DE makes any sense?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zzbozk", "is_robot_indexable": true, "report_reasons": null, "author": "mahdy1991", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zzbozk/switching_career_from_qa_to_data_engineering_need/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zzbozk/switching_career_from_qa_to_data_engineering_need/", "subreddit_subscribers": 84755, "created_utc": 1672434786.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Data noob in the house: I'd like a quick and dirty way to visualize some SQL data (bank transactions). I have a sqlite database, and I'd like to explore it a bit. What are my options? Bonus points for FOSS.", "author_fullname": "t2_3iu12ph8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Visualize sqlite data (histograms)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zzazc5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672433019.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data noob in the house: I&amp;#39;d like a quick and dirty way to visualize some SQL data (bank transactions). I have a sqlite database, and I&amp;#39;d like to explore it a bit. What are my options? Bonus points for FOSS.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zzazc5", "is_robot_indexable": true, "report_reasons": null, "author": "wpcarroll", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zzazc5/visualize_sqlite_data_histograms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zzazc5/visualize_sqlite_data_histograms/", "subreddit_subscribers": 84755, "created_utc": 1672433019.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We\u2019re looking at potentially using AirByte to transfer data and updates to a Postgres database.  That said, their MSSQL driver says it supports incremental log based updates.\n\nWe want to keep low load on our production database and this seems ideal for our larger tables.\n\nMy dba seems to think we need to add modified time stamps to all tables.  That would be a big lift and not deal with deletion use cases.  I\u2019d like to be as non-invasive as possible.\n\nDoes anybody have experience with this or other tools that could minimize impact on load and structure changes?\n\nTIA", "author_fullname": "t2_kaqsa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AirByte - Incremental MSSQL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zzrptl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1672495888.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672484677.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We\u2019re looking at potentially using AirByte to transfer data and updates to a Postgres database.  That said, their MSSQL driver says it supports incremental log based updates.&lt;/p&gt;\n\n&lt;p&gt;We want to keep low load on our production database and this seems ideal for our larger tables.&lt;/p&gt;\n\n&lt;p&gt;My dba seems to think we need to add modified time stamps to all tables.  That would be a big lift and not deal with deletion use cases.  I\u2019d like to be as non-invasive as possible.&lt;/p&gt;\n\n&lt;p&gt;Does anybody have experience with this or other tools that could minimize impact on load and structure changes?&lt;/p&gt;\n\n&lt;p&gt;TIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zzrptl", "is_robot_indexable": true, "report_reasons": null, "author": "vaporofnuance", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zzrptl/airbyte_incremental_mssql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zzrptl/airbyte_incremental_mssql/", "subreddit_subscribers": 84755, "created_utc": 1672484677.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have an on-prem SQL Server 2019 instance (\\~50M rows, 10K daily inserts) used for Read/Write workloads. We want to offload Read-Only workloads to ASMI using the [link](https://techcommunity.microsoft.com/t5/azure-sql-blog/managed-instance-link-connecting-sql-server-to-azure-reimagined/ba-p/2911614) feature. Has anyone tried it and willing to share their experiences?", "author_fullname": "t2_42hc4int", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure SQL Managed Instance (ASMI) link feature for data replication", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zzmti9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1672465780.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have an on-prem SQL Server 2019 instance (~50M rows, 10K daily inserts) used for Read/Write workloads. We want to offload Read-Only workloads to ASMI using the &lt;a href=\"https://techcommunity.microsoft.com/t5/azure-sql-blog/managed-instance-link-connecting-sql-server-to-azure-reimagined/ba-p/2911614\"&gt;link&lt;/a&gt; feature. Has anyone tried it and willing to share their experiences?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/tUeSOUlUmpNXBu6c-i70dzjHR19HvU46iw6JzngJr0g.jpg?auto=webp&amp;s=73f6eb2517c027c61307db8c20e4ea4cea6620d5", "width": 2427, "height": 1152}, "resolutions": [{"url": "https://external-preview.redd.it/tUeSOUlUmpNXBu6c-i70dzjHR19HvU46iw6JzngJr0g.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4f6b295507f6f42560a281a613b6499154ad95a4", "width": 108, "height": 51}, {"url": "https://external-preview.redd.it/tUeSOUlUmpNXBu6c-i70dzjHR19HvU46iw6JzngJr0g.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3739c8791cbca8a27074da501ff289f1d4b6dd7b", "width": 216, "height": 102}, {"url": "https://external-preview.redd.it/tUeSOUlUmpNXBu6c-i70dzjHR19HvU46iw6JzngJr0g.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=59f3a455649eb97234908dd89d5c7e032e072221", "width": 320, "height": 151}, {"url": "https://external-preview.redd.it/tUeSOUlUmpNXBu6c-i70dzjHR19HvU46iw6JzngJr0g.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2990e8949ed437bc975ac922563fa748d7c4e33f", "width": 640, "height": 303}, {"url": "https://external-preview.redd.it/tUeSOUlUmpNXBu6c-i70dzjHR19HvU46iw6JzngJr0g.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4a8251b6d493663f2e8b94dd9c7c1f94f235651e", "width": 960, "height": 455}, {"url": "https://external-preview.redd.it/tUeSOUlUmpNXBu6c-i70dzjHR19HvU46iw6JzngJr0g.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7f043f50bb0b7cb2090de7389917106f98bd07a0", "width": 1080, "height": 512}], "variants": {}, "id": "-vRmsq1GYk4mNHkQcqNcgCvxa-tXhUBPrsJLqqwjzYw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zzmti9", "is_robot_indexable": true, "report_reasons": null, "author": "vanillacap", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zzmti9/azure_sql_managed_instance_asmi_link_feature_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zzmti9/azure_sql_managed_instance_asmi_link_feature_for/", "subreddit_subscribers": 84755, "created_utc": 1672465780.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys, \n\nI am trying to implement concurrent.futures.ProcessPoolExecutor() in an AWS Glue Spark job and I could really use some help with understanding specifically max\\_workers and if this plays nice with Glue.  \n\nShould the max\\_workers value I pass in ultimately be the number of glue workers multiplied by the number of processors on each glue worker?  Is concurrent.futures.ProcessPoolExecutor even smart enough to recognize all of the 120 processors in the Glue cluster? \n\nAny help would be monumentally appreciated. I need to make an API call for every ID in a list, and given the average length of the generated list every day, I calculated that this process would take 24 hours to run with a regular for loop. I split the list into smaller lists based on the max\\_workers value, and I'm wanting to process these lists asynchronously. Just need to know if I'm on the right track.\n\nThanks!!\n\ncpus\\_per\\_glue\\_worker=4\n\nnumber\\_of\\_glue\\_workers=30\n\nnumber\\_of\\_workers = number\\_of\\_glue\\_workers \\* cpus\\_per\\_glue\\_worker\n\nwith concurrent.futures.ProcessPoolExecutor(max\\_workers=number\\_of\\_workers) as executor:\n\nresults = \\[executor.submit(\\*functionname\\*, i) for i in range(120)\\]", "author_fullname": "t2_rwmd2gxn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using Multiprocessing (concurrent.futures.ProcessPoolExecutor()) in AWS Glue Spark Job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zzikxv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672452707.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, &lt;/p&gt;\n\n&lt;p&gt;I am trying to implement concurrent.futures.ProcessPoolExecutor() in an AWS Glue Spark job and I could really use some help with understanding specifically max_workers and if this plays nice with Glue.  &lt;/p&gt;\n\n&lt;p&gt;Should the max_workers value I pass in ultimately be the number of glue workers multiplied by the number of processors on each glue worker?  Is concurrent.futures.ProcessPoolExecutor even smart enough to recognize all of the 120 processors in the Glue cluster? &lt;/p&gt;\n\n&lt;p&gt;Any help would be monumentally appreciated. I need to make an API call for every ID in a list, and given the average length of the generated list every day, I calculated that this process would take 24 hours to run with a regular for loop. I split the list into smaller lists based on the max_workers value, and I&amp;#39;m wanting to process these lists asynchronously. Just need to know if I&amp;#39;m on the right track.&lt;/p&gt;\n\n&lt;p&gt;Thanks!!&lt;/p&gt;\n\n&lt;p&gt;cpus_per_glue_worker=4&lt;/p&gt;\n\n&lt;p&gt;number_of_glue_workers=30&lt;/p&gt;\n\n&lt;p&gt;number_of_workers = number_of_glue_workers * cpus_per_glue_worker&lt;/p&gt;\n\n&lt;p&gt;with concurrent.futures.ProcessPoolExecutor(max_workers=number_of_workers) as executor:&lt;/p&gt;\n\n&lt;p&gt;results = [executor.submit(*functionname*, i) for i in range(120)]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zzikxv", "is_robot_indexable": true, "report_reasons": null, "author": "quiet_storm_09", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zzikxv/using_multiprocessing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zzikxv/using_multiprocessing/", "subreddit_subscribers": 84755, "created_utc": 1672452707.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello\n\nI have some experience with Spark sometime ago where 2.0 was just being released. I moved onto different tech stack since then and lost touch with it. \n\n3.x seems to be the current stable version and I feel too rusty with my outdated knowledge. Is there any primer that you can point me to pick up basics in 3.x.\n\nI am looking for some starting point tbh and finding it difficult as internet is flooded with too many shallow resources. \n\nTIA.", "author_fullname": "t2_j1zb3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Online resources - Spark Refresher", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zzg2gm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672445797.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello&lt;/p&gt;\n\n&lt;p&gt;I have some experience with Spark sometime ago where 2.0 was just being released. I moved onto different tech stack since then and lost touch with it. &lt;/p&gt;\n\n&lt;p&gt;3.x seems to be the current stable version and I feel too rusty with my outdated knowledge. Is there any primer that you can point me to pick up basics in 3.x.&lt;/p&gt;\n\n&lt;p&gt;I am looking for some starting point tbh and finding it difficult as internet is flooded with too many shallow resources. &lt;/p&gt;\n\n&lt;p&gt;TIA.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zzg2gm", "is_robot_indexable": true, "report_reasons": null, "author": "abhi5025", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zzg2gm/online_resources_spark_refresher/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zzg2gm/online_resources_spark_refresher/", "subreddit_subscribers": 84755, "created_utc": 1672445797.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello \nI need your help. \nI'm new to Pyspark and I need to write a script that moves several files.\n I would like to test if a file exists before moving it. \nI'm working on Azure and the files are in S2 storage. \nI saw that there was an OS module that allows you to do this but it seems that it only works if the file is local. \nDo you have a solution to perform this existence test of a file in S2?\n\nThks", "author_fullname": "t2_j68sac68", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pyspark Test if file exists", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zzfr0s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672444988.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello \nI need your help. \nI&amp;#39;m new to Pyspark and I need to write a script that moves several files.\n I would like to test if a file exists before moving it. \nI&amp;#39;m working on Azure and the files are in S2 storage. \nI saw that there was an OS module that allows you to do this but it seems that it only works if the file is local. \nDo you have a solution to perform this existence test of a file in S2?&lt;/p&gt;\n\n&lt;p&gt;Thks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zzfr0s", "is_robot_indexable": true, "report_reasons": null, "author": "Playful-Sprinkles-27", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zzfr0s/pyspark_test_if_file_exists/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zzfr0s/pyspark_test_if_file_exists/", "subreddit_subscribers": 84755, "created_utc": 1672444988.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}