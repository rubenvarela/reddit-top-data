{"kind": "Listing", "data": {"after": "t3_zz2ehu", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Elon Musk orders closure of \"one of Twitter's 3 main computing storage facilities\". Where might the gear resurface?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zz112y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 604, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_3udph", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 604, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "sysadmin", "selftext": "[removed]", "author_fullname": "t2_t0csvrcz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Elon Musk\u2019s orders were clear: Close the data center. Any thoughts ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/sysadmin", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zywe7y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 303, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 303, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672392723.0, "link_flair_type": "text", "wls": 6, "removed_by_category": "moderator", "banned_by": null, "author_flair_type": "text", "domain": "self.sysadmin", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qnp7", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zywe7y", "is_robot_indexable": false, "report_reasons": null, "author": "vaultRadon", "discussion_type": null, "num_comments": 547, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/sysadmin/comments/zywe7y/elon_musks_orders_were_clear_close_the_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/sysadmin/comments/zywe7y/elon_musks_orders_were_clear_close_the_data/", "subreddit_subscribers": 761905, "created_utc": 1672392723.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1672408275.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.sysadmin", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/sysadmin/comments/zywe7y/elon_musks_orders_were_clear_close_the_data/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hQaBTilr7KyaQ6gqI_Yml2_A2iSVj8WQQaIcNk9x8yE.jpg?auto=webp&amp;s=323a827f9d8c2de2c2a5cbee6b34d8acdec82337", "width": 1050, "height": 550}, "resolutions": [{"url": "https://external-preview.redd.it/hQaBTilr7KyaQ6gqI_Yml2_A2iSVj8WQQaIcNk9x8yE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9c00ed381bbda1e4f8437beecf86706518c26293", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/hQaBTilr7KyaQ6gqI_Yml2_A2iSVj8WQQaIcNk9x8yE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f73b8517d8c3d058679d55ed1b70675939b06d05", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/hQaBTilr7KyaQ6gqI_Yml2_A2iSVj8WQQaIcNk9x8yE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=07e15ce58d4e6ff876d9ecd45a6aa5fa6b091cc3", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/hQaBTilr7KyaQ6gqI_Yml2_A2iSVj8WQQaIcNk9x8yE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=877411bf1213606b2c8ed6658dae97524c5cb611", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/hQaBTilr7KyaQ6gqI_Yml2_A2iSVj8WQQaIcNk9x8yE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1305b81976ee2beb524b6f1b7c415f3e4de33deb", "width": 960, "height": 502}], "variants": {}, "id": "lcnmaitsATRy93Pa04p9qvDs3dKbxzmJyuVKfzukvCg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "zz112y", "is_robot_indexable": true, "report_reasons": null, "author": "GimmeSomeSugar", "discussion_type": null, "num_comments": 128, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_zywe7y", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zz112y/elon_musk_orders_closure_of_one_of_twitters_3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/sysadmin/comments/zywe7y/elon_musks_orders_were_clear_close_the_data/", "subreddit_subscribers": 662915, "created_utc": 1672408275.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "tl;dr: a natural language search engine for personal data archives .\n\nIv'e pulling a lot of old stuff from my archive lately, the thing is, the HDD (10tb seagate) is way too slow for searching in realtime, more over, I can't actually search with natural language so to find what I'm looking for I need to try a couple of searches.\n\nThat's why I decided to build haystack, a search engine for data, meant for finding technical details or relevant paragraphs..\n\nIt enables you to search large HDDs or slack, confluence, email all in one place.\n\n**no internet connection required.**\n\nIt supports natural language queries so a query like: `\"where was I last spring?\"`yields:\n\n    4 documents, 3 photos, and two emails\n\nhaystack stores user data locally, so there's no security risk - only you have access to internal docs, I didn't want to deal with security compliance headaches caused from storing user data in the cloud.\n\nRolled it out to my co-workers and friends a week ago and they thought it's a hit, and also less bugging, so I'm planning on releasing it publicly on March 2023.\n\n**Early access**\n\nIf you want to try it out before March 2023 - [Early access](https://haystack.it)\n\nor [Github](https://github.com/haystackoss/haystack)\n\nThanks, Yuval", "author_fullname": "t2_pd65mcfi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "haystack - your own google search for personal data archives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zz21n4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1672411620.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672411016.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;tl;dr: a natural language search engine for personal data archives .&lt;/p&gt;\n\n&lt;p&gt;Iv&amp;#39;e pulling a lot of old stuff from my archive lately, the thing is, the HDD (10tb seagate) is way too slow for searching in realtime, more over, I can&amp;#39;t actually search with natural language so to find what I&amp;#39;m looking for I need to try a couple of searches.&lt;/p&gt;\n\n&lt;p&gt;That&amp;#39;s why I decided to build haystack, a search engine for data, meant for finding technical details or relevant paragraphs..&lt;/p&gt;\n\n&lt;p&gt;It enables you to search large HDDs or slack, confluence, email all in one place.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;no internet connection required.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;It supports natural language queries so a query like: &lt;code&gt;&amp;quot;where was I last spring?&amp;quot;&lt;/code&gt;yields:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;4 documents, 3 photos, and two emails\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;haystack stores user data locally, so there&amp;#39;s no security risk - only you have access to internal docs, I didn&amp;#39;t want to deal with security compliance headaches caused from storing user data in the cloud.&lt;/p&gt;\n\n&lt;p&gt;Rolled it out to my co-workers and friends a week ago and they thought it&amp;#39;s a hit, and also less bugging, so I&amp;#39;m planning on releasing it publicly on March 2023.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Early access&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;If you want to try it out before March 2023 - &lt;a href=\"https://haystack.it\"&gt;Early access&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;or &lt;a href=\"https://github.com/haystackoss/haystack\"&gt;Github&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thanks, Yuval&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zz21n4", "is_robot_indexable": true, "report_reasons": null, "author": "yuvalsteuer", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zz21n4/haystack_your_own_google_search_for_personal_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zz21n4/haystack_your_own_google_search_for_personal_data/", "subreddit_subscribers": 662915, "created_utc": 1672411016.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "What program should I use for reliable automated backups? I don't mind paid but would prefer to avoid subscriptions.\n\nI have a home desktop running Windows 10. One SSD to run Windows, assorted programs, and a Linux virtual machine, and three HDDs full of personal data. I'm backing up to an external WD Elements HDD.\n\nI'd like to have a image backup of my SSD without the Linux VM, another image backup of just the VM, and a file level backup of my multiple data drives.\n\nA couple other questions:\n\nIf I run incremental backups can I eventually consolidate those files on the backup drive and be able to compare the consolidated full backup files against my local files?\n\nFinal question for anyone patient and kind enough to still be reading this, if I rename local files on my local data drives and reorganize their folders, would a file level backup program end up making duplicates or be able to track the name/folder changes?", "author_fullname": "t2_5md7f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reliable backup for Windows 10? File level and image/volume level backups?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zza4d6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672430906.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What program should I use for reliable automated backups? I don&amp;#39;t mind paid but would prefer to avoid subscriptions.&lt;/p&gt;\n\n&lt;p&gt;I have a home desktop running Windows 10. One SSD to run Windows, assorted programs, and a Linux virtual machine, and three HDDs full of personal data. I&amp;#39;m backing up to an external WD Elements HDD.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to have a image backup of my SSD without the Linux VM, another image backup of just the VM, and a file level backup of my multiple data drives.&lt;/p&gt;\n\n&lt;p&gt;A couple other questions:&lt;/p&gt;\n\n&lt;p&gt;If I run incremental backups can I eventually consolidate those files on the backup drive and be able to compare the consolidated full backup files against my local files?&lt;/p&gt;\n\n&lt;p&gt;Final question for anyone patient and kind enough to still be reading this, if I rename local files on my local data drives and reorganize their folders, would a file level backup program end up making duplicates or be able to track the name/folder changes?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zza4d6", "is_robot_indexable": true, "report_reasons": null, "author": "yodathewise", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zza4d6/reliable_backup_for_windows_10_file_level_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zza4d6/reliable_backup_for_windows_10_file_level_and/", "subreddit_subscribers": 662915, "created_utc": 1672430906.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "hi, i hope this is the right sub for this. also sorry it's kind of a long post. if anyone can help i'd appreciate it.\n\ni have an iphone 7 plus with 59.143 photos and 3.365 videos stored in the photos app. i turned on icloud photos which is taking forever by itself, but i wanted to store them on my hd (WD) too. i've only used airdrop to do this before (by transferring to my mac and then dragging it to the drive) but because of the volume i decided to use image capture.\n\nhere's where the trouble starts. image capture says i have 66.359 items in my phone. i thought maybe the extra items were from files and ignored it. i spent all day yesterday and today trying to transfer the files and it kept crashing so i had to restart it A LOT. but it seemed that the items that had already transferred got a green check mark so i assumed i wasn't accidentally transferring more than 1 copy of a single item.\n\nwell it looked like it crashed again so i went to restart and there was just a message saying one item couldn't transfer. i stupidly just closed it and started it again (because this had happened before). but then when i checked how many items were in my hd, the number was 70.752! \n\nobviously that's way more than i have in my phone and i'm confused. i do know that some files had more than one format transferred to the hd (live photos for example, they transfer as video and photo). but i am very tired and just want this to be over. i'm scared there's some item(s) missing but mostly just very confused as to how 7k items just showed up, first some on image capture and then even more on the hd (i only had about 1k of live photos so the math doesn't make sense)", "author_fullname": "t2_3y7zqvg2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "transferring 63k photos/videos from phone to external hd. how do i check it's all there?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zzip2q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672453023.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hi, i hope this is the right sub for this. also sorry it&amp;#39;s kind of a long post. if anyone can help i&amp;#39;d appreciate it.&lt;/p&gt;\n\n&lt;p&gt;i have an iphone 7 plus with 59.143 photos and 3.365 videos stored in the photos app. i turned on icloud photos which is taking forever by itself, but i wanted to store them on my hd (WD) too. i&amp;#39;ve only used airdrop to do this before (by transferring to my mac and then dragging it to the drive) but because of the volume i decided to use image capture.&lt;/p&gt;\n\n&lt;p&gt;here&amp;#39;s where the trouble starts. image capture says i have 66.359 items in my phone. i thought maybe the extra items were from files and ignored it. i spent all day yesterday and today trying to transfer the files and it kept crashing so i had to restart it A LOT. but it seemed that the items that had already transferred got a green check mark so i assumed i wasn&amp;#39;t accidentally transferring more than 1 copy of a single item.&lt;/p&gt;\n\n&lt;p&gt;well it looked like it crashed again so i went to restart and there was just a message saying one item couldn&amp;#39;t transfer. i stupidly just closed it and started it again (because this had happened before). but then when i checked how many items were in my hd, the number was 70.752! &lt;/p&gt;\n\n&lt;p&gt;obviously that&amp;#39;s way more than i have in my phone and i&amp;#39;m confused. i do know that some files had more than one format transferred to the hd (live photos for example, they transfer as video and photo). but i am very tired and just want this to be over. i&amp;#39;m scared there&amp;#39;s some item(s) missing but mostly just very confused as to how 7k items just showed up, first some on image capture and then even more on the hd (i only had about 1k of live photos so the math doesn&amp;#39;t make sense)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zzip2q", "is_robot_indexable": true, "report_reasons": null, "author": "mishaslight", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zzip2q/transferring_63k_photosvideos_from_phone_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zzip2q/transferring_63k_photosvideos_from_phone_to/", "subreddit_subscribers": 662915, "created_utc": 1672453023.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I want to download all the image from someone twitter profile just need tool similar to  Instaloader which is for instagram.", "author_fullname": "t2_87dvtck6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a tool that can download all of the images that someone tweets over time", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zz6pml", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "265b199a-b98c-11e2-8300-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "cloud", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672422591.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to download all the image from someone twitter profile just need tool similar to  Instaloader which is for instagram.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "10TB To the Cloud!", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zz6pml", "is_robot_indexable": true, "report_reasons": null, "author": "Firm-Bunch-5049", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/zz6pml/is_there_a_tool_that_can_download_all_of_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zz6pml/is_there_a_tool_that_can_download_all_of_the/", "subreddit_subscribers": 662915, "created_utc": 1672422591.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Background: [https://en.wikipedia.org/wiki/ITunes\\_LP](https://en.wikipedia.org/wiki/ITunes_LP), which includes a good list of all of the albums which were released with ITLP content. Since the format has been deprecated as of 2018, and with (what I assume is) the progression of web browsers, the few I have no longer \"play\" in Apple Music or as HTML content. But it was really good and informative content when used well by the studios. \n\nI've tried to find an archive of these but so far been unsuccessful. Anyone save and archive  ITLP content (not the music, just the .itlp media directories for albums where they were available via iTunes)?", "author_fullname": "t2_4uxg2e2g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apple ITLP (iTunes LP) Non-Music Media Archive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zzh6ll", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1672448796.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Background: &lt;a href=\"https://en.wikipedia.org/wiki/ITunes_LP\"&gt;https://en.wikipedia.org/wiki/ITunes_LP&lt;/a&gt;, which includes a good list of all of the albums which were released with ITLP content. Since the format has been deprecated as of 2018, and with (what I assume is) the progression of web browsers, the few I have no longer &amp;quot;play&amp;quot; in Apple Music or as HTML content. But it was really good and informative content when used well by the studios. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried to find an archive of these but so far been unsuccessful. Anyone save and archive  ITLP content (not the music, just the .itlp media directories for albums where they were available via iTunes)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DQHlgrP5GxKb6k3GKkVSltcjxiCxcemvcyvZ-8-i8bY.jpg?auto=webp&amp;s=4dc21f8572a5e52d144e3e9940a3ecb26cab78fc", "width": 100, "height": 100}, "resolutions": [], "variants": {}, "id": "LLxav6r_LuCPVWcr7jOBZjhIK99uC9XiYZ1zhEeXXxM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "zzh6ll", "is_robot_indexable": true, "report_reasons": null, "author": "TheRiZZoTTo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zzh6ll/apple_itlp_itunes_lp_nonmusic_media_archive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zzh6ll/apple_itlp_itunes_lp_nonmusic_media_archive/", "subreddit_subscribers": 662915, "created_utc": 1672448796.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "* My university alumni gmail edu account provides unlimited storage via google drive\n* In october 2022, i received a notification that there will be a 1tb limit enforced starting march 1 2023\n* I only have 2 files in my google drive:\n\n1. file-1 is an encrypted disk image = 60 gigs\n2. file-2 is an encrypted disk image = 3 TB\n\n* Last week, i bought a 5TB external HD to put the files on.\n* I am on a 1gbps ethernet fiber connection. Going to fast.com shows me that my DL speed is 850 mbps. My occasional torrenting reaches 100 mB/s without issue.\n* I downloaded file-1 (the 60 gig file) relatively quickly.\n* I am struggling to download file-2 (the 3TB file) and need guidance.\n\n\\----------------\n\n* Attempt 1) I downloaded the file in google chrome through google drives website. I right clicked on the file and clicked download. It was chugging along at 60 mB/s. I monitored casually. After about 3 hours, the download failed.\n* Attempt 2) Google takeout. I chose the option to transfer the data to OneDrive, but it failed after an hour.\n* Attempt 3) Downloaded Google Drives desktop app. The download was going at 90 mB/s (much faster than the download through chrome!) but it stopped and failed after about 4 hours.\n* Attempt 4) Rclone. I used the default/public API key and the download was going at 200 kB/s. I stopped it. I created my own API key and starting from scratch. The download was going at 30 mB/s (slower than both google chrome and the google drive app). I went to bed. Woke up in the morning and I see that it had failed. It had downloaded 700 GB overnight before it failed.\n\n============/===========\n\nrclone copy goog:file2.ext . -P\n\nTransferred:   \t  731.396 GiB / 3.173 TiB, 23%, 18.084 MiB/s, ETA 0s\n\nErrors:                 1 (retrying may help)\n\nElapsed time:   5h43m25.6s\n\n2022-12-30 10:17:33 ERROR : file2.ext: Failed to copy: multipart copy: failed to open source: open file failed: googleapi: Error 403: The download quota for this file has been exceeded., downloadQuotaExceeded\n\n============/===========\n\n* Due to the large file size, I only get 1 attempt at downloading it every 24 hours. With each failure (browser, google drive, rclone), I also receive a message that the download quota has been exceeded.\n* This is a private google account. No one has access but me. These two files are not shared with anyone.\n\nWhat should be my next attempt? I have about 60 days to find a solution before the deadline. Does any software exist that allows you to resume the google drive download from where it failed?\n\nThanks for reading.", "author_fullname": "t2_pegowzi4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "60 days left to download 1 large file from Google Drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zzfwsb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1672446176.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672445397.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;ul&gt;\n&lt;li&gt;My university alumni gmail edu account provides unlimited storage via google drive&lt;/li&gt;\n&lt;li&gt;In october 2022, i received a notification that there will be a 1tb limit enforced starting march 1 2023&lt;/li&gt;\n&lt;li&gt;I only have 2 files in my google drive:&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;ol&gt;\n&lt;li&gt;file-1 is an encrypted disk image = 60 gigs&lt;/li&gt;\n&lt;li&gt;file-2 is an encrypted disk image = 3 TB&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Last week, i bought a 5TB external HD to put the files on.&lt;/li&gt;\n&lt;li&gt;I am on a 1gbps ethernet fiber connection. Going to fast.com shows me that my DL speed is 850 mbps. My occasional torrenting reaches 100 mB/s without issue.&lt;/li&gt;\n&lt;li&gt;I downloaded file-1 (the 60 gig file) relatively quickly.&lt;/li&gt;\n&lt;li&gt;I am struggling to download file-2 (the 3TB file) and need guidance.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;----------------&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Attempt 1) I downloaded the file in google chrome through google drives website. I right clicked on the file and clicked download. It was chugging along at 60 mB/s. I monitored casually. After about 3 hours, the download failed.&lt;/li&gt;\n&lt;li&gt;Attempt 2) Google takeout. I chose the option to transfer the data to OneDrive, but it failed after an hour.&lt;/li&gt;\n&lt;li&gt;Attempt 3) Downloaded Google Drives desktop app. The download was going at 90 mB/s (much faster than the download through chrome!) but it stopped and failed after about 4 hours.&lt;/li&gt;\n&lt;li&gt;Attempt 4) Rclone. I used the default/public API key and the download was going at 200 kB/s. I stopped it. I created my own API key and starting from scratch. The download was going at 30 mB/s (slower than both google chrome and the google drive app). I went to bed. Woke up in the morning and I see that it had failed. It had downloaded 700 GB overnight before it failed.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;============/===========&lt;/p&gt;\n\n&lt;p&gt;rclone copy goog:file2.ext . -P&lt;/p&gt;\n\n&lt;p&gt;Transferred:      731.396 GiB / 3.173 TiB, 23%, 18.084 MiB/s, ETA 0s&lt;/p&gt;\n\n&lt;p&gt;Errors:                 1 (retrying may help)&lt;/p&gt;\n\n&lt;p&gt;Elapsed time:   5h43m25.6s&lt;/p&gt;\n\n&lt;p&gt;2022-12-30 10:17:33 ERROR : file2.ext: Failed to copy: multipart copy: failed to open source: open file failed: googleapi: Error 403: The download quota for this file has been exceeded., downloadQuotaExceeded&lt;/p&gt;\n\n&lt;p&gt;============/===========&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Due to the large file size, I only get 1 attempt at downloading it every 24 hours. With each failure (browser, google drive, rclone), I also receive a message that the download quota has been exceeded.&lt;/li&gt;\n&lt;li&gt;This is a private google account. No one has access but me. These two files are not shared with anyone.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What should be my next attempt? I have about 60 days to find a solution before the deadline. Does any software exist that allows you to resume the google drive download from where it failed?&lt;/p&gt;\n\n&lt;p&gt;Thanks for reading.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zzfwsb", "is_robot_indexable": true, "report_reasons": null, "author": "tomtom7723", "discussion_type": null, "num_comments": 7, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zzfwsb/60_days_left_to_download_1_large_file_from_google/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zzfwsb/60_days_left_to_download_1_large_file_from_google/", "subreddit_subscribers": 662915, "created_utc": 1672445397.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello! I\u2019m hoping that this is the correct community to ask in, but if I\u2019m in tht wrong place I apologize in advance \n\nI need to drastically increase the storage on my home network and also want to add redundancy. \n\nI was looking at older Drobo models, which looked fantastic. I like the idea of a NAS that just uses the available disk space without needing have all the drives match exactly. I\u2019ve read that Linux support is lacking, though. Ext3 is fine, but ext4 isn\u2019t, apparently. \n\nI also appreciate that they come with USB and network connectivity.  That way you don\u2019t have to decide whether it\u2019ll be connected directly to a server or hosted on the network. \n\nCan anyone suggest another consumer grade enclosure or NaS that\u2019s comparable? USB and Ethernet, with support for mix and match drives, And is compatible with ext4?\n\nA while ago, I found a Linux application that could do the mismatched drives, but forgot the name. But because it could only be used as network storage it didn\u2019t seem compelling \n\nMy reading about synologies indicates that they need identical sized drives, so that nixes them. \n\nWhat else is out there? Any suggestions appreciated!", "author_fullname": "t2_9cjip", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Storage suggestions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zzb792", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "nsfw", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672433590.0, "link_flair_type": "text", "wls": 3, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! I\u2019m hoping that this is the correct community to ask in, but if I\u2019m in tht wrong place I apologize in advance &lt;/p&gt;\n\n&lt;p&gt;I need to drastically increase the storage on my home network and also want to add redundancy. &lt;/p&gt;\n\n&lt;p&gt;I was looking at older Drobo models, which looked fantastic. I like the idea of a NAS that just uses the available disk space without needing have all the drives match exactly. I\u2019ve read that Linux support is lacking, though. Ext3 is fine, but ext4 isn\u2019t, apparently. &lt;/p&gt;\n\n&lt;p&gt;I also appreciate that they come with USB and network connectivity.  That way you don\u2019t have to decide whether it\u2019ll be connected directly to a server or hosted on the network. &lt;/p&gt;\n\n&lt;p&gt;Can anyone suggest another consumer grade enclosure or NaS that\u2019s comparable? USB and Ethernet, with support for mix and match drives, And is compatible with ext4?&lt;/p&gt;\n\n&lt;p&gt;A while ago, I found a Linux application that could do the mismatched drives, but forgot the name. But because it could only be used as network storage it didn\u2019t seem compelling &lt;/p&gt;\n\n&lt;p&gt;My reading about synologies indicates that they need identical sized drives, so that nixes them. &lt;/p&gt;\n\n&lt;p&gt;What else is out there? Any suggestions appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": true, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zzb792", "is_robot_indexable": true, "report_reasons": null, "author": "lucasjkr", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "promo_adult_nsfw", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zzb792/storage_suggestions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zzb792/storage_suggestions/", "subreddit_subscribers": 662915, "created_utc": 1672433590.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Does anyone has WD store return experience to share? They told me the return shipping is free as long as it's within 30 days of purchase.\n\nI did have to do a warranty replacement with them a while back and they didn't give me any trouble, so I'm wondering about purchasing from their online store.", "author_fullname": "t2_8b618kb0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Western Digital Store Return?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zzalzd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672432105.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone has WD store return experience to share? They told me the return shipping is free as long as it&amp;#39;s within 30 days of purchase.&lt;/p&gt;\n\n&lt;p&gt;I did have to do a warranty replacement with them a while back and they didn&amp;#39;t give me any trouble, so I&amp;#39;m wondering about purchasing from their online store.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zzalzd", "is_robot_indexable": true, "report_reasons": null, "author": "JustStranger6803", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zzalzd/western_digital_store_return/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zzalzd/western_digital_store_return/", "subreddit_subscribers": 662915, "created_utc": 1672432105.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Im not sure if I should ask this here or r/buildapc. Please remove if it is against the rules\n\nI found a good deal on a second hand corsair 900d and thinking of getting it. But I may need additional drive cages later on. Since it  is a pretty old case, I think it is impossible to get it from corsair or find it online.\n\nHow compatible are drive cages from other cases would be with this one? Or would it be possible to get it 3d printed? I don't care for the looks, I just would like to be able to add more drive cages when I need it.\n\nThis will be my first time building a pc so, sorry if it is a stupid question\n\nAlso if you have other comments on the case itself, please share", "author_fullname": "t2_r687it3e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Extra drive cages for Corsair 900D", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zz7jqd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672424556.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im not sure if I should ask this here or &lt;a href=\"/r/buildapc\"&gt;r/buildapc&lt;/a&gt;. Please remove if it is against the rules&lt;/p&gt;\n\n&lt;p&gt;I found a good deal on a second hand corsair 900d and thinking of getting it. But I may need additional drive cages later on. Since it  is a pretty old case, I think it is impossible to get it from corsair or find it online.&lt;/p&gt;\n\n&lt;p&gt;How compatible are drive cages from other cases would be with this one? Or would it be possible to get it 3d printed? I don&amp;#39;t care for the looks, I just would like to be able to add more drive cages when I need it.&lt;/p&gt;\n\n&lt;p&gt;This will be my first time building a pc so, sorry if it is a stupid question&lt;/p&gt;\n\n&lt;p&gt;Also if you have other comments on the case itself, please share&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "40 TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zz7jqd", "is_robot_indexable": true, "report_reasons": null, "author": "lemmeanon", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/zz7jqd/extra_drive_cages_for_corsair_900d/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zz7jqd/extra_drive_cages_for_corsair_900d/", "subreddit_subscribers": 662915, "created_utc": 1672424556.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello! I had an Iomega NAS from 2011 but the fan failed last year. I changed them 2 times but the new fans don't last (it's the same ID model but they doesn't work the same). I would like to salvage my 2tb drive and put it in another enclosure, I can format the drive to another file allocation table as I can still access files and move them on my current USB drives. I don't need raid or any server capacities, I just want the HDD available over my network. Only important stuff are pictures but those are backup in 3 places in 3 different spaces (2 USB drives + Cloud). My main usage is purely ease of use for my family; instead moving files around over USB drive, I prefer to have a single network IP that every device can access via SMB. Thanks a lot for your help!", "author_fullname": "t2_n8mdp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Single bay NAS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zzf4tu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672443411.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! I had an Iomega NAS from 2011 but the fan failed last year. I changed them 2 times but the new fans don&amp;#39;t last (it&amp;#39;s the same ID model but they doesn&amp;#39;t work the same). I would like to salvage my 2tb drive and put it in another enclosure, I can format the drive to another file allocation table as I can still access files and move them on my current USB drives. I don&amp;#39;t need raid or any server capacities, I just want the HDD available over my network. Only important stuff are pictures but those are backup in 3 places in 3 different spaces (2 USB drives + Cloud). My main usage is purely ease of use for my family; instead moving files around over USB drive, I prefer to have a single network IP that every device can access via SMB. Thanks a lot for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zzf4tu", "is_robot_indexable": true, "report_reasons": null, "author": "gifred", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zzf4tu/single_bay_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zzf4tu/single_bay_nas/", "subreddit_subscribers": 662915, "created_utc": 1672443411.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a Jellyfin media server running on an Unraid NAS with about 2TB of content. When I first setup the media server, I ripped and torrented content then encoded it to 2000Kb/s, but I now (obviously) realise that this is an incredibly low bitrate/quality, so I wanted to improve the quality of my content.\n\nWhat I'm doing now is finding higher quality torrents and downloading them, then re-encoding the content with Handbrake to make everything consistent. I re-encode everything to h264 with a constant framerate the same as the source, with 2 audio tracks, one to pass through the original audio (to preserve things like Dolby Atmos) and the other as AAC stereo for mobile devices, and pass through any subtitles. I use a tool I made to find the average bitrate of the torrented content and set that as the desired average bitrate in Handbrake. \n\nThis is all part of a Handbrake preset I made as I like trying to keep everything consistent, but I'm wondering if this is actually the best way of doing things to preserve as much quality as possible while keeping file sizes reasonable (yes I know h265 is better for file sizes, but most of my media server clients don't support it and my Unraid server isn't powerful enough for transcoding).", "author_fullname": "t2_nloj51k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Encoding video for media server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zzkqkv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672459077.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a Jellyfin media server running on an Unraid NAS with about 2TB of content. When I first setup the media server, I ripped and torrented content then encoded it to 2000Kb/s, but I now (obviously) realise that this is an incredibly low bitrate/quality, so I wanted to improve the quality of my content.&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m doing now is finding higher quality torrents and downloading them, then re-encoding the content with Handbrake to make everything consistent. I re-encode everything to h264 with a constant framerate the same as the source, with 2 audio tracks, one to pass through the original audio (to preserve things like Dolby Atmos) and the other as AAC stereo for mobile devices, and pass through any subtitles. I use a tool I made to find the average bitrate of the torrented content and set that as the desired average bitrate in Handbrake. &lt;/p&gt;\n\n&lt;p&gt;This is all part of a Handbrake preset I made as I like trying to keep everything consistent, but I&amp;#39;m wondering if this is actually the best way of doing things to preserve as much quality as possible while keeping file sizes reasonable (yes I know h265 is better for file sizes, but most of my media server clients don&amp;#39;t support it and my Unraid server isn&amp;#39;t powerful enough for transcoding).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zzkqkv", "is_robot_indexable": true, "report_reasons": null, "author": "Jeff-with-a-ph", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zzkqkv/encoding_video_for_media_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zzkqkv/encoding_video_for_media_server/", "subreddit_subscribers": 662915, "created_utc": 1672459077.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello All,\n\n   I am trying to archive all the Cutthroat Kitchen aftershows from the food network site. However, I am having trouble downloading them from the site. Anyone have any recommendations how to easily download the videos? These are free and not a paid service so I don't think it violates the rules. Any help is appreciated. Link below:\n\n&amp;#x200B;\n\n[https://www.foodnetwork.com/videos/channels/altons-after-show-season-1](https://www.foodnetwork.com/videos/channels/altons-after-show-season-1)", "author_fullname": "t2_hilrs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Riping from Food Network", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zzimr4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1672452847.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello All,&lt;/p&gt;\n\n&lt;p&gt;I am trying to archive all the Cutthroat Kitchen aftershows from the food network site. However, I am having trouble downloading them from the site. Anyone have any recommendations how to easily download the videos? These are free and not a paid service so I don&amp;#39;t think it violates the rules. Any help is appreciated. Link below:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.foodnetwork.com/videos/channels/altons-after-show-season-1\"&gt;https://www.foodnetwork.com/videos/channels/altons-after-show-season-1&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/K3r_cYY_91na2OS8ciwPhlsyBtV6_y7A3fekpI6ulb4.jpg?auto=webp&amp;s=98b75a58eebdb2d0fb1f2b6ac2f89a324f3966e0", "width": 616, "height": 462}, "resolutions": [{"url": "https://external-preview.redd.it/K3r_cYY_91na2OS8ciwPhlsyBtV6_y7A3fekpI6ulb4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2e22c396e32059c1b519c014c996698584b9338b", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/K3r_cYY_91na2OS8ciwPhlsyBtV6_y7A3fekpI6ulb4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=525683fe25f7207a3c9ff5f3e2efd5bcb2febe80", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/K3r_cYY_91na2OS8ciwPhlsyBtV6_y7A3fekpI6ulb4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fb600f0dbaa6821c3d305f804511e8f412d055a5", "width": 320, "height": 240}], "variants": {}, "id": "EztekyicgXrzJ_Isskqy77XEQ133VUg09PX45JGZ7M4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zzimr4", "is_robot_indexable": true, "report_reasons": null, "author": "Matthew_C1314", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zzimr4/riping_from_food_network/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zzimr4/riping_from_food_network/", "subreddit_subscribers": 662915, "created_utc": 1672452847.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "How to tell if a zip/rar/7z file is split with a program like 7-zip?", "author_fullname": "t2_6m84ad7z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to tell if a zip/rar/7z file is split?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zzi191", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672451167.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How to tell if a zip/rar/7z file is split with a program like 7-zip?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zzi191", "is_robot_indexable": true, "report_reasons": null, "author": "Jungy1eong", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zzi191/how_to_tell_if_a_ziprar7z_file_is_split/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zzi191/how_to_tell_if_a_ziprar7z_file_is_split/", "subreddit_subscribers": 662915, "created_utc": 1672451167.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "The title basically says it all. I am contemplating putting an aio into my DIY NAS. I am not sure what size would fit in there however when it is fully stocked with hard drives. From videos I've seen, space is definitely lost. So, I just want to confirm before buying one.", "author_fullname": "t2_rwbgmvw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What size AIO can you fit on the top of a Fractal Design 7 XL full of HDDs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zzfor0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672444829.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The title basically says it all. I am contemplating putting an aio into my DIY NAS. I am not sure what size would fit in there however when it is fully stocked with hard drives. From videos I&amp;#39;ve seen, space is definitely lost. So, I just want to confirm before buying one.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zzfor0", "is_robot_indexable": true, "report_reasons": null, "author": "Karizmology", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zzfor0/what_size_aio_can_you_fit_on_the_top_of_a_fractal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zzfor0/what_size_aio_can_you_fit_on_the_top_of_a_fractal/", "subreddit_subscribers": 662915, "created_utc": 1672444829.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm building a NAS with windows storage spaces (NTFS, not Refs as it is being removed from windows 10 pro) but I'm wondering how can I achieve some level of data integrity to avoid backing up corrupted files. I know snapraid has bit rot protection but can't find any examples on using storage spaces with snapraid (no, I don't want to use stablebit drivepool). Should I use individual drives instead and manually manage what's data and what's parity? What are some good tools to check for data integrity?", "author_fullname": "t2_22mo7vki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data integrity on Windows 10 Pro storage spaces", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zzfft9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672444204.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m building a NAS with windows storage spaces (NTFS, not Refs as it is being removed from windows 10 pro) but I&amp;#39;m wondering how can I achieve some level of data integrity to avoid backing up corrupted files. I know snapraid has bit rot protection but can&amp;#39;t find any examples on using storage spaces with snapraid (no, I don&amp;#39;t want to use stablebit drivepool). Should I use individual drives instead and manually manage what&amp;#39;s data and what&amp;#39;s parity? What are some good tools to check for data integrity?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zzfft9", "is_robot_indexable": true, "report_reasons": null, "author": "gr4viityy", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zzfft9/data_integrity_on_windows_10_pro_storage_spaces/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zzfft9/data_integrity_on_windows_10_pro_storage_spaces/", "subreddit_subscribers": 662915, "created_utc": 1672444204.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Talk about general topics in our Discussion Thread!\n\n* Try out new software that you liked/hated? \n* Tell us about that $40 2TB MicroSD card from Amazon that's totally not a scam\n* Come show us how much data you lost since you didn't have backups!\n\nTotally not an attempt to build community rapport.", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DataHoarder Discussion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zzc3qa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Bi-Weekly Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672435809.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Talk about general topics in our Discussion Thread!&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Try out new software that you liked/hated? &lt;/li&gt;\n&lt;li&gt;Tell us about that $40 2TB MicroSD card from Amazon that&amp;#39;s totally not a scam&lt;/li&gt;\n&lt;li&gt;Come show us how much data you lost since you didn&amp;#39;t have backups!&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Totally not an attempt to build community rapport.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "zzc3qa", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zzc3qa/datahoarder_discussion/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/DataHoarder/comments/zzc3qa/datahoarder_discussion/", "subreddit_subscribers": 662915, "created_utc": 1672435809.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,\n\nI'm currently using my 2 x 16Tb disk in RAID1 setup build on Synology 918.\nI'm looking for expansion options. I have considered so far following:\n- adding new 16Tb drive and building RAID5\n- adding new 16Tb drive on side as standalone\n- adding 2 x new 4Tb in RAID1 and building RAID0 2x16Tb\n- adding 2 x new 4Tb in RAID1 and leaving 2 x 16Tb each standalone\n\nMy critical data (documents, photos etc) are around 3Tb in size, currently placed on 16Tb volume together with some unnecessary data like movies, TV shows, ISO data store for ESXi etc. \n\nI'm slowly increasing critical data, but the non critical one is growing really fast.\n\nIn first option, I will have one volume, but with RAID5. Considering my critical data is being backed up to USB, I could take risk of potential rebuild of 32Tb volume, but still it's RAID5. \nIn last option, my critical data would move to separate volume, while non critical data could spin on standalone 2x16Tb drives.\n\nWhich would you recommend to me? Is that RAID5 really a risk if the critical data is backed up? I'm also worried about speed in RAID5, but maybe nvme cache is an option?\n\nGuys please advise, as I'm bit lost.", "author_fullname": "t2_jceh629e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Expansion options", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zzb9xu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672433782.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently using my 2 x 16Tb disk in RAID1 setup build on Synology 918.\nI&amp;#39;m looking for expansion options. I have considered so far following:\n- adding new 16Tb drive and building RAID5\n- adding new 16Tb drive on side as standalone\n- adding 2 x new 4Tb in RAID1 and building RAID0 2x16Tb\n- adding 2 x new 4Tb in RAID1 and leaving 2 x 16Tb each standalone&lt;/p&gt;\n\n&lt;p&gt;My critical data (documents, photos etc) are around 3Tb in size, currently placed on 16Tb volume together with some unnecessary data like movies, TV shows, ISO data store for ESXi etc. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m slowly increasing critical data, but the non critical one is growing really fast.&lt;/p&gt;\n\n&lt;p&gt;In first option, I will have one volume, but with RAID5. Considering my critical data is being backed up to USB, I could take risk of potential rebuild of 32Tb volume, but still it&amp;#39;s RAID5. \nIn last option, my critical data would move to separate volume, while non critical data could spin on standalone 2x16Tb drives.&lt;/p&gt;\n\n&lt;p&gt;Which would you recommend to me? Is that RAID5 really a risk if the critical data is backed up? I&amp;#39;m also worried about speed in RAID5, but maybe nvme cache is an option?&lt;/p&gt;\n\n&lt;p&gt;Guys please advise, as I&amp;#39;m bit lost.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zzb9xu", "is_robot_indexable": true, "report_reasons": null, "author": "Slushfall", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zzb9xu/expansion_options/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zzb9xu/expansion_options/", "subreddit_subscribers": 662915, "created_utc": 1672433782.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_59dkw3fm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "10TB WD Red NAS Drive (WD101EFBX) $159.99 -- Sold by WD on Amazon", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "sale", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zz8wp7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.53, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Sale", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1672427968.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "amazon.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.amazon.com/Western-Digital-10TB-Internal-Drive/dp/B08TZPS4QQ/?th=1", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ef8232de-b94e-11eb-ba29-0ed106a6f983", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zz8wp7", "is_robot_indexable": true, "report_reasons": null, "author": "Dorbiman", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zz8wp7/10tb_wd_red_nas_drive_wd101efbx_15999_sold_by_wd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.amazon.com/Western-Digital-10TB-Internal-Drive/dp/B08TZPS4QQ/?th=1", "subreddit_subscribers": 662915, "created_utc": 1672427968.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I think I can sum up my cloud storage needs with two 2 points...\n\n**1.** **I** ***don't*** **want continuous backup, I want to do it manually.**\n\nI don't have enough changing data on my desktop to need any sort of continuous backup. The data I'm looking to backup is mainly just 1) decades of old photos, videos, documents that aren't ever being changed/updated, 2) a handful of documents I update from time to time (e.g. weekly, monthly), and 3) new documents that show up infrequently and don't get updated after that (e.g. yearly tax documents).\n\nSo, I basically just have a bunch of stuff I'd like to manually upload somewhere and store as a backup (in addition to the external drive I already do this with), and then I'd like to manually upload some additional stuff or an updated version of a file that's already being stored on occasion.\n\n**2. I** ***do*** **want zero-knowledge encryption.** \n\nFor all the usual security/privacy reasons.\n\n**What would be the best option(s) for this purpose?** \n\nThanks in advance for any advice.", "author_fullname": "t2_noqb7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What cloud backup/storage option is best for this purpose?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zz8abo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672426437.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I think I can sum up my cloud storage needs with two 2 points...&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;1.&lt;/strong&gt; &lt;strong&gt;I&lt;/strong&gt; &lt;strong&gt;&lt;em&gt;don&amp;#39;t&lt;/em&gt;&lt;/strong&gt; &lt;strong&gt;want continuous backup, I want to do it manually.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have enough changing data on my desktop to need any sort of continuous backup. The data I&amp;#39;m looking to backup is mainly just 1) decades of old photos, videos, documents that aren&amp;#39;t ever being changed/updated, 2) a handful of documents I update from time to time (e.g. weekly, monthly), and 3) new documents that show up infrequently and don&amp;#39;t get updated after that (e.g. yearly tax documents).&lt;/p&gt;\n\n&lt;p&gt;So, I basically just have a bunch of stuff I&amp;#39;d like to manually upload somewhere and store as a backup (in addition to the external drive I already do this with), and then I&amp;#39;d like to manually upload some additional stuff or an updated version of a file that&amp;#39;s already being stored on occasion.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;2. I&lt;/strong&gt; &lt;strong&gt;&lt;em&gt;do&lt;/em&gt;&lt;/strong&gt; &lt;strong&gt;want zero-knowledge encryption.&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;For all the usual security/privacy reasons.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What would be the best option(s) for this purpose?&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for any advice.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zz8abo", "is_robot_indexable": true, "report_reasons": null, "author": "andleaveatrail", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zz8abo/what_cloud_backupstorage_option_is_best_for_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zz8abo/what_cloud_backupstorage_option_is_best_for_this/", "subreddit_subscribers": 662915, "created_utc": 1672426437.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019m looking for a modern scanner that also can imprint text such as Date or sequence counter. \nPreferably able to process 100+ sheets at a time. \nNot more than $3000 \n\nAny recommendation?", "author_fullname": "t2_bsvbpvnt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for scanner that can also imprint", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zz5y29", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672420756.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m looking for a modern scanner that also can imprint text such as Date or sequence counter. \nPreferably able to process 100+ sheets at a time. \nNot more than $3000 &lt;/p&gt;\n\n&lt;p&gt;Any recommendation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zz5y29", "is_robot_indexable": true, "report_reasons": null, "author": "Turbulent_Ad638", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zz5y29/looking_for_scanner_that_can_also_imprint/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zz5y29/looking_for_scanner_that_can_also_imprint/", "subreddit_subscribers": 662915, "created_utc": 1672420756.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm thinking of starting up my own media server and I want to create offsite backups that I do not need to worry about bitrot for. I'm certain that I want LTO for this, these backups are cold storage and are unlikely to be accessed with any kind of frequency. I'll likely backup other media besides video later but that's where I'm starting.\n\n&amp;#x200B;\n\nThe question I have is if [this drive](https://www.ebay.com/itm/404070258528?autorefresh=true) is the kind of drive I'm looking for. From what I understand, LTO drives salvaged from libraries are unusable outside of libraries. Given that I know very little about model numbers, I have no idea if this drive is one of those drives. I'm going to ask the seller but idk if the seller will know either. Alternatively, I could grab [this drive](https://www.ebay.com/itm/364092298827) for roughly the same price and it look to also be rack-mountable, a bonus to me. Which would you suggest?", "author_fullname": "t2_ro680jri", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I pull the trigger on this LTO drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zz4kih", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1672417375.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m thinking of starting up my own media server and I want to create offsite backups that I do not need to worry about bitrot for. I&amp;#39;m certain that I want LTO for this, these backups are cold storage and are unlikely to be accessed with any kind of frequency. I&amp;#39;ll likely backup other media besides video later but that&amp;#39;s where I&amp;#39;m starting.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The question I have is if &lt;a href=\"https://www.ebay.com/itm/404070258528?autorefresh=true\"&gt;this drive&lt;/a&gt; is the kind of drive I&amp;#39;m looking for. From what I understand, LTO drives salvaged from libraries are unusable outside of libraries. Given that I know very little about model numbers, I have no idea if this drive is one of those drives. I&amp;#39;m going to ask the seller but idk if the seller will know either. Alternatively, I could grab &lt;a href=\"https://www.ebay.com/itm/364092298827\"&gt;this drive&lt;/a&gt; for roughly the same price and it look to also be rack-mountable, a bonus to me. Which would you suggest?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/KUCE9AJQpmFmBKPudc1PIAxn1SK7MRpkH1o6DSSnzzo.jpg?auto=webp&amp;s=99e106b2ac15c3f4bb6bb24a62a9a12869494d8a", "width": 400, "height": 278}, "resolutions": [{"url": "https://external-preview.redd.it/KUCE9AJQpmFmBKPudc1PIAxn1SK7MRpkH1o6DSSnzzo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a5879346b9e23ecc4f22bf231f33883060475efc", "width": 108, "height": 75}, {"url": "https://external-preview.redd.it/KUCE9AJQpmFmBKPudc1PIAxn1SK7MRpkH1o6DSSnzzo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ac2ac85b7565bed52c0eaed1b8392cc01ea63ddf", "width": 216, "height": 150}, {"url": "https://external-preview.redd.it/KUCE9AJQpmFmBKPudc1PIAxn1SK7MRpkH1o6DSSnzzo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=da798c86b3a846dd94266f4af5f533d6a0b36c11", "width": 320, "height": 222}], "variants": {}, "id": "f4RHf9FrhfGQ_QJGqAFsy1iXGLzaZSyo33mIDPwLDuY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zz4kih", "is_robot_indexable": true, "report_reasons": null, "author": "Anon_Gentleman", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zz4kih/should_i_pull_the_trigger_on_this_lto_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zz4kih/should_i_pull_the_trigger_on_this_lto_drive/", "subreddit_subscribers": 662915, "created_utc": 1672417375.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi!\n\nI'm looking for a rather cheap 1TB NVME SSD that I will use as a portable SSD (with a SSD enclosure).\n\nI'm aware of USB speed limitations so I'm also planning on getting a new PC with USB 3.2 support.\n\nI have found these two models which seem to have good price-performance ratios.\n\n1. [SNV2S/1000G Kingston NV2 NVMe\u2122 SSD, 1 TB, M.2 PCIe](https://www.reichelt.com/fr/en/kingston-nv2-nvme-8482-ssd-1-tb-m-2-pcie-snv2s-1000g-p335967.html)\n2. [HIKVISION M.2 Internal SSD 1024 GB E3000 PCIe Gen 3x4, NVMe 3D TLC](https://www.amazon.de/dp/B09MPN17WS?smid=A3JWKAKR8XB7XF)\n\nWhich one would you recommend?", "author_fullname": "t2_j1hiqzy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which SSD would you recommend?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zz4fnf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672417043.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for a rather cheap 1TB NVME SSD that I will use as a portable SSD (with a SSD enclosure).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m aware of USB speed limitations so I&amp;#39;m also planning on getting a new PC with USB 3.2 support.&lt;/p&gt;\n\n&lt;p&gt;I have found these two models which seem to have good price-performance ratios.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;a href=\"https://www.reichelt.com/fr/en/kingston-nv2-nvme-8482-ssd-1-tb-m-2-pcie-snv2s-1000g-p335967.html\"&gt;SNV2S/1000G Kingston NV2 NVMe\u2122 SSD, 1 TB, M.2 PCIe&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.amazon.de/dp/B09MPN17WS?smid=A3JWKAKR8XB7XF\"&gt;HIKVISION M.2 Internal SSD 1024 GB E3000 PCIe Gen 3x4, NVMe 3D TLC&lt;/a&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Which one would you recommend?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zz4fnf", "is_robot_indexable": true, "report_reasons": null, "author": "TerribleCatastrophy", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zz4fnf/which_ssd_would_you_recommend/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zz4fnf/which_ssd_would_you_recommend/", "subreddit_subscribers": 662915, "created_utc": 1672417043.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "There was a seedbox that still had the Videos a couple weeks ago but now it seems to have shut off and stupid me didn\u2019t save them cause my hard drives were full at the time.\n\nhttps://old.reddit.com/r/DataHoarder/comments/flz0kx/need_help_downloading_video_from_the_met_opera/\n\nhttps://old.reddit.com/r/opendirectories/comments/q382t4/some_videos_of_famous_operas_for_opera_lovers/\n\nhttps://old.reddit.com/r/Piracy/comments/fjz5yr/downloading_metoperas_free_streams_for_the_next/\n\nhttps://old.reddit.com/r/Piracy/comments/jdrbe3/anybody_knows_how_to_download_a_met_opera/", "author_fullname": "t2_27sumuq7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone on here that did backup the Met Opera recordings which aired freely 2-3 years ago?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zz3ip4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672414888.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There was a seedbox that still had the Videos a couple weeks ago but now it seems to have shut off and stupid me didn\u2019t save them cause my hard drives were full at the time.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://old.reddit.com/r/DataHoarder/comments/flz0kx/need_help_downloading_video_from_the_met_opera/\"&gt;https://old.reddit.com/r/DataHoarder/comments/flz0kx/need_help_downloading_video_from_the_met_opera/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://old.reddit.com/r/opendirectories/comments/q382t4/some_videos_of_famous_operas_for_opera_lovers/\"&gt;https://old.reddit.com/r/opendirectories/comments/q382t4/some_videos_of_famous_operas_for_opera_lovers/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://old.reddit.com/r/Piracy/comments/fjz5yr/downloading_metoperas_free_streams_for_the_next/\"&gt;https://old.reddit.com/r/Piracy/comments/fjz5yr/downloading_metoperas_free_streams_for_the_next/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://old.reddit.com/r/Piracy/comments/jdrbe3/anybody_knows_how_to_download_a_met_opera/\"&gt;https://old.reddit.com/r/Piracy/comments/jdrbe3/anybody_knows_how_to_download_a_met_opera/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zz3ip4", "is_robot_indexable": true, "report_reasons": null, "author": "datahoarderx2018", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zz3ip4/anyone_on_here_that_did_backup_the_met_opera/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zz3ip4/anyone_on_here_that_did_backup_the_met_opera/", "subreddit_subscribers": 662915, "created_utc": 1672414888.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Got 2 x 8 TB drives recently off ebay , but in the hurry to get in there, I didn't realise they were SAS instead of SATA (HITACHI GLOBAL 8TB 7.2K RPM SAS III 3.5 INCH (HUH728080AL4200-IBM).  \n\n\nThe intended goal was to have them as external drives to my Lenovo ThinkCentre M720Q as part of a Sabrent 4 Bay docking station, but since that is SATA only, there goes that plan.\n\n&amp;#x200B;\n\nWhat are my alternatives?  \nMaybe an Icy Dock 4 Bay 2.5 Sas Sata Mobile Rack? \n\n(4 bay as now that I know what they are,  I could expand later)  \nThat seems to work (on paper), but how would I connect that to the Lenovo?\n\nOr is there something else you could recommend?  \n\n\nThanks!", "author_fullname": "t2_hpwog", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to connect 2 SAS drives as external drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zz2ehu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672412025.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Got 2 x 8 TB drives recently off ebay , but in the hurry to get in there, I didn&amp;#39;t realise they were SAS instead of SATA (HITACHI GLOBAL 8TB 7.2K RPM SAS III 3.5 INCH (HUH728080AL4200-IBM).  &lt;/p&gt;\n\n&lt;p&gt;The intended goal was to have them as external drives to my Lenovo ThinkCentre M720Q as part of a Sabrent 4 Bay docking station, but since that is SATA only, there goes that plan.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What are my alternatives?&lt;br/&gt;\nMaybe an Icy Dock 4 Bay 2.5 Sas Sata Mobile Rack? &lt;/p&gt;\n\n&lt;p&gt;(4 bay as now that I know what they are,  I could expand later)&lt;br/&gt;\nThat seems to work (on paper), but how would I connect that to the Lenovo?&lt;/p&gt;\n\n&lt;p&gt;Or is there something else you could recommend?  &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zz2ehu", "is_robot_indexable": true, "report_reasons": null, "author": "bsab80", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zz2ehu/how_to_connect_2_sas_drives_as_external_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zz2ehu/how_to_connect_2_sas_drives_as_external_drives/", "subreddit_subscribers": 662915, "created_utc": 1672412025.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}