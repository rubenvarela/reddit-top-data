{"kind": "Listing", "data": {"after": "t3_zos7dv", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How books are scanned.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_zopioc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2032, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_qodf051g", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 2032, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/703YrHcnLbRwveIOPpeaSiLKhzIRBCU6ibOix14YgbU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "interestingasfuck", "selftext": "", "author_fullname": "t2_4b5lm9jz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How books are scanned.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/interestingasfuck", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_zo20o7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 783, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 783, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/703YrHcnLbRwveIOPpeaSiLKhzIRBCU6ibOix14YgbU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "created": 1671266563.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.imgur.com", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.imgur.com/5Ts3xEp.gifv", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/SBUKflKHcSRxZnBw0tRv7-cVfcBov5-aEN2jQA3EnO0.jpg?auto=webp&amp;s=453f126fde1ad0e9f21a2cd50134a5a072df752a", "width": 406, "height": 720}, "resolutions": [{"url": "https://external-preview.redd.it/SBUKflKHcSRxZnBw0tRv7-cVfcBov5-aEN2jQA3EnO0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8ee0a6af03c78a14e94fad352d4d1a2fee83eea4", "width": 108, "height": 191}, {"url": "https://external-preview.redd.it/SBUKflKHcSRxZnBw0tRv7-cVfcBov5-aEN2jQA3EnO0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=25e4710d32f40b6cd43e0163956a91bf726e2323", "width": 216, "height": 383}, {"url": "https://external-preview.redd.it/SBUKflKHcSRxZnBw0tRv7-cVfcBov5-aEN2jQA3EnO0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=31360c7a3d3efd43d0d77f8a5cbb243b105c7394", "width": 320, "height": 567}], "variants": {}, "id": "iKRWgwf50bKsH6-hW4Rmc7m5VBY_c5WFisaUyZggjbk"}], "reddit_video_preview": {"bitrate_kbps": 2400, "fallback_url": "https://v.redd.it/bp7yf59vzk6a1/DASH_720.mp4", "height": 720, "width": 406, "scrubber_media_url": "https://v.redd.it/bp7yf59vzk6a1/DASH_96.mp4", "dash_url": "https://v.redd.it/bp7yf59vzk6a1/DASHPlaylist.mpd", "duration": 9, "hls_url": "https://v.redd.it/bp7yf59vzk6a1/HLSPlaylist.m3u8", "is_gif": true, "transcoding_status": "completed"}, "enabled": false}, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 150, "id": "award_f44611f1-b89e-46dc-97fe-892280b13b82", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Thank you stranger. Shows the award.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Helpful", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png"}], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qhsa", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zo20o7", "is_robot_indexable": true, "report_reasons": null, "author": "AmerBekic", "discussion_type": null, "num_comments": 60, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/interestingasfuck/comments/zo20o7/how_books_are_scanned/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.imgur.com/5Ts3xEp.gifv", "subreddit_subscribers": 10897536, "created_utc": 1671266563.0, "num_crossposts": 7, "media": null, "is_video": false}], "created": 1671336459.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.imgur.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.imgur.com/5Ts3xEp.gifv", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/SBUKflKHcSRxZnBw0tRv7-cVfcBov5-aEN2jQA3EnO0.jpg?auto=webp&amp;s=453f126fde1ad0e9f21a2cd50134a5a072df752a", "width": 406, "height": 720}, "resolutions": [{"url": "https://external-preview.redd.it/SBUKflKHcSRxZnBw0tRv7-cVfcBov5-aEN2jQA3EnO0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8ee0a6af03c78a14e94fad352d4d1a2fee83eea4", "width": 108, "height": 191}, {"url": "https://external-preview.redd.it/SBUKflKHcSRxZnBw0tRv7-cVfcBov5-aEN2jQA3EnO0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=25e4710d32f40b6cd43e0163956a91bf726e2323", "width": 216, "height": 383}, {"url": "https://external-preview.redd.it/SBUKflKHcSRxZnBw0tRv7-cVfcBov5-aEN2jQA3EnO0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=31360c7a3d3efd43d0d77f8a5cbb243b105c7394", "width": 320, "height": 567}], "variants": {}, "id": "iKRWgwf50bKsH6-hW4Rmc7m5VBY_c5WFisaUyZggjbk"}], "reddit_video_preview": {"bitrate_kbps": 2400, "fallback_url": "https://v.redd.it/bp7yf59vzk6a1/DASH_720.mp4", "height": 720, "width": 406, "scrubber_media_url": "https://v.redd.it/bp7yf59vzk6a1/DASH_96.mp4", "dash_url": "https://v.redd.it/bp7yf59vzk6a1/DASHPlaylist.mpd", "duration": 9, "hls_url": "https://v.redd.it/bp7yf59vzk6a1/HLSPlaylist.m3u8", "is_gif": true, "transcoding_status": "completed"}, "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zopioc", "is_robot_indexable": true, "report_reasons": null, "author": "ReturnMuch9510", "discussion_type": null, "num_comments": 111, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_zo20o7", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zopioc/how_books_are_scanned/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.imgur.com/5Ts3xEp.gifv", "subreddit_subscribers": 659988, "created_utc": 1671336459.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_y9d76v7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "wife bought me a 10tb drive for Christmas, it was mislabelled at the factory and it's actually a 12tb drive!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"e32q6ptsro6a1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 164, "x": 108, "u": "https://preview.redd.it/e32q6ptsro6a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fc07ba06291c98f54871ecacc9ca96e7c1cbb659"}, {"y": 328, "x": 216, "u": "https://preview.redd.it/e32q6ptsro6a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3268aad84863a4f181d28d0d674a313116a83d10"}, {"y": 485, "x": 320, "u": "https://preview.redd.it/e32q6ptsro6a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a90a5640f2572aa0406253064e56e3c5f58fd0a2"}, {"y": 971, "x": 640, "u": "https://preview.redd.it/e32q6ptsro6a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=05b48319920dc2655e59431c581bfb203fc3f9db"}, {"y": 1457, "x": 960, "u": "https://preview.redd.it/e32q6ptsro6a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1e1a98cd7e7da9aa324293c4a0e7a396ffac86fa"}, {"y": 1640, "x": 1080, "u": "https://preview.redd.it/e32q6ptsro6a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dbbc61fdf98e909aebb071deafe391c2508f0593"}], "s": {"y": 1640, "x": 1080, "u": "https://preview.redd.it/e32q6ptsro6a1.jpg?width=1080&amp;format=pjpg&amp;auto=webp&amp;s=14955ec5e1bb389e430cb57dadac85810685004f"}, "id": "e32q6ptsro6a1"}, "pgm5o4wsro6a1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 192, "x": 108, "u": "https://preview.redd.it/pgm5o4wsro6a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3bb6888ff9d81533532991a5623e25f1ad2e36fb"}, {"y": 384, "x": 216, "u": "https://preview.redd.it/pgm5o4wsro6a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=98e4a95d5dff5e514f95c882723eb326a0d4e8f2"}, {"y": 568, "x": 320, "u": "https://preview.redd.it/pgm5o4wsro6a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cd401d395c3997294c0b4a49681e8facf7dc2a00"}, {"y": 1137, "x": 640, "u": "https://preview.redd.it/pgm5o4wsro6a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1b80ae9263bafd4ba4b1ac336273c971b906cb76"}, {"y": 1706, "x": 960, "u": "https://preview.redd.it/pgm5o4wsro6a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=40e1eac36939f72bb733a82e1b799807e504b032"}, {"y": 1920, "x": 1080, "u": "https://preview.redd.it/pgm5o4wsro6a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c6de686304bd34069493e73ec8ffd2c887379675"}], "s": {"y": 4032, "x": 2268, "u": "https://preview.redd.it/pgm5o4wsro6a1.jpg?width=2268&amp;format=pjpg&amp;auto=webp&amp;s=c16837b83bce23931c309dca7e92438ab95026e9"}, "id": "pgm5o4wsro6a1"}}, "name": "t3_zp2srs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 565, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "e32q6ptsro6a1", "id": 220470265}, {"media_id": "pgm5o4wsro6a1", "id": 220470266}]}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 565, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/cnENuY7O9iqJflN1NbxecDGmwNN_bYcfWVhZfIQFFMY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671382175.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/zp2srs", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zp2srs", "is_robot_indexable": true, "report_reasons": null, "author": "joebaes1", "discussion_type": null, "num_comments": 99, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zp2srs/wife_bought_me_a_10tb_drive_for_christmas_it_was/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/zp2srs", "subreddit_subscribers": 659988, "created_utc": 1671382175.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_odki8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New Tech Job! Found a box full of HDD. Boss said I can keep them. I\u2019m happy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_zp569i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 147, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 147, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/7rT8hAuqT3MRTR1MP1OPlAD6ARCTf2wUJ5qmFny8EAw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671389040.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/8uf4g6iqtq6a1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/8uf4g6iqtq6a1.jpg?auto=webp&amp;s=742f439986c868c421687ae06390ddd309ff173b", "width": 3024, "height": 4032}, "resolutions": [{"url": "https://preview.redd.it/8uf4g6iqtq6a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3a5ee1e7620de17342bd2f86995edd478f386251", "width": 108, "height": 144}, {"url": "https://preview.redd.it/8uf4g6iqtq6a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b935252f7fd053e24e9929ee292df56abc502c91", "width": 216, "height": 288}, {"url": "https://preview.redd.it/8uf4g6iqtq6a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=33ecbeab74199128f5c16c32716524c6b07dc42c", "width": 320, "height": 426}, {"url": "https://preview.redd.it/8uf4g6iqtq6a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fa9e8dfa288c1a56da4a8534e5092b1f4c9d0b5d", "width": 640, "height": 853}, {"url": "https://preview.redd.it/8uf4g6iqtq6a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1a613b20f0f93fa5fdf8cc4445ad1311a90d628e", "width": 960, "height": 1280}, {"url": "https://preview.redd.it/8uf4g6iqtq6a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a98f4c47cf953b6cefd2742c5b5a97755746e1f3", "width": 1080, "height": 1440}], "variants": {}, "id": "waPfL5UvWtGz8D9UFHcwEu0cbU_Zz873TExKpXg0as0"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zp569i", "is_robot_indexable": true, "report_reasons": null, "author": "wicodly", "discussion_type": null, "num_comments": 61, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zp569i/new_tech_job_found_a_box_full_of_hdd_boss_said_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/8uf4g6iqtq6a1.jpg", "subreddit_subscribers": 659988, "created_utc": 1671389040.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " Hello internet,\n\nI  commonly use sites like keep2share to download files and have been  using mullvad to bypass data limitations. Some videos are broken into multiple parts and I often pull my phone out to download simultaneously.\n\nI  was wondering if there was a more efficient way to do this from one  device and if I could do something like linking different browser  windows to different IP addresses. I am constantly downloading files and  am perfectly fine with the time investment it may take to set something  like this up.  \nI thought of Jdownloader but I think that uses proxies versus a VPN correct?  \n\n\nSorry for the newbie questions", "author_fullname": "t2_uxz2rq9l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using VPN to bypass file hoster limits", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zpancs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671403485.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello internet,&lt;/p&gt;\n\n&lt;p&gt;I  commonly use sites like keep2share to download files and have been  using mullvad to bypass data limitations. Some videos are broken into multiple parts and I often pull my phone out to download simultaneously.&lt;/p&gt;\n\n&lt;p&gt;I  was wondering if there was a more efficient way to do this from one  device and if I could do something like linking different browser  windows to different IP addresses. I am constantly downloading files and  am perfectly fine with the time investment it may take to set something  like this up.&lt;br/&gt;\nI thought of Jdownloader but I think that uses proxies versus a VPN correct?  &lt;/p&gt;\n\n&lt;p&gt;Sorry for the newbie questions&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zpancs", "is_robot_indexable": true, "report_reasons": null, "author": "ForeignEfficiency401", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zpancs/using_vpn_to_bypass_file_hoster_limits/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zpancs/using_vpn_to_bypass_file_hoster_limits/", "subreddit_subscribers": 659988, "created_utc": 1671403485.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Does Gallery-dl support downloading twitter images as png? It only gives me jpeg at least by default.", "author_fullname": "t2_kwwap53o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Gallery-dl with Twitter in PNG format?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zoqdtz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671339298.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does Gallery-dl support downloading twitter images as png? It only gives me jpeg at least by default.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zoqdtz", "is_robot_indexable": true, "report_reasons": null, "author": "diamond-emerald", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zoqdtz/gallerydl_with_twitter_in_png_format/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zoqdtz/gallerydl_with_twitter_in_png_format/", "subreddit_subscribers": 659988, "created_utc": 1671339298.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Title.", "author_fullname": "t2_6lxl9l3q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to transfer files from an external SSD to Google Drive without first having to download them on your PC/smartphone?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zp4gac", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671387064.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zp4gac", "is_robot_indexable": true, "report_reasons": null, "author": "-Sh33ph3rd3r-", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zp4gac/is_it_possible_to_transfer_files_from_an_external/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zp4gac/is_it_possible_to_transfer_files_from_an_external/", "subreddit_subscribers": 659988, "created_utc": 1671387064.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Just wasted a day messing about with UNRAID to realize it's limited to 30 drives. :-/\n\nI have a sizable pile of 5TB, 4TB, 3TB and 2TB drives.  I live somewhere where power is cheap and cooling is fresh air for 9 out of 12 months.  I have JBODs and \"IT\" flashed controllers to run more than I have.  All told, it's around .5 PB... someday, I'd like to break the PB barrier, but today is not that day.\n\nCan someone recommend a single software platform to support various disk sizes, reasonable (N+2) resillency and easy growth/failure replacement?\n\nUNRAID, too few disks.  TrueNAS, would need a seperate pool for each disk size, replacement blows.  I know next to nothing about OpenMediaVault but am going to fire that up here soon to poke about.  I see people complaining about NFS speeds, but in general, I don't need this to be super fast.\n\nI run a plex server (I actually won't run that as a plugin, even if the platform supports it) that servers up and transcodes 4K HDR content, a few infrastructure VMs and some game servers, but outside of my plex server being a consumer of large disk, I don't have significant performance needs.  My VMs I'll either run local or if I feel the need to go back to multiple VM hosts, I'll come up with something seperate from my bulk storage.\n\nThanks for perusing my wall of text.  Curious what other folks are using for large drive count systems. \n\nI'll head off the \"12TB refurbs are cheap\" response with \"there's nothing cheaper than what you already have.\"", "author_fullname": "t2_er16k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for Storage Software/Platform Recommendations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zpdnok", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671411753.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just wasted a day messing about with UNRAID to realize it&amp;#39;s limited to 30 drives. :-/&lt;/p&gt;\n\n&lt;p&gt;I have a sizable pile of 5TB, 4TB, 3TB and 2TB drives.  I live somewhere where power is cheap and cooling is fresh air for 9 out of 12 months.  I have JBODs and &amp;quot;IT&amp;quot; flashed controllers to run more than I have.  All told, it&amp;#39;s around .5 PB... someday, I&amp;#39;d like to break the PB barrier, but today is not that day.&lt;/p&gt;\n\n&lt;p&gt;Can someone recommend a single software platform to support various disk sizes, reasonable (N+2) resillency and easy growth/failure replacement?&lt;/p&gt;\n\n&lt;p&gt;UNRAID, too few disks.  TrueNAS, would need a seperate pool for each disk size, replacement blows.  I know next to nothing about OpenMediaVault but am going to fire that up here soon to poke about.  I see people complaining about NFS speeds, but in general, I don&amp;#39;t need this to be super fast.&lt;/p&gt;\n\n&lt;p&gt;I run a plex server (I actually won&amp;#39;t run that as a plugin, even if the platform supports it) that servers up and transcodes 4K HDR content, a few infrastructure VMs and some game servers, but outside of my plex server being a consumer of large disk, I don&amp;#39;t have significant performance needs.  My VMs I&amp;#39;ll either run local or if I feel the need to go back to multiple VM hosts, I&amp;#39;ll come up with something seperate from my bulk storage.&lt;/p&gt;\n\n&lt;p&gt;Thanks for perusing my wall of text.  Curious what other folks are using for large drive count systems. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ll head off the &amp;quot;12TB refurbs are cheap&amp;quot; response with &amp;quot;there&amp;#39;s nothing cheaper than what you already have.&amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zpdnok", "is_robot_indexable": true, "report_reasons": null, "author": "Thranx", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zpdnok/looking_for_storage_softwareplatform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zpdnok/looking_for_storage_softwareplatform/", "subreddit_subscribers": 659988, "created_utc": 1671411753.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Aloha! Among other things I'm a YouTube archivist on Linux system, with lots of videos to store, lots of HDDs of varying sizes, capacity (80-500GB) and age (several disks with BAD sectors that I wanna use as 3rd data duplicates). Then I have a single gaming PC with 2 HDD hotswap ports free. I'm looking for a hoarding setup solution, some guidance towards tools maybe? How could I improve my operation in relation to my low knowledge levels?\n\nHow I have it running currently, is I have a 1TB inside the PC that acts as \"landing\" for incoming data, which I manually process (rename, move around, compare files, remux), then I connect HDDs that I decide should pick them up. I keep track of all data in LibreOffice Spreadsheet: on HDD arrival I sometimes measure its SMART data and update it in the spreadsheet. Then on departure I open the disk with file manager in \"Flat View\", to then copy all file entries with their full path on that disk, paste into spreadsheet page dedicated for that disk (every disk has a dedicated page and I refer to them by unique numbers, magic marker'ed on the disks). All disks are encrypted and NTFS, but I'm looking to formatting them to something better (BTRFS? It says it verifies file integrity, so if the data decays over time it'll be automatically fixed?)\n\nI'm hoping for a solution that could automate some things, especially that spreadsheet, since it's hard to keep track off. I wish disks would be automatically indexed before ejection, and some database would keep track of:\n\n1. what videos are where,\n2. what videos don't have a duplicate on another disk (and which disk keeps that duplicate),\n3. disks are divided into groups A, A\\*, B, B\\*, where:\n\n* A's duplicate to other A's once;\n* \\*'s can't have its duplicates on another \\*;\n* B's duplicate from A's only (acting as third duplicate), amount of duplicates depends on amount of B's drives.\n\nAlso worth noting I'm quite a distro-hopper, so I appreciate solutions that I can migrate between OSes. Due to limited amount of drives I can inject simultaneously, I'm guessing data pooling isn't solution for me.", "author_fullname": "t2_7nxyjgm2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cold-only storage solution with database indexing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zpapw6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1671404023.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671403677.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Aloha! Among other things I&amp;#39;m a YouTube archivist on Linux system, with lots of videos to store, lots of HDDs of varying sizes, capacity (80-500GB) and age (several disks with BAD sectors that I wanna use as 3rd data duplicates). Then I have a single gaming PC with 2 HDD hotswap ports free. I&amp;#39;m looking for a hoarding setup solution, some guidance towards tools maybe? How could I improve my operation in relation to my low knowledge levels?&lt;/p&gt;\n\n&lt;p&gt;How I have it running currently, is I have a 1TB inside the PC that acts as &amp;quot;landing&amp;quot; for incoming data, which I manually process (rename, move around, compare files, remux), then I connect HDDs that I decide should pick them up. I keep track of all data in LibreOffice Spreadsheet: on HDD arrival I sometimes measure its SMART data and update it in the spreadsheet. Then on departure I open the disk with file manager in &amp;quot;Flat View&amp;quot;, to then copy all file entries with their full path on that disk, paste into spreadsheet page dedicated for that disk (every disk has a dedicated page and I refer to them by unique numbers, magic marker&amp;#39;ed on the disks). All disks are encrypted and NTFS, but I&amp;#39;m looking to formatting them to something better (BTRFS? It says it verifies file integrity, so if the data decays over time it&amp;#39;ll be automatically fixed?)&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m hoping for a solution that could automate some things, especially that spreadsheet, since it&amp;#39;s hard to keep track off. I wish disks would be automatically indexed before ejection, and some database would keep track of:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;what videos are where,&lt;/li&gt;\n&lt;li&gt;what videos don&amp;#39;t have a duplicate on another disk (and which disk keeps that duplicate),&lt;/li&gt;\n&lt;li&gt;disks are divided into groups A, A*, B, B*, where:&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;ul&gt;\n&lt;li&gt;A&amp;#39;s duplicate to other A&amp;#39;s once;&lt;/li&gt;\n&lt;li&gt;*&amp;#39;s can&amp;#39;t have its duplicates on another *;&lt;/li&gt;\n&lt;li&gt;B&amp;#39;s duplicate from A&amp;#39;s only (acting as third duplicate), amount of duplicates depends on amount of B&amp;#39;s drives.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Also worth noting I&amp;#39;m quite a distro-hopper, so I appreciate solutions that I can migrate between OSes. Due to limited amount of drives I can inject simultaneously, I&amp;#39;m guessing data pooling isn&amp;#39;t solution for me.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zpapw6", "is_robot_indexable": true, "report_reasons": null, "author": "Incredible_Violent", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zpapw6/coldonly_storage_solution_with_database_indexing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zpapw6/coldonly_storage_solution_with_database_indexing/", "subreddit_subscribers": 659988, "created_utc": 1671403677.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I feel like I'll know what the unfortunate answer is, but the million dollar question is has anyone found a fast way to calculate the hamming distance between a very very very large set of hashes?\n\nI have a dataset (that will continue to grow) that I'm planning on granting limited access to the public via way of allowing the user upload an item, then the server checks against the database of hashes, and shows information from similar hashes. The issue is that the database of hashes will be over 500 hundred million.\n\nFrom my understanding of finding similar/identical content, hamming distance is the fastest approach in calculating the difference between items? The issue I am seeing is that this must be calculated for each query? So the server is checking the 500 hundred million images each and every time someone wants to check?\n\nIs there any way to speed this process that I'm not seeing in my research? How do things like deduplication software, or reverse/similiar image searches work so fast? What's their secret? Just more compute and they're harnessing a shit ton of compute for each query? [TinEye](https://services.tineye.com/TinEyeAPI) claims to be able to \"search a 57.6 billion web image index in real-time.\" but how?? This must be the KFC's secret herbs and spices or the Coke recipe and I'm just shit out of luck?", "author_fullname": "t2_4z6dy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "fastest way to go about calculating hamming distance?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zp7foz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1671395223.0, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671395036.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I feel like I&amp;#39;ll know what the unfortunate answer is, but the million dollar question is has anyone found a fast way to calculate the hamming distance between a very very very large set of hashes?&lt;/p&gt;\n\n&lt;p&gt;I have a dataset (that will continue to grow) that I&amp;#39;m planning on granting limited access to the public via way of allowing the user upload an item, then the server checks against the database of hashes, and shows information from similar hashes. The issue is that the database of hashes will be over 500 hundred million.&lt;/p&gt;\n\n&lt;p&gt;From my understanding of finding similar/identical content, hamming distance is the fastest approach in calculating the difference between items? The issue I am seeing is that this must be calculated for each query? So the server is checking the 500 hundred million images each and every time someone wants to check?&lt;/p&gt;\n\n&lt;p&gt;Is there any way to speed this process that I&amp;#39;m not seeing in my research? How do things like deduplication software, or reverse/similiar image searches work so fast? What&amp;#39;s their secret? Just more compute and they&amp;#39;re harnessing a shit ton of compute for each query? &lt;a href=\"https://services.tineye.com/TinEyeAPI\"&gt;TinEye&lt;/a&gt; claims to be able to &amp;quot;search a 57.6 billion web image index in real-time.&amp;quot; but how?? This must be the KFC&amp;#39;s secret herbs and spices or the Coke recipe and I&amp;#39;m just shit out of luck?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "100+TB offline | 1.45PB @ Google Drive", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zp7foz", "is_robot_indexable": true, "report_reasons": null, "author": "AdamLynch", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/zp7foz/fastest_way_to_go_about_calculating_hamming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zp7foz/fastest_way_to_go_about_calculating_hamming/", "subreddit_subscribers": 659988, "created_utc": 1671395036.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey all, I'm pretty new to actually organizing my storage. I have loads of stuff that I've collected through the years in several HDDs and SSDs, maybe a dozen or more in total. I was considering getting a NAS so that I can lower the risk of losing anything and also make everything accessible to me easily. \n\nWhat I'm most concerned about is availability/reliability. AWS guarantees 99,999999999%. That's not something you can get at home. There are so many ways to just mess up. The cost to scale is also very linear for AWS, compared to a home system.\n\nI have unlimited Internet already.", "author_fullname": "t2_jqpu8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using AWS S3 Glacier instead of building a NAS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zp6fxy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671392452.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, I&amp;#39;m pretty new to actually organizing my storage. I have loads of stuff that I&amp;#39;ve collected through the years in several HDDs and SSDs, maybe a dozen or more in total. I was considering getting a NAS so that I can lower the risk of losing anything and also make everything accessible to me easily. &lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m most concerned about is availability/reliability. AWS guarantees 99,999999999%. That&amp;#39;s not something you can get at home. There are so many ways to just mess up. The cost to scale is also very linear for AWS, compared to a home system.&lt;/p&gt;\n\n&lt;p&gt;I have unlimited Internet already.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zp6fxy", "is_robot_indexable": true, "report_reasons": null, "author": "piponwa", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zp6fxy/using_aws_s3_glacier_instead_of_building_a_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zp6fxy/using_aws_s3_glacier_instead_of_building_a_nas/", "subreddit_subscribers": 659988, "created_utc": 1671392452.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a NAS for backup, media server, VMs, etc. It's only serving myself, so I don't like the idea of spinning 6+ spinning up drives up/down when I occasionally need to access a few media files daily when when I reboot for maintenance, testing, or just don't use it for maybe weeks at a time max.\n\nAs I understand, SSDs rarely fail aside from reaching write limit, which is something measurable (and even then, I've heard of people having Samsung SSDs that are nearly twice the TBW that's in the spec). I don't plan on running RAID, since downtime and access to massive amount of data isn't important to me--instead, I prefer frequent incremental backups, occasional full backups, as well as longer life of drives and lower power consumption.\n\nI will only ever deal with 8-16TB worth of data I want online at the moment, rest is cold storage (combined total of ~100TB hard limit for the foreseeable, I only have 60TB data total). I prefer high TBW because performance is not important for me and backing up constant flow of new large media files is.\n\nAssuming high TBW SSDs are suitable for such a use case, what high TBW SSDs do you recommend? I was initially looking at Samsung SSDs because they are the gold standard in general, but I've come across Intel DC S3610 as a recommendation that is spec'd ~5x TBW more (10.7PB). I'm not normally one to look for used storage but people seem to have success with used ones from Ebay that are probably pulled from servers after their intended service and they usually a reasonable amount of remaining life at a great price. Unless these somehow fail in other ways, I don't see how they aren't very popular. This model is 7 years old though, so I'm thinking there might be better options (not necessarily price/TB).\n\nAny thoughts and suggestions are much appreciated.", "author_fullname": "t2_wwrd4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "High TBW SSDs for low power NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zp4h3n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671387130.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a NAS for backup, media server, VMs, etc. It&amp;#39;s only serving myself, so I don&amp;#39;t like the idea of spinning 6+ spinning up drives up/down when I occasionally need to access a few media files daily when when I reboot for maintenance, testing, or just don&amp;#39;t use it for maybe weeks at a time max.&lt;/p&gt;\n\n&lt;p&gt;As I understand, SSDs rarely fail aside from reaching write limit, which is something measurable (and even then, I&amp;#39;ve heard of people having Samsung SSDs that are nearly twice the TBW that&amp;#39;s in the spec). I don&amp;#39;t plan on running RAID, since downtime and access to massive amount of data isn&amp;#39;t important to me--instead, I prefer frequent incremental backups, occasional full backups, as well as longer life of drives and lower power consumption.&lt;/p&gt;\n\n&lt;p&gt;I will only ever deal with 8-16TB worth of data I want online at the moment, rest is cold storage (combined total of ~100TB hard limit for the foreseeable, I only have 60TB data total). I prefer high TBW because performance is not important for me and backing up constant flow of new large media files is.&lt;/p&gt;\n\n&lt;p&gt;Assuming high TBW SSDs are suitable for such a use case, what high TBW SSDs do you recommend? I was initially looking at Samsung SSDs because they are the gold standard in general, but I&amp;#39;ve come across Intel DC S3610 as a recommendation that is spec&amp;#39;d ~5x TBW more (10.7PB). I&amp;#39;m not normally one to look for used storage but people seem to have success with used ones from Ebay that are probably pulled from servers after their intended service and they usually a reasonable amount of remaining life at a great price. Unless these somehow fail in other ways, I don&amp;#39;t see how they aren&amp;#39;t very popular. This model is 7 years old though, so I&amp;#39;m thinking there might be better options (not necessarily price/TB).&lt;/p&gt;\n\n&lt;p&gt;Any thoughts and suggestions are much appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zp4h3n", "is_robot_indexable": true, "report_reasons": null, "author": "rofic", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zp4h3n/high_tbw_ssds_for_low_power_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zp4h3n/high_tbw_ssds_for_low_power_nas/", "subreddit_subscribers": 659988, "created_utc": 1671387130.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "hi! so i have what i think is a pretty obscure question/problem to (hopefully) solve lol. there are some songs i downloaded on apple music earlier this year by a certain artist, and recently (i'm not sure exactly when, but within the last few weeks) that artist removed some of those songs (their earliest releases) from all streaming platforms, rendering me unable to play them on my computer or phone.\n\nordinarily, if this happened (and i've certainly had it happen before) i would just find those songs on the internet and download the files to reupload to my apple music library on my computer so i could continue to be able to listen to them normally, but in this case, the artist isn't well known enough for their songs to be on any mp3 sites (trust me, i've checked) or soulseek, and if they were ever posted by the artist on youtube or anywhere else, they've since been taken down there as well.\n\nthe one positive in this scenario is that i keep very regular time machine backups of my macbook pro, so i was able to find a backup of my apple music library file from about a month ago (before the songs were removed from streaming), and also pull the .m4p files of all the songs that were removed and return them to the itunes media folder where they had been before the songs were removed- meaning if i turn off wi-fi on my computer and then use the option key when opening the apple music application so i can open the old version of my music library (instead of the current version where the songs are greyed out and unplayable), i'm still able to play the songs with no issue (since there's no internet connection for the apple music application to realize the songs have been removed since the backup i'm accessing was made).\n\ni was initially relieved when this worked, as up until that point, i was worried that the songs were completely and totally lost to the void and i'd never be able to hear them again, but the problem is that it's obviously quite a hassle to listen to them that way, and doesn't enable me to listen to them on my phone (plus needing to have my wi-fi off is a huge pain), so it's really not a viable solution beyond the super occasional listen. does anyone have any ideas for how i can use what i have at my disposal (apple music drm protected .m4p files and a time machine backup of my apple music library) to achieve my desired end result of acquiring regular (non protected) files of those songs to then reupload to my apple music library for full playability?\n\nall of the supposed apple music drm removal applications i've seen/checked out/tried really just record the audio playback, and many of them won't even work given that the songs aren't currently available in apple music (which they would have to be to be accessible to those programs). i also tried downloading some other screen audio recording software, but the quality was really really subpar. i don't need a 100% lossless quality solution (although that would be nice), but if the difference in quality is going to be obvious even just playing the song off of my computer's built in speakers, that doesn't really cut it.\n\nthe ideal solution for me would be an actual way to convert the apple music drm protected m4p files to mp3/m4a/aac/etc, but from the internet scouring i've done so far, that doesn't seem currently possible (although i would LOVE to find out i'm wrong about that lol). i would also be perfectly satisfied with finding the audio files online somewhere, but from all the searching i've done at this point, i really do think that unfortunately the artist is too obscure for anyone to have uploaded them. my only other thought on that idea was if there was some site i haven't heard of that automatically has any song uploaded to streaming (even if/after they're removed) but the only site i'm currently aware of that's close to that is one that only has songs that are still actively available on streaming- so it does have this artist's other music, but not the removed songs i'm looking for.\n\nanyways, if you've read this whole massive post, thank you lol- and any ideas or suggestions for a solution to this would be immensely appreciated!!!!!", "author_fullname": "t2_v2626iwu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "trying to obtain/convert files of obscure songs removed from streaming (potentially using apple music drm protected m4p files from time machine backup)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zp3oml", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671384736.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hi! so i have what i think is a pretty obscure question/problem to (hopefully) solve lol. there are some songs i downloaded on apple music earlier this year by a certain artist, and recently (i&amp;#39;m not sure exactly when, but within the last few weeks) that artist removed some of those songs (their earliest releases) from all streaming platforms, rendering me unable to play them on my computer or phone.&lt;/p&gt;\n\n&lt;p&gt;ordinarily, if this happened (and i&amp;#39;ve certainly had it happen before) i would just find those songs on the internet and download the files to reupload to my apple music library on my computer so i could continue to be able to listen to them normally, but in this case, the artist isn&amp;#39;t well known enough for their songs to be on any mp3 sites (trust me, i&amp;#39;ve checked) or soulseek, and if they were ever posted by the artist on youtube or anywhere else, they&amp;#39;ve since been taken down there as well.&lt;/p&gt;\n\n&lt;p&gt;the one positive in this scenario is that i keep very regular time machine backups of my macbook pro, so i was able to find a backup of my apple music library file from about a month ago (before the songs were removed from streaming), and also pull the .m4p files of all the songs that were removed and return them to the itunes media folder where they had been before the songs were removed- meaning if i turn off wi-fi on my computer and then use the option key when opening the apple music application so i can open the old version of my music library (instead of the current version where the songs are greyed out and unplayable), i&amp;#39;m still able to play the songs with no issue (since there&amp;#39;s no internet connection for the apple music application to realize the songs have been removed since the backup i&amp;#39;m accessing was made).&lt;/p&gt;\n\n&lt;p&gt;i was initially relieved when this worked, as up until that point, i was worried that the songs were completely and totally lost to the void and i&amp;#39;d never be able to hear them again, but the problem is that it&amp;#39;s obviously quite a hassle to listen to them that way, and doesn&amp;#39;t enable me to listen to them on my phone (plus needing to have my wi-fi off is a huge pain), so it&amp;#39;s really not a viable solution beyond the super occasional listen. does anyone have any ideas for how i can use what i have at my disposal (apple music drm protected .m4p files and a time machine backup of my apple music library) to achieve my desired end result of acquiring regular (non protected) files of those songs to then reupload to my apple music library for full playability?&lt;/p&gt;\n\n&lt;p&gt;all of the supposed apple music drm removal applications i&amp;#39;ve seen/checked out/tried really just record the audio playback, and many of them won&amp;#39;t even work given that the songs aren&amp;#39;t currently available in apple music (which they would have to be to be accessible to those programs). i also tried downloading some other screen audio recording software, but the quality was really really subpar. i don&amp;#39;t need a 100% lossless quality solution (although that would be nice), but if the difference in quality is going to be obvious even just playing the song off of my computer&amp;#39;s built in speakers, that doesn&amp;#39;t really cut it.&lt;/p&gt;\n\n&lt;p&gt;the ideal solution for me would be an actual way to convert the apple music drm protected m4p files to mp3/m4a/aac/etc, but from the internet scouring i&amp;#39;ve done so far, that doesn&amp;#39;t seem currently possible (although i would LOVE to find out i&amp;#39;m wrong about that lol). i would also be perfectly satisfied with finding the audio files online somewhere, but from all the searching i&amp;#39;ve done at this point, i really do think that unfortunately the artist is too obscure for anyone to have uploaded them. my only other thought on that idea was if there was some site i haven&amp;#39;t heard of that automatically has any song uploaded to streaming (even if/after they&amp;#39;re removed) but the only site i&amp;#39;m currently aware of that&amp;#39;s close to that is one that only has songs that are still actively available on streaming- so it does have this artist&amp;#39;s other music, but not the removed songs i&amp;#39;m looking for.&lt;/p&gt;\n\n&lt;p&gt;anyways, if you&amp;#39;ve read this whole massive post, thank you lol- and any ideas or suggestions for a solution to this would be immensely appreciated!!!!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zp3oml", "is_robot_indexable": true, "report_reasons": null, "author": "k66613", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zp3oml/trying_to_obtainconvert_files_of_obscure_songs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zp3oml/trying_to_obtainconvert_files_of_obscure_songs/", "subreddit_subscribers": 659988, "created_utc": 1671384736.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I'm doing it in this way: I create a folder with the TV serie's name, then I create a folder foreach season, and there I put the files with the name of TV serie - episodie number - episodie title\n\nIf the TV series name is for example \"DataHoarder\":\n\n    DataHoarder/Season 1/DataHoarder - 1x01 - Episodie title.ext\n    DataHoarder/Season 2/DataHoarder - 2x01 - Episodie title.ext\n\nI'm curious, which is your naming convention?", "author_fullname": "t2_2sh9g5iz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you name your TV series folder and files?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zp02be", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.58, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671374365.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m doing it in this way: I create a folder with the TV serie&amp;#39;s name, then I create a folder foreach season, and there I put the files with the name of TV serie - episodie number - episodie title&lt;/p&gt;\n\n&lt;p&gt;If the TV series name is for example &amp;quot;DataHoarder&amp;quot;:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;DataHoarder/Season 1/DataHoarder - 1x01 - Episodie title.ext\nDataHoarder/Season 2/DataHoarder - 2x01 - Episodie title.ext\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I&amp;#39;m curious, which is your naming convention?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "zp02be", "is_robot_indexable": true, "report_reasons": null, "author": "secon25", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zp02be/how_do_you_name_your_tv_series_folder_and_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zp02be/how_do_you_name_your_tv_series_folder_and_files/", "subreddit_subscribers": 659988, "created_utc": 1671374365.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " \n\nHey,\n\nI have several people that I follow on YT ad I am looking for a YT downloader that will detect when select channels go live or post a video and then automatically download that video. Is there anyone that knows of a program that does that? Please do not suggest I write a script or program in python because I don't do either.\n\nHappy Holidays!", "author_fullname": "t2_4i81zeh8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a YT Livestream Auto Downloader", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zopzkl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671337969.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey,&lt;/p&gt;\n\n&lt;p&gt;I have several people that I follow on YT ad I am looking for a YT downloader that will detect when select channels go live or post a video and then automatically download that video. Is there anyone that knows of a program that does that? Please do not suggest I write a script or program in python because I don&amp;#39;t do either.&lt;/p&gt;\n\n&lt;p&gt;Happy Holidays!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zopzkl", "is_robot_indexable": true, "report_reasons": null, "author": "WndrWmn77", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zopzkl/looking_for_a_yt_livestream_auto_downloader/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zopzkl/looking_for_a_yt_livestream_auto_downloader/", "subreddit_subscribers": 659988, "created_utc": 1671337969.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Recently posted a question about digitizing analog video, but I\u2019m also curious about audio cassettes. While the differences between analog and digital video are much more complex than analog and digital audio, I\u2019ve heard people say that analog audio is much easier to convert to digital.\n\nHowever, I\u2019ve seen some conflicting information about making this conversion. Some say it\u2019s as easy as connecting a tape player to a PC mic input with a 3.5mm jack and record it with audacity, while others say you\u2019d need to run it through an external converter first.\n\nSo, which way is recommended to preserve the quality? Is it really as simple as plug and play, or do you really need to convert the signal first?", "author_fullname": "t2_hzuqxbz5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Most effective way to digitize cassette audio?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zoo4c5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671332047.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Recently posted a question about digitizing analog video, but I\u2019m also curious about audio cassettes. While the differences between analog and digital video are much more complex than analog and digital audio, I\u2019ve heard people say that analog audio is much easier to convert to digital.&lt;/p&gt;\n\n&lt;p&gt;However, I\u2019ve seen some conflicting information about making this conversion. Some say it\u2019s as easy as connecting a tape player to a PC mic input with a 3.5mm jack and record it with audacity, while others say you\u2019d need to run it through an external converter first.&lt;/p&gt;\n\n&lt;p&gt;So, which way is recommended to preserve the quality? Is it really as simple as plug and play, or do you really need to convert the signal first?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zoo4c5", "is_robot_indexable": true, "report_reasons": null, "author": "urnotmydad23", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zoo4c5/most_effective_way_to_digitize_cassette_audio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zoo4c5/most_effective_way_to_digitize_cassette_audio/", "subreddit_subscribers": 659988, "created_utc": 1671332047.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone,\n\n**Background:** I have 2 external HDDs (WD My Book) bought from BestBuy. They have both been formatted as MacOS Extended or HFS+. I own both a Windows laptop and a Macbook Pro; I use my Macbook Pro more, which is why I chose an Apple filesystem. I have historically been able to write to both of these disks using both laptops (I use Paragon HFS+ to write to the disk using my Windows laptop; I've done this for 2 years now with various other hard drives). Both hard drives have only been in use for a few months; one is constantly used for file scraping, the other is purely for backup use... the file scraping one only started having problems 2 days ago. The backup hard drive started having problems 2 months ago. (I thought it was only a one-off thing, but seems to be a recurring issue now). I have other hard drives formatted the same way and used the same way, with no issues.\n\n**Issue:** At some point, after accumulating around \\~2TB (or slightly less) on each of them, I get a notification saying the disk is full even if there's around 6TB of free space left. Turns out, the drives aren't really full... I'm just unable to write to the disk (copy files ***to*** the drive, rewrite/edit, save files etc). However, I can continue to do any read functions (copy files ***from*** the disk to my local hard drive, open files/watch videos). This issue occurs on both the Windows and Mac laptops, so I don't think it's because I'm using an HFS+ file system.\n\n**Other details:**\n\n1. On Windows, if I try to write to the disk, File Explorer just says the disk is full. EDIT: It also ejects easily on Windows (\"safely remove hardware\"), unlike DiskUtility or Finder on Mac (see point 5 below).\n2. On my Mac, if I try to write to the disk (e.g. copy or move a file to the disk), Finder will just say \"Preparing to copy filenamehere.ext\"... but it  just stays like that indefinitely. If I try to cancel the copy, it causes Finder to freeze up/become unnavigable and eventually (after 15-30 mins) the entire computer freezes up too. If I try to stop the process early by restarting the computer/shutting down the computer, it just gets stuck. There is no way around this, other than to do a hard reboot (pushing down on the power button until the computer restarts).\n3. There is usually a \"small window\" when I am able to write to the disk. Most of the time, when my Macbook has been newly booted/restarted, I have a 10-15 minute window where I am able to write to the disk. Sometimes, it doesn't work at all even if the computer has been newly restarted. Usually this occurs after a hard reboot (see point 2 above).\n4. I tried using CrystalDiskInfo (I've seen some people use it on this sub)... it gives a blue rating on both disks and says they are \"good\" (doesn't give a % health rating though).\n5. I tried DiskUtility to see if there are problems. Sometimes, it says there's there are orphan blocks (usually after a hard reboot in point 2), and it gets repaired. See screenshot below. However, the problem still occurs EVEN IF DiskUtility says the disk is completely ok. There are also times where it won't eject or unmount from a Macbook, usually after the 15 minute window mentioned in point 3 (so DiskUtility can't even work on it). When this occurs, the only way to eject the disk is to restart (and if that fails, do a hard reboot).\n\nhttps://preview.redd.it/s3zilr4gmp6a1.png?width=935&amp;format=png&amp;auto=webp&amp;s=180cad374e27b81a220f195b0cc856af4711cb72\n\nSo what is going on here? Ultimately, I'm asking for help with the following:\n\n* Are these disks dying? Should I just discard them?\n* If not, how do I find a way to consistently write to these disks?\n* How do I prevent this in the future?\n\nI should also add that I'm kind of a tech noob, so please ELI5 where you can. Thank you in advance.", "author_fullname": "t2_pvdlv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "8TB Disks Unable to Write But Both Can Read, CrystalDiskInfo says Health Status is \"Good\" (no %)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 97, "top_awarded_type": null, "hide_score": false, "media_metadata": {"s3zilr4gmp6a1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 75, "x": 108, "u": "https://preview.redd.it/s3zilr4gmp6a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=45327f7c8075058a679fa090b155ae7831047d74"}, {"y": 151, "x": 216, "u": "https://preview.redd.it/s3zilr4gmp6a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=bcf7175f4331aaee423d6ce95e9f578aff4a3090"}, {"y": 223, "x": 320, "u": "https://preview.redd.it/s3zilr4gmp6a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=72641060a69e1e3eb5e530ff1714aeb4b4dad482"}, {"y": 447, "x": 640, "u": "https://preview.redd.it/s3zilr4gmp6a1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8f68930c53699ef4ce03cb28bbddd98aed05ee6f"}], "s": {"y": 654, "x": 935, "u": "https://preview.redd.it/s3zilr4gmp6a1.png?width=935&amp;format=png&amp;auto=webp&amp;s=180cad374e27b81a220f195b0cc856af4711cb72"}, "id": "s3zilr4gmp6a1"}}, "name": "t3_zp6mi6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/mqhjzHLzgASIw6AI-lO9yRXS2WBSlU0H9fufLA05Ar8.jpg", "edited": 1671394617.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671392937.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Background:&lt;/strong&gt; I have 2 external HDDs (WD My Book) bought from BestBuy. They have both been formatted as MacOS Extended or HFS+. I own both a Windows laptop and a Macbook Pro; I use my Macbook Pro more, which is why I chose an Apple filesystem. I have historically been able to write to both of these disks using both laptops (I use Paragon HFS+ to write to the disk using my Windows laptop; I&amp;#39;ve done this for 2 years now with various other hard drives). Both hard drives have only been in use for a few months; one is constantly used for file scraping, the other is purely for backup use... the file scraping one only started having problems 2 days ago. The backup hard drive started having problems 2 months ago. (I thought it was only a one-off thing, but seems to be a recurring issue now). I have other hard drives formatted the same way and used the same way, with no issues.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Issue:&lt;/strong&gt; At some point, after accumulating around ~2TB (or slightly less) on each of them, I get a notification saying the disk is full even if there&amp;#39;s around 6TB of free space left. Turns out, the drives aren&amp;#39;t really full... I&amp;#39;m just unable to write to the disk (copy files &lt;strong&gt;&lt;em&gt;to&lt;/em&gt;&lt;/strong&gt; the drive, rewrite/edit, save files etc). However, I can continue to do any read functions (copy files &lt;strong&gt;&lt;em&gt;from&lt;/em&gt;&lt;/strong&gt; the disk to my local hard drive, open files/watch videos). This issue occurs on both the Windows and Mac laptops, so I don&amp;#39;t think it&amp;#39;s because I&amp;#39;m using an HFS+ file system.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Other details:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;On Windows, if I try to write to the disk, File Explorer just says the disk is full. EDIT: It also ejects easily on Windows (&amp;quot;safely remove hardware&amp;quot;), unlike DiskUtility or Finder on Mac (see point 5 below).&lt;/li&gt;\n&lt;li&gt;On my Mac, if I try to write to the disk (e.g. copy or move a file to the disk), Finder will just say &amp;quot;Preparing to copy filenamehere.ext&amp;quot;... but it  just stays like that indefinitely. If I try to cancel the copy, it causes Finder to freeze up/become unnavigable and eventually (after 15-30 mins) the entire computer freezes up too. If I try to stop the process early by restarting the computer/shutting down the computer, it just gets stuck. There is no way around this, other than to do a hard reboot (pushing down on the power button until the computer restarts).&lt;/li&gt;\n&lt;li&gt;There is usually a &amp;quot;small window&amp;quot; when I am able to write to the disk. Most of the time, when my Macbook has been newly booted/restarted, I have a 10-15 minute window where I am able to write to the disk. Sometimes, it doesn&amp;#39;t work at all even if the computer has been newly restarted. Usually this occurs after a hard reboot (see point 2 above).&lt;/li&gt;\n&lt;li&gt;I tried using CrystalDiskInfo (I&amp;#39;ve seen some people use it on this sub)... it gives a blue rating on both disks and says they are &amp;quot;good&amp;quot; (doesn&amp;#39;t give a % health rating though).&lt;/li&gt;\n&lt;li&gt;I tried DiskUtility to see if there are problems. Sometimes, it says there&amp;#39;s there are orphan blocks (usually after a hard reboot in point 2), and it gets repaired. See screenshot below. However, the problem still occurs EVEN IF DiskUtility says the disk is completely ok. There are also times where it won&amp;#39;t eject or unmount from a Macbook, usually after the 15 minute window mentioned in point 3 (so DiskUtility can&amp;#39;t even work on it). When this occurs, the only way to eject the disk is to restart (and if that fails, do a hard reboot).&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/s3zilr4gmp6a1.png?width=935&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=180cad374e27b81a220f195b0cc856af4711cb72\"&gt;https://preview.redd.it/s3zilr4gmp6a1.png?width=935&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=180cad374e27b81a220f195b0cc856af4711cb72&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;So what is going on here? Ultimately, I&amp;#39;m asking for help with the following:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Are these disks dying? Should I just discard them?&lt;/li&gt;\n&lt;li&gt;If not, how do I find a way to consistently write to these disks?&lt;/li&gt;\n&lt;li&gt;How do I prevent this in the future?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I should also add that I&amp;#39;m kind of a tech noob, so please ELI5 where you can. Thank you in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zp6mi6", "is_robot_indexable": true, "report_reasons": null, "author": "throwawayawerty", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zp6mi6/8tb_disks_unable_to_write_but_both_can_read/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zp6mi6/8tb_disks_unable_to_write_but_both_can_read/", "subreddit_subscribers": 659988, "created_utc": 1671392937.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "i put a folder on media fire 613 files a while ago and removed it from my computer for some more space i cant redownload it because of the bulk download feture i will go insane please help", "author_fullname": "t2_dspn9abd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "mediafire bulk downloader site?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zp6fr4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671392438.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i put a folder on media fire 613 files a while ago and removed it from my computer for some more space i cant redownload it because of the bulk download feture i will go insane please help&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zp6fr4", "is_robot_indexable": true, "report_reasons": null, "author": "TheEurekaEffect_64", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zp6fr4/mediafire_bulk_downloader_site/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zp6fr4/mediafire_bulk_downloader_site/", "subreddit_subscribers": 659988, "created_utc": 1671392438.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm working on trying to solidify my backup strategy. I do think it's fairly solid, but there are a couple things I know that I can do better. \n\nCurrent strategy:\nCentralized storage via Synology NAS (1621+ w/ 32GB ECC RAM) with btrfs.\nNAS snapshots hourly and maintains snapshot through typical pruning measures. \nNAS backs up to connected Seagate Backup 8TB drive and Backblaze B2 via Hyper Backup.\nNUC11 running Windows with read-only user connects to shares and backs up to connected external hard drive via Arq 7.  Have rotational cold-storage via Arq as well.  \n\nA couple things I'd like to fix: \n\n* NUC11 running Windows (will likely convert to Hypervisor of some sort, even if just HyperV), was part of a project.\n* Potentially move the external drive hanging off of the NUC to an internal 2.5 HDD.\n* Add a backup tool that is open source, even if it's just a cold backup. \n* Potentially remove NUC11 in general, as I'm running less on it and have a beefy desktop, and far fewer full-time running services than I did.  Would move the service or two to run off of the NAS. Though, this would mean trying to incorporate my desktop into initiating a backup process of some sort, potentially manually, which makes it less desirable.\n\n\nThe amount of data that I would consider critical is very low, somewhere in between 200-300GB\n\nAny suggestions on how I could make this more solid?", "author_fullname": "t2_4ff7pn53", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rate/Help My Backup Strategy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zp66w9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1671392880.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671391783.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on trying to solidify my backup strategy. I do think it&amp;#39;s fairly solid, but there are a couple things I know that I can do better. &lt;/p&gt;\n\n&lt;p&gt;Current strategy:\nCentralized storage via Synology NAS (1621+ w/ 32GB ECC RAM) with btrfs.\nNAS snapshots hourly and maintains snapshot through typical pruning measures. \nNAS backs up to connected Seagate Backup 8TB drive and Backblaze B2 via Hyper Backup.\nNUC11 running Windows with read-only user connects to shares and backs up to connected external hard drive via Arq 7.  Have rotational cold-storage via Arq as well.  &lt;/p&gt;\n\n&lt;p&gt;A couple things I&amp;#39;d like to fix: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;NUC11 running Windows (will likely convert to Hypervisor of some sort, even if just HyperV), was part of a project.&lt;/li&gt;\n&lt;li&gt;Potentially move the external drive hanging off of the NUC to an internal 2.5 HDD.&lt;/li&gt;\n&lt;li&gt;Add a backup tool that is open source, even if it&amp;#39;s just a cold backup. &lt;/li&gt;\n&lt;li&gt;Potentially remove NUC11 in general, as I&amp;#39;m running less on it and have a beefy desktop, and far fewer full-time running services than I did.  Would move the service or two to run off of the NAS. Though, this would mean trying to incorporate my desktop into initiating a backup process of some sort, potentially manually, which makes it less desirable.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The amount of data that I would consider critical is very low, somewhere in between 200-300GB&lt;/p&gt;\n\n&lt;p&gt;Any suggestions on how I could make this more solid?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zp66w9", "is_robot_indexable": true, "report_reasons": null, "author": "StrongCommission", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zp66w9/ratehelp_my_backup_strategy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zp66w9/ratehelp_my_backup_strategy/", "subreddit_subscribers": 659988, "created_utc": 1671391783.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello! I recently got an old Toshiba T1000LE from a relative. Unfortunately I opened it up and there are a lot of bad caps and corrosion on the main board, but the hard disk seems fine (model is JVC JDE2825P30-7, a standard 2.5\" IDE) so I removed it from the machine to recover the files.\n\nProblem is my w10 computer can't seem to recognize or read anything from this drive. Assuming it's still working (it powers on and spins up) is there a way to recover files on it? Or to make it readable?\n\nI usually do this procedure for machines that mount more recent os (from w95 on) so I'm not really practical with hard drives this old. Original computer mounts MS-DOS 3.3, it's from 1990, the HDD is 20 mb.\n\nThanks a lot in advance!! \n\nhttps://preview.redd.it/x7zdvrye0p6a1.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;s=357cf72c82ea79c06e142584216efcc84d99373b\n\nhttps://preview.redd.it/j47n1vye0p6a1.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;s=713c08f17d28faa6f003696c04b2a57c50bbdceb\n\nhttps://preview.redd.it/n3tkhtye0p6a1.jpg?width=1126&amp;format=pjpg&amp;auto=webp&amp;s=c0b4c0ce66bd197097ad93e302cbf0e74543e655", "author_fullname": "t2_f01xd1hi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help reading an old ms-dos hdd", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 103, "top_awarded_type": null, "hide_score": false, "media_metadata": {"x7zdvrye0p6a1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 79, "x": 108, "u": "https://preview.redd.it/x7zdvrye0p6a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d0d76f01647e51b233123a3c7a77bec8bc805ae0"}, {"y": 159, "x": 216, "u": "https://preview.redd.it/x7zdvrye0p6a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e85156395f5f09761dd7553fd6f849a4be306339"}, {"y": 237, "x": 320, "u": "https://preview.redd.it/x7zdvrye0p6a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4bcb71935acb8294e715a3cef580971c765589a7"}, {"y": 474, "x": 640, "u": "https://preview.redd.it/x7zdvrye0p6a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=79bf07a0eeec4675ea1aa2f95eecf936db792f6e"}, {"y": 711, "x": 960, "u": "https://preview.redd.it/x7zdvrye0p6a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=df6ecbf1414d8d945a85cfbb19de60568eb98bea"}, {"y": 799, "x": 1080, "u": "https://preview.redd.it/x7zdvrye0p6a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d0da94c140b86cdc5cdddd52737cffe8e4bad6dd"}], "s": {"y": 948, "x": 1280, "u": "https://preview.redd.it/x7zdvrye0p6a1.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;s=357cf72c82ea79c06e142584216efcc84d99373b"}, "id": "x7zdvrye0p6a1"}, "n3tkhtye0p6a1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 100, "x": 108, "u": "https://preview.redd.it/n3tkhtye0p6a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0fa77ae6f88940981b3864860ababa727abe0b1d"}, {"y": 201, "x": 216, "u": "https://preview.redd.it/n3tkhtye0p6a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=335d3ed97bfe187419ce49be81d71ba8080767bb"}, {"y": 298, "x": 320, "u": "https://preview.redd.it/n3tkhtye0p6a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e52d818a5de8fd5e1bf1d3196428a092eee5a0c6"}, {"y": 596, "x": 640, "u": "https://preview.redd.it/n3tkhtye0p6a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d295d0602637d10529e8a09d5a0766989b24e195"}, {"y": 894, "x": 960, "u": "https://preview.redd.it/n3tkhtye0p6a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ca7bfcd7889de06e825db5e8731913d70e093fa9"}, {"y": 1006, "x": 1080, "u": "https://preview.redd.it/n3tkhtye0p6a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f6c9b13beedad969c3d13279475997b8727ac925"}], "s": {"y": 1049, "x": 1126, "u": "https://preview.redd.it/n3tkhtye0p6a1.jpg?width=1126&amp;format=pjpg&amp;auto=webp&amp;s=c0b4c0ce66bd197097ad93e302cbf0e74543e655"}, "id": "n3tkhtye0p6a1"}, "j47n1vye0p6a1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 70, "x": 108, "u": "https://preview.redd.it/j47n1vye0p6a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9dc6fce33f002778801e02a2d18a669b377d405b"}, {"y": 140, "x": 216, "u": "https://preview.redd.it/j47n1vye0p6a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1ec6f1040b9f210259ffc3c855e5810280f53687"}, {"y": 208, "x": 320, "u": "https://preview.redd.it/j47n1vye0p6a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c0e5596471751f69161a384b91816a5522d7cbb2"}, {"y": 416, "x": 640, "u": "https://preview.redd.it/j47n1vye0p6a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=02399b72e5f3c6d17f30afcdef34024a3b72a248"}, {"y": 624, "x": 960, "u": "https://preview.redd.it/j47n1vye0p6a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6e2089a9a1a7b29ccbbc58dc3d3d93968fc7cf3b"}, {"y": 702, "x": 1080, "u": "https://preview.redd.it/j47n1vye0p6a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=be0d9f3d54e4ba6f8045cd5669600c4ab8c894ed"}], "s": {"y": 832, "x": 1280, "u": "https://preview.redd.it/j47n1vye0p6a1.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;s=713c08f17d28faa6f003696c04b2a57c50bbdceb"}, "id": "j47n1vye0p6a1"}}, "name": "t3_zp3w62", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/ukfc4ZlcnoQPplx6Qzrya7Xl39bF2sfYrCNXGVagj-0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671385385.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! I recently got an old Toshiba T1000LE from a relative. Unfortunately I opened it up and there are a lot of bad caps and corrosion on the main board, but the hard disk seems fine (model is JVC JDE2825P30-7, a standard 2.5&amp;quot; IDE) so I removed it from the machine to recover the files.&lt;/p&gt;\n\n&lt;p&gt;Problem is my w10 computer can&amp;#39;t seem to recognize or read anything from this drive. Assuming it&amp;#39;s still working (it powers on and spins up) is there a way to recover files on it? Or to make it readable?&lt;/p&gt;\n\n&lt;p&gt;I usually do this procedure for machines that mount more recent os (from w95 on) so I&amp;#39;m not really practical with hard drives this old. Original computer mounts MS-DOS 3.3, it&amp;#39;s from 1990, the HDD is 20 mb.&lt;/p&gt;\n\n&lt;p&gt;Thanks a lot in advance!! &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/x7zdvrye0p6a1.jpg?width=1280&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=357cf72c82ea79c06e142584216efcc84d99373b\"&gt;https://preview.redd.it/x7zdvrye0p6a1.jpg?width=1280&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=357cf72c82ea79c06e142584216efcc84d99373b&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/j47n1vye0p6a1.jpg?width=1280&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=713c08f17d28faa6f003696c04b2a57c50bbdceb\"&gt;https://preview.redd.it/j47n1vye0p6a1.jpg?width=1280&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=713c08f17d28faa6f003696c04b2a57c50bbdceb&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/n3tkhtye0p6a1.jpg?width=1126&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=c0b4c0ce66bd197097ad93e302cbf0e74543e655\"&gt;https://preview.redd.it/n3tkhtye0p6a1.jpg?width=1126&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=c0b4c0ce66bd197097ad93e302cbf0e74543e655&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zp3w62", "is_robot_indexable": true, "report_reasons": null, "author": "Ska_arj", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zp3w62/need_help_reading_an_old_msdos_hdd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zp3w62/need_help_reading_an_old_msdos_hdd/", "subreddit_subscribers": 659988, "created_utc": 1671385385.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019ve had [this](https://www.lacie.com/support/desktop-storage/d2-usb-3-pci-express/) external drive for years but it has a small HD in there. How do I know many TB\u2019s it can handle properly? Or can I slap a 20TB in there?", "author_fullname": "t2_7ulew", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Have an older LaCie external (LRD0TU2) with a USB 3 interface. It has a 3 (or 4) TB in there. Wondering how large a HD I can throw in there.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zou0s9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671352851.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve had &lt;a href=\"https://www.lacie.com/support/desktop-storage/d2-usb-3-pci-express/\"&gt;this&lt;/a&gt; external drive for years but it has a small HD in there. How do I know many TB\u2019s it can handle properly? Or can I slap a 20TB in there?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zou0s9", "is_robot_indexable": true, "report_reasons": null, "author": "jamexxx", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zou0s9/have_an_older_lacie_external_lrd0tu2_with_a_usb_3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zou0s9/have_an_older_lacie_external_lrd0tu2_with_a_usb_3/", "subreddit_subscribers": 659988, "created_utc": 1671352851.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Just moving my Unraid server across to new hardware based around an ASRock Z790 Pro RS MoBo (have flashed the latest stable BIOS). \n\nI originally set up Unraid last month on an old/ repurposed Xeon based Thinkserver TS140.\n\nI moved the drives across (6TB Seagate, 8TB Seagate, 10TB WD, 18TB WD)\n\nPlus I'd been running the 2 x 20TB WDs unshucked as the parity drives via USB, so I shucked these and put them in the new case as I now have the PSU and drive bays to handle them.\n\nWhen I first turned the new PC on, only the Seagates were detected, both in BIOS &amp; Unraid.\n\nSo I tried taping pin 3 on the WD drives. The 10TB &amp; 18TB are now being detected in BIOS &amp; Unraid, but the 20TBs still aren't being detected.\n\nThe Thinkserver was running in Legacy BIOS mode. The ASRock doesn't have a legacy option (that I can find), so is running as UEFI. Would that affect this?\n\nAny suggestions of something else I can try to get the 20TBs working?\n\nAre others using these drives with a recent UEFI only motherboard?", "author_fullname": "t2_h5frl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pair of shucked 20TB WD200EDGZ WD Elements drives not detected with new motherboard, even with pin 3 masked", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zpd7sa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671410482.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just moving my Unraid server across to new hardware based around an ASRock Z790 Pro RS MoBo (have flashed the latest stable BIOS). &lt;/p&gt;\n\n&lt;p&gt;I originally set up Unraid last month on an old/ repurposed Xeon based Thinkserver TS140.&lt;/p&gt;\n\n&lt;p&gt;I moved the drives across (6TB Seagate, 8TB Seagate, 10TB WD, 18TB WD)&lt;/p&gt;\n\n&lt;p&gt;Plus I&amp;#39;d been running the 2 x 20TB WDs unshucked as the parity drives via USB, so I shucked these and put them in the new case as I now have the PSU and drive bays to handle them.&lt;/p&gt;\n\n&lt;p&gt;When I first turned the new PC on, only the Seagates were detected, both in BIOS &amp;amp; Unraid.&lt;/p&gt;\n\n&lt;p&gt;So I tried taping pin 3 on the WD drives. The 10TB &amp;amp; 18TB are now being detected in BIOS &amp;amp; Unraid, but the 20TBs still aren&amp;#39;t being detected.&lt;/p&gt;\n\n&lt;p&gt;The Thinkserver was running in Legacy BIOS mode. The ASRock doesn&amp;#39;t have a legacy option (that I can find), so is running as UEFI. Would that affect this?&lt;/p&gt;\n\n&lt;p&gt;Any suggestions of something else I can try to get the 20TBs working?&lt;/p&gt;\n\n&lt;p&gt;Are others using these drives with a recent UEFI only motherboard?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zpd7sa", "is_robot_indexable": true, "report_reasons": null, "author": "ceestars", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zpd7sa/pair_of_shucked_20tb_wd200edgz_wd_elements_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zpd7sa/pair_of_shucked_20tb_wd200edgz_wd_elements_drives/", "subreddit_subscribers": 659988, "created_utc": 1671410482.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "The sequence of events:\n\n1. I have this  hdd (TOSHIBA HDTB420EK3AA) and i want to use it to backup some internal drives on a desktop. I write a bash script to do this, i mess up,  i corrupt the data, and i have to format it. \n2. Trying to format this thing makes my pc freeze so badly i have to hard reset. I try the same with other machines, and different operating systmes, each one freezing aswell. The winner is an old laptop on lubuntu that manages to successfully format the drive in just over an hour. \n3. I go back to the first desktop and modify the script, i run it and it kinda works.  By looking at rsync output i notice that the average speed is 500 kb/s, reaching 40kb/s at some points. At some point it starts copying an .IPCH file that makes it reach 0 byte/s and then nothing. \n4. I decide to exclude this file and other folders containing very large amount  of small files, since it looks that the speed slows down especially in these cases. For what i know HDDs are ass in this type of operations but this is just ridiculous. \n5. So i stop the rsync, and everything freezes again. I can't even open the file explorer. I boot windows and use diskpart this time, then i install DiskInfo.  \n\nhttps://preview.redd.it/20pxjo5urq6a1.png?width=670&amp;format=png&amp;auto=webp&amp;s=5f70d06a653ae8e4fda4bbd6e43376a6e578c157\n\nTo me it looks very ok, but in the 20 minutes it took me to write this, diskpart managed to go from 0% to 2% in the process of formatting the disk. \n\nThe disk is almost factory new, but i can't send it back anymore. Any ideas?", "author_fullname": "t2_5wyz3lvz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should i keep using this external hdd?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"20pxjo5urq6a1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 114, "x": 108, "u": "https://preview.redd.it/20pxjo5urq6a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4b2ccb00d921eabdf655f7a7ba7b36bd5f043def"}, {"y": 229, "x": 216, "u": "https://preview.redd.it/20pxjo5urq6a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4ab30365ea0e1f70df33d22d957b285d4a1271b7"}, {"y": 339, "x": 320, "u": "https://preview.redd.it/20pxjo5urq6a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=46da3a48fa0ed6e77e698e3b96b503aaddc3e20d"}, {"y": 679, "x": 640, "u": "https://preview.redd.it/20pxjo5urq6a1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=4a70b82e6eca0c0e05c799b4cfa5197aebd75017"}], "s": {"y": 711, "x": 670, "u": "https://preview.redd.it/20pxjo5urq6a1.png?width=670&amp;format=png&amp;auto=webp&amp;s=5f70d06a653ae8e4fda4bbd6e43376a6e578c157"}, "id": "20pxjo5urq6a1"}}, "name": "t3_zpbwmp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/YIJfwFDyi8NAIsF3466KrDqfC5hDcq2t2L6SDHI14Hs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671406857.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The sequence of events:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I have this  hdd (TOSHIBA HDTB420EK3AA) and i want to use it to backup some internal drives on a desktop. I write a bash script to do this, i mess up,  i corrupt the data, and i have to format it. &lt;/li&gt;\n&lt;li&gt;Trying to format this thing makes my pc freeze so badly i have to hard reset. I try the same with other machines, and different operating systmes, each one freezing aswell. The winner is an old laptop on lubuntu that manages to successfully format the drive in just over an hour. &lt;/li&gt;\n&lt;li&gt;I go back to the first desktop and modify the script, i run it and it kinda works.  By looking at rsync output i notice that the average speed is 500 kb/s, reaching 40kb/s at some points. At some point it starts copying an .IPCH file that makes it reach 0 byte/s and then nothing. &lt;/li&gt;\n&lt;li&gt;I decide to exclude this file and other folders containing very large amount  of small files, since it looks that the speed slows down especially in these cases. For what i know HDDs are ass in this type of operations but this is just ridiculous. &lt;/li&gt;\n&lt;li&gt;So i stop the rsync, and everything freezes again. I can&amp;#39;t even open the file explorer. I boot windows and use diskpart this time, then i install DiskInfo.&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/20pxjo5urq6a1.png?width=670&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5f70d06a653ae8e4fda4bbd6e43376a6e578c157\"&gt;https://preview.redd.it/20pxjo5urq6a1.png?width=670&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5f70d06a653ae8e4fda4bbd6e43376a6e578c157&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;To me it looks very ok, but in the 20 minutes it took me to write this, diskpart managed to go from 0% to 2% in the process of formatting the disk. &lt;/p&gt;\n\n&lt;p&gt;The disk is almost factory new, but i can&amp;#39;t send it back anymore. Any ideas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zpbwmp", "is_robot_indexable": true, "report_reasons": null, "author": "Cute_Rub_9074", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zpbwmp/should_i_keep_using_this_external_hdd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zpbwmp/should_i_keep_using_this_external_hdd/", "subreddit_subscribers": 659988, "created_utc": 1671406857.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm seeding torrents and always wondered how this affects lifetime of hard disk?", "author_fullname": "t2_7w743fwz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much does just reading data from HDD/SSD affect their life compared to writing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zp3qv8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1671386383.0, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671384919.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m seeding torrents and always wondered how this affects lifetime of hard disk?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "40TB Y.Disk", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zp3qv8", "is_robot_indexable": true, "report_reasons": null, "author": "Bear_with_a_hammer", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/zp3qv8/how_much_does_just_reading_data_from_hddssd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zp3qv8/how_much_does_just_reading_data_from_hddssd/", "subreddit_subscribers": 659988, "created_utc": 1671384919.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I don\u2019t know if this is the right place to ask, but I have lurked for a while and have become confident that this community is knowledgeable enough to call out a potentially unoptimized setup given the details.\n\nSo I will do just that, describe my setup and then attempt to explain and fact-check my assumption of the issue/request advice.\n\nHopefully in thoroughly detailing everything, any questions someone might have should already be answered and suggestions will be well founded, but I am always open to answer questions that will clarify.\n\nJust to get this out of the way, everything is connected to Ethernet and I have nearly a gigabit send/receive which is more than enough for the amount of users I have. My point being that I am not here to waste anyones time to complain about a problem as apparent as buffering due to throttling my networks upload bandwidth.\n\nI have a Synology FS1018 that I had originally intended to run Plex on. It would have probably worked fine, but not all the content in my library can direct play, and I didn\u2019t feel like going out of my way to collect specific versions of content just for Plex.\n\nSo after about a year of getting frustrated with the Synology\u2019s processing power and inability to handle multiple streams that required re-encodes, I decided to build a PC capable of transcoding. \n\nIt\u2019s running windows 10 and has a ryzen 3900x and nvidia quadro p2000. I can admit that it is probably overkill and plenty powerful to handle the amount of users I will ever have watching at one time.\n\nIf I am correct about the problem which I am still getting to, the following will be a major indication that I messed up to anyone with more experience. \n\nI created a mount of the Synology Plex share on this transcoding machine in file explorer and specified the directories accordingly in Plex as the libraries. So now the only difference is Plex is running off of this windows machine instead and is accessing the content through a network share.\n\nI never moved the data off of the Synology for multiple reasons.\n\nFirstly, in my limited and potentially naive understanding, I wasn\u2019t aware of any reason I would need to. Especially when I considered that both systems are connected through gigabit Ethernet directly into the router.\n\nThe more legitimate reason being that I couldn\u2019t even if I wanted; the Synology is running a RAID 5 array, so it wouldn\u2019t be as easy as pulling the drives out to move them, and I didn\u2019t intend on buying more storage specifically for the machine I wanted to designate to transcoding. \n\nSo to finally demonstrate the problem, imagine there is a user streaming a 4K movie as well as another user that is watching a 1080p movie, both requiring a transcode. The Quadro is capable of handling both of these just fine, and according to others who have tested the p2000, it is capable of handling multiple 4k transcodes. So in this hypothetical, I check the task manager to see why the server is having issues with playback, and the bandwidth column is maxed out fluctuating between high 90s and 100%. The server still seems to be able to handle a handful of lower resolution streams just fine.\n\nSo with all that explained, the problem I am now facing doesn\u2019t seem to be related to the performance capabilities of the transcoding machine. It seems to be a problem regarding access-rate throttling between the windows machine and Synology, especially since it is transcoding the files to the windows machine and then sending them. I would just like to be sure this is the issue and if it is, what is my course of action from here.\n\nI am currently writing this in a hotel room and am going to be on vacation until Christmas, otherwise I would provide a screenshot of the task manager when it\u2019s being \u201cthrottled\u201d or whatever is happening. \n\nIf you have read everything this far, thank you. I don\u2019t even know if I could expect myself to read all this, but I really want to know what the best move is in my situation.", "author_fullname": "t2_gbr854b7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I think I\u2019m getting bottlenecked by access-rate within my network.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zovr52", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671359791.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don\u2019t know if this is the right place to ask, but I have lurked for a while and have become confident that this community is knowledgeable enough to call out a potentially unoptimized setup given the details.&lt;/p&gt;\n\n&lt;p&gt;So I will do just that, describe my setup and then attempt to explain and fact-check my assumption of the issue/request advice.&lt;/p&gt;\n\n&lt;p&gt;Hopefully in thoroughly detailing everything, any questions someone might have should already be answered and suggestions will be well founded, but I am always open to answer questions that will clarify.&lt;/p&gt;\n\n&lt;p&gt;Just to get this out of the way, everything is connected to Ethernet and I have nearly a gigabit send/receive which is more than enough for the amount of users I have. My point being that I am not here to waste anyones time to complain about a problem as apparent as buffering due to throttling my networks upload bandwidth.&lt;/p&gt;\n\n&lt;p&gt;I have a Synology FS1018 that I had originally intended to run Plex on. It would have probably worked fine, but not all the content in my library can direct play, and I didn\u2019t feel like going out of my way to collect specific versions of content just for Plex.&lt;/p&gt;\n\n&lt;p&gt;So after about a year of getting frustrated with the Synology\u2019s processing power and inability to handle multiple streams that required re-encodes, I decided to build a PC capable of transcoding. &lt;/p&gt;\n\n&lt;p&gt;It\u2019s running windows 10 and has a ryzen 3900x and nvidia quadro p2000. I can admit that it is probably overkill and plenty powerful to handle the amount of users I will ever have watching at one time.&lt;/p&gt;\n\n&lt;p&gt;If I am correct about the problem which I am still getting to, the following will be a major indication that I messed up to anyone with more experience. &lt;/p&gt;\n\n&lt;p&gt;I created a mount of the Synology Plex share on this transcoding machine in file explorer and specified the directories accordingly in Plex as the libraries. So now the only difference is Plex is running off of this windows machine instead and is accessing the content through a network share.&lt;/p&gt;\n\n&lt;p&gt;I never moved the data off of the Synology for multiple reasons.&lt;/p&gt;\n\n&lt;p&gt;Firstly, in my limited and potentially naive understanding, I wasn\u2019t aware of any reason I would need to. Especially when I considered that both systems are connected through gigabit Ethernet directly into the router.&lt;/p&gt;\n\n&lt;p&gt;The more legitimate reason being that I couldn\u2019t even if I wanted; the Synology is running a RAID 5 array, so it wouldn\u2019t be as easy as pulling the drives out to move them, and I didn\u2019t intend on buying more storage specifically for the machine I wanted to designate to transcoding. &lt;/p&gt;\n\n&lt;p&gt;So to finally demonstrate the problem, imagine there is a user streaming a 4K movie as well as another user that is watching a 1080p movie, both requiring a transcode. The Quadro is capable of handling both of these just fine, and according to others who have tested the p2000, it is capable of handling multiple 4k transcodes. So in this hypothetical, I check the task manager to see why the server is having issues with playback, and the bandwidth column is maxed out fluctuating between high 90s and 100%. The server still seems to be able to handle a handful of lower resolution streams just fine.&lt;/p&gt;\n\n&lt;p&gt;So with all that explained, the problem I am now facing doesn\u2019t seem to be related to the performance capabilities of the transcoding machine. It seems to be a problem regarding access-rate throttling between the windows machine and Synology, especially since it is transcoding the files to the windows machine and then sending them. I would just like to be sure this is the issue and if it is, what is my course of action from here.&lt;/p&gt;\n\n&lt;p&gt;I am currently writing this in a hotel room and am going to be on vacation until Christmas, otherwise I would provide a screenshot of the task manager when it\u2019s being \u201cthrottled\u201d or whatever is happening. &lt;/p&gt;\n\n&lt;p&gt;If you have read everything this far, thank you. I don\u2019t even know if I could expect myself to read all this, but I really want to know what the best move is in my situation.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zovr52", "is_robot_indexable": true, "report_reasons": null, "author": "N72826", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zovr52/i_think_im_getting_bottlenecked_by_accessrate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zovr52/i_think_im_getting_bottlenecked_by_accessrate/", "subreddit_subscribers": 659988, "created_utc": 1671359791.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I'm using this HDD (model wdbyvg0010bbk 1TB) while its connected to my tv (oled c1), i want to know if this model is fast enough to watch 4k Remux movies in full image quality. Everything i watched so far worked fine and fast, so i guess there is also no quality loss? \n\nAccording to a review i found the transfer speed for this model is 120-130 mbps: https://latestintech.com/wd-my-passport-1tb-review/", "author_fullname": "t2_v1wfdh59", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Watching 4k blu ray Remux movies with WD My Passport HDD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zos7dv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1671345722.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m using this HDD (model wdbyvg0010bbk 1TB) while its connected to my tv (oled c1), i want to know if this model is fast enough to watch 4k Remux movies in full image quality. Everything i watched so far worked fine and fast, so i guess there is also no quality loss? &lt;/p&gt;\n\n&lt;p&gt;According to a review i found the transfer speed for this model is 120-130 mbps: &lt;a href=\"https://latestintech.com/wd-my-passport-1tb-review/\"&gt;https://latestintech.com/wd-my-passport-1tb-review/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/uVPAUPUQEGIvt-kHt8gqXwGtMmDBTVUyvYBtnidpPFw.jpg?auto=webp&amp;s=125ada1b4a74ab8a9d40869d23e33c5ccd6647ba", "width": 816, "height": 542}, "resolutions": [{"url": "https://external-preview.redd.it/uVPAUPUQEGIvt-kHt8gqXwGtMmDBTVUyvYBtnidpPFw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1450d6d2f7a59fbf9622047647fc705c2f83a1b2", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/uVPAUPUQEGIvt-kHt8gqXwGtMmDBTVUyvYBtnidpPFw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a9a3dbe4c6a314209e045dca7507d09355431915", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/uVPAUPUQEGIvt-kHt8gqXwGtMmDBTVUyvYBtnidpPFw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7ddec3a8bc35f354212caa05147cfab888b1f8b9", "width": 320, "height": 212}, {"url": "https://external-preview.redd.it/uVPAUPUQEGIvt-kHt8gqXwGtMmDBTVUyvYBtnidpPFw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9f4618d2a4240b2e533846b7336b6571000d518f", "width": 640, "height": 425}], "variants": {}, "id": "v9MjFBtGI2TwiRoT1QxFHe9_-m_DY2_KFQcQEYoNQB8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zos7dv", "is_robot_indexable": true, "report_reasons": null, "author": "Life-Canary-2742", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zos7dv/watching_4k_blu_ray_remux_movies_with_wd_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zos7dv/watching_4k_blu_ray_remux_movies_with_wd_my/", "subreddit_subscribers": 659988, "created_utc": 1671345722.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}