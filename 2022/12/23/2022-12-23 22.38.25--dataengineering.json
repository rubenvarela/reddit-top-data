{"kind": "Listing", "data": {"after": null, "dist": 19, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I came into a DE role about 5 years back with the prior five years having been experience as more of a BI Engineer. One thing I've been grappling with is I keep moving to companies that only have a few people to support data.  I hate that I climb to the top of a small ladder in just a few years and then need to look externally to try and figure out what my next career advancement looks like.\n\nDo most of you all work in environments like this where there are only a handful of data roles and your career path is mostly formed by moving around?  How do you plan and navigate your career progression?\n\nIn my current role we have one senior engineer other than myself and we support most underlying data processes at the company. There isn't really an \"up\" from here, and without more people I don't see them ever having staff engineers etc.\n\nMy thinking is I need to look for larger companies with bigger teams and probably more established such that there is something of a career track to progress through over 10+ years but I'm wondering how common that actually is.", "author_fullname": "t2_a8fiar", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you have a career path in your company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zte32g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671798491.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I came into a DE role about 5 years back with the prior five years having been experience as more of a BI Engineer. One thing I&amp;#39;ve been grappling with is I keep moving to companies that only have a few people to support data.  I hate that I climb to the top of a small ladder in just a few years and then need to look externally to try and figure out what my next career advancement looks like.&lt;/p&gt;\n\n&lt;p&gt;Do most of you all work in environments like this where there are only a handful of data roles and your career path is mostly formed by moving around?  How do you plan and navigate your career progression?&lt;/p&gt;\n\n&lt;p&gt;In my current role we have one senior engineer other than myself and we support most underlying data processes at the company. There isn&amp;#39;t really an &amp;quot;up&amp;quot; from here, and without more people I don&amp;#39;t see them ever having staff engineers etc.&lt;/p&gt;\n\n&lt;p&gt;My thinking is I need to look for larger companies with bigger teams and probably more established such that there is something of a career track to progress through over 10+ years but I&amp;#39;m wondering how common that actually is.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zte32g", "is_robot_indexable": true, "report_reasons": null, "author": "Cynot88", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zte32g/do_you_have_a_career_path_in_your_company/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zte32g/do_you_have_a_career_path_in_your_company/", "subreddit_subscribers": 83954, "created_utc": 1671798491.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to learn AWS tools for big data and do a mini project to put on resume and gradually get that certificatio. I bought this udemy course AWS solutions architect by Stephen Marek and i need some help on is there anything should i follow along with course videos? Like documentation or anything as such. People who already done it any suggestions?", "author_fullname": "t2_71fs5pjg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggestions for learning AWS services for big data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zt9e0a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671780709.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to learn AWS tools for big data and do a mini project to put on resume and gradually get that certificatio. I bought this udemy course AWS solutions architect by Stephen Marek and i need some help on is there anything should i follow along with course videos? Like documentation or anything as such. People who already done it any suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zt9e0a", "is_robot_indexable": true, "report_reasons": null, "author": "Altruistic-Base1277", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zt9e0a/suggestions_for_learning_aws_services_for_big_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zt9e0a/suggestions_for_learning_aws_services_for_big_data/", "subreddit_subscribers": 83954, "created_utc": 1671780709.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just put the finishing touches on my first data project and wanted to share.\n\nIt's pretty simple and doesn't use big data engineering tools but data is nonetheless flowing from one place to another. I built this to get an understanding of how data can move from a raw format to a visualization. Plus, learning the basics of different tools/concepts (i.e., BigQuery, Cloud Storage, Compute Engine, cron, Python, APIs)\n\nThis project basically calls out to an API, processes the data, creates a csv file with the data, uploads it to Google Cloud Storage then to BigQuery. Then, my website queries BigQuery to pull the data for a simple table visualization.\n\n**Flowchart:**\n\n[Flowchart for my project](https://preview.redd.it/tw6ubvwdyn7a1.png?width=6430&amp;format=png&amp;auto=webp&amp;s=e1c45cbc2d3e704c3d5935b122c23ad02204b020)\n\nHere is the [GitHub repository](https://github.com/digitalghost-dev/stock-data-pipeline) if you're interested.", "author_fullname": "t2_bix7v2w5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Small Data Project that I Built", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 54, "top_awarded_type": null, "hide_score": false, "media_metadata": {"tw6ubvwdyn7a1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 41, "x": 108, "u": "https://preview.redd.it/tw6ubvwdyn7a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7042e9a8a66cce0bdcaff07686fecf476cf50fa7"}, {"y": 83, "x": 216, "u": "https://preview.redd.it/tw6ubvwdyn7a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9a13a7c8774628c5e49cca89e17066f21fde0751"}, {"y": 123, "x": 320, "u": "https://preview.redd.it/tw6ubvwdyn7a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d041e0863a7b08b9f94f3f0ccc08b5eb96ca192f"}, {"y": 247, "x": 640, "u": "https://preview.redd.it/tw6ubvwdyn7a1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=658470e62d1144db04fbec55e39d9417d0912cb9"}, {"y": 371, "x": 960, "u": "https://preview.redd.it/tw6ubvwdyn7a1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=1628c45e35bc2b8b8727d35c389ea19ff40038ac"}, {"y": 417, "x": 1080, "u": "https://preview.redd.it/tw6ubvwdyn7a1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c6f7898b56dc29a013d8c1ebc4ab743c414cea3f"}], "s": {"y": 2488, "x": 6430, "u": "https://preview.redd.it/tw6ubvwdyn7a1.png?width=6430&amp;format=png&amp;auto=webp&amp;s=e1c45cbc2d3e704c3d5935b122c23ad02204b020"}, "id": "tw6ubvwdyn7a1"}}, "name": "t3_ztiy4z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/vch6QDvTkjXD-v5lsuo1V1_abymKwrGSZ6xqmIvmVA8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671808605.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just put the finishing touches on my first data project and wanted to share.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s pretty simple and doesn&amp;#39;t use big data engineering tools but data is nonetheless flowing from one place to another. I built this to get an understanding of how data can move from a raw format to a visualization. Plus, learning the basics of different tools/concepts (i.e., BigQuery, Cloud Storage, Compute Engine, cron, Python, APIs)&lt;/p&gt;\n\n&lt;p&gt;This project basically calls out to an API, processes the data, creates a csv file with the data, uploads it to Google Cloud Storage then to BigQuery. Then, my website queries BigQuery to pull the data for a simple table visualization.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Flowchart:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/tw6ubvwdyn7a1.png?width=6430&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e1c45cbc2d3e704c3d5935b122c23ad02204b020\"&gt;Flowchart for my project&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Here is the &lt;a href=\"https://github.com/digitalghost-dev/stock-data-pipeline\"&gt;GitHub repository&lt;/a&gt; if you&amp;#39;re interested.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 50, "id": "award_02d9ab2c-162e-4c01-8438-317a016ed3d9", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=16&amp;height=16&amp;auto=webp&amp;s=10034f3fdf8214c8377134bb60c5b832d4bbf588", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=32&amp;height=32&amp;auto=webp&amp;s=100f785bf261fa9452a5d82ee0ef0793369dbfa5", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=48&amp;height=48&amp;auto=webp&amp;s=b15d030fdfbbe4af4a5b34ab9dc90a174df40a23", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=64&amp;height=64&amp;auto=webp&amp;s=601c75be6ee30dc4b47a5c65d64dea9a185502a1", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=128&amp;height=128&amp;auto=webp&amp;s=540f36e65c0e2f1347fe32020e4a1565e3680437", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "I'm in this with you.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Take My Energy", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=16&amp;height=16&amp;auto=webp&amp;s=045db73f47a9513c44823d132b4c393ab9241b6a", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=32&amp;height=32&amp;auto=webp&amp;s=298a02e0edbb5b5e293087eeede63802cbe1d2c7", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=48&amp;height=48&amp;auto=webp&amp;s=7d06d606eb23dbcd6dbe39ee0e60588c5eb89065", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=64&amp;height=64&amp;auto=webp&amp;s=ecd9854b14104a36a210028c43420f0dababd96b", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=128&amp;height=128&amp;auto=webp&amp;s=0d5d7b92c1d66aff435f2ad32e6330ca2b971f6d", "width": 128, "height": 128}], "icon_format": "PNG", "icon_height": 2048, "penny_price": 0, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "ztiy4z", "is_robot_indexable": true, "report_reasons": null, "author": "digitalghost-dev", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ztiy4z/small_data_project_that_i_built/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ztiy4z/small_data_project_that_i_built/", "subreddit_subscribers": 83954, "created_utc": 1671808605.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Let me start of with myself first. Please also state if you work for a large firm or small firm. Hopefullt this thread can help out other data engineers, especially new starters like myself.\n\nI have started my first role as a junior data engineer, been around 11 months, recently graduated, predominantly using python on AWS.\n\nOn a day to basis (small firm):\n- building scalable web scrapers using scrapy and selenium.\n- cleaning and manipulating data from jsons and csvs.\n- use the following AWS services: lambda, sqs, s3 etc\n- transforming between excel and jsons and csvs.\n- creating etl pipelines on AWS.\n\nAny tips would be appreciated on: if this is a good career, tools used (airflow? Is it better than step functions?), how much are you paid and what location?", "author_fullname": "t2_45tfneon", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Share what you do as a data engineer on a day to day basis?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ztpk9z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671821434.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let me start of with myself first. Please also state if you work for a large firm or small firm. Hopefullt this thread can help out other data engineers, especially new starters like myself.&lt;/p&gt;\n\n&lt;p&gt;I have started my first role as a junior data engineer, been around 11 months, recently graduated, predominantly using python on AWS.&lt;/p&gt;\n\n&lt;p&gt;On a day to basis (small firm):\n- building scalable web scrapers using scrapy and selenium.\n- cleaning and manipulating data from jsons and csvs.\n- use the following AWS services: lambda, sqs, s3 etc\n- transforming between excel and jsons and csvs.\n- creating etl pipelines on AWS.&lt;/p&gt;\n\n&lt;p&gt;Any tips would be appreciated on: if this is a good career, tools used (airflow? Is it better than step functions?), how much are you paid and what location?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ztpk9z", "is_robot_indexable": true, "report_reasons": null, "author": "Administrative_Ad768", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ztpk9z/share_what_you_do_as_a_data_engineer_on_a_day_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ztpk9z/share_what_you_do_as_a_data_engineer_on_a_day_to/", "subreddit_subscribers": 83954, "created_utc": 1671821434.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All, \n\nI accepted an offer to join a new company that is primarily using pyspark, airflow, and kubernetes for their workflow. ( mostly an on-prem stack with open source tools) \n\nMy current job uses snowflake, sql scripts, python, airflow, kubernetes, and AWS. \n\nIt\u2019s going to be a transition to move from the Snowflake SQL based workflow to purely Pyspark. I am quite familiar with python and I have used Pandas, but I am not sure of what to expect for Pyspark? \n\nDoes anyone know of a great resource to learn Pyspark? I love reading print books whenever possible, but I also like shorter online courses for introduction.", "author_fullname": "t2_tsrtqcem", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning Pyspark for a new role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ztkkjy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671811450.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All, &lt;/p&gt;\n\n&lt;p&gt;I accepted an offer to join a new company that is primarily using pyspark, airflow, and kubernetes for their workflow. ( mostly an on-prem stack with open source tools) &lt;/p&gt;\n\n&lt;p&gt;My current job uses snowflake, sql scripts, python, airflow, kubernetes, and AWS. &lt;/p&gt;\n\n&lt;p&gt;It\u2019s going to be a transition to move from the Snowflake SQL based workflow to purely Pyspark. I am quite familiar with python and I have used Pandas, but I am not sure of what to expect for Pyspark? &lt;/p&gt;\n\n&lt;p&gt;Does anyone know of a great resource to learn Pyspark? I love reading print books whenever possible, but I also like shorter online courses for introduction.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ztkkjy", "is_robot_indexable": true, "report_reasons": null, "author": "CookingGoBlue", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ztkkjy/learning_pyspark_for_a_new_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ztkkjy/learning_pyspark_for_a_new_role/", "subreddit_subscribers": 83954, "created_utc": 1671811450.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nWe have a bigquery table that is connected to our looker. \n\nRecently we have encountered optimization issue when looker query from the bq table.\n\nLookers query has a limit of 5 gig. We have several tiles on which query amount is over 5 gig. \n\nI was able to fix it using lookers aggregate awareness , wherein looker would create a temporary aggregated table in looker scratch schema  in our bq.  \n\n\n```\nParameter:p_dynamic_date{\nType:unquoted\nAllowed_value:{\n\tlabel:\u201dDaily\u201d\n\tvalue:\u201ddaily\u201d}\nAllowed_value:{\n\tlabel:\u201dMonthly\u201d\n\tvalue:\u201dmonthly\u201d}\nDefault_value:\u201ddaily\u201d\n}\nDimension:dynamic_date{\nType:string\nSql: {%if p_dynamic_date._parameter_value == \u2018daily\u2019 %}\n${OrderDate_dims_date1}\n{%elsif p_dynamic_date.parameter_value == \u2018monthly\u2019 %}\n${customer_happiness_order.OrderDate_dims_month}\n}\n{%else%}\n${default_dimension}\n{%endif%}\n\n```\n\n \nThe problem is that when using parameter dimension, base on the lookers documentation I can only put those parameters on filter parameter in aggregate awareness . \n\nWe do have several parameter dimension in our views that we use for our dynamic measures and dimensions. \n\nIs there any workaround or solutions for this? \nOther than creating aggregate awareness for each parameter value. \n\nSidenote: Our bq table already have partitioned column and cluster column. \nIt is a historical data with a 30 min time interval.", "author_fullname": "t2_are11xb5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bigquery and Looker optimization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ztc53z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671791441.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;We have a bigquery table that is connected to our looker. &lt;/p&gt;\n\n&lt;p&gt;Recently we have encountered optimization issue when looker query from the bq table.&lt;/p&gt;\n\n&lt;p&gt;Lookers query has a limit of 5 gig. We have several tiles on which query amount is over 5 gig. &lt;/p&gt;\n\n&lt;p&gt;I was able to fix it using lookers aggregate awareness , wherein looker would create a temporary aggregated table in looker scratch schema  in our bq.  &lt;/p&gt;\n\n&lt;p&gt;```\nParameter:p_dynamic_date{\nType:unquoted\nAllowed_value:{\n    label:\u201dDaily\u201d\n    value:\u201ddaily\u201d}\nAllowed_value:{\n    label:\u201dMonthly\u201d\n    value:\u201dmonthly\u201d}\nDefault_value:\u201ddaily\u201d\n}\nDimension:dynamic_date{\nType:string\nSql: {%if p_dynamic_date._parameter_value == \u2018daily\u2019 %}\n${OrderDate_dims_date1}\n{%elsif p_dynamic_date.parameter_value == \u2018monthly\u2019 %}\n${customer_happiness_order.OrderDate_dims_month}\n}\n{%else%}\n${default_dimension}\n{%endif%}&lt;/p&gt;\n\n&lt;p&gt;```&lt;/p&gt;\n\n&lt;p&gt;The problem is that when using parameter dimension, base on the lookers documentation I can only put those parameters on filter parameter in aggregate awareness . &lt;/p&gt;\n\n&lt;p&gt;We do have several parameter dimension in our views that we use for our dynamic measures and dimensions. &lt;/p&gt;\n\n&lt;p&gt;Is there any workaround or solutions for this? \nOther than creating aggregate awareness for each parameter value. &lt;/p&gt;\n\n&lt;p&gt;Sidenote: Our bq table already have partitioned column and cluster column. \nIt is a historical data with a 30 min time interval.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ztc53z", "is_robot_indexable": true, "report_reasons": null, "author": "Sublime-01", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ztc53z/bigquery_and_looker_optimization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ztc53z/bigquery_and_looker_optimization/", "subreddit_subscribers": 83954, "created_utc": 1671791441.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nIn recent days, I heard a lot about Rust for data engineering. What are your thoughts on this?  \nWhat do you think, will Rust suppress Scala? Will Rust rule over?\n\n\\#dataengineering", "author_fullname": "t2_ci308gob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scala or Rust? which one will rule in future?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ztbebo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671788577.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;In recent days, I heard a lot about Rust for data engineering. What are your thoughts on this?&lt;br/&gt;\nWhat do you think, will Rust suppress Scala? Will Rust rule over?&lt;/p&gt;\n\n&lt;p&gt;#dataengineering&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ztbebo", "is_robot_indexable": true, "report_reasons": null, "author": "Delicious_Attempt_99", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ztbebo/scala_or_rust_which_one_will_rule_in_future/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ztbebo/scala_or_rust_which_one_will_rule_in_future/", "subreddit_subscribers": 83954, "created_utc": 1671788577.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All,\n\nI'm a bit new to this community but I have a few questions I'd like your opinion on. I'm extracting data from an API which has a lot of nested fields. I'm currently unpacking this all. There are also some nested arrays in the data and currently we unnest them which results in a new row for each value in the array. \n\nSo for example we have a companies table, one column lists the countries that the company is active in. So the original table would be:\n\n \n\n|Company\\_id|Company\\_name|Countries|\n|:-|:-|:-|\n|1|Foo|\\[\"USA\", \"Canada\", \"Spain\"\\]|\n\nAfter flattening this becomes\n\n&amp;#x200B;\n\n|Company\\_id|Company\\_name|Countries|\n|:-|:-|:-|\n|1|Foo|USA|\n|1|Foo|Canada|\n|1|Foo|Spain|\n\nI am trying to model this in a STAR-Schema. The fact table currently lists the monthly value of a subscription and the companies table is actually a dimension. Flattening the table like I showed creates a many-to-many relation for the fact and dimension (because now the dimension has multiple rows per company). Furthermore I would like to use the countries as a filter, for example I want to show the sales of companies that are active in the USA. I am unsure what the best practice is in this case and I am curious on your views on this.", "author_fullname": "t2_ipra12z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Flattening arrays in dimenion table, what is best practice?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ztahb0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671784980.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a bit new to this community but I have a few questions I&amp;#39;d like your opinion on. I&amp;#39;m extracting data from an API which has a lot of nested fields. I&amp;#39;m currently unpacking this all. There are also some nested arrays in the data and currently we unnest them which results in a new row for each value in the array. &lt;/p&gt;\n\n&lt;p&gt;So for example we have a companies table, one column lists the countries that the company is active in. So the original table would be:&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Company_id&lt;/th&gt;\n&lt;th align=\"left\"&gt;Company_name&lt;/th&gt;\n&lt;th align=\"left\"&gt;Countries&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;Foo&lt;/td&gt;\n&lt;td align=\"left\"&gt;[&amp;quot;USA&amp;quot;, &amp;quot;Canada&amp;quot;, &amp;quot;Spain&amp;quot;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;After flattening this becomes&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Company_id&lt;/th&gt;\n&lt;th align=\"left\"&gt;Company_name&lt;/th&gt;\n&lt;th align=\"left\"&gt;Countries&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;Foo&lt;/td&gt;\n&lt;td align=\"left\"&gt;USA&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;Foo&lt;/td&gt;\n&lt;td align=\"left\"&gt;Canada&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;Foo&lt;/td&gt;\n&lt;td align=\"left\"&gt;Spain&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;I am trying to model this in a STAR-Schema. The fact table currently lists the monthly value of a subscription and the companies table is actually a dimension. Flattening the table like I showed creates a many-to-many relation for the fact and dimension (because now the dimension has multiple rows per company). Furthermore I would like to use the countries as a filter, for example I want to show the sales of companies that are active in the USA. I am unsure what the best practice is in this case and I am curious on your views on this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ztahb0", "is_robot_indexable": true, "report_reasons": null, "author": "starslet93", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ztahb0/flattening_arrays_in_dimenion_table_what_is_best/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ztahb0/flattening_arrays_in_dimenion_table_what_is_best/", "subreddit_subscribers": 83954, "created_utc": 1671784980.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_j1toq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A Delta Lake quick start for Spark, Rust, Python, and more.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_zt1oo7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/K33ysDez8p4bKKUNXbQbThO00LJdQGR9yavfg-cQQOE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671755222.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/delta-io/delta-docs/tree/main/static/quickstart_docker", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/c3HlKq2XD2kRA8M2Gs3txy4YUNKAXYxi_zrONGnD6xA.jpg?auto=webp&amp;s=c9cce79d37bc54993deae4d2116f4dc1b4e293d5", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/c3HlKq2XD2kRA8M2Gs3txy4YUNKAXYxi_zrONGnD6xA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9406cb9902ce2056a5ded25dc82d9c2b750d7cc4", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/c3HlKq2XD2kRA8M2Gs3txy4YUNKAXYxi_zrONGnD6xA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b81b34dbad340592773af9691a862b9a11d58ad1", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/c3HlKq2XD2kRA8M2Gs3txy4YUNKAXYxi_zrONGnD6xA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1c4eace392b665e725ce3531fb6ef729989da6a1", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/c3HlKq2XD2kRA8M2Gs3txy4YUNKAXYxi_zrONGnD6xA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=21656922eb45a2cbd42ef917f1fd3f1f74efed3c", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/c3HlKq2XD2kRA8M2Gs3txy4YUNKAXYxi_zrONGnD6xA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=22b9c050da3152da8a76f5eadd658c4a37502d30", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/c3HlKq2XD2kRA8M2Gs3txy4YUNKAXYxi_zrONGnD6xA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=acdd5960945b893c4607e958aa09bcd549815fdd", "width": 1080, "height": 540}], "variants": {}, "id": "9S7Py6rx2_jKBT44E-vXCYohH4HWZVDtMqg-tCS_c_Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "zt1oo7", "is_robot_indexable": true, "report_reasons": null, "author": "mjgcfb", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zt1oo7/a_delta_lake_quick_start_for_spark_rust_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/delta-io/delta-docs/tree/main/static/quickstart_docker", "subreddit_subscribers": 83954, "created_utc": 1671755222.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "It has been challenging for the tech industry lately, and the data engineering positions were relatively low, to begin with. I've had tough luck recently getting interviews for data engineering intern positions, where I only landed a single technical interview.\n\nI rarely post on Reddit, but I've started to think I'm doing something wrong, especially with the lack of feedback. I would appreciate guidance regarding my resume, my projects, projects to add, etc ...\n\n&amp;#x200B;\n\n[https://docs.google.com/document/d/1E5cYR4PSi86IFgZNi8V4WtuEbtpxzc5J/edit?usp=sharing&amp;ouid=114192761163778317150&amp;rtpof=true&amp;sd=true](https://docs.google.com/document/d/1E5cYR4PSi86IFgZNi8V4WtuEbtpxzc5J/edit?usp=sharing&amp;ouid=114192761163778317150&amp;rtpof=true&amp;sd=true)", "author_fullname": "t2_881mpsrv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trying to land my first data engineering position", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zszuxf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1671750775.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It has been challenging for the tech industry lately, and the data engineering positions were relatively low, to begin with. I&amp;#39;ve had tough luck recently getting interviews for data engineering intern positions, where I only landed a single technical interview.&lt;/p&gt;\n\n&lt;p&gt;I rarely post on Reddit, but I&amp;#39;ve started to think I&amp;#39;m doing something wrong, especially with the lack of feedback. I would appreciate guidance regarding my resume, my projects, projects to add, etc ...&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://docs.google.com/document/d/1E5cYR4PSi86IFgZNi8V4WtuEbtpxzc5J/edit?usp=sharing&amp;amp;ouid=114192761163778317150&amp;amp;rtpof=true&amp;amp;sd=true\"&gt;https://docs.google.com/document/d/1E5cYR4PSi86IFgZNi8V4WtuEbtpxzc5J/edit?usp=sharing&amp;amp;ouid=114192761163778317150&amp;amp;rtpof=true&amp;amp;sd=true&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rfe8PoD7BaBkaa_nO5LnQqttAebARxYcQ1TOE5L5H50.jpg?auto=webp&amp;s=6cf244dc5077bfb246e641ba7ad00544fe4b26a0", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/rfe8PoD7BaBkaa_nO5LnQqttAebARxYcQ1TOE5L5H50.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0d3c825e1c52b7e40d8f08660247e908bb4b3c7a", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/rfe8PoD7BaBkaa_nO5LnQqttAebARxYcQ1TOE5L5H50.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=156b023114b4fabee06250e53e333b10e47f5c28", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/rfe8PoD7BaBkaa_nO5LnQqttAebARxYcQ1TOE5L5H50.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7f1c24704abc97ca22107ac8ae4a94ded9ca884a", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/rfe8PoD7BaBkaa_nO5LnQqttAebARxYcQ1TOE5L5H50.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=784e0dfc051d4b6969b066b6d088f8c72baef39f", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/rfe8PoD7BaBkaa_nO5LnQqttAebARxYcQ1TOE5L5H50.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a09d625e1815f1e5b0e8a886b747b7c78dfd1d31", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/rfe8PoD7BaBkaa_nO5LnQqttAebARxYcQ1TOE5L5H50.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=29b5bdb5eb8489d978ded063b682a48c10dcb26c", "width": 1080, "height": 567}], "variants": {}, "id": "FZaMGs_jjAu_KG2EfScnoa7K9Y0K7ER-nga_1UXXVaw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "zszuxf", "is_robot_indexable": true, "report_reasons": null, "author": "263Iz", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zszuxf/trying_to_land_my_first_data_engineering_position/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zszuxf/trying_to_land_my_first_data_engineering_position/", "subreddit_subscribers": 83954, "created_utc": 1671750775.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company uses Databricks to spin up spark clusters and run spark applications/jobs on them. But when I asked for a staging cluster to be set up for testing purposes (1 master node and 1 worker which will go down after 1 hour of inactivity), they say it will double the cost. Does spinning up another small cluster incur any fixed fee which I am missing? I checked out the Databricks pricing on a very surface level: [https://www.databricks.com/product/pricing](https://www.databricks.com/product/pricing) and didn't find any fixed fee.\n\nThis also made me wonder if setting up staging clusters for testing spark applications/jobs is normal (it might be easier for companies managing in-house spark clusters, I feel) or if what I am asking for is far-fetched. This is my first time working on Spark, I am just curious. Thanks!", "author_fullname": "t2_uqx8q0b4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do companies set up staging environments for their spark pipeline(s)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ztgp64", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1671805105.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company uses Databricks to spin up spark clusters and run spark applications/jobs on them. But when I asked for a staging cluster to be set up for testing purposes (1 master node and 1 worker which will go down after 1 hour of inactivity), they say it will double the cost. Does spinning up another small cluster incur any fixed fee which I am missing? I checked out the Databricks pricing on a very surface level: &lt;a href=\"https://www.databricks.com/product/pricing\"&gt;https://www.databricks.com/product/pricing&lt;/a&gt; and didn&amp;#39;t find any fixed fee.&lt;/p&gt;\n\n&lt;p&gt;This also made me wonder if setting up staging clusters for testing spark applications/jobs is normal (it might be easier for companies managing in-house spark clusters, I feel) or if what I am asking for is far-fetched. This is my first time working on Spark, I am just curious. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/KQ6LtUPbNzOmSQucv-4d7A_9HFIwm2xgCV2yC7KKql8.jpg?auto=webp&amp;s=afbcf6c0a382f562f827b0c2c6f522c11c337cbe", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/KQ6LtUPbNzOmSQucv-4d7A_9HFIwm2xgCV2yC7KKql8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9548268e474bfa947a6d3486dac50b79a84a04bc", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/KQ6LtUPbNzOmSQucv-4d7A_9HFIwm2xgCV2yC7KKql8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7ebd62be4af601d1e09ae1cd9d9ee91065af4242", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/KQ6LtUPbNzOmSQucv-4d7A_9HFIwm2xgCV2yC7KKql8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=02919e6c9ddb4e8e87863d61487437299bb24c49", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/KQ6LtUPbNzOmSQucv-4d7A_9HFIwm2xgCV2yC7KKql8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=131f4845cdb1282ddb789a6eb9f04238f19b3a80", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/KQ6LtUPbNzOmSQucv-4d7A_9HFIwm2xgCV2yC7KKql8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=eee206a496dc7eca55db2b06e528bf544ddb73c5", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/KQ6LtUPbNzOmSQucv-4d7A_9HFIwm2xgCV2yC7KKql8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=65ec0864683118aefee5006e88b78842e5cba2a0", "width": 1080, "height": 567}], "variants": {}, "id": "chr5A0PJvePhRJ7lI3sFaxKWyQXhWy3BRSTRcBAQKNs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ztgp64", "is_robot_indexable": true, "report_reasons": null, "author": "the-fake-me", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ztgp64/do_companies_set_up_staging_environments_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ztgp64/do_companies_set_up_staging_environments_for/", "subreddit_subscribers": 83954, "created_utc": 1671805105.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious if there are roles or industries out there that combine a little bit of physical hands on work and pipelining/infra/modeling the usual stuff. \n\nTo elaborate, I really enjoy tinkering with microcontrollers and raspberry pis. I've set up small pipelines that required configuration of physical sensors and building the actual device and of course the data collection and software behind it. \n\nI'd imagine I could only find something like this in a robotics or similar startup where I could wear many hats. At a larger organization I'm sure these DEs exist but they're probably siloed from the physical hardware. \n\nAnyone else have any thoughts?", "author_fullname": "t2_3aaaxf9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering and Hands On?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ztetmq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671800873.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious if there are roles or industries out there that combine a little bit of physical hands on work and pipelining/infra/modeling the usual stuff. &lt;/p&gt;\n\n&lt;p&gt;To elaborate, I really enjoy tinkering with microcontrollers and raspberry pis. I&amp;#39;ve set up small pipelines that required configuration of physical sensors and building the actual device and of course the data collection and software behind it. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d imagine I could only find something like this in a robotics or similar startup where I could wear many hats. At a larger organization I&amp;#39;m sure these DEs exist but they&amp;#39;re probably siloed from the physical hardware. &lt;/p&gt;\n\n&lt;p&gt;Anyone else have any thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ztetmq", "is_robot_indexable": true, "report_reasons": null, "author": "felmalorne", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ztetmq/data_engineering_and_hands_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ztetmq/data_engineering_and_hands_on/", "subreddit_subscribers": 83954, "created_utc": 1671800873.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m working on an application that requires a Python backend. \n\nThere\u2019s a fair amount of: ingesting text file, manipulating with data frames and storing data. During development we store as CSVs and then import again.\n\nWhat storage would you recommend? \n\nI come from a typescript background and I\u2019m used to SQL databases. Would prefer to stick to this. I was thinking of using S3 and referencing the data in a SQL database. \n\nWhat do you think?", "author_fullname": "t2_77b0idef", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best data store for python use case", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ztcoy2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671793497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m working on an application that requires a Python backend. &lt;/p&gt;\n\n&lt;p&gt;There\u2019s a fair amount of: ingesting text file, manipulating with data frames and storing data. During development we store as CSVs and then import again.&lt;/p&gt;\n\n&lt;p&gt;What storage would you recommend? &lt;/p&gt;\n\n&lt;p&gt;I come from a typescript background and I\u2019m used to SQL databases. Would prefer to stick to this. I was thinking of using S3 and referencing the data in a SQL database. &lt;/p&gt;\n\n&lt;p&gt;What do you think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ztcoy2", "is_robot_indexable": true, "report_reasons": null, "author": "SnooPears6317", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ztcoy2/best_data_store_for_python_use_case/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ztcoy2/best_data_store_for_python_use_case/", "subreddit_subscribers": 83954, "created_utc": 1671793497.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_r1v4k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "We created this to advertise some new data health work we had been doing for the wider (non technical) business.... Thought you might enjoy as well!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": true, "name": "t3_zttf3l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/LVcZ9XgEgPylT8X7muTQj-GWegfrdEd6Thh8WOOUXGU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671831673.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/z9p7pgk5wp7a1.gif", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/z9p7pgk5wp7a1.gif?format=png8&amp;s=a6a37f7f7753dad879dabe1a1a757955d74212c3", "width": 600, "height": 338}, "resolutions": [{"url": "https://preview.redd.it/z9p7pgk5wp7a1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=fccb110c398bc1bd990a4937de530d8d7a9fde24", "width": 108, "height": 60}, {"url": "https://preview.redd.it/z9p7pgk5wp7a1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=0f48b95d1c7581cd45d6f4eca9cddab023cba6b3", "width": 216, "height": 121}, {"url": "https://preview.redd.it/z9p7pgk5wp7a1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=910dd3dee0f54f458e74edf52acc2c5b6173805f", "width": 320, "height": 180}], "variants": {"gif": {"source": {"url": "https://preview.redd.it/z9p7pgk5wp7a1.gif?s=9b8edbe68a0a55d0d0bd0d8ceaf402dd65273e2f", "width": 600, "height": 338}, "resolutions": [{"url": "https://preview.redd.it/z9p7pgk5wp7a1.gif?width=108&amp;crop=smart&amp;s=5464bed05a7f909e92c825c3fd1b97c738043999", "width": 108, "height": 60}, {"url": "https://preview.redd.it/z9p7pgk5wp7a1.gif?width=216&amp;crop=smart&amp;s=6586fbcb0b262d85292097528d9f44ed1ff8b834", "width": 216, "height": 121}, {"url": "https://preview.redd.it/z9p7pgk5wp7a1.gif?width=320&amp;crop=smart&amp;s=c31df8dc36324730d52c8757f5c2e3839918889d", "width": 320, "height": 180}]}, "mp4": {"source": {"url": "https://preview.redd.it/z9p7pgk5wp7a1.gif?format=mp4&amp;s=1161b96617652f61ea06b0729bef515c0df00baf", "width": 600, "height": 338}, "resolutions": [{"url": "https://preview.redd.it/z9p7pgk5wp7a1.gif?width=108&amp;format=mp4&amp;s=3599a794f9c020ef2b90e92026c452d7a52ca7e1", "width": 108, "height": 60}, {"url": "https://preview.redd.it/z9p7pgk5wp7a1.gif?width=216&amp;format=mp4&amp;s=eedc54367b2801fa1947584186401d7d661fec15", "width": 216, "height": 121}, {"url": "https://preview.redd.it/z9p7pgk5wp7a1.gif?width=320&amp;format=mp4&amp;s=19581a64708ab31dd76b62213f83b1aac3f93f0e", "width": 320, "height": 180}]}}, "id": "G30MWgocER86UYS-QovsNgPgXN-Qc9nnTC03c7djJgI"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "zttf3l", "is_robot_indexable": true, "report_reasons": null, "author": "cjvogel", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zttf3l/we_created_this_to_advertise_some_new_data_health/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/z9p7pgk5wp7a1.gif", "subreddit_subscribers": 83954, "created_utc": 1671831673.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a new to data engineering, but have been in the industry as a Database engineer/dev ops for about 8 years.\n\nPreviously done ETL with specific SAP tools which didn't require much transformation. Doing more of transformation work now using internal tools.  \nI have an example scenario and wondering what would typically be the best practices to apply.  \n\n\nWith HR related data there are department level 1 (about 8 entries) and department level 2 (each L1 department will have 10+ L2 departments). I need to group the L2 departments into a high level grouping like group#1, group#2, etc..\n\nMy thought process would either be:\n\n* case statement to add a new column to the query where if L2 departments = this/that it would be renamed to group#1 and such. I don' think is ideal as there would be likely too many entries to maintain and long term maintenance is likely very poor.\n* The other option would be to have a separate table to maintain only L2 department naming and a separate column for its grouping. Then in the final query i would want to match on the L2 department name to pull the grouping name.  \n\n\nI think the latter option would be easier to maintain in the long run. The original table doesn't exactly have ID's to represent the L2 name so it would be a name matching instead of ID.   \nAnd for general practice is it always better to create a separate table for referencing a potentially growing dataset? And that any query that have dependencies would just join on that table?", "author_fullname": "t2_4bo597fw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering best practices", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ztqmvp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671824234.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a new to data engineering, but have been in the industry as a Database engineer/dev ops for about 8 years.&lt;/p&gt;\n\n&lt;p&gt;Previously done ETL with specific SAP tools which didn&amp;#39;t require much transformation. Doing more of transformation work now using internal tools.&lt;br/&gt;\nI have an example scenario and wondering what would typically be the best practices to apply.  &lt;/p&gt;\n\n&lt;p&gt;With HR related data there are department level 1 (about 8 entries) and department level 2 (each L1 department will have 10+ L2 departments). I need to group the L2 departments into a high level grouping like group#1, group#2, etc..&lt;/p&gt;\n\n&lt;p&gt;My thought process would either be:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;case statement to add a new column to the query where if L2 departments = this/that it would be renamed to group#1 and such. I don&amp;#39; think is ideal as there would be likely too many entries to maintain and long term maintenance is likely very poor.&lt;/li&gt;\n&lt;li&gt;The other option would be to have a separate table to maintain only L2 department naming and a separate column for its grouping. Then in the final query i would want to match on the L2 department name to pull the grouping name.&lt;br/&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I think the latter option would be easier to maintain in the long run. The original table doesn&amp;#39;t exactly have ID&amp;#39;s to represent the L2 name so it would be a name matching instead of ID.&lt;br/&gt;\nAnd for general practice is it always better to create a separate table for referencing a potentially growing dataset? And that any query that have dependencies would just join on that table?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ztqmvp", "is_robot_indexable": true, "report_reasons": null, "author": "billyboee", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ztqmvp/data_engineering_best_practices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ztqmvp/data_engineering_best_practices/", "subreddit_subscribers": 83954, "created_utc": 1671824234.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_ffabopog", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Release 0.3.1 of Qbeast Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_ztft08", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/XUvfYJOP4pJhPu_dR1w3Vku1nD4q8HoVeUaoSdmTPz0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671803144.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/Qbeast-io/qbeast-spark/releases/tag/v0.3.1", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/AzmtQfJlpODTzny_oo-wc6U16bMHAREkatkoklwn8pU.jpg?auto=webp&amp;s=2a0525af9d70eeec3aba1b04b7787a31e0966ce7", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/AzmtQfJlpODTzny_oo-wc6U16bMHAREkatkoklwn8pU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4e3e9aa329e17effafb0e8d8770e1388167e4e12", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/AzmtQfJlpODTzny_oo-wc6U16bMHAREkatkoklwn8pU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b4d80ed10e7054903134747a102c8c1f00a964c1", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/AzmtQfJlpODTzny_oo-wc6U16bMHAREkatkoklwn8pU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d373c319c63b0c5bfbd681d8d6d136c99224f9ae", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/AzmtQfJlpODTzny_oo-wc6U16bMHAREkatkoklwn8pU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a31f7b5e217854df3db7506587f068b621d5e086", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/AzmtQfJlpODTzny_oo-wc6U16bMHAREkatkoklwn8pU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b89d4cd2ffd300752a5fb611c359339cca05f371", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/AzmtQfJlpODTzny_oo-wc6U16bMHAREkatkoklwn8pU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f468b7ca092608820284bd02106d17dd22da2850", "width": 1080, "height": 540}], "variants": {}, "id": "Izt85EhhkGzbGdpryLd1c_Y_1Dp0qafMg_Kwkgz9FvA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "ztft08", "is_robot_indexable": true, "report_reasons": null, "author": "paolapardo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ztft08/release_031_of_qbeast_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/Qbeast-io/qbeast-spark/releases/tag/v0.3.1", "subreddit_subscribers": 83954, "created_utc": 1671803144.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How did you prepare for the exam? I have been going through the content online though did initially struggle to answer some practice questions I found online.\n\nDo you have any recommendations on where I can find practice exams? Hard to find outside of YouTube. I am willing to pay :)", "author_fullname": "t2_12rfbr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Preparing for DP-203?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zte255", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1671807851.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671798399.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How did you prepare for the exam? I have been going through the content online though did initially struggle to answer some practice questions I found online.&lt;/p&gt;\n\n&lt;p&gt;Do you have any recommendations on where I can find practice exams? Hard to find outside of YouTube. I am willing to pay :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zte255", "is_robot_indexable": true, "report_reasons": null, "author": "That_Sweet_Science", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zte255/preparing_for_dp203/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zte255/preparing_for_dp203/", "subreddit_subscribers": 83954, "created_utc": 1671798399.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anyone could explain explain production dimenssion and fact tables ( buisness logic)? what should it include and so on?", "author_fullname": "t2_56g5f4cg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Production domain data model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ztrxlm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671827672.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone could explain explain production dimenssion and fact tables ( buisness logic)? what should it include and so on?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ztrxlm", "is_robot_indexable": true, "report_reasons": null, "author": "9gg6", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ztrxlm/production_domain_data_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ztrxlm/production_domain_data_model/", "subreddit_subscribers": 83954, "created_utc": 1671827672.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_49cfbl1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Tricks: How To Get Dirty Data Cleaned", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_ztbrbd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/AhA5peXfRoU4SU3x_KFQlQkBmJAiQBMcW_yE1_Af-rQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671789997.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/geekculture/data-engineering-tricks-how-to-get-dirty-data-cleaned-through-vdk-60eeeda11ba0", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bLdk5J-q_X10nkIminSlOyMeBfabAnkCkH7AAFzTmBU.jpg?auto=webp&amp;s=61a2b14e210e164f032c2b4eec791f24f4f9fd85", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/bLdk5J-q_X10nkIminSlOyMeBfabAnkCkH7AAFzTmBU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cfdfbefd2f2adcacc11fbc125a026aed3d874592", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/bLdk5J-q_X10nkIminSlOyMeBfabAnkCkH7AAFzTmBU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4a9bf1c447be23b118a91983dce2fac38ca1709a", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/bLdk5J-q_X10nkIminSlOyMeBfabAnkCkH7AAFzTmBU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bea6c673475c653fd36f14bd90657a6c43d544d0", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/bLdk5J-q_X10nkIminSlOyMeBfabAnkCkH7AAFzTmBU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ce88110a8107775586321e1bd82709757e652f8f", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/bLdk5J-q_X10nkIminSlOyMeBfabAnkCkH7AAFzTmBU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a4f309631dbebf825ff9324380cbcdb0722c80a5", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/bLdk5J-q_X10nkIminSlOyMeBfabAnkCkH7AAFzTmBU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b38b3383ba7bddb1efcfd48298fd49df2588bae4", "width": 1080, "height": 720}], "variants": {}, "id": "scIcfeKfFRoglimi8T69xKstBaawo5kLc9fWIR8punI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "ztbrbd", "is_robot_indexable": true, "report_reasons": null, "author": "zverulacis", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ztbrbd/data_engineering_tricks_how_to_get_dirty_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/geekculture/data-engineering-tricks-how-to-get-dirty-data-cleaned-through-vdk-60eeeda11ba0", "subreddit_subscribers": 83954, "created_utc": 1671789997.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}