{"kind": "Listing", "data": {"after": "t3_zkn6ps", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_1omlki7c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just accidentally nuked ~90% of my video library", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 90, "top_awarded_type": null, "hide_score": false, "name": "t3_zkc7jv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 688, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 688, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/JxQNCfnKe8WfA3OrEpx3B-VGJQFmz3-txa9-rY2TVb8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670880757.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/guh9oj5gaj5a1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/guh9oj5gaj5a1.png?auto=webp&amp;s=8d4162e08a0eb95f5808b839c879287c8e88657b", "width": 1493, "height": 964}, "resolutions": [{"url": "https://preview.redd.it/guh9oj5gaj5a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a655b2982fb80e95c8937d57dbff1c0f6250643b", "width": 108, "height": 69}, {"url": "https://preview.redd.it/guh9oj5gaj5a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=bb90753a98ae5f98cf4bd30f283a1775d58d6713", "width": 216, "height": 139}, {"url": "https://preview.redd.it/guh9oj5gaj5a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=86d23aeddbc14ffa850acde5b6ac9d8121f1d801", "width": 320, "height": 206}, {"url": "https://preview.redd.it/guh9oj5gaj5a1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=cb2e5841e1858156c88d669693728d61de69e089", "width": 640, "height": 413}, {"url": "https://preview.redd.it/guh9oj5gaj5a1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e190fc6ad72cc5bb8f0a33ba04a7f2745fdecb0f", "width": 960, "height": 619}, {"url": "https://preview.redd.it/guh9oj5gaj5a1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e1070499d138a01f4b1555806200fc7f3442ad16", "width": 1080, "height": 697}], "variants": {}, "id": "-IQY7NkOwJilESbG22s_hQOlk1Wwg1s1gimRet7UtX0"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zkc7jv", "is_robot_indexable": true, "report_reasons": null, "author": "randombystander3001", "discussion_type": null, "num_comments": 283, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zkc7jv/just_accidentally_nuked_90_of_my_video_library/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/guh9oj5gaj5a1.png", "subreddit_subscribers": 659017, "created_utc": 1670880757.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_dc1bf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Huge thanks to Seagate and u/Seagate_Surfer for running the IronWolf Pro SSD giveaway! It has found a good home and replaced an ancient OCZ relic.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"smerxp99hi5a1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/smerxp99hi5a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8ce7ce1a7531f48d50128c88f41834c439eb9a04"}, {"y": 162, "x": 216, "u": "https://preview.redd.it/smerxp99hi5a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=51d99f23267c6296f35f8718cf654cd1c2b3ce9c"}, {"y": 240, "x": 320, "u": "https://preview.redd.it/smerxp99hi5a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0dc449aad132695ef3c2d51ca76ac2b2bd908f56"}, {"y": 480, "x": 640, "u": "https://preview.redd.it/smerxp99hi5a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e120c9ec9ce3417efc0118987747a20595b26801"}, {"y": 720, "x": 960, "u": "https://preview.redd.it/smerxp99hi5a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=71b3726ea0c0dcb0eb21b3b6152df599a2b22872"}, {"y": 810, "x": 1080, "u": "https://preview.redd.it/smerxp99hi5a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e534075c1930e4020f4004d7d66656851b5e36cc"}], "s": {"y": 3024, "x": 4032, "u": "https://preview.redd.it/smerxp99hi5a1.jpg?width=4032&amp;format=pjpg&amp;auto=webp&amp;s=574037522ec30d587ec0df7fb2f90260813c73f9"}, "id": "smerxp99hi5a1"}, "b1p98rf8hi5a1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 138, "x": 108, "u": "https://preview.redd.it/b1p98rf8hi5a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=73d95b83319554632043d28d74d88b36d8de89e7"}, {"y": 276, "x": 216, "u": "https://preview.redd.it/b1p98rf8hi5a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=53cf0884e3b5b62a2cc91526f37cf2bd374ccfab"}, {"y": 409, "x": 320, "u": "https://preview.redd.it/b1p98rf8hi5a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=baa20e2c7a50427d52715404f44eaebbdd58e7c8"}, {"y": 819, "x": 640, "u": "https://preview.redd.it/b1p98rf8hi5a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ae4fd9db311173e99eb50045f8672311005d030c"}], "s": {"y": 922, "x": 720, "u": "https://preview.redd.it/b1p98rf8hi5a1.jpg?width=720&amp;format=pjpg&amp;auto=webp&amp;s=0fc5ab769725df96e84e8ef7491832bbddb8ad8f"}, "id": "b1p98rf8hi5a1"}, "61tian8ahi5a1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 39, "x": 108, "u": "https://preview.redd.it/61tian8ahi5a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2d0d6a0ade073c64da315099ed910a935af0a2c5"}, {"y": 78, "x": 216, "u": "https://preview.redd.it/61tian8ahi5a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f4ba353b79b466d87e1b3855c36789a3befad87a"}, {"y": 116, "x": 320, "u": "https://preview.redd.it/61tian8ahi5a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2a0d549cd84767d024d4e56452a115ec9e36ddca"}, {"y": 233, "x": 640, "u": "https://preview.redd.it/61tian8ahi5a1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b5a3e0a9422be67e363394c72f3d96222c3a8c43"}, {"y": 350, "x": 960, "u": "https://preview.redd.it/61tian8ahi5a1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=7df140ab2076ff3ba8047c1ea980751bfbdaf8a5"}, {"y": 394, "x": 1080, "u": "https://preview.redd.it/61tian8ahi5a1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=37e7d0103352e989bf5f3f846fef429d3b14da67"}], "s": {"y": 469, "x": 1284, "u": "https://preview.redd.it/61tian8ahi5a1.png?width=1284&amp;format=png&amp;auto=webp&amp;s=60a087c520ed31b30679540bb204a1e271ea363c"}, "id": "61tian8ahi5a1"}}, "name": "t3_zk7aa0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "ups": 312, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "b1p98rf8hi5a1", "id": 218525898}, {"media_id": "smerxp99hi5a1", "id": 218525899}, {"media_id": "61tian8ahi5a1", "id": 218525900}]}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 312, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/lvphIk5c9FViHQG02pQlJNYkKTllgXKlxAERzuVVKDU.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670870209.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/zk7aa0", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "74TB", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "zk7aa0", "is_robot_indexable": true, "report_reasons": null, "author": "Clawz114", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/zk7aa0/huge_thanks_to_seagate_and_useagate_surfer_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/zk7aa0", "subreddit_subscribers": 659017, "created_utc": 1670870209.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "because date hoarding is quite an expensive hobby.", "author_fullname": "t2_lo8e4f55", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Who are you by profession?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zk62zn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670867644.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;because date hoarding is quite an expensive hobby.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "russian military ship, go to hell", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "zk62zn", "is_robot_indexable": true, "report_reasons": null, "author": "kovach_ua", "discussion_type": null, "num_comments": 89, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/zk62zn/who_are_you_by_profession/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zk62zn/who_are_you_by_profession/", "subreddit_subscribers": 659017, "created_utc": 1670867644.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone,\n\nAs I frequently see interesting threads on Reddit, and I want to get them offline to 1) find them again easily, and 2) preserve them in case messages get removed, I made myself some time ago a Python script to \"download\" threads off Reddit.This script does not *only* download the thread, but generates a nice HTML file, so it can be opened in a browser and the thread navigated around conveniently. [Here is an example of such HTML file](https://htmlpreview.github.io/?https://github.com/Ailothaen/RedditArchiver/blob/main/github/example.html).\n\nRecently, I told myself it would be better to have a web frontend for that tooling, since I am sometimes on the go and do not have the script and/or the Python interpreter on my machine.\n\nThis therefore led to RedditArchive, a Flask self-hosted app to archive and download Reddit threads (screenshots available in the README):[https://github.com/Ailothaen/RedditArchiver](https://github.com/Ailothaen/RedditArchiver)\n\nYou can install it on a small server of yours, such as a Raspberry Pi or a VPS. Installations instructions are provided if you want to try it on.\n\nIf you do not want to deal with the hassle of setting a web server up, worry not! I also made the original script available here:[https://github.com/Ailothaen/RedditArchiver-standalone](https://github.com/Ailothaen/RedditArchiver-standalone)\n\nDo not hesitate to comment and make suggestions \u2013 I have ideas for further features, but that's probably for another time. \ud83e\udd89", "author_fullname": "t2_ozmwc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Made myself Python tooling to download threads off Reddit (available in Web UI and standalone script)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zk6491", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670867716.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;As I frequently see interesting threads on Reddit, and I want to get them offline to 1) find them again easily, and 2) preserve them in case messages get removed, I made myself some time ago a Python script to &amp;quot;download&amp;quot; threads off Reddit.This script does not &lt;em&gt;only&lt;/em&gt; download the thread, but generates a nice HTML file, so it can be opened in a browser and the thread navigated around conveniently. &lt;a href=\"https://htmlpreview.github.io/?https://github.com/Ailothaen/RedditArchiver/blob/main/github/example.html\"&gt;Here is an example of such HTML file&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Recently, I told myself it would be better to have a web frontend for that tooling, since I am sometimes on the go and do not have the script and/or the Python interpreter on my machine.&lt;/p&gt;\n\n&lt;p&gt;This therefore led to RedditArchive, a Flask self-hosted app to archive and download Reddit threads (screenshots available in the README):&lt;a href=\"https://github.com/Ailothaen/RedditArchiver\"&gt;https://github.com/Ailothaen/RedditArchiver&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;You can install it on a small server of yours, such as a Raspberry Pi or a VPS. Installations instructions are provided if you want to try it on.&lt;/p&gt;\n\n&lt;p&gt;If you do not want to deal with the hassle of setting a web server up, worry not! I also made the original script available here:&lt;a href=\"https://github.com/Ailothaen/RedditArchiver-standalone\"&gt;https://github.com/Ailothaen/RedditArchiver-standalone&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Do not hesitate to comment and make suggestions \u2013 I have ideas for further features, but that&amp;#39;s probably for another time. \ud83e\udd89&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zk6491", "is_robot_indexable": true, "report_reasons": null, "author": "Ailothaen", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zk6491/made_myself_python_tooling_to_download_threads/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zk6491/made_myself_python_tooling_to_download_threads/", "subreddit_subscribers": 659017, "created_utc": 1670867716.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I feel sorry for HBO fans, DC Comics movie fans, WB fans, etc. The epic content purge going on due to Mr Honey Boo Boo David Zaslav is unprecedented. It's like a supervillain plot to vaporize content. This is damaging long -term health for some short term tax chicanery and very small savings. He alienated fans and the creative community. But no matter how it turns out, he'll get a golden parachute and profit off the husk of once-great properties.  \nWe live in a time when all content could be available. But with so many great shows vaporized with no DVD/Blu-rays, the main takeaway is that datahoarding has been validated as a fan's only viable strategy.   \n\n\n[https://deadline.com/2022/08/john-oliver-business-daddy-warner-bros-discovery-1235087249/](https://deadline.com/2022/08/john-oliver-business-daddy-warner-bros-discovery-1235087249/)", "author_fullname": "t2_1hl1i680", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "There is no cure for Zaslav except Datahoarding", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zkv1ii", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1670936065.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I feel sorry for HBO fans, DC Comics movie fans, WB fans, etc. The epic content purge going on due to Mr Honey Boo Boo David Zaslav is unprecedented. It&amp;#39;s like a supervillain plot to vaporize content. This is damaging long -term health for some short term tax chicanery and very small savings. He alienated fans and the creative community. But no matter how it turns out, he&amp;#39;ll get a golden parachute and profit off the husk of once-great properties.&lt;br/&gt;\nWe live in a time when all content could be available. But with so many great shows vaporized with no DVD/Blu-rays, the main takeaway is that datahoarding has been validated as a fan&amp;#39;s only viable strategy.   &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://deadline.com/2022/08/john-oliver-business-daddy-warner-bros-discovery-1235087249/\"&gt;https://deadline.com/2022/08/john-oliver-business-daddy-warner-bros-discovery-1235087249/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/v_yItIRT5GCHSNXmwZ7leVlNn8KE6igt0_YR18aqeSY.jpg?auto=webp&amp;s=4852b99299be7c3e54a1ed46380251ffe3b439c6", "width": 1023, "height": 646}, "resolutions": [{"url": "https://external-preview.redd.it/v_yItIRT5GCHSNXmwZ7leVlNn8KE6igt0_YR18aqeSY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=30b1d32241b16d3fcdc8006d8a984f6c929c232e", "width": 108, "height": 68}, {"url": "https://external-preview.redd.it/v_yItIRT5GCHSNXmwZ7leVlNn8KE6igt0_YR18aqeSY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2b47a4e2b95e6fd60aaf75861d119ab2e4228a53", "width": 216, "height": 136}, {"url": "https://external-preview.redd.it/v_yItIRT5GCHSNXmwZ7leVlNn8KE6igt0_YR18aqeSY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2118c5e8f4a0b7617282422e2b74728e5eebba6f", "width": 320, "height": 202}, {"url": "https://external-preview.redd.it/v_yItIRT5GCHSNXmwZ7leVlNn8KE6igt0_YR18aqeSY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2b38fe97ab3c3b8b7840341ab702f305537b63b4", "width": 640, "height": 404}, {"url": "https://external-preview.redd.it/v_yItIRT5GCHSNXmwZ7leVlNn8KE6igt0_YR18aqeSY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2b1a4e61c95a016c43e430b2dd46dd4b87eee52a", "width": 960, "height": 606}], "variants": {}, "id": "BtZYr75q1Fxu7wqaB370Gmwi7gc4neWHlMymY9LpKok"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "zkv1ii", "is_robot_indexable": true, "report_reasons": null, "author": "UnlikelyAdventurer", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zkv1ii/there_is_no_cure_for_zaslav_except_datahoarding/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zkv1ii/there_is_no_cure_for_zaslav_except_datahoarding/", "subreddit_subscribers": 659017, "created_utc": 1670936065.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My apologies if this topic does not belong to this group, but I ran out of options and this is my last resource. \n\nThere is in **BBC Sounds** a podcast called **Night Tracks**. Each episode is a beautiful collection of classical and rare experimental music. The episodes are only available for certain amount of time and then they are removed from the website. \n\nI want to collect every single episode but I haven't found any way to download them. I've tried with multiple ad-ons, extensions, and software but it is just imposible. \n\nPerhaps someone here knows a way. I would deeply appreciate any help.", "author_fullname": "t2_tzaj22sa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A datahoarding attempt that has proven to be almost impossible", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zkdqq7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "265b199a-b98c-11e2-8300-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "cloud", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670883990.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My apologies if this topic does not belong to this group, but I ran out of options and this is my last resource. &lt;/p&gt;\n\n&lt;p&gt;There is in &lt;strong&gt;BBC Sounds&lt;/strong&gt; a podcast called &lt;strong&gt;Night Tracks&lt;/strong&gt;. Each episode is a beautiful collection of classical and rare experimental music. The episodes are only available for certain amount of time and then they are removed from the website. &lt;/p&gt;\n\n&lt;p&gt;I want to collect every single episode but I haven&amp;#39;t found any way to download them. I&amp;#39;ve tried with multiple ad-ons, extensions, and software but it is just imposible. &lt;/p&gt;\n\n&lt;p&gt;Perhaps someone here knows a way. I would deeply appreciate any help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "To the Cloud!", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zkdqq7", "is_robot_indexable": true, "report_reasons": null, "author": "Melancholic-Beast", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/zkdqq7/a_datahoarding_attempt_that_has_proven_to_be/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zkdqq7/a_datahoarding_attempt_that_has_proven_to_be/", "subreddit_subscribers": 659017, "created_utc": 1670883990.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Looking for something dedicated but less expensive like this for my Windows PC, don't need to have Raid:\n\n[https://eshop.macsales.com/item/OWC/SSDACL4M208T/#customer-reviews](https://eshop.macsales.com/item/OWC/SSDACL4M208T/#customer-reviews)\n\nThanks!", "author_fullname": "t2_3zj1o3uc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any dedicated PCIe 4.0 NVMe quad adapters?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zk7y1j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670871565.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for something dedicated but less expensive like this for my Windows PC, don&amp;#39;t need to have Raid:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://eshop.macsales.com/item/OWC/SSDACL4M208T/#customer-reviews\"&gt;https://eshop.macsales.com/item/OWC/SSDACL4M208T/#customer-reviews&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zk7y1j", "is_robot_indexable": true, "report_reasons": null, "author": "MarkGeraz", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zk7y1j/any_dedicated_pcie_40_nvme_quad_adapters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zk7y1j/any_dedicated_pcie_40_nvme_quad_adapters/", "subreddit_subscribers": 659017, "created_utc": 1670871565.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Let me spin you a tale as old as time about a man and his data. Hopefully, you can learn that without a solid main setup, even backups cannot save you. \n\nThe story starts in 2016 when I bought my first RAID controller and drives to build my first storage server. Being of young age and with limited means, I opted to cheap out on the controller and buy the (as I later figured out) awful [HighPoint Rocketraid 840A](https://www.amazon.com/High-Point-RocketRAID-840A-Adapter/dp/B01J3TZF5I), then going for about $300. Compared with an LSI card with 16 ports, that was approximately a third of the price when buying new (Stupid me didn't even consider buying used). Of course, it later turns out that the hardware RAID6 capabilities I bought the card for are not even present, but that is another story for another day. \n\nSo I set up a volume in the card's BIOS, and install some drivers. Then, a nice WebUI is presented, tracking the drives' health and the overall health of the array. I do a bi-weekly test on the drives to check for bad sectors, as well as scrub the array. Everything always comes out clean, with no issues, no bad sectors, nothing. As everyone always says, RAID is not backup, so of course, I have local backups of critical data and cloud backups of all the data (BackBlaze unlimited storage). So far, so good. \n\nThis goes on for 5-6 years, the NAS is chugging along nicely without issues. Come last year and feel ready for an upgrade. I have learned a lot these past years and as such would like something a little more robust. A Debian server with lots of custom cron jobs, remote access to the storage, etc etc. And, of course, OpenZFS - the last word in filesystems. I buy the LSI 9300-16i to replace my old RAID card, but choose to carry the drives forward, as I don't need more storage at this moment and they report as healthy. Right before the upgrade, one of the disks in the array dies. No worries, I buy a new disk, pop it in, and the controller automatically integrates it and rebuilds the array. So far, so good. \n\nSo transfer all my data to external drives, wipe the array, set up the new OS, set up a new vdev, and transfer the data. All is great. Or so I thought. After the first scrub results come in,  the story changes. 2 of the 9 disks in the array have read errors, with one having write errors as well.  \n\nhttps://preview.redd.it/kax9i6idyn5a1.png?width=679&amp;format=png&amp;auto=webp&amp;s=e6e59734b9cd73f161df9e31e64c16d9f0dbc81b\n\nThe vdev is degraded, but that is of little consequence, as the data fed to it from the start could be bad. Literally two days after setting up a ZFS array I find out that for 6 years, my RAID controller has been lying to me about the state of my data. I have no way of knowing when the drives went bad, which data was stored on them, and what use my backups are. I can't feasibly check every document, and every picture for corruption, and worst of all, I cannot restore anything from backups, since it all comes from the same, rotten source. I have unknowingly sabotaged my own backups. \n\nAnd all of this because of a stupid, worthless RAID card telling me that the disks have zero bad sectors and can be trusted. I don't know if I have any data loss, but as there are three drives in total that went bad with one dying outright, it may be possible. I can't trust my backups, I can't trust my NAS. \n\nI hope this story serves as a warning to those looking to save a buck on garbage-tier HBAs, while also serving as a wholehearted recommendation of ZFS. I have used it for less than a week, but I already feel like a part of the cult with integrity.", "author_fullname": "t2_g7mbw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unreliable hardware and the false sense of security of backups", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 83, "top_awarded_type": null, "hide_score": true, "media_metadata": {"kax9i6idyn5a1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 64, "x": 108, "u": "https://preview.redd.it/kax9i6idyn5a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=655bd8c58ca68a69226b4b33fdd811cc39128c8f"}, {"y": 129, "x": 216, "u": "https://preview.redd.it/kax9i6idyn5a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=532cf1c6162bf32054b7f124367a260da8976ec2"}, {"y": 191, "x": 320, "u": "https://preview.redd.it/kax9i6idyn5a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=127ea2614d8fa74015a8107872aa5a3488fcb0fd"}, {"y": 383, "x": 640, "u": "https://preview.redd.it/kax9i6idyn5a1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=513f972df17c0aa652f222cd291668b523a7bb95"}], "s": {"y": 407, "x": 679, "u": "https://preview.redd.it/kax9i6idyn5a1.png?width=679&amp;format=png&amp;auto=webp&amp;s=e6e59734b9cd73f161df9e31e64c16d9f0dbc81b"}, "id": "kax9i6idyn5a1"}}, "name": "t3_zkvkik", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Cautionary tale", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/cUlbUKBXPSn59XUYpALrsKU2hqroafw6zTBi3oXEVhk.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670937525.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let me spin you a tale as old as time about a man and his data. Hopefully, you can learn that without a solid main setup, even backups cannot save you. &lt;/p&gt;\n\n&lt;p&gt;The story starts in 2016 when I bought my first RAID controller and drives to build my first storage server. Being of young age and with limited means, I opted to cheap out on the controller and buy the (as I later figured out) awful &lt;a href=\"https://www.amazon.com/High-Point-RocketRAID-840A-Adapter/dp/B01J3TZF5I\"&gt;HighPoint Rocketraid 840A&lt;/a&gt;, then going for about $300. Compared with an LSI card with 16 ports, that was approximately a third of the price when buying new (Stupid me didn&amp;#39;t even consider buying used). Of course, it later turns out that the hardware RAID6 capabilities I bought the card for are not even present, but that is another story for another day. &lt;/p&gt;\n\n&lt;p&gt;So I set up a volume in the card&amp;#39;s BIOS, and install some drivers. Then, a nice WebUI is presented, tracking the drives&amp;#39; health and the overall health of the array. I do a bi-weekly test on the drives to check for bad sectors, as well as scrub the array. Everything always comes out clean, with no issues, no bad sectors, nothing. As everyone always says, RAID is not backup, so of course, I have local backups of critical data and cloud backups of all the data (BackBlaze unlimited storage). So far, so good. &lt;/p&gt;\n\n&lt;p&gt;This goes on for 5-6 years, the NAS is chugging along nicely without issues. Come last year and feel ready for an upgrade. I have learned a lot these past years and as such would like something a little more robust. A Debian server with lots of custom cron jobs, remote access to the storage, etc etc. And, of course, OpenZFS - the last word in filesystems. I buy the LSI 9300-16i to replace my old RAID card, but choose to carry the drives forward, as I don&amp;#39;t need more storage at this moment and they report as healthy. Right before the upgrade, one of the disks in the array dies. No worries, I buy a new disk, pop it in, and the controller automatically integrates it and rebuilds the array. So far, so good. &lt;/p&gt;\n\n&lt;p&gt;So transfer all my data to external drives, wipe the array, set up the new OS, set up a new vdev, and transfer the data. All is great. Or so I thought. After the first scrub results come in,  the story changes. 2 of the 9 disks in the array have read errors, with one having write errors as well.  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/kax9i6idyn5a1.png?width=679&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e6e59734b9cd73f161df9e31e64c16d9f0dbc81b\"&gt;https://preview.redd.it/kax9i6idyn5a1.png?width=679&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e6e59734b9cd73f161df9e31e64c16d9f0dbc81b&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The vdev is degraded, but that is of little consequence, as the data fed to it from the start could be bad. Literally two days after setting up a ZFS array I find out that for 6 years, my RAID controller has been lying to me about the state of my data. I have no way of knowing when the drives went bad, which data was stored on them, and what use my backups are. I can&amp;#39;t feasibly check every document, and every picture for corruption, and worst of all, I cannot restore anything from backups, since it all comes from the same, rotten source. I have unknowingly sabotaged my own backups. &lt;/p&gt;\n\n&lt;p&gt;And all of this because of a stupid, worthless RAID card telling me that the disks have zero bad sectors and can be trusted. I don&amp;#39;t know if I have any data loss, but as there are three drives in total that went bad with one dying outright, it may be possible. I can&amp;#39;t trust my backups, I can&amp;#39;t trust my NAS. &lt;/p&gt;\n\n&lt;p&gt;I hope this story serves as a warning to those looking to save a buck on garbage-tier HBAs, while also serving as a wholehearted recommendation of ZFS. I have used it for less than a week, but I already feel like a part of the cult with integrity.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "36TB ( 9x 4TB RaidZ3)", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "zkvkik", "is_robot_indexable": true, "report_reasons": null, "author": "frantakiller", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/zkvkik/unreliable_hardware_and_the_false_sense_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zkvkik/unreliable_hardware_and_the_false_sense_of/", "subreddit_subscribers": 659017, "created_utc": 1670937525.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi \n\nI'm trying to find an online backup solution for my veracrypt container that is around 300GB and growing. Ideally, I want a provider that doesn't require you to split the large file in parts. I'm not certain, but my current understanding is that I cannot split up the container into separate parts...\n\n&amp;#x200B;\n\nI don't need any syncing. I intend on uploading the entire container once per week. \n\n&amp;#x200B;\n\nAny suggestions would be much appreciated. ", "author_fullname": "t2_u07vnc7p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cloud solution for huge files that cannot be split up?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zk77qt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670870051.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to find an online backup solution for my veracrypt container that is around 300GB and growing. Ideally, I want a provider that doesn&amp;#39;t require you to split the large file in parts. I&amp;#39;m not certain, but my current understanding is that I cannot split up the container into separate parts...&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t need any syncing. I intend on uploading the entire container once per week. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any suggestions would be much appreciated. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zk77qt", "is_robot_indexable": true, "report_reasons": null, "author": "user44566829", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zk77qt/cloud_solution_for_huge_files_that_cannot_be/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zk77qt/cloud_solution_for_huge_files_that_cannot_be/", "subreddit_subscribers": 659017, "created_utc": 1670870051.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'd like to download the entire SCP wiki so I can browse it offline, but WITHOUT download the comment sections. Is there a software that can do this? How would I limit the software to only download this wiki and any pages closely related to it, without following any possible links to other wikis and downloading those?", "author_fullname": "t2_50fpwuu0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to download an entire wiki?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zkt9hc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670930243.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;d like to download the entire SCP wiki so I can browse it offline, but WITHOUT download the comment sections. Is there a software that can do this? How would I limit the software to only download this wiki and any pages closely related to it, without following any possible links to other wikis and downloading those?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zkt9hc", "is_robot_indexable": true, "report_reasons": null, "author": "Voldy256", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zkt9hc/how_to_download_an_entire_wiki/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zkt9hc/how_to_download_an_entire_wiki/", "subreddit_subscribers": 659017, "created_utc": 1670930243.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_oj0pl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Turkish movies which are hard to find on torrent are being uploaded with English subtitles to Youtube. Go ahead and back them up.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_zkbvih", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/wZznEwWjQxzEBKDpk0qBMND9lriEWFKgKWT3vWB22p8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670880033.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/@moviturkinternational/videos", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ru_AMlstSs-CGi-1_U-UXoek4nQGAg_xK8luucv6hFc.jpg?auto=webp&amp;s=bd24de6703c0cea3f6934e6e3e87ec331933771a", "width": 900, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/ru_AMlstSs-CGi-1_U-UXoek4nQGAg_xK8luucv6hFc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d43f81079e3aa103d4993d570555a39fc14ff42e", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/ru_AMlstSs-CGi-1_U-UXoek4nQGAg_xK8luucv6hFc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a538f9a9f896238f3e2aeaccd161890a4dd20c66", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/ru_AMlstSs-CGi-1_U-UXoek4nQGAg_xK8luucv6hFc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e0c6b70089562eda047670f5b50d0629c79f684c", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/ru_AMlstSs-CGi-1_U-UXoek4nQGAg_xK8luucv6hFc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=84131d91db097765f56c2ea83cf9b746c56b741e", "width": 640, "height": 640}], "variants": {}, "id": "1QOSAck5v15D_7FRM65FyafUWQnJojwQvqpO6xJFrpM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zkbvih", "is_robot_indexable": true, "report_reasons": null, "author": "Sacrer", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zkbvih/turkish_movies_which_are_hard_to_find_on_torrent/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/@moviturkinternational/videos", "subreddit_subscribers": 659017, "created_utc": 1670880033.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey all, apologies for asking a question I know has been asked a million times. In fact I saw what I'm pretty sure was the answer to my Q a couple weeks ago but have searched and searched and unfortunately can't find it again (shoulda archived it, heh.)\n\nI'm just starting to become a datahoarder and picked up a Synology NAS. My main motivation was the huge collection of tutorials and other knowledge I've saved on YouTube that may up and disappear one day.\n\n**First Goal:** I'm looking for really simple no-code (or very low code - I code all day long, and don't want to have to write/maintain a bunch of this stuff too) way to automatically archive anything I add to a specific YouTube playlist to my Synology NAS. I'd ideally like it to save thumbnails and descriptions as well.\n\n**Second Goal:** Some sort of easy interface for browsing, searching, and watching those archived videos, so I'm not just using crummy Windows search to try and find a video in the future.\n\nDoes anyone have suggestions that can address 1 or 2, or both?\n\nThanks in advance!", "author_fullname": "t2_mdffa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Simple and comprehensive approach to YouTube archiving + browsing/searching?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zk98yu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670874356.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, apologies for asking a question I know has been asked a million times. In fact I saw what I&amp;#39;m pretty sure was the answer to my Q a couple weeks ago but have searched and searched and unfortunately can&amp;#39;t find it again (shoulda archived it, heh.)&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m just starting to become a datahoarder and picked up a Synology NAS. My main motivation was the huge collection of tutorials and other knowledge I&amp;#39;ve saved on YouTube that may up and disappear one day.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;First Goal:&lt;/strong&gt; I&amp;#39;m looking for really simple no-code (or very low code - I code all day long, and don&amp;#39;t want to have to write/maintain a bunch of this stuff too) way to automatically archive anything I add to a specific YouTube playlist to my Synology NAS. I&amp;#39;d ideally like it to save thumbnails and descriptions as well.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Second Goal:&lt;/strong&gt; Some sort of easy interface for browsing, searching, and watching those archived videos, so I&amp;#39;m not just using crummy Windows search to try and find a video in the future.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have suggestions that can address 1 or 2, or both?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zk98yu", "is_robot_indexable": true, "report_reasons": null, "author": "turn-down-for-what", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zk98yu/simple_and_comprehensive_approach_to_youtube/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zk98yu/simple_and_comprehensive_approach_to_youtube/", "subreddit_subscribers": 659017, "created_utc": 1670874356.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_45n9c6l3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WD 14TB Easystore for 199.99 ($14.29 / TB) at Best Buy and BestBuy eBay Store. Ends 11:59PM Dec 13th", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "sale", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_zkw4y6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Sale", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/bOerLmHjtFBJamp5L8XZv4SL1o2vW9DFdufaadHsyHg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670939197.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "bestbuy.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.bestbuy.com/site/wd-easystore-14tb-external-usb-3-0-hard-drive-black/6425303.p?skuId=6425303", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZseKVRgX3jeJqr848TEUnFsXmb36I5tfKDi8Zy3BG-o.jpg?auto=webp&amp;s=0d9dc09b0ad8bb581b3f12d19a61f850933bb13d", "width": 1452, "height": 5012}, "resolutions": [{"url": "https://external-preview.redd.it/ZseKVRgX3jeJqr848TEUnFsXmb36I5tfKDi8Zy3BG-o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f13038664e7cac7334520eb6f6219ebcaa06077d", "width": 108, "height": 216}, {"url": "https://external-preview.redd.it/ZseKVRgX3jeJqr848TEUnFsXmb36I5tfKDi8Zy3BG-o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ced7daed466de03f936545afae108a381fbd5548", "width": 216, "height": 432}, {"url": "https://external-preview.redd.it/ZseKVRgX3jeJqr848TEUnFsXmb36I5tfKDi8Zy3BG-o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=99ce2e22c9b74024d7f6948409a3403bb9821faf", "width": 320, "height": 640}, {"url": "https://external-preview.redd.it/ZseKVRgX3jeJqr848TEUnFsXmb36I5tfKDi8Zy3BG-o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a06827eb64f82327b663eeb4bcc50b34736b2469", "width": 640, "height": 1280}, {"url": "https://external-preview.redd.it/ZseKVRgX3jeJqr848TEUnFsXmb36I5tfKDi8Zy3BG-o.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=959de205f67d48894b89a59f2999a355aea021a3", "width": 960, "height": 1920}, {"url": "https://external-preview.redd.it/ZseKVRgX3jeJqr848TEUnFsXmb36I5tfKDi8Zy3BG-o.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f171001b6b2b3e2579548bf4f45f34f0ee94f5cb", "width": 1080, "height": 2160}], "variants": {}, "id": "v3nUqdM-I-azEYHHZp7B5iu55trREQB_4lBrJlrXTo0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ef8232de-b94e-11eb-ba29-0ed106a6f983", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "zkw4y6", "is_robot_indexable": true, "report_reasons": null, "author": "unsuspectingcueball", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zkw4y6/wd_14tb_easystore_for_19999_1429_tb_at_best_buy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.bestbuy.com/site/wd-easystore-14tb-external-usb-3-0-hard-drive-black/6425303.p?skuId=6425303", "subreddit_subscribers": 659017, "created_utc": 1670939197.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I was staying at my uncles place, he's in pretty ruff shape was really sick can't leave the house much he's got a shit bag. So he's basically broke but he let us stay at his place for our grandpa's funeral, he doesn't have internet basically has a big stack of DVDs and some Japanese Chanel.\n\nSo basically I want to buy him a hard drive or computer, upload as much as I can fit on it. Then have it set so he can just plug it in, plug an HDMI. If anyone knows what my best route would be I haven't downloaded a torrent in a few years so any tips would help. Thanks", "author_fullname": "t2_9dc7zjd8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I want a hard drive that's Netflix like but does need to be connected to the internet.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zkvovh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670937881.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I was staying at my uncles place, he&amp;#39;s in pretty ruff shape was really sick can&amp;#39;t leave the house much he&amp;#39;s got a shit bag. So he&amp;#39;s basically broke but he let us stay at his place for our grandpa&amp;#39;s funeral, he doesn&amp;#39;t have internet basically has a big stack of DVDs and some Japanese Chanel.&lt;/p&gt;\n\n&lt;p&gt;So basically I want to buy him a hard drive or computer, upload as much as I can fit on it. Then have it set so he can just plug it in, plug an HDMI. If anyone knows what my best route would be I haven&amp;#39;t downloaded a torrent in a few years so any tips would help. Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zkvovh", "is_robot_indexable": true, "report_reasons": null, "author": "Pure-Cartographer230", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zkvovh/i_want_a_hard_drive_thats_netflix_like_but_does/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zkvovh/i_want_a_hard_drive_thats_netflix_like_but_does/", "subreddit_subscribers": 659017, "created_utc": 1670937881.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "https://www.amazon.com/dp/B0BGYV6B9V?psc=1\n\nA non-\"renewed\" disk drive at a reasonable price! I'm completely unfamiliar with the company however, are these bad signs? Do you guys have any thoughts on this company or this disk in particular? Any recommendations for me? I've been looking on diskprices.com and I'm kind of hung up on buying new/renewed, more drives, lower storage OR less drives, higher storage each... I'm looking to increase my storage capacity for my main rig PC, it's only got a 1TB NVME and an external USB HDD with 4TB. My goal is to hoard the entire Z-Library archive (23TB) and to maybe host my own cloud storage, but until then I'll just piece it together one at a time until a drive fills up or my PC runs out of space. \ninb4 read the wiki thank you thank you", "author_fullname": "t2_eflrm5nv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WDD (Max Digital Data?) Thoughts on increasing storage for main rig PC", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zka5fj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670876336.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.amazon.com/dp/B0BGYV6B9V?psc=1\"&gt;https://www.amazon.com/dp/B0BGYV6B9V?psc=1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;A non-&amp;quot;renewed&amp;quot; disk drive at a reasonable price! I&amp;#39;m completely unfamiliar with the company however, are these bad signs? Do you guys have any thoughts on this company or this disk in particular? Any recommendations for me? I&amp;#39;ve been looking on diskprices.com and I&amp;#39;m kind of hung up on buying new/renewed, more drives, lower storage OR less drives, higher storage each... I&amp;#39;m looking to increase my storage capacity for my main rig PC, it&amp;#39;s only got a 1TB NVME and an external USB HDD with 4TB. My goal is to hoard the entire Z-Library archive (23TB) and to maybe host my own cloud storage, but until then I&amp;#39;ll just piece it together one at a time until a drive fills up or my PC runs out of space. \ninb4 read the wiki thank you thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zka5fj", "is_robot_indexable": true, "report_reasons": null, "author": "Goberoberto", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zka5fj/wdd_max_digital_data_thoughts_on_increasing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zka5fj/wdd_max_digital_data_thoughts_on_increasing/", "subreddit_subscribers": 659017, "created_utc": 1670876336.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone,\n\nI have around 500gb of backup files ranging from 5gb to 150gb. The full backups are the large ones and contained in one large file. \n\nI am wondering what is the best way to upload the files to cloud (using gdrive now). Any kind of tools that can resume upload if connection got disconnected? Using Linux on my server. \n\nAppreciate any suggestions. Thank you.", "author_fullname": "t2_b88a0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Upload large files to gdrive dilemma", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zkk3ev", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670899655.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I have around 500gb of backup files ranging from 5gb to 150gb. The full backups are the large ones and contained in one large file. &lt;/p&gt;\n\n&lt;p&gt;I am wondering what is the best way to upload the files to cloud (using gdrive now). Any kind of tools that can resume upload if connection got disconnected? Using Linux on my server. &lt;/p&gt;\n\n&lt;p&gt;Appreciate any suggestions. Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zkk3ev", "is_robot_indexable": true, "report_reasons": null, "author": "abubin", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zkk3ev/upload_large_files_to_gdrive_dilemma/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zkk3ev/upload_large_files_to_gdrive_dilemma/", "subreddit_subscribers": 659017, "created_utc": 1670899655.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, I generally lurk and rarely posts here.\n\n&amp;#x200B;\n\nI saw the Western Digital sale post during Black Friday for the Red Pro NAS drives so I jumped on the chance. Bought 2, and then realized I needed more so bought 2 more. The first 2 drives came perfectly fine, passed SMART and had no problems with stress tests.  \n\n\nThe second batch had huge problems. One, they delivered only ONE drive instead of the two I ordered. Next, the one drive that did arrive was dead on arrival. SMART wasn't even working when I plugged it in. So I tried RMAing it,  but that requires registering it. So I tried registering the drive and lo and behold, I get   \n\"Sorry! Product registration failed, please try later. (STATCODE108)\"  \n\n\nCustomer support is just running me around the ringer. They keep promising me updates with no updates given after their promised deadline of \"24-48 hours.\" I have gone through both their chat system, garnering me the generic   \n(\"Please allow me to inform you that your issue has already been forwarde to our team and they are looking iinto the issue.\")   \nand calls - what else can I do?  \n\n\nI registered the previous 2 drives just fine. All drives were bought directly from the WD online store.", "author_fullname": "t2_lprcf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Western Digital RMA Help - Red PRO NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zke3o5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670884737.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I generally lurk and rarely posts here.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I saw the Western Digital sale post during Black Friday for the Red Pro NAS drives so I jumped on the chance. Bought 2, and then realized I needed more so bought 2 more. The first 2 drives came perfectly fine, passed SMART and had no problems with stress tests.  &lt;/p&gt;\n\n&lt;p&gt;The second batch had huge problems. One, they delivered only ONE drive instead of the two I ordered. Next, the one drive that did arrive was dead on arrival. SMART wasn&amp;#39;t even working when I plugged it in. So I tried RMAing it,  but that requires registering it. So I tried registering the drive and lo and behold, I get&lt;br/&gt;\n&amp;quot;Sorry! Product registration failed, please try later. (STATCODE108)&amp;quot;  &lt;/p&gt;\n\n&lt;p&gt;Customer support is just running me around the ringer. They keep promising me updates with no updates given after their promised deadline of &amp;quot;24-48 hours.&amp;quot; I have gone through both their chat system, garnering me the generic&lt;br/&gt;\n(&amp;quot;Please allow me to inform you that your issue has already been forwarde to our team and they are looking iinto the issue.&amp;quot;)&lt;br/&gt;\nand calls - what else can I do?  &lt;/p&gt;\n\n&lt;p&gt;I registered the previous 2 drives just fine. All drives were bought directly from the WD online store.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zke3o5", "is_robot_indexable": true, "report_reasons": null, "author": "RockyX123", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zke3o5/western_digital_rma_help_red_pro_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zke3o5/western_digital_rma_help_red_pro_nas/", "subreddit_subscribers": 659017, "created_utc": 1670884737.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "If an SSD has been formatted can data still be covered from the drive and if so what free software can i use to try and retrieve the data ?", "author_fullname": "t2_g3pttvkl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data recovery", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zka49j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670876261.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If an SSD has been formatted can data still be covered from the drive and if so what free software can i use to try and retrieve the data ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zka49j", "is_robot_indexable": true, "report_reasons": null, "author": "CumsockFinder", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zka49j/data_recovery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zka49j/data_recovery/", "subreddit_subscribers": 659017, "created_utc": 1670876261.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "i've been using a dead discord channel for random occasional file uploads for like a year, and would like to back them up. anybody know how I could extract the direct attachment urls from the entire channel without manual labor?\n\nthank", "author_fullname": "t2_fa63c16m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "quick way to grab direct links for discord uploads?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zk7un4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.54, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670871354.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i&amp;#39;ve been using a dead discord channel for random occasional file uploads for like a year, and would like to back them up. anybody know how I could extract the direct attachment urls from the entire channel without manual labor?&lt;/p&gt;\n\n&lt;p&gt;thank&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zk7un4", "is_robot_indexable": true, "report_reasons": null, "author": "pbdrizz", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zk7un4/quick_way_to_grab_direct_links_for_discord_uploads/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zk7un4/quick_way_to_grab_direct_links_for_discord_uploads/", "subreddit_subscribers": 659017, "created_utc": 1670871354.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nIm on windows, with 2 samba shares that are on different hard drives but same unraid server.\n\nI copy from one to another, does it copy directly on unraid or it goes all the way through my PC and slowed down by network?\n\nCan i just use my Windows 11with SpeedCommander to manage files on unraid or I must use something like Krusader to do it locally?\n\nThanks", "author_fullname": "t2_onbly768", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does Remote Copy/Move works?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zkkmyh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670901118.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;Im on windows, with 2 samba shares that are on different hard drives but same unraid server.&lt;/p&gt;\n\n&lt;p&gt;I copy from one to another, does it copy directly on unraid or it goes all the way through my PC and slowed down by network?&lt;/p&gt;\n\n&lt;p&gt;Can i just use my Windows 11with SpeedCommander to manage files on unraid or I must use something like Krusader to do it locally?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zkkmyh", "is_robot_indexable": true, "report_reasons": null, "author": "-Hexenhammer-", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zkkmyh/how_does_remote_copymove_works/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zkkmyh/how_does_remote_copymove_works/", "subreddit_subscribers": 659017, "created_utc": 1670901118.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just backed up my 2TB drive (yes baby numbers I know) to a bucket using copy. I'm new to all this so my question is how do I make it so that next time I need to back up it just uploads new items and not the full 2 TB again? \n\nThanks in advance", "author_fullname": "t2_5rmrxudp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "quick question about Rclone", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zkkltu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670901035.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just backed up my 2TB drive (yes baby numbers I know) to a bucket using copy. I&amp;#39;m new to all this so my question is how do I make it so that next time I need to back up it just uploads new items and not the full 2 TB again? &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zkkltu", "is_robot_indexable": true, "report_reasons": null, "author": "TroothBeToldPodcast", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zkkltu/quick_question_about_rclone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zkkltu/quick_question_about_rclone/", "subreddit_subscribers": 659017, "created_utc": 1670901035.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I used DVDFab to try and backup my Nick scene it dvd and i noticed it ripped extremely quickly. It even says its a large file like a dvd iso should be. Upon booting the iso file the intro screens worked fine but when i select play game it either crashes the video player, or restarts the iso from the start. \n\nIt seems most of the disc doesn\u2019t copy as it should at all, and i cant find any information online on how to fully rip these interactive dvd games. Any ideas?", "author_fullname": "t2_6j6wnh52", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Iso backups of \u201cscene it?\u201d Discs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zkeoig", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670886019.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I used DVDFab to try and backup my Nick scene it dvd and i noticed it ripped extremely quickly. It even says its a large file like a dvd iso should be. Upon booting the iso file the intro screens worked fine but when i select play game it either crashes the video player, or restarts the iso from the start. &lt;/p&gt;\n\n&lt;p&gt;It seems most of the disc doesn\u2019t copy as it should at all, and i cant find any information online on how to fully rip these interactive dvd games. Any ideas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zkeoig", "is_robot_indexable": true, "report_reasons": null, "author": "Slonkweed", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zkeoig/iso_backups_of_scene_it_discs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zkeoig/iso_backups_of_scene_it_discs/", "subreddit_subscribers": 659017, "created_utc": 1670886019.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I just bought a ULTRASTAR DC HC310 4TB to use for a backup of everything that's important to me and I'm looking for advices and tips on how to store it.\n\nI did read different opinions... Someone say to store it powered off in an antistatic bag and wrapped in pluriball. Others instead say that having it powered off corrupt faster the data and also the lubricant on the moving parts dries out so that when you power it on again it will put the drive under extreme friction.\n\nI have not enough knowledge about this to take a decision on my own so I'm here asking for help. \n\nAlso any other advice will be welcome (such as what to choose when formatting it or anything else that I might not know)\n\nThank you to everyone who will help me !", "author_fullname": "t2_14b9rj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need help with my first backup of everything that's important to me", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zk7hm7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.47, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1670871022.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670870622.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I just bought a ULTRASTAR DC HC310 4TB to use for a backup of everything that&amp;#39;s important to me and I&amp;#39;m looking for advices and tips on how to store it.&lt;/p&gt;\n\n&lt;p&gt;I did read different opinions... Someone say to store it powered off in an antistatic bag and wrapped in pluriball. Others instead say that having it powered off corrupt faster the data and also the lubricant on the moving parts dries out so that when you power it on again it will put the drive under extreme friction.&lt;/p&gt;\n\n&lt;p&gt;I have not enough knowledge about this to take a decision on my own so I&amp;#39;m here asking for help. &lt;/p&gt;\n\n&lt;p&gt;Also any other advice will be welcome (such as what to choose when formatting it or anything else that I might not know)&lt;/p&gt;\n\n&lt;p&gt;Thank you to everyone who will help me !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zk7hm7", "is_robot_indexable": true, "report_reasons": null, "author": "Cris257", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zk7hm7/i_need_help_with_my_first_backup_of_everything/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zk7hm7/i_need_help_with_my_first_backup_of_everything/", "subreddit_subscribers": 659017, "created_utc": 1670870622.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for SeaweedFS experiences", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zks9oa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_408kdxq7", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "TLDR;\n\nI'm torn between wanting to use SeaweedFS and worrying about data availability/recoverability. Hence I am looking for some (long-term) experiences from people who have tried or are using SeaweedFS.\n\n  \n\n\nFull story;\n\nI have been following SeaweedFS for quite some time and I loved it initially, however, as time progresses and I learned more about it I got a bit worried about its recoverability.\n\nI tested it locally and had some issues with it, but those were mainly due to my own lack of knowledge with regards to SeaweedFS and Linux. My failures are what made me initially doubt the recoverability potential of the software since I did have data-loss during my tests. Luckily it was only test-data.\n\nWhen you initially start reading about SeaweedFS it sounds really easy to set up and get started with, and it is, but there are so many things to be aware of when using it \"in production\" that are not always clear in the beginning. For example: The Filer \\*IS\\* a single point of failure if you don't back it up (even though the GitHub page states that there is no single point of failure). Or that it's best to use config files instead of cli parameters when running in production.\n\nOn the other hand, if you know you need to keep these things in mind, then it doesn't really form an issue.\n\nI'm really torn between wanting to use SeaweedFS and worrying about data availability and recoverability, and I'm looking for some experiences from people that have tried it are using SeaweedFS, especially long-term use.", "author_fullname": "t2_408kdxq7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for SeaweedFS experiences", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zks8xn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670926323.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TLDR;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m torn between wanting to use SeaweedFS and worrying about data availability/recoverability. Hence I am looking for some (long-term) experiences from people who have tried or are using SeaweedFS.&lt;/p&gt;\n\n&lt;p&gt;Full story;&lt;/p&gt;\n\n&lt;p&gt;I have been following SeaweedFS for quite some time and I loved it initially, however, as time progresses and I learned more about it I got a bit worried about its recoverability.&lt;/p&gt;\n\n&lt;p&gt;I tested it locally and had some issues with it, but those were mainly due to my own lack of knowledge with regards to SeaweedFS and Linux. My failures are what made me initially doubt the recoverability potential of the software since I did have data-loss during my tests. Luckily it was only test-data.&lt;/p&gt;\n\n&lt;p&gt;When you initially start reading about SeaweedFS it sounds really easy to set up and get started with, and it is, but there are so many things to be aware of when using it &amp;quot;in production&amp;quot; that are not always clear in the beginning. For example: The Filer *IS* a single point of failure if you don&amp;#39;t back it up (even though the GitHub page states that there is no single point of failure). Or that it&amp;#39;s best to use config files instead of cli parameters when running in production.&lt;/p&gt;\n\n&lt;p&gt;On the other hand, if you know you need to keep these things in mind, then it doesn&amp;#39;t really form an issue.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m really torn between wanting to use SeaweedFS and worrying about data availability and recoverability, and I&amp;#39;m looking for some experiences from people that have tried it are using SeaweedFS, especially long-term use.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zks8xn", "is_robot_indexable": true, "report_reasons": null, "author": "Stitch10925", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/zks8xn/looking_for_seaweedfs_experiences/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/zks8xn/looking_for_seaweedfs_experiences/", "subreddit_subscribers": 216807, "created_utc": 1670926323.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1670926407.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/selfhosted/comments/zks8xn/looking_for_seaweedfs_experiences/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zks9oa", "is_robot_indexable": true, "report_reasons": null, "author": "Stitch10925", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_zks8xn", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zks9oa/looking_for_seaweedfs_experiences/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/selfhosted/comments/zks8xn/looking_for_seaweedfs_experiences/", "subreddit_subscribers": 659017, "created_utc": 1670926407.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I need help understanding sata power connector. My psu rated at 500w has 1 ribbon with 5 sata power connectors on it, and another with 3 molex and 2 sata. Label says 5v at 15a and 12v at 41a.\n\nI'm connecting 2x molex into a hot swap drive bay that houses 3x hdd, and a sata on the same ribbon to another hdd.\n\nThe other ribbon has 2 sata connector attached to a drive bay housing 4x2.5\" (vendor says it still works if I only connect 1 sata connector). Another sata connector is attached to an ssd directly.\n\nQuestion: what is the max power draw my setup can support when fully populated? Assume the 3xhdd are the same make/model and the same for 4x2.5\". 2.5\" are all ssds.", "author_fullname": "t2_ratqygnj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Drives per rail...and drive bays", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zkn6ps", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670908411.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need help understanding sata power connector. My psu rated at 500w has 1 ribbon with 5 sata power connectors on it, and another with 3 molex and 2 sata. Label says 5v at 15a and 12v at 41a.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m connecting 2x molex into a hot swap drive bay that houses 3x hdd, and a sata on the same ribbon to another hdd.&lt;/p&gt;\n\n&lt;p&gt;The other ribbon has 2 sata connector attached to a drive bay housing 4x2.5&amp;quot; (vendor says it still works if I only connect 1 sata connector). Another sata connector is attached to an ssd directly.&lt;/p&gt;\n\n&lt;p&gt;Question: what is the max power draw my setup can support when fully populated? Assume the 3xhdd are the same make/model and the same for 4x2.5&amp;quot;. 2.5&amp;quot; are all ssds.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zkn6ps", "is_robot_indexable": true, "report_reasons": null, "author": "lmux", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zkn6ps/drives_per_railand_drive_bays/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zkn6ps/drives_per_railand_drive_bays/", "subreddit_subscribers": 659017, "created_utc": 1670908411.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}