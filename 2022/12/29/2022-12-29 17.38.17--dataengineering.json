{"kind": "Listing", "data": {"after": null, "dist": 23, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently a BI developer for an org with ~250 employees. In my role, I do the following:\n\n-Dimensional modeling in Power BI\n\n-Report development in Power BI - this includes writing measures in DAX, creating the visualizations, doing all the UX stuff, etc.\n\n-ETL data from Azure &gt; an on-prem server using a combination of SSIS, stored procedures, and job schedulers. This is all within MSSQL. The data is used for reporting purposes.\n\n-Refinement and scoping with the users -- I scope out requests, suggest solutions, and provide dev timelines.\n\nIf you are/were a DE hiring manager, what would you think of my experience? Is there anything that I **don't** do that you think I **could** do to make me a stronger candidate?", "author_fullname": "t2_emnkl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'd like to pivot from BI Developer to DE - what skills am I missing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zxpdk5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 50, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 50, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672271806.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently a BI developer for an org with ~250 employees. In my role, I do the following:&lt;/p&gt;\n\n&lt;p&gt;-Dimensional modeling in Power BI&lt;/p&gt;\n\n&lt;p&gt;-Report development in Power BI - this includes writing measures in DAX, creating the visualizations, doing all the UX stuff, etc.&lt;/p&gt;\n\n&lt;p&gt;-ETL data from Azure &amp;gt; an on-prem server using a combination of SSIS, stored procedures, and job schedulers. This is all within MSSQL. The data is used for reporting purposes.&lt;/p&gt;\n\n&lt;p&gt;-Refinement and scoping with the users -- I scope out requests, suggest solutions, and provide dev timelines.&lt;/p&gt;\n\n&lt;p&gt;If you are/were a DE hiring manager, what would you think of my experience? Is there anything that I &lt;strong&gt;don&amp;#39;t&lt;/strong&gt; do that you think I &lt;strong&gt;could&lt;/strong&gt; do to make me a stronger candidate?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zxpdk5", "is_robot_indexable": true, "report_reasons": null, "author": "Awkward_Tick0", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zxpdk5/id_like_to_pivot_from_bi_developer_to_de_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zxpdk5/id_like_to_pivot_from_bi_developer_to_de_what/", "subreddit_subscribers": 84563, "created_utc": 1672271806.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I have been working at my current company for a about 1.5 years. We currently have little documentation on anything. I was wondering if there\u2019s any examples online of good documentation for DE\u2019s. I would like to have an idea of what good documentation looks like for future roles and learn good habits.\n\nAny suggestions would be appreciated!", "author_fullname": "t2_uf0yg6x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good examples of Documentation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zxsmzt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 42, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 42, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672279907.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I have been working at my current company for a about 1.5 years. We currently have little documentation on anything. I was wondering if there\u2019s any examples online of good documentation for DE\u2019s. I would like to have an idea of what good documentation looks like for future roles and learn good habits.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions would be appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zxsmzt", "is_robot_indexable": true, "report_reasons": null, "author": "trapaholic400", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zxsmzt/good_examples_of_documentation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zxsmzt/good_examples_of_documentation/", "subreddit_subscribers": 84563, "created_utc": 1672279907.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all, having a really hard time finding good resources to better make sense of the spark UI (using databricks). Particularly, when I have a command or DLT pipeline that is taking a very long time, I want to learn how to use the UI to debug what is happening. \n\nLet me know if anyone can point me in the right direction for material that could help, thanks!", "author_fullname": "t2_2nfde5yl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Understanding Spark UI/Loga", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zxhphn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672253880.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, having a really hard time finding good resources to better make sense of the spark UI (using databricks). Particularly, when I have a command or DLT pipeline that is taking a very long time, I want to learn how to use the UI to debug what is happening. &lt;/p&gt;\n\n&lt;p&gt;Let me know if anyone can point me in the right direction for material that could help, thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zxhphn", "is_robot_indexable": true, "report_reasons": null, "author": "pmarct", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zxhphn/understanding_spark_uiloga/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zxhphn/understanding_spark_uiloga/", "subreddit_subscribers": 84563, "created_utc": 1672253880.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Assuming I don\u2019t pay for dbt cloud, I can get all of dbt\u2019s features for free and orchestrate with Airflow for an enterprise right?\n\nI\u2019m 90% sure this is true but it just seems crazy considering how small the benefit of dbt Cloud is over using Airflow + an IDE.", "author_fullname": "t2_i9si8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is dbt completely free?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zxqngm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672274891.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Assuming I don\u2019t pay for dbt cloud, I can get all of dbt\u2019s features for free and orchestrate with Airflow for an enterprise right?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m 90% sure this is true but it just seems crazy considering how small the benefit of dbt Cloud is over using Airflow + an IDE.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zxqngm", "is_robot_indexable": true, "report_reasons": null, "author": "FratthewStafford", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zxqngm/is_dbt_completely_free/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zxqngm/is_dbt_completely_free/", "subreddit_subscribers": 84563, "created_utc": 1672274891.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi I am a \u201cbackend engineer\u201d but truthfully I am more akin to a data engineer. My dumpster fire of a job has made me a de facto SQL, ETL, and SSIS/SSRS expert. Given that all my current experience in my current job is related to data engineering, I wanna make a shift to data engineering but I have no idea what to expect from these kind of job interviews\n\nAny advice or tips would be appreciated. My educational background is Computer Science software development so I am curious how similar data engineering job interviews are to software engineering job interviews", "author_fullname": "t2_bcn25", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do data engineering interviews work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zy7q2n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672326873.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi I am a \u201cbackend engineer\u201d but truthfully I am more akin to a data engineer. My dumpster fire of a job has made me a de facto SQL, ETL, and SSIS/SSRS expert. Given that all my current experience in my current job is related to data engineering, I wanna make a shift to data engineering but I have no idea what to expect from these kind of job interviews&lt;/p&gt;\n\n&lt;p&gt;Any advice or tips would be appreciated. My educational background is Computer Science software development so I am curious how similar data engineering job interviews are to software engineering job interviews&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zy7q2n", "is_robot_indexable": true, "report_reasons": null, "author": "Dats_Russia", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zy7q2n/how_do_data_engineering_interviews_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zy7q2n/how_do_data_engineering_interviews_work/", "subreddit_subscribers": 84563, "created_utc": 1672326873.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a delta table in Databricks, I query: *SELECT COUNT(\\* ) FROM table*  \n\\-&gt; I wonder how results are generated each time I run the query. The total rows/records will calculate from delta transaction logs or parquet file metadata or from Hive metastore.\n\nThanks to all!", "author_fullname": "t2_gajh4rjf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks - How Query work in delta lake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zy10vw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672305627.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a delta table in Databricks, I query: &lt;em&gt;SELECT COUNT(\\&lt;/em&gt; ) FROM table*&lt;br/&gt;\n-&amp;gt; I wonder how results are generated each time I run the query. The total rows/records will calculate from delta transaction logs or parquet file metadata or from Hive metastore.&lt;/p&gt;\n\n&lt;p&gt;Thanks to all!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zy10vw", "is_robot_indexable": true, "report_reasons": null, "author": "LoiLN", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zy10vw/databricks_how_query_work_in_delta_lake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zy10vw/databricks_how_query_work_in_delta_lake/", "subreddit_subscribers": 84563, "created_utc": 1672305627.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A beginner question. I am creating a Data Warehouse for my personal project and my batch process insert some duplicated rows in my DW table dimension. I did not find anything about it, but should (must) we always remove duplicated rows? seems to make sense since the fact table has a foreing key pointing to the primary key dimension table values, or maybe it depends of the project/DW?", "author_fullname": "t2_e55z81b9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dimension tables rows must be unique?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zxhh3g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1672253537.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672253323.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A beginner question. I am creating a Data Warehouse for my personal project and my batch process insert some duplicated rows in my DW table dimension. I did not find anything about it, but should (must) we always remove duplicated rows? seems to make sense since the fact table has a foreing key pointing to the primary key dimension table values, or maybe it depends of the project/DW?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zxhh3g", "is_robot_indexable": true, "report_reasons": null, "author": "ByHoldenCaulfield", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zxhh3g/dimension_tables_rows_must_be_unique/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zxhh3g/dimension_tables_rows_must_be_unique/", "subreddit_subscribers": 84563, "created_utc": 1672253323.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My career progression/education:\n\nData Analytics Intern(7 months)-&gt;Software Engineer(2 years)-&gt;Data Scientist(4 months). \n\nMS Data Science (in progress)\n\nBS Information Science, minor CS\n\n\nAll at same employer in the research sector. Employer is dysfunctional and tech stack is outdated. Learning as much of the modern data stack as I can on my own. \n\nRight now, I am sort of a \u201cfull stack\u201d data guy. I am much stronger at programming and data architecture than math. My lack of math background I worry will hinder my DS career. \n\nMy only worry is people saying that DE\u2019s are often second class citizens in industry to DS. My friend thinks I should stay in DS side since I have academia/research experience, and just look for jobs where I can do a bit of both. He also thinks DS will help my\nend career goal which is more business oriented. \n\nMy end career goal is to start a Data consulting company or be a Chief Data Officer at a company. \n\nWWYD? Play to my strengths and go DE, or keep chugging along DS to reach my goals?", "author_fullname": "t2_b7eqz4bi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I transfer from DS to DE and am I ready if so?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zxeyev", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672247426.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My career progression/education:&lt;/p&gt;\n\n&lt;p&gt;Data Analytics Intern(7 months)-&amp;gt;Software Engineer(2 years)-&amp;gt;Data Scientist(4 months). &lt;/p&gt;\n\n&lt;p&gt;MS Data Science (in progress)&lt;/p&gt;\n\n&lt;p&gt;BS Information Science, minor CS&lt;/p&gt;\n\n&lt;p&gt;All at same employer in the research sector. Employer is dysfunctional and tech stack is outdated. Learning as much of the modern data stack as I can on my own. &lt;/p&gt;\n\n&lt;p&gt;Right now, I am sort of a \u201cfull stack\u201d data guy. I am much stronger at programming and data architecture than math. My lack of math background I worry will hinder my DS career. &lt;/p&gt;\n\n&lt;p&gt;My only worry is people saying that DE\u2019s are often second class citizens in industry to DS. My friend thinks I should stay in DS side since I have academia/research experience, and just look for jobs where I can do a bit of both. He also thinks DS will help my\nend career goal which is more business oriented. &lt;/p&gt;\n\n&lt;p&gt;My end career goal is to start a Data consulting company or be a Chief Data Officer at a company. &lt;/p&gt;\n\n&lt;p&gt;WWYD? Play to my strengths and go DE, or keep chugging along DS to reach my goals?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zxeyev", "is_robot_indexable": true, "report_reasons": null, "author": "Old-Box228", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zxeyev/should_i_transfer_from_ds_to_de_and_am_i_ready_if/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zxeyev/should_i_transfer_from_ds_to_de_and_am_i_ready_if/", "subreddit_subscribers": 84563, "created_utc": 1672247426.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all,\n\n\ud83c\udf89 Hope you\u2019re all doing well and happy new year.\n\n\ud83e\uddea Need to test if your Spark code behave as expected? The Behavior Driven Development is what you need.\n\n\ud83d\udcd1 This new article shows you the benefits of such testing approach and how to define efficient BDD tests for your Spark data pipeline the easy way with example.\n\n\\#data \\#development \\#testing \\#pipeline \\#apachespark \\#cucumberbdd \\#bdd", "author_fullname": "t2_a52jqkli", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Build efficient tests for your Spark data pipeline using BDDs with Cucumber", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_zxzm4s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Jxt6b4ZVqA5MoqvStwdxgFzVHqEuh23CEG3Yfa1wXUc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1672300506.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "link.medium.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;\ud83c\udf89 Hope you\u2019re all doing well and happy new year.&lt;/p&gt;\n\n&lt;p&gt;\ud83e\uddea Need to test if your Spark code behave as expected? The Behavior Driven Development is what you need.&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udcd1 This new article shows you the benefits of such testing approach and how to define efficient BDD tests for your Spark data pipeline the easy way with example.&lt;/p&gt;\n\n&lt;p&gt;#data #development #testing #pipeline #apachespark #cucumberbdd #bdd&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://link.medium.com/Li9KGDKf9vb", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/zB8WOJz5-24GbLEoymOHtyz62SE-97t_h_gKRUDAwYk.jpg?auto=webp&amp;s=29794be49ec81397ee7c63004afea830180678f1", "width": 1200, "height": 632}, "resolutions": [{"url": "https://external-preview.redd.it/zB8WOJz5-24GbLEoymOHtyz62SE-97t_h_gKRUDAwYk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=80ed2bd635a4f8cef78aacc42cbfe890f1962955", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/zB8WOJz5-24GbLEoymOHtyz62SE-97t_h_gKRUDAwYk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e62874a11a4afc5512923b1536b3db45a1fe1a19", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/zB8WOJz5-24GbLEoymOHtyz62SE-97t_h_gKRUDAwYk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ab14457bfb5c3e55248f77d06cf0516fe1c4f93a", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/zB8WOJz5-24GbLEoymOHtyz62SE-97t_h_gKRUDAwYk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=aef515e117955ac5bc8256f219687ebb8f660444", "width": 640, "height": 337}, {"url": "https://external-preview.redd.it/zB8WOJz5-24GbLEoymOHtyz62SE-97t_h_gKRUDAwYk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0803c4ecbb7f76f5230df79796dd01f458490ba2", "width": 960, "height": 505}, {"url": "https://external-preview.redd.it/zB8WOJz5-24GbLEoymOHtyz62SE-97t_h_gKRUDAwYk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=406dd46f2fa7967916395a033b11cebc65417e23", "width": 1080, "height": 568}], "variants": {}, "id": "PEEIV4wVJvL0yCdrUlSYJRVB8fDIG01r2zyIWoP0uzk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zxzm4s", "is_robot_indexable": true, "report_reasons": null, "author": "Omaroid_", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zxzm4s/build_efficient_tests_for_your_spark_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://link.medium.com/Li9KGDKf9vb", "subreddit_subscribers": 84563, "created_utc": 1672300506.0, "num_crossposts": 3, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently practicing Leetcode.  The SQL Leetcode questions are basically what I would expect in a data engineer interview, but it's not clear how much python/data structures questions we should be practicing.\n\n\n\n\nIn my experience interviewing, it seems like python questions are typically pretty easy.  It's usually something like implement binary search or find the most frequent occurring number in a list.  I typically interviewed at smaller tech companies.\n\n\n\n\nAt bigger tech companies, how much more difficult do the python questions get?", "author_fullname": "t2_9n60bbfp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How hard are python/data structures questions in data engineering interviews?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zxq9q8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672273938.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently practicing Leetcode.  The SQL Leetcode questions are basically what I would expect in a data engineer interview, but it&amp;#39;s not clear how much python/data structures questions we should be practicing.&lt;/p&gt;\n\n&lt;p&gt;In my experience interviewing, it seems like python questions are typically pretty easy.  It&amp;#39;s usually something like implement binary search or find the most frequent occurring number in a list.  I typically interviewed at smaller tech companies.&lt;/p&gt;\n\n&lt;p&gt;At bigger tech companies, how much more difficult do the python questions get?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zxq9q8", "is_robot_indexable": true, "report_reasons": null, "author": "cloud_computer", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zxq9q8/how_hard_are_pythondata_structures_questions_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zxq9q8/how_hard_are_pythondata_structures_questions_in/", "subreddit_subscribers": 84563, "created_utc": 1672273938.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, Would just like to get some opinions. We're looking into using argo-workflow for our ETL to replace our existing airflow. Meeting some resistance since argo-workflow is just creating configuration files instead of programming. So you can't do things like unit tests (or at least I'm not aware of how to do unit tests in argo). There has been a push to using kubeflow pipeline. As far as I understand it just creates configuration yamls in the backend, but since the kfp uses python, I assume you can create unit tests.\n\nWe're not doing anything with ML. It's just data extraction and transformation and we don't want users to create their own workflow; it would be  a support nightmare.\n\nSo is kubeflow pipeline a valid option for ETL? and thoughts about unit testing (it's kinda a big deal for us)?", "author_fullname": "t2_ahoh5wg9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "argo-workflow vs kubeflow pipeline...thoughts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zxowf8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672270657.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, Would just like to get some opinions. We&amp;#39;re looking into using argo-workflow for our ETL to replace our existing airflow. Meeting some resistance since argo-workflow is just creating configuration files instead of programming. So you can&amp;#39;t do things like unit tests (or at least I&amp;#39;m not aware of how to do unit tests in argo). There has been a push to using kubeflow pipeline. As far as I understand it just creates configuration yamls in the backend, but since the kfp uses python, I assume you can create unit tests.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re not doing anything with ML. It&amp;#39;s just data extraction and transformation and we don&amp;#39;t want users to create their own workflow; it would be  a support nightmare.&lt;/p&gt;\n\n&lt;p&gt;So is kubeflow pipeline a valid option for ETL? and thoughts about unit testing (it&amp;#39;s kinda a big deal for us)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zxowf8", "is_robot_indexable": true, "report_reasons": null, "author": "liiyuj", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zxowf8/argoworkflow_vs_kubeflow_pipelinethoughts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zxowf8/argoworkflow_vs_kubeflow_pipelinethoughts/", "subreddit_subscribers": 84563, "created_utc": 1672270657.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_m0p42", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resume help! DA --&gt; DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_zxnx4c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ND3FZZ4hDJpsr74fLRSGukIx92Zr8DDOSAozL1JsmKQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1672268377.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/hepnrlx5wp8a1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/hepnrlx5wp8a1.jpg?auto=webp&amp;s=d0c5bbf8f488b7038207f6e0cb494f7cc9a9627a", "width": 2550, "height": 3300}, "resolutions": [{"url": "https://preview.redd.it/hepnrlx5wp8a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4e908dd9d998d2e734793088b47d79d6b1040c33", "width": 108, "height": 139}, {"url": "https://preview.redd.it/hepnrlx5wp8a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=824aaed211bf9d5251023b9b2457f086f101be23", "width": 216, "height": 279}, {"url": "https://preview.redd.it/hepnrlx5wp8a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5da2c71cbf1a27745cb3f2371759d4609148bc3f", "width": 320, "height": 414}, {"url": "https://preview.redd.it/hepnrlx5wp8a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3d8f9818adce27a8add61ed2034e92c4825559eb", "width": 640, "height": 828}, {"url": "https://preview.redd.it/hepnrlx5wp8a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a4947875930d10c315dfbb2ae5eb5484f840b528", "width": 960, "height": 1242}, {"url": "https://preview.redd.it/hepnrlx5wp8a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d802986482797b4fcfbea041776729cdc25d8f12", "width": 1080, "height": 1397}], "variants": {}, "id": "dCrCNhMGiJNoUdwKC4fGMQc8TJyLlYsg9IL4szZn8dw"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "zxnx4c", "is_robot_indexable": true, "report_reasons": null, "author": "throughahwae", "discussion_type": null, "num_comments": 4, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zxnx4c/resume_help_da_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/hepnrlx5wp8a1.jpg", "subreddit_subscribers": 84563, "created_utc": 1672268377.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Lowly analyst here, one of the upcoming tasks I have heading into the new year is to report on time and attendance for a department. Now a big problem I have is that I have looked at their spreadsheets and they are baaaad. I'm thinking they could possibly benefit from something else. We have Google Forms available but I was thinking, would it be easier to build the simplest of html forms and have them use this? Budget of course for this project is 0.00 so I guess I'd have to figure out some way to save this webpage on the department's shared Google drive so very limited server back end stuff. What do you guys think and how would you go about it?", "author_fullname": "t2_ftjmo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Would creating a locally hosted html form work better than a Google Form to record time and attendance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zxgj9c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1672254035.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672251124.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Lowly analyst here, one of the upcoming tasks I have heading into the new year is to report on time and attendance for a department. Now a big problem I have is that I have looked at their spreadsheets and they are baaaad. I&amp;#39;m thinking they could possibly benefit from something else. We have Google Forms available but I was thinking, would it be easier to build the simplest of html forms and have them use this? Budget of course for this project is 0.00 so I guess I&amp;#39;d have to figure out some way to save this webpage on the department&amp;#39;s shared Google drive so very limited server back end stuff. What do you guys think and how would you go about it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zxgj9c", "is_robot_indexable": true, "report_reasons": null, "author": "punchoutlanddragons", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zxgj9c/would_creating_a_locally_hosted_html_form_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zxgj9c/would_creating_a_locally_hosted_html_form_work/", "subreddit_subscribers": 84563, "created_utc": 1672251124.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hey guys im new to the whole DE space and working with a team...trying to figure out what a good setup would look like.\n\nlet's say i have `/airflow_main/dags` and i want this folder to contain a bunch of submodules -- each being a dag.\n\nhow do i go from someone on the team creating a repo, to them doing work and then that work showing up as a submodule in the folder above?\n\nwhere is their repo? is it in another repo that other people can look at? or is it in their `/home/user` folder?  and how do i tie it to the `/airflow_main/dags` directory?  are they cloning it, and then making a repo inside that?  i know git is very flexible, but i cant think of a clear roadmap.\n\nwhat i'd like to have is a setup where the people in my group do their own work and when they're done they ask me (programmatically if possible ) to load it into the main airflow repo - and then i can accept and have airflow run with updated dags.\n\nthe key here is i want the dags to be separate so that no one accidentally pulls an `rm -rf` so i'm trying to do this with linux permissions in mind.  im really trying to avoid someone just pushing their project into the main repo or deleting other peoples repos.\n\n&amp;#x200B;\n\nthanks!\n\n&amp;#x200B;\n\nedit:  i'm pretty weak on git, but they definitely have no experience with it - so i'm trying to have them do as little as possible - slowly ramping things up as we go...", "author_fullname": "t2_5qteskd9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how to structure git", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zxv3ec", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1672287472.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672286517.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey guys im new to the whole DE space and working with a team...trying to figure out what a good setup would look like.&lt;/p&gt;\n\n&lt;p&gt;let&amp;#39;s say i have &lt;code&gt;/airflow_main/dags&lt;/code&gt; and i want this folder to contain a bunch of submodules -- each being a dag.&lt;/p&gt;\n\n&lt;p&gt;how do i go from someone on the team creating a repo, to them doing work and then that work showing up as a submodule in the folder above?&lt;/p&gt;\n\n&lt;p&gt;where is their repo? is it in another repo that other people can look at? or is it in their &lt;code&gt;/home/user&lt;/code&gt; folder?  and how do i tie it to the &lt;code&gt;/airflow_main/dags&lt;/code&gt; directory?  are they cloning it, and then making a repo inside that?  i know git is very flexible, but i cant think of a clear roadmap.&lt;/p&gt;\n\n&lt;p&gt;what i&amp;#39;d like to have is a setup where the people in my group do their own work and when they&amp;#39;re done they ask me (programmatically if possible ) to load it into the main airflow repo - and then i can accept and have airflow run with updated dags.&lt;/p&gt;\n\n&lt;p&gt;the key here is i want the dags to be separate so that no one accidentally pulls an &lt;code&gt;rm -rf&lt;/code&gt; so i&amp;#39;m trying to do this with linux permissions in mind.  im really trying to avoid someone just pushing their project into the main repo or deleting other peoples repos.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;thanks!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;edit:  i&amp;#39;m pretty weak on git, but they definitely have no experience with it - so i&amp;#39;m trying to have them do as little as possible - slowly ramping things up as we go...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zxv3ec", "is_robot_indexable": true, "report_reasons": null, "author": "iseestupid", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zxv3ec/how_to_structure_git/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zxv3ec/how_to_structure_git/", "subreddit_subscribers": 84563, "created_utc": 1672286517.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "from sqlserver, there are sqlaudit files which are created randomly through out the day.\n\nthere is a task scheduler which triggers a powershell script through every other hour.\n\nthis powershell script takes each sqlaudit from the logs folder, transforms it to json, dumps it to s3.\n\nwhat logic can be added in the script so that it remembers the last file it has already processed + loaded to s3 and hence doesn't need to be loaded?\n\n1. cant mv processed files to another folder (as then logs cant be viewed from sqlserver)\n2. cant rename files with suffix \\_processed (client doesnt want edits to happen)\n3. if at the end of any powershell script run, one updates a watermark text file with timestamp (date h:m:s) of last processed file would that be efficient ? since at each run all the files in the folder would need to be checked whether it's greater than x.y.z? is there a way to make it faster than o(n)?\n4. Kindly suggest. All leads appreciated!", "author_fullname": "t2_piwlmz4s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "batching files to s3? (noob)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zxgrsu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1672255182.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672251678.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;from sqlserver, there are sqlaudit files which are created randomly through out the day.&lt;/p&gt;\n\n&lt;p&gt;there is a task scheduler which triggers a powershell script through every other hour.&lt;/p&gt;\n\n&lt;p&gt;this powershell script takes each sqlaudit from the logs folder, transforms it to json, dumps it to s3.&lt;/p&gt;\n\n&lt;p&gt;what logic can be added in the script so that it remembers the last file it has already processed + loaded to s3 and hence doesn&amp;#39;t need to be loaded?&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;cant mv processed files to another folder (as then logs cant be viewed from sqlserver)&lt;/li&gt;\n&lt;li&gt;cant rename files with suffix _processed (client doesnt want edits to happen)&lt;/li&gt;\n&lt;li&gt;if at the end of any powershell script run, one updates a watermark text file with timestamp (date h:m:s) of last processed file would that be efficient ? since at each run all the files in the folder would need to be checked whether it&amp;#39;s greater than x.y.z? is there a way to make it faster than o(n)?&lt;/li&gt;\n&lt;li&gt;Kindly suggest. All leads appreciated!&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zxgrsu", "is_robot_indexable": true, "report_reasons": null, "author": "Fun_Story2003", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zxgrsu/batching_files_to_s3_noob/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zxgrsu/batching_files_to_s3_noob/", "subreddit_subscribers": 84563, "created_utc": 1672251678.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I got a job as a data engineer. I am comfortable in SQL and python. But, no aws exposure. My upcoming team lead emphasised on learning cloud services. From where do I start? and what is the scope?", "author_fullname": "t2_7amqb26y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zy8lrb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672329166.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I got a job as a data engineer. I am comfortable in SQL and python. But, no aws exposure. My upcoming team lead emphasised on learning cloud services. From where do I start? and what is the scope?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zy8lrb", "is_robot_indexable": true, "report_reasons": null, "author": "Tousif_11", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zy8lrb/aws/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zy8lrb/aws/", "subreddit_subscribers": 84563, "created_utc": 1672329166.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We've recently run into the issue of hitting Redshift's [table limit](https://docs.aws.amazon.com/redshift/latest/mgmt/amazon-redshift-limits.html) (20k for xplus clusters). That may sound like an absurd amount of tables, but it's because we split tenants by schema. There are plans to change this down the line, but it ain't happening anytime soon.\n\nThe production DB is Postgres and we use Fivetran to get the data from a read replica into Redshift. In Redshift, we do some transformations via dbt to consolidate the schemas into one.\n\nI'm thinking about moving the consolidation logic more upstream (i.e. in the Postgres read replica), but it's not an easy lift.\n\nHas anyone else had to deal with this issue? What's a good work-around that doesn't involve beefing up the cluster? (100k tables looks to be the absolute max and even that isn't sustainable.)", "author_fullname": "t2_56bczqdd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Redshift table limit", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zy6tvv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672324475.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;ve recently run into the issue of hitting Redshift&amp;#39;s &lt;a href=\"https://docs.aws.amazon.com/redshift/latest/mgmt/amazon-redshift-limits.html\"&gt;table limit&lt;/a&gt; (20k for xplus clusters). That may sound like an absurd amount of tables, but it&amp;#39;s because we split tenants by schema. There are plans to change this down the line, but it ain&amp;#39;t happening anytime soon.&lt;/p&gt;\n\n&lt;p&gt;The production DB is Postgres and we use Fivetran to get the data from a read replica into Redshift. In Redshift, we do some transformations via dbt to consolidate the schemas into one.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking about moving the consolidation logic more upstream (i.e. in the Postgres read replica), but it&amp;#39;s not an easy lift.&lt;/p&gt;\n\n&lt;p&gt;Has anyone else had to deal with this issue? What&amp;#39;s a good work-around that doesn&amp;#39;t involve beefing up the cluster? (100k tables looks to be the absolute max and even that isn&amp;#39;t sustainable.)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zy6tvv", "is_robot_indexable": true, "report_reasons": null, "author": "script_sibi", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zy6tvv/redshift_table_limit/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zy6tvv/redshift_table_limit/", "subreddit_subscribers": 84563, "created_utc": 1672324475.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all!  \n\n\nI'm currently analyzing some solutions for moving our in-house Ingres database(vector) to an Azure cloud solution. We're working with large datasets for mapping/geographic applications. We're looking to atleast keep the same performance as we currently have.   \n\n\nI'm currently looking at the following solutions:\n\n* Azure SQL Hyperscale\n* Azure CosmoDB\n* Azure Synapse\n* Azure Databricks\n\nWould any of you have any other suggestions that would be worth looking into? or any pitfalls I could run into?  \n\n\nI'm currently working on a performance analysis with a subset of the data (capped at 200k rows per table), will that give me a honest view of what to expect from these solutions in terms of performance? or am I working on a bad assumption? Should I use a larger dataset?\n\n  \nThis is a new job (2 weeks in) and I am coming from a full stack dev position, so I'm not up to date on the data management aspects of our collective field. Any pointers would be much appreciated!", "author_fullname": "t2_4e7gu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "In-house Actian database to Azure solution", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zy60sg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672322233.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all!  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently analyzing some solutions for moving our in-house Ingres database(vector) to an Azure cloud solution. We&amp;#39;re working with large datasets for mapping/geographic applications. We&amp;#39;re looking to atleast keep the same performance as we currently have.   &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently looking at the following solutions:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Azure SQL Hyperscale&lt;/li&gt;\n&lt;li&gt;Azure CosmoDB&lt;/li&gt;\n&lt;li&gt;Azure Synapse&lt;/li&gt;\n&lt;li&gt;Azure Databricks&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Would any of you have any other suggestions that would be worth looking into? or any pitfalls I could run into?  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working on a performance analysis with a subset of the data (capped at 200k rows per table), will that give me a honest view of what to expect from these solutions in terms of performance? or am I working on a bad assumption? Should I use a larger dataset?&lt;/p&gt;\n\n&lt;p&gt;This is a new job (2 weeks in) and I am coming from a full stack dev position, so I&amp;#39;m not up to date on the data management aspects of our collective field. Any pointers would be much appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zy60sg", "is_robot_indexable": true, "report_reasons": null, "author": "Native136", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zy60sg/inhouse_actian_database_to_azure_solution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zy60sg/inhouse_actian_database_to_azure_solution/", "subreddit_subscribers": 84563, "created_utc": 1672322233.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6ivul0xf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resume advice - I am a university student looking for a DE internship. Any help is appreciated :D", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_zxqcup", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/RQtMqD_Us0ulVmf9lQq7oH0q2lYCAJaLVwxJNXo3L-E.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1672274157.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/ldkuwszofq8a1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/ldkuwszofq8a1.jpg?auto=webp&amp;s=5e9119d2fa40c56b57906b960e74483893aba595", "width": 1275, "height": 1650}, "resolutions": [{"url": "https://preview.redd.it/ldkuwszofq8a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=df4bee1bf46c313c8f77bc657468fb6c8d772d6f", "width": 108, "height": 139}, {"url": "https://preview.redd.it/ldkuwszofq8a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e6e6cd2b0aa1b4eb232f6528b9ccaaa3ed2cbfbc", "width": 216, "height": 279}, {"url": "https://preview.redd.it/ldkuwszofq8a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=adc120786e3b5320eeb0ec7061d7ce0fd72c5ce9", "width": 320, "height": 414}, {"url": "https://preview.redd.it/ldkuwszofq8a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5a4cb4cc15dc8159328701c2e238b49d40558017", "width": 640, "height": 828}, {"url": "https://preview.redd.it/ldkuwszofq8a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=09dc3cde19af4b544b511b1b855478b80e54d78b", "width": 960, "height": 1242}, {"url": "https://preview.redd.it/ldkuwszofq8a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6f29ba8e07388c166edbd544031af66c887cade9", "width": 1080, "height": 1397}], "variants": {}, "id": "B-NhjZo3iZyC_LsSOqCxFHC4OnbC91rcWYdkysNPdmA"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "zxqcup", "is_robot_indexable": true, "report_reasons": null, "author": "smrksmrk", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zxqcup/resume_advice_i_am_a_university_student_looking/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/ldkuwszofq8a1.jpg", "subreddit_subscribers": 84563, "created_utc": 1672274157.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nFor a client I am creating a data warehouse in which we have some slowly changing dimensions (or facts if that is even a thing?). For example we want to report the annually recurring revenue (ARR) for subscriptions and we want to have both the currently active and the expired subscriptions in there. So that we can see the ARR over a timeline. \n\nThe data we retrieve looks like this: \n\n&amp;#x200B;\n\n|subscription\\_id|account\\_id|ARR|start\\_date|end\\_date|\n|:-|:-|:-|:-|:-|\n|1|1|10|01-01-2022|31-03-2022|\n|2|2|20|01-01-2022|31-12-2022|\n|3|1|5|01-04-2022|31-11-2022|\n\nSo in this case the same account (account\\_id 1) renewed a subscription at the 01-04-2022. In the report of 2022 we want to see the ARR for all months in 2022. I've looked into slowly changing dimensions, however something I can not really see in that concept is how to report both the currently active license and the history in a dashboard. If we for example want to visualize the ARR in all of 2022 per month in a dashboarding tool we want to see both subscriptions for account\\_id 1 over the course of the year, not just the currently active one. This seems to be very tricky to do in most dashboarding tools. \n\nTo overcome this I've done the following. I created a calendar table with an interval of 1 month and I cross join it with the table above to generate a fact table. The end result would look like:\n\n&amp;#x200B;\n\n|timestamp|account\\_id|ARR|\n|:-|:-|:-|\n|01-01-2022|1|10|\n|01-01-2022|2|20|\n|01-02-2022|1|10|\n|...|...|...|\n|01-11-2022|1|10|\n|01-11-2022|2|20|\n|01-12-2022|2|20|\n\nThis makes it really easy for the user of the reporting tool to filter on a specific month and show the ARR between the dates and over multiple subscriptions. It does however generate a lot of extra data, but at the moment the storage space is not an issue. And it makes it more of a transactional style table, but the ARR is not really a transaction (i.e. it is not really a sold product on a specific date). \n\nMy question is: Are there better ways of generating a fact table where the source data contains a date range?", "author_fullname": "t2_ipra12z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Creating a fact table from slowly changing data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zy6k1l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672323728.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For a client I am creating a data warehouse in which we have some slowly changing dimensions (or facts if that is even a thing?). For example we want to report the annually recurring revenue (ARR) for subscriptions and we want to have both the currently active and the expired subscriptions in there. So that we can see the ARR over a timeline. &lt;/p&gt;\n\n&lt;p&gt;The data we retrieve looks like this: &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;subscription_id&lt;/th&gt;\n&lt;th align=\"left\"&gt;account_id&lt;/th&gt;\n&lt;th align=\"left\"&gt;ARR&lt;/th&gt;\n&lt;th align=\"left\"&gt;start_date&lt;/th&gt;\n&lt;th align=\"left\"&gt;end_date&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;10&lt;/td&gt;\n&lt;td align=\"left\"&gt;01-01-2022&lt;/td&gt;\n&lt;td align=\"left\"&gt;31-03-2022&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;2&lt;/td&gt;\n&lt;td align=\"left\"&gt;2&lt;/td&gt;\n&lt;td align=\"left\"&gt;20&lt;/td&gt;\n&lt;td align=\"left\"&gt;01-01-2022&lt;/td&gt;\n&lt;td align=\"left\"&gt;31-12-2022&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;3&lt;/td&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;5&lt;/td&gt;\n&lt;td align=\"left\"&gt;01-04-2022&lt;/td&gt;\n&lt;td align=\"left\"&gt;31-11-2022&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;So in this case the same account (account_id 1) renewed a subscription at the 01-04-2022. In the report of 2022 we want to see the ARR for all months in 2022. I&amp;#39;ve looked into slowly changing dimensions, however something I can not really see in that concept is how to report both the currently active license and the history in a dashboard. If we for example want to visualize the ARR in all of 2022 per month in a dashboarding tool we want to see both subscriptions for account_id 1 over the course of the year, not just the currently active one. This seems to be very tricky to do in most dashboarding tools. &lt;/p&gt;\n\n&lt;p&gt;To overcome this I&amp;#39;ve done the following. I created a calendar table with an interval of 1 month and I cross join it with the table above to generate a fact table. The end result would look like:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;timestamp&lt;/th&gt;\n&lt;th align=\"left\"&gt;account_id&lt;/th&gt;\n&lt;th align=\"left\"&gt;ARR&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;01-01-2022&lt;/td&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;10&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;01-01-2022&lt;/td&gt;\n&lt;td align=\"left\"&gt;2&lt;/td&gt;\n&lt;td align=\"left\"&gt;20&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;01-02-2022&lt;/td&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;10&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;...&lt;/td&gt;\n&lt;td align=\"left\"&gt;...&lt;/td&gt;\n&lt;td align=\"left\"&gt;...&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;01-11-2022&lt;/td&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;10&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;01-11-2022&lt;/td&gt;\n&lt;td align=\"left\"&gt;2&lt;/td&gt;\n&lt;td align=\"left\"&gt;20&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;01-12-2022&lt;/td&gt;\n&lt;td align=\"left\"&gt;2&lt;/td&gt;\n&lt;td align=\"left\"&gt;20&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;This makes it really easy for the user of the reporting tool to filter on a specific month and show the ARR between the dates and over multiple subscriptions. It does however generate a lot of extra data, but at the moment the storage space is not an issue. And it makes it more of a transactional style table, but the ARR is not really a transaction (i.e. it is not really a sold product on a specific date). &lt;/p&gt;\n\n&lt;p&gt;My question is: Are there better ways of generating a fact table where the source data contains a date range?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zy6k1l", "is_robot_indexable": true, "report_reasons": null, "author": "starslet93", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zy6k1l/creating_a_fact_table_from_slowly_changing_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zy6k1l/creating_a_fact_table_from_slowly_changing_data/", "subreddit_subscribers": 84563, "created_utc": 1672323728.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone dealt with neo4j before? How should I be orchestrating with this? I've had 0 experience with this tool, but im dealing with as follows: every morning, we load up a graph database with around edgeless 3500 nodes (so not a whole lot), hand it to another department and by the end of the day, there should be like a new variation of edges. This is recorded and recycled, and every week, it gets put through a graph neural network. I've been doing the in-between manually , but I know it will accrue technical debt and am looking for ways to streamline the process", "author_fullname": "t2_b7eh4ujn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using neo4j", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zxzbm8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672299459.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone dealt with neo4j before? How should I be orchestrating with this? I&amp;#39;ve had 0 experience with this tool, but im dealing with as follows: every morning, we load up a graph database with around edgeless 3500 nodes (so not a whole lot), hand it to another department and by the end of the day, there should be like a new variation of edges. This is recorded and recycled, and every week, it gets put through a graph neural network. I&amp;#39;ve been doing the in-between manually , but I know it will accrue technical debt and am looking for ways to streamline the process&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zxzbm8", "is_robot_indexable": true, "report_reasons": null, "author": "countlinard", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zxzbm8/using_neo4j/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zxzbm8/using_neo4j/", "subreddit_subscribers": 84563, "created_utc": 1672299459.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi\n\nI'm setting up a local lab environment for Spark and have just run into some issues relating to (I think) versioning of various supporting components. I'm hoping to use Spark with a UI composed of Jupyter notebooks with pyspark and delta-spark (amongst others), Anaconda as PM.\n\nDoes anyone know of a good reference for getting all these elements playing nicely together? e.g. for version x of Spark you would need version y of pyspark, version z of delta-spark, etc. Or, indeed, details of your own similar environments if similar?", "author_fullname": "t2_2bglroyh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Version compatibility reference", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zxz8jx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1672300613.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672299154.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m setting up a local lab environment for Spark and have just run into some issues relating to (I think) versioning of various supporting components. I&amp;#39;m hoping to use Spark with a UI composed of Jupyter notebooks with pyspark and delta-spark (amongst others), Anaconda as PM.&lt;/p&gt;\n\n&lt;p&gt;Does anyone know of a good reference for getting all these elements playing nicely together? e.g. for version x of Spark you would need version y of pyspark, version z of delta-spark, etc. Or, indeed, details of your own similar environments if similar?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zxz8jx", "is_robot_indexable": true, "report_reasons": null, "author": "H0twax", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zxz8jx/version_compatibility_reference/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zxz8jx/version_compatibility_reference/", "subreddit_subscribers": 84563, "created_utc": 1672299154.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, has anyone successfully used fal python script with dbt 1.3+? Any tips or more extensive examples than they provide in GitHub?\n\nI have a dbt staging model which is populated with cursor fetch next.. loop over the list of urls and download files to s3, then update a table with url to filename mapping. \n\nIt works fine by itself - I'm having a problem with proper yml configs to kick off the script when the model is updated by dbt run. Thx vm.", "author_fullname": "t2_11bm9f4z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "fal dbt python script", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zxrmfb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672277308.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, has anyone successfully used fal python script with dbt 1.3+? Any tips or more extensive examples than they provide in GitHub?&lt;/p&gt;\n\n&lt;p&gt;I have a dbt staging model which is populated with cursor fetch next.. loop over the list of urls and download files to s3, then update a table with url to filename mapping. &lt;/p&gt;\n\n&lt;p&gt;It works fine by itself - I&amp;#39;m having a problem with proper yml configs to kick off the script when the model is updated by dbt run. Thx vm.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zxrmfb", "is_robot_indexable": true, "report_reasons": null, "author": "ar405", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zxrmfb/fal_dbt_python_script/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zxrmfb/fal_dbt_python_script/", "subreddit_subscribers": 84563, "created_utc": 1672277308.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}