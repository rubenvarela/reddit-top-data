{"kind": "Listing", "data": {"after": null, "dist": 8, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a Data Engineer that has just started learning Python.  In my past experience, I always landed data in a STG table with as little changes as possible, then wrote SQL to load the Target and perform post-load logic.  As I'm working with pandas and data frames, I'm spending a lot of time on tasks like changing \"&lt;NULL&gt;\" values to NaN, parsing dates, setting datatypes, etc.\n\nBefore I go too far down that road, what are the opinions here about where to best perform these actions?  My alternative would be to define my STG tables with all \"Text\" columns, dump the data in raw, then perform all those actions with SQL on the way to my target.  Only downside I can foresee is possibly less options for error handling?  Is there a consensus on best practice for where to do these kinds of things?  Any insights are appreciated!", "author_fullname": "t2_14wbya", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Place for Transformations: Python or SQL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zv2rzg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 46, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 46, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671990483.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a Data Engineer that has just started learning Python.  In my past experience, I always landed data in a STG table with as little changes as possible, then wrote SQL to load the Target and perform post-load logic.  As I&amp;#39;m working with pandas and data frames, I&amp;#39;m spending a lot of time on tasks like changing &amp;quot;&amp;lt;NULL&amp;gt;&amp;quot; values to NaN, parsing dates, setting datatypes, etc.&lt;/p&gt;\n\n&lt;p&gt;Before I go too far down that road, what are the opinions here about where to best perform these actions?  My alternative would be to define my STG tables with all &amp;quot;Text&amp;quot; columns, dump the data in raw, then perform all those actions with SQL on the way to my target.  Only downside I can foresee is possibly less options for error handling?  Is there a consensus on best practice for where to do these kinds of things?  Any insights are appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zv2rzg", "is_robot_indexable": true, "report_reasons": null, "author": "phobia42", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zv2rzg/best_place_for_transformations_python_or_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zv2rzg/best_place_for_transformations_python_or_sql/", "subreddit_subscribers": 84147, "created_utc": 1671990483.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_u5y5wno7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Embedding an OLAP database in the lakeFS UI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 116, "top_awarded_type": null, "hide_score": false, "name": "t3_zuxh0t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "ups": 35, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/AMumL8-yQlBvVt-QtcoSJGN9ztAaHB5gA7Ivbkr-Qdk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671972282.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "lakefs.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://lakefs.io/blog/lakefs-duckdb-embedding-an-olap-database-in-the-lakefs-ui/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/19bM8x2z03RNBf_Zlc0YAIu3s3uAP1cVnJdEhSfaOUo.jpg?auto=webp&amp;s=e6e9986767998f7192b8feba4d5d6cd6ffa21239", "width": 1200, "height": 1000}, "resolutions": [{"url": "https://external-preview.redd.it/19bM8x2z03RNBf_Zlc0YAIu3s3uAP1cVnJdEhSfaOUo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1d702256466d7f588d77b3c05ed505ee746d28f9", "width": 108, "height": 90}, {"url": "https://external-preview.redd.it/19bM8x2z03RNBf_Zlc0YAIu3s3uAP1cVnJdEhSfaOUo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d814cd8fda1765420505a757255aa93bc29b7904", "width": 216, "height": 180}, {"url": "https://external-preview.redd.it/19bM8x2z03RNBf_Zlc0YAIu3s3uAP1cVnJdEhSfaOUo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ca57bf97e3b3bf6d3c548d8528a74f2ac8c54da9", "width": 320, "height": 266}, {"url": "https://external-preview.redd.it/19bM8x2z03RNBf_Zlc0YAIu3s3uAP1cVnJdEhSfaOUo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fdf256eea8f9814e2b56e64f91d2b612f8815640", "width": 640, "height": 533}, {"url": "https://external-preview.redd.it/19bM8x2z03RNBf_Zlc0YAIu3s3uAP1cVnJdEhSfaOUo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3452ec8a2776201854aa9a44ef08eaa0ee150b9f", "width": 960, "height": 800}, {"url": "https://external-preview.redd.it/19bM8x2z03RNBf_Zlc0YAIu3s3uAP1cVnJdEhSfaOUo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9b292f368226b5009b737a000b3fcd654108696a", "width": 1080, "height": 900}], "variants": {}, "id": "6-MCidx5Xkg-8Z2L_0Ge8tEi7ztLOSXZFTqvHXQOehQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zuxh0t", "is_robot_indexable": true, "report_reasons": null, "author": "rayhumrib", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zuxh0t/embedding_an_olap_database_in_the_lakefs_ui/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://lakefs.io/blog/lakefs-duckdb-embedding-an-olap-database-in-the-lakefs-ui/", "subreddit_subscribers": 84147, "created_utc": 1671972282.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\n\n[View Poll](https://www.reddit.com/poll/zv2puz)", "author_fullname": "t2_eajtr4nz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which lakehouse table format do you expect your organization will be using by the end of 2023?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zv2puz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671990300.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/zv2puz\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zv2puz", "is_robot_indexable": true, "report_reasons": null, "author": "alneuman", "discussion_type": null, "num_comments": 43, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1672422300323, "options": [{"text": "Hive", "id": "20612835"}, {"text": "Delta Lake", "id": "20612836"}, {"text": "Iceberg", "id": "20612837"}, {"text": "Hudi", "id": "20612838"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 634, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zv2puz/which_lakehouse_table_format_do_you_expect_your/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/zv2puz/which_lakehouse_table_format_do_you_expect_your/", "subreddit_subscribers": 84147, "created_utc": 1671990300.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello All,\n\nI am trying to create a Redshift cluster with cloudfomation template. When I modified the AWS provided template and deploying the stack, a new VPC is getting created. Has anyone experienced the same? \n\nAlso, unable to provide a name to Cluster parameter group, Cluster Subnet group and the Security group. \n\nAny references to how to create Redshift cluster within an existing VPC and on how to provide custom names to ClusterParametergroup, ClusterSubnetgroup and Security group.\n\n&amp;#x200B;\n\nThanks.", "author_fullname": "t2_mspamalq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Redshift Cluster with Cloudformation template.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zupa2j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671937700.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello All,&lt;/p&gt;\n\n&lt;p&gt;I am trying to create a Redshift cluster with cloudfomation template. When I modified the AWS provided template and deploying the stack, a new VPC is getting created. Has anyone experienced the same? &lt;/p&gt;\n\n&lt;p&gt;Also, unable to provide a name to Cluster parameter group, Cluster Subnet group and the Security group. &lt;/p&gt;\n\n&lt;p&gt;Any references to how to create Redshift cluster within an existing VPC and on how to provide custom names to ClusterParametergroup, ClusterSubnetgroup and Security group.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zupa2j", "is_robot_indexable": true, "report_reasons": null, "author": "Awsmason", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zupa2j/redshift_cluster_with_cloudformation_template/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zupa2j/redshift_cluster_with_cloudformation_template/", "subreddit_subscribers": 84147, "created_utc": 1671937700.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI\u2019m interested in becoming a data engineer, I\u2019m currently a systems project manager at a FAANG company. I have several years of experience with SQL but never an actual analyst title. I have a Bachelors is Business Administration with a minor in Management of Information Systems. \n\nI\u2019m curious to know if it\u2019s a better idea to take courses online for data engineering or to become a SWE first, then learn data engineering and take on that role? I have no coding experience other than SQL (which I know isn\u2019t technically a coding language).\n\nAlso, is it realistic to become a self-taught data engineer? I am trying to weigh between becoming a self taught front end vs data engineer.", "author_fullname": "t2_979mvrm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on career direction", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zv3wwp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671993984.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m interested in becoming a data engineer, I\u2019m currently a systems project manager at a FAANG company. I have several years of experience with SQL but never an actual analyst title. I have a Bachelors is Business Administration with a minor in Management of Information Systems. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m curious to know if it\u2019s a better idea to take courses online for data engineering or to become a SWE first, then learn data engineering and take on that role? I have no coding experience other than SQL (which I know isn\u2019t technically a coding language).&lt;/p&gt;\n\n&lt;p&gt;Also, is it realistic to become a self-taught data engineer? I am trying to weigh between becoming a self taught front end vs data engineer.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zv3wwp", "is_robot_indexable": true, "report_reasons": null, "author": "Hydroxidee", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zv3wwp/advice_on_career_direction/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zv3wwp/advice_on_career_direction/", "subreddit_subscribers": 84147, "created_utc": 1671993984.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi people, I need your suggestions.\nIn my opinion too much depending on UI tools for data engineering is so easy when we can code what we need and use cloud to do computation.\nAnd Apache beam+GCP dataflow and bigquery seems like the perfect solution. (I mean we can use a orchestration tool to get more advantages and of course a tool for dashboards too).\nI can develop EL pipelines and as well as transformation as both batch and streaming jobs, and use bigquery as DW.\nThis give me lesser tools and environment to manage and more time to focus and build the solution.\n\nWhat do you think\u2026", "author_fullname": "t2_4v8di1j8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Wouldn\u2019t google dataflow and google bigquery be enough for medium scale company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zv4kha", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671995950.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi people, I need your suggestions.\nIn my opinion too much depending on UI tools for data engineering is so easy when we can code what we need and use cloud to do computation.\nAnd Apache beam+GCP dataflow and bigquery seems like the perfect solution. (I mean we can use a orchestration tool to get more advantages and of course a tool for dashboards too).\nI can develop EL pipelines and as well as transformation as both batch and streaming jobs, and use bigquery as DW.\nThis give me lesser tools and environment to manage and more time to focus and build the solution.&lt;/p&gt;\n\n&lt;p&gt;What do you think\u2026&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zv4kha", "is_robot_indexable": true, "report_reasons": null, "author": "Tumbleweed-Afraid", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zv4kha/wouldnt_google_dataflow_and_google_bigquery_be/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zv4kha/wouldnt_google_dataflow_and_google_bigquery_be/", "subreddit_subscribers": 84147, "created_utc": 1671995950.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello. I am trying to get familiar with the AWS ecosystem, so I decided to take on a personal project as a way to learn. \n\nThe current rough idea is to create a web application with functionality similar to that of the learning resources page of the wiki ([https://dataengineering.wiki/Learning+Resources](https://dataengineering.wiki/Learning+Resources)). More specifically: \n\n1. Web-accessible\n2. Hosts a large repository of downloadable resources \n3. Extract and upload data into a downloadable or viewable data store on a daily basis\n\nKeeping in mind that I am a total AWS beginner, knowing only the basics of S3 and IAM, what AWS tools should I consider to create the personal project? Overall, I'm just trying to create something that will help lay down a foundation of AWS knowledge in a DE context.", "author_fullname": "t2_7gm6jz5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS beginner. How would you approach this personal project?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zv6j2v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672001904.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello. I am trying to get familiar with the AWS ecosystem, so I decided to take on a personal project as a way to learn. &lt;/p&gt;\n\n&lt;p&gt;The current rough idea is to create a web application with functionality similar to that of the learning resources page of the wiki (&lt;a href=\"https://dataengineering.wiki/Learning+Resources\"&gt;https://dataengineering.wiki/Learning+Resources&lt;/a&gt;). More specifically: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Web-accessible&lt;/li&gt;\n&lt;li&gt;Hosts a large repository of downloadable resources &lt;/li&gt;\n&lt;li&gt;Extract and upload data into a downloadable or viewable data store on a daily basis&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Keeping in mind that I am a total AWS beginner, knowing only the basics of S3 and IAM, what AWS tools should I consider to create the personal project? Overall, I&amp;#39;m just trying to create something that will help lay down a foundation of AWS knowledge in a DE context.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zv6j2v", "is_robot_indexable": true, "report_reasons": null, "author": "ZarekBro", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zv6j2v/aws_beginner_how_would_you_approach_this_personal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zv6j2v/aws_beginner_how_would_you_approach_this_personal/", "subreddit_subscribers": 84147, "created_utc": 1672001904.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For me, it was 4 different mainframes and ingestion took 5 days.", "author_fullname": "t2_nmytf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the most legacy platform you are using as a data source in your analytics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zv0a16", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671982591.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For me, it was 4 different mainframes and ingestion took 5 days.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zv0a16", "is_robot_indexable": true, "report_reasons": null, "author": "razkaplan", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zv0a16/whats_the_most_legacy_platform_you_are_using_as_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zv0a16/whats_the_most_legacy_platform_you_are_using_as_a/", "subreddit_subscribers": 84147, "created_utc": 1671982591.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}