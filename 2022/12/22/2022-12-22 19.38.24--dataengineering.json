{"kind": "Listing", "data": {"after": null, "dist": 24, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_10v76s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to adopt a functional programming pattern in a batch pipeline? I wrote the architectural pattern to adapt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 61, "top_awarded_type": null, "hide_score": false, "name": "t3_zs7h38", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "ups": 41, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/KilCxqm7PuvLAVGjP4QZz-cDljtSMHxAJFG9RcDZaVQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671670899.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dataengineeringweekly.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.dataengineeringweekly.com/p/functional-data-engineering-a-blueprint", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/o1vutyL5XJkZZsviRMX0HiqdS101sFQO6_9fNr2R8_I.jpg?auto=webp&amp;s=673d0962760dfc13127d8158ac0ed9f7ed0d3521", "width": 1200, "height": 526}, "resolutions": [{"url": "https://external-preview.redd.it/o1vutyL5XJkZZsviRMX0HiqdS101sFQO6_9fNr2R8_I.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=092b728e62ec2829a5f26145cb5857b4c5ba9cbf", "width": 108, "height": 47}, {"url": "https://external-preview.redd.it/o1vutyL5XJkZZsviRMX0HiqdS101sFQO6_9fNr2R8_I.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=35dce44d7c38efd6c71e0f158b573437835d7dba", "width": 216, "height": 94}, {"url": "https://external-preview.redd.it/o1vutyL5XJkZZsviRMX0HiqdS101sFQO6_9fNr2R8_I.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a70c24711e49be27f88a58a80a06d39708b78ccb", "width": 320, "height": 140}, {"url": "https://external-preview.redd.it/o1vutyL5XJkZZsviRMX0HiqdS101sFQO6_9fNr2R8_I.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d2ed83db3363d1aa22b9413fca4ec18562dd3696", "width": 640, "height": 280}, {"url": "https://external-preview.redd.it/o1vutyL5XJkZZsviRMX0HiqdS101sFQO6_9fNr2R8_I.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ef3e84da87f5e2d6a7a88fff2faa15cd4f309810", "width": 960, "height": 420}, {"url": "https://external-preview.redd.it/o1vutyL5XJkZZsviRMX0HiqdS101sFQO6_9fNr2R8_I.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a714aece5f0b409eb3839f3dcb90b6270c9be09a", "width": 1080, "height": 473}], "variants": {}, "id": "nNzxFS2Af2M8ce8NUpgFuftE9U0Nn2u6znwiPHeNoPM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zs7h38", "is_robot_indexable": true, "report_reasons": null, "author": "vananth22", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zs7h38/how_to_adopt_a_functional_programming_pattern_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.dataengineeringweekly.com/p/functional-data-engineering-a-blueprint", "subreddit_subscribers": 83807, "created_utc": 1671670899.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Idk about you, but my inbox &amp; LinkedIn/Medium/Mastodon feeds have been packed with posts &amp; discussions around Data Contracts - it's been \\_way too much\\_ to keep up with. \n\n[This blog post](https://blog.datahubproject.io/data-contracts-wrapped-2022-470e0c43365d) was super helpful for me -- it's a concise summary of the recent Data Contract buzz... it's broken down into the following topics:\n\n* Definitions: What is a data contract?\n* Scope: Where does it apply?\n* Lifecycle: How are data contracts created and stored?\n* Details: How are data contracts enforced?\n* Beyond the Tech: What sort of culture change is being proposed?\n* Deja Vu: Have we been through this hype before? Is this different from data mesh?\n\nSharing here in case others will find it helpful!", "author_fullname": "t2_g7cej1g1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "tl;dr of Data Contracts", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zs79hk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1671670385.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Idk about you, but my inbox &amp;amp; LinkedIn/Medium/Mastodon feeds have been packed with posts &amp;amp; discussions around Data Contracts - it&amp;#39;s been _way too much_ to keep up with. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://blog.datahubproject.io/data-contracts-wrapped-2022-470e0c43365d\"&gt;This blog post&lt;/a&gt; was super helpful for me -- it&amp;#39;s a concise summary of the recent Data Contract buzz... it&amp;#39;s broken down into the following topics:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Definitions: What is a data contract?&lt;/li&gt;\n&lt;li&gt;Scope: Where does it apply?&lt;/li&gt;\n&lt;li&gt;Lifecycle: How are data contracts created and stored?&lt;/li&gt;\n&lt;li&gt;Details: How are data contracts enforced?&lt;/li&gt;\n&lt;li&gt;Beyond the Tech: What sort of culture change is being proposed?&lt;/li&gt;\n&lt;li&gt;Deja Vu: Have we been through this hype before? Is this different from data mesh?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Sharing here in case others will find it helpful!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1BILH8qYbcrCVgMYwDn-0lSlXqLjjelMRCgF0N8wE6M.jpg?auto=webp&amp;s=ed8e9b6834d87174fdbb7029f262c634f0423a5d", "width": 1200, "height": 432}, "resolutions": [{"url": "https://external-preview.redd.it/1BILH8qYbcrCVgMYwDn-0lSlXqLjjelMRCgF0N8wE6M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e06eab0a6846c339bb3b6169017fd2b62420764e", "width": 108, "height": 38}, {"url": "https://external-preview.redd.it/1BILH8qYbcrCVgMYwDn-0lSlXqLjjelMRCgF0N8wE6M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=818ef5e9857eafde6d3154a90b9be94d5b910470", "width": 216, "height": 77}, {"url": "https://external-preview.redd.it/1BILH8qYbcrCVgMYwDn-0lSlXqLjjelMRCgF0N8wE6M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=04b65314cc7b49324a5ddde77dd7c876180feb90", "width": 320, "height": 115}, {"url": "https://external-preview.redd.it/1BILH8qYbcrCVgMYwDn-0lSlXqLjjelMRCgF0N8wE6M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=41f59128ce1e4ebc9216e9687cf5233900f09306", "width": 640, "height": 230}, {"url": "https://external-preview.redd.it/1BILH8qYbcrCVgMYwDn-0lSlXqLjjelMRCgF0N8wE6M.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=bed1dce3146db823fd404052a639e140adce35ae", "width": 960, "height": 345}, {"url": "https://external-preview.redd.it/1BILH8qYbcrCVgMYwDn-0lSlXqLjjelMRCgF0N8wE6M.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=56c06ed601c101c27398efbab1b699fdce7fdb05", "width": 1080, "height": 388}], "variants": {}, "id": "YsHsORn_K1UecQxk2UBJfGRSPsejeetIKaZpEq_7iJ0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zs79hk", "is_robot_indexable": true, "report_reasons": null, "author": "Brief_Actuator_8731", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zs79hk/tldr_of_data_contracts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zs79hk/tldr_of_data_contracts/", "subreddit_subscribers": 83807, "created_utc": 1671670385.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I have been reading Martin Kleppmann's Designing Data-Intensive Applications (DDIA), watching his lecture on YouTube, and reading a few other courses' slides and articles on distributed systems.\n\nI have a bunch of questions specifically regarding storage engines, replication, and consensus, but I'm not sure I can state them as clearly as I'd like. I have tried googling them but am not satisfied.\n\nI was wondering if I could throw my thoughts and questions to someone who has read and is confident about the fundamentals of databases and distributed systems as presented in DDIA.", "author_fullname": "t2_1nsaaq48", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone I can DM about Designing Data Intensive Applications and/or distributed systems?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zsm4q2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1671728177.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671715824.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I have been reading Martin Kleppmann&amp;#39;s Designing Data-Intensive Applications (DDIA), watching his lecture on YouTube, and reading a few other courses&amp;#39; slides and articles on distributed systems.&lt;/p&gt;\n\n&lt;p&gt;I have a bunch of questions specifically regarding storage engines, replication, and consensus, but I&amp;#39;m not sure I can state them as clearly as I&amp;#39;d like. I have tried googling them but am not satisfied.&lt;/p&gt;\n\n&lt;p&gt;I was wondering if I could throw my thoughts and questions to someone who has read and is confident about the fundamentals of databases and distributed systems as presented in DDIA.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zsm4q2", "is_robot_indexable": true, "report_reasons": null, "author": "FantasticGrape", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zsm4q2/anyone_i_can_dm_about_designing_data_intensive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zsm4q2/anyone_i_can_dm_about_designing_data_intensive/", "subreddit_subscribers": 83807, "created_utc": 1671715824.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys so I just graduated and I wanna jumpstart my career in data! I\u2019m a bit anxious about my resume specially because of all the time frames. 2020 was quite rough and I had to delay my graduation :( On the upside, I got an early entrance into my Masters program this year. I don\u2019t know how hiring managers will react to this as well as the rest of my CV. Any suggestions at all are greatly appreciated (: thanks", "author_fullname": "t2_jqznxjjy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with resume! Just graduated (:", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_zsfsqf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.74, "author_flair_background_color": "transparent", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "19bba012-ac9d-11eb-b77b-0eec37c01719", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/NPCQq7GqBJT-egQ5IANNtWSTfq2h70H_QHeACo_CduA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671694184.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys so I just graduated and I wanna jumpstart my career in data! I\u2019m a bit anxious about my resume specially because of all the time frames. 2020 was quite rough and I had to delay my graduation :( On the upside, I got an early entrance into my Masters program this year. I don\u2019t know how hiring managers will react to this as well as the rest of my CV. Any suggestions at all are greatly appreciated (: thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/lcid78131g7a1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/lcid78131g7a1.jpg?auto=webp&amp;s=27285ff9a5c374e09a742353327396e6d38de89c", "width": 1125, "height": 1473}, "resolutions": [{"url": "https://preview.redd.it/lcid78131g7a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=eb8032ff6aa43102c741db23d859a84adf7d6a3c", "width": 108, "height": 141}, {"url": "https://preview.redd.it/lcid78131g7a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=632336463c3f31c24488bf7e39732d72f8d47798", "width": 216, "height": 282}, {"url": "https://preview.redd.it/lcid78131g7a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2ed5438cf3c4a4d86a2e7b8f2bc1abd8ef795abf", "width": 320, "height": 418}, {"url": "https://preview.redd.it/lcid78131g7a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=62f3deae97604ea098f2a28019f31674695cf85c", "width": 640, "height": 837}, {"url": "https://preview.redd.it/lcid78131g7a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0e863378aedee8785c4840504763ccf16a573d91", "width": 960, "height": 1256}, {"url": "https://preview.redd.it/lcid78131g7a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=403872f811113edaa469194fd2a78dc5908d5b82", "width": 1080, "height": 1414}], "variants": {}, "id": "CVpR-GgVXeO2ojIzyTRtCXsdtucIWKrWXtIPVWUEDWs"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Analyst", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "zsfsqf", "is_robot_indexable": true, "report_reasons": null, "author": "D1N4D4N1", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/zsfsqf/help_with_resume_just_graduated/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/lcid78131g7a1.jpg", "subreddit_subscribers": 83807, "created_utc": 1671694184.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So my organization has had O365 with the power platform for a few years with a handful of individuals getting really good at treating SharePoint as a database for there power apps(\"front-end\") and power bi reports with power automate work around. The company doesn't want to invest in a proper database like SQL server or full Datavers.\n\nI think this is a recipe for disaster and would like to get options for or against continue using SharePoint as a \"database\".", "author_fullname": "t2_8yface1u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Organization wants to use SharePoint as a \"database\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zsprzt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671725543.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So my organization has had O365 with the power platform for a few years with a handful of individuals getting really good at treating SharePoint as a database for there power apps(&amp;quot;front-end&amp;quot;) and power bi reports with power automate work around. The company doesn&amp;#39;t want to invest in a proper database like SQL server or full Datavers.&lt;/p&gt;\n\n&lt;p&gt;I think this is a recipe for disaster and would like to get options for or against continue using SharePoint as a &amp;quot;database&amp;quot;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zsprzt", "is_robot_indexable": true, "report_reasons": null, "author": "Benmagz", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zsprzt/organization_wants_to_use_sharepoint_as_a_database/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zsprzt/organization_wants_to_use_sharepoint_as_a_database/", "subreddit_subscribers": 83807, "created_utc": 1671725543.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello All, \n\nI am a junior data engineer, and I have been tasked to develop a 1 year learning plan for myself. I work for a consulting firm that has clients which require all sorts of data related work. \n\nThis should include what I wish to learn - and what type of projects I would need to develop those skills. My organization pushes Azure cloud, but also has some projects with GCP and AWS. \n\nI am skilled with SQL and should have my Azure DP-203 by EOY. I also have basic Python skills (and will start getting a CS degree next year part time)\n\nHow should I go about developing this plan? What are the skills/projects that I should ask for to (a) maximize my understanding of this field, and (b) to maximize my potential future earnings. \n\nAll help is appreciated!\n\nThanks!", "author_fullname": "t2_m0kpq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "1 Year Development Plan", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zspr1o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671725477.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello All, &lt;/p&gt;\n\n&lt;p&gt;I am a junior data engineer, and I have been tasked to develop a 1 year learning plan for myself. I work for a consulting firm that has clients which require all sorts of data related work. &lt;/p&gt;\n\n&lt;p&gt;This should include what I wish to learn - and what type of projects I would need to develop those skills. My organization pushes Azure cloud, but also has some projects with GCP and AWS. &lt;/p&gt;\n\n&lt;p&gt;I am skilled with SQL and should have my Azure DP-203 by EOY. I also have basic Python skills (and will start getting a CS degree next year part time)&lt;/p&gt;\n\n&lt;p&gt;How should I go about developing this plan? What are the skills/projects that I should ask for to (a) maximize my understanding of this field, and (b) to maximize my potential future earnings. &lt;/p&gt;\n\n&lt;p&gt;All help is appreciated!&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zspr1o", "is_robot_indexable": true, "report_reasons": null, "author": "swinging_yorker", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zspr1o/1_year_development_plan/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zspr1o/1_year_development_plan/", "subreddit_subscribers": 83807, "created_utc": 1671725477.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all.\n\n&amp;#x200B;\n\nI am fairly new to the concept of testing my code. I just did some learning on how to use Pytest, but problem was that all the examples in the learning material was relatively simplistic and self-contained. When I try to apply it to my own code, I find myself wondering if the test **even make sense.**\n\n&amp;#x200B;\n\nI want to test the following piece of code that utilized AWS services (simplifed for ease of reading - full code can be seen at bottem):\n\n&amp;#x200B;\n\n    def download_file-bucket(bucket, obj, key):\n    connect_to_s3\n        download_csvfile_to_tmp_directory\n    \n    def parse_data_and_send:\n        parse_rows_form_csv\n        for row in csv:\n            payload = row.payload\n            send_to_sqs_queue(payload)\n    \n    def send_to_sqs_queue(payload):\n        connect_to_sqs\n        sqs.sendMessage(payload, connection)\n\nThat is the gist of it.\n\n&amp;#x200B;\n\nThe entire project is set up in Terraform using CodeBuild as the CI/CD tool, and I would like to run these unit test every time the code is deploying.\n\n&amp;#x200B;\n\n**My problem is this:**\n\nDoes it make sense to make unit tests here? I can test each function sure, but all of the functions rely on some AWS ressource that **may or may not exist**, depending on where in the development cycle I am in.\n\n&amp;#x200B;\n\nEven if it does exist, testing it on the real ressources would create a set of new problems, as f.eks. adding a file to the s3 bucket triggers code which will genererate new files etc.\n\n&amp;#x200B;\n\n**Two possible ways out I have considered:**\n\n1. Add a \"tests\" module in the Terraform deployment which is identical to the original ressources, but the ressources will only exist for the duration of the tests, and which will the tear-down when tests are concluded. However, this seems excessive\n2. Mock the outside dependencies like S3 bucket or sqs-queue. However, I feel this invalidates tests, as pretty much all the tests do are test if these outside dependencies work.\n\n&amp;#x200B;\n\nHow would you guys handle this situation?\n\n&amp;#x200B;\n\n*Real code:*\n\n    import os\n    import boto3\n    import logging\n    import pandas as pd\n    from distutils.log import error\n    import datetime\n    \n    # Set up logging\n    logging.basicConfig()\n    logger = logging.getLogger(__name__)\n    logger.setLevel(logging.DEBUG)\n    \n    \n    def s3_download_file(bucket, obj, dest):\n        s3 = session.client(\"s3\")\n    \n        try:\n            s3.download_file(\n                Bucket=bucket,\n                Key=obj,\n                Filename=dest\n            )\n        except:\n            logger.info(f\"Error downloading {obj} to {dest}...\")\n            logger.info(error)\n        else:\n            logger.info(f\"Successfully downloaded {obj} to {dest}...\")\n    \n    \n    def send_to_sqs(payload):\n        sqs = session.client(\"sqs\")\n        ts = datetime.datetime.utcnow().isoformat()\n        Queue_Url = os.environ[\"queue_url\"]\n        response = sqs.send_message(\n            QueueUrl=Queue_Url,\n            MessageBody=payload,\n            MessageAttributes={\n                \"_MessageSent\": {\n                    \"DataType\": \"String\",\n                    \"StringValue\": ts\n                }\n            }\n        )\n        id = response[\"MessageId\"]\n        httpStatus = response[\"ResponseMetadata\"][\"HTTPStatusCode\"]\n        logger.info(f\"Message {id} sent with status: {httpStatus}...\")\n    \n    \n    def handler(event, context):\n        # Fish out bucket and object name from event payload\n        bucket = event[\"Records\"][0][\"s3\"][\"bucket\"][\"name\"]\n        obj = event[\"Records\"][0][\"s3\"][\"object\"][\"key\"]\n        logger.info(f\"Get {obj} from {bucket}...\")\n        dest = os.path.abspath(os.path.join(cwd, tmpfiles, obj))\n    \n        # Log event received\n        logger.info(\"Received event...\")\n        logger.info(event)\n    \n        # Download file\n        s3_download_file(bucket, obj, dest)\n    \n        # Eventify data\n        df = pd.read_csv(dest)\n        rows = len(df.index)\n    \n        for i in range(0, rows):\n            tmp_df = df\n            row = tmp_df.iloc[[i], :]\n    \n            # Convert to JSON\n            payload = row.to_json(orient=\"records\")\n            send_to_sqs(payload)\n    \n    \n    ### START OF CODE ###\n    cwd = os.getcwd()\n    parent = os.path.join(cwd, os.pardir)\n    grandparent = os.path.join(parent, os.pardir)\n    tmpfiles = os.path.join(grandparent, \"tmp\")\n    \n    session = boto3.Session(region_name=\"eu-central-1\")", "author_fullname": "t2_onmeo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do unit tests make sense here?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zsl60x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671712712.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I am fairly new to the concept of testing my code. I just did some learning on how to use Pytest, but problem was that all the examples in the learning material was relatively simplistic and self-contained. When I try to apply it to my own code, I find myself wondering if the test &lt;strong&gt;even make sense.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I want to test the following piece of code that utilized AWS services (simplifed for ease of reading - full code can be seen at bottem):&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;def download_file-bucket(bucket, obj, key):\nconnect_to_s3\n    download_csvfile_to_tmp_directory\n\ndef parse_data_and_send:\n    parse_rows_form_csv\n    for row in csv:\n        payload = row.payload\n        send_to_sqs_queue(payload)\n\ndef send_to_sqs_queue(payload):\n    connect_to_sqs\n    sqs.sendMessage(payload, connection)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;That is the gist of it.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The entire project is set up in Terraform using CodeBuild as the CI/CD tool, and I would like to run these unit test every time the code is deploying.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;My problem is this:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Does it make sense to make unit tests here? I can test each function sure, but all of the functions rely on some AWS ressource that &lt;strong&gt;may or may not exist&lt;/strong&gt;, depending on where in the development cycle I am in.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Even if it does exist, testing it on the real ressources would create a set of new problems, as f.eks. adding a file to the s3 bucket triggers code which will genererate new files etc.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Two possible ways out I have considered:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Add a &amp;quot;tests&amp;quot; module in the Terraform deployment which is identical to the original ressources, but the ressources will only exist for the duration of the tests, and which will the tear-down when tests are concluded. However, this seems excessive&lt;/li&gt;\n&lt;li&gt;Mock the outside dependencies like S3 bucket or sqs-queue. However, I feel this invalidates tests, as pretty much all the tests do are test if these outside dependencies work.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;How would you guys handle this situation?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Real code:&lt;/em&gt;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import os\nimport boto3\nimport logging\nimport pandas as pd\nfrom distutils.log import error\nimport datetime\n\n# Set up logging\nlogging.basicConfig()\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.DEBUG)\n\n\ndef s3_download_file(bucket, obj, dest):\n    s3 = session.client(&amp;quot;s3&amp;quot;)\n\n    try:\n        s3.download_file(\n            Bucket=bucket,\n            Key=obj,\n            Filename=dest\n        )\n    except:\n        logger.info(f&amp;quot;Error downloading {obj} to {dest}...&amp;quot;)\n        logger.info(error)\n    else:\n        logger.info(f&amp;quot;Successfully downloaded {obj} to {dest}...&amp;quot;)\n\n\ndef send_to_sqs(payload):\n    sqs = session.client(&amp;quot;sqs&amp;quot;)\n    ts = datetime.datetime.utcnow().isoformat()\n    Queue_Url = os.environ[&amp;quot;queue_url&amp;quot;]\n    response = sqs.send_message(\n        QueueUrl=Queue_Url,\n        MessageBody=payload,\n        MessageAttributes={\n            &amp;quot;_MessageSent&amp;quot;: {\n                &amp;quot;DataType&amp;quot;: &amp;quot;String&amp;quot;,\n                &amp;quot;StringValue&amp;quot;: ts\n            }\n        }\n    )\n    id = response[&amp;quot;MessageId&amp;quot;]\n    httpStatus = response[&amp;quot;ResponseMetadata&amp;quot;][&amp;quot;HTTPStatusCode&amp;quot;]\n    logger.info(f&amp;quot;Message {id} sent with status: {httpStatus}...&amp;quot;)\n\n\ndef handler(event, context):\n    # Fish out bucket and object name from event payload\n    bucket = event[&amp;quot;Records&amp;quot;][0][&amp;quot;s3&amp;quot;][&amp;quot;bucket&amp;quot;][&amp;quot;name&amp;quot;]\n    obj = event[&amp;quot;Records&amp;quot;][0][&amp;quot;s3&amp;quot;][&amp;quot;object&amp;quot;][&amp;quot;key&amp;quot;]\n    logger.info(f&amp;quot;Get {obj} from {bucket}...&amp;quot;)\n    dest = os.path.abspath(os.path.join(cwd, tmpfiles, obj))\n\n    # Log event received\n    logger.info(&amp;quot;Received event...&amp;quot;)\n    logger.info(event)\n\n    # Download file\n    s3_download_file(bucket, obj, dest)\n\n    # Eventify data\n    df = pd.read_csv(dest)\n    rows = len(df.index)\n\n    for i in range(0, rows):\n        tmp_df = df\n        row = tmp_df.iloc[[i], :]\n\n        # Convert to JSON\n        payload = row.to_json(orient=&amp;quot;records&amp;quot;)\n        send_to_sqs(payload)\n\n\n### START OF CODE ###\ncwd = os.getcwd()\nparent = os.path.join(cwd, os.pardir)\ngrandparent = os.path.join(parent, os.pardir)\ntmpfiles = os.path.join(grandparent, &amp;quot;tmp&amp;quot;)\n\nsession = boto3.Session(region_name=&amp;quot;eu-central-1&amp;quot;)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zsl60x", "is_robot_indexable": true, "report_reasons": null, "author": "Hinkakan", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zsl60x/do_unit_tests_make_sense_here/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zsl60x/do_unit_tests_make_sense_here/", "subreddit_subscribers": 83807, "created_utc": 1671712712.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, I currently deal with 50+ TB data processing and I consider using Databricks DLT as solution to my problem with performance. Currently I deal with pretty complicated silver layer logic (joining 30+ tables, KPI calculations) and refreshing rate is 24h now but we want to go to even 5 minutes rate. \n\nI would appreciate the feedback of users that dealt with it and of course - please point the red flags, painpoints and if possible - more reliable/cheaper solutions than DLT.", "author_fullname": "t2_7mnlik68", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks DLT - limitations, pricing and alternatives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zskpj6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671711148.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I currently deal with 50+ TB data processing and I consider using Databricks DLT as solution to my problem with performance. Currently I deal with pretty complicated silver layer logic (joining 30+ tables, KPI calculations) and refreshing rate is 24h now but we want to go to even 5 minutes rate. &lt;/p&gt;\n\n&lt;p&gt;I would appreciate the feedback of users that dealt with it and of course - please point the red flags, painpoints and if possible - more reliable/cheaper solutions than DLT.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zskpj6", "is_robot_indexable": true, "report_reasons": null, "author": "Astherol", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zskpj6/databricks_dlt_limitations_pricing_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zskpj6/databricks_dlt_limitations_pricing_and/", "subreddit_subscribers": 83807, "created_utc": 1671711148.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have to use DBR 7.3 as I need ubuntu 18.04 for my specific work. but the problem is that I am not able to see my github code in the cluster with 7.3 DBR.\n\nI did some research and i found that the support of having github code in /Workspace/Repos is only provided in 11+ DBR.\n\nI am new to databricks, and i want to ask the experienced data engineers here who would have worked with the previous version of DBR, how to enable /mount the /Workspace directory ?", "author_fullname": "t2_869m5ow7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[DataBricks] How to mount /Workspace/Repos folder in DBR below 11.3 ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zsge27", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671696081.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have to use DBR 7.3 as I need ubuntu 18.04 for my specific work. but the problem is that I am not able to see my github code in the cluster with 7.3 DBR.&lt;/p&gt;\n\n&lt;p&gt;I did some research and i found that the support of having github code in /Workspace/Repos is only provided in 11+ DBR.&lt;/p&gt;\n\n&lt;p&gt;I am new to databricks, and i want to ask the experienced data engineers here who would have worked with the previous version of DBR, how to enable /mount the /Workspace directory ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zsge27", "is_robot_indexable": true, "report_reasons": null, "author": "Jaded_Click9591", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zsge27/databricks_how_to_mount_workspacerepos_folder_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zsge27/databricks_how_to_mount_workspacerepos_folder_in/", "subreddit_subscribers": 83807, "created_utc": 1671696081.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,  \nI am looking for some projects (ideally repos) with well-written API Extractor/connector classes in Python.  Whenever I write one, it works but I feel like my code is not the cleanest: for instance, I am not sure what should be defined as an attribute of this extractor class etc. I would imagine a generic Class used as a template for each connector. \n\nI've searched on this sub and there are similar questions already, such as :\n\n[https://www.reddit.com/r/dataengineering/comments/yyh6l9/what\\_are\\_your\\_favourite\\_github\\_repos\\_that\\_shows/](https://www.reddit.com/r/dataengineering/comments/yyh6l9/what_are_your_favourite_github_repos_that_shows/)\n\n\\- I've checked the Gitlab repo which was mentioned in the link above, but the connectors seem all written  independently\n\n\\- Airbyte repo looks good, albeit quite advanced. \n\nIf you have any other repositories showcasing great API connector classes, please share them !\n\nThanks.", "author_fullname": "t2_rau8gqvj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any project with well-written API Extractor/connector classes in Python?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zs2rl0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671660583.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;br/&gt;\nI am looking for some projects (ideally repos) with well-written API Extractor/connector classes in Python.  Whenever I write one, it works but I feel like my code is not the cleanest: for instance, I am not sure what should be defined as an attribute of this extractor class etc. I would imagine a generic Class used as a template for each connector. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve searched on this sub and there are similar questions already, such as :&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/dataengineering/comments/yyh6l9/what_are_your_favourite_github_repos_that_shows/\"&gt;https://www.reddit.com/r/dataengineering/comments/yyh6l9/what_are_your_favourite_github_repos_that_shows/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;- I&amp;#39;ve checked the Gitlab repo which was mentioned in the link above, but the connectors seem all written  independently&lt;/p&gt;\n\n&lt;p&gt;- Airbyte repo looks good, albeit quite advanced. &lt;/p&gt;\n\n&lt;p&gt;If you have any other repositories showcasing great API connector classes, please share them !&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zs2rl0", "is_robot_indexable": true, "report_reasons": null, "author": "Life_Translator_6101", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zs2rl0/any_project_with_wellwritten_api/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zs2rl0/any_project_with_wellwritten_api/", "subreddit_subscribers": 83807, "created_utc": 1671660583.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all!\n\nWe're kind of building a product for end to end data ingestion and ETL through our own custom built UI. So for transformations, we thought of using DBT Core as it satisfies all our requirements which are broadly: \n\n\\-able to handle high volume of data \n\n\\-cyber free \n\n\\-backup recovery \n\n\\-cloud agnostic \n\n\\-open source \n\n\\-compatible with airbyte \n\n\\-Can be white labeled \n\n So, any suggestions on any other better transformation tool that can be used here instead of DBT as DBT Core doesn't support any REST API calls that we'll need to integrate it with our UI.", "author_fullname": "t2_54tmiaey", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need Suggestion for transformation tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zrze6j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671653423.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all!&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re kind of building a product for end to end data ingestion and ETL through our own custom built UI. So for transformations, we thought of using DBT Core as it satisfies all our requirements which are broadly: &lt;/p&gt;\n\n&lt;p&gt;-able to handle high volume of data &lt;/p&gt;\n\n&lt;p&gt;-cyber free &lt;/p&gt;\n\n&lt;p&gt;-backup recovery &lt;/p&gt;\n\n&lt;p&gt;-cloud agnostic &lt;/p&gt;\n\n&lt;p&gt;-open source &lt;/p&gt;\n\n&lt;p&gt;-compatible with airbyte &lt;/p&gt;\n\n&lt;p&gt;-Can be white labeled &lt;/p&gt;\n\n&lt;p&gt;So, any suggestions on any other better transformation tool that can be used here instead of DBT as DBT Core doesn&amp;#39;t support any REST API calls that we&amp;#39;ll need to integrate it with our UI.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zrze6j", "is_robot_indexable": true, "report_reasons": null, "author": "flightofeagle", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zrze6j/need_suggestion_for_transformation_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zrze6j/need_suggestion_for_transformation_tool/", "subreddit_subscribers": 83807, "created_utc": 1671653423.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am new to this area and it is quite confusing to understand the differences between these vendors:\n\nInformatica\n\nCloudera\n\nOracle\n\nSnowflake\n\nVertica\n\nAlteryx\n\nDataiku\n\nMy understandign that Informatica and Cloudera is about data integration, Oracle is about data management, Snowflake and Vertica are more analytical??, alteryx is no-code data integration + analytics and Dataiku is more about collaboration and orchestration of data science workflows. \n\nNow, firstly, I am not confident that my understanding is correct and if you could even call all of them data management systems. Secondly, it seems like there is at least a lot of overlap between them? Would you just pick one or use some sort of combination?", "author_fullname": "t2_5fbb0xj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help me understand the difference between database management systems", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zse9fz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671689435.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am new to this area and it is quite confusing to understand the differences between these vendors:&lt;/p&gt;\n\n&lt;p&gt;Informatica&lt;/p&gt;\n\n&lt;p&gt;Cloudera&lt;/p&gt;\n\n&lt;p&gt;Oracle&lt;/p&gt;\n\n&lt;p&gt;Snowflake&lt;/p&gt;\n\n&lt;p&gt;Vertica&lt;/p&gt;\n\n&lt;p&gt;Alteryx&lt;/p&gt;\n\n&lt;p&gt;Dataiku&lt;/p&gt;\n\n&lt;p&gt;My understandign that Informatica and Cloudera is about data integration, Oracle is about data management, Snowflake and Vertica are more analytical??, alteryx is no-code data integration + analytics and Dataiku is more about collaboration and orchestration of data science workflows. &lt;/p&gt;\n\n&lt;p&gt;Now, firstly, I am not confident that my understanding is correct and if you could even call all of them data management systems. Secondly, it seems like there is at least a lot of overlap between them? Would you just pick one or use some sort of combination?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zse9fz", "is_robot_indexable": true, "report_reasons": null, "author": "kultuhtu", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zse9fz/help_me_understand_the_difference_between/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zse9fz/help_me_understand_the_difference_between/", "subreddit_subscribers": 83807, "created_utc": 1671689435.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are using EMRStudio and it appears to be so flaky that it's pretty much unusable.  \n\n\n- The notebook server will just die sometimes and throw you into the EMR Notebook list.\n- When you launch a workspace, it takes several minutes... and when it's finally ready it spams a new tab that steals focus while you're trying to do something else.\n- Attaching/detaching to a EMR cluster makes the whole UI reload. Sorry, you didn't want that code you were just writing!\n- Sometimes you need to attach to a cluster more than once to successfully be able to start a kernel.\n- Collaboration mode lets you share a notebook/workspace with another user. But it's limited to 5 collaborators per workspace and there are no access controls. Basically collaborate means they have access to everything and you can't just share a single notebook as you'd typically like to do when sharing some tables or charts with a colleague.\n\nI get this \"helpful\" error the first time I attach to an EMR cluster too:\n```\nThe code failed because of a fatal error:\n\tSession 0 did not start up in 60 seconds..\n\nSome things to try:\na) Make sure Spark has enough available resources for Jupyter to create a Spark context.\nb) Contact your Jupyter administrator to make sure the Spark magics library is configured correctly.\nc) Restart the kernel.\n```\n\nHas anyone used it successfully without having an aneurysm?", "author_fullname": "t2_unlas68x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is EMRStudio the worst AWS product they've released?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zs9tls", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671676982.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are using EMRStudio and it appears to be so flaky that it&amp;#39;s pretty much unusable.  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The notebook server will just die sometimes and throw you into the EMR Notebook list.&lt;/li&gt;\n&lt;li&gt;When you launch a workspace, it takes several minutes... and when it&amp;#39;s finally ready it spams a new tab that steals focus while you&amp;#39;re trying to do something else.&lt;/li&gt;\n&lt;li&gt;Attaching/detaching to a EMR cluster makes the whole UI reload. Sorry, you didn&amp;#39;t want that code you were just writing!&lt;/li&gt;\n&lt;li&gt;Sometimes you need to attach to a cluster more than once to successfully be able to start a kernel.&lt;/li&gt;\n&lt;li&gt;Collaboration mode lets you share a notebook/workspace with another user. But it&amp;#39;s limited to 5 collaborators per workspace and there are no access controls. Basically collaborate means they have access to everything and you can&amp;#39;t just share a single notebook as you&amp;#39;d typically like to do when sharing some tables or charts with a colleague.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I get this &amp;quot;helpful&amp;quot; error the first time I attach to an EMR cluster too:\n```\nThe code failed because of a fatal error:\n    Session 0 did not start up in 60 seconds..&lt;/p&gt;\n\n&lt;p&gt;Some things to try:\na) Make sure Spark has enough available resources for Jupyter to create a Spark context.\nb) Contact your Jupyter administrator to make sure the Spark magics library is configured correctly.\nc) Restart the kernel.\n```&lt;/p&gt;\n\n&lt;p&gt;Has anyone used it successfully without having an aneurysm?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zs9tls", "is_robot_indexable": true, "report_reasons": null, "author": "elephant_gate_332", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zs9tls/is_emrstudio_the_worst_aws_product_theyve_released/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zs9tls/is_emrstudio_the_worst_aws_product_theyve_released/", "subreddit_subscribers": 83807, "created_utc": 1671676982.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "DDIA is the data system design bible but I'm curious who has read it. Is it for junior DE folks starting up, or data architects who are usually involved in big data system design, and so on.  \n\n\nIf you have read it, what do you work as? When did you read it?\n\n[View Poll](https://www.reddit.com/poll/zss3om)", "author_fullname": "t2_msviuy1p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Have you read DDIA (Designing Data Intensive Applications) by Kleppmann?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zss3om", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671731157.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;DDIA is the data system design bible but I&amp;#39;m curious who has read it. Is it for junior DE folks starting up, or data architects who are usually involved in big data system design, and so on.  &lt;/p&gt;\n\n&lt;p&gt;If you have read it, what do you work as? When did you read it?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/zss3om\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zss3om", "is_robot_indexable": true, "report_reasons": null, "author": "vino_and_data", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1671990357117, "options": [{"text": "I'm a Junior DE, and have read it", "id": "20554181"}, {"text": "I'm a Mid/Senior DE and have read it", "id": "20554182"}, {"text": "I'm at Data Architect level or above, and have read it", "id": "20554183"}, {"text": "I work as DE (Junior/Mid/Senior) but never read it or planning to read", "id": "20554184"}, {"text": "Just here to see the results", "id": "20554185"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 42, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zss3om/have_you_read_ddia_designing_data_intensive/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/zss3om/have_you_read_ddia_designing_data_intensive/", "subreddit_subscribers": 83807, "created_utc": 1671731157.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anyone here has any experience/heard about these 2 certification programs?  I'm an IT BA with SQL/Python experience who is looking to make a transition to BI or data analytics field as a stepping stone to become a data engineer (a stepping stone because I don't think I have sufficient technical knowledge to become DE now).  I heard some good things about UW's BUSINESS INTELLIGENCE &amp; DATABASE DEVELOPMENT certification program, but I wonder if UCI's Database Management or Data Science certification is any good?\n\n[https://www.pce.uw.edu/certificates/business-intelligence-and-database-development](https://www.pce.uw.edu/certificates/business-intelligence-and-database-development)\n\n[https://ce.uci.edu/areas/it/database\\_mgmt/](https://ce.uci.edu/areas/it/database_mgmt/)\n\n[https://ce.uci.edu/areas/it/data\\_science/](https://ce.uci.edu/areas/it/data_science/)", "author_fullname": "t2_jq4nx76n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "UW's and UCI's certification program", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zsgnw3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1671696962.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone here has any experience/heard about these 2 certification programs?  I&amp;#39;m an IT BA with SQL/Python experience who is looking to make a transition to BI or data analytics field as a stepping stone to become a data engineer (a stepping stone because I don&amp;#39;t think I have sufficient technical knowledge to become DE now).  I heard some good things about UW&amp;#39;s BUSINESS INTELLIGENCE &amp;amp; DATABASE DEVELOPMENT certification program, but I wonder if UCI&amp;#39;s Database Management or Data Science certification is any good?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.pce.uw.edu/certificates/business-intelligence-and-database-development\"&gt;https://www.pce.uw.edu/certificates/business-intelligence-and-database-development&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://ce.uci.edu/areas/it/database_mgmt/\"&gt;https://ce.uci.edu/areas/it/database_mgmt/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://ce.uci.edu/areas/it/data_science/\"&gt;https://ce.uci.edu/areas/it/data_science/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xWBF4FgezyUcnUHN1egT8_PughjPVucKnd134vvSsPg.jpg?auto=webp&amp;s=f1d2d07e4dabde76a3725b349267696f621dda39", "width": 2000, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/xWBF4FgezyUcnUHN1egT8_PughjPVucKnd134vvSsPg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ecaea0c0ebbb4b00b2fc979d6b288d3a1fb6c17d", "width": 108, "height": 32}, {"url": "https://external-preview.redd.it/xWBF4FgezyUcnUHN1egT8_PughjPVucKnd134vvSsPg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e26df7396c45d84bc46d3d6d67a2dd305ef6bbbd", "width": 216, "height": 64}, {"url": "https://external-preview.redd.it/xWBF4FgezyUcnUHN1egT8_PughjPVucKnd134vvSsPg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=647d5a090fb506d9beba8c8e560526187ff6ed05", "width": 320, "height": 96}, {"url": "https://external-preview.redd.it/xWBF4FgezyUcnUHN1egT8_PughjPVucKnd134vvSsPg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e04608d6e5b2d76cc884569044c9c5ab29f914a0", "width": 640, "height": 192}, {"url": "https://external-preview.redd.it/xWBF4FgezyUcnUHN1egT8_PughjPVucKnd134vvSsPg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=86849049f74239a5153ec1a24413da77389548ff", "width": 960, "height": 288}, {"url": "https://external-preview.redd.it/xWBF4FgezyUcnUHN1egT8_PughjPVucKnd134vvSsPg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7a5899feb42b3bf93c766d8391e1fa8751e2dfb2", "width": 1080, "height": 324}], "variants": {}, "id": "KyQT6qC1geg5x74wBAu1AitKvbeimK94y50w5XQLs-I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zsgnw3", "is_robot_indexable": true, "report_reasons": null, "author": "tulipz123", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zsgnw3/uws_and_ucis_certification_program/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zsgnw3/uws_and_ucis_certification_program/", "subreddit_subscribers": 83807, "created_utc": 1671696962.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Background: wanting to break into DE after my first experience as a Data Analyst and most recently as a Generalist on a Drupal CMS project- aside from non-development, I work on Drupal configuration (no code) and pushing to GitHub, etc...\n\nI am fairly comfortable in Python, and am working on a YouTube Comment NLP pipeline and learning as I go...\n\nWhat gets me very anxious, is that I have a hard time with the \"LeetCode\"/algorithmic exercises...\n\nI grasp on to things that have a \"real-world\" application much better...\n\nThere seems to be a split as to whether these questions (leetcode/algo) are even appropriate for a DE interview- so my question is, regardless of whether I will get asked these questions in interviews, should I take my having a hard time with these as a sign that I'm not going down the right path?\n\nThanks all...", "author_fullname": "t2_8chdw7c4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Theoretical vs Practical", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zs46jd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671663147.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Background: wanting to break into DE after my first experience as a Data Analyst and most recently as a Generalist on a Drupal CMS project- aside from non-development, I work on Drupal configuration (no code) and pushing to GitHub, etc...&lt;/p&gt;\n\n&lt;p&gt;I am fairly comfortable in Python, and am working on a YouTube Comment NLP pipeline and learning as I go...&lt;/p&gt;\n\n&lt;p&gt;What gets me very anxious, is that I have a hard time with the &amp;quot;LeetCode&amp;quot;/algorithmic exercises...&lt;/p&gt;\n\n&lt;p&gt;I grasp on to things that have a &amp;quot;real-world&amp;quot; application much better...&lt;/p&gt;\n\n&lt;p&gt;There seems to be a split as to whether these questions (leetcode/algo) are even appropriate for a DE interview- so my question is, regardless of whether I will get asked these questions in interviews, should I take my having a hard time with these as a sign that I&amp;#39;m not going down the right path?&lt;/p&gt;\n\n&lt;p&gt;Thanks all...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zs46jd", "is_robot_indexable": true, "report_reasons": null, "author": "pdxtechnologist", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zs46jd/theoretical_vs_practical/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zs46jd/theoretical_vs_practical/", "subreddit_subscribers": 83807, "created_utc": 1671663147.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_40ihn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Converting an ETL script to Software-Defined Assets | Dagster Blog", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": true, "name": "t3_zst80d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/m8bYDsj1QdDDnhGehNiGjZz1dQdNsKI3nMo67UAzEUA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671733889.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dagster.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://dagster.io/blog/dagster-script-to-assets", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/d7Eoe-cRzlBsFJCyYhS_a0-F59YHACCH-1Ked-Uu3BQ.jpg?auto=webp&amp;s=207093ea4eb9417f27beb114c48e955066dc789c", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/d7Eoe-cRzlBsFJCyYhS_a0-F59YHACCH-1Ked-Uu3BQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0db6b12e6264fdabd21e34820c30dd6710267a71", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/d7Eoe-cRzlBsFJCyYhS_a0-F59YHACCH-1Ked-Uu3BQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b98cc03e897ff0181df58fed35cfff1f18b69c6c", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/d7Eoe-cRzlBsFJCyYhS_a0-F59YHACCH-1Ked-Uu3BQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=21f538f322f9f7f9ed14dc67ef777c296f895067", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/d7Eoe-cRzlBsFJCyYhS_a0-F59YHACCH-1Ked-Uu3BQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1bfd8c0deb5c4396eac51ca159c89236f22c946f", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/d7Eoe-cRzlBsFJCyYhS_a0-F59YHACCH-1Ked-Uu3BQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=72f2ed5dd59466653f614dacb64422eb54046170", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/d7Eoe-cRzlBsFJCyYhS_a0-F59YHACCH-1Ked-Uu3BQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5890eaf71abfe62f468ce82cd7fbdccc574c98f2", "width": 1080, "height": 567}], "variants": {}, "id": "Gc8vBf05T5Q2q1pr-v0LEtTsCcHKQIIrzdn6YpAEhQg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zst80d", "is_robot_indexable": true, "report_reasons": null, "author": "floydophone", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zst80d/converting_an_etl_script_to_softwaredefined/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dagster.io/blog/dagster-script-to-assets", "subreddit_subscribers": 83807, "created_utc": 1671733889.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a Data Science background but have found myself being the default Data Engineer as well for our company. We have a lot of requests for historic information. \n\nex) \nHow many sellers did we have on this day in the past?\nWho was the manager on this account on this day in the past?\n\nI have always tried to re-build the transformed data from source each run. However, I am hitting limitations with some of the historical numbers like this. Particularly prepping the data for easy ingestion into BI tools. \n\nIt seems like we have either have some more complicated code in the ETL or BI layer to figure out historical figures. Or store every entity's status for every day in the past. \n\nWhat have you found to be best? I get worried about appending new rows each day to a historical table in case we have to change a definition or find a bug and can't rerun the whole table historically. \n\nAny guidance or experiences here?", "author_fullname": "t2_62ipd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you best handle historic metrics? Re-create history each run or append new version each day?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zsscjr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671731755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a Data Science background but have found myself being the default Data Engineer as well for our company. We have a lot of requests for historic information. &lt;/p&gt;\n\n&lt;p&gt;ex) \nHow many sellers did we have on this day in the past?\nWho was the manager on this account on this day in the past?&lt;/p&gt;\n\n&lt;p&gt;I have always tried to re-build the transformed data from source each run. However, I am hitting limitations with some of the historical numbers like this. Particularly prepping the data for easy ingestion into BI tools. &lt;/p&gt;\n\n&lt;p&gt;It seems like we have either have some more complicated code in the ETL or BI layer to figure out historical figures. Or store every entity&amp;#39;s status for every day in the past. &lt;/p&gt;\n\n&lt;p&gt;What have you found to be best? I get worried about appending new rows each day to a historical table in case we have to change a definition or find a bug and can&amp;#39;t rerun the whole table historically. &lt;/p&gt;\n\n&lt;p&gt;Any guidance or experiences here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zsscjr", "is_robot_indexable": true, "report_reasons": null, "author": "Deerz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zsscjr/how_do_you_best_handle_historic_metrics_recreate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zsscjr/how_do_you_best_handle_historic_metrics_recreate/", "subreddit_subscribers": 83807, "created_utc": 1671731755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have some questions about databases and distributed systems as presented in Martin Kleppmann's Designing Data-Intensive Applications. My questions relate to storage engines, indices, replication, consistency, and consensus. I will try to frame them so that people who haven't read the book can still attempt to answer.\n\nFor some context, in Chapter 3 (Storage and Retrieval), Kleppmann talks about the \"Data Structures That Power Your Database.\" These include hash indexes; SSTables and LSM-Trees; and B-Trees. In Chapter 9 (Consistency and Consensus), Kleppmann talks about consistency models like linearizability, consensus, and more.\n\n&amp;#x200B;\n\n(1) Are SSTables the only way to store the actual database records/rows? Kleppmann's writing suggests it is. I think Postgres stores row/record data in what is called a heap file. The heap file does not have any sort of order, so it obviously isn't comparable to SSTables.\n\nI am just wondering why Kleppmann makes it seem as though SSTables are the only way rows/records are being stored.\n\n&amp;#x200B;\n\n(2) Just to confirm, do LSM-Trees and B-Trees store the index data or the row/record data? I believe they store the index data because Kleppmann uses terms like \"log-structured *index*\" (and not log-structured data storage). And, the SSTable stores the database records/rows, right?\n\nAny additional clarification between where/how the index data is stored versus the actual database's rows/records would be nice.\n\n&amp;#x200B;\n\n(3) In Chapter 9, Kleppmann says that multi-leader and leaderless replication schemes (in databases) are not linearizable and probably not linearizable, respectively. However, the example he gives to motivate linearizability seems to require a multi-leader or leaderless scheme.\n\nSpecifically, he talks about how to ensure linearizability when two people are trying to create an account on some application with the same username at the same time. We want to ensure that this process is linearizable so that we don't end up creating two accounts with the same username.\n\nBut, this necessitates that writes are happening on two nodes! So, why is Kleppmann giving an example that requires a multi-leader or leaderless scheme when he's told us previously that they're (probably) not linearizable?\n\n&amp;#x200B;\n\n(4a) What are the different ways that one can achieve linearizability? Here is what I think, after reading Chapter 9:\n\nFirst, with a single-leader, asynchronous replication scheme, you must send all reads and writes to the leader to ensure linearizability. This means the followers are basically only there for fault tolerance/availability (i.e. to replace the leader in case it goes down). This is a big drawback because we initially talked about how most applications are read-heavy, so the ability to read from any follower in a single leader *was* valuable. But, you can't do this if you want linearizability.\n\nSecond, with a leaderless replication scheme, you can achieve linearizability using total order broadcast. Specifically, you can send a request to any node and that node will do a total-order broadcast to every other node declaring what it wants to do in a global log. You can read or write from any node.\n\nThird, with a leaderless replication scheme, I think you can also use atomic commits where a single node reaches out to a coordinator; the coordinator uses a 2-Phase-Commit to ensure all nodes execute that node's request. This is similar to the previous method in that you have to contact every other node. You can read or write from any node. Kleppmann doesn't say you can use this to achieve linearizability, but I think this works?\n\nFourth, you can use a consensus algorithm like Raft or Paxos and a majority quorum to agree on the next request. You can read or write from any node.\n\nFifth, you can use a consensus algorithm like Raft or Paxos and, instead of using a majority quorum, sequence your operations through a single, elected leader (i.e. every node sends its read or writes through a chosen leader). I guess you can read or write from any node, but technically it all goes to a single leader.\n\n(4b) Relating to the first method above, Kleppmann says \"As discussed, single-leader replication determines a total order of operations by choosing one node as the leader and sequencing all operations on a single CPU core on the leader. The challenge then is **how to scale the system if the throughput is greater than a single leader can handle**, and also how to handle failover if the leader fails...\" I don't think he addresses the bolded part. How can a method that relies on a single leader scale?\n\nI have glossed over some important details, e.g. relating to fault tolerance, above. For instance, I don't think the second method is fault-tolerant since you need to ensure every node receives the message, so you're screwed if a single node goes down.\n\nThese questions are pretty specific, and they might not be the clearest, so please share any questions about my questions or the information I presented. Everything is useful to me.", "author_fullname": "t2_1nsaaq48", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Questions about Designing Data-Intensive Applications, databases, and distributed systems", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zsqsid", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1671728585.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671728054.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have some questions about databases and distributed systems as presented in Martin Kleppmann&amp;#39;s Designing Data-Intensive Applications. My questions relate to storage engines, indices, replication, consistency, and consensus. I will try to frame them so that people who haven&amp;#39;t read the book can still attempt to answer.&lt;/p&gt;\n\n&lt;p&gt;For some context, in Chapter 3 (Storage and Retrieval), Kleppmann talks about the &amp;quot;Data Structures That Power Your Database.&amp;quot; These include hash indexes; SSTables and LSM-Trees; and B-Trees. In Chapter 9 (Consistency and Consensus), Kleppmann talks about consistency models like linearizability, consensus, and more.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;(1) Are SSTables the only way to store the actual database records/rows? Kleppmann&amp;#39;s writing suggests it is. I think Postgres stores row/record data in what is called a heap file. The heap file does not have any sort of order, so it obviously isn&amp;#39;t comparable to SSTables.&lt;/p&gt;\n\n&lt;p&gt;I am just wondering why Kleppmann makes it seem as though SSTables are the only way rows/records are being stored.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;(2) Just to confirm, do LSM-Trees and B-Trees store the index data or the row/record data? I believe they store the index data because Kleppmann uses terms like &amp;quot;log-structured &lt;em&gt;index&lt;/em&gt;&amp;quot; (and not log-structured data storage). And, the SSTable stores the database records/rows, right?&lt;/p&gt;\n\n&lt;p&gt;Any additional clarification between where/how the index data is stored versus the actual database&amp;#39;s rows/records would be nice.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;(3) In Chapter 9, Kleppmann says that multi-leader and leaderless replication schemes (in databases) are not linearizable and probably not linearizable, respectively. However, the example he gives to motivate linearizability seems to require a multi-leader or leaderless scheme.&lt;/p&gt;\n\n&lt;p&gt;Specifically, he talks about how to ensure linearizability when two people are trying to create an account on some application with the same username at the same time. We want to ensure that this process is linearizable so that we don&amp;#39;t end up creating two accounts with the same username.&lt;/p&gt;\n\n&lt;p&gt;But, this necessitates that writes are happening on two nodes! So, why is Kleppmann giving an example that requires a multi-leader or leaderless scheme when he&amp;#39;s told us previously that they&amp;#39;re (probably) not linearizable?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;(4a) What are the different ways that one can achieve linearizability? Here is what I think, after reading Chapter 9:&lt;/p&gt;\n\n&lt;p&gt;First, with a single-leader, asynchronous replication scheme, you must send all reads and writes to the leader to ensure linearizability. This means the followers are basically only there for fault tolerance/availability (i.e. to replace the leader in case it goes down). This is a big drawback because we initially talked about how most applications are read-heavy, so the ability to read from any follower in a single leader &lt;em&gt;was&lt;/em&gt; valuable. But, you can&amp;#39;t do this if you want linearizability.&lt;/p&gt;\n\n&lt;p&gt;Second, with a leaderless replication scheme, you can achieve linearizability using total order broadcast. Specifically, you can send a request to any node and that node will do a total-order broadcast to every other node declaring what it wants to do in a global log. You can read or write from any node.&lt;/p&gt;\n\n&lt;p&gt;Third, with a leaderless replication scheme, I think you can also use atomic commits where a single node reaches out to a coordinator; the coordinator uses a 2-Phase-Commit to ensure all nodes execute that node&amp;#39;s request. This is similar to the previous method in that you have to contact every other node. You can read or write from any node. Kleppmann doesn&amp;#39;t say you can use this to achieve linearizability, but I think this works?&lt;/p&gt;\n\n&lt;p&gt;Fourth, you can use a consensus algorithm like Raft or Paxos and a majority quorum to agree on the next request. You can read or write from any node.&lt;/p&gt;\n\n&lt;p&gt;Fifth, you can use a consensus algorithm like Raft or Paxos and, instead of using a majority quorum, sequence your operations through a single, elected leader (i.e. every node sends its read or writes through a chosen leader). I guess you can read or write from any node, but technically it all goes to a single leader.&lt;/p&gt;\n\n&lt;p&gt;(4b) Relating to the first method above, Kleppmann says &amp;quot;As discussed, single-leader replication determines a total order of operations by choosing one node as the leader and sequencing all operations on a single CPU core on the leader. The challenge then is &lt;strong&gt;how to scale the system if the throughput is greater than a single leader can handle&lt;/strong&gt;, and also how to handle failover if the leader fails...&amp;quot; I don&amp;#39;t think he addresses the bolded part. How can a method that relies on a single leader scale?&lt;/p&gt;\n\n&lt;p&gt;I have glossed over some important details, e.g. relating to fault tolerance, above. For instance, I don&amp;#39;t think the second method is fault-tolerant since you need to ensure every node receives the message, so you&amp;#39;re screwed if a single node goes down.&lt;/p&gt;\n\n&lt;p&gt;These questions are pretty specific, and they might not be the clearest, so please share any questions about my questions or the information I presented. Everything is useful to me.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zsqsid", "is_robot_indexable": true, "report_reasons": null, "author": "FantasticGrape", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zsqsid/questions_about_designing_dataintensive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zsqsid/questions_about_designing_dataintensive/", "subreddit_subscribers": 83807, "created_utc": 1671728054.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "First of all, i want to thank all of you guys for the posts here in this sub, it really helped me land my first DE internship while in college, thanks to the great amount of resources and guidance given here. I start in january and in this meantime im reviewing some concepts of DE. Im good at python, not great, but can make my way through Googling and average in SQL, i know window functions and the basics.\n\nThe stack is python, sql and some aws tools. I already did some digging and  followed and end to end project on youtube to get a grasp at aws tools and what they are capable of, but im feeling a little overwhelmed by the amount of resources available. I did a little project using the twitter api, airflow and EC2 out of curiosity, nothing big or fancy, just the barebones to make it work and try to understand more about the tools. Im reading 'Data Pipelines Pocket Reference' again and started 'Fundamentals of Data Engineering'. Am i good to go on my internship or should i improve more my python and sql base?", "author_fullname": "t2_5r22gi6m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much should i expect to learn on the job as an intern?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zsqeg4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671727061.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First of all, i want to thank all of you guys for the posts here in this sub, it really helped me land my first DE internship while in college, thanks to the great amount of resources and guidance given here. I start in january and in this meantime im reviewing some concepts of DE. Im good at python, not great, but can make my way through Googling and average in SQL, i know window functions and the basics.&lt;/p&gt;\n\n&lt;p&gt;The stack is python, sql and some aws tools. I already did some digging and  followed and end to end project on youtube to get a grasp at aws tools and what they are capable of, but im feeling a little overwhelmed by the amount of resources available. I did a little project using the twitter api, airflow and EC2 out of curiosity, nothing big or fancy, just the barebones to make it work and try to understand more about the tools. Im reading &amp;#39;Data Pipelines Pocket Reference&amp;#39; again and started &amp;#39;Fundamentals of Data Engineering&amp;#39;. Am i good to go on my internship or should i improve more my python and sql base?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zsqeg4", "is_robot_indexable": true, "report_reasons": null, "author": "Upstairs-Ad-1466", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zsqeg4/how_much_should_i_expect_to_learn_on_the_job_as/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zsqeg4/how_much_should_i_expect_to_learn_on_the_job_as/", "subreddit_subscribers": 83807, "created_utc": 1671727061.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all, just wanted some outside opinions on Boolean flags in a dimensional model. If I have Boolean flags that represent the outcome of a business process, not the input attributes, would you put that in the dimension table or the fact table?\n\nI\u2019ve been leaning toward fact because it is a outcome, but I also know traditional dimensional modeling is metrics only in fact table.", "author_fullname": "t2_gge8z8qb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Modeling - Boolean Flags", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zsq4ro", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671726405.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all, just wanted some outside opinions on Boolean flags in a dimensional model. If I have Boolean flags that represent the outcome of a business process, not the input attributes, would you put that in the dimension table or the fact table?&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been leaning toward fact because it is a outcome, but I also know traditional dimensional modeling is metrics only in fact table.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zsq4ro", "is_robot_indexable": true, "report_reasons": null, "author": "No_Professional_9685", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zsq4ro/data_modeling_boolean_flags/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zsq4ro/data_modeling_boolean_flags/", "subreddit_subscribers": 83807, "created_utc": 1671726405.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone, I'm pretty new to data engineering so please forgive my ignorance. I'm using Snowflake, Hevo ETL, and AWS QuickSight for BI. \n\nI have 3 relational databases with identical schemas for storing application data in different regions:\n\n* prod\\_au\n* prod\\_nz\n* prod\\_us\n\nI'd like to consolidate these into a common database called 'prod\\_all' so that I can work with it more easily in BI. I don't want every table or column from the master databases and want to handle the transformation before sending it to the BI. Because the schemas are identical, I have multiple tables where the Id key is identical. So my thought was for the purpose of this table to union them and prefix the keys with the regional identifier like 'au27', 'nz66', 'us2', etc.\n\nSo my question is what is the best way to handle this? Should I create a database for this and what's the best way to continuously insert new or updated values from the master databases into this new table?\n\nThanks for your time!", "author_fullname": "t2_6pkcr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the best way to combine 3 different databases?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zs4dch", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671663592.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I&amp;#39;m pretty new to data engineering so please forgive my ignorance. I&amp;#39;m using Snowflake, Hevo ETL, and AWS QuickSight for BI. &lt;/p&gt;\n\n&lt;p&gt;I have 3 relational databases with identical schemas for storing application data in different regions:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;prod_au&lt;/li&gt;\n&lt;li&gt;prod_nz&lt;/li&gt;\n&lt;li&gt;prod_us&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;d like to consolidate these into a common database called &amp;#39;prod_all&amp;#39; so that I can work with it more easily in BI. I don&amp;#39;t want every table or column from the master databases and want to handle the transformation before sending it to the BI. Because the schemas are identical, I have multiple tables where the Id key is identical. So my thought was for the purpose of this table to union them and prefix the keys with the regional identifier like &amp;#39;au27&amp;#39;, &amp;#39;nz66&amp;#39;, &amp;#39;us2&amp;#39;, etc.&lt;/p&gt;\n\n&lt;p&gt;So my question is what is the best way to handle this? Should I create a database for this and what&amp;#39;s the best way to continuously insert new or updated values from the master databases into this new table?&lt;/p&gt;\n\n&lt;p&gt;Thanks for your time!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zs4dch", "is_robot_indexable": true, "report_reasons": null, "author": "PablanoPato", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zs4dch/whats_the_best_way_to_combine_3_different/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zs4dch/whats_the_best_way_to_combine_3_different/", "subreddit_subscribers": 83807, "created_utc": 1671663592.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "By UI changes I mean stuff like adding an export button to a web app to download data from a table. Is it normal for this to be part of a data engineer's job?", "author_fullname": "t2_s5w2bngt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any data engineers out there whose job scope involves making UI changes to company's product", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zsip3l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671704226.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;By UI changes I mean stuff like adding an export button to a web app to download data from a table. Is it normal for this to be part of a data engineer&amp;#39;s job?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zsip3l", "is_robot_indexable": true, "report_reasons": null, "author": "Global_Service_1094", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zsip3l/any_data_engineers_out_there_whose_job_scope/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zsip3l/any_data_engineers_out_there_whose_job_scope/", "subreddit_subscribers": 83807, "created_utc": 1671704226.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is an article about Airflow and how to install it using docker\n\n https://link.medium.com/pkGfRa24Xvb", "author_fullname": "t2_7ssutue8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow article", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zsn4z0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.14, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1671718728.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is an article about Airflow and how to install it using docker&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://link.medium.com/pkGfRa24Xvb\"&gt;https://link.medium.com/pkGfRa24Xvb&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/obVLieh4RXVSzC8EASin0xFYNyY2ULLh6_eMAbCm4eQ.jpg?auto=webp&amp;s=8a9794e68000f6f1a66e411ec3869c598b227b25", "width": 1200, "height": 507}, "resolutions": [{"url": "https://external-preview.redd.it/obVLieh4RXVSzC8EASin0xFYNyY2ULLh6_eMAbCm4eQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=60dc9859cacd77f1a614679a444f3bbda4e7cd36", "width": 108, "height": 45}, {"url": "https://external-preview.redd.it/obVLieh4RXVSzC8EASin0xFYNyY2ULLh6_eMAbCm4eQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4a86f5fb899e036942c1ddd8bc220e5a1e3bb2a0", "width": 216, "height": 91}, {"url": "https://external-preview.redd.it/obVLieh4RXVSzC8EASin0xFYNyY2ULLh6_eMAbCm4eQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c9883612a17227227641d124b8a8bb601205cf10", "width": 320, "height": 135}, {"url": "https://external-preview.redd.it/obVLieh4RXVSzC8EASin0xFYNyY2ULLh6_eMAbCm4eQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6bf38b10263bcff9a685ade70a08ae4e4c8d50bc", "width": 640, "height": 270}, {"url": "https://external-preview.redd.it/obVLieh4RXVSzC8EASin0xFYNyY2ULLh6_eMAbCm4eQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8e6aa77728cc5f81dd63ef2b772235e1e130921d", "width": 960, "height": 405}, {"url": "https://external-preview.redd.it/obVLieh4RXVSzC8EASin0xFYNyY2ULLh6_eMAbCm4eQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=98e6d1c72e2180f3351ef66d8b14f2f312141b80", "width": 1080, "height": 456}], "variants": {}, "id": "7E7HfHVgsnKu8czZS6eOzvGqIfDqgWZI-axvAvWy5Cw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zsn4z0", "is_robot_indexable": true, "report_reasons": null, "author": "Ansam93", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zsn4z0/airflow_article/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zsn4z0/airflow_article/", "subreddit_subscribers": 83807, "created_utc": 1671718728.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}