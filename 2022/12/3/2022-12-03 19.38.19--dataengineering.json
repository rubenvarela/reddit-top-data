{"kind": "Listing", "data": {"after": null, "dist": 17, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello every one. I am searching for websites where I can be tested for complex sql questions. Thanks in advance.", "author_fullname": "t2_76h7jr47", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where to Practice Complex SQL questions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zb329e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 59, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 59, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670028055.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello every one. I am searching for websites where I can be tested for complex sql questions. Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zb329e", "is_robot_indexable": true, "report_reasons": null, "author": "s1va1209", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zb329e/where_to_practice_complex_sql_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zb329e/where_to_practice_complex_sql_questions/", "subreddit_subscribers": 81750, "created_utc": 1670028055.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Moved jobs from aws environment to Google cloud services. Previously used Athena\u2019s schema on read to manage incoming files from external and internal sources. Worked perfectly even if data sets changed using aws glue. Now everything has to be imported into the data warehouse. \n\n\nI get the schema on read has drawbacks but kinda curious why a no movement solution isn\u2019t more popular?", "author_fullname": "t2_6mh3d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why isn\u2019t prestodb (trino) more popular?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zbe333", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670066365.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Moved jobs from aws environment to Google cloud services. Previously used Athena\u2019s schema on read to manage incoming files from external and internal sources. Worked perfectly even if data sets changed using aws glue. Now everything has to be imported into the data warehouse. &lt;/p&gt;\n\n&lt;p&gt;I get the schema on read has drawbacks but kinda curious why a no movement solution isn\u2019t more popular?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zbe333", "is_robot_indexable": true, "report_reasons": null, "author": "jahaz", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zbe333/why_isnt_prestodb_trino_more_popular/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zbe333/why_isnt_prestodb_trino_more_popular/", "subreddit_subscribers": 81750, "created_utc": 1670066365.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m curious to know what are some possible career paths to maximize compensation after being a senior data engineer that is paid market wages(130-160k). \n\nIs it true that at most companies, data engineering compensations cap out at around 200-300k? This title would either be a data engineering manager or staff/lead/principal data engineer.\n\nSome high paying or larger tech companies might have career paths for data engineering that could get 500-800k?", "author_fullname": "t2_8x16rrzg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some career paths after senior data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zbka09", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670085271.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m curious to know what are some possible career paths to maximize compensation after being a senior data engineer that is paid market wages(130-160k). &lt;/p&gt;\n\n&lt;p&gt;Is it true that at most companies, data engineering compensations cap out at around 200-300k? This title would either be a data engineering manager or staff/lead/principal data engineer.&lt;/p&gt;\n\n&lt;p&gt;Some high paying or larger tech companies might have career paths for data engineering that could get 500-800k?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zbka09", "is_robot_indexable": true, "report_reasons": null, "author": "Justanotherguy2022", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/zbka09/what_are_some_career_paths_after_senior_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zbka09/what_are_some_career_paths_after_senior_data/", "subreddit_subscribers": 81750, "created_utc": 1670085271.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys, in my work i have to do a lot of ETL pipelines with python.  I would like to know if there is any design pattern that helps in this process of downloading from a site with webscrapping, transforming the data and loading it in postgresql", "author_fullname": "t2_hzda3lb4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Design patter for Python ETL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zb39un", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670028666.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys, in my work i have to do a lot of ETL pipelines with python.  I would like to know if there is any design pattern that helps in this process of downloading from a site with webscrapping, transforming the data and loading it in postgresql&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zb39un", "is_robot_indexable": true, "report_reasons": null, "author": "salsichamma", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zb39un/design_patter_for_python_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zb39un/design_patter_for_python_etl/", "subreddit_subscribers": 81750, "created_utc": 1670028666.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know this has been asked before but I am struggling to think of questions you would ask in a system design interview for data engineering. Just looking for answers from more senior devs.\n\nPerhaps I just don\u2019t have enough interview experience to know what companies actually ask so I might be naive in thinking they would all ask something along the lines of designing a system to move raw data to a data warehouse for analytics. \n\nFor one, the current trend is having a data lake elt model with a data warehouse as a serving layer. This model pretty much applies to all companies looking to have a scalable data analytics solution. For a system design interview, what can you really ask here? \n\nSecond, a lot of the dsitributed infra and \u201csystem design\u201d is abstracted into open source libraries like apache spark, presto, hadoop/hive, etc. In my mind, it\u2019s pretty much plug and play between choosing these technologies more than \u201csystem design\u201d\n\nAm I seeing things the wrong way here?", "author_fullname": "t2_7jt0qboi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "System Design for Data Eng?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zb7jle", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670041615.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know this has been asked before but I am struggling to think of questions you would ask in a system design interview for data engineering. Just looking for answers from more senior devs.&lt;/p&gt;\n\n&lt;p&gt;Perhaps I just don\u2019t have enough interview experience to know what companies actually ask so I might be naive in thinking they would all ask something along the lines of designing a system to move raw data to a data warehouse for analytics. &lt;/p&gt;\n\n&lt;p&gt;For one, the current trend is having a data lake elt model with a data warehouse as a serving layer. This model pretty much applies to all companies looking to have a scalable data analytics solution. For a system design interview, what can you really ask here? &lt;/p&gt;\n\n&lt;p&gt;Second, a lot of the dsitributed infra and \u201csystem design\u201d is abstracted into open source libraries like apache spark, presto, hadoop/hive, etc. In my mind, it\u2019s pretty much plug and play between choosing these technologies more than \u201csystem design\u201d&lt;/p&gt;\n\n&lt;p&gt;Am I seeing things the wrong way here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zb7jle", "is_robot_indexable": true, "report_reasons": null, "author": "omscsdatathrow", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zb7jle/system_design_for_data_eng/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zb7jle/system_design_for_data_eng/", "subreddit_subscribers": 81750, "created_utc": 1670041615.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Following u/blef__ 's article yesterday for the Advent of Data,\nI didn't dare to be as thought provocative,\nbut here's my take on bottom-up data warehouse design,\nto get faster traction within a company when setting up that new data role/team/effort:\nhttps://www.adventofdata.com/modern-data-modeling-start-with-the-end/", "author_fullname": "t2_hizqfv2o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Modern Data Modeling : Start from the End?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zbe3c4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1670066395.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Following &lt;a href=\"/u/blef__\"&gt;u/blef__&lt;/a&gt; &amp;#39;s article yesterday for the Advent of Data,\nI didn&amp;#39;t dare to be as thought provocative,\nbut here&amp;#39;s my take on bottom-up data warehouse design,\nto get faster traction within a company when setting up that new data role/team/effort:\n&lt;a href=\"https://www.adventofdata.com/modern-data-modeling-start-with-the-end/\"&gt;https://www.adventofdata.com/modern-data-modeling-start-with-the-end/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/vlLNbbSJKK5SwCz2A0MVSw1zfm1K565HlEx_7tQLXlI.jpg?auto=webp&amp;s=860321faafb28e1b8bcb4633e1c790180ade053f", "width": 2000, "height": 1334}, "resolutions": [{"url": "https://external-preview.redd.it/vlLNbbSJKK5SwCz2A0MVSw1zfm1K565HlEx_7tQLXlI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=57c07865c1604b5f6299231785aa61394d13059b", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/vlLNbbSJKK5SwCz2A0MVSw1zfm1K565HlEx_7tQLXlI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0765689bae2958e23cae1621023ad8e856501e94", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/vlLNbbSJKK5SwCz2A0MVSw1zfm1K565HlEx_7tQLXlI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=29f82004e42189218aeca1668db3043d07c6bb73", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/vlLNbbSJKK5SwCz2A0MVSw1zfm1K565HlEx_7tQLXlI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=06c80979f97a31865f7b7ec3f012ed1958a24059", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/vlLNbbSJKK5SwCz2A0MVSw1zfm1K565HlEx_7tQLXlI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9cef35778d9358b7b6b173fdd2f36beecd095d68", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/vlLNbbSJKK5SwCz2A0MVSw1zfm1K565HlEx_7tQLXlI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3bfcceeb52591ae94db648bcdda773c66f408921", "width": 1080, "height": 720}], "variants": {}, "id": "7mWS4-Jq_UAucV_ev0FX3ua9BBgUB7PxPMdVyetbtvY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zbe3c4", "is_robot_indexable": true, "report_reasons": null, "author": "briceluu", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zbe3c4/modern_data_modeling_start_from_the_end/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zbe3c4/modern_data_modeling_start_from_the_end/", "subreddit_subscribers": 81750, "created_utc": 1670066395.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_jvuhrmb0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "From data analyst to seeking a junior data engineering role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_zbgb2d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Yt9TQlmov1686iVEmm51Lru-K6SBEGKGchy49f7JmMw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670074092.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/imix321rpo3a1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/imix321rpo3a1.jpg?auto=webp&amp;s=e814dedd2a37eb94fdd2894ed46270e72ed83606", "width": 1700, "height": 2800}, "resolutions": [{"url": "https://preview.redd.it/imix321rpo3a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=eda7358e7704624061beb121f3a1b02f1e6ca2e4", "width": 108, "height": 177}, {"url": "https://preview.redd.it/imix321rpo3a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1f6e09d321349f082a12bafebd1f2ef82c64cafb", "width": 216, "height": 355}, {"url": "https://preview.redd.it/imix321rpo3a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5f8b33cf8812134ee28f405a82b658168cbc3fff", "width": 320, "height": 527}, {"url": "https://preview.redd.it/imix321rpo3a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=08f1d147c368d50d5f51597a278a368fcbf88d93", "width": 640, "height": 1054}, {"url": "https://preview.redd.it/imix321rpo3a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5c6352c24b5eedc97deea6eeaf00f40c206438a5", "width": 960, "height": 1581}, {"url": "https://preview.redd.it/imix321rpo3a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f1f081d62e7ecdaa97ec7abd709105a6f0ae1ac4", "width": 1080, "height": 1778}], "variants": {}, "id": "ZE0ScyEDVo3dOZ8hDUw2Au7pspp1c7XXbHN3EuWr3q4"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "zbgb2d", "is_robot_indexable": true, "report_reasons": null, "author": "Necessary-Factor8861", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zbgb2d/from_data_analyst_to_seeking_a_junior_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/imix321rpo3a1.jpg", "subreddit_subscribers": 81750, "created_utc": 1670074092.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our business model is to ingest data from many different sources (some open, some closed), clean these data using our fusion and resolution services, and allow a user to rapidly search through our data using the front end react app.\n\n&amp;#x200B;\n\nWe've spent a long time building this product, and it isn't finished. It's full of bugs and the entire thing was rushed. None of our ETLs that bring data from the data warehouse to the application database work correctly. Nor do any of our ML models for fusion and resolution work correctly. The data warehouse itself is a mess, with critical discrepancies in schema design between our dev, staging, and prod environments. The dev application database has been called \"completed f\\*\\*ked\" by many, and the front-end team does all of their feature development in staging now. We've got a lot of major issues that are being ignored because management has no background in software engineering and no technical understanding of how the system works. They just think we aren't delivering fast enough, and they keep making promises to clients. If you try to explain to them why everything is going to be a lot more difficult than they realize, it's like talking to a brick wall. The entire company worked 10+ hours per day through the entire thanksgiving break and we still missed our deadline.\n\n&amp;#x200B;\n\nOk, this has turned into a rant.\n\n&amp;#x200B;\n\nSo on top of all of that, they've decided that instead of selling access to our main product, we're going to build a custom dashboard for every client who's willing to pay for one. I feel like this massively amplifies the work needed to meet our customer requirements when we were already struggling in our core competencies. \n\nIt also seems like it's a fundamentally bad idea to ever do this, even if we weren't already struggling before. The point of a software product is to do a couple of things that your clients need, and do them better than everyone else, right? Not to have a clunky, messy app that tries to do something different for everyone using individualized code for each client, right?", "author_fullname": "t2_6gwxih9e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is a custom dashboard for every customer ever a good idea?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zbho1r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670078091.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our business model is to ingest data from many different sources (some open, some closed), clean these data using our fusion and resolution services, and allow a user to rapidly search through our data using the front end react app.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve spent a long time building this product, and it isn&amp;#39;t finished. It&amp;#39;s full of bugs and the entire thing was rushed. None of our ETLs that bring data from the data warehouse to the application database work correctly. Nor do any of our ML models for fusion and resolution work correctly. The data warehouse itself is a mess, with critical discrepancies in schema design between our dev, staging, and prod environments. The dev application database has been called &amp;quot;completed f**ked&amp;quot; by many, and the front-end team does all of their feature development in staging now. We&amp;#39;ve got a lot of major issues that are being ignored because management has no background in software engineering and no technical understanding of how the system works. They just think we aren&amp;#39;t delivering fast enough, and they keep making promises to clients. If you try to explain to them why everything is going to be a lot more difficult than they realize, it&amp;#39;s like talking to a brick wall. The entire company worked 10+ hours per day through the entire thanksgiving break and we still missed our deadline.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Ok, this has turned into a rant.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So on top of all of that, they&amp;#39;ve decided that instead of selling access to our main product, we&amp;#39;re going to build a custom dashboard for every client who&amp;#39;s willing to pay for one. I feel like this massively amplifies the work needed to meet our customer requirements when we were already struggling in our core competencies. &lt;/p&gt;\n\n&lt;p&gt;It also seems like it&amp;#39;s a fundamentally bad idea to ever do this, even if we weren&amp;#39;t already struggling before. The point of a software product is to do a couple of things that your clients need, and do them better than everyone else, right? Not to have a clunky, messy app that tries to do something different for everyone using individualized code for each client, right?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zbho1r", "is_robot_indexable": true, "report_reasons": null, "author": "abelEngineer", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zbho1r/is_a_custom_dashboard_for_every_customer_ever_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zbho1r/is_a_custom_dashboard_for_every_customer_ever_a/", "subreddit_subscribers": 81750, "created_utc": 1670078091.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_mh2cfxap", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Panel] Data, Meet Ops: How the Data Team can Take a Leadership Role | Attend live or watch on demand, Dec 20, 2022, 10 AM PT.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_zb2hqc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ODM6GE-_Q9Yi3efQNz6F8A73dHNqTX3CrznDDWJeHJI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670026435.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "getcensus.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.getcensus.com/events/panel-data-meet-ops-how-the-data-team-can-take-a-leadership-role", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JdF7V774hgOpAs_i73wo3gJTLZ3IHo22w_rnJ406ikU.jpg?auto=webp&amp;s=bc3f5d5b2f04b6fde3d8e5193fd41cffe1cf5545", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/JdF7V774hgOpAs_i73wo3gJTLZ3IHo22w_rnJ406ikU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a9cfb8aa9e08c621f65b4efa4dc3cfdd64ce197b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/JdF7V774hgOpAs_i73wo3gJTLZ3IHo22w_rnJ406ikU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3a3c7d3de660320c1dbda8b267c00fe5c8d83861", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/JdF7V774hgOpAs_i73wo3gJTLZ3IHo22w_rnJ406ikU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fc67252155811487bc6b2f50df4234f67d9f9b2b", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/JdF7V774hgOpAs_i73wo3gJTLZ3IHo22w_rnJ406ikU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=71a990bb4ffab7aa72e86b121953d33073b38b7c", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/JdF7V774hgOpAs_i73wo3gJTLZ3IHo22w_rnJ406ikU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2038afda7e25804279836e84e8427e1ca417a4df", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/JdF7V774hgOpAs_i73wo3gJTLZ3IHo22w_rnJ406ikU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a70047f17c19843d3e65efa46e37f5a495edb75f", "width": 1080, "height": 565}], "variants": {}, "id": "-o-8SLKUWlRTGfL4YHVUOOguYOxb229vV8n7bpn4cJM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zb2hqc", "is_robot_indexable": true, "report_reasons": null, "author": "whb2030", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zb2hqc/panel_data_meet_ops_how_the_data_team_can_take_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.getcensus.com/events/panel-data-meet-ops-how-the-data-team-can-take-a-leadership-role", "subreddit_subscribers": 81750, "created_utc": 1670026435.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What kind of python questions are people seeing in data engineer interviews?\n\nAlgos? Hard? Medium? \n\nPandas? ETL?\n\nOther?", "author_fullname": "t2_3p620rl9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Python Q\u2019s Data Engineer Interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zbkfrh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670085726.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What kind of python questions are people seeing in data engineer interviews?&lt;/p&gt;\n\n&lt;p&gt;Algos? Hard? Medium? &lt;/p&gt;\n\n&lt;p&gt;Pandas? ETL?&lt;/p&gt;\n\n&lt;p&gt;Other?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "DE @ Amazon/Lyft/Author of Ace DE Interview", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zbkfrh", "is_robot_indexable": true, "report_reasons": null, "author": "chrisgarzon19", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/zbkfrh/python_qs_data_engineer_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zbkfrh/python_qs_data_engineer_interview/", "subreddit_subscribers": 81750, "created_utc": 1670085726.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m trying to optimise SQL queries to make single queries and data model more performant.\nDoes anyone recommend a website/tool to test speed and data load of SQL query, and design pre-aggregations, caching, joins, etc?", "author_fullname": "t2_5h34hmxg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best tool/design best practices to increase speed and reduce data load of SQL queries?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zbhoil", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670078127.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying to optimise SQL queries to make single queries and data model more performant.\nDoes anyone recommend a website/tool to test speed and data load of SQL query, and design pre-aggregations, caching, joins, etc?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zbhoil", "is_robot_indexable": true, "report_reasons": null, "author": "gansamino", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zbhoil/best_tooldesign_best_practices_to_increase_speed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zbhoil/best_tooldesign_best_practices_to_increase_speed/", "subreddit_subscribers": 81750, "created_utc": 1670078127.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Ever since college (graduated in 2005) I knew I wanted to be in data.\n\nI started off as a tech support rep for an ISP.\nThis led to me being a BI Analyst, I wrote reports and talked to BUs, great fun.\n\nI turned that into a DBA job in 2013, SQL Server.\nI moved up to DBA Advanced in 2015 and remained stagnant after that.  There wasn\u2019t much room for growth.\n\nSo in 2021 I interviewed and got a position with a cloud provider (Azure, GCP, AWS, one of those three) as a Database Consultant.  I helped customers migrate their data workloads into the cloud.  I was excited.  My hope was to gain experience and eventually turn it into a DE position either within the company or elsewhere.\n\nUnfortunately, there isn\u2019t much work in this space for a SQL Server person, and although I was told that I would have ample opportunities to gain knowledge and experience with all sorts of engines and technologies, it just didn\u2019t happen.  The work dried up and only the most experienced consultants can get work.\n\nI spent the last year doing almost literally nothing.  The pay is great, but I feel like I\u2019m regressing.  One can only do so many Udemy classes and workshops.\n\nI want to move on, and I know I want to get into DE.\n\nI\u2019m 41, and feeling a bit old.\n\nI have working knowledge of Spark, Snowflake, Airflow, Hadoop, but no professional experience.\n\nWhat\u2019s the best way to get into a DE role?  Just apply and pray?  Have a portfolio of some kind?  Contribute to open source projects?  All of the above?\n\nI\u2019d appreciate any insight you all can offer.", "author_fullname": "t2_443yq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Struggling - Need Guidance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zbnmoi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1670094617.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670093958.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Ever since college (graduated in 2005) I knew I wanted to be in data.&lt;/p&gt;\n\n&lt;p&gt;I started off as a tech support rep for an ISP.\nThis led to me being a BI Analyst, I wrote reports and talked to BUs, great fun.&lt;/p&gt;\n\n&lt;p&gt;I turned that into a DBA job in 2013, SQL Server.\nI moved up to DBA Advanced in 2015 and remained stagnant after that.  There wasn\u2019t much room for growth.&lt;/p&gt;\n\n&lt;p&gt;So in 2021 I interviewed and got a position with a cloud provider (Azure, GCP, AWS, one of those three) as a Database Consultant.  I helped customers migrate their data workloads into the cloud.  I was excited.  My hope was to gain experience and eventually turn it into a DE position either within the company or elsewhere.&lt;/p&gt;\n\n&lt;p&gt;Unfortunately, there isn\u2019t much work in this space for a SQL Server person, and although I was told that I would have ample opportunities to gain knowledge and experience with all sorts of engines and technologies, it just didn\u2019t happen.  The work dried up and only the most experienced consultants can get work.&lt;/p&gt;\n\n&lt;p&gt;I spent the last year doing almost literally nothing.  The pay is great, but I feel like I\u2019m regressing.  One can only do so many Udemy classes and workshops.&lt;/p&gt;\n\n&lt;p&gt;I want to move on, and I know I want to get into DE.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m 41, and feeling a bit old.&lt;/p&gt;\n\n&lt;p&gt;I have working knowledge of Spark, Snowflake, Airflow, Hadoop, but no professional experience.&lt;/p&gt;\n\n&lt;p&gt;What\u2019s the best way to get into a DE role?  Just apply and pray?  Have a portfolio of some kind?  Contribute to open source projects?  All of the above?&lt;/p&gt;\n\n&lt;p&gt;I\u2019d appreciate any insight you all can offer.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zbnmoi", "is_robot_indexable": true, "report_reasons": null, "author": "Brettuss", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zbnmoi/struggling_need_guidance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zbnmoi/struggling_need_guidance/", "subreddit_subscribers": 81750, "created_utc": 1670093958.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am working on a side project that consists of extracting  XML dataset stored in oracle, enriching it (rename, conversion to json) and then saving it on MongoDB.\n\nThe next step would be building a pipeline that move data from Mongo to the Data Warehouse on SqlServer.\n\nIs using mongodb in this case considered overkill ?\n\nReasons of usage:\n\n- Schema flexibility\n- Fast reads (for multithreaded pipelines).\n- Data compression(this is important because the dataset contains more than 300 tables with couple tables having few billions of rows).\n- good support for restful services\n- good support for alerts and notifications using change streams.\n\nWhat do you think ? Any advice is more than welcome.", "author_fullname": "t2_lzlbzvf6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any ideas on this ? Oracle(XMLType) -Enrichement:--&gt; MongoDB ---&gt; SQLServer(DW)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zb1qge", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1670024825.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670024368.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working on a side project that consists of extracting  XML dataset stored in oracle, enriching it (rename, conversion to json) and then saving it on MongoDB.&lt;/p&gt;\n\n&lt;p&gt;The next step would be building a pipeline that move data from Mongo to the Data Warehouse on SqlServer.&lt;/p&gt;\n\n&lt;p&gt;Is using mongodb in this case considered overkill ?&lt;/p&gt;\n\n&lt;p&gt;Reasons of usage:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Schema flexibility&lt;/li&gt;\n&lt;li&gt;Fast reads (for multithreaded pipelines).&lt;/li&gt;\n&lt;li&gt;Data compression(this is important because the dataset contains more than 300 tables with couple tables having few billions of rows).&lt;/li&gt;\n&lt;li&gt;good support for restful services&lt;/li&gt;\n&lt;li&gt;good support for alerts and notifications using change streams.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What do you think ? Any advice is more than welcome.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zb1qge", "is_robot_indexable": true, "report_reasons": null, "author": "Icy_Region3025", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zb1qge/any_ideas_on_this_oraclexmltype_enrichement/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zb1qge/any_ideas_on_this_oraclexmltype_enrichement/", "subreddit_subscribers": 81750, "created_utc": 1670024368.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In attempt to optimize our structured streaming, we're looking to place a timestamp in each step of the DAG. We have a logging query listener that we can extract the amount of rows we've processed:\n\n    override def onQueryProgress(event: StreamingQueryListener.QueryProgressEvent): Unit = {     log.info(s\"${jobId} executionTime=${event.progress.durationMs.get(\"triggerExecution\")}\")      log.info(s\"${jobId} progress=${event.progress}\")     event.progress.sources.foreach { source =&gt;       log.info(s\"${jobId} source=${source.description} processed=${source.numInputRows} tps=${source.processedRowsPerSecond}\")     }   } \n\nWe've placed this in the DAG. How can we place a timestamp in each step of the DAG, can it be in the listener or a custom method is preferred?\n\nThe high-level static DAG:\n\n1. Unionize all event streams\n2. Join the streams if applicable\n3. Parse and group the unionized stream\n4. Featurize the streams while manipulating the structured state\n5. Sink the streams\n6. Await termination\n\nHere's how we add the listener to spark:\n\n    loggingQueryListener = new LoggingQueryListener(s\"AAA-${jobId}\") spark.streams.addListener(loggingQueryListener)", "author_fullname": "t2_1tbzh2ae", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark Structured Streaming DAG: How to add timestamps in parsing, grouping, &amp; featurize steps so I can determine how long each step takes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zazy3t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670020067.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In attempt to optimize our structured streaming, we&amp;#39;re looking to place a timestamp in each step of the DAG. We have a logging query listener that we can extract the amount of rows we&amp;#39;ve processed:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;override def onQueryProgress(event: StreamingQueryListener.QueryProgressEvent): Unit = {     log.info(s&amp;quot;${jobId} executionTime=${event.progress.durationMs.get(&amp;quot;triggerExecution&amp;quot;)}&amp;quot;)      log.info(s&amp;quot;${jobId} progress=${event.progress}&amp;quot;)     event.progress.sources.foreach { source =&amp;gt;       log.info(s&amp;quot;${jobId} source=${source.description} processed=${source.numInputRows} tps=${source.processedRowsPerSecond}&amp;quot;)     }   } \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;We&amp;#39;ve placed this in the DAG. How can we place a timestamp in each step of the DAG, can it be in the listener or a custom method is preferred?&lt;/p&gt;\n\n&lt;p&gt;The high-level static DAG:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Unionize all event streams&lt;/li&gt;\n&lt;li&gt;Join the streams if applicable&lt;/li&gt;\n&lt;li&gt;Parse and group the unionized stream&lt;/li&gt;\n&lt;li&gt;Featurize the streams while manipulating the structured state&lt;/li&gt;\n&lt;li&gt;Sink the streams&lt;/li&gt;\n&lt;li&gt;Await termination&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Here&amp;#39;s how we add the listener to spark:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;loggingQueryListener = new LoggingQueryListener(s&amp;quot;AAA-${jobId}&amp;quot;) spark.streams.addListener(loggingQueryListener)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zazy3t", "is_robot_indexable": true, "report_reasons": null, "author": "TeslaMecca", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zazy3t/spark_structured_streaming_dag_how_to_add/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zazy3t/spark_structured_streaming_dag_how_to_add/", "subreddit_subscribers": 81750, "created_utc": 1670020067.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am living in Netherlands and looking for a remote data engineer job ,if anyone can help me . thanks in advance \nI worked for 5 years as Business intelligence analyst and have an experience in SQL , data modeling and data warehouse.\nGot a nano degree in data engineering", "author_fullname": "t2_7ssutue8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineer job", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zbjk4q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670083280.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am living in Netherlands and looking for a remote data engineer job ,if anyone can help me . thanks in advance \nI worked for 5 years as Business intelligence analyst and have an experience in SQL , data modeling and data warehouse.\nGot a nano degree in data engineering&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zbjk4q", "is_robot_indexable": true, "report_reasons": null, "author": "Ansam93", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zbjk4q/data_engineer_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zbjk4q/data_engineer_job/", "subreddit_subscribers": 81750, "created_utc": 1670083280.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_mh2cfxap", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interesting Survey on LinkedIn: How much does data engineering overlap with software engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 64, "top_awarded_type": null, "hide_score": false, "name": "t3_zb0k0r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 64, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/-59hKcLIq6o1vRVPHKh1-blm4nS3EC-XeGsbA9iWjYE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670021394.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "linkedin.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.linkedin.com/posts/eczachly_softwareengineering-dataengineering-activity-7004253697153105920-FFEn?utm_source=share&amp;utm_medium=member_desktop", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5ZI7oL3JTPPt59G0vTfOaQMHvka17QCAdFnF87leUeA.jpg?auto=webp&amp;s=52cc36e047bdca039326e84d3b7ce7aabaf12be6", "width": 64, "height": 64}, "resolutions": [], "variants": {}, "id": "QqSY3F9i2BgB-OdT_JpQr1vBqr2oq4spYNzkghHXwCM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zb0k0r", "is_robot_indexable": true, "report_reasons": null, "author": "whb2030", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zb0k0r/interesting_survey_on_linkedin_how_much_does_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.linkedin.com/posts/eczachly_softwareengineering-dataengineering-activity-7004253697153105920-FFEn?utm_source=share&amp;utm_medium=member_desktop", "subreddit_subscribers": 81750, "created_utc": 1670021394.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI am a data engineer (mostly on azure tech)  from philippines and I am having a hard time to find job overseas. Browsing on some companies in linkedin, I haven't found yet any company that will provide work visa but when broswing through other tech (c#, java ,front  end) some of them does provide.\n\nIs it me or data engineering with azure is not as in-demand right now?", "author_fullname": "t2_1o3gtlar", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "So hard to find a job overseas - Azure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zb2d93", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670026075.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I am a data engineer (mostly on azure tech)  from philippines and I am having a hard time to find job overseas. Browsing on some companies in linkedin, I haven&amp;#39;t found yet any company that will provide work visa but when broswing through other tech (c#, java ,front  end) some of them does provide.&lt;/p&gt;\n\n&lt;p&gt;Is it me or data engineering with azure is not as in-demand right now?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zb2d93", "is_robot_indexable": true, "report_reasons": null, "author": "aljandeleon", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zb2d93/so_hard_to_find_a_job_overseas_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zb2d93/so_hard_to_find_a_job_overseas_azure/", "subreddit_subscribers": 81750, "created_utc": 1670026075.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}