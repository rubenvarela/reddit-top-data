{"kind": "Listing", "data": {"after": null, "dist": 23, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_brkxjomi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If data engineering did Spotify Wrapped", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 139, "top_awarded_type": null, "hide_score": false, "name": "t3_zaqmay", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 327, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 327, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/2fQ1Y_URnhu3RTFsjzcXVc9Y0DA5lzvuvlLxRs464Bw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_1": 1}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1669998791.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/uemt99k9ii3a1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/uemt99k9ii3a1.png?auto=webp&amp;s=ea1942b60002c2a9eaf20946d643c54244452c3d", "width": 466, "height": 465}, "resolutions": [{"url": "https://preview.redd.it/uemt99k9ii3a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=200ec08abe53cfaba89ba58d7122811fdbeed410", "width": 108, "height": 107}, {"url": "https://preview.redd.it/uemt99k9ii3a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=94b9f7ebe2e6e1a1ed47dc0ea1d5e37adc66e718", "width": 216, "height": 215}, {"url": "https://preview.redd.it/uemt99k9ii3a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ab3ea93438e1f613266ec142da53a2044144ce57", "width": 320, "height": 319}], "variants": {}, "id": "fIKAP8PlJPMhCtF3FGYm5FYOUY43klnqYKiiCvbH-lc"}], "enabled": true}, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 100, "id": "gid_1", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Shows the Silver Award... and that's it.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Silver", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "zaqmay", "is_robot_indexable": true, "report_reasons": null, "author": "Straight_House8628", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zaqmay/if_data_engineering_did_spotify_wrapped/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/uemt99k9ii3a1.png", "subreddit_subscribers": 81713, "created_utc": 1669998791.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking to learn more about dbt(core) and more specifically, what challenges teams have with it. There is no shortage of \"pro\" dbt content on the internet, but I'd like to have a discussion about what's *wrong* with it. Not to hate on it, just to discuss what it could do better and/or differently (in your opinion).\n\nFor the sake of this discussion, let's assume everyone is bought into the idea of ELT and doing the T in the (presumably cloud based) warehouse using SQL. If you want to debate dbt vs a tool like Spark, then please start another thread. Full disclosure: I've never worked somewhere that uses dbt (I *have* played with it) but I know that there is a high probability my next employer(regardless of who that is) will already be using dbt. I also know enough to believe that dbt is the best choice out there for managing SQL transforms, but is that only because it is the only choice?\n\nOk, I'll start.\n\n* I hate that dbt makes me use references to build the DAG. Why can't it just parse my SQL and infer the DAG from that? (Maybe it can and it just isn't obvious?)", "author_fullname": "t2_ulpt0gri", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's \"wrong\" with dbt ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zamewl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 115, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 115, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669988066.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking to learn more about dbt(core) and more specifically, what challenges teams have with it. There is no shortage of &amp;quot;pro&amp;quot; dbt content on the internet, but I&amp;#39;d like to have a discussion about what&amp;#39;s &lt;em&gt;wrong&lt;/em&gt; with it. Not to hate on it, just to discuss what it could do better and/or differently (in your opinion).&lt;/p&gt;\n\n&lt;p&gt;For the sake of this discussion, let&amp;#39;s assume everyone is bought into the idea of ELT and doing the T in the (presumably cloud based) warehouse using SQL. If you want to debate dbt vs a tool like Spark, then please start another thread. Full disclosure: I&amp;#39;ve never worked somewhere that uses dbt (I &lt;em&gt;have&lt;/em&gt; played with it) but I know that there is a high probability my next employer(regardless of who that is) will already be using dbt. I also know enough to believe that dbt is the best choice out there for managing SQL transforms, but is that only because it is the only choice?&lt;/p&gt;\n\n&lt;p&gt;Ok, I&amp;#39;ll start.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I hate that dbt makes me use references to build the DAG. Why can&amp;#39;t it just parse my SQL and infer the DAG from that? (Maybe it can and it just isn&amp;#39;t obvious?)&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zamewl", "is_robot_indexable": true, "report_reasons": null, "author": "dadaengineering", "discussion_type": null, "num_comments": 77, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zamewl/whats_wrong_with_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zamewl/whats_wrong_with_dbt/", "subreddit_subscribers": 81713, "created_utc": 1669988066.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are your KPIs / North Star metrics for Data Engineering? How do you establish the productivity of your team?  \n\n\nI know this is hard to quantify, but we're trying to set a few north star metrics that we could display to the rest of the company", "author_fullname": "t2_kinpz3uc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering KPIs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zanclu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 40, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 40, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669990420.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are your KPIs / North Star metrics for Data Engineering? How do you establish the productivity of your team?  &lt;/p&gt;\n\n&lt;p&gt;I know this is hard to quantify, but we&amp;#39;re trying to set a few north star metrics that we could display to the rest of the company&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zanclu", "is_robot_indexable": true, "report_reasons": null, "author": "Brewash_Beer", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zanclu/data_engineering_kpis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zanclu/data_engineering_kpis/", "subreddit_subscribers": 81713, "created_utc": 1669990420.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello every one. I am searching for websites where I can be tested for complex sql questions. Thanks in advance.", "author_fullname": "t2_76h7jr47", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where to Practice Complex SQL questions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zb329e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670028055.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello every one. I am searching for websites where I can be tested for complex sql questions. Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zb329e", "is_robot_indexable": true, "report_reasons": null, "author": "s1va1209", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zb329e/where_to_practice_complex_sql_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zb329e/where_to_practice_complex_sql_questions/", "subreddit_subscribers": 81713, "created_utc": 1670028055.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys, in my work i have to do a lot of ETL pipelines with python.  I would like to know if there is any design pattern that helps in this process of downloading from a site with webscrapping, transforming the data and loading it in postgresql", "author_fullname": "t2_hzda3lb4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Design patter for Python ETL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zb39un", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670028666.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys, in my work i have to do a lot of ETL pipelines with python.  I would like to know if there is any design pattern that helps in this process of downloading from a site with webscrapping, transforming the data and loading it in postgresql&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zb39un", "is_robot_indexable": true, "report_reasons": null, "author": "salsichamma", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zb39un/design_patter_for_python_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zb39un/design_patter_for_python_etl/", "subreddit_subscribers": 81713, "created_utc": 1670028666.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know this has been asked before but I am struggling to think of questions you would ask in a system design interview for data engineering. Just looking for answers from more senior devs.\n\nPerhaps I just don\u2019t have enough interview experience to know what companies actually ask so I might be naive in thinking they would all ask something along the lines of designing a system to move raw data to a data warehouse for analytics. \n\nFor one, the current trend is having a data lake elt model with a data warehouse as a serving layer. This model pretty much applies to all companies looking to have a scalable data analytics solution. For a system design interview, what can you really ask here? \n\nSecond, a lot of the dsitributed infra and \u201csystem design\u201d is abstracted into open source libraries like apache spark, presto, hadoop/hive, etc. In my mind, it\u2019s pretty much plug and play between choosing these technologies more than \u201csystem design\u201d\n\nAm I seeing things the wrong way here?", "author_fullname": "t2_7jt0qboi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "System Design for Data Eng?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zb7jle", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670041615.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know this has been asked before but I am struggling to think of questions you would ask in a system design interview for data engineering. Just looking for answers from more senior devs.&lt;/p&gt;\n\n&lt;p&gt;Perhaps I just don\u2019t have enough interview experience to know what companies actually ask so I might be naive in thinking they would all ask something along the lines of designing a system to move raw data to a data warehouse for analytics. &lt;/p&gt;\n\n&lt;p&gt;For one, the current trend is having a data lake elt model with a data warehouse as a serving layer. This model pretty much applies to all companies looking to have a scalable data analytics solution. For a system design interview, what can you really ask here? &lt;/p&gt;\n\n&lt;p&gt;Second, a lot of the dsitributed infra and \u201csystem design\u201d is abstracted into open source libraries like apache spark, presto, hadoop/hive, etc. In my mind, it\u2019s pretty much plug and play between choosing these technologies more than \u201csystem design\u201d&lt;/p&gt;\n\n&lt;p&gt;Am I seeing things the wrong way here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zb7jle", "is_robot_indexable": true, "report_reasons": null, "author": "omscsdatathrow", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zb7jle/system_design_for_data_eng/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zb7jle/system_design_for_data_eng/", "subreddit_subscribers": 81713, "created_utc": 1670041615.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Following u/blef__ 's article yesterday for the Advent of Data,\nI didn't dare to be as thought provocative,\nbut here's my take on bottom-up data warehouse design,\nto get faster traction within a company when setting up that new data role/team/effort:\nhttps://www.adventofdata.com/modern-data-modeling-start-with-the-end/", "author_fullname": "t2_hizqfv2o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Modern Data Modeling : Start from the End?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zbe3c4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1670066395.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Following &lt;a href=\"/u/blef__\"&gt;u/blef__&lt;/a&gt; &amp;#39;s article yesterday for the Advent of Data,\nI didn&amp;#39;t dare to be as thought provocative,\nbut here&amp;#39;s my take on bottom-up data warehouse design,\nto get faster traction within a company when setting up that new data role/team/effort:\n&lt;a href=\"https://www.adventofdata.com/modern-data-modeling-start-with-the-end/\"&gt;https://www.adventofdata.com/modern-data-modeling-start-with-the-end/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/vlLNbbSJKK5SwCz2A0MVSw1zfm1K565HlEx_7tQLXlI.jpg?auto=webp&amp;s=860321faafb28e1b8bcb4633e1c790180ade053f", "width": 2000, "height": 1334}, "resolutions": [{"url": "https://external-preview.redd.it/vlLNbbSJKK5SwCz2A0MVSw1zfm1K565HlEx_7tQLXlI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=57c07865c1604b5f6299231785aa61394d13059b", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/vlLNbbSJKK5SwCz2A0MVSw1zfm1K565HlEx_7tQLXlI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0765689bae2958e23cae1621023ad8e856501e94", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/vlLNbbSJKK5SwCz2A0MVSw1zfm1K565HlEx_7tQLXlI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=29f82004e42189218aeca1668db3043d07c6bb73", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/vlLNbbSJKK5SwCz2A0MVSw1zfm1K565HlEx_7tQLXlI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=06c80979f97a31865f7b7ec3f012ed1958a24059", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/vlLNbbSJKK5SwCz2A0MVSw1zfm1K565HlEx_7tQLXlI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9cef35778d9358b7b6b173fdd2f36beecd095d68", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/vlLNbbSJKK5SwCz2A0MVSw1zfm1K565HlEx_7tQLXlI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3bfcceeb52591ae94db648bcdda773c66f408921", "width": 1080, "height": 720}], "variants": {}, "id": "7mWS4-Jq_UAucV_ev0FX3ua9BBgUB7PxPMdVyetbtvY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zbe3c4", "is_robot_indexable": true, "report_reasons": null, "author": "briceluu", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zbe3c4/modern_data_modeling_start_from_the_end/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zbe3c4/modern_data_modeling_start_from_the_end/", "subreddit_subscribers": 81713, "created_utc": 1670066395.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://www.youtube.com/watch?v=0x-\\_2QJyccs](https://www.youtube.com/watch?v=0x-_2QJyccs)", "author_fullname": "t2_17cxf7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks workspace and community edition", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zbawdz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.54, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1670053469.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=0x-_2QJyccs\"&gt;https://www.youtube.com/watch?v=0x-_2QJyccs&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/wzxtpgObEHeRiGIsBSs6AMfQOtPeFs3rQlAsYguCqOw.jpg?auto=webp&amp;s=c511512fe4fd9556e304bae16bd6e771e1776e3c", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/wzxtpgObEHeRiGIsBSs6AMfQOtPeFs3rQlAsYguCqOw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9d89f055e85cfcddb9de00f72ef795525594c55a", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/wzxtpgObEHeRiGIsBSs6AMfQOtPeFs3rQlAsYguCqOw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=db05808b07152e47a7cbd3baba6cb91580b82c2f", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/wzxtpgObEHeRiGIsBSs6AMfQOtPeFs3rQlAsYguCqOw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=baa886081aa9e1d871cbcca9251d26c75c5c58f3", "width": 320, "height": 240}], "variants": {}, "id": "pJ7svDTLOGCuK9fgyZt7OR1qn2MT-tre-ot7m4NYb3w"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zbawdz", "is_robot_indexable": true, "report_reasons": null, "author": "AdityaSinghRathi", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zbawdz/databricks_workspace_and_community_edition/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zbawdz/databricks_workspace_and_community_edition/", "subreddit_subscribers": 81713, "created_utc": 1670053469.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_mh2cfxap", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Panel] Data, Meet Ops: How the Data Team can Take a Leadership Role | Attend live or watch on demand, Dec 20, 2022, 10 AM PT.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_zb2hqc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ODM6GE-_Q9Yi3efQNz6F8A73dHNqTX3CrznDDWJeHJI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670026435.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "getcensus.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.getcensus.com/events/panel-data-meet-ops-how-the-data-team-can-take-a-leadership-role", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JdF7V774hgOpAs_i73wo3gJTLZ3IHo22w_rnJ406ikU.jpg?auto=webp&amp;s=bc3f5d5b2f04b6fde3d8e5193fd41cffe1cf5545", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/JdF7V774hgOpAs_i73wo3gJTLZ3IHo22w_rnJ406ikU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a9cfb8aa9e08c621f65b4efa4dc3cfdd64ce197b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/JdF7V774hgOpAs_i73wo3gJTLZ3IHo22w_rnJ406ikU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3a3c7d3de660320c1dbda8b267c00fe5c8d83861", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/JdF7V774hgOpAs_i73wo3gJTLZ3IHo22w_rnJ406ikU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fc67252155811487bc6b2f50df4234f67d9f9b2b", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/JdF7V774hgOpAs_i73wo3gJTLZ3IHo22w_rnJ406ikU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=71a990bb4ffab7aa72e86b121953d33073b38b7c", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/JdF7V774hgOpAs_i73wo3gJTLZ3IHo22w_rnJ406ikU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2038afda7e25804279836e84e8427e1ca417a4df", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/JdF7V774hgOpAs_i73wo3gJTLZ3IHo22w_rnJ406ikU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a70047f17c19843d3e65efa46e37f5a495edb75f", "width": 1080, "height": 565}], "variants": {}, "id": "-o-8SLKUWlRTGfL4YHVUOOguYOxb229vV8n7bpn4cJM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zb2hqc", "is_robot_indexable": true, "report_reasons": null, "author": "whb2030", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zb2hqc/panel_data_meet_ops_how_the_data_team_can_take_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.getcensus.com/events/panel-data-meet-ops-how-the-data-team-can-take-a-leadership-role", "subreddit_subscribers": 81713, "created_utc": 1670026435.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I currently have a personal (hobby) project I am working on but would like thoughts and opinions of others before I continue further. \n\n**Background:**\n\nI currently have Python Web Scrappers that collects data from multiple sites parses them into a JSON file, which is then converted into SQL scripts, and then a shellscript that calls the file and updates a local database tables from the JSON Files and then deletes the JSON files once updated. The SQL Server then does all the transforming if it doesn't meet my personal data quality rules.\n\nFrom that point, It then goes into PowerBi for a simple dashboard so I can review the data quickly.\n\n(The websites where I pull data from don't offer API Services. If they do use an API, then I use the API instead. )\n\n**Questions/Thoughts:**\n\nOne of the big downsides that I have with this format, is that the computer needs to be running at the time I need it to, to pull the data from the scrappers and update the DB and I am not too sure how I would go about into automating this process. I haven't looked too deep into this as of yet, but I am assuming a remote VM or some some cloud based product? \n\nWhat I am looking for from yourselves, how would you have approached your project, what would you have done differently? What other technology would you have used? Have I missed anything important?\n\n I am open to spending funds on better technology, Software, services.", "author_fullname": "t2_nypenmf9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Methodology? [ Python Scrapper - MS SQL Server - Dashboard ]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zasap3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670002828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently have a personal (hobby) project I am working on but would like thoughts and opinions of others before I continue further. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Background:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I currently have Python Web Scrappers that collects data from multiple sites parses them into a JSON file, which is then converted into SQL scripts, and then a shellscript that calls the file and updates a local database tables from the JSON Files and then deletes the JSON files once updated. The SQL Server then does all the transforming if it doesn&amp;#39;t meet my personal data quality rules.&lt;/p&gt;\n\n&lt;p&gt;From that point, It then goes into PowerBi for a simple dashboard so I can review the data quickly.&lt;/p&gt;\n\n&lt;p&gt;(The websites where I pull data from don&amp;#39;t offer API Services. If they do use an API, then I use the API instead. )&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Questions/Thoughts:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;One of the big downsides that I have with this format, is that the computer needs to be running at the time I need it to, to pull the data from the scrappers and update the DB and I am not too sure how I would go about into automating this process. I haven&amp;#39;t looked too deep into this as of yet, but I am assuming a remote VM or some some cloud based product? &lt;/p&gt;\n\n&lt;p&gt;What I am looking for from yourselves, how would you have approached your project, what would you have done differently? What other technology would you have used? Have I missed anything important?&lt;/p&gt;\n\n&lt;p&gt;I am open to spending funds on better technology, Software, services.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zasap3", "is_robot_indexable": true, "report_reasons": null, "author": "DevStandUp", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zasap3/best_methodology_python_scrapper_ms_sql_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zasap3/best_methodology_python_scrapper_ms_sql_server/", "subreddit_subscribers": 81713, "created_utc": 1670002828.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Moved jobs from aws environment to Google cloud services. Previously used Athena\u2019s schema on read to manage incoming files from external and internal sources. Worked perfectly even if data sets changed using aws glue. Now everything has to be imported into the data warehouse. \n\n\nI get the schema on read has drawbacks but kinda curious why a no movement solution isn\u2019t more popular?", "author_fullname": "t2_6mh3d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why isn\u2019t prestodb (trino) more popular?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zbe333", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670066365.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Moved jobs from aws environment to Google cloud services. Previously used Athena\u2019s schema on read to manage incoming files from external and internal sources. Worked perfectly even if data sets changed using aws glue. Now everything has to be imported into the data warehouse. &lt;/p&gt;\n\n&lt;p&gt;I get the schema on read has drawbacks but kinda curious why a no movement solution isn\u2019t more popular?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zbe333", "is_robot_indexable": true, "report_reasons": null, "author": "jahaz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zbe333/why_isnt_prestodb_trino_more_popular/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zbe333/why_isnt_prestodb_trino_more_popular/", "subreddit_subscribers": 81713, "created_utc": 1670066365.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Started applying two weeks ago, and lots of rejection letter has poured in. I know that's normal but i would really appreciate your feedback on my resume.", "author_fullname": "t2_jvuhrmb0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "From Data Analyst to Junior Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zb8yi0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670046379.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Started applying two weeks ago, and lots of rejection letter has poured in. I know that&amp;#39;s normal but i would really appreciate your feedback on my resume.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "zb8yi0", "is_robot_indexable": true, "report_reasons": null, "author": "Necessary-Factor8861", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zb8yi0/from_data_analyst_to_junior_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zb8yi0/from_data_analyst_to_junior_data_engineer/", "subreddit_subscribers": 81713, "created_utc": 1670046379.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am working on a side project that consists of extracting  XML dataset stored in oracle, enriching it (rename, conversion to json) and then saving it on MongoDB.\n\nThe next step would be building a pipeline that move data from Mongo to the Data Warehouse on SqlServer.\n\nIs using mongodb in this case considered overkill ?\n\nReasons of usage:\n\n- Schema flexibility\n- Fast reads (for multithreaded pipelines).\n- Data compression(this is important because the dataset contains more than 300 tables with couple tables having few billions of rows).\n- good support for restful services\n- good support for alerts and notifications using change streams.\n\nWhat do you think ? Any advice is more than welcome.", "author_fullname": "t2_lzlbzvf6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any ideas on this ? Oracle(XMLType) -Enrichement:--&gt; MongoDB ---&gt; SQLServer(DW)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zb1qge", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1670024825.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670024368.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working on a side project that consists of extracting  XML dataset stored in oracle, enriching it (rename, conversion to json) and then saving it on MongoDB.&lt;/p&gt;\n\n&lt;p&gt;The next step would be building a pipeline that move data from Mongo to the Data Warehouse on SqlServer.&lt;/p&gt;\n\n&lt;p&gt;Is using mongodb in this case considered overkill ?&lt;/p&gt;\n\n&lt;p&gt;Reasons of usage:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Schema flexibility&lt;/li&gt;\n&lt;li&gt;Fast reads (for multithreaded pipelines).&lt;/li&gt;\n&lt;li&gt;Data compression(this is important because the dataset contains more than 300 tables with couple tables having few billions of rows).&lt;/li&gt;\n&lt;li&gt;good support for restful services&lt;/li&gt;\n&lt;li&gt;good support for alerts and notifications using change streams.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What do you think ? Any advice is more than welcome.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zb1qge", "is_robot_indexable": true, "report_reasons": null, "author": "Icy_Region3025", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zb1qge/any_ideas_on_this_oraclexmltype_enrichement/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zb1qge/any_ideas_on_this_oraclexmltype_enrichement/", "subreddit_subscribers": 81713, "created_utc": 1670024368.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In attempt to optimize our structured streaming, we're looking to place a timestamp in each step of the DAG. We have a logging query listener that we can extract the amount of rows we've processed:\n\n    override def onQueryProgress(event: StreamingQueryListener.QueryProgressEvent): Unit = {     log.info(s\"${jobId} executionTime=${event.progress.durationMs.get(\"triggerExecution\")}\")      log.info(s\"${jobId} progress=${event.progress}\")     event.progress.sources.foreach { source =&gt;       log.info(s\"${jobId} source=${source.description} processed=${source.numInputRows} tps=${source.processedRowsPerSecond}\")     }   } \n\nWe've placed this in the DAG. How can we place a timestamp in each step of the DAG, can it be in the listener or a custom method is preferred?\n\nThe high-level static DAG:\n\n1. Unionize all event streams\n2. Join the streams if applicable\n3. Parse and group the unionized stream\n4. Featurize the streams while manipulating the structured state\n5. Sink the streams\n6. Await termination\n\nHere's how we add the listener to spark:\n\n    loggingQueryListener = new LoggingQueryListener(s\"AAA-${jobId}\") spark.streams.addListener(loggingQueryListener)", "author_fullname": "t2_1tbzh2ae", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark Structured Streaming DAG: How to add timestamps in parsing, grouping, &amp; featurize steps so I can determine how long each step takes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zazy3t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670020067.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In attempt to optimize our structured streaming, we&amp;#39;re looking to place a timestamp in each step of the DAG. We have a logging query listener that we can extract the amount of rows we&amp;#39;ve processed:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;override def onQueryProgress(event: StreamingQueryListener.QueryProgressEvent): Unit = {     log.info(s&amp;quot;${jobId} executionTime=${event.progress.durationMs.get(&amp;quot;triggerExecution&amp;quot;)}&amp;quot;)      log.info(s&amp;quot;${jobId} progress=${event.progress}&amp;quot;)     event.progress.sources.foreach { source =&amp;gt;       log.info(s&amp;quot;${jobId} source=${source.description} processed=${source.numInputRows} tps=${source.processedRowsPerSecond}&amp;quot;)     }   } \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;We&amp;#39;ve placed this in the DAG. How can we place a timestamp in each step of the DAG, can it be in the listener or a custom method is preferred?&lt;/p&gt;\n\n&lt;p&gt;The high-level static DAG:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Unionize all event streams&lt;/li&gt;\n&lt;li&gt;Join the streams if applicable&lt;/li&gt;\n&lt;li&gt;Parse and group the unionized stream&lt;/li&gt;\n&lt;li&gt;Featurize the streams while manipulating the structured state&lt;/li&gt;\n&lt;li&gt;Sink the streams&lt;/li&gt;\n&lt;li&gt;Await termination&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Here&amp;#39;s how we add the listener to spark:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;loggingQueryListener = new LoggingQueryListener(s&amp;quot;AAA-${jobId}&amp;quot;) spark.streams.addListener(loggingQueryListener)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zazy3t", "is_robot_indexable": true, "report_reasons": null, "author": "TeslaMecca", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zazy3t/spark_structured_streaming_dag_how_to_add/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zazy3t/spark_structured_streaming_dag_how_to_add/", "subreddit_subscribers": 81713, "created_utc": 1670020067.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "It seems peoples rarely talk about data governance in this subreddit. Is data engineer the right team for data governance project? Can someone share about the most important thing to do when doing this kind of project. What will be first thing you would do if this is the first data governance project in your company? I know this topic will be really wide, but I just wanna hear peoples story about it.", "author_fullname": "t2_tm5irceo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Governance Project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zas8xy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670002716.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It seems peoples rarely talk about data governance in this subreddit. Is data engineer the right team for data governance project? Can someone share about the most important thing to do when doing this kind of project. What will be first thing you would do if this is the first data governance project in your company? I know this topic will be really wide, but I just wanna hear peoples story about it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zas8xy", "is_robot_indexable": true, "report_reasons": null, "author": "natas_m", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zas8xy/data_governance_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zas8xy/data_governance_project/", "subreddit_subscribers": 81713, "created_utc": 1670002716.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, just wondered if anyone had experience with Databricks and the way they handle model promotion. I find it quite counter intuitive but I might not have the right intuition.\n\nIn their MLOps implementation, they promote models from a \"Staging\" state to a \"Production\" state. However as soon as a model is promoted, all testing pipelines relying on a model in \"Staging\" state break, since there is no longer any model in that state. So when testing just code changes, we'd need first to save a new model in \"Staging\", instead or reusing the model that was already there. Strong vibes of pipeline smell, but I might not be seeing an obvious clean solution.\n\nIf anyone has any idea, that would lighten up my day!", "author_fullname": "t2_lh1thuv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks &amp; Model Registry", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zan66d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669989959.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, just wondered if anyone had experience with Databricks and the way they handle model promotion. I find it quite counter intuitive but I might not have the right intuition.&lt;/p&gt;\n\n&lt;p&gt;In their MLOps implementation, they promote models from a &amp;quot;Staging&amp;quot; state to a &amp;quot;Production&amp;quot; state. However as soon as a model is promoted, all testing pipelines relying on a model in &amp;quot;Staging&amp;quot; state break, since there is no longer any model in that state. So when testing just code changes, we&amp;#39;d need first to save a new model in &amp;quot;Staging&amp;quot;, instead or reusing the model that was already there. Strong vibes of pipeline smell, but I might not be seeing an obvious clean solution.&lt;/p&gt;\n\n&lt;p&gt;If anyone has any idea, that would lighten up my day!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zan66d", "is_robot_indexable": true, "report_reasons": null, "author": "aupagizon", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zan66d/databricks_model_registry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zan66d/databricks_model_registry/", "subreddit_subscribers": 81713, "created_utc": 1669989959.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_mh2cfxap", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interesting Survey on LinkedIn: How much does data engineering overlap with software engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 64, "top_awarded_type": null, "hide_score": false, "name": "t3_zb0k0r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 64, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/-59hKcLIq6o1vRVPHKh1-blm4nS3EC-XeGsbA9iWjYE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670021394.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "linkedin.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.linkedin.com/posts/eczachly_softwareengineering-dataengineering-activity-7004253697153105920-FFEn?utm_source=share&amp;utm_medium=member_desktop", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5ZI7oL3JTPPt59G0vTfOaQMHvka17QCAdFnF87leUeA.jpg?auto=webp&amp;s=52cc36e047bdca039326e84d3b7ce7aabaf12be6", "width": 64, "height": 64}, "resolutions": [], "variants": {}, "id": "QqSY3F9i2BgB-OdT_JpQr1vBqr2oq4spYNzkghHXwCM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zb0k0r", "is_robot_indexable": true, "report_reasons": null, "author": "whb2030", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zb0k0r/interesting_survey_on_linkedin_how_much_does_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.linkedin.com/posts/eczachly_softwareengineering-dataengineering-activity-7004253697153105920-FFEn?utm_source=share&amp;utm_medium=member_desktop", "subreddit_subscribers": 81713, "created_utc": 1670021394.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI am a data engineer (mostly on azure tech)  from philippines and I am having a hard time to find job overseas. Browsing on some companies in linkedin, I haven't found yet any company that will provide work visa but when broswing through other tech (c#, java ,front  end) some of them does provide.\n\nIs it me or data engineering with azure is not as in-demand right now?", "author_fullname": "t2_1o3gtlar", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "So hard to find a job overseas - Azure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zb2d93", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670026075.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I am a data engineer (mostly on azure tech)  from philippines and I am having a hard time to find job overseas. Browsing on some companies in linkedin, I haven&amp;#39;t found yet any company that will provide work visa but when broswing through other tech (c#, java ,front  end) some of them does provide.&lt;/p&gt;\n\n&lt;p&gt;Is it me or data engineering with azure is not as in-demand right now?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zb2d93", "is_robot_indexable": true, "report_reasons": null, "author": "aljandeleon", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zb2d93/so_hard_to_find_a_job_overseas_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zb2d93/so_hard_to_find_a_job_overseas_azure/", "subreddit_subscribers": 81713, "created_utc": 1670026075.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_796g5y3q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Information vs. Data - Are you conscious?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 84, "top_awarded_type": null, "hide_score": false, "name": "t3_zank10", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.44, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/XnSaCSQWNtjtbDij5lHQPEb2XB3BTb1OrkvF7DGpsQs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1669990983.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@alejandro.attento/information-vs-data-are-you-conscious-e67a852fae05", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/CDCRjVq0ZwpDRr_UkUU30QwOD3LIEMhuCbWFtfF-CcQ.jpg?auto=webp&amp;s=a0fe1a694af55e94aac3cfa32bb6962685286735", "width": 732, "height": 442}, "resolutions": [{"url": "https://external-preview.redd.it/CDCRjVq0ZwpDRr_UkUU30QwOD3LIEMhuCbWFtfF-CcQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f40596e13bd282f29c3a4b71b82d866163e94704", "width": 108, "height": 65}, {"url": "https://external-preview.redd.it/CDCRjVq0ZwpDRr_UkUU30QwOD3LIEMhuCbWFtfF-CcQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1fc20b39d7a73b3b43e55f9645844debbf592288", "width": 216, "height": 130}, {"url": "https://external-preview.redd.it/CDCRjVq0ZwpDRr_UkUU30QwOD3LIEMhuCbWFtfF-CcQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=14f086875e097d77b1e592db6b2f2e45c304b26b", "width": 320, "height": 193}, {"url": "https://external-preview.redd.it/CDCRjVq0ZwpDRr_UkUU30QwOD3LIEMhuCbWFtfF-CcQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=72741db975e4561c39b998f414b22c6854303990", "width": 640, "height": 386}], "variants": {}, "id": "RvwE1Bk6mp7F6xxa-5luxhjK-7ScYuDMlKxx9BnXvAg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zank10", "is_robot_indexable": true, "report_reasons": null, "author": "elaleeman94", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zank10/information_vs_data_are_you_conscious/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@alejandro.attento/information-vs-data-are-you-conscious-e67a852fae05", "subreddit_subscribers": 81713, "created_utc": 1669990983.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://www.youtube.com/watch?v=0x-\\_2QJyccs](https://www.youtube.com/watch?v=0x-_2QJyccs)", "author_fullname": "t2_17cxf7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks workspace and community edition", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zbawyo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.29, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1670053531.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=0x-_2QJyccs\"&gt;https://www.youtube.com/watch?v=0x-_2QJyccs&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/wzxtpgObEHeRiGIsBSs6AMfQOtPeFs3rQlAsYguCqOw.jpg?auto=webp&amp;s=c511512fe4fd9556e304bae16bd6e771e1776e3c", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/wzxtpgObEHeRiGIsBSs6AMfQOtPeFs3rQlAsYguCqOw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9d89f055e85cfcddb9de00f72ef795525594c55a", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/wzxtpgObEHeRiGIsBSs6AMfQOtPeFs3rQlAsYguCqOw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=db05808b07152e47a7cbd3baba6cb91580b82c2f", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/wzxtpgObEHeRiGIsBSs6AMfQOtPeFs3rQlAsYguCqOw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=baa886081aa9e1d871cbcca9251d26c75c5c58f3", "width": 320, "height": 240}], "variants": {}, "id": "pJ7svDTLOGCuK9fgyZt7OR1qn2MT-tre-ot7m4NYb3w"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "zbawyo", "is_robot_indexable": true, "report_reasons": null, "author": "AdityaSinghRathi", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zbawyo/databricks_workspace_and_community_edition/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zbawyo/databricks_workspace_and_community_edition/", "subreddit_subscribers": 81713, "created_utc": 1670053531.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://www.youtube.com/watch?v=0x-\\_2QJyccs](https://www.youtube.com/watch?v=0x-_2QJyccs)", "author_fullname": "t2_17cxf7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks workspace and community edition", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zbawqw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1670053508.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=0x-_2QJyccs\"&gt;https://www.youtube.com/watch?v=0x-_2QJyccs&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/wzxtpgObEHeRiGIsBSs6AMfQOtPeFs3rQlAsYguCqOw.jpg?auto=webp&amp;s=c511512fe4fd9556e304bae16bd6e771e1776e3c", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/wzxtpgObEHeRiGIsBSs6AMfQOtPeFs3rQlAsYguCqOw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9d89f055e85cfcddb9de00f72ef795525594c55a", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/wzxtpgObEHeRiGIsBSs6AMfQOtPeFs3rQlAsYguCqOw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=db05808b07152e47a7cbd3baba6cb91580b82c2f", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/wzxtpgObEHeRiGIsBSs6AMfQOtPeFs3rQlAsYguCqOw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=baa886081aa9e1d871cbcca9251d26c75c5c58f3", "width": 320, "height": 240}], "variants": {}, "id": "pJ7svDTLOGCuK9fgyZt7OR1qn2MT-tre-ot7m4NYb3w"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zbawqw", "is_robot_indexable": true, "report_reasons": null, "author": "AdityaSinghRathi", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zbawqw/databricks_workspace_and_community_edition/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zbawqw/databricks_workspace_and_community_edition/", "subreddit_subscribers": 81713, "created_utc": 1670053508.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://www.youtube.com/watch?v=0x-\\_2QJyccs](https://www.youtube.com/watch?v=0x-_2QJyccs)", "author_fullname": "t2_17cxf7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks workspace and community edition", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zbax4m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1670053550.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=0x-_2QJyccs\"&gt;https://www.youtube.com/watch?v=0x-_2QJyccs&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/wzxtpgObEHeRiGIsBSs6AMfQOtPeFs3rQlAsYguCqOw.jpg?auto=webp&amp;s=c511512fe4fd9556e304bae16bd6e771e1776e3c", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/wzxtpgObEHeRiGIsBSs6AMfQOtPeFs3rQlAsYguCqOw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9d89f055e85cfcddb9de00f72ef795525594c55a", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/wzxtpgObEHeRiGIsBSs6AMfQOtPeFs3rQlAsYguCqOw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=db05808b07152e47a7cbd3baba6cb91580b82c2f", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/wzxtpgObEHeRiGIsBSs6AMfQOtPeFs3rQlAsYguCqOw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=baa886081aa9e1d871cbcca9251d26c75c5c58f3", "width": 320, "height": 240}], "variants": {}, "id": "pJ7svDTLOGCuK9fgyZt7OR1qn2MT-tre-ot7m4NYb3w"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zbax4m", "is_robot_indexable": true, "report_reasons": null, "author": "AdityaSinghRathi", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zbax4m/databricks_workspace_and_community_edition/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zbax4m/databricks_workspace_and_community_edition/", "subreddit_subscribers": 81713, "created_utc": 1670053550.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Microsoft Azure Data Engineering is one of the best Data Science tools out there, but which one is its best benefit?\n\n[View Poll](https://www.reddit.com/poll/zaqqqx)", "author_fullname": "t2_gk917caz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which is the best feature of Microsoft Azure Data Engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zaqqqx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669999107.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Microsoft Azure Data Engineering is one of the best Data Science tools out there, but which one is its best benefit?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/zaqqqx\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zaqqqx", "is_robot_indexable": true, "report_reasons": null, "author": "joyful_reader", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1670603907647, "options": [{"text": "Data Warehousing", "id": "20142769"}, {"text": "Data Security", "id": "20142770"}, {"text": "Data Monitoring", "id": "20142771"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 81, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zaqqqx/which_is_the_best_feature_of_microsoft_azure_data/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/zaqqqx/which_is_the_best_feature_of_microsoft_azure_data/", "subreddit_subscribers": 81713, "created_utc": 1669999107.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}