{"kind": "Listing", "data": {"after": "t3_zb0k0r", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_brkxjomi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If data engineering did Spotify Wrapped", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 139, "top_awarded_type": null, "hide_score": false, "name": "t3_zaqmay", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 295, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 295, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/2fQ1Y_URnhu3RTFsjzcXVc9Y0DA5lzvuvlLxRs464Bw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_1": 1}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1669998791.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/uemt99k9ii3a1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/uemt99k9ii3a1.png?auto=webp&amp;s=ea1942b60002c2a9eaf20946d643c54244452c3d", "width": 466, "height": 465}, "resolutions": [{"url": "https://preview.redd.it/uemt99k9ii3a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=200ec08abe53cfaba89ba58d7122811fdbeed410", "width": 108, "height": 107}, {"url": "https://preview.redd.it/uemt99k9ii3a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=94b9f7ebe2e6e1a1ed47dc0ea1d5e37adc66e718", "width": 216, "height": 215}, {"url": "https://preview.redd.it/uemt99k9ii3a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ab3ea93438e1f613266ec142da53a2044144ce57", "width": 320, "height": 319}], "variants": {}, "id": "fIKAP8PlJPMhCtF3FGYm5FYOUY43klnqYKiiCvbH-lc"}], "enabled": true}, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 100, "id": "gid_1", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Shows the Silver Award... and that's it.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Silver", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "zaqmay", "is_robot_indexable": true, "report_reasons": null, "author": "Straight_House8628", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zaqmay/if_data_engineering_did_spotify_wrapped/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/uemt99k9ii3a1.png", "subreddit_subscribers": 81702, "created_utc": 1669998791.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking to learn more about dbt(core) and more specifically, what challenges teams have with it. There is no shortage of \"pro\" dbt content on the internet, but I'd like to have a discussion about what's *wrong* with it. Not to hate on it, just to discuss what it could do better and/or differently (in your opinion).\n\nFor the sake of this discussion, let's assume everyone is bought into the idea of ELT and doing the T in the (presumably cloud based) warehouse using SQL. If you want to debate dbt vs a tool like Spark, then please start another thread. Full disclosure: I've never worked somewhere that uses dbt (I *have* played with it) but I know that there is a high probability my next employer(regardless of who that is) will already be using dbt. I also know enough to believe that dbt is the best choice out there for managing SQL transforms, but is that only because it is the only choice?\n\nOk, I'll start.\n\n* I hate that dbt makes me use references to build the DAG. Why can't it just parse my SQL and infer the DAG from that? (Maybe it can and it just isn't obvious?)", "author_fullname": "t2_ulpt0gri", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's \"wrong\" with dbt ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zamewl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 108, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 108, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669988066.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking to learn more about dbt(core) and more specifically, what challenges teams have with it. There is no shortage of &amp;quot;pro&amp;quot; dbt content on the internet, but I&amp;#39;d like to have a discussion about what&amp;#39;s &lt;em&gt;wrong&lt;/em&gt; with it. Not to hate on it, just to discuss what it could do better and/or differently (in your opinion).&lt;/p&gt;\n\n&lt;p&gt;For the sake of this discussion, let&amp;#39;s assume everyone is bought into the idea of ELT and doing the T in the (presumably cloud based) warehouse using SQL. If you want to debate dbt vs a tool like Spark, then please start another thread. Full disclosure: I&amp;#39;ve never worked somewhere that uses dbt (I &lt;em&gt;have&lt;/em&gt; played with it) but I know that there is a high probability my next employer(regardless of who that is) will already be using dbt. I also know enough to believe that dbt is the best choice out there for managing SQL transforms, but is that only because it is the only choice?&lt;/p&gt;\n\n&lt;p&gt;Ok, I&amp;#39;ll start.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I hate that dbt makes me use references to build the DAG. Why can&amp;#39;t it just parse my SQL and infer the DAG from that? (Maybe it can and it just isn&amp;#39;t obvious?)&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zamewl", "is_robot_indexable": true, "report_reasons": null, "author": "dadaengineering", "discussion_type": null, "num_comments": 72, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zamewl/whats_wrong_with_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zamewl/whats_wrong_with_dbt/", "subreddit_subscribers": 81702, "created_utc": 1669988066.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are your KPIs / North Star metrics for Data Engineering? How do you establish the productivity of your team?  \n\n\nI know this is hard to quantify, but we're trying to set a few north star metrics that we could display to the rest of the company", "author_fullname": "t2_kinpz3uc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering KPIs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zanclu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 38, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 38, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669990420.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are your KPIs / North Star metrics for Data Engineering? How do you establish the productivity of your team?  &lt;/p&gt;\n\n&lt;p&gt;I know this is hard to quantify, but we&amp;#39;re trying to set a few north star metrics that we could display to the rest of the company&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zanclu", "is_robot_indexable": true, "report_reasons": null, "author": "Brewash_Beer", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zanclu/data_engineering_kpis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zanclu/data_engineering_kpis/", "subreddit_subscribers": 81702, "created_utc": 1669990420.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello every one. I am searching for websites where I can be tested for complex sql questions. Thanks in advance.", "author_fullname": "t2_76h7jr47", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where to Practice Complex SQL questions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zb329e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670028055.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello every one. I am searching for websites where I can be tested for complex sql questions. Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zb329e", "is_robot_indexable": true, "report_reasons": null, "author": "s1va1209", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zb329e/where_to_practice_complex_sql_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zb329e/where_to_practice_complex_sql_questions/", "subreddit_subscribers": 81702, "created_utc": 1670028055.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I'm in a new job where I'm in way over my head (or so it feels like) and my weakest side is that I suck at Azure. Managed identities, service principals, oauth 2.0, sas tokens, file system drivers, vnets, subnets... There are so many security concepts that I simply read about so many times, but I am never able to learn how they are all related and get an overview. My brain is simply unable to comprehend it all unless I can REALLY get a grasp. I'm a very all or nothing guy, hearing a word here and there never makes it stick. \n\nI'm currently working with the IaC team tp implement Databricks, Unity Catalog and for everything outside Databricks I really struggle. Does anyone have any good tips? I was recommended by a colleague to do the AZ-104 certification (or at least read the learning materials). Any other tips?", "author_fullname": "t2_4ov075m4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need to improve my cloud (Azure) skills to become a better data engineer. Tips?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zagbo0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669970714.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;m in a new job where I&amp;#39;m in way over my head (or so it feels like) and my weakest side is that I suck at Azure. Managed identities, service principals, oauth 2.0, sas tokens, file system drivers, vnets, subnets... There are so many security concepts that I simply read about so many times, but I am never able to learn how they are all related and get an overview. My brain is simply unable to comprehend it all unless I can REALLY get a grasp. I&amp;#39;m a very all or nothing guy, hearing a word here and there never makes it stick. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working with the IaC team tp implement Databricks, Unity Catalog and for everything outside Databricks I really struggle. Does anyone have any good tips? I was recommended by a colleague to do the AZ-104 certification (or at least read the learning materials). Any other tips?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zagbo0", "is_robot_indexable": true, "report_reasons": null, "author": "HealthyDoggos4Life", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zagbo0/need_to_improve_my_cloud_azure_skills_to_become_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zagbo0/need_to_improve_my_cloud_azure_skills_to_become_a/", "subreddit_subscribers": 81702, "created_utc": 1669970714.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys, in my work i have to do a lot of ETL pipelines with python.  I would like to know if there is any design pattern that helps in this process of downloading from a site with webscrapping, transforming the data and loading it in postgresql", "author_fullname": "t2_hzda3lb4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Design patter for Python ETL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zb39un", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670028666.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys, in my work i have to do a lot of ETL pipelines with python.  I would like to know if there is any design pattern that helps in this process of downloading from a site with webscrapping, transforming the data and loading it in postgresql&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zb39un", "is_robot_indexable": true, "report_reasons": null, "author": "salsichamma", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zb39un/design_patter_for_python_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zb39un/design_patter_for_python_etl/", "subreddit_subscribers": 81702, "created_utc": 1670028666.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know this has been asked before but I am struggling to think of questions you would ask in a system design interview for data engineering. Just looking for answers from more senior devs.\n\nPerhaps I just don\u2019t have enough interview experience to know what companies actually ask so I might be naive in thinking they would all ask something along the lines of designing a system to move raw data to a data warehouse for analytics. \n\nFor one, the current trend is having a data lake elt model with a data warehouse as a serving layer. This model pretty much applies to all companies looking to have a scalable data analytics solution. For a system design interview, what can you really ask here? \n\nSecond, a lot of the dsitributed infra and \u201csystem design\u201d is abstracted into open source libraries like apache spark, presto, hadoop/hive, etc. In my mind, it\u2019s pretty much plug and play between choosing these technologies more than \u201csystem design\u201d\n\nAm I seeing things the wrong way here?", "author_fullname": "t2_7jt0qboi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "System Design for Data Eng?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zb7jle", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670041615.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know this has been asked before but I am struggling to think of questions you would ask in a system design interview for data engineering. Just looking for answers from more senior devs.&lt;/p&gt;\n\n&lt;p&gt;Perhaps I just don\u2019t have enough interview experience to know what companies actually ask so I might be naive in thinking they would all ask something along the lines of designing a system to move raw data to a data warehouse for analytics. &lt;/p&gt;\n\n&lt;p&gt;For one, the current trend is having a data lake elt model with a data warehouse as a serving layer. This model pretty much applies to all companies looking to have a scalable data analytics solution. For a system design interview, what can you really ask here? &lt;/p&gt;\n\n&lt;p&gt;Second, a lot of the dsitributed infra and \u201csystem design\u201d is abstracted into open source libraries like apache spark, presto, hadoop/hive, etc. In my mind, it\u2019s pretty much plug and play between choosing these technologies more than \u201csystem design\u201d&lt;/p&gt;\n\n&lt;p&gt;Am I seeing things the wrong way here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zb7jle", "is_robot_indexable": true, "report_reasons": null, "author": "omscsdatathrow", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zb7jle/system_design_for_data_eng/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zb7jle/system_design_for_data_eng/", "subreddit_subscribers": 81702, "created_utc": 1670041615.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a junior data engineer, and got what I thought was an interesting question in an interview - intrigued by your collective approaches. I was given a toy case of a healthcare business that wanted to build a model to detect coughing in their waiting rooms (to de-risk spread of disease etc etc). They have some messy raw audio data from their waiting rooms that is usable. The interviewer asked how I would go about sourcing a robust dataset to train a model on. I came up with three ideas - intrigued to see what you guys think:  \n\n\n* Mechanical Turk the raw audio files to segment out the cases of coughing and label them depending on the \"type\" of cough (wheezy, light, hard etc)\n* Scrape YouTube vids for coughing occurrences and then Mechanical Turk or manually label the audio similar to above\n* Employ actors to cough to outlined constraints e.g. \"young woman with a wheezy cough, no background noise\", \"man with light cough in a busy space\" etc. etc.  \n\n\nThoughts welcomed!", "author_fullname": "t2_5lfzc2mu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data sourcing interview question I got - opinions wanted please", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zahfgf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669974559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a junior data engineer, and got what I thought was an interesting question in an interview - intrigued by your collective approaches. I was given a toy case of a healthcare business that wanted to build a model to detect coughing in their waiting rooms (to de-risk spread of disease etc etc). They have some messy raw audio data from their waiting rooms that is usable. The interviewer asked how I would go about sourcing a robust dataset to train a model on. I came up with three ideas - intrigued to see what you guys think:  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Mechanical Turk the raw audio files to segment out the cases of coughing and label them depending on the &amp;quot;type&amp;quot; of cough (wheezy, light, hard etc)&lt;/li&gt;\n&lt;li&gt;Scrape YouTube vids for coughing occurrences and then Mechanical Turk or manually label the audio similar to above&lt;/li&gt;\n&lt;li&gt;Employ actors to cough to outlined constraints e.g. &amp;quot;young woman with a wheezy cough, no background noise&amp;quot;, &amp;quot;man with light cough in a busy space&amp;quot; etc. etc.&lt;br/&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thoughts welcomed!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "zahfgf", "is_robot_indexable": true, "report_reasons": null, "author": "fourcornerclub", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zahfgf/data_sourcing_interview_question_i_got_opinions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zahfgf/data_sourcing_interview_question_i_got_opinions/", "subreddit_subscribers": 81702, "created_utc": 1669974559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, \n \nI need to see the previous changes made to a stored procedure in BigQuery. Is there a way to keep track of the changes made to a procedure in the past? \n\nI am aware that bigquery offers change history option for tables but I am not sure if it's the case for procedures as well. \n\nThanks in advance,", "author_fullname": "t2_8wbw972l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Change History for Procedures in BigQuery?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zaii9u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1670007239.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669977725.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, &lt;/p&gt;\n\n&lt;p&gt;I need to see the previous changes made to a stored procedure in BigQuery. Is there a way to keep track of the changes made to a procedure in the past? &lt;/p&gt;\n\n&lt;p&gt;I am aware that bigquery offers change history option for tables but I am not sure if it&amp;#39;s the case for procedures as well. &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance,&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zaii9u", "is_robot_indexable": true, "report_reasons": null, "author": "HappyEnvironment8225", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zaii9u/change_history_for_procedures_in_bigquery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zaii9u/change_history_for_procedures_in_bigquery/", "subreddit_subscribers": 81702, "created_utc": 1669977725.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://www.youtube.com/watch?v=0x-\\_2QJyccs](https://www.youtube.com/watch?v=0x-_2QJyccs)", "author_fullname": "t2_17cxf7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks workspace and community edition", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zbax4m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1670053550.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=0x-_2QJyccs\"&gt;https://www.youtube.com/watch?v=0x-_2QJyccs&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/wzxtpgObEHeRiGIsBSs6AMfQOtPeFs3rQlAsYguCqOw.jpg?auto=webp&amp;s=c511512fe4fd9556e304bae16bd6e771e1776e3c", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/wzxtpgObEHeRiGIsBSs6AMfQOtPeFs3rQlAsYguCqOw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9d89f055e85cfcddb9de00f72ef795525594c55a", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/wzxtpgObEHeRiGIsBSs6AMfQOtPeFs3rQlAsYguCqOw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=db05808b07152e47a7cbd3baba6cb91580b82c2f", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/wzxtpgObEHeRiGIsBSs6AMfQOtPeFs3rQlAsYguCqOw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=baa886081aa9e1d871cbcca9251d26c75c5c58f3", "width": 320, "height": 240}], "variants": {}, "id": "pJ7svDTLOGCuK9fgyZt7OR1qn2MT-tre-ot7m4NYb3w"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zbax4m", "is_robot_indexable": true, "report_reasons": null, "author": "AdityaSinghRathi", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zbax4m/databricks_workspace_and_community_edition/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zbax4m/databricks_workspace_and_community_edition/", "subreddit_subscribers": 81702, "created_utc": 1670053550.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I currently have a personal (hobby) project I am working on but would like thoughts and opinions of others before I continue further. \n\n**Background:**\n\nI currently have Python Web Scrappers that collects data from multiple sites parses them into a JSON file, which is then converted into SQL scripts, and then a shellscript that calls the file and updates a local database tables from the JSON Files and then deletes the JSON files once updated. The SQL Server then does all the transforming if it doesn't meet my personal data quality rules.\n\nFrom that point, It then goes into PowerBi for a simple dashboard so I can review the data quickly.\n\n(The websites where I pull data from don't offer API Services. If they do use an API, then I use the API instead. )\n\n**Questions/Thoughts:**\n\nOne of the big downsides that I have with this format, is that the computer needs to be running at the time I need it to, to pull the data from the scrappers and update the DB and I am not too sure how I would go about into automating this process. I haven't looked too deep into this as of yet, but I am assuming a remote VM or some some cloud based product? \n\nWhat I am looking for from yourselves, how would you have approached your project, what would you have done differently? What other technology would you have used? Have I missed anything important?\n\n I am open to spending funds on better technology, Software, services.", "author_fullname": "t2_nypenmf9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Methodology? [ Python Scrapper - MS SQL Server - Dashboard ]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zasap3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670002828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently have a personal (hobby) project I am working on but would like thoughts and opinions of others before I continue further. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Background:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I currently have Python Web Scrappers that collects data from multiple sites parses them into a JSON file, which is then converted into SQL scripts, and then a shellscript that calls the file and updates a local database tables from the JSON Files and then deletes the JSON files once updated. The SQL Server then does all the transforming if it doesn&amp;#39;t meet my personal data quality rules.&lt;/p&gt;\n\n&lt;p&gt;From that point, It then goes into PowerBi for a simple dashboard so I can review the data quickly.&lt;/p&gt;\n\n&lt;p&gt;(The websites where I pull data from don&amp;#39;t offer API Services. If they do use an API, then I use the API instead. )&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Questions/Thoughts:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;One of the big downsides that I have with this format, is that the computer needs to be running at the time I need it to, to pull the data from the scrappers and update the DB and I am not too sure how I would go about into automating this process. I haven&amp;#39;t looked too deep into this as of yet, but I am assuming a remote VM or some some cloud based product? &lt;/p&gt;\n\n&lt;p&gt;What I am looking for from yourselves, how would you have approached your project, what would you have done differently? What other technology would you have used? Have I missed anything important?&lt;/p&gt;\n\n&lt;p&gt;I am open to spending funds on better technology, Software, services.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zasap3", "is_robot_indexable": true, "report_reasons": null, "author": "DevStandUp", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zasap3/best_methodology_python_scrapper_ms_sql_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zasap3/best_methodology_python_scrapper_ms_sql_server/", "subreddit_subscribers": 81702, "created_utc": 1670002828.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, I have recently graduated and I've been working 3 months as a Junior Data Engineer in a tech consulting company (a body rental company) in Spain. Currently I don't know most of the tools/skills I hear about in this sub (Airflow, Docker...) and we are not using them either. I've been working with SSIS and Informatica Intelligent Cloud Services this months and I want to know what do you think about. Are these tools outdated? is it a valuable skill and should I keep learning? Or shoud I try to use other tools in my job. I want to learn other tools in my free time but right now I'm having problems finding some. Thanks in advance!", "author_fullname": "t2_2b0vnvfy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about the stack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zahp81", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669975409.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I have recently graduated and I&amp;#39;ve been working 3 months as a Junior Data Engineer in a tech consulting company (a body rental company) in Spain. Currently I don&amp;#39;t know most of the tools/skills I hear about in this sub (Airflow, Docker...) and we are not using them either. I&amp;#39;ve been working with SSIS and Informatica Intelligent Cloud Services this months and I want to know what do you think about. Are these tools outdated? is it a valuable skill and should I keep learning? Or shoud I try to use other tools in my job. I want to learn other tools in my free time but right now I&amp;#39;m having problems finding some. Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zahp81", "is_robot_indexable": true, "report_reasons": null, "author": "jota_point", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zahp81/question_about_the_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zahp81/question_about_the_stack/", "subreddit_subscribers": 81702, "created_utc": 1669975409.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone!\n\nSo our team has planned to use Airflow (MWAA) to run the jobs. Is it possible to trigger/ track job information using Control M? \n\nI'm pretty new to these orchestration tools, so any help would be really appreciated!", "author_fullname": "t2_5hwgf7ph", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Control - M and MWA Airflow Integration?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zahl8k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669975129.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone!&lt;/p&gt;\n\n&lt;p&gt;So our team has planned to use Airflow (MWAA) to run the jobs. Is it possible to trigger/ track job information using Control M? &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m pretty new to these orchestration tools, so any help would be really appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zahl8k", "is_robot_indexable": true, "report_reasons": null, "author": "fullyloadedkid", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zahl8k/control_m_and_mwa_airflow_integration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zahl8k/control_m_and_mwa_airflow_integration/", "subreddit_subscribers": 81702, "created_utc": 1669975129.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello!\n\nWe have a good amount of data (around 700Gb) that we need to move from Redshift to an RDS table. The data has been unloaded into an S3 in parallel (data\\_000\\_part0, data\\_001\\_part0, etc...) with a manifest file. It does not seem that we can load data from S3 to RDS thanks to the manifest file, as we would do with Redshift: [https://docs.aws.amazon.com/redshift/latest/dg/t\\_Reloading\\_unload\\_files.html](https://docs.aws.amazon.com/redshift/latest/dg/t_Reloading_unload_files.html)\n\nIn this case, would the only solution be to loop over all the unloaded files in the S3 bucket and perform the `aws_s3.table_import_from_s3`, or did I miss a parameter in this command that would accept the manifest file?\n\nI don't really have time to implement another solution and would be glad to keep the process as it is, and find a workaround with `aws_s3.table_import_from_s3`.\n\n Thanks!", "author_fullname": "t2_f1ixi4vt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to move data from Redshift to S3 and then from S3 to RDS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zaglxw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669971701.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;We have a good amount of data (around 700Gb) that we need to move from Redshift to an RDS table. The data has been unloaded into an S3 in parallel (data_000_part0, data_001_part0, etc...) with a manifest file. It does not seem that we can load data from S3 to RDS thanks to the manifest file, as we would do with Redshift: &lt;a href=\"https://docs.aws.amazon.com/redshift/latest/dg/t_Reloading_unload_files.html\"&gt;https://docs.aws.amazon.com/redshift/latest/dg/t_Reloading_unload_files.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;In this case, would the only solution be to loop over all the unloaded files in the S3 bucket and perform the &lt;code&gt;aws_s3.table_import_from_s3&lt;/code&gt;, or did I miss a parameter in this command that would accept the manifest file?&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t really have time to implement another solution and would be glad to keep the process as it is, and find a workaround with &lt;code&gt;aws_s3.table_import_from_s3&lt;/code&gt;.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zaglxw", "is_robot_indexable": true, "report_reasons": null, "author": "No_Fudge1060", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zaglxw/best_way_to_move_data_from_redshift_to_s3_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zaglxw/best_way_to_move_data_from_redshift_to_s3_and/", "subreddit_subscribers": 81702, "created_utc": 1669971701.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://www.youtube.com/watch?v=0x-\\_2QJyccs](https://www.youtube.com/watch?v=0x-_2QJyccs)", "author_fullname": "t2_17cxf7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks workspace and community edition", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zbawyo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1670053531.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=0x-_2QJyccs\"&gt;https://www.youtube.com/watch?v=0x-_2QJyccs&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/wzxtpgObEHeRiGIsBSs6AMfQOtPeFs3rQlAsYguCqOw.jpg?auto=webp&amp;s=c511512fe4fd9556e304bae16bd6e771e1776e3c", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/wzxtpgObEHeRiGIsBSs6AMfQOtPeFs3rQlAsYguCqOw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9d89f055e85cfcddb9de00f72ef795525594c55a", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/wzxtpgObEHeRiGIsBSs6AMfQOtPeFs3rQlAsYguCqOw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=db05808b07152e47a7cbd3baba6cb91580b82c2f", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/wzxtpgObEHeRiGIsBSs6AMfQOtPeFs3rQlAsYguCqOw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=baa886081aa9e1d871cbcca9251d26c75c5c58f3", "width": 320, "height": 240}], "variants": {}, "id": "pJ7svDTLOGCuK9fgyZt7OR1qn2MT-tre-ot7m4NYb3w"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "zbawyo", "is_robot_indexable": true, "report_reasons": null, "author": "AdityaSinghRathi", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zbawyo/databricks_workspace_and_community_edition/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zbawyo/databricks_workspace_and_community_edition/", "subreddit_subscribers": 81702, "created_utc": 1670053531.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://www.youtube.com/watch?v=0x-\\_2QJyccs](https://www.youtube.com/watch?v=0x-_2QJyccs)", "author_fullname": "t2_17cxf7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks workspace and community edition", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zbawqw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1670053508.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=0x-_2QJyccs\"&gt;https://www.youtube.com/watch?v=0x-_2QJyccs&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/wzxtpgObEHeRiGIsBSs6AMfQOtPeFs3rQlAsYguCqOw.jpg?auto=webp&amp;s=c511512fe4fd9556e304bae16bd6e771e1776e3c", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/wzxtpgObEHeRiGIsBSs6AMfQOtPeFs3rQlAsYguCqOw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9d89f055e85cfcddb9de00f72ef795525594c55a", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/wzxtpgObEHeRiGIsBSs6AMfQOtPeFs3rQlAsYguCqOw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=db05808b07152e47a7cbd3baba6cb91580b82c2f", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/wzxtpgObEHeRiGIsBSs6AMfQOtPeFs3rQlAsYguCqOw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=baa886081aa9e1d871cbcca9251d26c75c5c58f3", "width": 320, "height": 240}], "variants": {}, "id": "pJ7svDTLOGCuK9fgyZt7OR1qn2MT-tre-ot7m4NYb3w"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zbawqw", "is_robot_indexable": true, "report_reasons": null, "author": "AdityaSinghRathi", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zbawqw/databricks_workspace_and_community_edition/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zbawqw/databricks_workspace_and_community_edition/", "subreddit_subscribers": 81702, "created_utc": 1670053508.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://www.youtube.com/watch?v=0x-\\_2QJyccs](https://www.youtube.com/watch?v=0x-_2QJyccs)", "author_fullname": "t2_17cxf7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks workspace and community edition", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zbawdz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1670053469.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=0x-_2QJyccs\"&gt;https://www.youtube.com/watch?v=0x-_2QJyccs&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/wzxtpgObEHeRiGIsBSs6AMfQOtPeFs3rQlAsYguCqOw.jpg?auto=webp&amp;s=c511512fe4fd9556e304bae16bd6e771e1776e3c", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/wzxtpgObEHeRiGIsBSs6AMfQOtPeFs3rQlAsYguCqOw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9d89f055e85cfcddb9de00f72ef795525594c55a", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/wzxtpgObEHeRiGIsBSs6AMfQOtPeFs3rQlAsYguCqOw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=db05808b07152e47a7cbd3baba6cb91580b82c2f", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/wzxtpgObEHeRiGIsBSs6AMfQOtPeFs3rQlAsYguCqOw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=baa886081aa9e1d871cbcca9251d26c75c5c58f3", "width": 320, "height": 240}], "variants": {}, "id": "pJ7svDTLOGCuK9fgyZt7OR1qn2MT-tre-ot7m4NYb3w"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zbawdz", "is_robot_indexable": true, "report_reasons": null, "author": "AdityaSinghRathi", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zbawdz/databricks_workspace_and_community_edition/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zbawdz/databricks_workspace_and_community_edition/", "subreddit_subscribers": 81702, "created_utc": 1670053469.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Started applying two weeks ago, and lots of rejection letter has poured in. I know that's normal but i would really appreciate your feedback on my resume.", "author_fullname": "t2_jvuhrmb0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "From Data Analyst to Junior Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zb8yi0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670046379.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Started applying two weeks ago, and lots of rejection letter has poured in. I know that&amp;#39;s normal but i would really appreciate your feedback on my resume.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "zb8yi0", "is_robot_indexable": true, "report_reasons": null, "author": "Necessary-Factor8861", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zb8yi0/from_data_analyst_to_junior_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zb8yi0/from_data_analyst_to_junior_data_engineer/", "subreddit_subscribers": 81702, "created_utc": 1670046379.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_mh2cfxap", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Panel] Data, Meet Ops: How the Data Team can Take a Leadership Role | Attend live or watch on demand, Dec 20, 2022, 10 AM PT.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_zb2hqc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ODM6GE-_Q9Yi3efQNz6F8A73dHNqTX3CrznDDWJeHJI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670026435.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "getcensus.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.getcensus.com/events/panel-data-meet-ops-how-the-data-team-can-take-a-leadership-role", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JdF7V774hgOpAs_i73wo3gJTLZ3IHo22w_rnJ406ikU.jpg?auto=webp&amp;s=bc3f5d5b2f04b6fde3d8e5193fd41cffe1cf5545", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/JdF7V774hgOpAs_i73wo3gJTLZ3IHo22w_rnJ406ikU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a9cfb8aa9e08c621f65b4efa4dc3cfdd64ce197b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/JdF7V774hgOpAs_i73wo3gJTLZ3IHo22w_rnJ406ikU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3a3c7d3de660320c1dbda8b267c00fe5c8d83861", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/JdF7V774hgOpAs_i73wo3gJTLZ3IHo22w_rnJ406ikU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fc67252155811487bc6b2f50df4234f67d9f9b2b", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/JdF7V774hgOpAs_i73wo3gJTLZ3IHo22w_rnJ406ikU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=71a990bb4ffab7aa72e86b121953d33073b38b7c", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/JdF7V774hgOpAs_i73wo3gJTLZ3IHo22w_rnJ406ikU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2038afda7e25804279836e84e8427e1ca417a4df", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/JdF7V774hgOpAs_i73wo3gJTLZ3IHo22w_rnJ406ikU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a70047f17c19843d3e65efa46e37f5a495edb75f", "width": 1080, "height": 565}], "variants": {}, "id": "-o-8SLKUWlRTGfL4YHVUOOguYOxb229vV8n7bpn4cJM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zb2hqc", "is_robot_indexable": true, "report_reasons": null, "author": "whb2030", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zb2hqc/panel_data_meet_ops_how_the_data_team_can_take_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.getcensus.com/events/panel-data-meet-ops-how-the-data-team-can-take-a-leadership-role", "subreddit_subscribers": 81702, "created_utc": 1670026435.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am working on a side project that consists of extracting  XML dataset stored in oracle, enriching it (rename, conversion to json) and then saving it on MongoDB.\n\nThe next step would be building a pipeline that move data from Mongo to the Data Warehouse on SqlServer.\n\nIs using mongodb in this case considered overkill ?\n\nReasons of usage:\n\n- Schema flexibility\n- Fast reads (for multithreaded pipelines).\n- Data compression(this is important because the dataset contains more than 300 tables with couple tables having few billions of rows).\n- good support for restful services\n- good support for alerts and notifications using change streams.\n\nWhat do you think ? Any advice is more than welcome.", "author_fullname": "t2_lzlbzvf6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any ideas on this ? Oracle(XMLType) -Enrichement:--&gt; MongoDB ---&gt; SQLServer(DW)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zb1qge", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1670024825.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670024368.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working on a side project that consists of extracting  XML dataset stored in oracle, enriching it (rename, conversion to json) and then saving it on MongoDB.&lt;/p&gt;\n\n&lt;p&gt;The next step would be building a pipeline that move data from Mongo to the Data Warehouse on SqlServer.&lt;/p&gt;\n\n&lt;p&gt;Is using mongodb in this case considered overkill ?&lt;/p&gt;\n\n&lt;p&gt;Reasons of usage:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Schema flexibility&lt;/li&gt;\n&lt;li&gt;Fast reads (for multithreaded pipelines).&lt;/li&gt;\n&lt;li&gt;Data compression(this is important because the dataset contains more than 300 tables with couple tables having few billions of rows).&lt;/li&gt;\n&lt;li&gt;good support for restful services&lt;/li&gt;\n&lt;li&gt;good support for alerts and notifications using change streams.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What do you think ? Any advice is more than welcome.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zb1qge", "is_robot_indexable": true, "report_reasons": null, "author": "Icy_Region3025", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zb1qge/any_ideas_on_this_oraclexmltype_enrichement/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zb1qge/any_ideas_on_this_oraclexmltype_enrichement/", "subreddit_subscribers": 81702, "created_utc": 1670024368.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In attempt to optimize our structured streaming, we're looking to place a timestamp in each step of the DAG. We have a logging query listener that we can extract the amount of rows we've processed:\n\n    override def onQueryProgress(event: StreamingQueryListener.QueryProgressEvent): Unit = {     log.info(s\"${jobId} executionTime=${event.progress.durationMs.get(\"triggerExecution\")}\")      log.info(s\"${jobId} progress=${event.progress}\")     event.progress.sources.foreach { source =&gt;       log.info(s\"${jobId} source=${source.description} processed=${source.numInputRows} tps=${source.processedRowsPerSecond}\")     }   } \n\nWe've placed this in the DAG. How can we place a timestamp in each step of the DAG, can it be in the listener or a custom method is preferred?\n\nThe high-level static DAG:\n\n1. Unionize all event streams\n2. Join the streams if applicable\n3. Parse and group the unionized stream\n4. Featurize the streams while manipulating the structured state\n5. Sink the streams\n6. Await termination\n\nHere's how we add the listener to spark:\n\n    loggingQueryListener = new LoggingQueryListener(s\"AAA-${jobId}\") spark.streams.addListener(loggingQueryListener)", "author_fullname": "t2_1tbzh2ae", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark Structured Streaming DAG: How to add timestamps in parsing, grouping, &amp; featurize steps so I can determine how long each step takes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zazy3t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670020067.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In attempt to optimize our structured streaming, we&amp;#39;re looking to place a timestamp in each step of the DAG. We have a logging query listener that we can extract the amount of rows we&amp;#39;ve processed:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;override def onQueryProgress(event: StreamingQueryListener.QueryProgressEvent): Unit = {     log.info(s&amp;quot;${jobId} executionTime=${event.progress.durationMs.get(&amp;quot;triggerExecution&amp;quot;)}&amp;quot;)      log.info(s&amp;quot;${jobId} progress=${event.progress}&amp;quot;)     event.progress.sources.foreach { source =&amp;gt;       log.info(s&amp;quot;${jobId} source=${source.description} processed=${source.numInputRows} tps=${source.processedRowsPerSecond}&amp;quot;)     }   } \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;We&amp;#39;ve placed this in the DAG. How can we place a timestamp in each step of the DAG, can it be in the listener or a custom method is preferred?&lt;/p&gt;\n\n&lt;p&gt;The high-level static DAG:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Unionize all event streams&lt;/li&gt;\n&lt;li&gt;Join the streams if applicable&lt;/li&gt;\n&lt;li&gt;Parse and group the unionized stream&lt;/li&gt;\n&lt;li&gt;Featurize the streams while manipulating the structured state&lt;/li&gt;\n&lt;li&gt;Sink the streams&lt;/li&gt;\n&lt;li&gt;Await termination&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Here&amp;#39;s how we add the listener to spark:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;loggingQueryListener = new LoggingQueryListener(s&amp;quot;AAA-${jobId}&amp;quot;) spark.streams.addListener(loggingQueryListener)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zazy3t", "is_robot_indexable": true, "report_reasons": null, "author": "TeslaMecca", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zazy3t/spark_structured_streaming_dag_how_to_add/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zazy3t/spark_structured_streaming_dag_how_to_add/", "subreddit_subscribers": 81702, "created_utc": 1670020067.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "It seems peoples rarely talk about data governance in this subreddit. Is data engineer the right team for data governance project? Can someone share about the most important thing to do when doing this kind of project. What will be first thing you would do if this is the first data governance project in your company? I know this topic will be really wide, but I just wanna hear peoples story about it.", "author_fullname": "t2_tm5irceo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Governance Project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zas8xy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670002716.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It seems peoples rarely talk about data governance in this subreddit. Is data engineer the right team for data governance project? Can someone share about the most important thing to do when doing this kind of project. What will be first thing you would do if this is the first data governance project in your company? I know this topic will be really wide, but I just wanna hear peoples story about it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zas8xy", "is_robot_indexable": true, "report_reasons": null, "author": "natas_m", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zas8xy/data_governance_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zas8xy/data_governance_project/", "subreddit_subscribers": 81702, "created_utc": 1670002716.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, just wondered if anyone had experience with Databricks and the way they handle model promotion. I find it quite counter intuitive but I might not have the right intuition.\n\nIn their MLOps implementation, they promote models from a \"Staging\" state to a \"Production\" state. However as soon as a model is promoted, all testing pipelines relying on a model in \"Staging\" state break, since there is no longer any model in that state. So when testing just code changes, we'd need first to save a new model in \"Staging\", instead or reusing the model that was already there. Strong vibes of pipeline smell, but I might not be seeing an obvious clean solution.\n\nIf anyone has any idea, that would lighten up my day!", "author_fullname": "t2_lh1thuv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks &amp; Model Registry", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zan66d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669989959.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, just wondered if anyone had experience with Databricks and the way they handle model promotion. I find it quite counter intuitive but I might not have the right intuition.&lt;/p&gt;\n\n&lt;p&gt;In their MLOps implementation, they promote models from a &amp;quot;Staging&amp;quot; state to a &amp;quot;Production&amp;quot; state. However as soon as a model is promoted, all testing pipelines relying on a model in &amp;quot;Staging&amp;quot; state break, since there is no longer any model in that state. So when testing just code changes, we&amp;#39;d need first to save a new model in &amp;quot;Staging&amp;quot;, instead or reusing the model that was already there. Strong vibes of pipeline smell, but I might not be seeing an obvious clean solution.&lt;/p&gt;\n\n&lt;p&gt;If anyone has any idea, that would lighten up my day!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zan66d", "is_robot_indexable": true, "report_reasons": null, "author": "aupagizon", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zan66d/databricks_model_registry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zan66d/databricks_model_registry/", "subreddit_subscribers": 81702, "created_utc": 1669989959.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI am a data engineer (mostly on azure tech)  from philippines and I am having a hard time to find job overseas. Browsing on some companies in linkedin, I haven't found yet any company that will provide work visa but when broswing through other tech (c#, java ,front  end) some of them does provide.\n\nIs it me or data engineering with azure is not as in-demand right now?", "author_fullname": "t2_1o3gtlar", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "So hard to find a job overseas - Azure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zb2d93", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670026075.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I am a data engineer (mostly on azure tech)  from philippines and I am having a hard time to find job overseas. Browsing on some companies in linkedin, I haven&amp;#39;t found yet any company that will provide work visa but when broswing through other tech (c#, java ,front  end) some of them does provide.&lt;/p&gt;\n\n&lt;p&gt;Is it me or data engineering with azure is not as in-demand right now?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zb2d93", "is_robot_indexable": true, "report_reasons": null, "author": "aljandeleon", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zb2d93/so_hard_to_find_a_job_overseas_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zb2d93/so_hard_to_find_a_job_overseas_azure/", "subreddit_subscribers": 81702, "created_utc": 1670026075.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_mh2cfxap", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interesting Survey on LinkedIn: How much does data engineering overlap with software engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 64, "top_awarded_type": null, "hide_score": false, "name": "t3_zb0k0r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 64, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/-59hKcLIq6o1vRVPHKh1-blm4nS3EC-XeGsbA9iWjYE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670021394.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "linkedin.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.linkedin.com/posts/eczachly_softwareengineering-dataengineering-activity-7004253697153105920-FFEn?utm_source=share&amp;utm_medium=member_desktop", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5ZI7oL3JTPPt59G0vTfOaQMHvka17QCAdFnF87leUeA.jpg?auto=webp&amp;s=52cc36e047bdca039326e84d3b7ce7aabaf12be6", "width": 64, "height": 64}, "resolutions": [], "variants": {}, "id": "QqSY3F9i2BgB-OdT_JpQr1vBqr2oq4spYNzkghHXwCM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zb0k0r", "is_robot_indexable": true, "report_reasons": null, "author": "whb2030", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zb0k0r/interesting_survey_on_linkedin_how_much_does_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.linkedin.com/posts/eczachly_softwareengineering-dataengineering-activity-7004253697153105920-FFEn?utm_source=share&amp;utm_medium=member_desktop", "subreddit_subscribers": 81702, "created_utc": 1670021394.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}