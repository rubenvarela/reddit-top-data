{"kind": "Listing", "data": {"after": null, "dist": 17, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Yall,\n\nBackground: I have been in Healthcare for \\~4 years as a general product manager and was recently part of a mass layoff. I found an opportunity at a really interesting startup (Series A) to be their data product manager and gladly accepted (Feb 6 start date). I know my way around FHIR and HL7, but I thought this would be overseeing the data side of things from a much higher-level. THAT IS NOT THE CASE.\n\nI was informed this Friday that their current data pipeline and integrations are shabby at best and they are looking for what amounts to a complete overhaul with this new position dictating all the nitty gritty details on how it should be built, what tech stack to utilize, and other additional items.\n\nEssentially it would be:\n\n* Patient EHR FHIR data ingest via REST\n* \\-&gt; ETL (general I know)\n* \\-&gt; Reporting and Analytics Platform + surfacing some data to users/patients\n\nWhere on earth should I get started with learning how to tackle this with only high-level understanding of data pipelines? Also, what tech stack do I start with learning?\n\nI am honestly contemplating just dropping the job and interviewing elsewhere, but the pay is really good compared to the other offers i've been getting. Any advice would be greatly appreciated, thank you.\n\n&amp;#x200B;\n\nEDIT: It seems the company at least currently uses AWS EMR and Databricks, if that helps in any way.", "author_fullname": "t2_7sk48", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "1.5 months to learn as much data engineering as I can before new job, where do I even start?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zos8hp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1671347715.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671345848.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Yall,&lt;/p&gt;\n\n&lt;p&gt;Background: I have been in Healthcare for ~4 years as a general product manager and was recently part of a mass layoff. I found an opportunity at a really interesting startup (Series A) to be their data product manager and gladly accepted (Feb 6 start date). I know my way around FHIR and HL7, but I thought this would be overseeing the data side of things from a much higher-level. THAT IS NOT THE CASE.&lt;/p&gt;\n\n&lt;p&gt;I was informed this Friday that their current data pipeline and integrations are shabby at best and they are looking for what amounts to a complete overhaul with this new position dictating all the nitty gritty details on how it should be built, what tech stack to utilize, and other additional items.&lt;/p&gt;\n\n&lt;p&gt;Essentially it would be:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Patient EHR FHIR data ingest via REST&lt;/li&gt;\n&lt;li&gt;-&amp;gt; ETL (general I know)&lt;/li&gt;\n&lt;li&gt;-&amp;gt; Reporting and Analytics Platform + surfacing some data to users/patients&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Where on earth should I get started with learning how to tackle this with only high-level understanding of data pipelines? Also, what tech stack do I start with learning?&lt;/p&gt;\n\n&lt;p&gt;I am honestly contemplating just dropping the job and interviewing elsewhere, but the pay is really good compared to the other offers i&amp;#39;ve been getting. Any advice would be greatly appreciated, thank you.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;EDIT: It seems the company at least currently uses AWS EMR and Databricks, if that helps in any way.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zos8hp", "is_robot_indexable": true, "report_reasons": null, "author": "antassantas", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zos8hp/15_months_to_learn_as_much_data_engineering_as_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zos8hp/15_months_to_learn_as_much_data_engineering_as_i/", "subreddit_subscribers": 83226, "created_utc": 1671345848.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[DuckDB](https://duckdb.org/) (an in-process SQL OLAP database management system) is gaining a lot of popularity these days. So, we created a new monthly newsletter to keep you updated about the last projects, articles, resources, videos, and everything related to DuckDB. You can read the first issue here:\n\n[https://motherduck.com/blog/duckdb-ecosystem-newsletter-one/](https://motherduck.com/blog/duckdb-ecosystem-newsletter-one/)", "author_fullname": "t2_ugjew", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New monthly newsletter related to DuckDB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zoetye", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1671307527.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://duckdb.org/\"&gt;DuckDB&lt;/a&gt; (an in-process SQL OLAP database management system) is gaining a lot of popularity these days. So, we created a new monthly newsletter to keep you updated about the last projects, articles, resources, videos, and everything related to DuckDB. You can read the first issue here:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://motherduck.com/blog/duckdb-ecosystem-newsletter-one/\"&gt;https://motherduck.com/blog/duckdb-ecosystem-newsletter-one/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/GctXJNpN2X3nQLnJV4YKiGNicM-bQELTDEHwQJ3tLlo.jpg?auto=webp&amp;s=df4fb13c0741919fd9f695ba304cb6d3a1fb56ed", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/GctXJNpN2X3nQLnJV4YKiGNicM-bQELTDEHwQJ3tLlo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5ac7c3882de773b950cd2e3cd83aba08b84d6fa7", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/GctXJNpN2X3nQLnJV4YKiGNicM-bQELTDEHwQJ3tLlo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e011b38bce0303748d54aed1967329a61ba0bf14", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/GctXJNpN2X3nQLnJV4YKiGNicM-bQELTDEHwQJ3tLlo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=28287676b7e382af057ff233ebabb92eb44395da", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/GctXJNpN2X3nQLnJV4YKiGNicM-bQELTDEHwQJ3tLlo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=17a7e3ab4756e9f324d7dfbf41f4877a51c3a790", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/GctXJNpN2X3nQLnJV4YKiGNicM-bQELTDEHwQJ3tLlo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b38599a9c28c8b8760b7158ed21e418d1d88ff32", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/GctXJNpN2X3nQLnJV4YKiGNicM-bQELTDEHwQJ3tLlo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4eaa0d481f6cb0b5bde29d1b7160f655cc8a2cc8", "width": 1080, "height": 567}], "variants": {}, "id": "jWyiaF4Jb7ULQyU8SCl75THeEbJM9dbSQ9YXdauXufk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zoetye", "is_robot_indexable": true, "report_reasons": null, "author": "marcosluis2186", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zoetye/new_monthly_newsletter_related_to_duckdb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zoetye/new_monthly_newsletter_related_to_duckdb/", "subreddit_subscribers": 83226, "created_utc": 1671307527.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "*Context:* Team Lead in a primarily AWS environment. We do not use Airflow now and I\u2019m investigating benefits over our current setup.  \n\nI don\u2019t see anything on the ol\u2019 Google and can\u2019t find much in the subreddit that indicates what we do is common but also nothing indicates it is bad design.. maybe additional coding required is all. \n\nWe just kick off ingest EC2 clusters that use Spark and stage data into s3, then clean it and ship it to our data warehouse. What we do to monitor and kick off each step is a combination of EventBridge and Lambda functions. That is basically it though.\n\nWant to get thoughts.. sorry I know it\u2019s not super detailed but would rather not publicly post the super intricate details of the pipeline. If you want more I can DM a few more details.\n\nThank you all!", "author_fullname": "t2_gz1dn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS EventBridge with Lambda as an orchestrator", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zoi1an", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671315753.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;em&gt;Context:&lt;/em&gt; Team Lead in a primarily AWS environment. We do not use Airflow now and I\u2019m investigating benefits over our current setup.  &lt;/p&gt;\n\n&lt;p&gt;I don\u2019t see anything on the ol\u2019 Google and can\u2019t find much in the subreddit that indicates what we do is common but also nothing indicates it is bad design.. maybe additional coding required is all. &lt;/p&gt;\n\n&lt;p&gt;We just kick off ingest EC2 clusters that use Spark and stage data into s3, then clean it and ship it to our data warehouse. What we do to monitor and kick off each step is a combination of EventBridge and Lambda functions. That is basically it though.&lt;/p&gt;\n\n&lt;p&gt;Want to get thoughts.. sorry I know it\u2019s not super detailed but would rather not publicly post the super intricate details of the pipeline. If you want more I can DM a few more details.&lt;/p&gt;\n\n&lt;p&gt;Thank you all!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zoi1an", "is_robot_indexable": true, "report_reasons": null, "author": "frankenbenz", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zoi1an/aws_eventbridge_with_lambda_as_an_orchestrator/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zoi1an/aws_eventbridge_with_lambda_as_an_orchestrator/", "subreddit_subscribers": 83226, "created_utc": 1671315753.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've watched a couple of videos in Scala for Spark and the language seemed really understandable and well structured for me. Although, I don't quite understand if using Scala is beneficial for Spark (over Python + PySpark, for example) as it's still executing on the same Spark kernel.\nWhat is Scala usually used for in the modern data stack?", "author_fullname": "t2_1qtw7ivc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the advantage of Scala over Python in DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zou6p4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671353517.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve watched a couple of videos in Scala for Spark and the language seemed really understandable and well structured for me. Although, I don&amp;#39;t quite understand if using Scala is beneficial for Spark (over Python + PySpark, for example) as it&amp;#39;s still executing on the same Spark kernel.\nWhat is Scala usually used for in the modern data stack?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zou6p4", "is_robot_indexable": true, "report_reasons": null, "author": "redcat10601", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zou6p4/what_is_the_advantage_of_scala_over_python_in_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zou6p4/what_is_the_advantage_of_scala_over_python_in_de/", "subreddit_subscribers": 83226, "created_utc": 1671353517.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I've learned how to use T-SQL in SMSS. I want to get some practise in making a database with raw/unprocessed data. Do such sources exist? What format would they be in as opposed to being organised into tables? Are there any reliable suggestions you can give?\n\nThanks in advance.", "author_fullname": "t2_tv2a43m8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Raw Data Sources for Practise in Building Databases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zog2ic", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671310761.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;ve learned how to use T-SQL in SMSS. I want to get some practise in making a database with raw/unprocessed data. Do such sources exist? What format would they be in as opposed to being organised into tables? Are there any reliable suggestions you can give?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zog2ic", "is_robot_indexable": true, "report_reasons": null, "author": "headrazor", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zog2ic/raw_data_sources_for_practise_in_building/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zog2ic/raw_data_sources_for_practise_in_building/", "subreddit_subscribers": 83226, "created_utc": 1671310761.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m working on a personal project to work on my DE skills. From what I\u2019ve read ELT seems to be better than ETL nowadays.  I have an api I want to pull from and will orchestrate in airflow to store the json in s3 or GCS.  Once it\u2019s in storage I\u2019m a little lost on the best method to then transform this json and put it in my Postgres instance.  Should I just create another airflow task and use a python operator to run another python script to do the transformation?\n\nThanks in advance", "author_fullname": "t2_dqlps", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best option for T in ELT Project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zoi81y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671316245.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m working on a personal project to work on my DE skills. From what I\u2019ve read ELT seems to be better than ETL nowadays.  I have an api I want to pull from and will orchestrate in airflow to store the json in s3 or GCS.  Once it\u2019s in storage I\u2019m a little lost on the best method to then transform this json and put it in my Postgres instance.  Should I just create another airflow task and use a python operator to run another python script to do the transformation?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zoi81y", "is_robot_indexable": true, "report_reasons": null, "author": "dynamex1097", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zoi81y/best_option_for_t_in_elt_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zoi81y/best_option_for_t_in_elt_project/", "subreddit_subscribers": 83226, "created_utc": 1671316245.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been working as a data engineer for couple of years now. Working with Azure databricks and ADLS(for storage). Used delta tables based on ADLS when required.\n\nMy time with PySpark has made me just about competent with the syntax. Given the requirements I can go ahead and create notebooks that achieve the ETL requirements. Have also tried understanding how a spark job runs under the hood at a high level.  \nI have joined a project recently where we are building an application from scratch. As per the architecture we have Azure Data factory and microservices working in tandem to move from one step to another(orchestrators and conmmunicating b/w serives). The Databricks notebooks will be given the appropriate configurations and input data sets as per the design. And Databricks will be doing the heavy lifting calculations on the input datasets and write the output data as delta tables.\n\n I have realized that the notebooks I created in my earlier projects were heavy(long single notebooks) and had lot of duplicate code across notebooks. Have hit notebook performance issues too.\n\nI want to be better at designing a pipeline for this project. The aim is to deliver a efficient, lean and modularized code that has low tech debt and required minimum code changes when new input datasets are added in the application in future.   \nAlso would love to learn about ingenuous configurations strategies (have kept my configs in normal csv and read as dataframe mostly till now; just recently started using json).\n\nPlease share how you became better at designing your pipelines. Any good examples of projects(with code repos) that are elegant and can be studied would also help. Or just plain books or study material that can help.\n\nThanks in advance.", "author_fullname": "t2_as8ip02m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help to Level-up as a PySpark developer. Need guidance on how to structure my code.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zoxlih", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671366704.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been working as a data engineer for couple of years now. Working with Azure databricks and ADLS(for storage). Used delta tables based on ADLS when required.&lt;/p&gt;\n\n&lt;p&gt;My time with PySpark has made me just about competent with the syntax. Given the requirements I can go ahead and create notebooks that achieve the ETL requirements. Have also tried understanding how a spark job runs under the hood at a high level.&lt;br/&gt;\nI have joined a project recently where we are building an application from scratch. As per the architecture we have Azure Data factory and microservices working in tandem to move from one step to another(orchestrators and conmmunicating b/w serives). The Databricks notebooks will be given the appropriate configurations and input data sets as per the design. And Databricks will be doing the heavy lifting calculations on the input datasets and write the output data as delta tables.&lt;/p&gt;\n\n&lt;p&gt;I have realized that the notebooks I created in my earlier projects were heavy(long single notebooks) and had lot of duplicate code across notebooks. Have hit notebook performance issues too.&lt;/p&gt;\n\n&lt;p&gt;I want to be better at designing a pipeline for this project. The aim is to deliver a efficient, lean and modularized code that has low tech debt and required minimum code changes when new input datasets are added in the application in future.&lt;br/&gt;\nAlso would love to learn about ingenuous configurations strategies (have kept my configs in normal csv and read as dataframe mostly till now; just recently started using json).&lt;/p&gt;\n\n&lt;p&gt;Please share how you became better at designing your pipelines. Any good examples of projects(with code repos) that are elegant and can be studied would also help. Or just plain books or study material that can help.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zoxlih", "is_robot_indexable": true, "report_reasons": null, "author": "Independent-Time-551", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zoxlih/help_to_levelup_as_a_pyspark_developer_need/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zoxlih/help_to_levelup_as_a_pyspark_developer_need/", "subreddit_subscribers": 83226, "created_utc": 1671366704.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys,\nFrom your experience, what models would you consider for product assortment/range optimisation for FMCG retail sector\n( i.e getting the right product range in the right store/ product placement).\n\nI\u2019ve seen some use XGBoost for product placement, but curious to know what other models work well.\n\nI know we have to take product substitution into consideration so Customer Decision Tree Model is already taken care of.", "author_fullname": "t2_idusno00", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Product assortment/ range optimisation for FMCG", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zoldtb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671324154.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,\nFrom your experience, what models would you consider for product assortment/range optimisation for FMCG retail sector\n( i.e getting the right product range in the right store/ product placement).&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve seen some use XGBoost for product placement, but curious to know what other models work well.&lt;/p&gt;\n\n&lt;p&gt;I know we have to take product substitution into consideration so Customer Decision Tree Model is already taken care of.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zoldtb", "is_robot_indexable": true, "report_reasons": null, "author": "Maria_Adel", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zoldtb/product_assortment_range_optimisation_for_fmcg/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zoldtb/product_assortment_range_optimisation_for_fmcg/", "subreddit_subscribers": 83226, "created_utc": 1671324154.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_uypc8pwv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineer vs Senior Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 89, "top_awarded_type": null, "hide_score": true, "name": "t3_zoyze6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/TylQG7jA_hQLN04qINrOtJYYPIEjIzOlzX_Fbv18zPI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671371160.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dataengineeringcentral.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://dataengineeringcentral.substack.com/p/data-engineer-vs-senior-data-engineer", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/GxlhFVictSdqj7XYLai8Wuux9fofCp1y1i1kI4rQgdA.jpg?auto=webp&amp;s=537d4e7376ed97065e3adee58a61cfc65159bfd6", "width": 942, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/GxlhFVictSdqj7XYLai8Wuux9fofCp1y1i1kI4rQgdA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9248dbb376d0e3b92b3abe158fbb5dabbf7de8ac", "width": 108, "height": 68}, {"url": "https://external-preview.redd.it/GxlhFVictSdqj7XYLai8Wuux9fofCp1y1i1kI4rQgdA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=512c9ac958cdbb5f3066ec8cc014d4030624053b", "width": 216, "height": 137}, {"url": "https://external-preview.redd.it/GxlhFVictSdqj7XYLai8Wuux9fofCp1y1i1kI4rQgdA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5c99d2e12879f0411ee9f24bab1ea3f12b6b779f", "width": 320, "height": 203}, {"url": "https://external-preview.redd.it/GxlhFVictSdqj7XYLai8Wuux9fofCp1y1i1kI4rQgdA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f8f4f09985bcaac23a896ca7c5ac83ad45add879", "width": 640, "height": 407}], "variants": {}, "id": "7YhDB7i9_L4eH_fQCC93dV0PxGlsfw1YXevAOxHpcG0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zoyze6", "is_robot_indexable": true, "report_reasons": null, "author": "DarkClear3881", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zoyze6/data_engineer_vs_senior_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dataengineeringcentral.substack.com/p/data-engineer-vs-senior-data-engineer", "subreddit_subscribers": 83226, "created_utc": 1671371160.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For past 1 year, I have been handling a lot of data engineering stuff. While my official role was still software engineer, my day to day work was that of a data engineer. Now, my project has ended but company has realized the need for a full time data engineer. Before they hire someone from outside, company has offered me the role first. Company is offering to make it all formal by creating a new data engineer position for me. Alternatively, I can go back to my earlier software engineering role as a Java developer. Which career pathway has more scope and future resiliency? Should I go down the data engineering rabbit hole or should I stick to generic software engineering.", "author_fullname": "t2_t6oufyru", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Company is offering to make me full time data engineer. Should I go into this or should I go back to software engineering. Which path has better career scope?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zoytmj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671370679.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For past 1 year, I have been handling a lot of data engineering stuff. While my official role was still software engineer, my day to day work was that of a data engineer. Now, my project has ended but company has realized the need for a full time data engineer. Before they hire someone from outside, company has offered me the role first. Company is offering to make it all formal by creating a new data engineer position for me. Alternatively, I can go back to my earlier software engineering role as a Java developer. Which career pathway has more scope and future resiliency? Should I go down the data engineering rabbit hole or should I stick to generic software engineering.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zoytmj", "is_robot_indexable": true, "report_reasons": null, "author": "MatchCaseFirst", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zoytmj/company_is_offering_to_make_me_full_time_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zoytmj/company_is_offering_to_make_me_full_time_data/", "subreddit_subscribers": 83226, "created_utc": 1671370679.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm running Hadoop on WSL 2, using [start-all.sh](https://start-all.sh) I'm able to launch the UI interface for YARN at [http://localhost:8088](http://localhost:8088) , in the UI I could see there is 1 active nodeHowever, I couldn't open the namenode interface on port 9870I'm using hadoop 3.3.0\n\nAfter checking service with jps, there is only secondary namenode and data node running, while the name node service is gone.  \n\n\nHere is my core-site.xml:  \n \n\n    &lt;configuration&gt;\n &lt;property&gt;\n &lt;name&gt;fs.defaultFS&lt;/name&gt;\n &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;\n &lt;/property&gt;\n &lt;property&gt;\n &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;\n &lt;value&gt;file:/hadoop/hadoop-3.3.0/tmp&lt;/value&gt;\n &lt;description&gt;&lt;/description&gt;\n &lt;/property&gt;\n&lt;/configuration&gt;\n\nWhile running format for namenode, this query showed up:  \n `Re-format filesystem in Storage Directory root= /hadoop/hadoop-3.3.0/tmp/dfs/name; location= null ? (Y or N)`   \nThen I check the log of namenode, it seems unable to read from filepath:  \n `org.apache.hadoop.util.ExitUtil: Exiting with status 1: java.io.IOException: Could not parse line: Filesystem     1024-blocks      Used Available Capacity Mounted on`\n\n  \nHow could I configure the namenode to make it run?  \nThank you for all the help!", "author_fullname": "t2_11cquw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Running Hadoop, I could launch the Yarn management UI in browser, but unable to launch Namenode interface", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zoy3ry", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1671375302.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671368429.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m running Hadoop on WSL 2, using &lt;a href=\"https://start-all.sh\"&gt;start-all.sh&lt;/a&gt; I&amp;#39;m able to launch the UI interface for YARN at &lt;a href=\"http://localhost:8088\"&gt;http://localhost:8088&lt;/a&gt; , in the UI I could see there is 1 active nodeHowever, I couldn&amp;#39;t open the namenode interface on port 9870I&amp;#39;m using hadoop 3.3.0&lt;/p&gt;\n\n&lt;p&gt;After checking service with jps, there is only secondary namenode and data node running, while the name node service is gone.  &lt;/p&gt;\n\n&lt;p&gt;Here is my core-site.xml:  &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;&amp;lt;configuration&amp;gt;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;lt;property&amp;gt;\n &amp;lt;name&amp;gt;fs.defaultFS&amp;lt;/name&amp;gt;\n &amp;lt;value&amp;gt;hdfs://localhost:9000&amp;lt;/value&amp;gt;\n &amp;lt;/property&amp;gt;\n &amp;lt;property&amp;gt;\n &amp;lt;name&amp;gt;hadoop.tmp.dir&amp;lt;/name&amp;gt;\n &amp;lt;value&amp;gt;file:/hadoop/hadoop-3.3.0/tmp&amp;lt;/value&amp;gt;\n &amp;lt;description&amp;gt;&amp;lt;/description&amp;gt;\n &amp;lt;/property&amp;gt;\n&amp;lt;/configuration&amp;gt;&lt;/p&gt;\n\n&lt;p&gt;While running format for namenode, this query showed up:&lt;br/&gt;\n &lt;code&gt;Re-format filesystem in Storage Directory root= /hadoop/hadoop-3.3.0/tmp/dfs/name; location= null ? (Y or N)&lt;/code&gt;&lt;br/&gt;\nThen I check the log of namenode, it seems unable to read from filepath:&lt;br/&gt;\n &lt;code&gt;org.apache.hadoop.util.ExitUtil: Exiting with status 1: java.io.IOException: Could not parse line: Filesystem     1024-blocks      Used Available Capacity Mounted on&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;How could I configure the namenode to make it run?&lt;br/&gt;\nThank you for all the help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zoy3ry", "is_robot_indexable": true, "report_reasons": null, "author": "Laurence-Lin", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zoy3ry/running_hadoop_i_could_launch_the_yarn_management/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zoy3ry/running_hadoop_i_could_launch_the_yarn_management/", "subreddit_subscribers": 83226, "created_utc": 1671368429.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello redditors, I have exprience 3 yrs of exprience in SAP basis administration. \n\nI'm quite good with SQL, I love the language. I've done some courses in Hadoop, Spark.\n\nI'm bad at self-study. Could you guide me How can I get a junior position / switch to data engineering?\n\nI'm desperately searching for an curriculum that could prepare me for interviews.", "author_fullname": "t2_ced9sbiw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "desparate for a career switch, appreciate any guidance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zoumpw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671355257.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello redditors, I have exprience 3 yrs of exprience in SAP basis administration. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m quite good with SQL, I love the language. I&amp;#39;ve done some courses in Hadoop, Spark.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m bad at self-study. Could you guide me How can I get a junior position / switch to data engineering?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m desperately searching for an curriculum that could prepare me for interviews.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zoumpw", "is_robot_indexable": true, "report_reasons": null, "author": "ElegantAd8474", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zoumpw/desparate_for_a_career_switch_appreciate_any/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zoumpw/desparate_for_a_career_switch_appreciate_any/", "subreddit_subscribers": 83226, "created_utc": 1671355257.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI am an working as a application support specialist at a large HRM software company for over 5 years. I wanted to move to data engineering. I am very proficient in SQL, Excel and Power BI. i have some knowledge of Python, JavaScript and C#. I am preparing for Microsoft DP900 exam then Dp203. However, I am seeking some advice how to land on the first job with these skills.", "author_fullname": "t2_180ek63h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Application support wanted to move to Data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zon077", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671328682.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I am an working as a application support specialist at a large HRM software company for over 5 years. I wanted to move to data engineering. I am very proficient in SQL, Excel and Power BI. i have some knowledge of Python, JavaScript and C#. I am preparing for Microsoft DP900 exam then Dp203. However, I am seeking some advice how to land on the first job with these skills.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zon077", "is_robot_indexable": true, "report_reasons": null, "author": "shuvo3000", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zon077/application_support_wanted_to_move_to_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zon077/application_support_wanted_to_move_to_data/", "subreddit_subscribers": 83226, "created_utc": 1671328682.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know I can research this myself, and I will, but I also wanted to get some input from you.\n\nI have the following:\n\n- Professional experience with Javascript, Typescript and Python\n- Some project work with AWS, like ECS etc, but nothing of IaaC\n- A bit of databases (SQL, Mongo..) from school, projects and internship\n- Some experience setting up CI/CD pipelines (Jenkins, Github actions..)\n\nI\u2019m also extremely confident I can learn by myself \u201canything\u201d\n\nIn my position, what would be the best way to break into data engineering? Any particular certification or personal project you think would help?\n\nWould hugely appreciate any suggestions.", "author_fullname": "t2_cdff2c9r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get a job in Data Engineering as a SWE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zokvzv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671322995.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know I can research this myself, and I will, but I also wanted to get some input from you.&lt;/p&gt;\n\n&lt;p&gt;I have the following:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Professional experience with Javascript, Typescript and Python&lt;/li&gt;\n&lt;li&gt;Some project work with AWS, like ECS etc, but nothing of IaaC&lt;/li&gt;\n&lt;li&gt;A bit of databases (SQL, Mongo..) from school, projects and internship&lt;/li&gt;\n&lt;li&gt;Some experience setting up CI/CD pipelines (Jenkins, Github actions..)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I\u2019m also extremely confident I can learn by myself \u201canything\u201d&lt;/p&gt;\n\n&lt;p&gt;In my position, what would be the best way to break into data engineering? Any particular certification or personal project you think would help?&lt;/p&gt;\n\n&lt;p&gt;Would hugely appreciate any suggestions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zokvzv", "is_robot_indexable": true, "report_reasons": null, "author": "Zealousideal_Post694", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zokvzv/how_to_get_a_job_in_data_engineering_as_a_swe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zokvzv/how_to_get_a_job_in_data_engineering_as_a_swe/", "subreddit_subscribers": 83226, "created_utc": 1671322995.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm building out a simple tech stack to be able to analyze Quickbooks and Hubspot data (and eventually connect with product data).\n\nMy planned tech stack is Quickbooks + Hubspot -&gt; Prefect on Kubernetes -&gt; AWS S3 -&gt; AWS DynamoDB -&gt; Tableau\n\nIs this overkill? Or am I overestimating how difficult this will be?\n\n3 YOE of experience as data scientist in a bigger tech company (a lot of this was done for me before, but I've got a strong technical foundation).", "author_fullname": "t2_jlldx1g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Small Tech Company Tech Stack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zohw0f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671315377.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m building out a simple tech stack to be able to analyze Quickbooks and Hubspot data (and eventually connect with product data).&lt;/p&gt;\n\n&lt;p&gt;My planned tech stack is Quickbooks + Hubspot -&amp;gt; Prefect on Kubernetes -&amp;gt; AWS S3 -&amp;gt; AWS DynamoDB -&amp;gt; Tableau&lt;/p&gt;\n\n&lt;p&gt;Is this overkill? Or am I overestimating how difficult this will be?&lt;/p&gt;\n\n&lt;p&gt;3 YOE of experience as data scientist in a bigger tech company (a lot of this was done for me before, but I&amp;#39;ve got a strong technical foundation).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zohw0f", "is_robot_indexable": true, "report_reasons": null, "author": "PrimoTimes", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zohw0f/small_tech_company_tech_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zohw0f/small_tech_company_tech_stack/", "subreddit_subscribers": 83226, "created_utc": 1671315377.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking at moving to the EU and wondering if anyone has any experience in working D.E roles with English only.\n\nIn Australia I've been on 98k\u20ac for permanent positions or 579\u20ac per day for contract and I'd like to receive a similar amount.\n\nI have an EU passport.", "author_fullname": "t2_99stunfc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any EU D.E's?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zorwxh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "620fb7b8-ac9d-11eb-a99a-0ed5d8300de1", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671344633.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking at moving to the EU and wondering if anyone has any experience in working D.E roles with English only.&lt;/p&gt;\n\n&lt;p&gt;In Australia I&amp;#39;ve been on 98k\u20ac for permanent positions or 579\u20ac per day for contract and I&amp;#39;d like to receive a similar amount.&lt;/p&gt;\n\n&lt;p&gt;I have an EU passport.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Tech Lead", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zorwxh", "is_robot_indexable": true, "report_reasons": null, "author": "CapitalistZ", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/zorwxh/any_eu_des/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zorwxh/any_eu_des/", "subreddit_subscribers": 83226, "created_utc": 1671344633.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am pondering again, for the first time in many years, if it would be possible to build a generic abstraction which takes GraphQL-like queries as input, and generates a query plan which gets executed across multiple disparate data stores. By \"GraphQL-like\", I mean anything which allows you to specify a nested tree of data requirements, it doesn't have to be a GraphQL spec adhering thing. By \"multiple disparate data stores\", I mean:\n\n- SQL databases (Postgres, MySQL, SQL Server, etc.)\n- NoSQL database (MongoDB, Cassandra, etc..)\n- REST APIs (stripe API, AWS API, etc.)\n- File/object stores (S3, etc.)\n\nEssentially, anything which has the notion of objects with relations between them is fair game. Say for example you had a GraphQL query sort of like this:\n\n    query Posts {\n      posts {\n        id\n        title\n        body\n        background {\n          id\n          attachments {\n            id\n            url\n            width\n            height\n          }\n        }\n        comments {\n          id\n          body\n          user {\n            id\n            email\n            username\n            name\n            stripe_customer {\n              id\n              email\n            }\n          }\n        }\n      }\n    }\n\nThe `stripe_customer` would be fetching from the Stripe API, the `background` would be in MongoDB with nested `attachment` documents, and the comments and posts are in a local PostgreSQL. You could imagine even more complicated scenarios, spanning 2 or 3 REST APIs, 2 or 3 SQL databases, and 1 or 2 NoSQL databases, in one query.\n\nDo you think it would be possible to build an **automatic** translator of these nested object GraphQL-like queries into a set of requests across these different data stores? I am imagining like creating an interface/adapter on top of each data store, which takes a SQL-like query as input and does `execute` on a query. The input GraphQL-like query would get divided into queries for each data store.\n\nIt seems really complicated and potentially impossible, to in a somewhat optimized way and automatic. I am just trying to think if there is any way to avoid having to write the manual implementation/handler of each type of GraphQL query (fetch this part from PostgreSQL, this part from MongoDB, etc.). That would be possible, but time consuming and error prone and difficult. Hence wondering if it might be possible to abstract over this sort of system and do the translation to sub-queries across stores automatically.", "author_fullname": "t2_97wpoelk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automatically converting deeply GraphQL query into optimized \"SQL\" query across multiple different data stores?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zoj5mg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671318652.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am pondering again, for the first time in many years, if it would be possible to build a generic abstraction which takes GraphQL-like queries as input, and generates a query plan which gets executed across multiple disparate data stores. By &amp;quot;GraphQL-like&amp;quot;, I mean anything which allows you to specify a nested tree of data requirements, it doesn&amp;#39;t have to be a GraphQL spec adhering thing. By &amp;quot;multiple disparate data stores&amp;quot;, I mean:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;SQL databases (Postgres, MySQL, SQL Server, etc.)&lt;/li&gt;\n&lt;li&gt;NoSQL database (MongoDB, Cassandra, etc..)&lt;/li&gt;\n&lt;li&gt;REST APIs (stripe API, AWS API, etc.)&lt;/li&gt;\n&lt;li&gt;File/object stores (S3, etc.)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Essentially, anything which has the notion of objects with relations between them is fair game. Say for example you had a GraphQL query sort of like this:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;query Posts {\n  posts {\n    id\n    title\n    body\n    background {\n      id\n      attachments {\n        id\n        url\n        width\n        height\n      }\n    }\n    comments {\n      id\n      body\n      user {\n        id\n        email\n        username\n        name\n        stripe_customer {\n          id\n          email\n        }\n      }\n    }\n  }\n}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;The &lt;code&gt;stripe_customer&lt;/code&gt; would be fetching from the Stripe API, the &lt;code&gt;background&lt;/code&gt; would be in MongoDB with nested &lt;code&gt;attachment&lt;/code&gt; documents, and the comments and posts are in a local PostgreSQL. You could imagine even more complicated scenarios, spanning 2 or 3 REST APIs, 2 or 3 SQL databases, and 1 or 2 NoSQL databases, in one query.&lt;/p&gt;\n\n&lt;p&gt;Do you think it would be possible to build an &lt;strong&gt;automatic&lt;/strong&gt; translator of these nested object GraphQL-like queries into a set of requests across these different data stores? I am imagining like creating an interface/adapter on top of each data store, which takes a SQL-like query as input and does &lt;code&gt;execute&lt;/code&gt; on a query. The input GraphQL-like query would get divided into queries for each data store.&lt;/p&gt;\n\n&lt;p&gt;It seems really complicated and potentially impossible, to in a somewhat optimized way and automatic. I am just trying to think if there is any way to avoid having to write the manual implementation/handler of each type of GraphQL query (fetch this part from PostgreSQL, this part from MongoDB, etc.). That would be possible, but time consuming and error prone and difficult. Hence wondering if it might be possible to abstract over this sort of system and do the translation to sub-queries across stores automatically.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zoj5mg", "is_robot_indexable": true, "report_reasons": null, "author": "lancejpollard", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zoj5mg/automatically_converting_deeply_graphql_query/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zoj5mg/automatically_converting_deeply_graphql_query/", "subreddit_subscribers": 83226, "created_utc": 1671318652.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}