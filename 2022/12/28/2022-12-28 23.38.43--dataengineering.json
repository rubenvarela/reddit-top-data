{"kind": "Listing", "data": {"after": null, "dist": 21, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Case in point, [this](https://www.reddit.com/r/dataengineeringjobs/comments/zwix9s/data_engineer_cloud_infrastructure_remote_110150k/) post from r/dataengineeringjobs for The California College Guidance Initiative. Like which part of their data is petabyte scale? how can i find out? am i underestimating how small a petabyte of data is?", "author_fullname": "t2_2pxsf0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "You guys ever puzzled by how some organizations are generating petabytes of data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zx8ss8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 49, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 49, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1672232022.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672231835.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Case in point, &lt;a href=\"https://www.reddit.com/r/dataengineeringjobs/comments/zwix9s/data_engineer_cloud_infrastructure_remote_110150k/\"&gt;this&lt;/a&gt; post from &lt;a href=\"/r/dataengineeringjobs\"&gt;r/dataengineeringjobs&lt;/a&gt; for The California College Guidance Initiative. Like which part of their data is petabyte scale? how can i find out? am i underestimating how small a petabyte of data is?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zx8ss8", "is_robot_indexable": true, "report_reasons": null, "author": "blue_trains_", "discussion_type": null, "num_comments": 44, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zx8ss8/you_guys_ever_puzzled_by_how_some_organizations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zx8ss8/you_guys_ever_puzzled_by_how_some_organizations/", "subreddit_subscribers": 84474, "created_utc": 1672231835.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently create a ETL project to scrape data from coinmarketcap and make it into pandas dataframe. Is it recommended to write table to bigquery using pandas method to\\_gbq because the code is simpler this way? or is there better alternative way to do it. BI Engineer looking to transition to DE role, please advice thank you.", "author_fullname": "t2_yi8tt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Write table to bigquery using pandas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zwztg1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1672201019.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672200448.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently create a ETL project to scrape data from coinmarketcap and make it into pandas dataframe. Is it recommended to write table to bigquery using pandas method to_gbq because the code is simpler this way? or is there better alternative way to do it. BI Engineer looking to transition to DE role, please advice thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zwztg1", "is_robot_indexable": true, "report_reasons": null, "author": "amponaja", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zwztg1/write_table_to_bigquery_using_pandas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zwztg1/write_table_to_bigquery_using_pandas/", "subreddit_subscribers": 84474, "created_utc": 1672200448.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A couple days ago, I came across this [post](https://www.reddit.com/r/dataengineering/comments/zr2klf/etl_using_pandas/?utm_source=share&amp;utm_medium=ios_app&amp;utm_name=iossmf) which suggested that using Pandas was quite an inefficient way to build out an ETL pipeline. \n\nAs someone that\u2019s just recently transitioned into DE it\u2019s the only way I know how. What are the better alternatives out there and what would be a good starting point for me?", "author_fullname": "t2_7iiccjhp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to ETL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zx7w7w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672229009.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A couple days ago, I came across this &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/zr2klf/etl_using_pandas/?utm_source=share&amp;amp;utm_medium=ios_app&amp;amp;utm_name=iossmf\"&gt;post&lt;/a&gt; which suggested that using Pandas was quite an inefficient way to build out an ETL pipeline. &lt;/p&gt;\n\n&lt;p&gt;As someone that\u2019s just recently transitioned into DE it\u2019s the only way I know how. What are the better alternatives out there and what would be a good starting point for me?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zx7w7w", "is_robot_indexable": true, "report_reasons": null, "author": "Ill-Advisor-8235", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zx7w7w/best_way_to_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zx7w7w/best_way_to_etl/", "subreddit_subscribers": 84474, "created_utc": 1672229009.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all.\n     \nI was wondering what is the percentage of development vs time spent in maintenance in typical DE projects and how different clients deal with it.\n     \nI'm working in a banking project with a team comprised of 20 data professionals. We've been working for this client since 2016, so as you can imagine, the amount of projects delivered so far is huge.\n     \nWith the the amount of data models running in production there is always something to fix. Could be an upstream data change, a ticket of a commercial of the bank asking for ad-hoc analysis or rule clarification, an error caused by a bug in our code, or 100 other reasons.\n     \nWe are working in the proposal to renew the contract for more 2 years but the client wants a 80% development and 20% maintenance SLA. Analyzing the hours spent I 2022 we're more close to 60%/40% and we think 80-20 is unrealistic. \n\nHow is it in your projects? How do you address this question next to the clients and argument that maintenance is something that cannot be ignored and is normal to happen?\n\nThank you.", "author_fullname": "t2_tn7215n2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Development time vs maintenance time percentage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zx53oh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672218665.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all.&lt;/p&gt;\n\n&lt;p&gt;I was wondering what is the percentage of development vs time spent in maintenance in typical DE projects and how different clients deal with it.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working in a banking project with a team comprised of 20 data professionals. We&amp;#39;ve been working for this client since 2016, so as you can imagine, the amount of projects delivered so far is huge.&lt;/p&gt;\n\n&lt;p&gt;With the the amount of data models running in production there is always something to fix. Could be an upstream data change, a ticket of a commercial of the bank asking for ad-hoc analysis or rule clarification, an error caused by a bug in our code, or 100 other reasons.&lt;/p&gt;\n\n&lt;p&gt;We are working in the proposal to renew the contract for more 2 years but the client wants a 80% development and 20% maintenance SLA. Analyzing the hours spent I 2022 we&amp;#39;re more close to 60%/40% and we think 80-20 is unrealistic. &lt;/p&gt;\n\n&lt;p&gt;How is it in your projects? How do you address this question next to the clients and argument that maintenance is something that cannot be ignored and is normal to happen?&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zx53oh", "is_robot_indexable": true, "report_reasons": null, "author": "UniqueNicknameNeeded", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zx53oh/development_time_vs_maintenance_time_percentage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zx53oh/development_time_vs_maintenance_time_percentage/", "subreddit_subscribers": 84474, "created_utc": 1672218665.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,   \nFirst of all I must admit that I am overwhelmed by amount of tools DE can use in their job. I want to focus mainly on Azure stack as I am Power BI developer myself, so it is natural choice for me I guess. From what I understood, the tools listed below should be enough to perform junior DE tasks?  \n\n\nETL - Azure Data Factory / Synapse Analytics\n\nStorage / Data warehouse - Azure data lake gen 2 / Synapse Analytics\n\nData transformation - Azure Databricks (can also do ETL in there?)  \n\n\nWhile I might not understand - can I perform whole ETL in Synapse/ADF same as can I in Azure Databricks? I know there are lot more tools in Azure stack but these main 3 (ADF, Databrick, Synapse) should be enough to start with?", "author_fullname": "t2_ajcdrgrx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure DE/ETL stack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zx9kc9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672234044.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;br/&gt;\nFirst of all I must admit that I am overwhelmed by amount of tools DE can use in their job. I want to focus mainly on Azure stack as I am Power BI developer myself, so it is natural choice for me I guess. From what I understood, the tools listed below should be enough to perform junior DE tasks?  &lt;/p&gt;\n\n&lt;p&gt;ETL - Azure Data Factory / Synapse Analytics&lt;/p&gt;\n\n&lt;p&gt;Storage / Data warehouse - Azure data lake gen 2 / Synapse Analytics&lt;/p&gt;\n\n&lt;p&gt;Data transformation - Azure Databricks (can also do ETL in there?)  &lt;/p&gt;\n\n&lt;p&gt;While I might not understand - can I perform whole ETL in Synapse/ADF same as can I in Azure Databricks? I know there are lot more tools in Azure stack but these main 3 (ADF, Databrick, Synapse) should be enough to start with?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zx9kc9", "is_robot_indexable": true, "report_reasons": null, "author": "Commercial-Ask971", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zx9kc9/azure_deetl_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zx9kc9/azure_deetl_stack/", "subreddit_subscribers": 84474, "created_utc": 1672234044.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are your experiences like what\u2019s the competition level for the position?", "author_fullname": "t2_3il9fbpi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone work/ interview at Bloomberg?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zwtkbp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672183247.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are your experiences like what\u2019s the competition level for the position?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zwtkbp", "is_robot_indexable": true, "report_reasons": null, "author": "a4444999", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zwtkbp/anyone_work_interview_at_bloomberg/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zwtkbp/anyone_work_interview_at_bloomberg/", "subreddit_subscribers": 84474, "created_utc": 1672183247.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all, having a really hard time finding good resources to better make sense of the spark UI (using databricks). Particularly, when I have a command or DLT pipeline that is taking a very long time, I want to learn how to use the UI to debug what is happening. \n\nLet me know if anyone can point me in the right direction for material that could help, thanks!", "author_fullname": "t2_2nfde5yl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Understanding Spark UI/Loga", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zxhphn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672253880.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, having a really hard time finding good resources to better make sense of the spark UI (using databricks). Particularly, when I have a command or DLT pipeline that is taking a very long time, I want to learn how to use the UI to debug what is happening. &lt;/p&gt;\n\n&lt;p&gt;Let me know if anyone can point me in the right direction for material that could help, thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zxhphn", "is_robot_indexable": true, "report_reasons": null, "author": "pmarct", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zxhphn/understanding_spark_uiloga/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zxhphn/understanding_spark_uiloga/", "subreddit_subscribers": 84474, "created_utc": 1672253880.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " In your production project, when do you use google dataflow for transformations as opposed to doing transformations in Bigquery itself through scheduled queries or airflow? I suppose doing the transformations in bigquery will allow for using dbt models thereby adding other benefits that dbt offers. What is the general consensus in the DE space regarding this?\n\nShould complex transformations be done in dataflow or bigquery (using SQL / python client library) in below cases:\n\n\u00a0\u00a0\u00a0\u00a0 1. when the data is already in bigquery tables?\n\n\u00a0\u00a0\u00a0\u00a0 2. when the data is in GCS with bigquery external tables on top of them?\n\n\u00a0\u00a0\u00a0\u00a0 3. when the data is streaming into a pub/sub topic and into bigquery tables?", "author_fullname": "t2_q44oqe9d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google Dataflow vs Bigquery for transformations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zx9paw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672234430.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In your production project, when do you use google dataflow for transformations as opposed to doing transformations in Bigquery itself through scheduled queries or airflow? I suppose doing the transformations in bigquery will allow for using dbt models thereby adding other benefits that dbt offers. What is the general consensus in the DE space regarding this?&lt;/p&gt;\n\n&lt;p&gt;Should complex transformations be done in dataflow or bigquery (using SQL / python client library) in below cases:&lt;/p&gt;\n\n&lt;p&gt;\u00a0\u00a0\u00a0\u00a0 1. when the data is already in bigquery tables?&lt;/p&gt;\n\n&lt;p&gt;\u00a0\u00a0\u00a0\u00a0 2. when the data is in GCS with bigquery external tables on top of them?&lt;/p&gt;\n\n&lt;p&gt;\u00a0\u00a0\u00a0\u00a0 3. when the data is streaming into a pub/sub topic and into bigquery tables?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zx9paw", "is_robot_indexable": true, "report_reasons": null, "author": "proberunsam", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zx9paw/google_dataflow_vs_bigquery_for_transformations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zx9paw/google_dataflow_vs_bigquery_for_transformations/", "subreddit_subscribers": 84474, "created_utc": 1672234430.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, \n\nI would like to get some suggestion on how I should approach solving an inefficient data  system that I found at my workplace. So basically, there is a weekly meeting data report that I have to prepare every week, and the process works like this...\n\n1. Download three data files (excel) from a third party company website\n2. Use those data to update new records into our \"master\" data file (this is done manually which I see there can be an improvement)\n3. Make graphs and reports from the master file\n\nThe problem is that the files are all in excel file. I am familiar with sql and python, but I do not have experience in architecting ETL pipeline. I would like to make a system/pipeline that could automatically fill out the updated data records in a format (data transform) that I would like it to be in the master file just by downloading and placing the file somewhere in the hardware/desktop. Is this possible? Do i need to simply use excel's power query? Any advice would be great", "author_fullname": "t2_5uvrlw9s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggestion of Data pipeline for inefficient work system at my company", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zwxil9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672193813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, &lt;/p&gt;\n\n&lt;p&gt;I would like to get some suggestion on how I should approach solving an inefficient data  system that I found at my workplace. So basically, there is a weekly meeting data report that I have to prepare every week, and the process works like this...&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Download three data files (excel) from a third party company website&lt;/li&gt;\n&lt;li&gt;Use those data to update new records into our &amp;quot;master&amp;quot; data file (this is done manually which I see there can be an improvement)&lt;/li&gt;\n&lt;li&gt;Make graphs and reports from the master file&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The problem is that the files are all in excel file. I am familiar with sql and python, but I do not have experience in architecting ETL pipeline. I would like to make a system/pipeline that could automatically fill out the updated data records in a format (data transform) that I would like it to be in the master file just by downloading and placing the file somewhere in the hardware/desktop. Is this possible? Do i need to simply use excel&amp;#39;s power query? Any advice would be great&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zwxil9", "is_robot_indexable": true, "report_reasons": null, "author": "Professional_Ball_58", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zwxil9/suggestion_of_data_pipeline_for_inefficient_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zwxil9/suggestion_of_data_pipeline_for_inefficient_work/", "subreddit_subscribers": 84474, "created_utc": 1672193813.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For DSA (Data structures and Algorithms) rounds for data engineer roles is it fine if I use c++ for dsa ?\n\nI know Python and Java but practiced dsa with c++ mainly and I am comfortable with it", "author_fullname": "t2_qc5tuhod", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DSA Languages", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zx9fvv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672233690.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For DSA (Data structures and Algorithms) rounds for data engineer roles is it fine if I use c++ for dsa ?&lt;/p&gt;\n\n&lt;p&gt;I know Python and Java but practiced dsa with c++ mainly and I am comfortable with it&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "zx9fvv", "is_robot_indexable": true, "report_reasons": null, "author": "Reddit_user210", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zx9fvv/dsa_languages/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zx9fvv/dsa_languages/", "subreddit_subscribers": 84474, "created_utc": 1672233690.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A beginner question. I am creating a Data Warehouse for my personal project and my batch process insert some duplicated rows in my DW table dimension. I did not find anything about it, but should (must) we always remove duplicated rows? seems to make sense since the fact table has a foreing key pointing to the primary key dimension table values, or maybe it depends of the project/DW?", "author_fullname": "t2_e55z81b9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dimension tables rows must be unique?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zxhh3g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1672253537.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672253323.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A beginner question. I am creating a Data Warehouse for my personal project and my batch process insert some duplicated rows in my DW table dimension. I did not find anything about it, but should (must) we always remove duplicated rows? seems to make sense since the fact table has a foreing key pointing to the primary key dimension table values, or maybe it depends of the project/DW?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zxhh3g", "is_robot_indexable": true, "report_reasons": null, "author": "ByHoldenCaulfield", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zxhh3g/dimension_tables_rows_must_be_unique/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zxhh3g/dimension_tables_rows_must_be_unique/", "subreddit_subscribers": 84474, "created_utc": 1672253323.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "from sqlserver, there are sqlaudit files which are created randomly through out the day.\n\nthere is a task scheduler which triggers a powershell script through every other hour.\n\nthis powershell script takes each sqlaudit from the logs folder, transforms it to json, dumps it to s3.\n\nwhat logic can be added in the script so that it remembers the last file it has already processed + loaded to s3 and hence doesn't need to be loaded?\n\n1. cant mv processed files to another folder (as then logs cant be viewed from sqlserver)\n2. cant rename files with suffix \\_processed (client doesnt want edits to happen)\n3. if at the end of any powershell script run, one updates a watermark text file with timestamp (date h:m:s) of last processed file would that be efficient ? since at each run all the files in the folder would need to be checked whether it's greater than x.y.z? is there a way to make it faster than o(n)?\n4. Kindly suggest. All leads appreciated!", "author_fullname": "t2_piwlmz4s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "batching files to s3? (noob)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zxgrsu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1672255182.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672251678.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;from sqlserver, there are sqlaudit files which are created randomly through out the day.&lt;/p&gt;\n\n&lt;p&gt;there is a task scheduler which triggers a powershell script through every other hour.&lt;/p&gt;\n\n&lt;p&gt;this powershell script takes each sqlaudit from the logs folder, transforms it to json, dumps it to s3.&lt;/p&gt;\n\n&lt;p&gt;what logic can be added in the script so that it remembers the last file it has already processed + loaded to s3 and hence doesn&amp;#39;t need to be loaded?&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;cant mv processed files to another folder (as then logs cant be viewed from sqlserver)&lt;/li&gt;\n&lt;li&gt;cant rename files with suffix _processed (client doesnt want edits to happen)&lt;/li&gt;\n&lt;li&gt;if at the end of any powershell script run, one updates a watermark text file with timestamp (date h:m:s) of last processed file would that be efficient ? since at each run all the files in the folder would need to be checked whether it&amp;#39;s greater than x.y.z? is there a way to make it faster than o(n)?&lt;/li&gt;\n&lt;li&gt;Kindly suggest. All leads appreciated!&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zxgrsu", "is_robot_indexable": true, "report_reasons": null, "author": "Fun_Story2003", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zxgrsu/batching_files_to_s3_noob/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zxgrsu/batching_files_to_s3_noob/", "subreddit_subscribers": 84474, "created_utc": 1672251678.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Lowly analyst here, one of the upcoming tasks I have heading into the new year is to report on time and attendance for a department. Now a big problem I have is that I have looked at their spreadsheets and they are baaaad. I'm thinking they could possibly benefit from something else. We have Google Forms available but I was thinking, would it be easier to build the simplest of html forms and have them use this? Budget of course for this project is 0.00 so I guess I'd have to figure out some way to save this webpage on the department's shared Google drive so very limited server back end stuff. What do you guys think and how would you go about it?", "author_fullname": "t2_ftjmo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Would creating a locally hosted html form work better than a Google Form to record time and attendance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zxgj9c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1672254035.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672251124.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Lowly analyst here, one of the upcoming tasks I have heading into the new year is to report on time and attendance for a department. Now a big problem I have is that I have looked at their spreadsheets and they are baaaad. I&amp;#39;m thinking they could possibly benefit from something else. We have Google Forms available but I was thinking, would it be easier to build the simplest of html forms and have them use this? Budget of course for this project is 0.00 so I guess I&amp;#39;d have to figure out some way to save this webpage on the department&amp;#39;s shared Google drive so very limited server back end stuff. What do you guys think and how would you go about it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zxgj9c", "is_robot_indexable": true, "report_reasons": null, "author": "punchoutlanddragons", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zxgj9c/would_creating_a_locally_hosted_html_form_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zxgj9c/would_creating_a_locally_hosted_html_form_work/", "subreddit_subscribers": 84474, "created_utc": 1672251124.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, \n\nCurrently have one vendor that sends a xlsx file by email every week and a file that needs to be manually extracted from  a web portal (can\u2019t connect directly or schedule email out)?\n\nWhat would be the best steps to attempt to automate these processes?\n\nThank you\n\nNote: File sizes are small &lt;10mb", "author_fullname": "t2_a7nec5bo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practice for creating pipelines from email and vendor portal?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zx52o6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672218563.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, &lt;/p&gt;\n\n&lt;p&gt;Currently have one vendor that sends a xlsx file by email every week and a file that needs to be manually extracted from  a web portal (can\u2019t connect directly or schedule email out)?&lt;/p&gt;\n\n&lt;p&gt;What would be the best steps to attempt to automate these processes?&lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n\n&lt;p&gt;Note: File sizes are small &amp;lt;10mb&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zx52o6", "is_robot_indexable": true, "report_reasons": null, "author": "TheCumCopter", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zx52o6/best_practice_for_creating_pipelines_from_email/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zx52o6/best_practice_for_creating_pipelines_from_email/", "subreddit_subscribers": 84474, "created_utc": 1672218563.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I would guess that data structures and algorithms, databases, and machine learning would provide a good base. Based on your experiences in this field what other courses should I take?\n\nI know the requirements for positions vary a lot, but how can I make myself as prepared as possible for any data engineering role?", "author_fullname": "t2_j9d5u3uf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What CS courses are good for data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zx1m8g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672206074.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would guess that data structures and algorithms, databases, and machine learning would provide a good base. Based on your experiences in this field what other courses should I take?&lt;/p&gt;\n\n&lt;p&gt;I know the requirements for positions vary a lot, but how can I make myself as prepared as possible for any data engineering role?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zx1m8g", "is_robot_indexable": true, "report_reasons": null, "author": "OrganicBluebird9464", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zx1m8g/what_cs_courses_are_good_for_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zx1m8g/what_cs_courses_are_good_for_data_engineering/", "subreddit_subscribers": 84474, "created_utc": 1672206074.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_m0p42", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resume help! DA --&gt; DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_zxnx4c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ND3FZZ4hDJpsr74fLRSGukIx92Zr8DDOSAozL1JsmKQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1672268377.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/hepnrlx5wp8a1.jpg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/hepnrlx5wp8a1.jpg?auto=webp&amp;s=d0c5bbf8f488b7038207f6e0cb494f7cc9a9627a", "width": 2550, "height": 3300}, "resolutions": [{"url": "https://preview.redd.it/hepnrlx5wp8a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4e908dd9d998d2e734793088b47d79d6b1040c33", "width": 108, "height": 139}, {"url": "https://preview.redd.it/hepnrlx5wp8a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=824aaed211bf9d5251023b9b2457f086f101be23", "width": 216, "height": 279}, {"url": "https://preview.redd.it/hepnrlx5wp8a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5da2c71cbf1a27745cb3f2371759d4609148bc3f", "width": 320, "height": 414}, {"url": "https://preview.redd.it/hepnrlx5wp8a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3d8f9818adce27a8add61ed2034e92c4825559eb", "width": 640, "height": 828}, {"url": "https://preview.redd.it/hepnrlx5wp8a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a4947875930d10c315dfbb2ae5eb5484f840b528", "width": 960, "height": 1242}, {"url": "https://preview.redd.it/hepnrlx5wp8a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d802986482797b4fcfbea041776729cdc25d8f12", "width": 1080, "height": 1397}], "variants": {}, "id": "dCrCNhMGiJNoUdwKC4fGMQc8TJyLlYsg9IL4szZn8dw"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "zxnx4c", "is_robot_indexable": true, "report_reasons": null, "author": "throughahwae", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zxnx4c/resume_help_da_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/hepnrlx5wp8a1.jpg", "subreddit_subscribers": 84474, "created_utc": 1672268377.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My career progression/education:\n\nData Analytics Intern(7 months)-&gt;Software Engineer(2 years)-&gt;Data Scientist(4 months). \n\nMS Data Science (in progress)\n\nBS Information Science, minor CS\n\n\nAll at same employer in the research sector. Employer is dysfunctional and tech stack is outdated. Learning as much of the modern data stack as I can on my own. \n\nRight now, I am sort of a \u201cfull stack\u201d data guy. I am much stronger at programming and data architecture than math. My lack of math background I worry will hinder my DS career. \n\nMy only worry is people saying that DE\u2019s are often second class citizens in industry to DS. My friend thinks I should stay in DS side since I have academia/research experience, and just look for jobs where I can do a bit of both. He also thinks DS will help my\nend career goal which is more business oriented. \n\nMy end career goal is to start a Data consulting company or be a Chief Data Officer at a company. \n\nWWYD? Play to my strengths and go DE, or keep chugging along DS to reach my goals?", "author_fullname": "t2_b7eqz4bi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I transfer from DS to DE and am I ready if so?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zxeyev", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672247426.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My career progression/education:&lt;/p&gt;\n\n&lt;p&gt;Data Analytics Intern(7 months)-&amp;gt;Software Engineer(2 years)-&amp;gt;Data Scientist(4 months). &lt;/p&gt;\n\n&lt;p&gt;MS Data Science (in progress)&lt;/p&gt;\n\n&lt;p&gt;BS Information Science, minor CS&lt;/p&gt;\n\n&lt;p&gt;All at same employer in the research sector. Employer is dysfunctional and tech stack is outdated. Learning as much of the modern data stack as I can on my own. &lt;/p&gt;\n\n&lt;p&gt;Right now, I am sort of a \u201cfull stack\u201d data guy. I am much stronger at programming and data architecture than math. My lack of math background I worry will hinder my DS career. &lt;/p&gt;\n\n&lt;p&gt;My only worry is people saying that DE\u2019s are often second class citizens in industry to DS. My friend thinks I should stay in DS side since I have academia/research experience, and just look for jobs where I can do a bit of both. He also thinks DS will help my\nend career goal which is more business oriented. &lt;/p&gt;\n\n&lt;p&gt;My end career goal is to start a Data consulting company or be a Chief Data Officer at a company. &lt;/p&gt;\n\n&lt;p&gt;WWYD? Play to my strengths and go DE, or keep chugging along DS to reach my goals?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zxeyev", "is_robot_indexable": true, "report_reasons": null, "author": "Old-Box228", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zxeyev/should_i_transfer_from_ds_to_de_and_am_i_ready_if/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zxeyev/should_i_transfer_from_ds_to_de_and_am_i_ready_if/", "subreddit_subscribers": 84474, "created_utc": 1672247426.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We're switching up our DWH and while there's some specific planning going on I thought I'd canvas the community to see if anyone had warnings or tips they wish they knew when they went through it. \n\nFor context, it's a fairly small data set so far (burgeoning analytics warehouse) and we're moving away from SF. There are only a few prod workflows that we need to be careful with but may as well be careful all around. Source data is available so we could just re-pipe it until the new set up is ready I guess. \n\nThanks for any and all tips.", "author_fullname": "t2_ut20i32q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DWH migrations tips?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zxcfmg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672241439.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;re switching up our DWH and while there&amp;#39;s some specific planning going on I thought I&amp;#39;d canvas the community to see if anyone had warnings or tips they wish they knew when they went through it. &lt;/p&gt;\n\n&lt;p&gt;For context, it&amp;#39;s a fairly small data set so far (burgeoning analytics warehouse) and we&amp;#39;re moving away from SF. There are only a few prod workflows that we need to be careful with but may as well be careful all around. Source data is available so we could just re-pipe it until the new set up is ready I guess. &lt;/p&gt;\n\n&lt;p&gt;Thanks for any and all tips.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zxcfmg", "is_robot_indexable": true, "report_reasons": null, "author": "alex_o_h", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zxcfmg/dwh_migrations_tips/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zxcfmg/dwh_migrations_tips/", "subreddit_subscribers": 84474, "created_utc": 1672241439.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is there a way to automate the azure pipeline creation and to package this as PIP install? \n\n&amp;#x200B;\n\np.s without using terraform", "author_fullname": "t2_56g5f4cg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure pipeline autoamtion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zx3qex", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672213425.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a way to automate the azure pipeline creation and to package this as PIP install? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;p.s without using terraform&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zx3qex", "is_robot_indexable": true, "report_reasons": null, "author": "9gg6", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zx3qex/azure_pipeline_autoamtion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zx3qex/azure_pipeline_autoamtion/", "subreddit_subscribers": 84474, "created_utc": 1672213425.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When solve machine learning problem we usually don\u201dt use One-hot encoding category feature. Because One-hot encoding is computationally intensive and should only learning performed on small samples of training set for identified machine learning problems.", "author_fullname": "t2_jo7rjf10", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reason Don't use One-hot encoding with category feature", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zx1i02", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.2, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1672208836.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672205694.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When solve machine learning problem we usually don\u201dt use One-hot encoding category feature. Because One-hot encoding is computationally intensive and should only learning performed on small samples of training set for identified machine learning problems.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zx1i02", "is_robot_indexable": true, "report_reasons": null, "author": "Due-Tangerine1104", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zx1i02/reason_dont_use_onehot_encoding_with_category/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zx1i02/reason_dont_use_onehot_encoding_with_category/", "subreddit_subscribers": 84474, "created_utc": 1672205694.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://lakefs.io/blog/5-new-year-resolutions-for-data-engineers/](https://lakefs.io/blog/5-new-year-resolutions-for-data-engineers/)", "author_fullname": "t2_m2ywgliu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "5 New Year Resolutions for Data Engineers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zx393f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.11, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1672211648.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://lakefs.io/blog/5-new-year-resolutions-for-data-engineers/\"&gt;https://lakefs.io/blog/5-new-year-resolutions-for-data-engineers/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JX1GCSJgqCTsN0ZM79drprF82W6-61vVqmF89BBGG9s.jpg?auto=webp&amp;s=8bb1cbb56d8fff2acd7cbd6f58a825b41022e927", "width": 295, "height": 213}, "resolutions": [{"url": "https://external-preview.redd.it/JX1GCSJgqCTsN0ZM79drprF82W6-61vVqmF89BBGG9s.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=985501ce17410c873c4b97d93d9fa60bcd78acbc", "width": 108, "height": 77}, {"url": "https://external-preview.redd.it/JX1GCSJgqCTsN0ZM79drprF82W6-61vVqmF89BBGG9s.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ef5c0f97e92742d99e2dcd3c387c5409a8535957", "width": 216, "height": 155}], "variants": {}, "id": "jtH4WqBez22t3Aip9zGz1ZuXD78zetLvfrk4scew50U"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zx393f", "is_robot_indexable": true, "report_reasons": null, "author": "PuzzleheadedLion9876", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zx393f/5_new_year_resolutions_for_data_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zx393f/5_new_year_resolutions_for_data_engineers/", "subreddit_subscribers": 84474, "created_utc": 1672211648.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}