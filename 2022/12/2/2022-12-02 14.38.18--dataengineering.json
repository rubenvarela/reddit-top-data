{"kind": "Listing", "data": {"after": null, "dist": 20, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can you recommend any videos which go though the Kimball Methodology. I have seen some on YouTube but they are mostly under 10 minutes and go over the basics. I am looking for an in depth video.", "author_fullname": "t2_12rfbr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Videos which explain the Kimball Methodology?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z9tk7l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 41, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669915322.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can you recommend any videos which go though the Kimball Methodology. I have seen some on YouTube but they are mostly under 10 minutes and go over the basics. I am looking for an in depth video.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z9tk7l", "is_robot_indexable": true, "report_reasons": null, "author": "That_Sweet_Science", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z9tk7l/videos_which_explain_the_kimball_methodology/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z9tk7l/videos_which_explain_the_kimball_methodology/", "subreddit_subscribers": 81636, "created_utc": 1669915322.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am wondering on how to get hands on with cloud services like redshift, s3, kinda stuffs. I think i've some good overview of data warehouse  and dimensional modelling. Thinking of applying data warehouse concepts on a project or something and i'm thinking of building data warehouse on a cloud to get some practical experience but the thing is I don't know where to start with the cloud. \n\nShould I gather experience exploring the tools or rather take some courses? \n\nAnd also what kind of projects would really stand out from others ?", "author_fullname": "t2_aenh4mw5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get start with cloud(AWS)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_za88nk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669947588.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am wondering on how to get hands on with cloud services like redshift, s3, kinda stuffs. I think i&amp;#39;ve some good overview of data warehouse  and dimensional modelling. Thinking of applying data warehouse concepts on a project or something and i&amp;#39;m thinking of building data warehouse on a cloud to get some practical experience but the thing is I don&amp;#39;t know where to start with the cloud. &lt;/p&gt;\n\n&lt;p&gt;Should I gather experience exploring the tools or rather take some courses? &lt;/p&gt;\n\n&lt;p&gt;And also what kind of projects would really stand out from others ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "za88nk", "is_robot_indexable": true, "report_reasons": null, "author": "Suspicious_Peanut282", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/za88nk/how_to_get_start_with_cloudaws/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/za88nk/how_to_get_start_with_cloudaws/", "subreddit_subscribers": 81636, "created_utc": 1669947588.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "While the following is similar to a lot of hopeful graduates looking for their first data job, my story is a little bit on the unusual side so I figured some more tailored advice would be very much appreciated. Thank you for valuable time in advance!\n\nI'm from a social science background in psychology where I focused on doing extra statistics subjects at university and always wanted to be  a researcher. Bombed out of my PhD with no measurable accomplishments besides an appreciation for Python, and exposure to MATLAB for data pipelines on EEG data. I spent the next 2 years consulting 4th year students on how to run data analysis on their research  -- all in SPSS.\n\nPulled myself together and left that behind me to focus entirely on full-time work search and upskilling. I'm currently learning Python, PowerBI, and TSQL and applying them in small projects.Right now I'm working mainly on kaggle datasets - one for querying in SQL Server Management Studio to show my ability to write SQL and visualising in PowerBI, and the other one using entirely Python because the file is sqlite and SSMS makes it annoying to open, so Python sqlite3 it is!\n\nOn that note, it seems to be advice I hear from everyone, just demonstrate your skills with projects. But if everyone is doing projects, it seems a little difficult to stand out if you're not an IT/CS/Data graduate.\n\nMy current plans are to keep plugging away at these projects and upload to github, learning daily on Udemy for PowerBI and a couple of Jose Portilla courses for Python and Python for data science, then move on to a bit more of a complex project involving sentiment analysis in Python. At the same time I've started on CS50 as I recognise I lack some fundamentals and have some bad coding habits.\n\nDoes anybody have some advice for demonstrating skills or suitability for an entry level data role besides what I'm already doing, and continuing to grow into a data engineering career?\n\n\\- Sincerely, a data enthusiast", "author_fullname": "t2_zz4yu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Breaking into data analyst role and future data engineer career", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_za1nhu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669932670.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;While the following is similar to a lot of hopeful graduates looking for their first data job, my story is a little bit on the unusual side so I figured some more tailored advice would be very much appreciated. Thank you for valuable time in advance!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m from a social science background in psychology where I focused on doing extra statistics subjects at university and always wanted to be  a researcher. Bombed out of my PhD with no measurable accomplishments besides an appreciation for Python, and exposure to MATLAB for data pipelines on EEG data. I spent the next 2 years consulting 4th year students on how to run data analysis on their research  -- all in SPSS.&lt;/p&gt;\n\n&lt;p&gt;Pulled myself together and left that behind me to focus entirely on full-time work search and upskilling. I&amp;#39;m currently learning Python, PowerBI, and TSQL and applying them in small projects.Right now I&amp;#39;m working mainly on kaggle datasets - one for querying in SQL Server Management Studio to show my ability to write SQL and visualising in PowerBI, and the other one using entirely Python because the file is sqlite and SSMS makes it annoying to open, so Python sqlite3 it is!&lt;/p&gt;\n\n&lt;p&gt;On that note, it seems to be advice I hear from everyone, just demonstrate your skills with projects. But if everyone is doing projects, it seems a little difficult to stand out if you&amp;#39;re not an IT/CS/Data graduate.&lt;/p&gt;\n\n&lt;p&gt;My current plans are to keep plugging away at these projects and upload to github, learning daily on Udemy for PowerBI and a couple of Jose Portilla courses for Python and Python for data science, then move on to a bit more of a complex project involving sentiment analysis in Python. At the same time I&amp;#39;ve started on CS50 as I recognise I lack some fundamentals and have some bad coding habits.&lt;/p&gt;\n\n&lt;p&gt;Does anybody have some advice for demonstrating skills or suitability for an entry level data role besides what I&amp;#39;m already doing, and continuing to grow into a data engineering career?&lt;/p&gt;\n\n&lt;p&gt;- Sincerely, a data enthusiast&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "za1nhu", "is_robot_indexable": true, "report_reasons": null, "author": "OloroMemez", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/za1nhu/breaking_into_data_analyst_role_and_future_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/za1nhu/breaking_into_data_analyst_role_and_future_data/", "subreddit_subscribers": 81636, "created_utc": 1669932670.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is a recurring thread that happens quarterly and was created to help increase transparency around salary and compensation for Data Engineering. Please comment below and include the following:\n\n1. Current title\n\n2. Years of experience (YOE)\n\n3. Location\n\n4. Base salary &amp; currency (dollars, euro, pesos, etc.)\n\n5. Bonuses/Equity (optional)\n\n6. Industry (optional)\n\n7. Tech stack (optional)", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Quarterly Salary Discussion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "collections": [{"permalink": "https://www.reddit.com/r/dataengineering/collection/ef3eb514-328d-4549-a705-94c26963d79b", "link_ids": ["t3_npxcqc", "t3_pfwuyg", "t3_r6jfnm", "t3_t4clep", "t3_v2ka3w", "t3_x3bb11", "t3_z9szj1"], "description": "", "title": "Data Engineering Salaries", "created_at_utc": 1621559056.076, "subreddit_id": "t5_36en4", "author_name": "theporterhaus", "collection_id": "ef3eb514-328d-4549-a705-94c26963d79b", "author_id": "t2_2tv9i42n", "last_update_utc": 1669914008.806, "display_layout": null}], "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z9szj1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669914008.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a recurring thread that happens quarterly and was created to help increase transparency around salary and compensation for Data Engineering. Please comment below and include the following:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Current title&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Years of experience (YOE)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Location&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Base salary &amp;amp; currency (dollars, euro, pesos, etc.)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Bonuses/Equity (optional)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Industry (optional)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Tech stack (optional)&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "z9szj1", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 37, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z9szj1/quarterly_salary_discussion/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/dataengineering/comments/z9szj1/quarterly_salary_discussion/", "subreddit_subscribers": 81636, "created_utc": 1669914008.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone, I was recently debating a friend who is a data engineer on whether data sourcing or model building capability will be more valuable as pre-trained foundational models become more and more capable. My position is that in an era of finetuning data will be king and OpenAI will kill the majority of other models. Would love to trigger a wider debate!", "author_fullname": "t2_5lfzc2mu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Discussion thread: \"data sourcing is more important than model building capability in the era of foundational model fine-tuning\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z9qrss", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669908664.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I was recently debating a friend who is a data engineer on whether data sourcing or model building capability will be more valuable as pre-trained foundational models become more and more capable. My position is that in an era of finetuning data will be king and OpenAI will kill the majority of other models. Would love to trigger a wider debate!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z9qrss", "is_robot_indexable": true, "report_reasons": null, "author": "fourcornerclub", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z9qrss/discussion_thread_data_sourcing_is_more_important/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z9qrss/discussion_thread_data_sourcing_is_more_important/", "subreddit_subscribers": 81636, "created_utc": 1669908664.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I'm in a new job where I'm in way over my head (or so it feels like) and my weakest side is that I suck at Azure. Managed identities, service principals, oauth 2.0, sas tokens, file system drivers, vnets, subnets... There are so many security concepts that I simply read about so many times, but I am never able to learn how they are all related and get an overview. My brain is simply unable to comprehend it all unless I can REALLY get a grasp. I'm a very all or nothing guy, hearing a word here and there never makes it stick. \n\nI'm currently working with the IaC team tp implement Databricks, Unity Catalog and for everything outside Databricks I really struggle. Does anyone have any good tips? I was recommended by a colleague to do the AZ-104 certification (or at least read the learning materials). Any other tips?", "author_fullname": "t2_4ov075m4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need to improve my cloud (Azure) skills to become a better data engineer. Tips?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zagbo0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669970714.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;m in a new job where I&amp;#39;m in way over my head (or so it feels like) and my weakest side is that I suck at Azure. Managed identities, service principals, oauth 2.0, sas tokens, file system drivers, vnets, subnets... There are so many security concepts that I simply read about so many times, but I am never able to learn how they are all related and get an overview. My brain is simply unable to comprehend it all unless I can REALLY get a grasp. I&amp;#39;m a very all or nothing guy, hearing a word here and there never makes it stick. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working with the IaC team tp implement Databricks, Unity Catalog and for everything outside Databricks I really struggle. Does anyone have any good tips? I was recommended by a colleague to do the AZ-104 certification (or at least read the learning materials). Any other tips?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zagbo0", "is_robot_indexable": true, "report_reasons": null, "author": "HealthyDoggos4Life", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zagbo0/need_to_improve_my_cloud_azure_skills_to_become_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zagbo0/need_to_improve_my_cloud_azure_skills_to_become_a/", "subreddit_subscribers": 81636, "created_utc": 1669970714.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all!\n\nI'm the developer behind [Rocketry](https://github.com/Miksus/rocketry), a Pythonic scheduling engine. I originally developed it for other needs than data engineering but as some have said they have started to replace Airflow with it, I thought perhaps some of you might like it as well. I'm also interested in your opinions.\n\nA bit about the framework, it is quite minimal:\n\n    from rocketry import Rocketry\n    from rocketry.conds import daily\n    \n    app = Rocketry()\n    \n    @app.task(daily.at(\"10:00\"))\n    def do_daily():\n        ... # This function runs once a day at 10 AM\n    \n    if __name__ == \"__main__\":\n        app.run()\n\nIt has bunch of features: logical scheduling syntax, parallelism/concurrency, dynamic parametization, log to database etc. You can read from the docs: [https://rocketry.readthedocs.io/](https://rocketry.readthedocs.io/)\n\nI don't think Rocketry will achieve the same level of adaptation as Airflow and it is missing many advanced features Airflow has such as built-in UI ([working on such](https://github.com/Miksus/rocketry-with-fastapi)), executors for containers etc. but considering how versatile it is and how powerful the scheduling is (basically logical statements), I think it could be interesting for those data engineers who need to customize their setup or need something smaller in scale.\n\nDo you think there is anything missing from the available mature task orchestration products? Or is the space already saturated?", "author_fullname": "t2_23tmpa91", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scheduling in Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zaeiam", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1669964573.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m the developer behind &lt;a href=\"https://github.com/Miksus/rocketry\"&gt;Rocketry&lt;/a&gt;, a Pythonic scheduling engine. I originally developed it for other needs than data engineering but as some have said they have started to replace Airflow with it, I thought perhaps some of you might like it as well. I&amp;#39;m also interested in your opinions.&lt;/p&gt;\n\n&lt;p&gt;A bit about the framework, it is quite minimal:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;from rocketry import Rocketry\nfrom rocketry.conds import daily\n\napp = Rocketry()\n\n@app.task(daily.at(&amp;quot;10:00&amp;quot;))\ndef do_daily():\n    ... # This function runs once a day at 10 AM\n\nif __name__ == &amp;quot;__main__&amp;quot;:\n    app.run()\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;It has bunch of features: logical scheduling syntax, parallelism/concurrency, dynamic parametization, log to database etc. You can read from the docs: &lt;a href=\"https://rocketry.readthedocs.io/\"&gt;https://rocketry.readthedocs.io/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t think Rocketry will achieve the same level of adaptation as Airflow and it is missing many advanced features Airflow has such as built-in UI (&lt;a href=\"https://github.com/Miksus/rocketry-with-fastapi\"&gt;working on such&lt;/a&gt;), executors for containers etc. but considering how versatile it is and how powerful the scheduling is (basically logical statements), I think it could be interesting for those data engineers who need to customize their setup or need something smaller in scale.&lt;/p&gt;\n\n&lt;p&gt;Do you think there is anything missing from the available mature task orchestration products? Or is the space already saturated?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/K19odH5iyfuYZOK4oa3bjY5rvA0RaMLXsaOmBJW51GA.jpg?auto=webp&amp;s=22e17de7b28f864d02096b53e631e72426ba53e0", "width": 475, "height": 355}, "resolutions": [{"url": "https://external-preview.redd.it/K19odH5iyfuYZOK4oa3bjY5rvA0RaMLXsaOmBJW51GA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=75cfb8d79b5fb3996c7fadff940884cf21b60e36", "width": 108, "height": 80}, {"url": "https://external-preview.redd.it/K19odH5iyfuYZOK4oa3bjY5rvA0RaMLXsaOmBJW51GA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=20790f2d1e5644f77eeaecf1b46d986980c91311", "width": 216, "height": 161}, {"url": "https://external-preview.redd.it/K19odH5iyfuYZOK4oa3bjY5rvA0RaMLXsaOmBJW51GA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=83fa69e9d75035c2f014bca4c9621d7ee208260c", "width": 320, "height": 239}], "variants": {}, "id": "S-mAwIQucPvJFVqzltcRgmxIb2CrlEbzXkiwGmBizIc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "zaeiam", "is_robot_indexable": true, "report_reasons": null, "author": "Natural-Intelligence", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zaeiam/scheduling_in_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zaeiam/scheduling_in_data_engineering/", "subreddit_subscribers": 81636, "created_utc": 1669964573.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking to learn more about dbt(core) and more specifically, what challenges teams have with it. There is no shortage of \"pro\" dbt content on the internet, but I'd like to have a discussion about what's *wrong* with it. Not to hate on it, just to discuss what it could do better and/or differently (in your opinion).\n\nFor the sake of this discussion, let's assume everyone is bought into the idea of ELT and doing the T in the (presumably cloud based) warehouse using SQL. If you want to debate dbt vs a tool like Spark, then please start another thread. Full disclosure: I've never worked somewhere that uses dbt (I *have* played with it) but I know that there is a high probability my next employer(regardless of who that is) will already be using dbt. I also know enough to believe that dbt is the best choice out there for managing SQL transforms, but is that only because it is the only choice?\n\nOk, I'll start.\n\n* I hate that dbt makes me use references to build the DAG. Why can't it just parse my SQL and infer the DAG from that? (Maybe it can and it just isn't obvious?)", "author_fullname": "t2_ulpt0gri", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's \"wrong\" with dbt ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zamewl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669988066.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking to learn more about dbt(core) and more specifically, what challenges teams have with it. There is no shortage of &amp;quot;pro&amp;quot; dbt content on the internet, but I&amp;#39;d like to have a discussion about what&amp;#39;s &lt;em&gt;wrong&lt;/em&gt; with it. Not to hate on it, just to discuss what it could do better and/or differently (in your opinion).&lt;/p&gt;\n\n&lt;p&gt;For the sake of this discussion, let&amp;#39;s assume everyone is bought into the idea of ELT and doing the T in the (presumably cloud based) warehouse using SQL. If you want to debate dbt vs a tool like Spark, then please start another thread. Full disclosure: I&amp;#39;ve never worked somewhere that uses dbt (I &lt;em&gt;have&lt;/em&gt; played with it) but I know that there is a high probability my next employer(regardless of who that is) will already be using dbt. I also know enough to believe that dbt is the best choice out there for managing SQL transforms, but is that only because it is the only choice?&lt;/p&gt;\n\n&lt;p&gt;Ok, I&amp;#39;ll start.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I hate that dbt makes me use references to build the DAG. Why can&amp;#39;t it just parse my SQL and infer the DAG from that? (Maybe it can and it just isn&amp;#39;t obvious?)&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zamewl", "is_robot_indexable": true, "report_reasons": null, "author": "dadaengineering", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zamewl/whats_wrong_with_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zamewl/whats_wrong_with_dbt/", "subreddit_subscribers": 81636, "created_utc": 1669988066.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8otab4hd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hadoop Distributed File System", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_zadteq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/rih_mGYvtrZiW6CGn-tSdT7r2TCmsNWEyM1h6SWesx8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1669962328.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "hitachivantara.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.hitachivantara.com/en-us/insights/faq/hadoop-distributed-file-system.html", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7pebVmTSCfL-37MD1ubzlDPGAL3LjXDFcFREv7_ccFM.jpg?auto=webp&amp;s=621d4ec30514c64e9251d2d3a8321817fcb760b9", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/7pebVmTSCfL-37MD1ubzlDPGAL3LjXDFcFREv7_ccFM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=769e5456de5da1ce9a695db889295020b406ac49", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/7pebVmTSCfL-37MD1ubzlDPGAL3LjXDFcFREv7_ccFM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=13e9168b46167b1454580f889f0e2c5b2d06e52e", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/7pebVmTSCfL-37MD1ubzlDPGAL3LjXDFcFREv7_ccFM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d82483a1960865a3d831b6a03229dcb277a9ffe6", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/7pebVmTSCfL-37MD1ubzlDPGAL3LjXDFcFREv7_ccFM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d64aba344ccb713a053beb71974c00b4a5fc4279", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/7pebVmTSCfL-37MD1ubzlDPGAL3LjXDFcFREv7_ccFM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f0656a92059608c6758bbec802f4eda4fe293641", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/7pebVmTSCfL-37MD1ubzlDPGAL3LjXDFcFREv7_ccFM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b1d3080974a56e26d07cf182173be95c92b94fd7", "width": 1080, "height": 565}], "variants": {}, "id": "5IBEoPxJh0oVgTEqp_z5W6GnTwyJi_myOg-8stAyetQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zadteq", "is_robot_indexable": true, "report_reasons": null, "author": "ranjeettechnincal", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zadteq/hadoop_distributed_file_system/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.hitachivantara.com/en-us/insights/faq/hadoop-distributed-file-system.html", "subreddit_subscribers": 81636, "created_utc": 1669962328.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3yleu7rp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Announcing: Regression Testing for Your Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z9pcst", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1669905187.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "alvin.ai", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.alvin.ai/posts/announcing-regression-testing-for-your-data", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "z9pcst", "is_robot_indexable": true, "report_reasons": null, "author": "gabsferreiradev", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z9pcst/announcing_regression_testing_for_your_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.alvin.ai/posts/announcing-regression-testing-for-your-data", "subreddit_subscribers": 81636, "created_utc": 1669905187.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, \n \nI need to see the previous changes made to a stored procedures in BigQuery. Is there a way to keep track of the changes made to a procedure in the past? \n\nI am aware that bigquery offers changes history option for tables but I am not sure if it's the case for procedures as well. \n\nThanks in advance,", "author_fullname": "t2_8wbw972l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Change History for Procedures in BigQuery?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zaii9u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669977725.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, &lt;/p&gt;\n\n&lt;p&gt;I need to see the previous changes made to a stored procedures in BigQuery. Is there a way to keep track of the changes made to a procedure in the past? &lt;/p&gt;\n\n&lt;p&gt;I am aware that bigquery offers changes history option for tables but I am not sure if it&amp;#39;s the case for procedures as well. &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance,&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zaii9u", "is_robot_indexable": true, "report_reasons": null, "author": "HappyEnvironment8225", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zaii9u/change_history_for_procedures_in_bigquery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zaii9u/change_history_for_procedures_in_bigquery/", "subreddit_subscribers": 81636, "created_utc": 1669977725.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a junior data engineer, and got what I thought was an interesting question in an interview - intrigued by your collective approaches. I was given a toy case of a healthcare business that wanted to build a model to detect coughing in their waiting rooms (to de-risk spread of disease etc etc). They have some messy raw audio data from their waiting rooms that is usable. The interviewer asked how I would go about sourcing a robust dataset to train a model on. I came up with three ideas - intrigued to see what you guys think:  \n\n\n* Mechanical Turk the raw audio files to segment out the cases of coughing and label them depending on the \"type\" of cough (wheezy, light, hard etc)\n* Scrape YouTube vids for coughing occurrences and then Mechanical Turk or manually label the audio similar to above\n* Employ actors to cough to outlined constraints e.g. \"young woman with a wheezy cough, no background noise\", \"man with light cough in a busy space\" etc. etc.  \n\n\nThoughts welcomed!", "author_fullname": "t2_5lfzc2mu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data sourcing interview question I got - opinions wanted please", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zahfgf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669974559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a junior data engineer, and got what I thought was an interesting question in an interview - intrigued by your collective approaches. I was given a toy case of a healthcare business that wanted to build a model to detect coughing in their waiting rooms (to de-risk spread of disease etc etc). They have some messy raw audio data from their waiting rooms that is usable. The interviewer asked how I would go about sourcing a robust dataset to train a model on. I came up with three ideas - intrigued to see what you guys think:  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Mechanical Turk the raw audio files to segment out the cases of coughing and label them depending on the &amp;quot;type&amp;quot; of cough (wheezy, light, hard etc)&lt;/li&gt;\n&lt;li&gt;Scrape YouTube vids for coughing occurrences and then Mechanical Turk or manually label the audio similar to above&lt;/li&gt;\n&lt;li&gt;Employ actors to cough to outlined constraints e.g. &amp;quot;young woman with a wheezy cough, no background noise&amp;quot;, &amp;quot;man with light cough in a busy space&amp;quot; etc. etc.&lt;br/&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thoughts welcomed!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "zahfgf", "is_robot_indexable": true, "report_reasons": null, "author": "fourcornerclub", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zahfgf/data_sourcing_interview_question_i_got_opinions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zahfgf/data_sourcing_interview_question_i_got_opinions/", "subreddit_subscribers": 81636, "created_utc": 1669974559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working with a software that uses Aurora MySQL as it's primary storage and it's modeled with single table multi tenancy: every entity has a tenant\\_id column (except the tenants table).\n\nI want to implement a feature where users can write their own SQL queries for analytics. Current schema won't allow it, so I need to implement a pipeline that outputs \\_n\\_ files per table (\\_n\\_ being the number of tenants). End goal would be querying S3 Data using Athena, maybe even something like Metabase.\n\nAlso planning to implement Airbyte to sync other external sources (ie Saleforce) onto our data lake.\n\nMy initial research lead me to Airflow then Dagster then AWS Glue. I'm feeling a bit stuck on how to design this. Any hints that could that could aid my research journey are really appreciated. Thanks!", "author_fullname": "t2_gyauc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First data lake pipeline advice - multitenancy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zackyb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669958535.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working with a software that uses Aurora MySQL as it&amp;#39;s primary storage and it&amp;#39;s modeled with single table multi tenancy: every entity has a tenant_id column (except the tenants table).&lt;/p&gt;\n\n&lt;p&gt;I want to implement a feature where users can write their own SQL queries for analytics. Current schema won&amp;#39;t allow it, so I need to implement a pipeline that outputs _n_ files per table (_n_ being the number of tenants). End goal would be querying S3 Data using Athena, maybe even something like Metabase.&lt;/p&gt;\n\n&lt;p&gt;Also planning to implement Airbyte to sync other external sources (ie Saleforce) onto our data lake.&lt;/p&gt;\n\n&lt;p&gt;My initial research lead me to Airflow then Dagster then AWS Glue. I&amp;#39;m feeling a bit stuck on how to design this. Any hints that could that could aid my research journey are really appreciated. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zackyb", "is_robot_indexable": true, "report_reasons": null, "author": "fedeisas", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zackyb/first_data_lake_pipeline_advice_multitenancy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zackyb/first_data_lake_pipeline_advice_multitenancy/", "subreddit_subscribers": 81636, "created_utc": 1669958535.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, I have recently graduated and I've been working 3 months as a Junior Data Engineer in a tech consulting company (a body rental company) in Spain. Currently I don't know most of the tools/skills I hear about in this sub (Airflow, Docker...) and we are not using them either. I've been working with SSIS and Informatica Intelligent Cloud Services this months and I want to know what do you think about. Are these tools outdated? is it a valuable skill and should I keep learning? Or shoud I try to use other tools in my job. I want to learn other tools in my free time but right now I'm having problems finding some. Thanks in advance!", "author_fullname": "t2_2b0vnvfy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about the stack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zahp81", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669975409.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I have recently graduated and I&amp;#39;ve been working 3 months as a Junior Data Engineer in a tech consulting company (a body rental company) in Spain. Currently I don&amp;#39;t know most of the tools/skills I hear about in this sub (Airflow, Docker...) and we are not using them either. I&amp;#39;ve been working with SSIS and Informatica Intelligent Cloud Services this months and I want to know what do you think about. Are these tools outdated? is it a valuable skill and should I keep learning? Or shoud I try to use other tools in my job. I want to learn other tools in my free time but right now I&amp;#39;m having problems finding some. Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zahp81", "is_robot_indexable": true, "report_reasons": null, "author": "jota_point", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zahp81/question_about_the_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zahp81/question_about_the_stack/", "subreddit_subscribers": 81636, "created_utc": 1669975409.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone!\n\nSo our team has planned to use Airflow (MWAA) to run the jobs. Is it possible to trigger/ track job information using Control M? \n\nI'm pretty new to these orchestration tools, so any help would be really appreciated!", "author_fullname": "t2_5hwgf7ph", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Control - M and MWA Airflow Integration?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zahl8k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669975129.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone!&lt;/p&gt;\n\n&lt;p&gt;So our team has planned to use Airflow (MWAA) to run the jobs. Is it possible to trigger/ track job information using Control M? &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m pretty new to these orchestration tools, so any help would be really appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zahl8k", "is_robot_indexable": true, "report_reasons": null, "author": "fullyloadedkid", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zahl8k/control_m_and_mwa_airflow_integration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zahl8k/control_m_and_mwa_airflow_integration/", "subreddit_subscribers": 81636, "created_utc": 1669975129.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello!\n\nWe have a good amount of data (around 700Gb) that we need to move from Redshift to an RDS table. The data has been unloaded into an S3 in parallel (data\\_000\\_part0, data\\_001\\_part0, etc...) with a manifest file. It does not seem that we can load data from S3 to RDS thanks to the manifest file, as we would do with Redshift: [https://docs.aws.amazon.com/redshift/latest/dg/t\\_Reloading\\_unload\\_files.html](https://docs.aws.amazon.com/redshift/latest/dg/t_Reloading_unload_files.html)\n\nIn this case, would the only solution be to loop over all the unloaded files in the S3 bucket and perform the `aws_s3.table_import_from_s3`, or did I miss a parameter in this command that would accept the manifest file?\n\nI don't really have time to implement another solution and would be glad to keep the process as it is, and find a workaround with `aws_s3.table_import_from_s3`.\n\n Thanks!", "author_fullname": "t2_f1ixi4vt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to move data from Redshift to S3 and then from S3 to RDS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zaglxw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669971701.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;We have a good amount of data (around 700Gb) that we need to move from Redshift to an RDS table. The data has been unloaded into an S3 in parallel (data_000_part0, data_001_part0, etc...) with a manifest file. It does not seem that we can load data from S3 to RDS thanks to the manifest file, as we would do with Redshift: &lt;a href=\"https://docs.aws.amazon.com/redshift/latest/dg/t_Reloading_unload_files.html\"&gt;https://docs.aws.amazon.com/redshift/latest/dg/t_Reloading_unload_files.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;In this case, would the only solution be to loop over all the unloaded files in the S3 bucket and perform the &lt;code&gt;aws_s3.table_import_from_s3&lt;/code&gt;, or did I miss a parameter in this command that would accept the manifest file?&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t really have time to implement another solution and would be glad to keep the process as it is, and find a workaround with &lt;code&gt;aws_s3.table_import_from_s3&lt;/code&gt;.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zaglxw", "is_robot_indexable": true, "report_reasons": null, "author": "No_Fudge1060", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zaglxw/best_way_to_move_data_from_redshift_to_s3_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zaglxw/best_way_to_move_data_from_redshift_to_s3_and/", "subreddit_subscribers": 81636, "created_utc": 1669971701.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company has a dozen data-scientists that like to use Notebooks to run/test spark processing.\n\nThe issue I have, is that to avoid having to initialize a spark session, they keep one open, which holds whatever resources they have been using even if the Notebook is idle.\n\nHave you faced a similar use case? Any way I can get the best of both worlds?", "author_fullname": "t2_85uwiihz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Accommodating Spark for Jupyter Notebook usage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zaex8y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1669968555.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669965913.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company has a dozen data-scientists that like to use Notebooks to run/test spark processing.&lt;/p&gt;\n\n&lt;p&gt;The issue I have, is that to avoid having to initialize a spark session, they keep one open, which holds whatever resources they have been using even if the Notebook is idle.&lt;/p&gt;\n\n&lt;p&gt;Have you faced a similar use case? Any way I can get the best of both worlds?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zaex8y", "is_robot_indexable": true, "report_reasons": null, "author": "GeekyTricky", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zaex8y/accommodating_spark_for_jupyter_notebook_usage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zaex8y/accommodating_spark_for_jupyter_notebook_usage/", "subreddit_subscribers": 81636, "created_utc": 1669965913.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This thread is a place where you can share things that might not warrant their own thread. It is automatically posted each month and you can find previous threads in the collection.\n\nExamples:\n\n* What are you working on this month?\n* What was something you accomplished?\n* What was something you learned recently?\n* What is something frustrating you currently?\n\nAs always, sub rules apply. Please be respectful and stay curious.", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Monthly General Discussion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "collections": [{"permalink": "https://www.reddit.com/r/dataengineering/collection/6278fda2-fad1-4706-9e82-6ddb67d49c0b", "link_ids": ["t3_shzqhy", "t3_t4clgk", "t3_ttu87x", "t3_ug2xqg", "t3_v2ka5e", "t3_vp487n", "t3_wdl07g", "t3_x3bb2b", "t3_xsyy4v", "t3_yjchhi", "t3_z9szlc"], "description": "", "title": "Monthly General Discussions", "created_at_utc": 1642292653.587, "subreddit_id": "t5_36en4", "author_name": "theporterhaus", "collection_id": "6278fda2-fad1-4706-9e82-6ddb67d49c0b", "author_id": "t2_2tv9i42n", "last_update_utc": 1669914009.731, "display_layout": null}], "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z9szlc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669914009.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This thread is a place where you can share things that might not warrant their own thread. It is automatically posted each month and you can find previous threads in the collection.&lt;/p&gt;\n\n&lt;p&gt;Examples:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;What are you working on this month?&lt;/li&gt;\n&lt;li&gt;What was something you accomplished?&lt;/li&gt;\n&lt;li&gt;What was something you learned recently?&lt;/li&gt;\n&lt;li&gt;What is something frustrating you currently?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;As always, sub rules apply. Please be respectful and stay curious.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z9szlc", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z9szlc/monthly_general_discussion/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/dataengineering/comments/z9szlc/monthly_general_discussion/", "subreddit_subscribers": 81636, "created_utc": 1669914009.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Snowflake for beginners like from where to start", "author_fullname": "t2_jfvfwj1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can anyone give Snowflake Roadmap ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z9p0gx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669904315.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Snowflake for beginners like from where to start&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z9p0gx", "is_robot_indexable": true, "report_reasons": null, "author": "Vijay_Sharma_777", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z9p0gx/can_anyone_give_snowflake_roadmap/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z9p0gx/can_anyone_give_snowflake_roadmap/", "subreddit_subscribers": 81636, "created_utc": 1669904315.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious about how to drive revenue via your 1st party customer data?  \n\n\nNext Tuesday (Dec. 6),  [Jim Lumsden](https://www.linkedin.com/in/jim-a-lumsden/) (data lead @\u00a0[Prolific](https://www.linkedin.com/company/prolific-academic/)), [Mike Maloney](https://www.linkedin.com/in/mike-maloney-5229274/) (field CDO\u00a0@\u00a0[Snowplow](https://www.linkedin.com/in/mike-maloney-5229274/)), [Shashi Raina](https://www.linkedin.com/in/shashiraina/) (sr. partner solutions architect @\u00a0[AWS](https://www.linkedin.com/company/amazon-web-services/)),\u00a0and [Donny Flynn](https://www.linkedin.com/in/donny-flynn-578149a4/) (customer data architect @ [Census](https://www.linkedin.com/company/19055959/admin/)) will break down how to create a data-first culture to support and drive revenue like never before.\n\nThey'll discuss how, using real-world examples from the Prolific data team, Snowplow, AWS, and Census can help you drive more growth for your business by unlocking rich, unified, and accessible behavioral data across your organization.\n\nFaced with the need for high-quality, reliable data, Prolific\u2019s data team built a technology stack to create complete Customer Behavioral Profiles, ensuring the rest of their could access actionable data to best engage with their customers.\n\nWith Customer Behavioral Profiles (and the right data stack), you too can predict your user\u2019s next best action and power your sales team with complete visibility into your customers\u2019 interactions, which means higher sales conversions and revenue. \ud83e\udd11\n\n**Join us as we discuss:**  \n\n\n* The importance of having a high quality data-first culture\u00a0\ud83e\udd1d\n* How Prolific supercharged their sales team with product analytics\u00a0\ud83d\ude80\n* How Customer Behavioral Profiles can empower your organization \ud83d\udcc8\n\nHope to see you there! Sing up \ud83d\udc49 [**here**](https://www.getcensus.com/events/webinar-how-prolific-supercharged-revenue-with-powerful-customer-profiles) \ud83d\udc48", "author_fullname": "t2_ezsyorvh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to support and drive revenue team through data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z9ycz0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.27, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669925665.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious about how to drive revenue via your 1st party customer data?  &lt;/p&gt;\n\n&lt;p&gt;Next Tuesday (Dec. 6),  &lt;a href=\"https://www.linkedin.com/in/jim-a-lumsden/\"&gt;Jim Lumsden&lt;/a&gt; (data lead @\u00a0&lt;a href=\"https://www.linkedin.com/company/prolific-academic/\"&gt;Prolific&lt;/a&gt;), &lt;a href=\"https://www.linkedin.com/in/mike-maloney-5229274/\"&gt;Mike Maloney&lt;/a&gt; (field CDO\u00a0@\u00a0&lt;a href=\"https://www.linkedin.com/in/mike-maloney-5229274/\"&gt;Snowplow&lt;/a&gt;), &lt;a href=\"https://www.linkedin.com/in/shashiraina/\"&gt;Shashi Raina&lt;/a&gt; (sr. partner solutions architect @\u00a0&lt;a href=\"https://www.linkedin.com/company/amazon-web-services/\"&gt;AWS&lt;/a&gt;),\u00a0and &lt;a href=\"https://www.linkedin.com/in/donny-flynn-578149a4/\"&gt;Donny Flynn&lt;/a&gt; (customer data architect @ &lt;a href=\"https://www.linkedin.com/company/19055959/admin/\"&gt;Census&lt;/a&gt;) will break down how to create a data-first culture to support and drive revenue like never before.&lt;/p&gt;\n\n&lt;p&gt;They&amp;#39;ll discuss how, using real-world examples from the Prolific data team, Snowplow, AWS, and Census can help you drive more growth for your business by unlocking rich, unified, and accessible behavioral data across your organization.&lt;/p&gt;\n\n&lt;p&gt;Faced with the need for high-quality, reliable data, Prolific\u2019s data team built a technology stack to create complete Customer Behavioral Profiles, ensuring the rest of their could access actionable data to best engage with their customers.&lt;/p&gt;\n\n&lt;p&gt;With Customer Behavioral Profiles (and the right data stack), you too can predict your user\u2019s next best action and power your sales team with complete visibility into your customers\u2019 interactions, which means higher sales conversions and revenue. \ud83e\udd11&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Join us as we discuss:&lt;/strong&gt;  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The importance of having a high quality data-first culture\u00a0\ud83e\udd1d&lt;/li&gt;\n&lt;li&gt;How Prolific supercharged their sales team with product analytics\u00a0\ud83d\ude80&lt;/li&gt;\n&lt;li&gt;How Customer Behavioral Profiles can empower your organization \ud83d\udcc8&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Hope to see you there! Sing up \ud83d\udc49 &lt;a href=\"https://www.getcensus.com/events/webinar-how-prolific-supercharged-revenue-with-powerful-customer-profiles\"&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt; \ud83d\udc48&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z9ycz0", "is_robot_indexable": true, "report_reasons": null, "author": "Firm_Spite2939", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z9ycz0/how_to_support_and_drive_revenue_team_through_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z9ycz0/how_to_support_and_drive_revenue_team_through_data/", "subreddit_subscribers": 81636, "created_utc": 1669925665.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}