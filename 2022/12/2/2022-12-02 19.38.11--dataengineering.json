{"kind": "Listing", "data": {"after": null, "dist": 21, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking to learn more about dbt(core) and more specifically, what challenges teams have with it. There is no shortage of \"pro\" dbt content on the internet, but I'd like to have a discussion about what's *wrong* with it. Not to hate on it, just to discuss what it could do better and/or differently (in your opinion).\n\nFor the sake of this discussion, let's assume everyone is bought into the idea of ELT and doing the T in the (presumably cloud based) warehouse using SQL. If you want to debate dbt vs a tool like Spark, then please start another thread. Full disclosure: I've never worked somewhere that uses dbt (I *have* played with it) but I know that there is a high probability my next employer(regardless of who that is) will already be using dbt. I also know enough to believe that dbt is the best choice out there for managing SQL transforms, but is that only because it is the only choice?\n\nOk, I'll start.\n\n* I hate that dbt makes me use references to build the DAG. Why can't it just parse my SQL and infer the DAG from that? (Maybe it can and it just isn't obvious?)", "author_fullname": "t2_ulpt0gri", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's \"wrong\" with dbt ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zamewl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 74, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 74, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669988066.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking to learn more about dbt(core) and more specifically, what challenges teams have with it. There is no shortage of &amp;quot;pro&amp;quot; dbt content on the internet, but I&amp;#39;d like to have a discussion about what&amp;#39;s &lt;em&gt;wrong&lt;/em&gt; with it. Not to hate on it, just to discuss what it could do better and/or differently (in your opinion).&lt;/p&gt;\n\n&lt;p&gt;For the sake of this discussion, let&amp;#39;s assume everyone is bought into the idea of ELT and doing the T in the (presumably cloud based) warehouse using SQL. If you want to debate dbt vs a tool like Spark, then please start another thread. Full disclosure: I&amp;#39;ve never worked somewhere that uses dbt (I &lt;em&gt;have&lt;/em&gt; played with it) but I know that there is a high probability my next employer(regardless of who that is) will already be using dbt. I also know enough to believe that dbt is the best choice out there for managing SQL transforms, but is that only because it is the only choice?&lt;/p&gt;\n\n&lt;p&gt;Ok, I&amp;#39;ll start.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I hate that dbt makes me use references to build the DAG. Why can&amp;#39;t it just parse my SQL and infer the DAG from that? (Maybe it can and it just isn&amp;#39;t obvious?)&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zamewl", "is_robot_indexable": true, "report_reasons": null, "author": "dadaengineering", "discussion_type": null, "num_comments": 43, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zamewl/whats_wrong_with_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zamewl/whats_wrong_with_dbt/", "subreddit_subscribers": 81661, "created_utc": 1669988066.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_brkxjomi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If data engineering did Spotify Wrapped", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 139, "top_awarded_type": null, "hide_score": false, "name": "t3_zaqmay", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 52, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 52, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/2fQ1Y_URnhu3RTFsjzcXVc9Y0DA5lzvuvlLxRs464Bw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_1": 1}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1669998791.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/uemt99k9ii3a1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/uemt99k9ii3a1.png?auto=webp&amp;s=ea1942b60002c2a9eaf20946d643c54244452c3d", "width": 466, "height": 465}, "resolutions": [{"url": "https://preview.redd.it/uemt99k9ii3a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=200ec08abe53cfaba89ba58d7122811fdbeed410", "width": 108, "height": 107}, {"url": "https://preview.redd.it/uemt99k9ii3a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=94b9f7ebe2e6e1a1ed47dc0ea1d5e37adc66e718", "width": 216, "height": 215}, {"url": "https://preview.redd.it/uemt99k9ii3a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ab3ea93438e1f613266ec142da53a2044144ce57", "width": 320, "height": 319}], "variants": {}, "id": "fIKAP8PlJPMhCtF3FGYm5FYOUY43klnqYKiiCvbH-lc"}], "enabled": true}, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 100, "id": "gid_1", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Shows the Silver Award... and that's it.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Silver", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "zaqmay", "is_robot_indexable": true, "report_reasons": null, "author": "Straight_House8628", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zaqmay/if_data_engineering_did_spotify_wrapped/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/uemt99k9ii3a1.png", "subreddit_subscribers": 81661, "created_utc": 1669998791.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am wondering on how to get hands on with cloud services like redshift, s3, kinda stuffs. I think i've some good overview of data warehouse  and dimensional modelling. Thinking of applying data warehouse concepts on a project or something and i'm thinking of building data warehouse on a cloud to get some practical experience but the thing is I don't know where to start with the cloud. \n\nShould I gather experience exploring the tools or rather take some courses? \n\nAnd also what kind of projects would really stand out from others ?", "author_fullname": "t2_aenh4mw5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get start with cloud(AWS)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_za88nk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669947588.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am wondering on how to get hands on with cloud services like redshift, s3, kinda stuffs. I think i&amp;#39;ve some good overview of data warehouse  and dimensional modelling. Thinking of applying data warehouse concepts on a project or something and i&amp;#39;m thinking of building data warehouse on a cloud to get some practical experience but the thing is I don&amp;#39;t know where to start with the cloud. &lt;/p&gt;\n\n&lt;p&gt;Should I gather experience exploring the tools or rather take some courses? &lt;/p&gt;\n\n&lt;p&gt;And also what kind of projects would really stand out from others ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "za88nk", "is_robot_indexable": true, "report_reasons": null, "author": "Suspicious_Peanut282", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/za88nk/how_to_get_start_with_cloudaws/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/za88nk/how_to_get_start_with_cloudaws/", "subreddit_subscribers": 81661, "created_utc": 1669947588.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "While the following is similar to a lot of hopeful graduates looking for their first data job, my story is a little bit on the unusual side so I figured some more tailored advice would be very much appreciated. Thank you for valuable time in advance!\n\nI'm from a social science background in psychology where I focused on doing extra statistics subjects at university and always wanted to be  a researcher. Bombed out of my PhD with no measurable accomplishments besides an appreciation for Python, and exposure to MATLAB for data pipelines on EEG data. I spent the next 2 years consulting 4th year students on how to run data analysis on their research  -- all in SPSS.\n\nPulled myself together and left that behind me to focus entirely on full-time work search and upskilling. I'm currently learning Python, PowerBI, and TSQL and applying them in small projects.Right now I'm working mainly on kaggle datasets - one for querying in SQL Server Management Studio to show my ability to write SQL and visualising in PowerBI, and the other one using entirely Python because the file is sqlite and SSMS makes it annoying to open, so Python sqlite3 it is!\n\nOn that note, it seems to be advice I hear from everyone, just demonstrate your skills with projects. But if everyone is doing projects, it seems a little difficult to stand out if you're not an IT/CS/Data graduate.\n\nMy current plans are to keep plugging away at these projects and upload to github, learning daily on Udemy for PowerBI and a couple of Jose Portilla courses for Python and Python for data science, then move on to a bit more of a complex project involving sentiment analysis in Python. At the same time I've started on CS50 as I recognise I lack some fundamentals and have some bad coding habits.\n\nDoes anybody have some advice for demonstrating skills or suitability for an entry level data role besides what I'm already doing, and continuing to grow into a data engineering career?\n\n\\- Sincerely, a data enthusiast", "author_fullname": "t2_zz4yu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Breaking into data analyst role and future data engineer career", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_za1nhu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669932670.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;While the following is similar to a lot of hopeful graduates looking for their first data job, my story is a little bit on the unusual side so I figured some more tailored advice would be very much appreciated. Thank you for valuable time in advance!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m from a social science background in psychology where I focused on doing extra statistics subjects at university and always wanted to be  a researcher. Bombed out of my PhD with no measurable accomplishments besides an appreciation for Python, and exposure to MATLAB for data pipelines on EEG data. I spent the next 2 years consulting 4th year students on how to run data analysis on their research  -- all in SPSS.&lt;/p&gt;\n\n&lt;p&gt;Pulled myself together and left that behind me to focus entirely on full-time work search and upskilling. I&amp;#39;m currently learning Python, PowerBI, and TSQL and applying them in small projects.Right now I&amp;#39;m working mainly on kaggle datasets - one for querying in SQL Server Management Studio to show my ability to write SQL and visualising in PowerBI, and the other one using entirely Python because the file is sqlite and SSMS makes it annoying to open, so Python sqlite3 it is!&lt;/p&gt;\n\n&lt;p&gt;On that note, it seems to be advice I hear from everyone, just demonstrate your skills with projects. But if everyone is doing projects, it seems a little difficult to stand out if you&amp;#39;re not an IT/CS/Data graduate.&lt;/p&gt;\n\n&lt;p&gt;My current plans are to keep plugging away at these projects and upload to github, learning daily on Udemy for PowerBI and a couple of Jose Portilla courses for Python and Python for data science, then move on to a bit more of a complex project involving sentiment analysis in Python. At the same time I&amp;#39;ve started on CS50 as I recognise I lack some fundamentals and have some bad coding habits.&lt;/p&gt;\n\n&lt;p&gt;Does anybody have some advice for demonstrating skills or suitability for an entry level data role besides what I&amp;#39;m already doing, and continuing to grow into a data engineering career?&lt;/p&gt;\n\n&lt;p&gt;- Sincerely, a data enthusiast&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "za1nhu", "is_robot_indexable": true, "report_reasons": null, "author": "OloroMemez", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/za1nhu/breaking_into_data_analyst_role_and_future_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/za1nhu/breaking_into_data_analyst_role_and_future_data/", "subreddit_subscribers": 81661, "created_utc": 1669932670.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are your KPIs / North Star metrics for Data Engineering? How do you establish the productivity of your team?  \n\n\nI know this is hard to quantify, but we're trying to set a few north star metrics that we could display to the rest of the company", "author_fullname": "t2_kinpz3uc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering KPIs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zanclu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669990420.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are your KPIs / North Star metrics for Data Engineering? How do you establish the productivity of your team?  &lt;/p&gt;\n\n&lt;p&gt;I know this is hard to quantify, but we&amp;#39;re trying to set a few north star metrics that we could display to the rest of the company&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zanclu", "is_robot_indexable": true, "report_reasons": null, "author": "Brewash_Beer", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zanclu/data_engineering_kpis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zanclu/data_engineering_kpis/", "subreddit_subscribers": 81661, "created_utc": 1669990420.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I'm in a new job where I'm in way over my head (or so it feels like) and my weakest side is that I suck at Azure. Managed identities, service principals, oauth 2.0, sas tokens, file system drivers, vnets, subnets... There are so many security concepts that I simply read about so many times, but I am never able to learn how they are all related and get an overview. My brain is simply unable to comprehend it all unless I can REALLY get a grasp. I'm a very all or nothing guy, hearing a word here and there never makes it stick. \n\nI'm currently working with the IaC team tp implement Databricks, Unity Catalog and for everything outside Databricks I really struggle. Does anyone have any good tips? I was recommended by a colleague to do the AZ-104 certification (or at least read the learning materials). Any other tips?", "author_fullname": "t2_4ov075m4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need to improve my cloud (Azure) skills to become a better data engineer. Tips?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zagbo0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669970714.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;m in a new job where I&amp;#39;m in way over my head (or so it feels like) and my weakest side is that I suck at Azure. Managed identities, service principals, oauth 2.0, sas tokens, file system drivers, vnets, subnets... There are so many security concepts that I simply read about so many times, but I am never able to learn how they are all related and get an overview. My brain is simply unable to comprehend it all unless I can REALLY get a grasp. I&amp;#39;m a very all or nothing guy, hearing a word here and there never makes it stick. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working with the IaC team tp implement Databricks, Unity Catalog and for everything outside Databricks I really struggle. Does anyone have any good tips? I was recommended by a colleague to do the AZ-104 certification (or at least read the learning materials). Any other tips?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zagbo0", "is_robot_indexable": true, "report_reasons": null, "author": "HealthyDoggos4Life", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zagbo0/need_to_improve_my_cloud_azure_skills_to_become_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zagbo0/need_to_improve_my_cloud_azure_skills_to_become_a/", "subreddit_subscribers": 81661, "created_utc": 1669970714.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all!\n\nI'm the developer behind [Rocketry](https://github.com/Miksus/rocketry), a Pythonic scheduling engine. I originally developed it for other needs than data engineering but as some have said they have started to replace Airflow with it, I thought perhaps some of you might like it as well. I'm also interested in your opinions.\n\nA bit about the framework, it is quite minimal:\n\n    from rocketry import Rocketry\n    from rocketry.conds import daily\n    \n    app = Rocketry()\n    \n    @app.task(daily.at(\"10:00\"))\n    def do_daily():\n        ... # This function runs once a day at 10 AM\n    \n    if __name__ == \"__main__\":\n        app.run()\n\nIt has bunch of features: logical scheduling syntax, parallelism/concurrency, dynamic parametization, log to database etc. You can read from the docs: [https://rocketry.readthedocs.io/](https://rocketry.readthedocs.io/)\n\nI don't think Rocketry will achieve the same level of adaptation as Airflow and it is missing many advanced features Airflow has such as built-in UI ([working on such](https://github.com/Miksus/rocketry-with-fastapi)), executors for containers etc. but considering how versatile it is and how powerful the scheduling is (basically logical statements), I think it could be interesting for those data engineers who need to customize their setup or need something smaller in scale.\n\nDo you think there is anything missing from the available mature task orchestration products? Or is the space already saturated?", "author_fullname": "t2_23tmpa91", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scheduling in Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zaeiam", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1669964573.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m the developer behind &lt;a href=\"https://github.com/Miksus/rocketry\"&gt;Rocketry&lt;/a&gt;, a Pythonic scheduling engine. I originally developed it for other needs than data engineering but as some have said they have started to replace Airflow with it, I thought perhaps some of you might like it as well. I&amp;#39;m also interested in your opinions.&lt;/p&gt;\n\n&lt;p&gt;A bit about the framework, it is quite minimal:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;from rocketry import Rocketry\nfrom rocketry.conds import daily\n\napp = Rocketry()\n\n@app.task(daily.at(&amp;quot;10:00&amp;quot;))\ndef do_daily():\n    ... # This function runs once a day at 10 AM\n\nif __name__ == &amp;quot;__main__&amp;quot;:\n    app.run()\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;It has bunch of features: logical scheduling syntax, parallelism/concurrency, dynamic parametization, log to database etc. You can read from the docs: &lt;a href=\"https://rocketry.readthedocs.io/\"&gt;https://rocketry.readthedocs.io/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t think Rocketry will achieve the same level of adaptation as Airflow and it is missing many advanced features Airflow has such as built-in UI (&lt;a href=\"https://github.com/Miksus/rocketry-with-fastapi\"&gt;working on such&lt;/a&gt;), executors for containers etc. but considering how versatile it is and how powerful the scheduling is (basically logical statements), I think it could be interesting for those data engineers who need to customize their setup or need something smaller in scale.&lt;/p&gt;\n\n&lt;p&gt;Do you think there is anything missing from the available mature task orchestration products? Or is the space already saturated?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/K19odH5iyfuYZOK4oa3bjY5rvA0RaMLXsaOmBJW51GA.jpg?auto=webp&amp;s=22e17de7b28f864d02096b53e631e72426ba53e0", "width": 475, "height": 355}, "resolutions": [{"url": "https://external-preview.redd.it/K19odH5iyfuYZOK4oa3bjY5rvA0RaMLXsaOmBJW51GA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=75cfb8d79b5fb3996c7fadff940884cf21b60e36", "width": 108, "height": 80}, {"url": "https://external-preview.redd.it/K19odH5iyfuYZOK4oa3bjY5rvA0RaMLXsaOmBJW51GA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=20790f2d1e5644f77eeaecf1b46d986980c91311", "width": 216, "height": 161}, {"url": "https://external-preview.redd.it/K19odH5iyfuYZOK4oa3bjY5rvA0RaMLXsaOmBJW51GA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=83fa69e9d75035c2f014bca4c9621d7ee208260c", "width": 320, "height": 239}], "variants": {}, "id": "S-mAwIQucPvJFVqzltcRgmxIb2CrlEbzXkiwGmBizIc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "zaeiam", "is_robot_indexable": true, "report_reasons": null, "author": "Natural-Intelligence", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zaeiam/scheduling_in_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zaeiam/scheduling_in_data_engineering/", "subreddit_subscribers": 81661, "created_utc": 1669964573.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8otab4hd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hadoop Distributed File System", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_zadteq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/rih_mGYvtrZiW6CGn-tSdT7r2TCmsNWEyM1h6SWesx8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1669962328.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "hitachivantara.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.hitachivantara.com/en-us/insights/faq/hadoop-distributed-file-system.html", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7pebVmTSCfL-37MD1ubzlDPGAL3LjXDFcFREv7_ccFM.jpg?auto=webp&amp;s=621d4ec30514c64e9251d2d3a8321817fcb760b9", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/7pebVmTSCfL-37MD1ubzlDPGAL3LjXDFcFREv7_ccFM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=769e5456de5da1ce9a695db889295020b406ac49", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/7pebVmTSCfL-37MD1ubzlDPGAL3LjXDFcFREv7_ccFM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=13e9168b46167b1454580f889f0e2c5b2d06e52e", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/7pebVmTSCfL-37MD1ubzlDPGAL3LjXDFcFREv7_ccFM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d82483a1960865a3d831b6a03229dcb277a9ffe6", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/7pebVmTSCfL-37MD1ubzlDPGAL3LjXDFcFREv7_ccFM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d64aba344ccb713a053beb71974c00b4a5fc4279", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/7pebVmTSCfL-37MD1ubzlDPGAL3LjXDFcFREv7_ccFM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f0656a92059608c6758bbec802f4eda4fe293641", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/7pebVmTSCfL-37MD1ubzlDPGAL3LjXDFcFREv7_ccFM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b1d3080974a56e26d07cf182173be95c92b94fd7", "width": 1080, "height": 565}], "variants": {}, "id": "5IBEoPxJh0oVgTEqp_z5W6GnTwyJi_myOg-8stAyetQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zadteq", "is_robot_indexable": true, "report_reasons": null, "author": "ranjeettechnincal", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zadteq/hadoop_distributed_file_system/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.hitachivantara.com/en-us/insights/faq/hadoop-distributed-file-system.html", "subreddit_subscribers": 81661, "created_utc": 1669962328.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working with a software that uses Aurora MySQL as it's primary storage and it's modeled with single table multi tenancy: every entity has a tenant\\_id column (except the tenants table).\n\nI want to implement a feature where users can write their own SQL queries for analytics. Current schema won't allow it, so I need to implement a pipeline that outputs \\_n\\_ files per table (\\_n\\_ being the number of tenants). End goal would be querying S3 Data using Athena, maybe even something like Metabase.\n\nAlso planning to implement Airbyte to sync other external sources (ie Saleforce) onto our data lake.\n\nMy initial research lead me to Airflow then Dagster then AWS Glue. I'm feeling a bit stuck on how to design this. Any hints that could that could aid my research journey are really appreciated. Thanks!", "author_fullname": "t2_gyauc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First data lake pipeline advice - multitenancy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zackyb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669958535.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working with a software that uses Aurora MySQL as it&amp;#39;s primary storage and it&amp;#39;s modeled with single table multi tenancy: every entity has a tenant_id column (except the tenants table).&lt;/p&gt;\n\n&lt;p&gt;I want to implement a feature where users can write their own SQL queries for analytics. Current schema won&amp;#39;t allow it, so I need to implement a pipeline that outputs _n_ files per table (_n_ being the number of tenants). End goal would be querying S3 Data using Athena, maybe even something like Metabase.&lt;/p&gt;\n\n&lt;p&gt;Also planning to implement Airbyte to sync other external sources (ie Saleforce) onto our data lake.&lt;/p&gt;\n\n&lt;p&gt;My initial research lead me to Airflow then Dagster then AWS Glue. I&amp;#39;m feeling a bit stuck on how to design this. Any hints that could that could aid my research journey are really appreciated. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zackyb", "is_robot_indexable": true, "report_reasons": null, "author": "fedeisas", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zackyb/first_data_lake_pipeline_advice_multitenancy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zackyb/first_data_lake_pipeline_advice_multitenancy/", "subreddit_subscribers": 81661, "created_utc": 1669958535.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, \n \nI need to see the previous changes made to a stored procedure in BigQuery. Is there a way to keep track of the changes made to a procedure in the past? \n\nI am aware that bigquery offers change history option for tables but I am not sure if it's the case for procedures as well. \n\nThanks in advance,", "author_fullname": "t2_8wbw972l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Change History for Procedures in BigQuery?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zaii9u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1670007239.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669977725.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, &lt;/p&gt;\n\n&lt;p&gt;I need to see the previous changes made to a stored procedure in BigQuery. Is there a way to keep track of the changes made to a procedure in the past? &lt;/p&gt;\n\n&lt;p&gt;I am aware that bigquery offers change history option for tables but I am not sure if it&amp;#39;s the case for procedures as well. &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance,&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zaii9u", "is_robot_indexable": true, "report_reasons": null, "author": "HappyEnvironment8225", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zaii9u/change_history_for_procedures_in_bigquery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zaii9u/change_history_for_procedures_in_bigquery/", "subreddit_subscribers": 81661, "created_utc": 1669977725.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a junior data engineer, and got what I thought was an interesting question in an interview - intrigued by your collective approaches. I was given a toy case of a healthcare business that wanted to build a model to detect coughing in their waiting rooms (to de-risk spread of disease etc etc). They have some messy raw audio data from their waiting rooms that is usable. The interviewer asked how I would go about sourcing a robust dataset to train a model on. I came up with three ideas - intrigued to see what you guys think:  \n\n\n* Mechanical Turk the raw audio files to segment out the cases of coughing and label them depending on the \"type\" of cough (wheezy, light, hard etc)\n* Scrape YouTube vids for coughing occurrences and then Mechanical Turk or manually label the audio similar to above\n* Employ actors to cough to outlined constraints e.g. \"young woman with a wheezy cough, no background noise\", \"man with light cough in a busy space\" etc. etc.  \n\n\nThoughts welcomed!", "author_fullname": "t2_5lfzc2mu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data sourcing interview question I got - opinions wanted please", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zahfgf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669974559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a junior data engineer, and got what I thought was an interesting question in an interview - intrigued by your collective approaches. I was given a toy case of a healthcare business that wanted to build a model to detect coughing in their waiting rooms (to de-risk spread of disease etc etc). They have some messy raw audio data from their waiting rooms that is usable. The interviewer asked how I would go about sourcing a robust dataset to train a model on. I came up with three ideas - intrigued to see what you guys think:  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Mechanical Turk the raw audio files to segment out the cases of coughing and label them depending on the &amp;quot;type&amp;quot; of cough (wheezy, light, hard etc)&lt;/li&gt;\n&lt;li&gt;Scrape YouTube vids for coughing occurrences and then Mechanical Turk or manually label the audio similar to above&lt;/li&gt;\n&lt;li&gt;Employ actors to cough to outlined constraints e.g. &amp;quot;young woman with a wheezy cough, no background noise&amp;quot;, &amp;quot;man with light cough in a busy space&amp;quot; etc. etc.&lt;br/&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thoughts welcomed!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "zahfgf", "is_robot_indexable": true, "report_reasons": null, "author": "fourcornerclub", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zahfgf/data_sourcing_interview_question_i_got_opinions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zahfgf/data_sourcing_interview_question_i_got_opinions/", "subreddit_subscribers": 81661, "created_utc": 1669974559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, just wondered if anyone had experience with Databricks and the way they handle model promotion. I find it quite counter intuitive but I might not have the right intuition.\n\nIn their MLOps implementation, they promote models from a \"Staging\" state to a \"Production\" state. However as soon as a model is promoted, all testing pipelines relying on a model in \"Staging\" state break, since there is no longer any model in that state. So when testing just code changes, we'd need first to save a new model in \"Staging\", instead or reusing the model that was already there. Strong vibes of pipeline smell, but I might not be seeing an obvious clean solution.\n\nIf anyone has any idea, that would lighten up my day!", "author_fullname": "t2_lh1thuv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks &amp; Model Registry", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zan66d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669989959.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, just wondered if anyone had experience with Databricks and the way they handle model promotion. I find it quite counter intuitive but I might not have the right intuition.&lt;/p&gt;\n\n&lt;p&gt;In their MLOps implementation, they promote models from a &amp;quot;Staging&amp;quot; state to a &amp;quot;Production&amp;quot; state. However as soon as a model is promoted, all testing pipelines relying on a model in &amp;quot;Staging&amp;quot; state break, since there is no longer any model in that state. So when testing just code changes, we&amp;#39;d need first to save a new model in &amp;quot;Staging&amp;quot;, instead or reusing the model that was already there. Strong vibes of pipeline smell, but I might not be seeing an obvious clean solution.&lt;/p&gt;\n\n&lt;p&gt;If anyone has any idea, that would lighten up my day!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zan66d", "is_robot_indexable": true, "report_reasons": null, "author": "aupagizon", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zan66d/databricks_model_registry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zan66d/databricks_model_registry/", "subreddit_subscribers": 81661, "created_utc": 1669989959.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, I have recently graduated and I've been working 3 months as a Junior Data Engineer in a tech consulting company (a body rental company) in Spain. Currently I don't know most of the tools/skills I hear about in this sub (Airflow, Docker...) and we are not using them either. I've been working with SSIS and Informatica Intelligent Cloud Services this months and I want to know what do you think about. Are these tools outdated? is it a valuable skill and should I keep learning? Or shoud I try to use other tools in my job. I want to learn other tools in my free time but right now I'm having problems finding some. Thanks in advance!", "author_fullname": "t2_2b0vnvfy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about the stack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zahp81", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669975409.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I have recently graduated and I&amp;#39;ve been working 3 months as a Junior Data Engineer in a tech consulting company (a body rental company) in Spain. Currently I don&amp;#39;t know most of the tools/skills I hear about in this sub (Airflow, Docker...) and we are not using them either. I&amp;#39;ve been working with SSIS and Informatica Intelligent Cloud Services this months and I want to know what do you think about. Are these tools outdated? is it a valuable skill and should I keep learning? Or shoud I try to use other tools in my job. I want to learn other tools in my free time but right now I&amp;#39;m having problems finding some. Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zahp81", "is_robot_indexable": true, "report_reasons": null, "author": "jota_point", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zahp81/question_about_the_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zahp81/question_about_the_stack/", "subreddit_subscribers": 81661, "created_utc": 1669975409.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone!\n\nSo our team has planned to use Airflow (MWAA) to run the jobs. Is it possible to trigger/ track job information using Control M? \n\nI'm pretty new to these orchestration tools, so any help would be really appreciated!", "author_fullname": "t2_5hwgf7ph", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Control - M and MWA Airflow Integration?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zahl8k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669975129.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone!&lt;/p&gt;\n\n&lt;p&gt;So our team has planned to use Airflow (MWAA) to run the jobs. Is it possible to trigger/ track job information using Control M? &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m pretty new to these orchestration tools, so any help would be really appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zahl8k", "is_robot_indexable": true, "report_reasons": null, "author": "fullyloadedkid", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zahl8k/control_m_and_mwa_airflow_integration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zahl8k/control_m_and_mwa_airflow_integration/", "subreddit_subscribers": 81661, "created_utc": 1669975129.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello!\n\nWe have a good amount of data (around 700Gb) that we need to move from Redshift to an RDS table. The data has been unloaded into an S3 in parallel (data\\_000\\_part0, data\\_001\\_part0, etc...) with a manifest file. It does not seem that we can load data from S3 to RDS thanks to the manifest file, as we would do with Redshift: [https://docs.aws.amazon.com/redshift/latest/dg/t\\_Reloading\\_unload\\_files.html](https://docs.aws.amazon.com/redshift/latest/dg/t_Reloading_unload_files.html)\n\nIn this case, would the only solution be to loop over all the unloaded files in the S3 bucket and perform the `aws_s3.table_import_from_s3`, or did I miss a parameter in this command that would accept the manifest file?\n\nI don't really have time to implement another solution and would be glad to keep the process as it is, and find a workaround with `aws_s3.table_import_from_s3`.\n\n Thanks!", "author_fullname": "t2_f1ixi4vt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to move data from Redshift to S3 and then from S3 to RDS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zaglxw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669971701.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;We have a good amount of data (around 700Gb) that we need to move from Redshift to an RDS table. The data has been unloaded into an S3 in parallel (data_000_part0, data_001_part0, etc...) with a manifest file. It does not seem that we can load data from S3 to RDS thanks to the manifest file, as we would do with Redshift: &lt;a href=\"https://docs.aws.amazon.com/redshift/latest/dg/t_Reloading_unload_files.html\"&gt;https://docs.aws.amazon.com/redshift/latest/dg/t_Reloading_unload_files.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;In this case, would the only solution be to loop over all the unloaded files in the S3 bucket and perform the &lt;code&gt;aws_s3.table_import_from_s3&lt;/code&gt;, or did I miss a parameter in this command that would accept the manifest file?&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t really have time to implement another solution and would be glad to keep the process as it is, and find a workaround with &lt;code&gt;aws_s3.table_import_from_s3&lt;/code&gt;.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zaglxw", "is_robot_indexable": true, "report_reasons": null, "author": "No_Fudge1060", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zaglxw/best_way_to_move_data_from_redshift_to_s3_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zaglxw/best_way_to_move_data_from_redshift_to_s3_and/", "subreddit_subscribers": 81661, "created_utc": 1669971701.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company has a dozen data-scientists that like to use Notebooks to run/test spark processing.\n\nThe issue I have, is that to avoid having to initialize a spark session, they keep one open, which holds whatever resources they have been using even if the Notebook is idle.\n\nHave you faced a similar use case? Any way I can get the best of both worlds?", "author_fullname": "t2_85uwiihz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Accommodating Spark for Jupyter Notebook usage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zaex8y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1669968555.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669965913.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company has a dozen data-scientists that like to use Notebooks to run/test spark processing.&lt;/p&gt;\n\n&lt;p&gt;The issue I have, is that to avoid having to initialize a spark session, they keep one open, which holds whatever resources they have been using even if the Notebook is idle.&lt;/p&gt;\n\n&lt;p&gt;Have you faced a similar use case? Any way I can get the best of both worlds?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zaex8y", "is_robot_indexable": true, "report_reasons": null, "author": "GeekyTricky", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zaex8y/accommodating_spark_for_jupyter_notebook_usage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zaex8y/accommodating_spark_for_jupyter_notebook_usage/", "subreddit_subscribers": 81661, "created_utc": 1669965913.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I currently have a personal (hobby) project I am working on but would like thoughts and opinions of others before I continue further. \n\n**Background:**\n\nI currently have Python Web Scrappers that collects data from multiple sites parses them into a JSON file, which is then converted into SQL scripts, and then a shellscript that calls the file and updates a local database tables from the JSON Files and then deletes the JSON files once updated. The SQL Server then does all the transforming if it doesn't meet my personal data quality rules.\n\nFrom that point, It then goes into PowerBi for a simple dashboard so I can review the data quickly.\n\n(The websites where I pull data from don't offer API Services. If they do use an API, then I use the API instead. )\n\n**Questions/Thoughts:**\n\nOne of the big downsides that I have with this format, is that the computer needs to be running at the time I need it to, to pull the data from the scrappers and update the DB and I am not too sure how I would go about into automating this process. I haven't looked too deep into this as of yet, but I am assuming a remote VM or some some cloud based product? \n\nWhat I am looking for from yourselves, how would you have approached your project, what would you have done differently? What other technology would you have used? Have I missed anything important?\n\n I am open to spending funds on better technology, Software, services.", "author_fullname": "t2_nypenmf9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Methodology? [ Python Scrapper - MS SQL Server - Dashboard ]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zasap3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670002828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently have a personal (hobby) project I am working on but would like thoughts and opinions of others before I continue further. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Background:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I currently have Python Web Scrappers that collects data from multiple sites parses them into a JSON file, which is then converted into SQL scripts, and then a shellscript that calls the file and updates a local database tables from the JSON Files and then deletes the JSON files once updated. The SQL Server then does all the transforming if it doesn&amp;#39;t meet my personal data quality rules.&lt;/p&gt;\n\n&lt;p&gt;From that point, It then goes into PowerBi for a simple dashboard so I can review the data quickly.&lt;/p&gt;\n\n&lt;p&gt;(The websites where I pull data from don&amp;#39;t offer API Services. If they do use an API, then I use the API instead. )&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Questions/Thoughts:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;One of the big downsides that I have with this format, is that the computer needs to be running at the time I need it to, to pull the data from the scrappers and update the DB and I am not too sure how I would go about into automating this process. I haven&amp;#39;t looked too deep into this as of yet, but I am assuming a remote VM or some some cloud based product? &lt;/p&gt;\n\n&lt;p&gt;What I am looking for from yourselves, how would you have approached your project, what would you have done differently? What other technology would you have used? Have I missed anything important?&lt;/p&gt;\n\n&lt;p&gt;I am open to spending funds on better technology, Software, services.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zasap3", "is_robot_indexable": true, "report_reasons": null, "author": "DevStandUp", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zasap3/best_methodology_python_scrapper_ms_sql_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zasap3/best_methodology_python_scrapper_ms_sql_server/", "subreddit_subscribers": 81661, "created_utc": 1670002828.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "It seems peoples rarely talk about data governance in this subreddit. Is data engineer the right team for data governance project? Can someone share about the most important thing to do when doing this kind of project. What will be first thing you would do if this is the first data governance project in your company? I know this topic will be really wide, but I just wanna hear peoples story about it.", "author_fullname": "t2_tm5irceo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Governance Project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zas8xy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670002716.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It seems peoples rarely talk about data governance in this subreddit. Is data engineer the right team for data governance project? Can someone share about the most important thing to do when doing this kind of project. What will be first thing you would do if this is the first data governance project in your company? I know this topic will be really wide, but I just wanna hear peoples story about it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zas8xy", "is_robot_indexable": true, "report_reasons": null, "author": "natas_m", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zas8xy/data_governance_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zas8xy/data_governance_project/", "subreddit_subscribers": 81661, "created_utc": 1670002716.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_796g5y3q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Information vs. Data - Are you conscious?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 84, "top_awarded_type": null, "hide_score": false, "name": "t3_zank10", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.44, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/XnSaCSQWNtjtbDij5lHQPEb2XB3BTb1OrkvF7DGpsQs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1669990983.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@alejandro.attento/information-vs-data-are-you-conscious-e67a852fae05", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/CDCRjVq0ZwpDRr_UkUU30QwOD3LIEMhuCbWFtfF-CcQ.jpg?auto=webp&amp;s=a0fe1a694af55e94aac3cfa32bb6962685286735", "width": 732, "height": 442}, "resolutions": [{"url": "https://external-preview.redd.it/CDCRjVq0ZwpDRr_UkUU30QwOD3LIEMhuCbWFtfF-CcQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f40596e13bd282f29c3a4b71b82d866163e94704", "width": 108, "height": 65}, {"url": "https://external-preview.redd.it/CDCRjVq0ZwpDRr_UkUU30QwOD3LIEMhuCbWFtfF-CcQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1fc20b39d7a73b3b43e55f9645844debbf592288", "width": 216, "height": 130}, {"url": "https://external-preview.redd.it/CDCRjVq0ZwpDRr_UkUU30QwOD3LIEMhuCbWFtfF-CcQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=14f086875e097d77b1e592db6b2f2e45c304b26b", "width": 320, "height": 193}, {"url": "https://external-preview.redd.it/CDCRjVq0ZwpDRr_UkUU30QwOD3LIEMhuCbWFtfF-CcQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=72741db975e4561c39b998f414b22c6854303990", "width": 640, "height": 386}], "variants": {}, "id": "RvwE1Bk6mp7F6xxa-5luxhjK-7ScYuDMlKxx9BnXvAg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zank10", "is_robot_indexable": true, "report_reasons": null, "author": "elaleeman94", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zank10/information_vs_data_are_you_conscious/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@alejandro.attento/information-vs-data-are-you-conscious-e67a852fae05", "subreddit_subscribers": 81661, "created_utc": 1669990983.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Microsoft Azure Data Engineering is one of the best Data Science tools out there, but which one is its best benefit?\n\n[View Poll](https://www.reddit.com/poll/zaqqqx)", "author_fullname": "t2_gk917caz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which is the best feature of Microsoft Azure Data Engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zaqqqx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669999107.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Microsoft Azure Data Engineering is one of the best Data Science tools out there, but which one is its best benefit?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/zaqqqx\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zaqqqx", "is_robot_indexable": true, "report_reasons": null, "author": "joyful_reader", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1670603907647, "options": [{"text": "Data Warehousing", "id": "20142769"}, {"text": "Data Security", "id": "20142770"}, {"text": "Data Monitoring", "id": "20142771"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 34, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zaqqqx/which_is_the_best_feature_of_microsoft_azure_data/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/zaqqqx/which_is_the_best_feature_of_microsoft_azure_data/", "subreddit_subscribers": 81661, "created_utc": 1669999107.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious about how to drive revenue via your 1st party customer data?  \n\n\nNext Tuesday (Dec. 6),  [Jim Lumsden](https://www.linkedin.com/in/jim-a-lumsden/) (data lead @\u00a0[Prolific](https://www.linkedin.com/company/prolific-academic/)), [Mike Maloney](https://www.linkedin.com/in/mike-maloney-5229274/) (field CDO\u00a0@\u00a0[Snowplow](https://www.linkedin.com/in/mike-maloney-5229274/)), [Shashi Raina](https://www.linkedin.com/in/shashiraina/) (sr. partner solutions architect @\u00a0[AWS](https://www.linkedin.com/company/amazon-web-services/)),\u00a0and [Donny Flynn](https://www.linkedin.com/in/donny-flynn-578149a4/) (customer data architect @ [Census](https://www.linkedin.com/company/19055959/admin/)) will break down how to create a data-first culture to support and drive revenue like never before.\n\nThey'll discuss how, using real-world examples from the Prolific data team, Snowplow, AWS, and Census can help you drive more growth for your business by unlocking rich, unified, and accessible behavioral data across your organization.\n\nFaced with the need for high-quality, reliable data, Prolific\u2019s data team built a technology stack to create complete Customer Behavioral Profiles, ensuring the rest of their could access actionable data to best engage with their customers.\n\nWith Customer Behavioral Profiles (and the right data stack), you too can predict your user\u2019s next best action and power your sales team with complete visibility into your customers\u2019 interactions, which means higher sales conversions and revenue. \ud83e\udd11\n\n**Join us as we discuss:**  \n\n\n* The importance of having a high quality data-first culture\u00a0\ud83e\udd1d\n* How Prolific supercharged their sales team with product analytics\u00a0\ud83d\ude80\n* How Customer Behavioral Profiles can empower your organization \ud83d\udcc8\n\nHope to see you there! Sing up \ud83d\udc49 [**here**](https://www.getcensus.com/events/webinar-how-prolific-supercharged-revenue-with-powerful-customer-profiles) \ud83d\udc48", "author_fullname": "t2_ezsyorvh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to support and drive revenue team through data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z9ycz0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.11, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669925665.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious about how to drive revenue via your 1st party customer data?  &lt;/p&gt;\n\n&lt;p&gt;Next Tuesday (Dec. 6),  &lt;a href=\"https://www.linkedin.com/in/jim-a-lumsden/\"&gt;Jim Lumsden&lt;/a&gt; (data lead @\u00a0&lt;a href=\"https://www.linkedin.com/company/prolific-academic/\"&gt;Prolific&lt;/a&gt;), &lt;a href=\"https://www.linkedin.com/in/mike-maloney-5229274/\"&gt;Mike Maloney&lt;/a&gt; (field CDO\u00a0@\u00a0&lt;a href=\"https://www.linkedin.com/in/mike-maloney-5229274/\"&gt;Snowplow&lt;/a&gt;), &lt;a href=\"https://www.linkedin.com/in/shashiraina/\"&gt;Shashi Raina&lt;/a&gt; (sr. partner solutions architect @\u00a0&lt;a href=\"https://www.linkedin.com/company/amazon-web-services/\"&gt;AWS&lt;/a&gt;),\u00a0and &lt;a href=\"https://www.linkedin.com/in/donny-flynn-578149a4/\"&gt;Donny Flynn&lt;/a&gt; (customer data architect @ &lt;a href=\"https://www.linkedin.com/company/19055959/admin/\"&gt;Census&lt;/a&gt;) will break down how to create a data-first culture to support and drive revenue like never before.&lt;/p&gt;\n\n&lt;p&gt;They&amp;#39;ll discuss how, using real-world examples from the Prolific data team, Snowplow, AWS, and Census can help you drive more growth for your business by unlocking rich, unified, and accessible behavioral data across your organization.&lt;/p&gt;\n\n&lt;p&gt;Faced with the need for high-quality, reliable data, Prolific\u2019s data team built a technology stack to create complete Customer Behavioral Profiles, ensuring the rest of their could access actionable data to best engage with their customers.&lt;/p&gt;\n\n&lt;p&gt;With Customer Behavioral Profiles (and the right data stack), you too can predict your user\u2019s next best action and power your sales team with complete visibility into your customers\u2019 interactions, which means higher sales conversions and revenue. \ud83e\udd11&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Join us as we discuss:&lt;/strong&gt;  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The importance of having a high quality data-first culture\u00a0\ud83e\udd1d&lt;/li&gt;\n&lt;li&gt;How Prolific supercharged their sales team with product analytics\u00a0\ud83d\ude80&lt;/li&gt;\n&lt;li&gt;How Customer Behavioral Profiles can empower your organization \ud83d\udcc8&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Hope to see you there! Sing up \ud83d\udc49 &lt;a href=\"https://www.getcensus.com/events/webinar-how-prolific-supercharged-revenue-with-powerful-customer-profiles\"&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt; \ud83d\udc48&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z9ycz0", "is_robot_indexable": true, "report_reasons": null, "author": "Firm_Spite2939", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z9ycz0/how_to_support_and_drive_revenue_team_through_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z9ycz0/how_to_support_and_drive_revenue_team_through_data/", "subreddit_subscribers": 81661, "created_utc": 1669925665.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}