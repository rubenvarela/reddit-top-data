{"kind": "Listing", "data": {"after": "t3_z9ycz0", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've received a job offer for senior data engineer with request of :\n- Team Leader, Mentor\n- salary up to 6 figure \n- Startup\n- Full remote in the field I want\n\nSalary would be 5x than what I'm earning now.\nI would call myself more a middle data engineer, I'm good in troubleshooting, but I've never mentored as I'm still learning a lot of things that I still don't know.\n\nShould I give it a try and let the company decide if I'm fit ?", "author_fullname": "t2_fsoatxql", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Huge offer for Senior Role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z9lxmi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 45, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 45, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669895576.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve received a job offer for senior data engineer with request of :\n- Team Leader, Mentor\n- salary up to 6 figure \n- Startup\n- Full remote in the field I want&lt;/p&gt;\n\n&lt;p&gt;Salary would be 5x than what I&amp;#39;m earning now.\nI would call myself more a middle data engineer, I&amp;#39;m good in troubleshooting, but I&amp;#39;ve never mentored as I&amp;#39;m still learning a lot of things that I still don&amp;#39;t know.&lt;/p&gt;\n\n&lt;p&gt;Should I give it a try and let the company decide if I&amp;#39;m fit ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "z9lxmi", "is_robot_indexable": true, "report_reasons": null, "author": "CauliflowerJolly4599", "discussion_type": null, "num_comments": 52, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z9lxmi/huge_offer_for_senior_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z9lxmi/huge_offer_for_senior_role/", "subreddit_subscribers": 81624, "created_utc": 1669895576.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can you recommend any videos which go though the Kimball Methodology. I have seen some on YouTube but they are mostly under 10 minutes and go over the basics. I am looking for an in depth video.", "author_fullname": "t2_12rfbr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Videos which explain the Kimball Methodology?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z9tk7l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 39, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 39, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669915322.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can you recommend any videos which go though the Kimball Methodology. I have seen some on YouTube but they are mostly under 10 minutes and go over the basics. I am looking for an in depth video.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z9tk7l", "is_robot_indexable": true, "report_reasons": null, "author": "That_Sweet_Science", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z9tk7l/videos_which_explain_the_kimball_methodology/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z9tk7l/videos_which_explain_the_kimball_methodology/", "subreddit_subscribers": 81624, "created_utc": 1669915322.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I am working as a data scientist at a company who has been so far outsourcing our engineering work to other companies. So all I know is that there is a data warehouse where I can find data that needs to be analyzed.\n\nNow, my company wants to get into data engineering as well. One tool of interest is Snowflake. Since we are working with AWS cloud services, it shouldn't be a problem to start with Snowflake. However, I just don't know how to build a data warehouse from scratch using Snowflake. Where should I start?\n\nAre there any courses or do I only learn by doing?\n\nActually I would prefer if someone could give me a helicopter view about data engineering in general.\n\nApologies for the long text and thank you in advance.", "author_fullname": "t2_8rj37fy7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where to start with Snowflake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z9kodn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669891226.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am working as a data scientist at a company who has been so far outsourcing our engineering work to other companies. So all I know is that there is a data warehouse where I can find data that needs to be analyzed.&lt;/p&gt;\n\n&lt;p&gt;Now, my company wants to get into data engineering as well. One tool of interest is Snowflake. Since we are working with AWS cloud services, it shouldn&amp;#39;t be a problem to start with Snowflake. However, I just don&amp;#39;t know how to build a data warehouse from scratch using Snowflake. Where should I start?&lt;/p&gt;\n\n&lt;p&gt;Are there any courses or do I only learn by doing?&lt;/p&gt;\n\n&lt;p&gt;Actually I would prefer if someone could give me a helicopter view about data engineering in general.&lt;/p&gt;\n\n&lt;p&gt;Apologies for the long text and thank you in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z9kodn", "is_robot_indexable": true, "report_reasons": null, "author": "Kiiro-Kaminari", "discussion_type": null, "num_comments": 40, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z9kodn/where_to_start_with_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z9kodn/where_to_start_with_snowflake/", "subreddit_subscribers": 81624, "created_utc": 1669891226.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am wondering on how to get hands on with cloud services like redshift, s3, kinda stuffs. I think i've some good overview of data warehouse  and dimensional modelling. Thinking of applying data warehouse concepts on a project or something and i'm thinking of building data warehouse on a cloud to get some practical experience but the thing is I don't know where to start with the cloud. \n\nShould I gather experience exploring the tools or rather take some courses? \n\nAnd also what kind of projects would really stand out from others ?", "author_fullname": "t2_aenh4mw5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get start with cloud(AWS)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_za88nk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669947588.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am wondering on how to get hands on with cloud services like redshift, s3, kinda stuffs. I think i&amp;#39;ve some good overview of data warehouse  and dimensional modelling. Thinking of applying data warehouse concepts on a project or something and i&amp;#39;m thinking of building data warehouse on a cloud to get some practical experience but the thing is I don&amp;#39;t know where to start with the cloud. &lt;/p&gt;\n\n&lt;p&gt;Should I gather experience exploring the tools or rather take some courses? &lt;/p&gt;\n\n&lt;p&gt;And also what kind of projects would really stand out from others ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "za88nk", "is_robot_indexable": true, "report_reasons": null, "author": "Suspicious_Peanut282", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/za88nk/how_to_get_start_with_cloudaws/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/za88nk/how_to_get_start_with_cloudaws/", "subreddit_subscribers": 81624, "created_utc": 1669947588.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "While the following is similar to a lot of hopeful graduates looking for their first data job, my story is a little bit on the unusual side so I figured some more tailored advice would be very much appreciated. Thank you for valuable time in advance!\n\nI'm from a social science background in psychology where I focused on doing extra statistics subjects at university and always wanted to be  a researcher. Bombed out of my PhD with no measurable accomplishments besides an appreciation for Python, and exposure to MATLAB for data pipelines on EEG data. I spent the next 2 years consulting 4th year students on how to run data analysis on their research  -- all in SPSS.\n\nPulled myself together and left that behind me to focus entirely on full-time work search and upskilling. I'm currently learning Python, PowerBI, and TSQL and applying them in small projects.Right now I'm working mainly on kaggle datasets - one for querying in SQL Server Management Studio to show my ability to write SQL and visualising in PowerBI, and the other one using entirely Python because the file is sqlite and SSMS makes it annoying to open, so Python sqlite3 it is!\n\nOn that note, it seems to be advice I hear from everyone, just demonstrate your skills with projects. But if everyone is doing projects, it seems a little difficult to stand out if you're not an IT/CS/Data graduate.\n\nMy current plans are to keep plugging away at these projects and upload to github, learning daily on Udemy for PowerBI and a couple of Jose Portilla courses for Python and Python for data science, then move on to a bit more of a complex project involving sentiment analysis in Python. At the same time I've started on CS50 as I recognise I lack some fundamentals and have some bad coding habits.\n\nDoes anybody have some advice for demonstrating skills or suitability for an entry level data role besides what I'm already doing, and continuing to grow into a data engineering career?\n\n\\- Sincerely, a data enthusiast", "author_fullname": "t2_zz4yu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Breaking into data analyst role and future data engineer career", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_za1nhu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669932670.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;While the following is similar to a lot of hopeful graduates looking for their first data job, my story is a little bit on the unusual side so I figured some more tailored advice would be very much appreciated. Thank you for valuable time in advance!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m from a social science background in psychology where I focused on doing extra statistics subjects at university and always wanted to be  a researcher. Bombed out of my PhD with no measurable accomplishments besides an appreciation for Python, and exposure to MATLAB for data pipelines on EEG data. I spent the next 2 years consulting 4th year students on how to run data analysis on their research  -- all in SPSS.&lt;/p&gt;\n\n&lt;p&gt;Pulled myself together and left that behind me to focus entirely on full-time work search and upskilling. I&amp;#39;m currently learning Python, PowerBI, and TSQL and applying them in small projects.Right now I&amp;#39;m working mainly on kaggle datasets - one for querying in SQL Server Management Studio to show my ability to write SQL and visualising in PowerBI, and the other one using entirely Python because the file is sqlite and SSMS makes it annoying to open, so Python sqlite3 it is!&lt;/p&gt;\n\n&lt;p&gt;On that note, it seems to be advice I hear from everyone, just demonstrate your skills with projects. But if everyone is doing projects, it seems a little difficult to stand out if you&amp;#39;re not an IT/CS/Data graduate.&lt;/p&gt;\n\n&lt;p&gt;My current plans are to keep plugging away at these projects and upload to github, learning daily on Udemy for PowerBI and a couple of Jose Portilla courses for Python and Python for data science, then move on to a bit more of a complex project involving sentiment analysis in Python. At the same time I&amp;#39;ve started on CS50 as I recognise I lack some fundamentals and have some bad coding habits.&lt;/p&gt;\n\n&lt;p&gt;Does anybody have some advice for demonstrating skills or suitability for an entry level data role besides what I&amp;#39;m already doing, and continuing to grow into a data engineering career?&lt;/p&gt;\n\n&lt;p&gt;- Sincerely, a data enthusiast&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "za1nhu", "is_robot_indexable": true, "report_reasons": null, "author": "OloroMemez", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/za1nhu/breaking_into_data_analyst_role_and_future_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/za1nhu/breaking_into_data_analyst_role_and_future_data/", "subreddit_subscribers": 81624, "created_utc": 1669932670.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is a recurring thread that happens quarterly and was created to help increase transparency around salary and compensation for Data Engineering. Please comment below and include the following:\n\n1. Current title\n\n2. Years of experience (YOE)\n\n3. Location\n\n4. Base salary &amp; currency (dollars, euro, pesos, etc.)\n\n5. Bonuses/Equity (optional)\n\n6. Industry (optional)\n\n7. Tech stack (optional)", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Quarterly Salary Discussion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "collections": [{"permalink": "https://www.reddit.com/r/dataengineering/collection/ef3eb514-328d-4549-a705-94c26963d79b", "link_ids": ["t3_npxcqc", "t3_pfwuyg", "t3_r6jfnm", "t3_t4clep", "t3_v2ka3w", "t3_x3bb11", "t3_z9szj1"], "description": "", "title": "Data Engineering Salaries", "created_at_utc": 1621559056.076, "subreddit_id": "t5_36en4", "author_name": "theporterhaus", "collection_id": "ef3eb514-328d-4549-a705-94c26963d79b", "author_id": "t2_2tv9i42n", "last_update_utc": 1669914008.806, "display_layout": null}], "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z9szj1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669914008.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a recurring thread that happens quarterly and was created to help increase transparency around salary and compensation for Data Engineering. Please comment below and include the following:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Current title&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Years of experience (YOE)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Location&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Base salary &amp;amp; currency (dollars, euro, pesos, etc.)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Bonuses/Equity (optional)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Industry (optional)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Tech stack (optional)&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "z9szj1", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 32, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z9szj1/quarterly_salary_discussion/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/dataengineering/comments/z9szj1/quarterly_salary_discussion/", "subreddit_subscribers": 81624, "created_utc": 1669914008.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone, I was recently debating a friend who is a data engineer on whether data sourcing or model building capability will be more valuable as pre-trained foundational models become more and more capable. My position is that in an era of finetuning data will be king and OpenAI will kill the majority of other models. Would love to trigger a wider debate!", "author_fullname": "t2_5lfzc2mu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Discussion thread: \"data sourcing is more important than model building capability in the era of foundational model fine-tuning\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z9qrss", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669908664.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I was recently debating a friend who is a data engineer on whether data sourcing or model building capability will be more valuable as pre-trained foundational models become more and more capable. My position is that in an era of finetuning data will be king and OpenAI will kill the majority of other models. Would love to trigger a wider debate!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z9qrss", "is_robot_indexable": true, "report_reasons": null, "author": "fourcornerclub", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z9qrss/discussion_thread_data_sourcing_is_more_important/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z9qrss/discussion_thread_data_sourcing_is_more_important/", "subreddit_subscribers": 81624, "created_utc": 1669908664.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3yleu7rp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Announcing: Regression Testing for Your Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z9pcst", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1669905187.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "alvin.ai", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.alvin.ai/posts/announcing-regression-testing-for-your-data", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "z9pcst", "is_robot_indexable": true, "report_reasons": null, "author": "gabsferreiradev", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z9pcst/announcing_regression_testing_for_your_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.alvin.ai/posts/announcing-regression-testing-for-your-data", "subreddit_subscribers": 81624, "created_utc": 1669905187.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I'm in a new job where I'm in way over my head (or so it feels like) and my weakest side is that I suck at Azure. Managed identities, service principals, oauth 2.0, sas tokens, file system drivers, vnets, subnets... There are so many security concepts that I simply read about so many times, but I am never able to learn how they are all related and get an overview. My brain is simply unable to comprehend it all unless I can REALLY get a grasp. I'm a very all or nothing guy, hearing a word here and there never makes it stick. \n\nI'm currently working with the IaC team tp implement Databricks, Unity Catalog and for everything outside Databricks I really struggle. Does anyone have any good tips? I was recommended by a colleague to do the AZ-104 certification (or at least read the learning materials). Any other tips?", "author_fullname": "t2_4ov075m4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need to improve my cloud (Azure) skills to become a better data engineer. Tips?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zagbo0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669970714.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;m in a new job where I&amp;#39;m in way over my head (or so it feels like) and my weakest side is that I suck at Azure. Managed identities, service principals, oauth 2.0, sas tokens, file system drivers, vnets, subnets... There are so many security concepts that I simply read about so many times, but I am never able to learn how they are all related and get an overview. My brain is simply unable to comprehend it all unless I can REALLY get a grasp. I&amp;#39;m a very all or nothing guy, hearing a word here and there never makes it stick. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working with the IaC team tp implement Databricks, Unity Catalog and for everything outside Databricks I really struggle. Does anyone have any good tips? I was recommended by a colleague to do the AZ-104 certification (or at least read the learning materials). Any other tips?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zagbo0", "is_robot_indexable": true, "report_reasons": null, "author": "HealthyDoggos4Life", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zagbo0/need_to_improve_my_cloud_azure_skills_to_become_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zagbo0/need_to_improve_my_cloud_azure_skills_to_become_a/", "subreddit_subscribers": 81624, "created_utc": 1669970714.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all!\n\nI'm the developer behind [Rocketry](https://github.com/Miksus/rocketry), a Pythonic scheduling engine. I originally developed it for other needs than data engineering but as some have said they have started to replace Airflow with it, I thought perhaps some of you might like it as well. I'm also interested in your opinions.\n\nA bit about the framework, it is quite minimal:\n\n    from rocketry import Rocketry\n    from rocketry.conds import daily\n    \n    app = Rocketry()\n    \n    @app.task(daily.at(\"10:00\"))\n    def do_daily():\n        ... # This function runs once a day at 10 AM\n    \n    if __name__ == \"__main__\":\n        app.run()\n\nIt has bunch of features: logical scheduling syntax, parallelism/concurrency, dynamic parametization, log to database etc. You can read from the docs: [https://rocketry.readthedocs.io/](https://rocketry.readthedocs.io/)\n\nI don't think Rocketry will achieve the same level of adaptation as Airflow and it is missing many advanced features Airflow has such as built-in UI ([working on such](https://github.com/Miksus/rocketry-with-fastapi)), executors for containers etc. but considering how versatile it is and how powerful the scheduling is (basically logical statements), I think it could be interesting for those data engineers who need to customize their setup or need something smaller in scale.\n\nDo you think there is anything missing from the available mature task orchestration products? Or is the space already saturated?", "author_fullname": "t2_23tmpa91", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scheduling in Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zaeiam", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1669964573.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m the developer behind &lt;a href=\"https://github.com/Miksus/rocketry\"&gt;Rocketry&lt;/a&gt;, a Pythonic scheduling engine. I originally developed it for other needs than data engineering but as some have said they have started to replace Airflow with it, I thought perhaps some of you might like it as well. I&amp;#39;m also interested in your opinions.&lt;/p&gt;\n\n&lt;p&gt;A bit about the framework, it is quite minimal:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;from rocketry import Rocketry\nfrom rocketry.conds import daily\n\napp = Rocketry()\n\n@app.task(daily.at(&amp;quot;10:00&amp;quot;))\ndef do_daily():\n    ... # This function runs once a day at 10 AM\n\nif __name__ == &amp;quot;__main__&amp;quot;:\n    app.run()\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;It has bunch of features: logical scheduling syntax, parallelism/concurrency, dynamic parametization, log to database etc. You can read from the docs: &lt;a href=\"https://rocketry.readthedocs.io/\"&gt;https://rocketry.readthedocs.io/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t think Rocketry will achieve the same level of adaptation as Airflow and it is missing many advanced features Airflow has such as built-in UI (&lt;a href=\"https://github.com/Miksus/rocketry-with-fastapi\"&gt;working on such&lt;/a&gt;), executors for containers etc. but considering how versatile it is and how powerful the scheduling is (basically logical statements), I think it could be interesting for those data engineers who need to customize their setup or need something smaller in scale.&lt;/p&gt;\n\n&lt;p&gt;Do you think there is anything missing from the available mature task orchestration products? Or is the space already saturated?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/K19odH5iyfuYZOK4oa3bjY5rvA0RaMLXsaOmBJW51GA.jpg?auto=webp&amp;s=22e17de7b28f864d02096b53e631e72426ba53e0", "width": 475, "height": 355}, "resolutions": [{"url": "https://external-preview.redd.it/K19odH5iyfuYZOK4oa3bjY5rvA0RaMLXsaOmBJW51GA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=75cfb8d79b5fb3996c7fadff940884cf21b60e36", "width": 108, "height": 80}, {"url": "https://external-preview.redd.it/K19odH5iyfuYZOK4oa3bjY5rvA0RaMLXsaOmBJW51GA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=20790f2d1e5644f77eeaecf1b46d986980c91311", "width": 216, "height": 161}, {"url": "https://external-preview.redd.it/K19odH5iyfuYZOK4oa3bjY5rvA0RaMLXsaOmBJW51GA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=83fa69e9d75035c2f014bca4c9621d7ee208260c", "width": 320, "height": 239}], "variants": {}, "id": "S-mAwIQucPvJFVqzltcRgmxIb2CrlEbzXkiwGmBizIc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "zaeiam", "is_robot_indexable": true, "report_reasons": null, "author": "Natural-Intelligence", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zaeiam/scheduling_in_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zaeiam/scheduling_in_data_engineering/", "subreddit_subscribers": 81624, "created_utc": 1669964573.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company has a dozen data-scientists that like to use Notebooks to run/test spark processing.\n\nThe issue I have, is that to avoid having to initialize a spark session, they keep one open, which holds whatever resources they have been using even if the Notebook is idle.\n\nHave you faced a similar use case? Any way I can get the best of both worlds?", "author_fullname": "t2_85uwiihz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Accommodating Spark for Jupyter Notebook usage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zaex8y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1669968555.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669965913.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company has a dozen data-scientists that like to use Notebooks to run/test spark processing.&lt;/p&gt;\n\n&lt;p&gt;The issue I have, is that to avoid having to initialize a spark session, they keep one open, which holds whatever resources they have been using even if the Notebook is idle.&lt;/p&gt;\n\n&lt;p&gt;Have you faced a similar use case? Any way I can get the best of both worlds?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zaex8y", "is_robot_indexable": true, "report_reasons": null, "author": "GeekyTricky", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zaex8y/accommodating_spark_for_jupyter_notebook_usage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zaex8y/accommodating_spark_for_jupyter_notebook_usage/", "subreddit_subscribers": 81624, "created_utc": 1669965913.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8otab4hd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hadoop Distributed File System", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_zadteq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/rih_mGYvtrZiW6CGn-tSdT7r2TCmsNWEyM1h6SWesx8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1669962328.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "hitachivantara.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.hitachivantara.com/en-us/insights/faq/hadoop-distributed-file-system.html", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7pebVmTSCfL-37MD1ubzlDPGAL3LjXDFcFREv7_ccFM.jpg?auto=webp&amp;s=621d4ec30514c64e9251d2d3a8321817fcb760b9", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/7pebVmTSCfL-37MD1ubzlDPGAL3LjXDFcFREv7_ccFM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=769e5456de5da1ce9a695db889295020b406ac49", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/7pebVmTSCfL-37MD1ubzlDPGAL3LjXDFcFREv7_ccFM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=13e9168b46167b1454580f889f0e2c5b2d06e52e", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/7pebVmTSCfL-37MD1ubzlDPGAL3LjXDFcFREv7_ccFM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d82483a1960865a3d831b6a03229dcb277a9ffe6", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/7pebVmTSCfL-37MD1ubzlDPGAL3LjXDFcFREv7_ccFM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d64aba344ccb713a053beb71974c00b4a5fc4279", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/7pebVmTSCfL-37MD1ubzlDPGAL3LjXDFcFREv7_ccFM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f0656a92059608c6758bbec802f4eda4fe293641", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/7pebVmTSCfL-37MD1ubzlDPGAL3LjXDFcFREv7_ccFM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b1d3080974a56e26d07cf182173be95c92b94fd7", "width": 1080, "height": 565}], "variants": {}, "id": "5IBEoPxJh0oVgTEqp_z5W6GnTwyJi_myOg-8stAyetQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zadteq", "is_robot_indexable": true, "report_reasons": null, "author": "ranjeettechnincal", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zadteq/hadoop_distributed_file_system/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.hitachivantara.com/en-us/insights/faq/hadoop-distributed-file-system.html", "subreddit_subscribers": 81624, "created_utc": 1669962328.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working with a software that uses Aurora MySQL as it's primary storage and it's modeled with single table multi tenancy: every entity has a tenant\\_id column (except the tenants table).\n\nI want to implement a feature where users can write their own SQL queries for analytics. Current schema won't allow it, so I need to implement a pipeline that outputs \\_n\\_ files per table (\\_n\\_ being the number of tenants). End goal would be querying S3 Data using Athena, maybe even something like Metabase.\n\nAlso planning to implement Airbyte to sync other external sources (ie Saleforce) onto our data lake.\n\nMy initial research lead me to Airflow then Dagster then AWS Glue. I'm feeling a bit stuck on how to design this. Any hints that could that could aid my research journey are really appreciated. Thanks!", "author_fullname": "t2_gyauc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First data lake pipeline advice - multitenancy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zackyb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669958535.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working with a software that uses Aurora MySQL as it&amp;#39;s primary storage and it&amp;#39;s modeled with single table multi tenancy: every entity has a tenant_id column (except the tenants table).&lt;/p&gt;\n\n&lt;p&gt;I want to implement a feature where users can write their own SQL queries for analytics. Current schema won&amp;#39;t allow it, so I need to implement a pipeline that outputs _n_ files per table (_n_ being the number of tenants). End goal would be querying S3 Data using Athena, maybe even something like Metabase.&lt;/p&gt;\n\n&lt;p&gt;Also planning to implement Airbyte to sync other external sources (ie Saleforce) onto our data lake.&lt;/p&gt;\n\n&lt;p&gt;My initial research lead me to Airflow then Dagster then AWS Glue. I&amp;#39;m feeling a bit stuck on how to design this. Any hints that could that could aid my research journey are really appreciated. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zackyb", "is_robot_indexable": true, "report_reasons": null, "author": "fedeisas", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zackyb/first_data_lake_pipeline_advice_multitenancy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zackyb/first_data_lake_pipeline_advice_multitenancy/", "subreddit_subscribers": 81624, "created_utc": 1669958535.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a sparse matrix like this  {\\[1 0 2, 0 3 0, 4 0 5\\]}  in a pyspark dataframe cell. I'd like to have three columns with the following values in each cell:\n\nvalues: \\[1, 2, 3, 4, 5\\],  rowIndices=\\[0, 2, 1, 0, 2\\],  colPointers=\\[0, 2, 3, 5\\]\n\nDoes anyone know how I can get the desired outcome?", "author_fullname": "t2_6cgfmz1c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a way using pyspark to transform a sparse matrix that is in the cell of a dataframe into CSC format?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z9o7i6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669902175.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a sparse matrix like this  {[1 0 2, 0 3 0, 4 0 5]}  in a pyspark dataframe cell. I&amp;#39;d like to have three columns with the following values in each cell:&lt;/p&gt;\n\n&lt;p&gt;values: [1, 2, 3, 4, 5],  rowIndices=[0, 2, 1, 0, 2],  colPointers=[0, 2, 3, 5]&lt;/p&gt;\n\n&lt;p&gt;Does anyone know how I can get the desired outcome?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z9o7i6", "is_robot_indexable": true, "report_reasons": null, "author": "BewitchedHare", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z9o7i6/is_there_a_way_using_pyspark_to_transform_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z9o7i6/is_there_a_way_using_pyspark_to_transform_a/", "subreddit_subscribers": 81624, "created_utc": 1669902175.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, I have recently graduated and I've been working 3 months as a Junior Data Engineer in a tech consulting company (a body rental company) in Spain. Currently I don't know most of the tools/skills I hear about in this sub (Airflow, Docker...) and we are not using them either. I've been working with SSIS and Informatica Intelligent Cloud Services this months and I want to know what do you think about. Are these tools outdated? is it a valuable skill and should I keep learning? Or shoud I try to use other tools in my job. I want to learn other tools in my free time but right now I'm having problems finding some. Thanks in advance!", "author_fullname": "t2_2b0vnvfy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about the stack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zahp81", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669975409.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I have recently graduated and I&amp;#39;ve been working 3 months as a Junior Data Engineer in a tech consulting company (a body rental company) in Spain. Currently I don&amp;#39;t know most of the tools/skills I hear about in this sub (Airflow, Docker...) and we are not using them either. I&amp;#39;ve been working with SSIS and Informatica Intelligent Cloud Services this months and I want to know what do you think about. Are these tools outdated? is it a valuable skill and should I keep learning? Or shoud I try to use other tools in my job. I want to learn other tools in my free time but right now I&amp;#39;m having problems finding some. Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zahp81", "is_robot_indexable": true, "report_reasons": null, "author": "jota_point", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zahp81/question_about_the_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zahp81/question_about_the_stack/", "subreddit_subscribers": 81624, "created_utc": 1669975409.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone!\n\nSo our team has planned to use Airflow (MWAA) to run the jobs. Is it possible to trigger/ track job information using Control M? \n\nI'm pretty new to these orchestration tools, so any help would be really appreciated!", "author_fullname": "t2_5hwgf7ph", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Control - M and MWA Airflow Integration?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zahl8k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669975129.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone!&lt;/p&gt;\n\n&lt;p&gt;So our team has planned to use Airflow (MWAA) to run the jobs. Is it possible to trigger/ track job information using Control M? &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m pretty new to these orchestration tools, so any help would be really appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zahl8k", "is_robot_indexable": true, "report_reasons": null, "author": "fullyloadedkid", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zahl8k/control_m_and_mwa_airflow_integration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zahl8k/control_m_and_mwa_airflow_integration/", "subreddit_subscribers": 81624, "created_utc": 1669975129.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a junior data engineer, and got what I thought was an interesting question in an interview - intrigued by your collective approaches. I was given a toy case of a healthcare business that wanted to build a model to detect coughing in their waiting rooms (to de-risk spread of disease etc etc). They have some messy raw audio data from their waiting rooms that is usable. The interviewer asked how I would go about sourcing a robust dataset to train a model on. I came up with three ideas - intrigued to see what you guys think:  \n\n\n* Mechanical Turk the raw audio files to segment out the cases of coughing and label them depending on the \"type\" of cough (wheezy, light, hard etc)\n* Scrape YouTube vids for coughing occurrences and then Mechanical Turk or manually label the audio similar to above\n* Employ actors to cough to outlined constraints e.g. \"young woman with a wheezy cough, no background noise\", \"man with light cough in a busy space\" etc. etc.  \n\n\nThoughts welcomed!", "author_fullname": "t2_5lfzc2mu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data sourcing interview question I got - opinions wanted please", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zahfgf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669974559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a junior data engineer, and got what I thought was an interesting question in an interview - intrigued by your collective approaches. I was given a toy case of a healthcare business that wanted to build a model to detect coughing in their waiting rooms (to de-risk spread of disease etc etc). They have some messy raw audio data from their waiting rooms that is usable. The interviewer asked how I would go about sourcing a robust dataset to train a model on. I came up with three ideas - intrigued to see what you guys think:  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Mechanical Turk the raw audio files to segment out the cases of coughing and label them depending on the &amp;quot;type&amp;quot; of cough (wheezy, light, hard etc)&lt;/li&gt;\n&lt;li&gt;Scrape YouTube vids for coughing occurrences and then Mechanical Turk or manually label the audio similar to above&lt;/li&gt;\n&lt;li&gt;Employ actors to cough to outlined constraints e.g. &amp;quot;young woman with a wheezy cough, no background noise&amp;quot;, &amp;quot;man with light cough in a busy space&amp;quot; etc. etc.&lt;br/&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thoughts welcomed!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "zahfgf", "is_robot_indexable": true, "report_reasons": null, "author": "fourcornerclub", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zahfgf/data_sourcing_interview_question_i_got_opinions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zahfgf/data_sourcing_interview_question_i_got_opinions/", "subreddit_subscribers": 81624, "created_utc": 1669974559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello!\n\nWe have a good amount of data (around 700Gb) that we need to move from Redshift to an RDS table. The data has been unloaded into an S3 in parallel (data\\_000\\_part0, data\\_001\\_part0, etc...) with a manifest file. It does not seem that we can load data from S3 to RDS thanks to the manifest file, as we would do with Redshift: [https://docs.aws.amazon.com/redshift/latest/dg/t\\_Reloading\\_unload\\_files.html](https://docs.aws.amazon.com/redshift/latest/dg/t_Reloading_unload_files.html)\n\nIn this case, would the only solution be to loop over all the unloaded files in the S3 bucket and perform the `aws_s3.table_import_from_s3`, or did I miss a parameter in this command that would accept the manifest file?\n\nI don't really have time to implement another solution and would be glad to keep the process as it is, and find a workaround with `aws_s3.table_import_from_s3`.\n\n Thanks!", "author_fullname": "t2_f1ixi4vt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to move data from Redshift to S3 and then from S3 to RDS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zaglxw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669971701.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;We have a good amount of data (around 700Gb) that we need to move from Redshift to an RDS table. The data has been unloaded into an S3 in parallel (data_000_part0, data_001_part0, etc...) with a manifest file. It does not seem that we can load data from S3 to RDS thanks to the manifest file, as we would do with Redshift: &lt;a href=\"https://docs.aws.amazon.com/redshift/latest/dg/t_Reloading_unload_files.html\"&gt;https://docs.aws.amazon.com/redshift/latest/dg/t_Reloading_unload_files.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;In this case, would the only solution be to loop over all the unloaded files in the S3 bucket and perform the &lt;code&gt;aws_s3.table_import_from_s3&lt;/code&gt;, or did I miss a parameter in this command that would accept the manifest file?&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t really have time to implement another solution and would be glad to keep the process as it is, and find a workaround with &lt;code&gt;aws_s3.table_import_from_s3&lt;/code&gt;.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zaglxw", "is_robot_indexable": true, "report_reasons": null, "author": "No_Fudge1060", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zaglxw/best_way_to_move_data_from_redshift_to_s3_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zaglxw/best_way_to_move_data_from_redshift_to_s3_and/", "subreddit_subscribers": 81624, "created_utc": 1669971701.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This thread is a place where you can share things that might not warrant their own thread. It is automatically posted each month and you can find previous threads in the collection.\n\nExamples:\n\n* What are you working on this month?\n* What was something you accomplished?\n* What was something you learned recently?\n* What is something frustrating you currently?\n\nAs always, sub rules apply. Please be respectful and stay curious.", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Monthly General Discussion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "collections": [{"permalink": "https://www.reddit.com/r/dataengineering/collection/6278fda2-fad1-4706-9e82-6ddb67d49c0b", "link_ids": ["t3_shzqhy", "t3_t4clgk", "t3_ttu87x", "t3_ug2xqg", "t3_v2ka5e", "t3_vp487n", "t3_wdl07g", "t3_x3bb2b", "t3_xsyy4v", "t3_yjchhi", "t3_z9szlc"], "description": "", "title": "Monthly General Discussions", "created_at_utc": 1642292653.587, "subreddit_id": "t5_36en4", "author_name": "theporterhaus", "collection_id": "6278fda2-fad1-4706-9e82-6ddb67d49c0b", "author_id": "t2_2tv9i42n", "last_update_utc": 1669914009.731, "display_layout": null}], "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z9szlc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669914009.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This thread is a place where you can share things that might not warrant their own thread. It is automatically posted each month and you can find previous threads in the collection.&lt;/p&gt;\n\n&lt;p&gt;Examples:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;What are you working on this month?&lt;/li&gt;\n&lt;li&gt;What was something you accomplished?&lt;/li&gt;\n&lt;li&gt;What was something you learned recently?&lt;/li&gt;\n&lt;li&gt;What is something frustrating you currently?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;As always, sub rules apply. Please be respectful and stay curious.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z9szlc", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z9szlc/monthly_general_discussion/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/dataengineering/comments/z9szlc/monthly_general_discussion/", "subreddit_subscribers": 81624, "created_utc": 1669914009.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_b87bzpdn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow vs. Flyte Cheat Sheet", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_z9o2c0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/NxaoGcaDxWWHU3TIlcpIAADJBhzL7P67hFzlOa5sbeU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1669901774.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.flyte.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.flyte.org/airflow-vs-flyte-cheat-sheet", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/RC2MbRygwwxqDo2VZlmIQtpAQJ1cFxGvZZgYEEdN82E.jpg?auto=webp&amp;s=ea0b0bbe73aadad3e6bd577d02fd9f1e299e27c5", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/RC2MbRygwwxqDo2VZlmIQtpAQJ1cFxGvZZgYEEdN82E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=dd87e3f2a93d6c5f2ee0920f84f94d8d861b8a3a", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/RC2MbRygwwxqDo2VZlmIQtpAQJ1cFxGvZZgYEEdN82E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e80ebb2b9f15f1b055861c552975a8d4c6e053d3", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/RC2MbRygwwxqDo2VZlmIQtpAQJ1cFxGvZZgYEEdN82E.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4a5376ca225abc8e21c4896f8bdaaf4fa6aded3d", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/RC2MbRygwwxqDo2VZlmIQtpAQJ1cFxGvZZgYEEdN82E.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8437da0fb0dbe8b9d0eb7281d9a55dfae67e9d33", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/RC2MbRygwwxqDo2VZlmIQtpAQJ1cFxGvZZgYEEdN82E.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2c8504ece89596222f57ec4dab9e60d2762e1197", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/RC2MbRygwwxqDo2VZlmIQtpAQJ1cFxGvZZgYEEdN82E.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f9e17604e06ab06128ebec6051975f4ebf1313f9", "width": 1080, "height": 567}], "variants": {}, "id": "eDvgPS-16Y3YVp1p6K0ygAMUMl_0d2j-femVqSuz6vk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "z9o2c0", "is_robot_indexable": true, "report_reasons": null, "author": "allasamhita", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z9o2c0/airflow_vs_flyte_cheat_sheet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.flyte.org/airflow-vs-flyte-cheat-sheet", "subreddit_subscribers": 81624, "created_utc": 1669901774.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " For one of our NLP project, we have scraped data (downloaded raw data in html format) form a web portal. We are trying to parse the html and finding difficulties as the template they have used in the portal varies over the period of time and quite difficult as sometimes they don't even use proper styling for headers or etc.. We have to identify header, divions, sub division and contents. This hierarchy style is not consistent as they have used several templates to build the portal.  \nAny ideas on how to tackle the situation?", "author_fullname": "t2_eozceps7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help required for html parsing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z9lf4h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669893887.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For one of our NLP project, we have scraped data (downloaded raw data in html format) form a web portal. We are trying to parse the html and finding difficulties as the template they have used in the portal varies over the period of time and quite difficult as sometimes they don&amp;#39;t even use proper styling for headers or etc.. We have to identify header, divions, sub division and contents. This hierarchy style is not consistent as they have used several templates to build the portal.&lt;br/&gt;\nAny ideas on how to tackle the situation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z9lf4h", "is_robot_indexable": true, "report_reasons": null, "author": "Liily_07", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z9lf4h/help_required_for_html_parsing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z9lf4h/help_required_for_html_parsing/", "subreddit_subscribers": 81624, "created_utc": 1669893887.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have followed [this guide](https://www.thedataswamp.com/blog/dynamically-calling-rest-apis-in-azure-data-factory) to create a for each loop retrieving the data I need and it is working, however I would like all my JSON records in a single file, but the copy task is overwriting the previously imported record and I cannot see how to make this an insert/upsert rather than overwriting.  \nDue to my lack of experience and probably asking the wrong questions, Google has not been my friend and I have been unable to adapt this to meet my needs. I have tried changing copy behaviour from none to merge but this still did not solve the issue.  \nCan anyone advise how to achieve what I am after?\n\nThanks in advance!", "author_fullname": "t2_996yq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure Data Factory - For Each overwriting records instead of inserting as new", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z9l6vg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1669893100.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have followed &lt;a href=\"https://www.thedataswamp.com/blog/dynamically-calling-rest-apis-in-azure-data-factory\"&gt;this guide&lt;/a&gt; to create a for each loop retrieving the data I need and it is working, however I would like all my JSON records in a single file, but the copy task is overwriting the previously imported record and I cannot see how to make this an insert/upsert rather than overwriting.&lt;br/&gt;\nDue to my lack of experience and probably asking the wrong questions, Google has not been my friend and I have been unable to adapt this to meet my needs. I have tried changing copy behaviour from none to merge but this still did not solve the issue.&lt;br/&gt;\nCan anyone advise how to achieve what I am after?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/A6xBRktcYTsXDyL8-2tvXRmg93hjJ0aotNVNIADyVwM.jpg?auto=webp&amp;s=a5285e03128d1cd7e6d5f22b283fee9099ce5bc9", "width": 636, "height": 472}, "resolutions": [{"url": "https://external-preview.redd.it/A6xBRktcYTsXDyL8-2tvXRmg93hjJ0aotNVNIADyVwM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d06ffb409fe322ffcf5592050d8f465ef2531e17", "width": 108, "height": 80}, {"url": "https://external-preview.redd.it/A6xBRktcYTsXDyL8-2tvXRmg93hjJ0aotNVNIADyVwM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3fb81a949d387b787cf83eefff576de71db63768", "width": 216, "height": 160}, {"url": "https://external-preview.redd.it/A6xBRktcYTsXDyL8-2tvXRmg93hjJ0aotNVNIADyVwM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2a2d8e088ce91100c8bb15487974fad9f956d2c4", "width": 320, "height": 237}], "variants": {}, "id": "Nvpgvhk7vqwO548EuMgHcL0SJjabUQkQdK7STRIyfnw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z9l6vg", "is_robot_indexable": true, "report_reasons": null, "author": "StylishNihilist", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z9l6vg/azure_data_factory_for_each_overwriting_records/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z9l6vg/azure_data_factory_for_each_overwriting_records/", "subreddit_subscribers": 81624, "created_utc": 1669893100.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "From a career standpoint, does it make sense to get the basic certifications for all the major cloud providers (AWS, Azure, GCP), or should I pick and focus on one?\n\nI am pretty sure the consulting firm I work for will pay for whichever option I go for. It would make sense to go for AWS, since it's the most used, but the customer I am currently assigned on uses GCP and Azure, so I am not sure on which to pick. If it makes sense to get them all, it saves me from the agony of choice.", "author_fullname": "t2_41lgybw3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking advice on cloud certifications", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z9ks43", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669891620.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;From a career standpoint, does it make sense to get the basic certifications for all the major cloud providers (AWS, Azure, GCP), or should I pick and focus on one?&lt;/p&gt;\n\n&lt;p&gt;I am pretty sure the consulting firm I work for will pay for whichever option I go for. It would make sense to go for AWS, since it&amp;#39;s the most used, but the customer I am currently assigned on uses GCP and Azure, so I am not sure on which to pick. If it makes sense to get them all, it saves me from the agony of choice.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "z9ks43", "is_robot_indexable": true, "report_reasons": null, "author": "arminredditer", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z9ks43/seeking_advice_on_cloud_certifications/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z9ks43/seeking_advice_on_cloud_certifications/", "subreddit_subscribers": 81624, "created_utc": 1669891620.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Snowflake for beginners like from where to start", "author_fullname": "t2_jfvfwj1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can anyone give Snowflake Roadmap ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z9p0gx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669904315.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Snowflake for beginners like from where to start&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z9p0gx", "is_robot_indexable": true, "report_reasons": null, "author": "Vijay_Sharma_777", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z9p0gx/can_anyone_give_snowflake_roadmap/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z9p0gx/can_anyone_give_snowflake_roadmap/", "subreddit_subscribers": 81624, "created_utc": 1669904315.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious about how to drive revenue via your 1st party customer data?  \n\n\nNext Tuesday (Dec. 6),  [Jim Lumsden](https://www.linkedin.com/in/jim-a-lumsden/) (data lead @\u00a0[Prolific](https://www.linkedin.com/company/prolific-academic/)), [Mike Maloney](https://www.linkedin.com/in/mike-maloney-5229274/) (field CDO\u00a0@\u00a0[Snowplow](https://www.linkedin.com/in/mike-maloney-5229274/)), [Shashi Raina](https://www.linkedin.com/in/shashiraina/) (sr. partner solutions architect @\u00a0[AWS](https://www.linkedin.com/company/amazon-web-services/)),\u00a0and [Donny Flynn](https://www.linkedin.com/in/donny-flynn-578149a4/) (customer data architect @ [Census](https://www.linkedin.com/company/19055959/admin/)) will break down how to create a data-first culture to support and drive revenue like never before.\n\nThey'll discuss how, using real-world examples from the Prolific data team, Snowplow, AWS, and Census can help you drive more growth for your business by unlocking rich, unified, and accessible behavioral data across your organization.\n\nFaced with the need for high-quality, reliable data, Prolific\u2019s data team built a technology stack to create complete Customer Behavioral Profiles, ensuring the rest of their could access actionable data to best engage with their customers.\n\nWith Customer Behavioral Profiles (and the right data stack), you too can predict your user\u2019s next best action and power your sales team with complete visibility into your customers\u2019 interactions, which means higher sales conversions and revenue. \ud83e\udd11\n\n**Join us as we discuss:**  \n\n\n* The importance of having a high quality data-first culture\u00a0\ud83e\udd1d\n* How Prolific supercharged their sales team with product analytics\u00a0\ud83d\ude80\n* How Customer Behavioral Profiles can empower your organization \ud83d\udcc8\n\nHope to see you there! Sing up \ud83d\udc49 [**here**](https://www.getcensus.com/events/webinar-how-prolific-supercharged-revenue-with-powerful-customer-profiles) \ud83d\udc48", "author_fullname": "t2_ezsyorvh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to support and drive revenue team through data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z9ycz0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.14, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669925665.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious about how to drive revenue via your 1st party customer data?  &lt;/p&gt;\n\n&lt;p&gt;Next Tuesday (Dec. 6),  &lt;a href=\"https://www.linkedin.com/in/jim-a-lumsden/\"&gt;Jim Lumsden&lt;/a&gt; (data lead @\u00a0&lt;a href=\"https://www.linkedin.com/company/prolific-academic/\"&gt;Prolific&lt;/a&gt;), &lt;a href=\"https://www.linkedin.com/in/mike-maloney-5229274/\"&gt;Mike Maloney&lt;/a&gt; (field CDO\u00a0@\u00a0&lt;a href=\"https://www.linkedin.com/in/mike-maloney-5229274/\"&gt;Snowplow&lt;/a&gt;), &lt;a href=\"https://www.linkedin.com/in/shashiraina/\"&gt;Shashi Raina&lt;/a&gt; (sr. partner solutions architect @\u00a0&lt;a href=\"https://www.linkedin.com/company/amazon-web-services/\"&gt;AWS&lt;/a&gt;),\u00a0and &lt;a href=\"https://www.linkedin.com/in/donny-flynn-578149a4/\"&gt;Donny Flynn&lt;/a&gt; (customer data architect @ &lt;a href=\"https://www.linkedin.com/company/19055959/admin/\"&gt;Census&lt;/a&gt;) will break down how to create a data-first culture to support and drive revenue like never before.&lt;/p&gt;\n\n&lt;p&gt;They&amp;#39;ll discuss how, using real-world examples from the Prolific data team, Snowplow, AWS, and Census can help you drive more growth for your business by unlocking rich, unified, and accessible behavioral data across your organization.&lt;/p&gt;\n\n&lt;p&gt;Faced with the need for high-quality, reliable data, Prolific\u2019s data team built a technology stack to create complete Customer Behavioral Profiles, ensuring the rest of their could access actionable data to best engage with their customers.&lt;/p&gt;\n\n&lt;p&gt;With Customer Behavioral Profiles (and the right data stack), you too can predict your user\u2019s next best action and power your sales team with complete visibility into your customers\u2019 interactions, which means higher sales conversions and revenue. \ud83e\udd11&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Join us as we discuss:&lt;/strong&gt;  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The importance of having a high quality data-first culture\u00a0\ud83e\udd1d&lt;/li&gt;\n&lt;li&gt;How Prolific supercharged their sales team with product analytics\u00a0\ud83d\ude80&lt;/li&gt;\n&lt;li&gt;How Customer Behavioral Profiles can empower your organization \ud83d\udcc8&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Hope to see you there! Sing up \ud83d\udc49 &lt;a href=\"https://www.getcensus.com/events/webinar-how-prolific-supercharged-revenue-with-powerful-customer-profiles\"&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt; \ud83d\udc48&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z9ycz0", "is_robot_indexable": true, "report_reasons": null, "author": "Firm_Spite2939", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z9ycz0/how_to_support_and_drive_revenue_team_through_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z9ycz0/how_to_support_and_drive_revenue_team_through_data/", "subreddit_subscribers": 81624, "created_utc": 1669925665.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}