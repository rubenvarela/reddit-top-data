{"kind": "Listing", "data": {"after": null, "dist": 8, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_u5y5wno7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Embedding an OLAP database in the lakeFS UI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 116, "top_awarded_type": null, "hide_score": false, "name": "t3_zuxh0t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/AMumL8-yQlBvVt-QtcoSJGN9ztAaHB5gA7Ivbkr-Qdk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671972282.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "lakefs.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://lakefs.io/blog/lakefs-duckdb-embedding-an-olap-database-in-the-lakefs-ui/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/19bM8x2z03RNBf_Zlc0YAIu3s3uAP1cVnJdEhSfaOUo.jpg?auto=webp&amp;s=e6e9986767998f7192b8feba4d5d6cd6ffa21239", "width": 1200, "height": 1000}, "resolutions": [{"url": "https://external-preview.redd.it/19bM8x2z03RNBf_Zlc0YAIu3s3uAP1cVnJdEhSfaOUo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1d702256466d7f588d77b3c05ed505ee746d28f9", "width": 108, "height": 90}, {"url": "https://external-preview.redd.it/19bM8x2z03RNBf_Zlc0YAIu3s3uAP1cVnJdEhSfaOUo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d814cd8fda1765420505a757255aa93bc29b7904", "width": 216, "height": 180}, {"url": "https://external-preview.redd.it/19bM8x2z03RNBf_Zlc0YAIu3s3uAP1cVnJdEhSfaOUo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ca57bf97e3b3bf6d3c548d8528a74f2ac8c54da9", "width": 320, "height": 266}, {"url": "https://external-preview.redd.it/19bM8x2z03RNBf_Zlc0YAIu3s3uAP1cVnJdEhSfaOUo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fdf256eea8f9814e2b56e64f91d2b612f8815640", "width": 640, "height": 533}, {"url": "https://external-preview.redd.it/19bM8x2z03RNBf_Zlc0YAIu3s3uAP1cVnJdEhSfaOUo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3452ec8a2776201854aa9a44ef08eaa0ee150b9f", "width": 960, "height": 800}, {"url": "https://external-preview.redd.it/19bM8x2z03RNBf_Zlc0YAIu3s3uAP1cVnJdEhSfaOUo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9b292f368226b5009b737a000b3fcd654108696a", "width": 1080, "height": 900}], "variants": {}, "id": "6-MCidx5Xkg-8Z2L_0Ge8tEi7ztLOSXZFTqvHXQOehQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zuxh0t", "is_robot_indexable": true, "report_reasons": null, "author": "rayhumrib", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zuxh0t/embedding_an_olap_database_in_the_lakefs_ui/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://lakefs.io/blog/lakefs-duckdb-embedding-an-olap-database-in-the-lakefs-ui/", "subreddit_subscribers": 84129, "created_utc": 1671972282.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello All,\n\nI am trying to create a Redshift cluster with cloudfomation template. When I modified the AWS provided template and deploying the stack, a new VPC is getting created. Has anyone experienced the same? \n\nAlso, unable to provide a name to Cluster parameter group, Cluster Subnet group and the Security group. \n\nAny references to how to create Redshift cluster within an existing VPC and on how to provide custom names to ClusterParametergroup, ClusterSubnetgroup and Security group.\n\n&amp;#x200B;\n\nThanks.", "author_fullname": "t2_mspamalq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Redshift Cluster with Cloudformation template.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zupa2j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671937700.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello All,&lt;/p&gt;\n\n&lt;p&gt;I am trying to create a Redshift cluster with cloudfomation template. When I modified the AWS provided template and deploying the stack, a new VPC is getting created. Has anyone experienced the same? &lt;/p&gt;\n\n&lt;p&gt;Also, unable to provide a name to Cluster parameter group, Cluster Subnet group and the Security group. &lt;/p&gt;\n\n&lt;p&gt;Any references to how to create Redshift cluster within an existing VPC and on how to provide custom names to ClusterParametergroup, ClusterSubnetgroup and Security group.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zupa2j", "is_robot_indexable": true, "report_reasons": null, "author": "Awsmason", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zupa2j/redshift_cluster_with_cloudformation_template/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zupa2j/redshift_cluster_with_cloudformation_template/", "subreddit_subscribers": 84129, "created_utc": 1671937700.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Everyone!\n\nI am running a few services in AWS using airflow. One of the task invokes a stored procedure in MySQL in AWS RDS to create a table and then another task to export that table to S3 using AWS Data Migration Service. The problem is I need to wait for the table to be fully created before triggering the DMS task which I do not know how yet. My initial idea is to use time.sleep for a few mins but I dont think that's a good idea.\n\nAny ideas are appreciated. Thank you.", "author_fullname": "t2_gzg678i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS - how to wait before starting another service", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zun9in", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671930278.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Everyone!&lt;/p&gt;\n\n&lt;p&gt;I am running a few services in AWS using airflow. One of the task invokes a stored procedure in MySQL in AWS RDS to create a table and then another task to export that table to S3 using AWS Data Migration Service. The problem is I need to wait for the table to be fully created before triggering the DMS task which I do not know how yet. My initial idea is to use time.sleep for a few mins but I dont think that&amp;#39;s a good idea.&lt;/p&gt;\n\n&lt;p&gt;Any ideas are appreciated. Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zun9in", "is_robot_indexable": true, "report_reasons": null, "author": "ryandane123", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zun9in/aws_how_to_wait_before_starting_another_service/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zun9in/aws_how_to_wait_before_starting_another_service/", "subreddit_subscribers": 84129, "created_utc": 1671930278.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a Data Engineer that has just started learning Python.  In my past experience, I always landed data in a STG table with as little changes as possible, then wrote SQL to load the Target and perform post-load logic.  As I'm working with pandas and data frames, I'm spending a lot of time on tasks like changing \"&lt;NULL&gt;\" values to NaN, parsing dates, setting datatypes, etc.\n\nBefore I go too far down that road, what are the opinions here about where to best perform these actions?  My alternative would be to define my STG tables with all \"Text\" columns, dump the data in raw, then perform all those actions with SQL on the way to my target.  Only downside I can foresee is possibly less options for error handling?  Is there a consensus on best practice for where to do these kinds of things?  Any insights are appreciated!", "author_fullname": "t2_14wbya", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Place for Transformations: Python or SQL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zv2rzg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671990483.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a Data Engineer that has just started learning Python.  In my past experience, I always landed data in a STG table with as little changes as possible, then wrote SQL to load the Target and perform post-load logic.  As I&amp;#39;m working with pandas and data frames, I&amp;#39;m spending a lot of time on tasks like changing &amp;quot;&amp;lt;NULL&amp;gt;&amp;quot; values to NaN, parsing dates, setting datatypes, etc.&lt;/p&gt;\n\n&lt;p&gt;Before I go too far down that road, what are the opinions here about where to best perform these actions?  My alternative would be to define my STG tables with all &amp;quot;Text&amp;quot; columns, dump the data in raw, then perform all those actions with SQL on the way to my target.  Only downside I can foresee is possibly less options for error handling?  Is there a consensus on best practice for where to do these kinds of things?  Any insights are appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zv2rzg", "is_robot_indexable": true, "report_reasons": null, "author": "phobia42", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zv2rzg/best_place_for_transformations_python_or_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zv2rzg/best_place_for_transformations_python_or_sql/", "subreddit_subscribers": 84129, "created_utc": 1671990483.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI\u2019m interested in becoming a data engineer, I\u2019m currently a systems project manager at a FAANG company. I have several years of experience with SQL but never an actual analyst title. I have a Bachelors is Business Administration with a minor in Management of Information Systems. \n\nI\u2019m curious to know if it\u2019s a better idea to take courses online for data engineering or to become a SWE first, then learn data engineering and take on that role? I have no coding experience other than SQL (which I know isn\u2019t technically a coding language).\n\nAlso, is it realistic to become a self-taught data engineer? I am trying to weigh between becoming a self taught front end vs data engineer.", "author_fullname": "t2_979mvrm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on career direction", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zv3wwp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671993984.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m interested in becoming a data engineer, I\u2019m currently a systems project manager at a FAANG company. I have several years of experience with SQL but never an actual analyst title. I have a Bachelors is Business Administration with a minor in Management of Information Systems. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m curious to know if it\u2019s a better idea to take courses online for data engineering or to become a SWE first, then learn data engineering and take on that role? I have no coding experience other than SQL (which I know isn\u2019t technically a coding language).&lt;/p&gt;\n\n&lt;p&gt;Also, is it realistic to become a self-taught data engineer? I am trying to weigh between becoming a self taught front end vs data engineer.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zv3wwp", "is_robot_indexable": true, "report_reasons": null, "author": "Hydroxidee", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zv3wwp/advice_on_career_direction/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zv3wwp/advice_on_career_direction/", "subreddit_subscribers": 84129, "created_utc": 1671993984.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\n\n[View Poll](https://www.reddit.com/poll/zv2puz)", "author_fullname": "t2_eajtr4nz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which lakehouse table format do you expect your organization will be using by the end of 2023?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zv2puz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671990300.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/zv2puz\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zv2puz", "is_robot_indexable": true, "report_reasons": null, "author": "alneuman", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1672422300323, "options": [{"text": "Hive", "id": "20612835"}, {"text": "Delta Lake", "id": "20612836"}, {"text": "Iceberg", "id": "20612837"}, {"text": "Hudi", "id": "20612838"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 260, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zv2puz/which_lakehouse_table_format_do_you_expect_your/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/zv2puz/which_lakehouse_table_format_do_you_expect_your/", "subreddit_subscribers": 84129, "created_utc": 1671990300.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi people, I need your suggestions.\nIn my opinion too much depending on UI tools for data engineering is so easy when we can code what we need and use cloud to do computation.\nAnd Apache beam+GCP dataflow and bigquery seems like the perfect solution. (I mean we can use a orchestration tool to get more advantages and of course a tool for dashboards too).\nI can develop EL pipelines and as well as transformation as both batch and streaming jobs, and use bigquery as DW.\nThis give me lesser tools and environment to manage and more time to focus and build the solution.\n\nWhat do you think\u2026", "author_fullname": "t2_4v8di1j8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Wouldn\u2019t google dataflow and google bigquery be enough for medium scale company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zv4kha", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671995950.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi people, I need your suggestions.\nIn my opinion too much depending on UI tools for data engineering is so easy when we can code what we need and use cloud to do computation.\nAnd Apache beam+GCP dataflow and bigquery seems like the perfect solution. (I mean we can use a orchestration tool to get more advantages and of course a tool for dashboards too).\nI can develop EL pipelines and as well as transformation as both batch and streaming jobs, and use bigquery as DW.\nThis give me lesser tools and environment to manage and more time to focus and build the solution.&lt;/p&gt;\n\n&lt;p&gt;What do you think\u2026&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zv4kha", "is_robot_indexable": true, "report_reasons": null, "author": "Tumbleweed-Afraid", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zv4kha/wouldnt_google_dataflow_and_google_bigquery_be/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zv4kha/wouldnt_google_dataflow_and_google_bigquery_be/", "subreddit_subscribers": 84129, "created_utc": 1671995950.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For me, it was 4 different mainframes and ingestion took 5 days.", "author_fullname": "t2_nmytf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the most legacy platform you are using as a data source in your analytics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zv0a16", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671982591.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For me, it was 4 different mainframes and ingestion took 5 days.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zv0a16", "is_robot_indexable": true, "report_reasons": null, "author": "razkaplan", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zv0a16/whats_the_most_legacy_platform_you_are_using_as_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zv0a16/whats_the_most_legacy_platform_you_are_using_as_a/", "subreddit_subscribers": 84129, "created_utc": 1671982591.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}