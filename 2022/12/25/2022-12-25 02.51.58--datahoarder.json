{"kind": "Listing", "data": {"after": "t3_zu49sx", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Today is my first day home since thanksgiving. Sitting in the garage at my mom\u2019s place when I walked in her garage is my Black Friday order. A 16tb western digital red. Just sitting in a static bag. She reminded me the box was wet so she opened it.\n\nPlug it into the computer, pull up disc management. \n\nAnd promptly formatted the wrong drive. Poof. Around 15tb of movies and tv shows.\n\nThe only backup is a list in meta media manager of the movies. \n\nPlex should be able to tell me what tv shows I had.\n\nI should be able to recover everything, but man some of those shows/seasons were low seeded and took forever.\n\nThe best part? The 16tb red drive won\u2019t initialize. And I bought it from newegg.\n\n\n\n\ud83e\udd37\u200d\u2642\ufe0f merry Christmas \ud83c\udf81\ud83c\udf84", "author_fullname": "t2_b8r6aj5o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I failed.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zufyy1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 527, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 527, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "nsfw", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671907533.0, "link_flair_type": "text", "wls": 3, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Today is my first day home since thanksgiving. Sitting in the garage at my mom\u2019s place when I walked in her garage is my Black Friday order. A 16tb western digital red. Just sitting in a static bag. She reminded me the box was wet so she opened it.&lt;/p&gt;\n\n&lt;p&gt;Plug it into the computer, pull up disc management. &lt;/p&gt;\n\n&lt;p&gt;And promptly formatted the wrong drive. Poof. Around 15tb of movies and tv shows.&lt;/p&gt;\n\n&lt;p&gt;The only backup is a list in meta media manager of the movies. &lt;/p&gt;\n\n&lt;p&gt;Plex should be able to tell me what tv shows I had.&lt;/p&gt;\n\n&lt;p&gt;I should be able to recover everything, but man some of those shows/seasons were low seeded and took forever.&lt;/p&gt;\n\n&lt;p&gt;The best part? The 16tb red drive won\u2019t initialize. And I bought it from newegg.&lt;/p&gt;\n\n&lt;p&gt;\ud83e\udd37\u200d\u2642\ufe0f merry Christmas \ud83c\udf81\ud83c\udf84&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": true, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zufyy1", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Professional3832", "discussion_type": null, "num_comments": 97, "send_replies": true, "whitelist_status": "promo_adult_nsfw", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zufyy1/i_failed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zufyy1/i_failed/", "subreddit_subscribers": 661888, "created_utc": 1671907533.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_2iuyumlr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I just realized I am the owner of a currently-working IBM 75GXP \"Death Star.\" (It's still Friday somewhere)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "friday", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_zu3lqp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 280, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Free-Post Friday!", "can_mod_post": false, "score": 280, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/0GBplccnGiO9CLLzR8g7_4CqAk3bSMk-XyhCqcwnr9Y.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671862957.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/geurrufahs7a1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/geurrufahs7a1.jpg?auto=webp&amp;s=a790a3c9180e95f9516117e0ac84d3658d0a30e0", "width": 3024, "height": 4032}, "resolutions": [{"url": "https://preview.redd.it/geurrufahs7a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a4d12567357440624f29f8b2f3c8a528b04cd56c", "width": 108, "height": 144}, {"url": "https://preview.redd.it/geurrufahs7a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=57c2b8f139ff50af14b7ff79666037bf690869db", "width": 216, "height": 288}, {"url": "https://preview.redd.it/geurrufahs7a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0e49d9326143c4434d8390c49cb5751e784fafff", "width": 320, "height": 426}, {"url": "https://preview.redd.it/geurrufahs7a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6596a34711bbe1f4b6f42c15a2924c5567055f43", "width": 640, "height": 853}, {"url": "https://preview.redd.it/geurrufahs7a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=594f1aa8d312c312c1eb956c24b61806a4cafaeb", "width": 960, "height": 1280}, {"url": "https://preview.redd.it/geurrufahs7a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=13b97234daefd9a57134763572b79a5cfe981d13", "width": 1080, "height": 1440}], "variants": {}, "id": "xxpnA90_HfZJ_EwdYuQ4Gsrb71ZaweGsfDjbmiDctv8"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82f515be-b94e-11eb-9f8a-0e1030dba663", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "20.6TB", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zu3lqp", "is_robot_indexable": true, "report_reasons": null, "author": "wyatt8750", "discussion_type": null, "num_comments": 46, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/zu3lqp/i_just_realized_i_am_the_owner_of_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/geurrufahs7a1.jpg", "subreddit_subscribers": 661888, "created_utc": 1671862957.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_7uq2db", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "I bought a external hard drive but it made noise so i opened it. This was loose. Does anyone know if it is important or crucial?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "media_metadata": {"3hc1zfq5wu7a1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/3hc1zfq5wu7a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=54714cc87801a038e4bffdb69309909319c3f0aa"}, {"y": 162, "x": 216, "u": "https://preview.redd.it/3hc1zfq5wu7a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b601fd362834a19e50b2d58efbff9490ceedabaf"}, {"y": 240, "x": 320, "u": "https://preview.redd.it/3hc1zfq5wu7a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6d3667b408ef7413985f36857a2750e9f85906e6"}, {"y": 480, "x": 640, "u": "https://preview.redd.it/3hc1zfq5wu7a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ac04a9b461b21cda62ee293b96937d8a09a628b4"}, {"y": 720, "x": 960, "u": "https://preview.redd.it/3hc1zfq5wu7a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3d6f174730de51af023268aafe4d01669b4de640"}, {"y": 810, "x": 1080, "u": "https://preview.redd.it/3hc1zfq5wu7a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=90afaaa9c916ab86188e8af3ba3eb5db84334141"}], "s": {"y": 3024, "x": 4032, "u": "https://preview.redd.it/3hc1zfq5wu7a1.jpg?width=4032&amp;format=pjpg&amp;auto=webp&amp;s=6c32aa7787bf370f13ddd8e9e137f52c7b226424"}, "id": "3hc1zfq5wu7a1"}, "567gjeq5wu7a1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/567gjeq5wu7a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3a49189739c5fd1283e88c3ec689d7e1a55d74be"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/567gjeq5wu7a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=46637fc0b4e198a3bd8c4d3a346d805755b63898"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/567gjeq5wu7a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bef203c53f82591b9add23241950019d189a0895"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/567gjeq5wu7a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=db900743e890c5415e9d4caa7788c4322ebdd8dd"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/567gjeq5wu7a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=67e0190741a3f4808bacbdd6f8899247b7190509"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/567gjeq5wu7a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=33532430daa1b9217425b0010aa9683ba7002add"}], "s": {"y": 4032, "x": 3024, "u": "https://preview.redd.it/567gjeq5wu7a1.jpg?width=3024&amp;format=pjpg&amp;auto=webp&amp;s=52285ba53808953c0a57045c27fcf2c003aa369f"}, "id": "567gjeq5wu7a1"}}, "name": "t3_zuawmx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "ups": 212, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "3hc1zfq5wu7a1", "id": 222452277}, {"media_id": "567gjeq5wu7a1", "id": 222452278}]}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 212, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/vZjgP199De85409oIFEJz9oynldwCTfAsAaqiyLOszw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671892131.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/zuawmx", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zuawmx", "is_robot_indexable": true, "report_reasons": null, "author": "Elliott_The_Chicken", "discussion_type": null, "num_comments": 45, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zuawmx/i_bought_a_external_hard_drive_but_it_made_noise/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/zuawmx", "subreddit_subscribers": 661888, "created_utc": 1671892131.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A massive Australian archive of newspapers and documents at the National Library of Australia's funding runs out in July 2023 \u2013 and the National Library is threatening to pull the plug. Can we help?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 68, "top_awarded_type": null, "hide_score": false, "name": "t3_zu2zng", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 53, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e4444668-b98a-11e2-b419-12313d169640", "is_original_content": false, "author_fullname": "t2_123lealg", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 53, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Jdm6HDauY2D6LZnM5ZW7S4ImwjySSxYKuL9qWyvzInw.jpg", "edited": false, "author_flair_css_class": "threefive", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "AustralianPolitics", "selftext": "", "author_fullname": "t2_83cz1fj4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trove's funding runs out in July 2023 \u2013 and the National Library is threatening to pull the plug. It's time for a radical overhaul", "link_flair_richtext": [{"e": "text", "t": "Opinion Piece"}], "subreddit_name_prefixed": "r/AustralianPolitics", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 68, "top_awarded_type": null, "hide_score": false, "name": "t3_zttgdv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 49, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Opinion Piece", "can_mod_post": false, "score": 49, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Jdm6HDauY2D6LZnM5ZW7S4ImwjySSxYKuL9qWyvzInw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671831769.0, "link_flair_type": "richtext", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "theconversation.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "new", "banned_at_utc": null, "url_overridden_by_dest": "https://theconversation.com/troves-funding-runs-out-in-july-2023-and-the-national-library-is-threatening-to-pull-the-plug-its-time-for-a-radical-overhaul-197025", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Jeycfop4HqZxbuffKYgnG3qQbW3yrlqzPyWWPoIpdZ8.jpg?auto=webp&amp;s=b316a8d27d8e138ab76327e2b6375a72d18fc35d", "width": 1356, "height": 668}, "resolutions": [{"url": "https://external-preview.redd.it/Jeycfop4HqZxbuffKYgnG3qQbW3yrlqzPyWWPoIpdZ8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cf3bcc65d8ce383c1dfe67741bb91a85bb17e03e", "width": 108, "height": 53}, {"url": "https://external-preview.redd.it/Jeycfop4HqZxbuffKYgnG3qQbW3yrlqzPyWWPoIpdZ8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=def81e2165be2b07d11d5d3d3abc454737803811", "width": 216, "height": 106}, {"url": "https://external-preview.redd.it/Jeycfop4HqZxbuffKYgnG3qQbW3yrlqzPyWWPoIpdZ8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=70a898c48c232c913175a71dfbbc78949cf1bfe5", "width": 320, "height": 157}, {"url": "https://external-preview.redd.it/Jeycfop4HqZxbuffKYgnG3qQbW3yrlqzPyWWPoIpdZ8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7362378ef69546ab4cf8a0cb0c8a3b051448aa97", "width": 640, "height": 315}, {"url": "https://external-preview.redd.it/Jeycfop4HqZxbuffKYgnG3qQbW3yrlqzPyWWPoIpdZ8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1e0d31dfef2ce480b37bba22c8f0740a68107e2d", "width": 960, "height": 472}, {"url": "https://external-preview.redd.it/Jeycfop4HqZxbuffKYgnG3qQbW3yrlqzPyWWPoIpdZ8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=82cba7f98b7e9090bcd9e2530fe4047c24e55f5b", "width": 1080, "height": 532}], "variants": {}, "id": "EuLyq_b6Y8-qILP7KDuWtaS4qM2GMIdYybZMiukvOjw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0fa87b9e-e2cb-11e2-8fce-12313b0c8c59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2snwr", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#000000", "id": "zttgdv", "is_robot_indexable": true, "report_reasons": null, "author": "89b3ea330bd60ede80ad", "discussion_type": null, "num_comments": 7, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/AustralianPolitics/comments/zttgdv/troves_funding_runs_out_in_july_2023_and_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://theconversation.com/troves-funding-runs-out-in-july-2023-and-the-national-library-is-threatening-to-pull-the-plug-its-time-for-a-radical-overhaul-197025", "subreddit_subscribers": 224377, "created_utc": 1671831769.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1671860736.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "theconversation.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://theconversation.com/troves-funding-runs-out-in-july-2023-and-the-national-library-is-threatening-to-pull-the-plug-its-time-for-a-radical-overhaul-197025", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Jeycfop4HqZxbuffKYgnG3qQbW3yrlqzPyWWPoIpdZ8.jpg?auto=webp&amp;s=b316a8d27d8e138ab76327e2b6375a72d18fc35d", "width": 1356, "height": 668}, "resolutions": [{"url": "https://external-preview.redd.it/Jeycfop4HqZxbuffKYgnG3qQbW3yrlqzPyWWPoIpdZ8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cf3bcc65d8ce383c1dfe67741bb91a85bb17e03e", "width": 108, "height": 53}, {"url": "https://external-preview.redd.it/Jeycfop4HqZxbuffKYgnG3qQbW3yrlqzPyWWPoIpdZ8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=def81e2165be2b07d11d5d3d3abc454737803811", "width": 216, "height": 106}, {"url": "https://external-preview.redd.it/Jeycfop4HqZxbuffKYgnG3qQbW3yrlqzPyWWPoIpdZ8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=70a898c48c232c913175a71dfbbc78949cf1bfe5", "width": 320, "height": 157}, {"url": "https://external-preview.redd.it/Jeycfop4HqZxbuffKYgnG3qQbW3yrlqzPyWWPoIpdZ8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7362378ef69546ab4cf8a0cb0c8a3b051448aa97", "width": 640, "height": 315}, {"url": "https://external-preview.redd.it/Jeycfop4HqZxbuffKYgnG3qQbW3yrlqzPyWWPoIpdZ8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1e0d31dfef2ce480b37bba22c8f0740a68107e2d", "width": 960, "height": 472}, {"url": "https://external-preview.redd.it/Jeycfop4HqZxbuffKYgnG3qQbW3yrlqzPyWWPoIpdZ8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=82cba7f98b7e9090bcd9e2530fe4047c24e55f5b", "width": 1080, "height": 532}], "variants": {}, "id": "EuLyq_b6Y8-qILP7KDuWtaS4qM2GMIdYybZMiukvOjw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "1.44MB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zu2zng", "is_robot_indexable": true, "report_reasons": null, "author": "King_Millez", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_zttgdv", "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/zu2zng/a_massive_australian_archive_of_newspapers_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://theconversation.com/troves-funding-runs-out-in-july-2023-and-the-national-library-is-threatening-to-pull-the-plug-its-time-for-a-radical-overhaul-197025", "subreddit_subscribers": 661888, "created_utc": 1671860736.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_gh87r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seagate Expansion 14TB External Hard Drive - $199.99 - $14.28/TB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "sale", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_zu74ma", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Sale", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/aLqq_93atLfm-41v2Fa_L0-xqrrEW3LjaU2AwyyLgFY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671877322.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "newegg.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.newegg.com/seagate-expansion-14tb-black/p/N82E16822184958", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/nI-Yr1Eb668Ujra70Z2m4G-_R5DY13lMvMbeULO9VPI.jpg?auto=webp&amp;s=689278e484ad9c4c83d4df70e18048e82725e8dc", "width": 640, "height": 480}, "resolutions": [{"url": "https://external-preview.redd.it/nI-Yr1Eb668Ujra70Z2m4G-_R5DY13lMvMbeULO9VPI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=edaa62fd8b79b6465f58877995efcfa3893f14a3", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/nI-Yr1Eb668Ujra70Z2m4G-_R5DY13lMvMbeULO9VPI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=122a2c5874c9e4e5c8368eec8f52730025ff11ad", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/nI-Yr1Eb668Ujra70Z2m4G-_R5DY13lMvMbeULO9VPI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9d64e06c5bb1f3e5b184ad4af9bf570f1c2642de", "width": 320, "height": 240}, {"url": "https://external-preview.redd.it/nI-Yr1Eb668Ujra70Z2m4G-_R5DY13lMvMbeULO9VPI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=efb1139b3a693a031f32356adbabc972e66055f5", "width": 640, "height": 480}], "variants": {}, "id": "7vuS_CbXNVn0x0fZd8EQmhVJFDFp6gzzPLeuoH7cgn8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ef8232de-b94e-11eb-ba29-0ed106a6f983", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "zu74ma", "is_robot_indexable": true, "report_reasons": null, "author": "Viknee", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zu74ma/seagate_expansion_14tb_external_hard_drive_19999/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.newegg.com/seagate-expansion-14tb-black/p/N82E16822184958", "subreddit_subscribers": 661888, "created_utc": 1671877322.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Anyone have any stories of lost media or cool pieces of your data stores?", "author_fullname": "t2_4aid7dde", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What\u2019s the rarest piece of data you have preserved?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zukpxk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671921889.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone have any stories of lost media or cool pieces of your data stores?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "zukpxk", "is_robot_indexable": true, "report_reasons": null, "author": "Dirtrubber", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zukpxk/whats_the_rarest_piece_of_data_you_have_preserved/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zukpxk/whats_the_rarest_piece_of_data_you_have_preserved/", "subreddit_subscribers": 661888, "created_utc": 1671921889.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "link to the previous post to make some light on the project  \n\n\n[2021 Update](https://www.reddit.com/r/DataHoarder/comments/ro9k0z/bibliotheca_alexandrina_an_almost_500_gb_hoard_of/)  \n\n\n**Bibliotheca Alexandrina - 602 GB**   \nmagnet:?xt=urn:btih:5b407389216bb686e7d2f7ecf8aeb1e960f53154  \n\n\n**Variorum Collected Studies** \\- 116 GB  \n magnet:?xt=urn:btih:f9f10ded2a254eacfefa4deeef040d8aa56ed18b \n\nThe series is published by Ashgate and since it was established in 1970, over 1000 volumes have been produced. [https://en.wikipedia.org/wiki/Variorum\\_Collected\\_Studies](https://en.wikipedia.org/wiki/Variorum_Collected_Studies) \n\n  \nFAQ  \n**what's included in these 600GB?**  \nClassical and medieval academic books, something early modern (1600s), some archeology/prehistory  \n\n\n**what's the difference between this collection and libgen/zlibrary/archive/..?**  \nquality of the books. Many of my books are tagged as retail, i can vouch for each of them  \n\n\n**why zipped folders?**  \nall the folders have been zipped due the path being way too long for torrent, if you get some issues unpacking just rename the folder inside the zip. If you don't like the idea of torrenting zipped files from a random stranger on internet i can send the files separately (no clue how but its a possibility)  \n\n\n**are there any alternative to torrent?**   \ntill few months ago i was using gdrive but it became too unreliable and drives kept getting deleted,   \nNow im brainstorming a way to upload everything on a cloud to avoid torrenting zipped folders but everything so far is beyond my financial capabilities  \n\n\n**is there a list of the books collected?**  \nyes, under the info folder   \n\n\n**i need a single file/or few folders can you send them to me without torrent?**  \ndm me here [Bibliotheca Alexandrina Discord](https://discord.gg/5Ga2jzjZxB) and ill help you out  \n\n\n**will you stop doing this?**  \ni've been working on this collection since october 2008, i have no intentions to stop anytime soon  \n\n\n**how can i contribute to the project?**  \nsending books im missing, maybe your university has access to some forgotten scans or has access to some publishers? anything helps!  \n\n\n**what's next?**  \ni do work actively on a **Warhammer Collection** and im planning to do something about sword &amp; sorcery fantasy but no ETA yet.  \nmagnet:?xt=urn:btih:ce271c2c106af88f97f7dc2b875f5667131fd5f0  \n\n\n  \n\n\n\\- My upload speed is 2MB, it might take a little while to upload, please have some patience :)  \n\n\n  \nenjoy!", "author_fullname": "t2_nmbmr98", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bibliotheca Alexandrina - a 600 GB+ hoard of history books [December 2022]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zuniqw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Bibliotheca Alexandrina", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671931198.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;link to the previous post to make some light on the project  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/ro9k0z/bibliotheca_alexandrina_an_almost_500_gb_hoard_of/\"&gt;2021 Update&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Bibliotheca Alexandrina - 602 GB&lt;/strong&gt;&lt;br/&gt;\nmagnet:?xt=urn:btih:5b407389216bb686e7d2f7ecf8aeb1e960f53154  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Variorum Collected Studies&lt;/strong&gt; - 116 GB&lt;br/&gt;\n magnet:?xt=urn:btih:f9f10ded2a254eacfefa4deeef040d8aa56ed18b &lt;/p&gt;\n\n&lt;p&gt;The series is published by Ashgate and since it was established in 1970, over 1000 volumes have been produced. &lt;a href=\"https://en.wikipedia.org/wiki/Variorum_Collected_Studies\"&gt;https://en.wikipedia.org/wiki/Variorum_Collected_Studies&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;FAQ&lt;br/&gt;\n&lt;strong&gt;what&amp;#39;s included in these 600GB?&lt;/strong&gt;&lt;br/&gt;\nClassical and medieval academic books, something early modern (1600s), some archeology/prehistory  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;what&amp;#39;s the difference between this collection and libgen/zlibrary/archive/..?&lt;/strong&gt;&lt;br/&gt;\nquality of the books. Many of my books are tagged as retail, i can vouch for each of them  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;why zipped folders?&lt;/strong&gt;&lt;br/&gt;\nall the folders have been zipped due the path being way too long for torrent, if you get some issues unpacking just rename the folder inside the zip. If you don&amp;#39;t like the idea of torrenting zipped files from a random stranger on internet i can send the files separately (no clue how but its a possibility)  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;are there any alternative to torrent?&lt;/strong&gt;&lt;br/&gt;\ntill few months ago i was using gdrive but it became too unreliable and drives kept getting deleted,&lt;br/&gt;\nNow im brainstorming a way to upload everything on a cloud to avoid torrenting zipped folders but everything so far is beyond my financial capabilities  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;is there a list of the books collected?&lt;/strong&gt;&lt;br/&gt;\nyes, under the info folder   &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;i need a single file/or few folders can you send them to me without torrent?&lt;/strong&gt;&lt;br/&gt;\ndm me here &lt;a href=\"https://discord.gg/5Ga2jzjZxB\"&gt;Bibliotheca Alexandrina Discord&lt;/a&gt; and ill help you out  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;will you stop doing this?&lt;/strong&gt;&lt;br/&gt;\ni&amp;#39;ve been working on this collection since october 2008, i have no intentions to stop anytime soon  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;how can i contribute to the project?&lt;/strong&gt;&lt;br/&gt;\nsending books im missing, maybe your university has access to some forgotten scans or has access to some publishers? anything helps!  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;what&amp;#39;s next?&lt;/strong&gt;&lt;br/&gt;\ni do work actively on a &lt;strong&gt;Warhammer Collection&lt;/strong&gt; and im planning to do something about sword &amp;amp; sorcery fantasy but no ETA yet.&lt;br/&gt;\nmagnet:?xt=urn:btih:ce271c2c106af88f97f7dc2b875f5667131fd5f0  &lt;/p&gt;\n\n&lt;p&gt;- My upload speed is 2MB, it might take a little while to upload, please have some patience :)  &lt;/p&gt;\n\n&lt;p&gt;enjoy!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "zuniqw", "is_robot_indexable": true, "report_reasons": null, "author": "RedHeadedKhajiit", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zuniqw/bibliotheca_alexandrina_a_600_gb_hoard_of_history/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zuniqw/bibliotheca_alexandrina_a_600_gb_hoard_of_history/", "subreddit_subscribers": 661888, "created_utc": 1671931198.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have hardware infrastructure in place and have a folder structure I like. All that is fine.\n\nIt would be cool to have an app that made it easier to search and go through content. I'd like to be able to tag similar things instead of relying only on using folders. I'm imagining something like Plex where there is a database of information and you can browse or search.\n\nI've heard of [stash](https://github.com/stashapp/stash) but don't have any experience with it.\n\nTwo additional challenges:\n\n1. Most of my content are videos posted online, so these aren't like official released media. There probably isn't an easy database that exists with all the info. I assume I'd have to build that db myself.\n2. For privacy's sake, I keep all of the data encrypted with VeraCrypt. I am not tied to this solution, but I do want to restrict access, ideally at the file storage layer (but not required). So any solution either has to work directly with some form of encrypted storage, or as part of starting up needs to be able to mount and then access storage otherwise decrypted and made available (maybe something with ZFS?).\n   1. App ideally also requires authentication to access.", "author_fullname": "t2_qhuwf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you easily access/browse and organize stored NSFW content?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zu0qod", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "nsfw", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1671853021.0, "link_flair_type": "text", "wls": 3, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have hardware infrastructure in place and have a folder structure I like. All that is fine.&lt;/p&gt;\n\n&lt;p&gt;It would be cool to have an app that made it easier to search and go through content. I&amp;#39;d like to be able to tag similar things instead of relying only on using folders. I&amp;#39;m imagining something like Plex where there is a database of information and you can browse or search.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve heard of &lt;a href=\"https://github.com/stashapp/stash\"&gt;stash&lt;/a&gt; but don&amp;#39;t have any experience with it.&lt;/p&gt;\n\n&lt;p&gt;Two additional challenges:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Most of my content are videos posted online, so these aren&amp;#39;t like official released media. There probably isn&amp;#39;t an easy database that exists with all the info. I assume I&amp;#39;d have to build that db myself.&lt;/li&gt;\n&lt;li&gt;For privacy&amp;#39;s sake, I keep all of the data encrypted with VeraCrypt. I am not tied to this solution, but I do want to restrict access, ideally at the file storage layer (but not required). So any solution either has to work directly with some form of encrypted storage, or as part of starting up needs to be able to mount and then access storage otherwise decrypted and made available (maybe something with ZFS?).\n\n&lt;ol&gt;\n&lt;li&gt;App ideally also requires authentication to access.&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": true, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DMpLwO4MnR-DkY8zg9fevSIOvWBSza0P7if-tj1dv2Q.jpg?auto=webp&amp;s=0bf25eee62b61ba4ad9936e3997d24b5a4e2f4d7", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/DMpLwO4MnR-DkY8zg9fevSIOvWBSza0P7if-tj1dv2Q.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2a90cdefb8bcb16efb6a5dab5a6fece1db897871", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/DMpLwO4MnR-DkY8zg9fevSIOvWBSza0P7if-tj1dv2Q.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e374b7c792c750249399bc3dc70d0f8609dc6c4b", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/DMpLwO4MnR-DkY8zg9fevSIOvWBSza0P7if-tj1dv2Q.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3dc3fb3bb724633e0f6ab6089878af2c987f03cb", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/DMpLwO4MnR-DkY8zg9fevSIOvWBSza0P7if-tj1dv2Q.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a67c45fd8f91f88901741fb7c5ee9550e298b39c", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/DMpLwO4MnR-DkY8zg9fevSIOvWBSza0P7if-tj1dv2Q.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e60c155112f3c1b5565ffd2ac2a57ac38eeb6776", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/DMpLwO4MnR-DkY8zg9fevSIOvWBSza0P7if-tj1dv2Q.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9f515c643bad9db645cdfaa8f605b7da4f3e1b1d", "width": 1080, "height": 540}], "variants": {"obfuscated": {"source": {"url": "https://external-preview.redd.it/DMpLwO4MnR-DkY8zg9fevSIOvWBSza0P7if-tj1dv2Q.jpg?blur=40&amp;format=pjpg&amp;auto=webp&amp;s=6b4b26682864e9d55e480a5d3ec5d304d24b10ad", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/DMpLwO4MnR-DkY8zg9fevSIOvWBSza0P7if-tj1dv2Q.jpg?width=108&amp;crop=smart&amp;blur=10&amp;format=pjpg&amp;auto=webp&amp;s=7a2631029b611d6efe0468b07d404ac87352030d", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/DMpLwO4MnR-DkY8zg9fevSIOvWBSza0P7if-tj1dv2Q.jpg?width=216&amp;crop=smart&amp;blur=21&amp;format=pjpg&amp;auto=webp&amp;s=47dbd192a7f3f47a38fb1fc252fb757b67525050", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/DMpLwO4MnR-DkY8zg9fevSIOvWBSza0P7if-tj1dv2Q.jpg?width=320&amp;crop=smart&amp;blur=32&amp;format=pjpg&amp;auto=webp&amp;s=d2b515779aa49c89f26e1eb5182cbf023227805b", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/DMpLwO4MnR-DkY8zg9fevSIOvWBSza0P7if-tj1dv2Q.jpg?width=640&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=8d295f69734c043f9413ec22f328d3d9a7e09fba", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/DMpLwO4MnR-DkY8zg9fevSIOvWBSza0P7if-tj1dv2Q.jpg?width=960&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=37265230c938a020e2d1fe2fd69c1de66365684b", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/DMpLwO4MnR-DkY8zg9fevSIOvWBSza0P7if-tj1dv2Q.jpg?width=1080&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=1296c4b838fc1a8a69bedcb4dffb400a1063694d", "width": 1080, "height": 540}]}, "nsfw": {"source": {"url": "https://external-preview.redd.it/DMpLwO4MnR-DkY8zg9fevSIOvWBSza0P7if-tj1dv2Q.jpg?blur=40&amp;format=pjpg&amp;auto=webp&amp;s=6b4b26682864e9d55e480a5d3ec5d304d24b10ad", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/DMpLwO4MnR-DkY8zg9fevSIOvWBSza0P7if-tj1dv2Q.jpg?width=108&amp;crop=smart&amp;blur=10&amp;format=pjpg&amp;auto=webp&amp;s=7a2631029b611d6efe0468b07d404ac87352030d", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/DMpLwO4MnR-DkY8zg9fevSIOvWBSza0P7if-tj1dv2Q.jpg?width=216&amp;crop=smart&amp;blur=21&amp;format=pjpg&amp;auto=webp&amp;s=47dbd192a7f3f47a38fb1fc252fb757b67525050", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/DMpLwO4MnR-DkY8zg9fevSIOvWBSza0P7if-tj1dv2Q.jpg?width=320&amp;crop=smart&amp;blur=32&amp;format=pjpg&amp;auto=webp&amp;s=d2b515779aa49c89f26e1eb5182cbf023227805b", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/DMpLwO4MnR-DkY8zg9fevSIOvWBSza0P7if-tj1dv2Q.jpg?width=640&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=8d295f69734c043f9413ec22f328d3d9a7e09fba", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/DMpLwO4MnR-DkY8zg9fevSIOvWBSza0P7if-tj1dv2Q.jpg?width=960&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=37265230c938a020e2d1fe2fd69c1de66365684b", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/DMpLwO4MnR-DkY8zg9fevSIOvWBSza0P7if-tj1dv2Q.jpg?width=1080&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=1296c4b838fc1a8a69bedcb4dffb400a1063694d", "width": 1080, "height": 540}]}}, "id": "RbwIA5jnSpyJNg2rOxEgx0axUnKZhPgLy-2f4uOwkGc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zu0qod", "is_robot_indexable": true, "report_reasons": null, "author": "DontCryForMeThrowAwa", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "promo_adult_nsfw", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zu0qod/how_do_you_easily_accessbrowse_and_organize/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zu0qod/how_do_you_easily_accessbrowse_and_organize/", "subreddit_subscribers": 661888, "created_utc": 1671853021.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Download and search your own selection of books from libgen with linux", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zudr4x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_bshvx5lk", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "libgen", "selftext": "Here is a guide to :\n\n* download only a subset of books from libgen\n* rename the books in readable file names\n* search the books for content like zlibrary used to do\n\nThis guide requires basic knowledge of linux, bash, regular expressions, SQL and torrenting.\n\n&amp;#x200B;\n\n**Downloading only a part of libgen**\n\nFirst, you need to install a mysql server, dbeaver and transmission-daemon on a linux machine\n\n[https://www.digitalocean.com/community/tutorials/how-to-install-mysql-on-ubuntu-20-04](https://www.digitalocean.com/community/tutorials/how-to-install-mysql-on-ubuntu-20-04)\n\n[https://dbeaver.io/](https://dbeaver.io/)\n\n[https://transmissionbt.com/](https://transmissionbt.com/)\n\nYou will also need to download the libgen database (libgen\\_compact is enough) and all the torrents\n\n[http://libgen.rs/dbdumps/](http://libgen.rs/dbdumps/)\n\n[http://libgen.rs/repository\\_torrent/](http://libgen.rs/repository_torrent/)\n\nOnce you have installed and setup the mysql server, create the libgen database and run the following command to import the data\n\n    mysql -u root -p libgen &lt; libgen_compact.sql\n\n&amp;#x200B;\n\nThe default transmission web interface is located at\n\n[http://localhost:9091/transmission/web/](http://localhost:9091/transmission/web/)\n\nIts settings are in /etc/transmission-daemon/settings.json\n\nConfigure transmission to not start torrents when added. Also set your download directory to the drive you would like to use for storage, *use an ext4 partition*. Under the network settings, set an open port from your router or vpn. You will also want to set scrape-paused-torrents-enabled to false. cd into the directory where you downloaded the torrents and run\n\n    for i in *.torrent; do transmission-remote -a $i; done\n\nto add all torrents without starting them\n\n    transmission-remote -l &gt; torrents.csv #saves info about transmission\u2019 torrents ID\n    for i in $(seq 1 3533); do transmission-remote -t $i -if &gt;&gt; files.csv; done\n    transmission-remote -tall -Gall # unselect all books from downloading\n\nConvert the output of transmission-remote to csv format :\n\n    sed -i -re 's/^\\s+//g' torrents.csv\n    sed -i -re 's/\\s{2,}/;/g' torrents.csv\n    \n    sed -i '0,/#/s//ID /' files.csv\n    sed -i '/files/d' files.csv\n    sed -i '/#/d' files.csv\n    sed -i -re 's/^\\s+//g' files.csv\n    sed -i -re 's/[:%]/ /g' files.csv\n    sed -i -re 's/\\//;/g' files.csv\n    sed -i -re 's/\\s{2,}/;/g' files.csv\n    sed -i -re 's/nan/0/gi' files.csv\n\nEdit files.csv to replace the first line with :\n\n    ID;Done;Priority;Get;Size;Name;MD5\n\nNext, use dbeaver to import the csv files you just created into the libgen database (right click on the database &gt; import data &gt; csv) and name the tables \u201cfiles\u201d and \u201ctorrents\u201d\n\nCreate three indexes on these tables, either using the followin SQL queries or by using dbeavers gui. The fields that need indexes are Name and md5.\n\n    CREATE INDEX files_md5_IDX USING BTREE ON libgen.files (md5);\n    CREATE INDEX files_Name_IDX USING BTREE ON libgen.files (Name);\n    CREATE INDEX torrents_Name_IDX USING BTREE ON libgen.torrents (Name);\n\nIn dbeaver and run the following query :\n\n    select sum(Filesize), count(*)\n    from updated u\n    inner join files f on f.md5 = u.MD5\n    INNER JOIN torrents t on t.Name = f.Name\n    WHERE Extension in ('pdf')\n    and `Year` in ('2023', '2022', '2021', '2020')\n    and `Language` in ('Spanish', 'English')\n    and Filesize &lt; 40000000\n\nThis query counts the size of the books you are going to download. Tune it until you find a selection of books that both interest you and fits in your hard drive. In the above case, the query selects \\~700 Gb of english and Spanish books published in the years 2020-23 that are below 40MB.\n\nOnce you have found a where clause that satisfy your needs, use the following query to produce a list of transmission commands that will enable the download of the desired books :\n\n    select CONCAT('transmission-remote -t', t.ID, ' -g', f.ID)\n    from updated u\n    inner join files f on f.md5 = u.MD5\n    INNER JOIN torrents t on t.Name = f.Name\n    WHERE Extension in ('pdf')\n    and `Year` in ('2023', '2022', '2021', '2020')\n    and `Language` in ('Spanish', 'English')\n    and Filesize &lt; 40000000\n    ORDER by t.ID DESC, f.ID desc\n\ndbeaver has an export data feature that you can use to save the results of this query to a text file. Once the export is done, open the text file and remove the | characters to obtain only the bash commands. Add set -x at the top of the file if you wish to follow the execution of these commands. In the above example \\~70k files are selected for downloads and the execution takes a while.\n\n    Bash commands.txt # takes a while, use tmux if you need to disconnect\n\nTransmission is now ready to download the selection of books that you made. However there are \\~ 3k torrents to download and transmission will have a difficult time handling the queue of torrents if you start them all at once. This is why I made the following nodejs script that will stop idle torrents and start 20 torrents at random :\n\n    const { exec } = require('child_process');\n    exec('transmission-remote -l', (err, stdout, stderr) =&gt; {\n        if (err) {\n            // node couldn't execute the command\n            console.error(err)\n            return;\n        }\n    \n        let lines = stdout.split(/\\n/)\n        let header = lines.shift().replace(/^\\s+/, '').split(/\\s+/)\n        lines.pop()\n        lines.pop()\n    \n        let torrents = []\n        for(let line of lines) {\n            line = line.replace(/^\\s+/, '').split(/\\s{2,}/)\n            let obj = {}\n            for(let n = 0 ; n &lt; line.length ; ++n) {\n            obj[header[n]] = line[n]\n            }\n            torrents.push(obj)\n        }\n        \n        torrents = torrents.filter(t =&gt; t.ID &gt; 1000)\n        \n        for(let t of torrents.filter(t =&gt; (t.Status == 'Idle' || t.Status == 'Queued'))\n        {    \n            exec(`transmission-remote -t${t.ID} -S`)\n        }\n    \n        let tornd = torrents.filter(t =&gt; (t.Status == 'Stopped' || t.Status == 'Paused')).sort(() =&gt; Math.random() - 0.5)\n    \n        for(let t = 0 ; t &lt; 20 ; ++t) {\n            exec(`transmission-remote -t${tornd[t].ID} -s`)\n        }\n    });\n\nSave it in queue.js and run node queue.js every 10 min or so with a crontab.\n\n&amp;#x200B;\n\n**Renaming the books into readable filenames**\n\nHere we create ext4 hard links for each book with readable filenames, assuming the torrents are downloaded in md5/ and the links go into books/\n\nSame principle as earlier, run the following query with your own where clause :\n\n    select CONCAT('mkdir -p \"books/', `Year`, '/',\n    case when Publisher = '' then 'no publisher' ELSE\n    replace(Publisher, '\"', ' ') end\n    , '/', REPLACE(left(Author, 100), '\"', ' '), '\"') --  u.\\* -- CONCAT()  \n    from updated u\n    inner join files f on f.md5 = u.MD5\n    INNER JOIN torrents t on t.Name = f.Name\n    WHERE Extension in ('pdf')\n    and `Year` in ('2023', '2022', '2021', '2020')\n    and `Language` in ('Spanish', 'English')\n    and Filesize &lt; 40000000\n\nSave the result in a TXT file, remove the first lines and the | characters to get a valid bash file. Execute it, this will create directories to store the books in books/YEAR/Publisher/Author/Title.pdf\n\nUse the same trick to create hard links with readable filenames :\n\n    select distinct CONCAT('ln  md5/', t.Name, '/', f.md5,\n        ' \"books/', `Year`, '/',\n        case when Publisher = '' then 'no publisher' ELSE\n        replace(Publisher, '\"', ' ') end, '/',\n        REPLACE(left(Author, 100), '\"', ' '), '/',\n        REPLACE(REPLACE(left(Title , 200), '\"', ' '), '/', ' '), '.',\n        Extension,  '\"')  \n    from updated u\n    inner join files f on f.md5 = u.MD5\n    INNER JOIN torrents t on t.Name = f.Name\n    WHERE Extension in ('pdf')\n    and `Year` in ('2023', '2022', '2021', '2020')\n    and `Language` in ('Spanish', 'English')\n    and Filesize &lt; 40000000\n\n&amp;#x200B;\n\n**Searching the books for content**\n\nAt this point, you should be able to search the author and titles of books with your linux file explorer of choice. To search your books by content, index them into recoll or docfetcher\n\n[https://www.lesbonscomptes.com/recoll/pages/index-recoll.html](https://www.lesbonscomptes.com/recoll/pages/index-recoll.html)\n\n[https://docfetcher.sourceforge.net/en/index.html](https://docfetcher.sourceforge.net/en/index.html)", "author_fullname": "t2_bshvx5lk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Download and search your own selection of books from libgen with linux", "link_flair_richtext": [], "subreddit_name_prefixed": "r/libgen", "hidden": false, "pwls": 7, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zsst9i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1671793732.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1671732867.0, "link_flair_type": "text", "wls": 7, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.libgen", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Here is a guide to :&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;download only a subset of books from libgen&lt;/li&gt;\n&lt;li&gt;rename the books in readable file names&lt;/li&gt;\n&lt;li&gt;search the books for content like zlibrary used to do&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;This guide requires basic knowledge of linux, bash, regular expressions, SQL and torrenting.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Downloading only a part of libgen&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;First, you need to install a mysql server, dbeaver and transmission-daemon on a linux machine&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-mysql-on-ubuntu-20-04\"&gt;https://www.digitalocean.com/community/tutorials/how-to-install-mysql-on-ubuntu-20-04&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://dbeaver.io/\"&gt;https://dbeaver.io/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://transmissionbt.com/\"&gt;https://transmissionbt.com/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;You will also need to download the libgen database (libgen_compact is enough) and all the torrents&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://libgen.rs/dbdumps/\"&gt;http://libgen.rs/dbdumps/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://libgen.rs/repository_torrent/\"&gt;http://libgen.rs/repository_torrent/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Once you have installed and setup the mysql server, create the libgen database and run the following command to import the data&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;mysql -u root -p libgen &amp;lt; libgen_compact.sql\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The default transmission web interface is located at&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://localhost:9091/transmission/web/\"&gt;http://localhost:9091/transmission/web/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Its settings are in /etc/transmission-daemon/settings.json&lt;/p&gt;\n\n&lt;p&gt;Configure transmission to not start torrents when added. Also set your download directory to the drive you would like to use for storage, &lt;em&gt;use an ext4 partition&lt;/em&gt;. Under the network settings, set an open port from your router or vpn. You will also want to set scrape-paused-torrents-enabled to false. cd into the directory where you downloaded the torrents and run&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;for i in *.torrent; do transmission-remote -a $i; done\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;to add all torrents without starting them&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;transmission-remote -l &amp;gt; torrents.csv #saves info about transmission\u2019 torrents ID\nfor i in $(seq 1 3533); do transmission-remote -t $i -if &amp;gt;&amp;gt; files.csv; done\ntransmission-remote -tall -Gall # unselect all books from downloading\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Convert the output of transmission-remote to csv format :&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;sed -i -re &amp;#39;s/^\\s+//g&amp;#39; torrents.csv\nsed -i -re &amp;#39;s/\\s{2,}/;/g&amp;#39; torrents.csv\n\nsed -i &amp;#39;0,/#/s//ID /&amp;#39; files.csv\nsed -i &amp;#39;/files/d&amp;#39; files.csv\nsed -i &amp;#39;/#/d&amp;#39; files.csv\nsed -i -re &amp;#39;s/^\\s+//g&amp;#39; files.csv\nsed -i -re &amp;#39;s/[:%]/ /g&amp;#39; files.csv\nsed -i -re &amp;#39;s/\\//;/g&amp;#39; files.csv\nsed -i -re &amp;#39;s/\\s{2,}/;/g&amp;#39; files.csv\nsed -i -re &amp;#39;s/nan/0/gi&amp;#39; files.csv\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Edit files.csv to replace the first line with :&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;ID;Done;Priority;Get;Size;Name;MD5\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Next, use dbeaver to import the csv files you just created into the libgen database (right click on the database &amp;gt; import data &amp;gt; csv) and name the tables \u201cfiles\u201d and \u201ctorrents\u201d&lt;/p&gt;\n\n&lt;p&gt;Create three indexes on these tables, either using the followin SQL queries or by using dbeavers gui. The fields that need indexes are Name and md5.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;CREATE INDEX files_md5_IDX USING BTREE ON libgen.files (md5);\nCREATE INDEX files_Name_IDX USING BTREE ON libgen.files (Name);\nCREATE INDEX torrents_Name_IDX USING BTREE ON libgen.torrents (Name);\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;In dbeaver and run the following query :&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;select sum(Filesize), count(*)\nfrom updated u\ninner join files f on f.md5 = u.MD5\nINNER JOIN torrents t on t.Name = f.Name\nWHERE Extension in (&amp;#39;pdf&amp;#39;)\nand `Year` in (&amp;#39;2023&amp;#39;, &amp;#39;2022&amp;#39;, &amp;#39;2021&amp;#39;, &amp;#39;2020&amp;#39;)\nand `Language` in (&amp;#39;Spanish&amp;#39;, &amp;#39;English&amp;#39;)\nand Filesize &amp;lt; 40000000\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;This query counts the size of the books you are going to download. Tune it until you find a selection of books that both interest you and fits in your hard drive. In the above case, the query selects ~700 Gb of english and Spanish books published in the years 2020-23 that are below 40MB.&lt;/p&gt;\n\n&lt;p&gt;Once you have found a where clause that satisfy your needs, use the following query to produce a list of transmission commands that will enable the download of the desired books :&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;select CONCAT(&amp;#39;transmission-remote -t&amp;#39;, t.ID, &amp;#39; -g&amp;#39;, f.ID)\nfrom updated u\ninner join files f on f.md5 = u.MD5\nINNER JOIN torrents t on t.Name = f.Name\nWHERE Extension in (&amp;#39;pdf&amp;#39;)\nand `Year` in (&amp;#39;2023&amp;#39;, &amp;#39;2022&amp;#39;, &amp;#39;2021&amp;#39;, &amp;#39;2020&amp;#39;)\nand `Language` in (&amp;#39;Spanish&amp;#39;, &amp;#39;English&amp;#39;)\nand Filesize &amp;lt; 40000000\nORDER by t.ID DESC, f.ID desc\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;dbeaver has an export data feature that you can use to save the results of this query to a text file. Once the export is done, open the text file and remove the | characters to obtain only the bash commands. Add set -x at the top of the file if you wish to follow the execution of these commands. In the above example ~70k files are selected for downloads and the execution takes a while.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Bash commands.txt # takes a while, use tmux if you need to disconnect\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Transmission is now ready to download the selection of books that you made. However there are ~ 3k torrents to download and transmission will have a difficult time handling the queue of torrents if you start them all at once. This is why I made the following nodejs script that will stop idle torrents and start 20 torrents at random :&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;const { exec } = require(&amp;#39;child_process&amp;#39;);\nexec(&amp;#39;transmission-remote -l&amp;#39;, (err, stdout, stderr) =&amp;gt; {\n    if (err) {\n        // node couldn&amp;#39;t execute the command\n        console.error(err)\n        return;\n    }\n\n    let lines = stdout.split(/\\n/)\n    let header = lines.shift().replace(/^\\s+/, &amp;#39;&amp;#39;).split(/\\s+/)\n    lines.pop()\n    lines.pop()\n\n    let torrents = []\n    for(let line of lines) {\n        line = line.replace(/^\\s+/, &amp;#39;&amp;#39;).split(/\\s{2,}/)\n        let obj = {}\n        for(let n = 0 ; n &amp;lt; line.length ; ++n) {\n        obj[header[n]] = line[n]\n        }\n        torrents.push(obj)\n    }\n\n    torrents = torrents.filter(t =&amp;gt; t.ID &amp;gt; 1000)\n\n    for(let t of torrents.filter(t =&amp;gt; (t.Status == &amp;#39;Idle&amp;#39; || t.Status == &amp;#39;Queued&amp;#39;))\n    {    \n        exec(`transmission-remote -t${t.ID} -S`)\n    }\n\n    let tornd = torrents.filter(t =&amp;gt; (t.Status == &amp;#39;Stopped&amp;#39; || t.Status == &amp;#39;Paused&amp;#39;)).sort(() =&amp;gt; Math.random() - 0.5)\n\n    for(let t = 0 ; t &amp;lt; 20 ; ++t) {\n        exec(`transmission-remote -t${tornd[t].ID} -s`)\n    }\n});\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Save it in queue.js and run node queue.js every 10 min or so with a crontab.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Renaming the books into readable filenames&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Here we create ext4 hard links for each book with readable filenames, assuming the torrents are downloaded in md5/ and the links go into books/&lt;/p&gt;\n\n&lt;p&gt;Same principle as earlier, run the following query with your own where clause :&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;select CONCAT(&amp;#39;mkdir -p &amp;quot;books/&amp;#39;, `Year`, &amp;#39;/&amp;#39;,\ncase when Publisher = &amp;#39;&amp;#39; then &amp;#39;no publisher&amp;#39; ELSE\nreplace(Publisher, &amp;#39;&amp;quot;&amp;#39;, &amp;#39; &amp;#39;) end\n, &amp;#39;/&amp;#39;, REPLACE(left(Author, 100), &amp;#39;&amp;quot;&amp;#39;, &amp;#39; &amp;#39;), &amp;#39;&amp;quot;&amp;#39;) --  u.\\* -- CONCAT()  \nfrom updated u\ninner join files f on f.md5 = u.MD5\nINNER JOIN torrents t on t.Name = f.Name\nWHERE Extension in (&amp;#39;pdf&amp;#39;)\nand `Year` in (&amp;#39;2023&amp;#39;, &amp;#39;2022&amp;#39;, &amp;#39;2021&amp;#39;, &amp;#39;2020&amp;#39;)\nand `Language` in (&amp;#39;Spanish&amp;#39;, &amp;#39;English&amp;#39;)\nand Filesize &amp;lt; 40000000\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Save the result in a TXT file, remove the first lines and the | characters to get a valid bash file. Execute it, this will create directories to store the books in books/YEAR/Publisher/Author/Title.pdf&lt;/p&gt;\n\n&lt;p&gt;Use the same trick to create hard links with readable filenames :&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;select distinct CONCAT(&amp;#39;ln  md5/&amp;#39;, t.Name, &amp;#39;/&amp;#39;, f.md5,\n    &amp;#39; &amp;quot;books/&amp;#39;, `Year`, &amp;#39;/&amp;#39;,\n    case when Publisher = &amp;#39;&amp;#39; then &amp;#39;no publisher&amp;#39; ELSE\n    replace(Publisher, &amp;#39;&amp;quot;&amp;#39;, &amp;#39; &amp;#39;) end, &amp;#39;/&amp;#39;,\n    REPLACE(left(Author, 100), &amp;#39;&amp;quot;&amp;#39;, &amp;#39; &amp;#39;), &amp;#39;/&amp;#39;,\n    REPLACE(REPLACE(left(Title , 200), &amp;#39;&amp;quot;&amp;#39;, &amp;#39; &amp;#39;), &amp;#39;/&amp;#39;, &amp;#39; &amp;#39;), &amp;#39;.&amp;#39;,\n    Extension,  &amp;#39;&amp;quot;&amp;#39;)  \nfrom updated u\ninner join files f on f.md5 = u.MD5\nINNER JOIN torrents t on t.Name = f.Name\nWHERE Extension in (&amp;#39;pdf&amp;#39;)\nand `Year` in (&amp;#39;2023&amp;#39;, &amp;#39;2022&amp;#39;, &amp;#39;2021&amp;#39;, &amp;#39;2020&amp;#39;)\nand `Language` in (&amp;#39;Spanish&amp;#39;, &amp;#39;English&amp;#39;)\nand Filesize &amp;lt; 40000000\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Searching the books for content&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;At this point, you should be able to search the author and titles of books with your linux file explorer of choice. To search your books by content, index them into recoll or docfetcher&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.lesbonscomptes.com/recoll/pages/index-recoll.html\"&gt;https://www.lesbonscomptes.com/recoll/pages/index-recoll.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://docfetcher.sourceforge.net/en/index.html\"&gt;https://docfetcher.sourceforge.net/en/index.html&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/UsqiQKE_5YkAEqLMx1beyWyipl85naYBEzT9LuUmNOc.jpg?auto=webp&amp;s=bfb2aa514cefbde75d81d86deb33251e320c8faa", "width": 1568, "height": 784}, "resolutions": [{"url": "https://external-preview.redd.it/UsqiQKE_5YkAEqLMx1beyWyipl85naYBEzT9LuUmNOc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ca189d234ffde1e67ee1426b0de35253537e5f29", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/UsqiQKE_5YkAEqLMx1beyWyipl85naYBEzT9LuUmNOc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0a634b3ce132accfa566afc70403db74ad98e2c1", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/UsqiQKE_5YkAEqLMx1beyWyipl85naYBEzT9LuUmNOc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5fea11b8307edd6c893f40cec0a0a6d3f0740c58", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/UsqiQKE_5YkAEqLMx1beyWyipl85naYBEzT9LuUmNOc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=aa6b54d349fd70c7c19b349c0fd1bd5a3c65a746", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/UsqiQKE_5YkAEqLMx1beyWyipl85naYBEzT9LuUmNOc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=349489e70497b4c2a5b07df1a44512344a95ff0b", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/UsqiQKE_5YkAEqLMx1beyWyipl85naYBEzT9LuUmNOc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e5be016a3eaf97700b200058d6a9646f80f3befa", "width": 1080, "height": 540}], "variants": {}, "id": "IsWuUhmV3hSS-NPet3uoG5GxCXKNtDuw1mFTW0ICBBo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_31p7i", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zsst9i", "is_robot_indexable": true, "report_reasons": null, "author": "TheoGrd", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "some_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/libgen/comments/zsst9i/download_and_search_your_own_selection_of_books/", "parent_whitelist_status": "some_ads", "stickied": false, "url": "https://old.reddit.com/r/libgen/comments/zsst9i/download_and_search_your_own_selection_of_books/", "subreddit_subscribers": 46639, "created_utc": 1671732867.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1671901013.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.libgen", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/libgen/comments/zsst9i/download_and_search_your_own_selection_of_books/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/UsqiQKE_5YkAEqLMx1beyWyipl85naYBEzT9LuUmNOc.jpg?auto=webp&amp;s=bfb2aa514cefbde75d81d86deb33251e320c8faa", "width": 1568, "height": 784}, "resolutions": [{"url": "https://external-preview.redd.it/UsqiQKE_5YkAEqLMx1beyWyipl85naYBEzT9LuUmNOc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ca189d234ffde1e67ee1426b0de35253537e5f29", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/UsqiQKE_5YkAEqLMx1beyWyipl85naYBEzT9LuUmNOc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0a634b3ce132accfa566afc70403db74ad98e2c1", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/UsqiQKE_5YkAEqLMx1beyWyipl85naYBEzT9LuUmNOc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5fea11b8307edd6c893f40cec0a0a6d3f0740c58", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/UsqiQKE_5YkAEqLMx1beyWyipl85naYBEzT9LuUmNOc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=aa6b54d349fd70c7c19b349c0fd1bd5a3c65a746", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/UsqiQKE_5YkAEqLMx1beyWyipl85naYBEzT9LuUmNOc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=349489e70497b4c2a5b07df1a44512344a95ff0b", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/UsqiQKE_5YkAEqLMx1beyWyipl85naYBEzT9LuUmNOc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e5be016a3eaf97700b200058d6a9646f80f3befa", "width": 1080, "height": 540}], "variants": {}, "id": "IsWuUhmV3hSS-NPet3uoG5GxCXKNtDuw1mFTW0ICBBo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zudr4x", "is_robot_indexable": true, "report_reasons": null, "author": "TheoGrd", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_zsst9i", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zudr4x/download_and_search_your_own_selection_of_books/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/libgen/comments/zsst9i/download_and_search_your_own_selection_of_books/", "subreddit_subscribers": 661888, "created_utc": 1671901013.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My GF went to best buy and bought 4 of these for one of her clients who halted the project for their office refresh.  They let her keep the external drives and asked if I wanted them.  I've shucked a drive before to use in a Linux PC, any reason why these won't work in a ds920+?\n\nThey cannot be returned as they were purchased by her client and setup for her to pickup.\n\nWanted to know if anything to look out for before I tear them apart.  Otherwise if there's problems I'll have her sell them or just use them as externals with a UnionFS", "author_fullname": "t2_sxco8at7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WD Easystore 18tb x 4", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zubr9u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671894853.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My GF went to best buy and bought 4 of these for one of her clients who halted the project for their office refresh.  They let her keep the external drives and asked if I wanted them.  I&amp;#39;ve shucked a drive before to use in a Linux PC, any reason why these won&amp;#39;t work in a ds920+?&lt;/p&gt;\n\n&lt;p&gt;They cannot be returned as they were purchased by her client and setup for her to pickup.&lt;/p&gt;\n\n&lt;p&gt;Wanted to know if anything to look out for before I tear them apart.  Otherwise if there&amp;#39;s problems I&amp;#39;ll have her sell them or just use them as externals with a UnionFS&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zubr9u", "is_robot_indexable": true, "report_reasons": null, "author": "blitzblitzblutz", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zubr9u/wd_easystore_18tb_x_4/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zubr9u/wd_easystore_18tb_x_4/", "subreddit_subscribers": 661888, "created_utc": 1671894853.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "[https://www.reddit.com/r/DataHoarder/comments/a6ah2q/so\\_we\\_spent\\_175\\_usd\\_to\\_purchase\\_a\\_5tb\\_drive/](https://www.reddit.com/r/DataHoarder/comments/a6ah2q/so_we_spent_175_usd_to_purchase_a_5tb_drive/)\n\nIt's been four years since I made this post, where I acquired a drive holding a 2014 dump of [animemusicvdieos.org](https://animemusicvdieos.org) including an export of it's database.  I'm gonna be honest here... It's collected dust since.  I've made a few attempts to upload it to [Archive.org](https://Archive.org) via FTP but I just get errors.  Tried different PCs and FTP clients, I start getting hung transfers and it all goes to hell.  This is a huge amount of data so it's not like I can just toss it on Gdrive.\n\nSo I'm looking for other people who can help.  People I can send this data too and hopefully they can  upload to [archive.org](https://archive.org) and share by other means if they want.  This drive won't function forever, I really need to get around to duplicating it's contents and propagating it across the internet and into other individual's collections.\n\nIdeas?", "author_fullname": "t2_76pgn19", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Datahoaders, I need help preserving about 5TB of Anime Music Videos and a database", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zulp5s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671924991.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/a6ah2q/so_we_spent_175_usd_to_purchase_a_5tb_drive/\"&gt;https://www.reddit.com/r/DataHoarder/comments/a6ah2q/so_we_spent_175_usd_to_purchase_a_5tb_drive/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s been four years since I made this post, where I acquired a drive holding a 2014 dump of &lt;a href=\"https://animemusicvdieos.org\"&gt;animemusicvdieos.org&lt;/a&gt; including an export of it&amp;#39;s database.  I&amp;#39;m gonna be honest here... It&amp;#39;s collected dust since.  I&amp;#39;ve made a few attempts to upload it to &lt;a href=\"https://Archive.org\"&gt;Archive.org&lt;/a&gt; via FTP but I just get errors.  Tried different PCs and FTP clients, I start getting hung transfers and it all goes to hell.  This is a huge amount of data so it&amp;#39;s not like I can just toss it on Gdrive.&lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;m looking for other people who can help.  People I can send this data too and hopefully they can  upload to &lt;a href=\"https://archive.org\"&gt;archive.org&lt;/a&gt; and share by other means if they want.  This drive won&amp;#39;t function forever, I really need to get around to duplicating it&amp;#39;s contents and propagating it across the internet and into other individual&amp;#39;s collections.&lt;/p&gt;\n\n&lt;p&gt;Ideas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zulp5s", "is_robot_indexable": true, "report_reasons": null, "author": "AshleyUncia", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zulp5s/datahoaders_i_need_help_preserving_about_5tb_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zulp5s/datahoaders_i_need_help_preserving_about_5tb_of/", "subreddit_subscribers": 661888, "created_utc": 1671924991.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have some animated series on dvds and I want to split them into episodes but I want the episodes to be have zero quality loss to be the exact same 1 to 1 copy of the DVD . How I can do that? Thank you.", "author_fullname": "t2_v0pt8cbe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I split a DVD tv show in separate episodes with ZERO quality loss?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zu6ph7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671875494.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have some animated series on dvds and I want to split them into episodes but I want the episodes to be have zero quality loss to be the exact same 1 to 1 copy of the DVD . How I can do that? Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zu6ph7", "is_robot_indexable": true, "report_reasons": null, "author": "Hot_Location_5198", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zu6ph7/how_do_i_split_a_dvd_tv_show_in_separate_episodes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zu6ph7/how_do_i_split_a_dvd_tv_show_in_separate_episodes/", "subreddit_subscribers": 661888, "created_utc": 1671875494.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Got some drives off Amazon for a sale price similar to what was on Samsung. Samsungs authenticity checker says they're real. Is that really all I need to do?", "author_fullname": "t2_t8ajrtjc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Samsung's drive authenticity checker trustworthy enough for no other investigation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ztz1oh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671847656.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Got some drives off Amazon for a sale price similar to what was on Samsung. Samsungs authenticity checker says they&amp;#39;re real. Is that really all I need to do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ztz1oh", "is_robot_indexable": true, "report_reasons": null, "author": "5personfami1ydinner", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ztz1oh/is_samsungs_drive_authenticity_checker/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ztz1oh/is_samsungs_drive_authenticity_checker/", "subreddit_subscribers": 661888, "created_utc": 1671847656.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Most of the posts here are about hoarding many terabytes for a year or so, but I want to ask about a much smaller amount of data.  Does anyone know much about IPFS (Inter Planetary File System)  and how well it can survive over time?  Mostly I'm questioning theoretical, not as much on the practical side, because in reality there are a million variables.  \n\nI'm thinking, if I have a small amount of data, less than a few MB, not enough to really cost anyone in resources, how long will / can it last on the IPFS network?  Let's say I pin something in one service like Pinata, is it likely that Cloudflare will keep a copy of it 10 years from now?  Is there any way to make that more likely to be retained, i.e. would Cloudflare need to agree to hold my pins even if the source disappears (probably in exchange for money, but what if I forget for a year)?  Or if Pinata goes out of business in, say, 10 years, do I lose the chance of recovering my file?", "author_fullname": "t2_3ptve9wc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "IPFS = 10-20 year long term cloud storage (\"forever\")?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zuo7s6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671933727.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Most of the posts here are about hoarding many terabytes for a year or so, but I want to ask about a much smaller amount of data.  Does anyone know much about IPFS (Inter Planetary File System)  and how well it can survive over time?  Mostly I&amp;#39;m questioning theoretical, not as much on the practical side, because in reality there are a million variables.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking, if I have a small amount of data, less than a few MB, not enough to really cost anyone in resources, how long will / can it last on the IPFS network?  Let&amp;#39;s say I pin something in one service like Pinata, is it likely that Cloudflare will keep a copy of it 10 years from now?  Is there any way to make that more likely to be retained, i.e. would Cloudflare need to agree to hold my pins even if the source disappears (probably in exchange for money, but what if I forget for a year)?  Or if Pinata goes out of business in, say, 10 years, do I lose the chance of recovering my file?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zuo7s6", "is_robot_indexable": true, "report_reasons": null, "author": "sqljuju", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zuo7s6/ipfs_1020_year_long_term_cloud_storage_forever/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zuo7s6/ipfs_1020_year_long_term_cloud_storage_forever/", "subreddit_subscribers": 661888, "created_utc": 1671933727.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I have a question, I want to have my operating system in one drive, and all the data thar is saved from files that are downloading and, basic apps to be stored in other hard drive, because the default path for downloaded apps, are in the Disc with the operating system, and apps that are getting installed are going to the drive with the operating system, please no hate just a noob how tries to organize his stuff", "author_fullname": "t2_k3t2id", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "noob here", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zuo3g2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671933298.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have a question, I want to have my operating system in one drive, and all the data thar is saved from files that are downloading and, basic apps to be stored in other hard drive, because the default path for downloaded apps, are in the Disc with the operating system, and apps that are getting installed are going to the drive with the operating system, please no hate just a noob how tries to organize his stuff&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zuo3g2", "is_robot_indexable": true, "report_reasons": null, "author": "daddyhitler420", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zuo3g2/noob_here/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zuo3g2/noob_here/", "subreddit_subscribers": 661888, "created_utc": 1671933298.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So, i like to backup files very often from my computer or hard drive to google drive. It would be an absolute pain to go in to every folder and search to see which files have not been uploaded, and upload those files every time. \n\nI like to just go to google drive and drag all the files into a folder and let them upload. Problem is, there are many. When I do this, google never asks me if I want to replace the files or whatever. It always just reuploads the files that already exist and adds a number to the end of the name.\n\nIs there any way to stop this so that it does not upload file with the same name?", "author_fullname": "t2_y7xmw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any way to not upload duplicates on Google Drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zuk6kz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671920203.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, i like to backup files very often from my computer or hard drive to google drive. It would be an absolute pain to go in to every folder and search to see which files have not been uploaded, and upload those files every time. &lt;/p&gt;\n\n&lt;p&gt;I like to just go to google drive and drag all the files into a folder and let them upload. Problem is, there are many. When I do this, google never asks me if I want to replace the files or whatever. It always just reuploads the files that already exist and adds a number to the end of the name.&lt;/p&gt;\n\n&lt;p&gt;Is there any way to stop this so that it does not upload file with the same name?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zuk6kz", "is_robot_indexable": true, "report_reasons": null, "author": "AllAboutGadgets", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zuk6kz/any_way_to_not_upload_duplicates_on_google_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zuk6kz/any_way_to_not_upload_duplicates_on_google_drive/", "subreddit_subscribers": 661888, "created_utc": 1671920203.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have an 8tb hard drive that I got 5 years ago, but I recently heard hard drives only last 3-5 years and Google seemed to confirm it so I'm panicking on what to do. Do they really just fail over time or maybe that's just for smaller hard drives? I'm not too techy when it comes to computer parts so I don't really know these things. It's made by seagate and it's one that needs to be plugged into the wall. \nI'm pretty sure it's this one: Seagate Backup Plus Hub 8TB Desktop Hard Drive with Rescue Data Recovery Services https://a.co/d/9YmSkMP", "author_fullname": "t2_1ro5pgjh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can someone help this noob?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zuc8fo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671896335.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an 8tb hard drive that I got 5 years ago, but I recently heard hard drives only last 3-5 years and Google seemed to confirm it so I&amp;#39;m panicking on what to do. Do they really just fail over time or maybe that&amp;#39;s just for smaller hard drives? I&amp;#39;m not too techy when it comes to computer parts so I don&amp;#39;t really know these things. It&amp;#39;s made by seagate and it&amp;#39;s one that needs to be plugged into the wall. \nI&amp;#39;m pretty sure it&amp;#39;s this one: Seagate Backup Plus Hub 8TB Desktop Hard Drive with Rescue Data Recovery Services &lt;a href=\"https://a.co/d/9YmSkMP\"&gt;https://a.co/d/9YmSkMP&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zuc8fo", "is_robot_indexable": true, "report_reasons": null, "author": "oharacopter", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zuc8fo/can_someone_help_this_noob/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zuc8fo/can_someone_help_this_noob/", "subreddit_subscribers": 661888, "created_utc": 1671896335.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So, I'm using Google Workspace Enterprise Standard now for storage, \\~30TB but I will have to soon close my VAT ID and I understand it is required now. Can I make an account for it without one? Or is there anything similar I could use for a similar price point?\n\nIs the only solution in my future just a bunch (more) drives for local storage?", "author_fullname": "t2_6bst9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google Enterprise without VAT ID?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zuc0z9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671895686.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, I&amp;#39;m using Google Workspace Enterprise Standard now for storage, ~30TB but I will have to soon close my VAT ID and I understand it is required now. Can I make an account for it without one? Or is there anything similar I could use for a similar price point?&lt;/p&gt;\n\n&lt;p&gt;Is the only solution in my future just a bunch (more) drives for local storage?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "14TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zuc0z9", "is_robot_indexable": true, "report_reasons": null, "author": "TehBard", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/zuc0z9/google_enterprise_without_vat_id/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zuc0z9/google_enterprise_without_vat_id/", "subreddit_subscribers": 661888, "created_utc": 1671895686.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have an external HDD 3.0. When I copy files from the HDD to the PC (NVMe) the speed is 38MB/s. Is it normal? \n\nAnd if I copy from PC to HDD, the speed is 130MB/s but after 2 seconds drop down to 34MB/s.\n\nI searched the internet but nothing seems to improve speed.", "author_fullname": "t2_hfaqbh8d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why is my external HDD so slow?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zum7je", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671926654.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an external HDD 3.0. When I copy files from the HDD to the PC (NVMe) the speed is 38MB/s. Is it normal? &lt;/p&gt;\n\n&lt;p&gt;And if I copy from PC to HDD, the speed is 130MB/s but after 2 seconds drop down to 34MB/s.&lt;/p&gt;\n\n&lt;p&gt;I searched the internet but nothing seems to improve speed.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zum7je", "is_robot_indexable": true, "report_reasons": null, "author": "ALE2000XVX", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zum7je/why_is_my_external_hdd_so_slow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zum7je/why_is_my_external_hdd_so_slow/", "subreddit_subscribers": 661888, "created_utc": 1671926654.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I found a bunch of .amr files in one of my archives of past voice mails. After doing some copying and replacing I learned they are a lossy file type. I couldn't find any documentation on .amr files specifically, but I assume they suffer generation loss the same way .mp3s do.\n\nI know that you can't increase quality by converting a lossy file to a lossless file, but can you prevent it from losing any more quality? These are sentimental files and I'm wondering if they'd be better preserved as .flacs", "author_fullname": "t2_efwdl4fz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does converting lossy audio to .flac stop generation loss, and quality degradation over time?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zum47k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671926381.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I found a bunch of .amr files in one of my archives of past voice mails. After doing some copying and replacing I learned they are a lossy file type. I couldn&amp;#39;t find any documentation on .amr files specifically, but I assume they suffer generation loss the same way .mp3s do.&lt;/p&gt;\n\n&lt;p&gt;I know that you can&amp;#39;t increase quality by converting a lossy file to a lossless file, but can you prevent it from losing any more quality? These are sentimental files and I&amp;#39;m wondering if they&amp;#39;d be better preserved as .flacs&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zum47k", "is_robot_indexable": true, "report_reasons": null, "author": "fishswimminginatank", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zum47k/does_converting_lossy_audio_to_flac_stop/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zum47k/does_converting_lossy_audio_to_flac_stop/", "subreddit_subscribers": 661888, "created_utc": 1671926381.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_6aijoaio", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How a coverless drives looks in operation (surrounded by +180TB drives)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_zukb60", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/zV8pqbNB9Vk?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"How a running hard drive looks without a cover\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "How a running hard drive looks without a cover", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/zV8pqbNB9Vk?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"How a running hard drive looks without a cover\"&gt;&lt;/iframe&gt;", "author_name": "MJ1Productions", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/zV8pqbNB9Vk/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@mj1productions961"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/zV8pqbNB9Vk?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"How a running hard drive looks without a cover\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/zukb60", "height": 200}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/zvAXJ1tV_0CyQ1uKjc2WujXl-5UqiNMs7EQ2NC-E57A.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671920601.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=zV8pqbNB9Vk", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4-AnQuoO7qlpSyCMx7GRdx_Jbp5J4xn-7U_WhOv5e_4.jpg?auto=webp&amp;s=986731e30b99255e7fb3c0c115752787bd5fa782", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/4-AnQuoO7qlpSyCMx7GRdx_Jbp5J4xn-7U_WhOv5e_4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cb83fc77c1a6b0abab1a57fd1eea5db6a6b4a06e", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/4-AnQuoO7qlpSyCMx7GRdx_Jbp5J4xn-7U_WhOv5e_4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9ff2c963883c979313389fb017e2a5e243d57cf3", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/4-AnQuoO7qlpSyCMx7GRdx_Jbp5J4xn-7U_WhOv5e_4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5afb21864f0445534090bccf70959ddaadc046e5", "width": 320, "height": 240}], "variants": {}, "id": "OYhcdRXzlM1GAcKPJeaARcCNgKSwa6frrhkHCoOdSH8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "150TB", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zukb60", "is_robot_indexable": true, "report_reasons": null, "author": "1DonBot", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/zukb60/how_a_coverless_drives_looks_in_operation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=zV8pqbNB9Vk", "subreddit_subscribers": 661888, "created_utc": 1671920601.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "How a running hard drive looks without a cover", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/zV8pqbNB9Vk?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"How a running hard drive looks without a cover\"&gt;&lt;/iframe&gt;", "author_name": "MJ1Productions", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/zV8pqbNB9Vk/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@mj1productions961"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "While attempting to back up a bunch of twitter accounts, I noticed that for some reason the Rate-Limit Reset error that it gives after ripping a bunch of programs effectively freezes it forever. If I wait out the 15 minutes, it'll give the exact same error again. I haven't seen it get past a rate limit reset. Anyone know how to either slow it down enough that it doesn't trigger the rate limit reset, or how to make it keep ripping after the reset is over?", "author_fullname": "t2_dagzzx2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Gallery-DL Tweet Rate-Limiter Breaking Program", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zueequ", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671902918.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;While attempting to back up a bunch of twitter accounts, I noticed that for some reason the Rate-Limit Reset error that it gives after ripping a bunch of programs effectively freezes it forever. If I wait out the 15 minutes, it&amp;#39;ll give the exact same error again. I haven&amp;#39;t seen it get past a rate limit reset. Anyone know how to either slow it down enough that it doesn&amp;#39;t trigger the rate limit reset, or how to make it keep ripping after the reset is over?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zueequ", "is_robot_indexable": true, "report_reasons": null, "author": "SomeHusky", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zueequ/gallerydl_tweet_ratelimiter_breaking_program/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zueequ/gallerydl_tweet_ratelimiter_breaking_program/", "subreddit_subscribers": 661888, "created_utc": 1671902918.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone, I have a lot of HDD used as backup of my videos and photos. I don't use them to work, just as an archive.\n\nI am looking for a solution that would guarantee me a lot of space so I don't have to keep that many HDDs around. \n\nAnother question is: is there a way to upload my file to said solution? Because I move around a lot and the archive will be at home.\n\n&amp;#x200B;\n\nAny suggestion? Thank y'all.", "author_fullname": "t2_rsfs7kw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the best way to backup a lot of multimedia files?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zu9m35", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671887694.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I have a lot of HDD used as backup of my videos and photos. I don&amp;#39;t use them to work, just as an archive.&lt;/p&gt;\n\n&lt;p&gt;I am looking for a solution that would guarantee me a lot of space so I don&amp;#39;t have to keep that many HDDs around. &lt;/p&gt;\n\n&lt;p&gt;Another question is: is there a way to upload my file to said solution? Because I move around a lot and the archive will be at home.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any suggestion? Thank y&amp;#39;all.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zu9m35", "is_robot_indexable": true, "report_reasons": null, "author": "Automatic_Peace", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zu9m35/what_is_the_best_way_to_backup_a_lot_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zu9m35/what_is_the_best_way_to_backup_a_lot_of/", "subreddit_subscribers": 661888, "created_utc": 1671887694.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "does enyone have an ftp account on betaarchive and could download one file for me? The file I'm  looking for is medal of honor allied assault beta.", "author_fullname": "t2_bp7y1tvl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "betaarchive download", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zu6ycb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671876559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;does enyone have an ftp account on betaarchive and could download one file for me? The file I&amp;#39;m  looking for is medal of honor allied assault beta.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zu6ycb", "is_robot_indexable": true, "report_reasons": null, "author": "ConclusionPrimary748", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zu6ycb/betaarchive_download/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zu6ycb/betaarchive_download/", "subreddit_subscribers": 661888, "created_utc": 1671876559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My Mac battery died, and the Mac is fried. I now have all my data on this SSD. What device will allow me to retrieve this data and transfer it to another Hard Disk Drive/The Cloud?\n\nThe guy at Apple said a \"caddy\", is that it?\n\nAny link to a device on Amazon would be highly appreciated.\n\nhttps://preview.redd.it/vbfrrnkqos7a1.jpg?width=2287&amp;format=pjpg&amp;auto=webp&amp;s=7b55e6996d0f90648e78d45c868bcacb787c9098\n\nhttps://preview.redd.it/gmc89tpsos7a1.jpg?width=612&amp;format=pjpg&amp;auto=webp&amp;s=33b504864a2060194a999d53b4eeb5de8089dffb", "author_fullname": "t2_2qelqk3u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Accessing data on internal/physisal SSD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 40, "top_awarded_type": null, "hide_score": false, "media_metadata": {"gmc89tpsos7a1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 216, "x": 108, "u": "https://preview.redd.it/gmc89tpsos7a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9e3ae4f23ed30cc62dfe7a537e2c557e392eb7b6"}, {"y": 432, "x": 216, "u": "https://preview.redd.it/gmc89tpsos7a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0b7fc011a089cf2b65066649ed291e5cf8ca9ad7"}, {"y": 640, "x": 320, "u": "https://preview.redd.it/gmc89tpsos7a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9912f9a85ada638b904b19a2a971a206d579d265"}], "s": {"y": 2113, "x": 612, "u": "https://preview.redd.it/gmc89tpsos7a1.jpg?width=612&amp;format=pjpg&amp;auto=webp&amp;s=33b504864a2060194a999d53b4eeb5de8089dffb"}, "id": "gmc89tpsos7a1"}, "vbfrrnkqos7a1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 31, "x": 108, "u": "https://preview.redd.it/vbfrrnkqos7a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b13de2d5e01d254017ac420b15593a8660cec54f"}, {"y": 62, "x": 216, "u": "https://preview.redd.it/vbfrrnkqos7a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bac3abab0f4821ce0b41ca7f413a78ba4f90240d"}, {"y": 93, "x": 320, "u": "https://preview.redd.it/vbfrrnkqos7a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=148d499b191c94cf10f6b72500f6adb5c6b8b83b"}, {"y": 186, "x": 640, "u": "https://preview.redd.it/vbfrrnkqos7a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=81b819047e64e77fe4c39a0a979321e4d19fc36a"}, {"y": 279, "x": 960, "u": "https://preview.redd.it/vbfrrnkqos7a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e0bf190907adc28c9e8b98d16729d89eabed3af3"}, {"y": 314, "x": 1080, "u": "https://preview.redd.it/vbfrrnkqos7a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4770fa2cae820584f8ffd1a27c1501ab531fba7b"}], "s": {"y": 667, "x": 2287, "u": "https://preview.redd.it/vbfrrnkqos7a1.jpg?width=2287&amp;format=pjpg&amp;auto=webp&amp;s=7b55e6996d0f90648e78d45c868bcacb787c9098"}, "id": "vbfrrnkqos7a1"}}, "name": "t3_zu49sx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/84SRYjh5ckzDYCzNZ4CyT53fJYr58PzuUQJtDzWuXeo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671865520.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My Mac battery died, and the Mac is fried. I now have all my data on this SSD. What device will allow me to retrieve this data and transfer it to another Hard Disk Drive/The Cloud?&lt;/p&gt;\n\n&lt;p&gt;The guy at Apple said a &amp;quot;caddy&amp;quot;, is that it?&lt;/p&gt;\n\n&lt;p&gt;Any link to a device on Amazon would be highly appreciated.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/vbfrrnkqos7a1.jpg?width=2287&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=7b55e6996d0f90648e78d45c868bcacb787c9098\"&gt;https://preview.redd.it/vbfrrnkqos7a1.jpg?width=2287&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=7b55e6996d0f90648e78d45c868bcacb787c9098&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/gmc89tpsos7a1.jpg?width=612&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=33b504864a2060194a999d53b4eeb5de8089dffb\"&gt;https://preview.redd.it/gmc89tpsos7a1.jpg?width=612&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=33b504864a2060194a999d53b4eeb5de8089dffb&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zu49sx", "is_robot_indexable": true, "report_reasons": null, "author": "Wifi-guy101", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zu49sx/accessing_data_on_internalphysisal_ssd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zu49sx/accessing_data_on_internalphysisal_ssd/", "subreddit_subscribers": 661888, "created_utc": 1671865520.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}