{"kind": "Listing", "data": {"after": "t3_zibwgv", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Pretty sure Memorex isn't a recommended brand anyway, but I figured it can't hurt to put it out there in case someone just didn't know.\n\nI received a stack of 19 Memorex DVDs from a relative to put them on a flash drive for Christmas. I've gone through 13 so far and 6 have come back with issues.\n\nIn MakeMKV, all but one disc reported:\n\nError 'Scsi error - MEDIUM ERROR:L-EC UNCORRECTABLE ERROR' occurred while reading\n\nThe other disc had a different error I don't remember and haven't seen since. Some others were completely unreadable. Some discs were accessible through other means, but any video I could retrieve are severely corrupted so I'll have to copy a bunch of tapes as well to fill in the gaps.\n\nNo discs had any visible damage. No bit rot no scratches. They've been untouched since 2005.\n\nI'm not asking for any advice, just recording my experience with these discs for others to reference and maybe kick their butt into gear to update their storage situation.", "author_fullname": "t2_2yo9if6c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PSA to anyone who used Memorex DVD-R from 2005", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ziwl8o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 243, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 243, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670772843.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Pretty sure Memorex isn&amp;#39;t a recommended brand anyway, but I figured it can&amp;#39;t hurt to put it out there in case someone just didn&amp;#39;t know.&lt;/p&gt;\n\n&lt;p&gt;I received a stack of 19 Memorex DVDs from a relative to put them on a flash drive for Christmas. I&amp;#39;ve gone through 13 so far and 6 have come back with issues.&lt;/p&gt;\n\n&lt;p&gt;In MakeMKV, all but one disc reported:&lt;/p&gt;\n\n&lt;p&gt;Error &amp;#39;Scsi error - MEDIUM ERROR:L-EC UNCORRECTABLE ERROR&amp;#39; occurred while reading&lt;/p&gt;\n\n&lt;p&gt;The other disc had a different error I don&amp;#39;t remember and haven&amp;#39;t seen since. Some others were completely unreadable. Some discs were accessible through other means, but any video I could retrieve are severely corrupted so I&amp;#39;ll have to copy a bunch of tapes as well to fill in the gaps.&lt;/p&gt;\n\n&lt;p&gt;No discs had any visible damage. No bit rot no scratches. They&amp;#39;ve been untouched since 2005.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not asking for any advice, just recording my experience with these discs for others to reference and maybe kick their butt into gear to update their storage situation.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "ziwl8o", "is_robot_indexable": true, "report_reasons": null, "author": "DeckardTBechard", "discussion_type": null, "num_comments": 46, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ziwl8o/psa_to_anyone_who_used_memorex_dvdr_from_2005/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ziwl8o/psa_to_anyone_who_used_memorex_dvdr_from_2005/", "subreddit_subscribers": 658850, "created_utc": 1670772843.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Archive Of A Vanishing World | Albert Kahn sought to preserve a world he perceived to be disappearing. A century later, his \u201cArchives de la Plan\u00e8te\u201d connects disparate lands, dying ecosystems and cultures, and a world being utterly transformed by modernity.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 103, "top_awarded_type": null, "hide_score": false, "name": "t3_zidk9g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 122, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_5uj3gfdz", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 122, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/nSE5wMFlwq-7M5dE2PIflnKhdTgYZyxlieSriZfzgGw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "longform", "selftext": "", "author_fullname": "t2_i9130lnw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Archive Of A Vanishing World | Albert Kahn sought to preserve a world he perceived to be disappearing. A century later, his \u201cArchives de la Plan\u00e8te\u201d connects disparate lands, dying ecosystems and cultures, and a world being utterly transformed by modernity.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/longform", "hidden": false, "pwls": 0, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 103, "top_awarded_type": null, "hide_score": false, "name": "t3_wxql4s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/nSE5wMFlwq-7M5dE2PIflnKhdTgYZyxlieSriZfzgGw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "created": 1661464174.0, "link_flair_type": "text", "wls": 0, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "noemamag.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.noemamag.com/the-archive-of-a-vanishing-world/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/gF4WTeMZ7ALPTPO7wx5qjEhXeal0gnR6iY1yjUOAdNI.jpg?auto=webp&amp;s=5fa23c5797ce0f314ebe80f50453d29c7068e614", "width": 2000, "height": 1483}, "resolutions": [{"url": "https://external-preview.redd.it/gF4WTeMZ7ALPTPO7wx5qjEhXeal0gnR6iY1yjUOAdNI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=62fe2cec7ca18e760a4304daae0b2fd627f10479", "width": 108, "height": 80}, {"url": "https://external-preview.redd.it/gF4WTeMZ7ALPTPO7wx5qjEhXeal0gnR6iY1yjUOAdNI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d59b271df4a7de9cf47f0c3a59b965c8841a4395", "width": 216, "height": 160}, {"url": "https://external-preview.redd.it/gF4WTeMZ7ALPTPO7wx5qjEhXeal0gnR6iY1yjUOAdNI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6075aabef09ce217ab4965df5b79518760d514df", "width": 320, "height": 237}, {"url": "https://external-preview.redd.it/gF4WTeMZ7ALPTPO7wx5qjEhXeal0gnR6iY1yjUOAdNI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a11ff3f53ee8d023569ca28740167293dfe62f00", "width": 640, "height": 474}, {"url": "https://external-preview.redd.it/gF4WTeMZ7ALPTPO7wx5qjEhXeal0gnR6iY1yjUOAdNI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=06bd9dc51c2bd23121495cc139ea6bf49ea2da91", "width": 960, "height": 711}, {"url": "https://external-preview.redd.it/gF4WTeMZ7ALPTPO7wx5qjEhXeal0gnR6iY1yjUOAdNI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5efa1d055e76dc8e7070beab7dfd637417709f4e", "width": 1080, "height": 800}], "variants": {}, "id": "dmqVbCAW_PWPbL0j8VThH7pHcUksTJF8O_JiUPO74gU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qht5", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "wxql4s", "is_robot_indexable": true, "report_reasons": null, "author": "bethany_mcguire", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "no_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/longform/comments/wxql4s/the_archive_of_a_vanishing_world_albert_kahn/", "parent_whitelist_status": "no_ads", "stickied": false, "url": "https://www.noemamag.com/the-archive-of-a-vanishing-world/", "subreddit_subscribers": 12001, "created_utc": 1661464174.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1670730066.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "noemamag.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.noemamag.com/the-archive-of-a-vanishing-world/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/gF4WTeMZ7ALPTPO7wx5qjEhXeal0gnR6iY1yjUOAdNI.jpg?auto=webp&amp;s=5fa23c5797ce0f314ebe80f50453d29c7068e614", "width": 2000, "height": 1483}, "resolutions": [{"url": "https://external-preview.redd.it/gF4WTeMZ7ALPTPO7wx5qjEhXeal0gnR6iY1yjUOAdNI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=62fe2cec7ca18e760a4304daae0b2fd627f10479", "width": 108, "height": 80}, {"url": "https://external-preview.redd.it/gF4WTeMZ7ALPTPO7wx5qjEhXeal0gnR6iY1yjUOAdNI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d59b271df4a7de9cf47f0c3a59b965c8841a4395", "width": 216, "height": 160}, {"url": "https://external-preview.redd.it/gF4WTeMZ7ALPTPO7wx5qjEhXeal0gnR6iY1yjUOAdNI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6075aabef09ce217ab4965df5b79518760d514df", "width": 320, "height": 237}, {"url": "https://external-preview.redd.it/gF4WTeMZ7ALPTPO7wx5qjEhXeal0gnR6iY1yjUOAdNI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a11ff3f53ee8d023569ca28740167293dfe62f00", "width": 640, "height": 474}, {"url": "https://external-preview.redd.it/gF4WTeMZ7ALPTPO7wx5qjEhXeal0gnR6iY1yjUOAdNI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=06bd9dc51c2bd23121495cc139ea6bf49ea2da91", "width": 960, "height": 711}, {"url": "https://external-preview.redd.it/gF4WTeMZ7ALPTPO7wx5qjEhXeal0gnR6iY1yjUOAdNI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5efa1d055e76dc8e7070beab7dfd637417709f4e", "width": 1080, "height": 800}], "variants": {}, "id": "dmqVbCAW_PWPbL0j8VThH7pHcUksTJF8O_JiUPO74gU"}], "enabled": false}, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 250, "id": "award_a67d649d-5aa5-407e-a98b-32fd9e3a9696", "penny_donate": null, "award_sub_type": "APPRECIATION", "coin_reward": 100, "icon_url": "https://i.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=16&amp;height=16&amp;auto=webp&amp;s=bbfa251092cce139b37d74237ec28a8c4e8f06b0", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=32&amp;height=32&amp;auto=webp&amp;s=e1f9dd28741e2551b1fbbd341b006cc316f48fa1", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=48&amp;height=48&amp;auto=webp&amp;s=d93434d26563a534397ff748cce71d4b733c32d9", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=64&amp;height=64&amp;auto=webp&amp;s=cf4a1ddb8474d11682f0d88aa32562f9fcbf30b0", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=128&amp;height=128&amp;auto=webp&amp;s=70b1596cdd0ae75b52db5c2732d8c336d300cc11", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "The more you know... Gives %{coin_symbol}100 Coins to both the author and the community.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 100, "count": 1, "static_icon_height": 2048, "name": "Today I Learned", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=16&amp;height=16&amp;auto=webp&amp;s=bbfa251092cce139b37d74237ec28a8c4e8f06b0", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=32&amp;height=32&amp;auto=webp&amp;s=e1f9dd28741e2551b1fbbd341b006cc316f48fa1", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=48&amp;height=48&amp;auto=webp&amp;s=d93434d26563a534397ff748cce71d4b733c32d9", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=64&amp;height=64&amp;auto=webp&amp;s=cf4a1ddb8474d11682f0d88aa32562f9fcbf30b0", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=128&amp;height=128&amp;auto=webp&amp;s=70b1596cdd0ae75b52db5c2732d8c336d300cc11", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "zidk9g", "is_robot_indexable": true, "report_reasons": null, "author": "kraft-skunk", "discussion_type": null, "num_comments": 3, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_wxql4s", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zidk9g/the_archive_of_a_vanishing_world_albert_kahn/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.noemamag.com/the-archive-of-a-vanishing-world/", "subreddit_subscribers": 658850, "created_utc": 1670730066.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_h6kxy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How 45 Drives Open Source Houston Command Center Makes ZFS On Linux Easy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_ziognu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 55, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/07uTKOB1z7E?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"How 45 Drives Open Source Houston Command Center Makes ZFS On Linux Easy\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "How 45 Drives Open Source Houston Command Center Makes ZFS On Linux Easy", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/07uTKOB1z7E?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"How 45 Drives Open Source Houston Command Center Makes ZFS On Linux Easy\"&gt;&lt;/iframe&gt;", "author_name": "Lawrence Systems", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/07uTKOB1z7E/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@LAWRENCESYSTEMS"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/07uTKOB1z7E?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"How 45 Drives Open Source Houston Command Center Makes ZFS On Linux Easy\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/ziognu", "height": 200}, "link_flair_text": "Video", "can_mod_post": false, "score": 55, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/K-SJm8OQcs7j5BXias9NZdNlSINQyZtJog_OUa2NHXI.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670757690.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=07uTKOB1z7E", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QSt43o6FlOwL5od-fJPC1lDVthKeGhjoK068srqkQG4.jpg?auto=webp&amp;s=306b7ddfb448fcc8423057c899d248ff84d6ab0c", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/QSt43o6FlOwL5od-fJPC1lDVthKeGhjoK068srqkQG4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=11cfab0791905228777a90a7934cda94b8cb9b5d", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/QSt43o6FlOwL5od-fJPC1lDVthKeGhjoK068srqkQG4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5188d89ad88ae2ad3e9fd7707cc108f0ffa01048", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/QSt43o6FlOwL5od-fJPC1lDVthKeGhjoK068srqkQG4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b61a30be4f580e2bd063906dfdb8260a54aa2d65", "width": 320, "height": 240}], "variants": {}, "id": "ZRD4ZV5bW5cnOu7k8S2Q7FXH1yik2jwraBNvo3tp4Q0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "400TB raw", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "ziognu", "is_robot_indexable": true, "report_reasons": null, "author": "It_Is1-24PM", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/ziognu/how_45_drives_open_source_houston_command_center/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=07uTKOB1z7E", "subreddit_subscribers": 658850, "created_utc": 1670757690.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "How 45 Drives Open Source Houston Command Center Makes ZFS On Linux Easy", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/07uTKOB1z7E?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"How 45 Drives Open Source Houston Command Center Makes ZFS On Linux Easy\"&gt;&lt;/iframe&gt;", "author_name": "Lawrence Systems", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/07uTKOB1z7E/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@LAWRENCESYSTEMS"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019m not too sure where to post this but my Aunts birthday is coming up and I wanted to suppose her by digitizing a huge collection of Mini CDs we had from recording in the Sony Handicam. The problem is I have no idea how to accomplish this. Ive been looking online saying I have to finalize the disks but we lost the Camera a long time ago. And the DVD player I have now is too big for the disk and it doesn\u2019t reach the laser for it to be read. i\u2019ve submitted some pictures for context. Links to products I could use and just advice in general would be much appreciated. I thank any and all who answer in advance. \n\nhttps://imgur.com/a/XxFOpAU/", "author_fullname": "t2_1gzox78b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Convert / Digitize Mini CDs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zj1in9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1670781143.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m not too sure where to post this but my Aunts birthday is coming up and I wanted to suppose her by digitizing a huge collection of Mini CDs we had from recording in the Sony Handicam. The problem is I have no idea how to accomplish this. Ive been looking online saying I have to finalize the disks but we lost the Camera a long time ago. And the DVD player I have now is too big for the disk and it doesn\u2019t reach the laser for it to be read. i\u2019ve submitted some pictures for context. Links to products I could use and just advice in general would be much appreciated. I thank any and all who answer in advance. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://imgur.com/a/XxFOpAU/\"&gt;https://imgur.com/a/XxFOpAU/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/IFCCfA1gzcM3rYXncct0pGnXMtPEHimLbTZv4SAwghE.jpg?auto=webp&amp;s=2eb91746775e5c5b9d8ae9968bf0cac1d051e989", "width": 1500, "height": 2000}, "resolutions": [{"url": "https://external-preview.redd.it/IFCCfA1gzcM3rYXncct0pGnXMtPEHimLbTZv4SAwghE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b50b6fabcec68eaf05513ba9f17851e8d3232d5c", "width": 108, "height": 144}, {"url": "https://external-preview.redd.it/IFCCfA1gzcM3rYXncct0pGnXMtPEHimLbTZv4SAwghE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b1a85222f148675de890c42ba824ae8093bc8cbc", "width": 216, "height": 288}, {"url": "https://external-preview.redd.it/IFCCfA1gzcM3rYXncct0pGnXMtPEHimLbTZv4SAwghE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1df31c78c061c24303689bc6967448951b3c9f66", "width": 320, "height": 426}, {"url": "https://external-preview.redd.it/IFCCfA1gzcM3rYXncct0pGnXMtPEHimLbTZv4SAwghE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f4a0890e5b734910843fb5c30aa2891ffa44d220", "width": 640, "height": 853}, {"url": "https://external-preview.redd.it/IFCCfA1gzcM3rYXncct0pGnXMtPEHimLbTZv4SAwghE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5e37644eae4001d3755b2e8dca6f36e75fdc2d68", "width": 960, "height": 1280}, {"url": "https://external-preview.redd.it/IFCCfA1gzcM3rYXncct0pGnXMtPEHimLbTZv4SAwghE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=eba881871f7561dd5e50bc21c8569a5ea58721df", "width": 1080, "height": 1440}], "variants": {}, "id": "Aocy3QeJzyQ0zog21FfBmD2vqr7bvvqDi8LSqGeMkZ0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zj1in9", "is_robot_indexable": true, "report_reasons": null, "author": "SuperSpirito", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zj1in9/how_to_convert_digitize_mini_cds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zj1in9/how_to_convert_digitize_mini_cds/", "subreddit_subscribers": 658850, "created_utc": 1670781143.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I was just reading the arch wiki on setting up RAID and it mentions it's highly recommended to partition the device used for RAID. But it doesn't really explain why. Could someone enlighten me please? Aside from the later suggestion of leaving 100 MiB on the end to make replacement easier is there a reason I should partition the drive before putting it into RAID?\n\nhttps://wiki.archlinux.org/title/RAID#Partition_the_devices\n\nNote: yesterday I did just this but using LVM. So I had 2 18TiB drives, I created 32 partitions about 0.5TiB each and then put them into an LV with total size 18TiB and RAID1 across each device.", "author_fullname": "t2_4fuysild", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why is it recommended to partition drives in RAID?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ziozxs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.61, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670759186.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was just reading the arch wiki on setting up RAID and it mentions it&amp;#39;s highly recommended to partition the device used for RAID. But it doesn&amp;#39;t really explain why. Could someone enlighten me please? Aside from the later suggestion of leaving 100 MiB on the end to make replacement easier is there a reason I should partition the drive before putting it into RAID?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://wiki.archlinux.org/title/RAID#Partition_the_devices\"&gt;https://wiki.archlinux.org/title/RAID#Partition_the_devices&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Note: yesterday I did just this but using LVM. So I had 2 18TiB drives, I created 32 partitions about 0.5TiB each and then put them into an LV with total size 18TiB and RAID1 across each device.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ziozxs", "is_robot_indexable": true, "report_reasons": null, "author": "emax-gomax", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ziozxs/why_is_it_recommended_to_partition_drives_in_raid/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ziozxs/why_is_it_recommended_to_partition_drives_in_raid/", "subreddit_subscribers": 658850, "created_utc": 1670759186.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " Is there a way to download the contents of my account in case yahoo goes belly up unexpectedly or something..", "author_fullname": "t2_8cdiegha", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Found my old yahoo account from 2007 and it has some old emails between my and some family members I'd like to keep.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zj4zl1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670786714.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a way to download the contents of my account in case yahoo goes belly up unexpectedly or something..&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zj4zl1", "is_robot_indexable": true, "report_reasons": null, "author": "Perfect_Salamander_2", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zj4zl1/found_my_old_yahoo_account_from_2007_and_it_has/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zj4zl1/found_my_old_yahoo_account_from_2007_and_it_has/", "subreddit_subscribers": 658850, "created_utc": 1670786714.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_8rszy3ze", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "I am becoming a hoarder", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 75, "top_awarded_type": null, "hide_score": false, "media_metadata": {"onwk0if19d5a1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 65, "x": 108, "u": "https://preview.redd.it/onwk0if19d5a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e3448e86478afdc6a50a6248364ca06701ef3109"}, {"y": 130, "x": 216, "u": "https://preview.redd.it/onwk0if19d5a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=747748cadf9bf58c237b4bd194122b8a75daa950"}, {"y": 193, "x": 320, "u": "https://preview.redd.it/onwk0if19d5a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=08d4fd0213483b295bef49262abb1a3c37ec50f0"}, {"y": 386, "x": 640, "u": "https://preview.redd.it/onwk0if19d5a1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a00052bcf7c914b58d292311ba1c276efc36906e"}, {"y": 579, "x": 960, "u": "https://preview.redd.it/onwk0if19d5a1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ecabdcb7b76d8c4171041caf75af50177e660291"}, {"y": 651, "x": 1080, "u": "https://preview.redd.it/onwk0if19d5a1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=de487f9f4c92a68a002d05efeece3fc0c48bb8b8"}], "s": {"y": 652, "x": 1081, "u": "https://preview.redd.it/onwk0if19d5a1.png?width=1081&amp;format=png&amp;auto=webp&amp;s=82bbba3ad4e1ba2bb8ee0c211923ae13f7965cd0"}, "id": "onwk0if19d5a1"}, "e6mje7cz8d5a1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 58, "x": 108, "u": "https://preview.redd.it/e6mje7cz8d5a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ee939f8ceb7184302aaa4023e9ce27f4795a6307"}, {"y": 117, "x": 216, "u": "https://preview.redd.it/e6mje7cz8d5a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5690e164585691a3bd772245ce180f80933dda03"}, {"y": 173, "x": 320, "u": "https://preview.redd.it/e6mje7cz8d5a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=97790a00cc430c1f04fb9997be065a1a67802b5e"}, {"y": 346, "x": 640, "u": "https://preview.redd.it/e6mje7cz8d5a1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f2c6cd1f798a11fe3c6913130fd57640865392b1"}], "s": {"y": 349, "x": 644, "u": "https://preview.redd.it/e6mje7cz8d5a1.png?width=644&amp;format=png&amp;auto=webp&amp;s=01b0528670e3b302966b5a4bb26ff9c83ea64695"}, "id": "e6mje7cz8d5a1"}}, "name": "t3_zjhcte", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "ups": 7, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"caption": "Archiving an entire website's sheet music collection. Estimated final size: 2 TB", "media_id": "e6mje7cz8d5a1", "id": 218271134}, {"caption": "There are two archives, each with &gt;1000 of these folders, each folder containing 100 PDFs (minus any that don't exist)", "media_id": "onwk0if19d5a1", "id": 218271135}]}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/3s8I8EThQEm5g4qswVDPoTxh0YSgHog6_HDMqpONDuM.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670806954.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/zjhcte", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "90 GB sheet music", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "zjhcte", "is_robot_indexable": true, "report_reasons": null, "author": "WhyIsIsTakenTaken", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/zjhcte/i_am_becoming_a_hoarder/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/zjhcte", "subreddit_subscribers": 658850, "created_utc": 1670806954.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I am looking for a server that I can use to host and stream &lt;2TB worth of videos, which may later expand to 4TB, but I doubt it may expand over that, these are the types of videos I have want that I want to stream.\n\n* one-on-one zoom consultations I've done\n\n* ripped youtube videos \n\n* Videos ripped from online courses I've paid for\n\n* personal recorded videos recorded using my phone\n\nMy idea is to have a dedicated media(video) library where I can have it all in one dashboard. Instead of having to open up multiple tabs or files (i.e. youtube, google chrome, etc.). \n\nI don't want to host these videos on any cloud services (i.e. OneDrive, Google Drive, mega.nz, etc.). For fear thay my files/videos get flagged as copyright and my account suspended.\n\nI'd also like to have the ability to create embedded video links, to put onto my Personal Knowledge Management System  (PKM System), which would most likely be a combination of Notion, OneNote and Nimbus Note.\n\nI already have a Synology NAS DS218+ that I use for cold storage back-up, but it's not suited to host media. I also don't want to have a NAS were I store sensitive files and at the same time open to the web with media hosting. I want these two things, physically compartmentalized.\n\nI will be the only dedicated-user of these media files being streamed, so there is no worry of  bandwidth, when streaming video files.", "author_fullname": "t2_tbw8wxe3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's a good stand-alone dedicated NAS to host/stream media?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zjhnbn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670807578.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am looking for a server that I can use to host and stream &amp;lt;2TB worth of videos, which may later expand to 4TB, but I doubt it may expand over that, these are the types of videos I have want that I want to stream.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;one-on-one zoom consultations I&amp;#39;ve done&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;ripped youtube videos &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Videos ripped from online courses I&amp;#39;ve paid for&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;personal recorded videos recorded using my phone&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;My idea is to have a dedicated media(video) library where I can have it all in one dashboard. Instead of having to open up multiple tabs or files (i.e. youtube, google chrome, etc.). &lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t want to host these videos on any cloud services (i.e. OneDrive, Google Drive, mega.nz, etc.). For fear thay my files/videos get flagged as copyright and my account suspended.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d also like to have the ability to create embedded video links, to put onto my Personal Knowledge Management System  (PKM System), which would most likely be a combination of Notion, OneNote and Nimbus Note.&lt;/p&gt;\n\n&lt;p&gt;I already have a Synology NAS DS218+ that I use for cold storage back-up, but it&amp;#39;s not suited to host media. I also don&amp;#39;t want to have a NAS were I store sensitive files and at the same time open to the web with media hosting. I want these two things, physically compartmentalized.&lt;/p&gt;\n\n&lt;p&gt;I will be the only dedicated-user of these media files being streamed, so there is no worry of  bandwidth, when streaming video files.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zjhnbn", "is_robot_indexable": true, "report_reasons": null, "author": "ApolloRising434", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zjhnbn/whats_a_good_standalone_dedicated_nas_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zjhnbn/whats_a_good_standalone_dedicated_nas_to/", "subreddit_subscribers": 658850, "created_utc": 1670807578.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi All\n\nI tend to find myself having weird 'me only' issues when hoarding. Im currently sat at over 1m images, from deviantart, pixiv, pinterest but then i discovered wallhaven.....you can see where this is going.\n\nAssuming you are using gallery-dl with the '--write-metadata' option to download an ID search or batch of single images it will check the json for the file for the username, create a folder structure and then sort the files for that user to the correct folder.\n\nit'll then add the user account to a txt file for batch downloading of that users uploads. Eventually, ill no doubt have all the user accounts (if they have uploaded) but i then use this for more downloads.\n\nAs an example, i download all the images tagged for cyberpunk 2077 lets say around 300, this is parsed i then have 90 users ready to go and end up with 100k images after running that list. They state they only have about 1m images themselves so shouldn't take long to get it all then just append to my collection.\n\nI couldn't find a list of all users, a search all(\\*) or a list of how many IDs they have. But if you know, let me know. I could have just iterated over IDs in a loop 1 to 999999 but thats possibly a lot of waste.\n\nAnyway......\n\nAs i say, this fits my need for how i scrape stuff from there but thought id share it should someone want to improve/make use of it. Its powershell btw\n\n[https://pastebin.com/q6JXgTL7](https://pastebin.com/q6JXgTL7)", "author_fullname": "t2_8088jmi3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Wallhaven Organiser", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zjcsp9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1670798375.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All&lt;/p&gt;\n\n&lt;p&gt;I tend to find myself having weird &amp;#39;me only&amp;#39; issues when hoarding. Im currently sat at over 1m images, from deviantart, pixiv, pinterest but then i discovered wallhaven.....you can see where this is going.&lt;/p&gt;\n\n&lt;p&gt;Assuming you are using gallery-dl with the &amp;#39;--write-metadata&amp;#39; option to download an ID search or batch of single images it will check the json for the file for the username, create a folder structure and then sort the files for that user to the correct folder.&lt;/p&gt;\n\n&lt;p&gt;it&amp;#39;ll then add the user account to a txt file for batch downloading of that users uploads. Eventually, ill no doubt have all the user accounts (if they have uploaded) but i then use this for more downloads.&lt;/p&gt;\n\n&lt;p&gt;As an example, i download all the images tagged for cyberpunk 2077 lets say around 300, this is parsed i then have 90 users ready to go and end up with 100k images after running that list. They state they only have about 1m images themselves so shouldn&amp;#39;t take long to get it all then just append to my collection.&lt;/p&gt;\n\n&lt;p&gt;I couldn&amp;#39;t find a list of all users, a search all(*) or a list of how many IDs they have. But if you know, let me know. I could have just iterated over IDs in a loop 1 to 999999 but thats possibly a lot of waste.&lt;/p&gt;\n\n&lt;p&gt;Anyway......&lt;/p&gt;\n\n&lt;p&gt;As i say, this fits my need for how i scrape stuff from there but thought id share it should someone want to improve/make use of it. Its powershell btw&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://pastebin.com/q6JXgTL7\"&gt;https://pastebin.com/q6JXgTL7&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-WiKXADWH5lgU4gQv5fcDAQ9QKNBZTJ-D83BykIL2HA.jpg?auto=webp&amp;s=07c121a0180003f7373863af66192b6ff6a937da", "width": 150, "height": 150}, "resolutions": [{"url": "https://external-preview.redd.it/-WiKXADWH5lgU4gQv5fcDAQ9QKNBZTJ-D83BykIL2HA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=df9c6a296446d05d873c629a30253398c4d29c1b", "width": 108, "height": 108}], "variants": {}, "id": "OgFzGCIRw1ZxjMOSkfV1OiH-_nQiZl8rzSonmOAuhGs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zjcsp9", "is_robot_indexable": true, "report_reasons": null, "author": "Obvious-Viking", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zjcsp9/wallhaven_organiser/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zjcsp9/wallhaven_organiser/", "subreddit_subscribers": 658850, "created_utc": 1670798375.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Every pixiv scraper I can find is purely for scraping tags, but I want to bulk download all my followings, coz I follow over 1k people. Any suggestions?", "author_fullname": "t2_10no10lp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any pixiv scraper that can target my follow list or list of users?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zjbah6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670796273.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Every pixiv scraper I can find is purely for scraping tags, but I want to bulk download all my followings, coz I follow over 1k people. Any suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zjbah6", "is_robot_indexable": true, "report_reasons": null, "author": "MayonnaisalSpray", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zjbah6/any_pixiv_scraper_that_can_target_my_follow_list/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zjbah6/any_pixiv_scraper_that_can_target_my_follow_list/", "subreddit_subscribers": 658850, "created_utc": 1670796273.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Not sure if this is the right place to ask. At the moment just have a small Pi nas running openmediavault with a 4tb 3.5\" hdd in a sabrent powered enclosure. My one issue: the enclosure has a built in power save/sleep function that I cannot disable. Tried going through and making sure APM was disabled, spindown was disabled, etc, but after exhausting all resources I am fairly sure this is a function of the enclosure(even though it is not listed in the product info anywhere I can find). this causes extremely slow load times for Plex initially and can cause temporary hangups browsing files, etc. Anyone know of a good 3.5\" enclosure that does not have a sleep function? I have been looking online and this was the best option that did not list powersave, and ended up having it anyway. Not ready to pull the trigger on an add-on board yet for the Pi. Thanks for any replies!", "author_fullname": "t2_1p8cryl3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "External enclosure question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zjavhw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670795640.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not sure if this is the right place to ask. At the moment just have a small Pi nas running openmediavault with a 4tb 3.5&amp;quot; hdd in a sabrent powered enclosure. My one issue: the enclosure has a built in power save/sleep function that I cannot disable. Tried going through and making sure APM was disabled, spindown was disabled, etc, but after exhausting all resources I am fairly sure this is a function of the enclosure(even though it is not listed in the product info anywhere I can find). this causes extremely slow load times for Plex initially and can cause temporary hangups browsing files, etc. Anyone know of a good 3.5&amp;quot; enclosure that does not have a sleep function? I have been looking online and this was the best option that did not list powersave, and ended up having it anyway. Not ready to pull the trigger on an add-on board yet for the Pi. Thanks for any replies!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zjavhw", "is_robot_indexable": true, "report_reasons": null, "author": "dyno241", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zjavhw/external_enclosure_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zjavhw/external_enclosure_question/", "subreddit_subscribers": 658850, "created_utc": 1670795640.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "A few months ago, I accidentally bought the SAS version of a 16TB Seagate Exos, when I meant to get SATA.\n\nI knew I was planning a new living room PC soon, and having it double as a NAS, so I kept it.  I ordered another 16TB SAS drive and a SAS RAID controller a couple weeks ago to put the new computer together.  I want to make a basic RAID 1.\n\nWindows shows the controller as \"Avago adapter sas3 3008 fury - StorPort\" and says the driver is good, but I don't see any sign of the connected drives, or any UI to set up the controller.\n\nAre there any good guides for this?  Any guides I've found assume SATA drives and either the RAID support on the motherboard or Windows virtual volumes -- and that you can actually see that the drives exist before you get started.", "author_fullname": "t2_375h2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SAS drives not recognized in Windows 11?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zjg7g2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670804633.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A few months ago, I accidentally bought the SAS version of a 16TB Seagate Exos, when I meant to get SATA.&lt;/p&gt;\n\n&lt;p&gt;I knew I was planning a new living room PC soon, and having it double as a NAS, so I kept it.  I ordered another 16TB SAS drive and a SAS RAID controller a couple weeks ago to put the new computer together.  I want to make a basic RAID 1.&lt;/p&gt;\n\n&lt;p&gt;Windows shows the controller as &amp;quot;Avago adapter sas3 3008 fury - StorPort&amp;quot; and says the driver is good, but I don&amp;#39;t see any sign of the connected drives, or any UI to set up the controller.&lt;/p&gt;\n\n&lt;p&gt;Are there any good guides for this?  Any guides I&amp;#39;ve found assume SATA drives and either the RAID support on the motherboard or Windows virtual volumes -- and that you can actually see that the drives exist before you get started.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zjg7g2", "is_robot_indexable": true, "report_reasons": null, "author": "PstScrpt", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zjg7g2/sas_drives_not_recognized_in_windows_11/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zjg7g2/sas_drives_not_recognized_in_windows_11/", "subreddit_subscribers": 658850, "created_utc": 1670804633.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "WD My Cloud Home is *finally* gaining the ability to have local access to shares with the upcoming Firmware 8.12.0 and will finally support SMB shares. [ref](https://support-en.wd.com/app/answers/detailweb/a_id/34991)\n\nDoes there exist any windows software that gives me SMB syncing magic like dropbox/seafile/nextcloud client?\n\nThat way I don't have to do a highly unreliable NET USE, or explorer smb mount.\n\nI love that seafile/nextcloud can use the windows and mac cloud files feature that integrate with explorer and finder and download the underlying file on first access. Are there any SMB sync tools that can do this too?\n\nWould be great to find some SMB sync software I can install on each persons laptop, point it at the local network address of the mycloud and have files up to date in the background.", "author_fullname": "t2_bwu4e10v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a dropbox style sync client for SMB with MyCloud Home?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zjfkxm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670803409.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;WD My Cloud Home is &lt;em&gt;finally&lt;/em&gt; gaining the ability to have local access to shares with the upcoming Firmware 8.12.0 and will finally support SMB shares. &lt;a href=\"https://support-en.wd.com/app/answers/detailweb/a_id/34991\"&gt;ref&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Does there exist any windows software that gives me SMB syncing magic like dropbox/seafile/nextcloud client?&lt;/p&gt;\n\n&lt;p&gt;That way I don&amp;#39;t have to do a highly unreliable NET USE, or explorer smb mount.&lt;/p&gt;\n\n&lt;p&gt;I love that seafile/nextcloud can use the windows and mac cloud files feature that integrate with explorer and finder and download the underlying file on first access. Are there any SMB sync tools that can do this too?&lt;/p&gt;\n\n&lt;p&gt;Would be great to find some SMB sync software I can install on each persons laptop, point it at the local network address of the mycloud and have files up to date in the background.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zjfkxm", "is_robot_indexable": true, "report_reasons": null, "author": "ComprehensiveDonut27", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zjfkxm/is_there_a_dropbox_style_sync_client_for_smb_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zjfkxm/is_there_a_dropbox_style_sync_client_for_smb_with/", "subreddit_subscribers": 658850, "created_utc": 1670803409.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have about 250-300 blurays that I have made over time. I do not have originals any longer as I sold them off when Bluray was \"hot\". These are now 5+ years old and worried about bluRay rot.\n\n90+% of the blurays are LTH 25gb\n\nWould a 8TB be good enough to store all them? Since streaming is so abundant now and looks to be for the forseeable future unless something serious happened to the world ( nowadays who can say, would it be better to find them on the net when I want?\n\nWill an external HD be ok if written to and then only accessed when needed ( once or twice a month) and then shut off?  \n\nI am getting older and plan on retiring in next 10 years. I will have plenty of time to watch all my \"classic\" movies a that time. So I am wanting to store all this until I retire.  Then my family can deal with it when I pass.... HAHA  dont know what they are in for\n\n\n32TB so far not including blurays", "author_fullname": "t2_lzwh7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thinking of moving my copied BluRays to external hard drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zjbo3e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670796815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have about 250-300 blurays that I have made over time. I do not have originals any longer as I sold them off when Bluray was &amp;quot;hot&amp;quot;. These are now 5+ years old and worried about bluRay rot.&lt;/p&gt;\n\n&lt;p&gt;90+% of the blurays are LTH 25gb&lt;/p&gt;\n\n&lt;p&gt;Would a 8TB be good enough to store all them? Since streaming is so abundant now and looks to be for the forseeable future unless something serious happened to the world ( nowadays who can say, would it be better to find them on the net when I want?&lt;/p&gt;\n\n&lt;p&gt;Will an external HD be ok if written to and then only accessed when needed ( once or twice a month) and then shut off?  &lt;/p&gt;\n\n&lt;p&gt;I am getting older and plan on retiring in next 10 years. I will have plenty of time to watch all my &amp;quot;classic&amp;quot; movies a that time. So I am wanting to store all this until I retire.  Then my family can deal with it when I pass.... HAHA  dont know what they are in for&lt;/p&gt;\n\n&lt;p&gt;32TB so far not including blurays&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zjbo3e", "is_robot_indexable": true, "report_reasons": null, "author": "cmdrmcgarrett", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zjbo3e/thinking_of_moving_my_copied_blurays_to_external/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zjbo3e/thinking_of_moving_my_copied_blurays_to_external/", "subreddit_subscribers": 658850, "created_utc": 1670796815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "After losing a couple SSD's the pain of losing my files was too great. I started doing some research and bought a TerraMaster D4-300 and two 12Tb HDD. I am unsure what would be the best next steps for backing up my files. \n\nMy initial strategy was to start backing up on one HDD 1 and then set up HDD 2 as a mirrored backup. Now that I have it all plugged in, I am unsure about the best way to do that and looking for advice. I am working from a 4TB Macbook Pro that will go back and forth to work with me and ideally, the TM will be a part of a desk/monitor set up I can just connect laptop to when working from home. \n\nSomething like drivepool seems perfect for what I need but I can see from other posts that's not an option for Mac. Should I just set up a ChronoSync task to mirror HDD 1 to HDD 2 and sync whenever I add files?\n\nI'm a noob at all this so any advice would be greatly appreciated, thanks!", "author_fullname": "t2_11nnr2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for starting down the path of a hoarder", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zjbi2f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670796570.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After losing a couple SSD&amp;#39;s the pain of losing my files was too great. I started doing some research and bought a TerraMaster D4-300 and two 12Tb HDD. I am unsure what would be the best next steps for backing up my files. &lt;/p&gt;\n\n&lt;p&gt;My initial strategy was to start backing up on one HDD 1 and then set up HDD 2 as a mirrored backup. Now that I have it all plugged in, I am unsure about the best way to do that and looking for advice. I am working from a 4TB Macbook Pro that will go back and forth to work with me and ideally, the TM will be a part of a desk/monitor set up I can just connect laptop to when working from home. &lt;/p&gt;\n\n&lt;p&gt;Something like drivepool seems perfect for what I need but I can see from other posts that&amp;#39;s not an option for Mac. Should I just set up a ChronoSync task to mirror HDD 1 to HDD 2 and sync whenever I add files?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a noob at all this so any advice would be greatly appreciated, thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zjbi2f", "is_robot_indexable": true, "report_reasons": null, "author": "DaBeigeMage", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zjbi2f/advice_for_starting_down_the_path_of_a_hoarder/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zjbi2f/advice_for_starting_down_the_path_of_a_hoarder/", "subreddit_subscribers": 658850, "created_utc": 1670796570.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Question above -- currently debating about buying 20TB hard drives, but unsure if they are supported with my OS and unsure how to check if they are supported.\n\nI have an i3-10105, 64gb of ram and running Ubuntu Server 22.04.", "author_fullname": "t2_4quxu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is &gt;16TB HDDs an issue with Ubuntu Server 22.04 LTS on modern hardware? I remember reading ext4 only supporting up to 16TB.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ziev62", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.61, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670733001.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Question above -- currently debating about buying 20TB hard drives, but unsure if they are supported with my OS and unsure how to check if they are supported.&lt;/p&gt;\n\n&lt;p&gt;I have an i3-10105, 64gb of ram and running Ubuntu Server 22.04.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ziev62", "is_robot_indexable": true, "report_reasons": null, "author": "DigitalSpeed", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ziev62/is_16tb_hdds_an_issue_with_ubuntu_server_2204_lts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ziev62/is_16tb_hdds_an_issue_with_ubuntu_server_2204_lts/", "subreddit_subscribers": 658850, "created_utc": 1670733001.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi ,  \n\n\nI have 2 x \" WD Black D10 8Tb \" drives in enclosures.     \nThey have been great however both \" apd \" 12V 3.0 A power     \nadaptors have since failed ..\n\nI'm looking for 2 - 4 adaptors and happy to pay 5 usd each ,  \nplus shipping costs to Portland. For the original \" APD \" ones    \nto match what I had ..  \n\n\nWanted to buy :      \n2 - 4 \" APD \" 12V  \\* 3.0 A \\* power adaptors    \n( US ones are ok even though I'm in AUS )  \n    \nHere's a photo of them :       \n\\[ [https://imgur.com/a/QE1ZzMe](https://imgur.com/a/QE1ZzMe) \\]      \n\n\nThanks ,       \n\u00a0   \n\u2014 Chuan", "author_fullname": "t2_fghh5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[WTB] \" WD Black D10 \" 8Tb \u2014 Replacement 12V / 3.0 A power adaptors", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ziluh5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1670750334.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi ,  &lt;/p&gt;\n\n&lt;p&gt;I have 2 x &amp;quot; WD Black D10 8Tb &amp;quot; drives in enclosures.&lt;br/&gt;\nThey have been great however both &amp;quot; apd &amp;quot; 12V 3.0 A power&lt;br/&gt;\nadaptors have since failed ..&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for 2 - 4 adaptors and happy to pay 5 usd each ,&lt;br/&gt;\nplus shipping costs to Portland. For the original &amp;quot; APD &amp;quot; ones&lt;br/&gt;\nto match what I had ..  &lt;/p&gt;\n\n&lt;p&gt;Wanted to buy :&lt;br/&gt;\n2 - 4 &amp;quot; APD &amp;quot; 12V  * 3.0 A * power adaptors&lt;br/&gt;\n( US ones are ok even though I&amp;#39;m in AUS )  &lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s a photo of them :&lt;br/&gt;\n[ &lt;a href=\"https://imgur.com/a/QE1ZzMe\"&gt;https://imgur.com/a/QE1ZzMe&lt;/a&gt; ]      &lt;/p&gt;\n\n&lt;p&gt;Thanks ,&lt;br/&gt;\n\u00a0&lt;br/&gt;\n\u2014 Chuan&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Qx8m4rNE2o-fKJ0GQS9h9GrYXMl3pzKL1HWrPxifiO8.jpg?auto=webp&amp;s=1d25718b4175b608f9f3716d65d22b2c6c61f58d", "width": 2736, "height": 3648}, "resolutions": [{"url": "https://external-preview.redd.it/Qx8m4rNE2o-fKJ0GQS9h9GrYXMl3pzKL1HWrPxifiO8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a16af017be45e38cc048ab43d7ff7e10633cd760", "width": 108, "height": 144}, {"url": "https://external-preview.redd.it/Qx8m4rNE2o-fKJ0GQS9h9GrYXMl3pzKL1HWrPxifiO8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bfa295667e16b3e534996d7a7ccc40d3b48ece4a", "width": 216, "height": 288}, {"url": "https://external-preview.redd.it/Qx8m4rNE2o-fKJ0GQS9h9GrYXMl3pzKL1HWrPxifiO8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f20ba1a23628a4933e6ce9258da20fb6fad2cb99", "width": 320, "height": 426}, {"url": "https://external-preview.redd.it/Qx8m4rNE2o-fKJ0GQS9h9GrYXMl3pzKL1HWrPxifiO8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=db88511c256c923d19a024af9b0f9d9fab69d308", "width": 640, "height": 853}, {"url": "https://external-preview.redd.it/Qx8m4rNE2o-fKJ0GQS9h9GrYXMl3pzKL1HWrPxifiO8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3f0fa0a86d1f52722a732f9c3c4a16a3409a9061", "width": 960, "height": 1280}, {"url": "https://external-preview.redd.it/Qx8m4rNE2o-fKJ0GQS9h9GrYXMl3pzKL1HWrPxifiO8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=95935e2413fcca5a9008fdce92c2ce3d114ada53", "width": 1080, "height": 1440}], "variants": {}, "id": "Bz2szLUv3fNZ42DlgD7ZIHG4Oj9RSxNMahL6hN5z534"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ziluh5", "is_robot_indexable": true, "report_reasons": null, "author": "chuan_l", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ziluh5/wtb_wd_black_d10_8tb_replacement_12v_30_a_power/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ziluh5/wtb_wd_black_d10_8tb_replacement_12v_30_a_power/", "subreddit_subscribers": 658850, "created_utc": 1670750334.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Also, would being able to hold this content make it harder for the authorities to deal with book piracy? See here: \n\nhttps://join.substack.com/p/copyrights-costs\n\n&gt;Anna\u2019s Archive is active on the normal internet\u2014no need for Tor\u2014and has an \u201cAbout\u201d page that says: \u201cThis website was created by Anna, the person behind the Pirate Library Mirror, which is a backup of the Z-Library shadow library.\u201d And I estimate that people with 300 terabytes of disk space have the ability to personally mirror the totality of the shadow-library material that exists\u2014maybe that\u2019s irrelevant, but the fact that people can personally mirror the totality of the content in question might make it harder to crack down on shadow libraries.", "author_fullname": "t2_dranep8p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much space would it take to hold all of the shadow-library content in existence?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zj9hmh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1670793576.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Also, would being able to hold this content make it harder for the authorities to deal with book piracy? See here: &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://join.substack.com/p/copyrights-costs\"&gt;https://join.substack.com/p/copyrights-costs&lt;/a&gt;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Anna\u2019s Archive is active on the normal internet\u2014no need for Tor\u2014and has an \u201cAbout\u201d page that says: \u201cThis website was created by Anna, the person behind the Pirate Library Mirror, which is a backup of the Z-Library shadow library.\u201d And I estimate that people with 300 terabytes of disk space have the ability to personally mirror the totality of the shadow-library material that exists\u2014maybe that\u2019s irrelevant, but the fact that people can personally mirror the totality of the content in question might make it harder to crack down on shadow libraries.&lt;/p&gt;\n&lt;/blockquote&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/iMgAG5khu2IybQzzkE1u5WD9_vAJy2WSuYo8Ter7P-A.jpg?auto=webp&amp;s=1dac45b95bcde1a6a11afb045a681ba428dc15a4", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/iMgAG5khu2IybQzzkE1u5WD9_vAJy2WSuYo8Ter7P-A.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=edf6bd18331f88fd08808623c1f30035e06b67e4", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/iMgAG5khu2IybQzzkE1u5WD9_vAJy2WSuYo8Ter7P-A.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e608d25e66098fcd3479c7075d8a08b600c9e028", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/iMgAG5khu2IybQzzkE1u5WD9_vAJy2WSuYo8Ter7P-A.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0af745763d96b0c944c93fc6ffc2cf49bfd6f8d0", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/iMgAG5khu2IybQzzkE1u5WD9_vAJy2WSuYo8Ter7P-A.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f88c59bad9cfb4635f5a073822a576f19722556b", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/iMgAG5khu2IybQzzkE1u5WD9_vAJy2WSuYo8Ter7P-A.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=becae61703e4b6c49961761b2f2eb10a020a9ce6", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/iMgAG5khu2IybQzzkE1u5WD9_vAJy2WSuYo8Ter7P-A.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=51ef7bf4183c3a7acc9b7e3c259dbf6b750be974", "width": 1080, "height": 540}], "variants": {}, "id": "IWGyv6nQC-VPVF3n6rO3yLMKDPn78cqxe6flJKhikuc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zj9hmh", "is_robot_indexable": true, "report_reasons": null, "author": "LinguisticsTurtle", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zj9hmh/how_much_space_would_it_take_to_hold_all_of_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zj9hmh/how_much_space_would_it_take_to_hold_all_of_the/", "subreddit_subscribers": 658850, "created_utc": 1670793576.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hi! How to download from Internet Archive using ia downloader, but files keep their original title and not be renamed by doc file \"identifier\"?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zj4w86", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_59rlp3yo", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "internetarchive", "selftext": "I'm trying to download doc in bulk using ia downloader but each is named after their identifier. What command line to use so files keep their original title?", "author_fullname": "t2_59rlp3yo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to download all pdf from a collection using ia downloader, but files keep their original title and not be renamed by doc file identifier?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/internetarchive", "hidden": false, "pwls": null, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zj4pau", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670786235.0, "link_flair_type": "text", "wls": null, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.internetarchive", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to download doc in bulk using ia downloader but each is named after their identifier. What command line to use so files keep their original title?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x0rs", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zj4pau", "is_robot_indexable": true, "report_reasons": null, "author": "mataka54321", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": null, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/internetarchive/comments/zj4pau/how_to_download_all_pdf_from_a_collection_using/", "parent_whitelist_status": null, "stickied": false, "url": "https://old.reddit.com/r/internetarchive/comments/zj4pau/how_to_download_all_pdf_from_a_collection_using/", "subreddit_subscribers": 485, "created_utc": 1670786235.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1670786554.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.internetarchive", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/internetarchive/comments/zj4pau/how_to_download_all_pdf_from_a_collection_using/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zj4w86", "is_robot_indexable": true, "report_reasons": null, "author": "mataka54321", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_zj4pau", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zj4w86/hi_how_to_download_from_internet_archive_using_ia/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/internetarchive/comments/zj4pau/how_to_download_all_pdf_from_a_collection_using/", "subreddit_subscribers": 658850, "created_utc": 1670786554.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I was a little disappointed when I installed a new external HDD in an enclosure and it maxed out at 50 mb/s copying data from my internal nvme SSD, but accepted it for what it was. I just purchased a second external HDD and am copying between the two and have hit 180+ mbs per second which I was not expecting.\n\nTo add further confusion the new drive is plugged into my slower USB port which (they are both 3.0) ruled so by testing an external drive in each port on opposite sides of the laptop, this slower port gets 15 mb/s when transferring from my internal drive.\n\nWondering what the bottleneck could be and if there's anything I can do.", "author_fullname": "t2_5hpsob4z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HDD transfer speeds question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zj4bsc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670785621.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was a little disappointed when I installed a new external HDD in an enclosure and it maxed out at 50 mb/s copying data from my internal nvme SSD, but accepted it for what it was. I just purchased a second external HDD and am copying between the two and have hit 180+ mbs per second which I was not expecting.&lt;/p&gt;\n\n&lt;p&gt;To add further confusion the new drive is plugged into my slower USB port which (they are both 3.0) ruled so by testing an external drive in each port on opposite sides of the laptop, this slower port gets 15 mb/s when transferring from my internal drive.&lt;/p&gt;\n\n&lt;p&gt;Wondering what the bottleneck could be and if there&amp;#39;s anything I can do.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zj4bsc", "is_robot_indexable": true, "report_reasons": null, "author": "Artifact-O", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zj4bsc/hdd_transfer_speeds_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zj4bsc/hdd_transfer_speeds_question/", "subreddit_subscribers": 658850, "created_utc": 1670785621.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I purchased a set of PNY flashdrives before, 16GB. The problem is they are slow, practically unusably slow. Even some of the cheaper USB 3.0 drives I got from Sandisk are about 1/10th the speed of some more expensive Samsung 3.0 drives I got. \n \nThere are tons of random no-name USB drive packs on Amazon and the like, but I trust those about as much as Google's privacy policies. Are there any good USB drive packs on Amazon or anywhere else? Or do I just have to buy individual usb drives?", "author_fullname": "t2_9njdn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any good packs of USB Flashdrives anywhere, or do I have to purchase shingle?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zijdq7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670743025.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I purchased a set of PNY flashdrives before, 16GB. The problem is they are slow, practically unusably slow. Even some of the cheaper USB 3.0 drives I got from Sandisk are about 1/10th the speed of some more expensive Samsung 3.0 drives I got. &lt;/p&gt;\n\n&lt;p&gt;There are tons of random no-name USB drive packs on Amazon and the like, but I trust those about as much as Google&amp;#39;s privacy policies. Are there any good USB drive packs on Amazon or anywhere else? Or do I just have to buy individual usb drives?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zijdq7", "is_robot_indexable": true, "report_reasons": null, "author": "Cyber_Akuma", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zijdq7/are_there_any_good_packs_of_usb_flashdrives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zijdq7/are_there_any_good_packs_of_usb_flashdrives/", "subreddit_subscribers": 658850, "created_utc": 1670743025.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My daughter's First Grade teacher took a quick video of her in class and posted it a few years ago. She left the school and we haven't been able to reach her. We'd like to be able to download the video so save it as it's very cute. Do y'all have any advice on how to do that?", "author_fullname": "t2_59mtpzg1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Downloading Video From Twitter", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zicafb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670727255.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My daughter&amp;#39;s First Grade teacher took a quick video of her in class and posted it a few years ago. She left the school and we haven&amp;#39;t been able to reach her. We&amp;#39;d like to be able to download the video so save it as it&amp;#39;s very cute. Do y&amp;#39;all have any advice on how to do that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zicafb", "is_robot_indexable": true, "report_reasons": null, "author": "RR1904", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zicafb/downloading_video_from_twitter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zicafb/downloading_video_from_twitter/", "subreddit_subscribers": 658850, "created_utc": 1670727255.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "When I start a new project there are these filters: \n\n\\+\\*.png +\\*.gif +\\*.jpg +\\*.jpeg +\\*.css +\\*.js -ad.doubleclick.net/\\* -mime:application/foobar \n\nI delete these filters because I am worried that by leaving them then only .png .gif .jpg .jpeg .css .js files will be downloaded and all the other files won't be downloaded, am I correct? \n\nSo I delete the filters and I leave the page blank, but what does happen when the page is left blank? I tried to use the filter +\\* to see if it is the same thing but then other files are downloaded if I leave the page blank and different files are downloaded if I use the +\\* filter.\n\nMy question is what is downloaded when no filter is used?\n\nAnother question, what's the difference between this filters:\n\n\\+\\*.png +\\*.gif +\\*.jpg +\\*.jpeg +\\*.css +\\*.js -ad.doubleclick.net/\\* -mime:application/foobar \n\nand this filters:\n\n\\-\\*  \n\\+\\*.png +\\*.gif +\\*.jpg +\\*.jpeg +\\*.css +\\*.js -ad.doubleclick.net/\\* -mime:application/foobar", "author_fullname": "t2_xtwzx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HTTrack, what does happen if I leave the Scan Rules (filters) page blank?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ziyrse", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670776556.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When I start a new project there are these filters: &lt;/p&gt;\n\n&lt;p&gt;+*.png +*.gif +*.jpg +*.jpeg +*.css +*.js -ad.doubleclick.net/* -mime:application/foobar &lt;/p&gt;\n\n&lt;p&gt;I delete these filters because I am worried that by leaving them then only .png .gif .jpg .jpeg .css .js files will be downloaded and all the other files won&amp;#39;t be downloaded, am I correct? &lt;/p&gt;\n\n&lt;p&gt;So I delete the filters and I leave the page blank, but what does happen when the page is left blank? I tried to use the filter +* to see if it is the same thing but then other files are downloaded if I leave the page blank and different files are downloaded if I use the +* filter.&lt;/p&gt;\n\n&lt;p&gt;My question is what is downloaded when no filter is used?&lt;/p&gt;\n\n&lt;p&gt;Another question, what&amp;#39;s the difference between this filters:&lt;/p&gt;\n\n&lt;p&gt;+*.png +*.gif +*.jpg +*.jpeg +*.css +*.js -ad.doubleclick.net/* -mime:application/foobar &lt;/p&gt;\n\n&lt;p&gt;and this filters:&lt;/p&gt;\n\n&lt;p&gt;-*&lt;br/&gt;\n+*.png +*.gif +*.jpg +*.jpeg +*.css +*.js -ad.doubleclick.net/* -mime:application/foobar&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ziyrse", "is_robot_indexable": true, "report_reasons": null, "author": "fjnk", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ziyrse/httrack_what_does_happen_if_i_leave_the_scan/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ziyrse/httrack_what_does_happen_if_i_leave_the_scan/", "subreddit_subscribers": 658850, "created_utc": 1670776556.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Looking for a solution (preferably free) that can download over 5k songs in .wav format preferably though .mp3 320kbps should also do the trick. I can make a playlist on any service except Apple Music and also have a stored .txt and .csv version of the songs I'm looking for. All of the solutions I have seen require inputting each song into the downloader individually and I was wondering if there was a solution that can mass-download all of them at once. I'm on Win10 and am comfortable using command prompt.", "author_fullname": "t2_12225d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to download large amounts of high-quality music?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zie4ch", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670731266.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for a solution (preferably free) that can download over 5k songs in .wav format preferably though .mp3 320kbps should also do the trick. I can make a playlist on any service except Apple Music and also have a stored .txt and .csv version of the songs I&amp;#39;m looking for. All of the solutions I have seen require inputting each song into the downloader individually and I was wondering if there was a solution that can mass-download all of them at once. I&amp;#39;m on Win10 and am comfortable using command prompt.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "16TB + 3TB NAS", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zie4ch", "is_robot_indexable": true, "report_reasons": null, "author": "shoey9998", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/zie4ch/best_way_to_download_large_amounts_of_highquality/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zie4ch/best_way_to_download_large_amounts_of_highquality/", "subreddit_subscribers": 658850, "created_utc": 1670731266.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I was about to buy a WD 4TB \u201cportable\u201d external hard drive, but then I noticed I could get an internal 3.5\u201d WD Blue with the same capacity for significantly cheaper, or a WD Red for a bit cheaper than the portable.\n\nI already have a hard drive case with USB adapter, although I don\u2019t know how durable it is. I bought it to keep on my desk for occasional use, not to take with me places. I don\u2019t think it\u2019s especially flimsy though. \n\nIs there a hidden cost if I go for the WD Blue and put it in the case instead of just getting the portable? For example, does the portable have more protection against physical damage? Or is it the same guts inside a cheap case?", "author_fullname": "t2_tggommtv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need an external hard drive I can take with me places. Is there a disadvantage to buying an internal drive and putting it in a SATA to USB adapter shell, instead of getting one advertised as \u201cportable\u201d?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zibwgv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.3, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670726391.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was about to buy a WD 4TB \u201cportable\u201d external hard drive, but then I noticed I could get an internal 3.5\u201d WD Blue with the same capacity for significantly cheaper, or a WD Red for a bit cheaper than the portable.&lt;/p&gt;\n\n&lt;p&gt;I already have a hard drive case with USB adapter, although I don\u2019t know how durable it is. I bought it to keep on my desk for occasional use, not to take with me places. I don\u2019t think it\u2019s especially flimsy though. &lt;/p&gt;\n\n&lt;p&gt;Is there a hidden cost if I go for the WD Blue and put it in the case instead of just getting the portable? For example, does the portable have more protection against physical damage? Or is it the same guts inside a cheap case?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "zibwgv", "is_robot_indexable": true, "report_reasons": null, "author": "bobisnotmyuncIe", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/zibwgv/i_need_an_external_hard_drive_i_can_take_with_me/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/zibwgv/i_need_an_external_hard_drive_i_can_take_with_me/", "subreddit_subscribers": 658850, "created_utc": 1670726391.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}