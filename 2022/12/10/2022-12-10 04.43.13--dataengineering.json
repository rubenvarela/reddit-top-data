{"kind": "Listing", "data": {"after": "t3_zh8n3m", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2tv9i42n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "r/dataengineering wrapped", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_zgpcsx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": "#46d160", "ups": 133, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fd5b074e-239e-11e8-a28b-0e0f8d9eda5a", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meta", "can_mod_post": false, "score": 133, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/wLlymWwl9eaAfSQZjuMwbaOW4JGgAzxz075QTC52Xo8.jpg", "edited": false, "author_flair_css_class": "mod", "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670568048.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/wjtxidai0v4a1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/wjtxidai0v4a1.jpg?auto=webp&amp;s=2a561f30687e02c450631655922ba11edd826201", "width": 1080, "height": 1920}, "resolutions": [{"url": "https://preview.redd.it/wjtxidai0v4a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=770909f78c9872d2f502348b9a412ab739e263bf", "width": 108, "height": 192}, {"url": "https://preview.redd.it/wjtxidai0v4a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=497471eacf95be0d0c3c9523087648970cac3bb3", "width": 216, "height": 384}, {"url": "https://preview.redd.it/wjtxidai0v4a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3f6d7faebc4cb0a3cda11ac0ce99aa067ac07d57", "width": 320, "height": 568}, {"url": "https://preview.redd.it/wjtxidai0v4a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=363afbeff41a35f07e6a6a688bfccb90805a5fed", "width": 640, "height": 1137}, {"url": "https://preview.redd.it/wjtxidai0v4a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=93c8858b820203780874918db4e315dca44b1098", "width": 960, "height": 1706}, {"url": "https://preview.redd.it/wjtxidai0v4a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=13ea126ab7a94f38585c114bdeb6f1a97dc8a76a", "width": 1080, "height": 1920}], "variants": {}, "id": "6NRogcjC4XiYOQhU1pjkrZuPyCrvBBP8GeLQ9t2y6MY"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5d8a87e8-a952-11eb-9a8a-0e3979f03641", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "mod | Sr. Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "zgpcsx", "is_robot_indexable": true, "report_reasons": null, "author": "theporterhaus", "discussion_type": null, "num_comments": 3, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "light", "permalink": "/r/dataengineering/comments/zgpcsx/rdataengineering_wrapped/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/wjtxidai0v4a1.jpg", "subreddit_subscribers": 82401, "created_utc": 1670568048.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\nhttps://preview.redd.it/s8llls4you4a1.png?width=460&amp;format=png&amp;auto=webp&amp;s=0e7cccdde22e2da0be5d14dff0e0f7f02d664628\n\nI love the irony of this :D \n\n&amp;#x200B;\n\n(and probably also the meta-paradox of being a jerk by posting this thus violating the very rule I'm citing \ud83d\ude09 )", "author_fullname": "t2_bvkm0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dates are hard\u2014we can relate to that, can't we r/dataengineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"s8llls4you4a1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 109, "x": 108, "u": "https://preview.redd.it/s8llls4you4a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3f756ff21ba91600cd4d8c7c74f1d322c80d4937"}, {"y": 219, "x": 216, "u": "https://preview.redd.it/s8llls4you4a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=36c3599e24a661f896517cb1bb61cb7490a02724"}, {"y": 324, "x": 320, "u": "https://preview.redd.it/s8llls4you4a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=da1061070f16f5a33564ac4cd46d6d066cff4802"}], "s": {"y": 467, "x": 460, "u": "https://preview.redd.it/s8llls4you4a1.png?width=460&amp;format=png&amp;auto=webp&amp;s=0e7cccdde22e2da0be5d14dff0e0f7f02d664628"}, "id": "s8llls4you4a1"}}, "name": "t3_zgtrnk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 95, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 95, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/lRoOsAy7xdttw5-id-v1nfKCGtkz5CUP62h43Pfxseo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670582282.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/s8llls4you4a1.png?width=460&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0e7cccdde22e2da0be5d14dff0e0f7f02d664628\"&gt;https://preview.redd.it/s8llls4you4a1.png?width=460&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0e7cccdde22e2da0be5d14dff0e0f7f02d664628&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I love the irony of this :D &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;(and probably also the meta-paradox of being a jerk by posting this thus violating the very rule I&amp;#39;m citing \ud83d\ude09 )&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "zgtrnk", "is_robot_indexable": true, "report_reasons": null, "author": "rmoff", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zgtrnk/dates_are_hardwe_can_relate_to_that_cant_we/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zgtrnk/dates_are_hardwe_can_relate_to_that_cant_we/", "subreddit_subscribers": 82401, "created_utc": 1670582282.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So far I've created a Python script to merge the critical data from each excel into a JSON file so every file it's an object, it takes approximately half a second per excel file so I'm going to parse 7 thousand at a time so I doesn't take the whole day. \nThe thing is that the data isn't clean, so I don't think JSON it's the best file type for this scenario. \nHave you done something similar? Any advice?\n\nEdit: Sorry, Forgot to mention, although the data is stored in excels it is not in tabular. \nEach file it's basically a QA test register, consist of a unique ID, multiple parameters containing part number, date, qty and stuff like that, then it contains the amount of features measured and each feature measure can have multiple samples", "author_fullname": "t2_5ho9t8h4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I have over 70,000 excel files that I need to analyze.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zh0asy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1670604366.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670599985.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So far I&amp;#39;ve created a Python script to merge the critical data from each excel into a JSON file so every file it&amp;#39;s an object, it takes approximately half a second per excel file so I&amp;#39;m going to parse 7 thousand at a time so I doesn&amp;#39;t take the whole day. \nThe thing is that the data isn&amp;#39;t clean, so I don&amp;#39;t think JSON it&amp;#39;s the best file type for this scenario. \nHave you done something similar? Any advice?&lt;/p&gt;\n\n&lt;p&gt;Edit: Sorry, Forgot to mention, although the data is stored in excels it is not in tabular. \nEach file it&amp;#39;s basically a QA test register, consist of a unique ID, multiple parameters containing part number, date, qty and stuff like that, then it contains the amount of features measured and each feature measure can have multiple samples&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zh0asy", "is_robot_indexable": true, "report_reasons": null, "author": "Slayne_S", "discussion_type": null, "num_comments": 56, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zh0asy/i_have_over_70000_excel_files_that_i_need_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zh0asy/i_have_over_70000_excel_files_that_i_need_to/", "subreddit_subscribers": 82401, "created_utc": 1670599985.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This one seems confusing to me as if you don't run create if not exists every time then technically your batch job is not idempotent. On the other hand, it seems inelegant to have complicated table definitions etc in your batch job.\n\nFor context I'm working with pyspark jobs on databricks.", "author_fullname": "t2_18xb5x05", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you have create table jobs/pipelines seperate from regularly run update pipelines? Or do you just run create if not exists every time you run your batch jobs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zh0sb5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670601212.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This one seems confusing to me as if you don&amp;#39;t run create if not exists every time then technically your batch job is not idempotent. On the other hand, it seems inelegant to have complicated table definitions etc in your batch job.&lt;/p&gt;\n\n&lt;p&gt;For context I&amp;#39;m working with pyspark jobs on databricks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zh0sb5", "is_robot_indexable": true, "report_reasons": null, "author": "the-data-scientist", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zh0sb5/do_you_have_create_table_jobspipelines_seperate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zh0sb5/do_you_have_create_table_jobspipelines_seperate/", "subreddit_subscribers": 82401, "created_utc": 1670601212.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What advice do you have for aspiring data engineers who are just starting out in the field?", "author_fullname": "t2_3p620rl9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice For Aspiring DE's", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zgpues", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670569674.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What advice do you have for aspiring data engineers who are just starting out in the field?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "DE @ Amazon/Lyft/Author of Ace DE Interview", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zgpues", "is_robot_indexable": true, "report_reasons": null, "author": "chrisgarzon19", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/zgpues/advice_for_aspiring_des/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zgpues/advice_for_aspiring_des/", "subreddit_subscribers": 82401, "created_utc": 1670569674.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_w2y7e99", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Replacing Looker with Cube and Metabase", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_zgvvsz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 9, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/o3_3qur-Hl0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Replacing Looker with Cube and Metabase\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Replacing Looker with Cube and Metabase", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/o3_3qur-Hl0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Replacing Looker with Cube and Metabase\"&gt;&lt;/iframe&gt;", "author_name": "Cube", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/o3_3qur-Hl0/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@cube8910"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/o3_3qur-Hl0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Replacing Looker with Cube and Metabase\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/zgvvsz", "height": 200}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/YmpGAtrzB9E7h1Vk3tkK6lZ1zlaRbu2MYLbvtljxYPI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670588424.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=o3_3qur-Hl0", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hWtyNNl6WciiPeYyQJqCtdWwoHLpx_jAV7nAVzn8GDA.jpg?auto=webp&amp;s=d5aac53f42371f81fbeef23c370b1cbb18895cd9", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/hWtyNNl6WciiPeYyQJqCtdWwoHLpx_jAV7nAVzn8GDA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ccc476f4ed901ef702f24ac7a7aafbaec7313f22", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/hWtyNNl6WciiPeYyQJqCtdWwoHLpx_jAV7nAVzn8GDA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bd4958722e896d207507f1105a5ee64f59292e6c", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/hWtyNNl6WciiPeYyQJqCtdWwoHLpx_jAV7nAVzn8GDA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2db1858a5ef4affb38c8c04bea4d9fdceab50014", "width": 320, "height": 240}], "variants": {}, "id": "CJFTP2Zny9qZBWmH_kAC0Z7hc80p1yvrqY10mRzaE4Q"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "zgvvsz", "is_robot_indexable": true, "report_reasons": null, "author": "whichalps", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zgvvsz/replacing_looker_with_cube_and_metabase/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=o3_3qur-Hl0", "subreddit_subscribers": 82401, "created_utc": 1670588424.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Replacing Looker with Cube and Metabase", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/o3_3qur-Hl0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Replacing Looker with Cube and Metabase\"&gt;&lt;/iframe&gt;", "author_name": "Cube", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/o3_3qur-Hl0/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@cube8910"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2mhgth69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The new way of creating Sensors in Apache Airflow! \ud83e\udef6", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_zh096u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/QYZEqGGgvyRtgAsk1QABGdNW7bECXjuSXvyf1O8eBR0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670599872.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "linkedin.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.linkedin.com/posts/marclamberti_airflow-apacheairflow-dataengineering-activity-7006984438110670848-d-p7?utm_source=share&amp;utm_medium=member_desktop", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/oJknx6cTFRscfGdJIsTMbfqf06Fv5fmQhXj_yp80qOo.jpg?auto=webp&amp;s=5b233c2c1455e8ff462eb90e113da7221296f40f", "width": 1042, "height": 544}, "resolutions": [{"url": "https://external-preview.redd.it/oJknx6cTFRscfGdJIsTMbfqf06Fv5fmQhXj_yp80qOo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0a5f9d38fd913415726afe77428ba64ab0708533", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/oJknx6cTFRscfGdJIsTMbfqf06Fv5fmQhXj_yp80qOo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=34271b22c2e3dd27275f68a40bcf46b05a5b2b15", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/oJknx6cTFRscfGdJIsTMbfqf06Fv5fmQhXj_yp80qOo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=dd385f8fe0654c50c40bf397b220dcb4485c712b", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/oJknx6cTFRscfGdJIsTMbfqf06Fv5fmQhXj_yp80qOo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3abe88e0d983064e21d9abbe70d8a59f1dfbe316", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/oJknx6cTFRscfGdJIsTMbfqf06Fv5fmQhXj_yp80qOo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=cdcad97c501f073d584fbf374b6b7220fc593173", "width": 960, "height": 501}], "variants": {}, "id": "INVLTnqVQs_P7yaCQEoPAvOsj4Ol3PZKsrTyuWMcxSk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zh096u", "is_robot_indexable": true, "report_reasons": null, "author": "marclamberti", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zh096u/the_new_way_of_creating_sensors_in_apache_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.linkedin.com/posts/marclamberti_airflow-apacheairflow-dataengineering-activity-7006984438110670848-d-p7?utm_source=share&amp;utm_medium=member_desktop", "subreddit_subscribers": 82401, "created_utc": 1670599872.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey I have been trying to solve this issue for the past couple days. We are looking to bring in DBT and our snowflake accounts are split by environment. So we have 3 accounts (Dev, qa, prod). \n\nDoes anyone use DBT with 3 snowflake accounts? What is your branching strategy? \n\nI want to use trunk based (1 long lived branch) but I can\u2019t figure out how to do that currently. \n\nI would appreciate any help on this!", "author_fullname": "t2_1n3qfa0v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT + Snowflake Envs Account level", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zha4fc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670623385.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey I have been trying to solve this issue for the past couple days. We are looking to bring in DBT and our snowflake accounts are split by environment. So we have 3 accounts (Dev, qa, prod). &lt;/p&gt;\n\n&lt;p&gt;Does anyone use DBT with 3 snowflake accounts? What is your branching strategy? &lt;/p&gt;\n\n&lt;p&gt;I want to use trunk based (1 long lived branch) but I can\u2019t figure out how to do that currently. &lt;/p&gt;\n\n&lt;p&gt;I would appreciate any help on this!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zha4fc", "is_robot_indexable": true, "report_reasons": null, "author": "Culpgrant21", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zha4fc/dbt_snowflake_envs_account_level/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zha4fc/dbt_snowflake_envs_account_level/", "subreddit_subscribers": 82401, "created_utc": 1670623385.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "even more so for cdc type of data/streaming data without affecting its real time latency\n\nwhere/how does it fit in your data architecture", "author_fullname": "t2_epjy5nh4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how do you do anonymisation in your organisation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zh4gho", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1670610021.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670609819.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;even more so for cdc type of data/streaming data without affecting its real time latency&lt;/p&gt;\n\n&lt;p&gt;where/how does it fit in your data architecture&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zh4gho", "is_robot_indexable": true, "report_reasons": null, "author": "Spare-Youth-6874", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zh4gho/how_do_you_do_anonymisation_in_your_organisation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zh4gho/how_do_you_do_anonymisation_in_your_organisation/", "subreddit_subscribers": 82401, "created_utc": 1670609819.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone know if its possible to use Synapse Spark Pool with DBT? If so can you share your experience with that set up? I see documentation for using Synapse dedicated and seeverless SQL pool with DBT but not the Spark Pool. All the DBT Spark documentation is for databricks and AWS EMR. Any insight would help", "author_fullname": "t2_l15do6pb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT + Spark (synapse)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zh0whm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670601488.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone know if its possible to use Synapse Spark Pool with DBT? If so can you share your experience with that set up? I see documentation for using Synapse dedicated and seeverless SQL pool with DBT but not the Spark Pool. All the DBT Spark documentation is for databricks and AWS EMR. Any insight would help&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zh0whm", "is_robot_indexable": true, "report_reasons": null, "author": "Fearless_Strategy_19", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zh0whm/dbt_spark_synapse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zh0whm/dbt_spark_synapse/", "subreddit_subscribers": 82401, "created_utc": 1670601488.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I am in somewhat a tough situation. I have been offered a job offer and contract with all benefits and salary mentioned, but it's contingent on certain criteria, all which I'm fine with except for a reference from my current manager. I don't mind giving reference of my manager, but I feel like there's a risk that if I ask reference from my manager, and give notice thereafter, and if the job offer is rescinded from the new place for some reason, I will be left in a difficult situation where my manager will not trust me thereafter.\n\nHas anyone else experienced such a dilemma? HR from new place says that I can give my notice safely and just ask HR/Manager from old place for reference since all other checks (background, drugs etc.) have been done.", "author_fullname": "t2_l35gwhuh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job Offer in Writing, but Contingent on Reference From Current Manager (UK)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zh0i52", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670600485.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I am in somewhat a tough situation. I have been offered a job offer and contract with all benefits and salary mentioned, but it&amp;#39;s contingent on certain criteria, all which I&amp;#39;m fine with except for a reference from my current manager. I don&amp;#39;t mind giving reference of my manager, but I feel like there&amp;#39;s a risk that if I ask reference from my manager, and give notice thereafter, and if the job offer is rescinded from the new place for some reason, I will be left in a difficult situation where my manager will not trust me thereafter.&lt;/p&gt;\n\n&lt;p&gt;Has anyone else experienced such a dilemma? HR from new place says that I can give my notice safely and just ask HR/Manager from old place for reference since all other checks (background, drugs etc.) have been done.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "zh0i52", "is_robot_indexable": true, "report_reasons": null, "author": "Senior_Anteater4688", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zh0i52/job_offer_in_writing_but_contingent_on_reference/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zh0i52/job_offer_in_writing_but_contingent_on_reference/", "subreddit_subscribers": 82401, "created_utc": 1670600485.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What is the general consensus on where a production **database** for **Airflow** should be?\n\nI usually start an Airflow Docker container. Airflow rightfully suggests to not use SQLite, but instead switch to Postgres or Mysql. \n\nNow, from an architecture and resilience point of view:\n\n1. Should I install the RDBMS (I choose Postgres) in the same Docker container as Airflow?\n2. or should I put the database in an extra container?", "author_fullname": "t2_136crg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow DB: In the same container or a separate one?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zgy0w1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670594275.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is the general consensus on where a production &lt;strong&gt;database&lt;/strong&gt; for &lt;strong&gt;Airflow&lt;/strong&gt; should be?&lt;/p&gt;\n\n&lt;p&gt;I usually start an Airflow Docker container. Airflow rightfully suggests to not use SQLite, but instead switch to Postgres or Mysql. &lt;/p&gt;\n\n&lt;p&gt;Now, from an architecture and resilience point of view:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Should I install the RDBMS (I choose Postgres) in the same Docker container as Airflow?&lt;/li&gt;\n&lt;li&gt;or should I put the database in an extra container?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zgy0w1", "is_robot_indexable": true, "report_reasons": null, "author": "Boruroku", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zgy0w1/airflow_db_in_the_same_container_or_a_separate_one/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zgy0w1/airflow_db_in_the_same_container_or_a_separate_one/", "subreddit_subscribers": 82401, "created_utc": 1670594275.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am coming across this term called Shard when I was reading some Docs on Pub/Sub in GCP and wanted to know what exactly is this? I have read some articles which I found on google. But can some one explain this to me in easy terms.   \nThanks in Advance.", "author_fullname": "t2_76h7jr47", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is a Shard?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zh4uqs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670610718.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am coming across this term called Shard when I was reading some Docs on Pub/Sub in GCP and wanted to know what exactly is this? I have read some articles which I found on google. But can some one explain this to me in easy terms.&lt;br/&gt;\nThanks in Advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zh4uqs", "is_robot_indexable": true, "report_reasons": null, "author": "s1va1209", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zh4uqs/what_is_a_shard/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zh4uqs/what_is_a_shard/", "subreddit_subscribers": 82401, "created_utc": 1670610718.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I just started my first DE job and am the only DE here. I'm trying to work my way through DE courses to architect something up which I'm currently building as a demo. I'm working with a pretty much non-existent senior DE who doesn't have much technical or programming knowledge but rather is a manager. \n\nI'm here for 3 months now and I'm quite unhappy as I thought I'd have better mentorship and leadership however, it really is a one man band here. I'm unsure as to whether to find a new job or not now. What should I do?", "author_fullname": "t2_tgwctzuo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm a junior/grad, is it normal for me to be the ONLY data engineer in a company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zgvc4r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670586909.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just started my first DE job and am the only DE here. I&amp;#39;m trying to work my way through DE courses to architect something up which I&amp;#39;m currently building as a demo. I&amp;#39;m working with a pretty much non-existent senior DE who doesn&amp;#39;t have much technical or programming knowledge but rather is a manager. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m here for 3 months now and I&amp;#39;m quite unhappy as I thought I&amp;#39;d have better mentorship and leadership however, it really is a one man band here. I&amp;#39;m unsure as to whether to find a new job or not now. What should I do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zgvc4r", "is_robot_indexable": true, "report_reasons": null, "author": "Icy_Requirement_3635", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zgvc4r/im_a_juniorgrad_is_it_normal_for_me_to_be_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zgvc4r/im_a_juniorgrad_is_it_normal_for_me_to_be_the/", "subreddit_subscribers": 82401, "created_utc": 1670586909.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I wonder how in demand Databricks is. I\u2019m curious cause my company offers trainings in some technologies and Databricks is one of them. However most of the job vacancies I see, at least around me, are not asking for Databricks skills/experience specifically. A lot of them mention Spark, but not Databricks specifically. I\u2019m curious to see how popular it is in this community.\n\n[View Poll](https://www.reddit.com/poll/zhcfid)", "author_fullname": "t2_8dnn00ks", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Databricks in demand? How often do you use it at your job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zhcfid", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670628728.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wonder how in demand Databricks is. I\u2019m curious cause my company offers trainings in some technologies and Databricks is one of them. However most of the job vacancies I see, at least around me, are not asking for Databricks skills/experience specifically. A lot of them mention Spark, but not Databricks specifically. I\u2019m curious to see how popular it is in this community.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/zhcfid\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zhcfid", "is_robot_indexable": true, "report_reasons": null, "author": "Se7enEl11ven", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1670887928052, "options": [{"text": "I use it Daily/Frequently", "id": "20289706"}, {"text": "I use it from time to time/Depends on projects", "id": "20289707"}, {"text": "I don\u2019t use it but already did (Old job or project)", "id": "20289708"}, {"text": "Never used it", "id": "20289709"}, {"text": "Never used it and never heard of it before", "id": "20289710"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 93, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zhcfid/is_databricks_in_demand_how_often_do_you_use_it/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/zhcfid/is_databricks_in_demand_how_often_do_you_use_it/", "subreddit_subscribers": 82401, "created_utc": 1670628728.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nPreviously, our Postgres tables were single monolithic tables. We successfully used AWS DMS to migrate the data in them toward Redshift. 1 to 1 table mappings, no problem. Smiles every day.\n\nNow, we're frowning big time!\n\nFor some of the Postgres tables that are expected to grow quickly, we've implemented partitioning. DMS clearly states that it won't work as expected under these conditions.\n\n[https://docs.aws.amazon.com/dms/latest/userguide/CHAP\\_Source.PostgreSQL.html#CHAP\\_Source.PostgreSQL.Limitations](https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Source.PostgreSQL.html#CHAP_Source.PostgreSQL.Limitations)\n\nThe root cause of the incompatibilities is that the Postgres WAL entries are no longer associated with the top-level table, but rather ONLY with the partition tables underneath. This has several undesired side-effects, and supports what is said in the AWS documentation.\n\nWhile we've mangled DMS to jankily work here, it is not robust in this scenario.\n\nPlease would you clever folks help me tackle this specific migration problem? If I can provide any more info, I'd be happy to.\n\nEDIT: I should mention what we've tried. We have tried or considered several things.\n\n1. A scheduled Glue job? We're comfortable with Glue, but are attracted to no-code solutions for this. We'd accept Glue, we just haven't yet tried it here.\n2. MSK Connect? We've tried MSK Connect, sending data to S3 rather than Redshift (leaving the S3 -&gt; Redshift problem for later). Seems to work well. It does incremental batches based on our 'updated\\_at' field. There are some concerns about performance and/or whether this is the right approach. \n3. Debezium? Being WAL-based, we feel it will suffer the same fate as DMS.", "author_fullname": "t2_3aird6b7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Migrating Postgres \\w Paritioned Tables to Redshift", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zhbd7z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1670626715.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670626268.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;Previously, our Postgres tables were single monolithic tables. We successfully used AWS DMS to migrate the data in them toward Redshift. 1 to 1 table mappings, no problem. Smiles every day.&lt;/p&gt;\n\n&lt;p&gt;Now, we&amp;#39;re frowning big time!&lt;/p&gt;\n\n&lt;p&gt;For some of the Postgres tables that are expected to grow quickly, we&amp;#39;ve implemented partitioning. DMS clearly states that it won&amp;#39;t work as expected under these conditions.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Source.PostgreSQL.html#CHAP_Source.PostgreSQL.Limitations\"&gt;https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Source.PostgreSQL.html#CHAP_Source.PostgreSQL.Limitations&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The root cause of the incompatibilities is that the Postgres WAL entries are no longer associated with the top-level table, but rather ONLY with the partition tables underneath. This has several undesired side-effects, and supports what is said in the AWS documentation.&lt;/p&gt;\n\n&lt;p&gt;While we&amp;#39;ve mangled DMS to jankily work here, it is not robust in this scenario.&lt;/p&gt;\n\n&lt;p&gt;Please would you clever folks help me tackle this specific migration problem? If I can provide any more info, I&amp;#39;d be happy to.&lt;/p&gt;\n\n&lt;p&gt;EDIT: I should mention what we&amp;#39;ve tried. We have tried or considered several things.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;A scheduled Glue job? We&amp;#39;re comfortable with Glue, but are attracted to no-code solutions for this. We&amp;#39;d accept Glue, we just haven&amp;#39;t yet tried it here.&lt;/li&gt;\n&lt;li&gt;MSK Connect? We&amp;#39;ve tried MSK Connect, sending data to S3 rather than Redshift (leaving the S3 -&amp;gt; Redshift problem for later). Seems to work well. It does incremental batches based on our &amp;#39;updated_at&amp;#39; field. There are some concerns about performance and/or whether this is the right approach. &lt;/li&gt;\n&lt;li&gt;Debezium? Being WAL-based, we feel it will suffer the same fate as DMS.&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zhbd7z", "is_robot_indexable": true, "report_reasons": null, "author": "agsilvio", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zhbd7z/migrating_postgres_w_paritioned_tables_to_redshift/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zhbd7z/migrating_postgres_w_paritioned_tables_to_redshift/", "subreddit_subscribers": 82401, "created_utc": 1670626268.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m trying to understand what\u2019s the best way to troubleshoot and debug data inconsistency in prod or downstream applications. \n\nDefinitely live debugging and tinkering around prod data is not an option, although I\u2019m guilty of having done that on few occasions. \n\nWhat do you folks do? What does the process look like? Reproducing is not exactly possible bcz the state of data keeps changing and you never know which data caused the error. \n\nOne rogue way of dealing with it is blindly rerunning that pipeline hoping and praying it writes clean data this time. \n\nHow do you troubleshoot data issues in prod?", "author_fullname": "t2_8r6amwln", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Debugging data errors or inconsistencies in downstream dashboards", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zgxm83", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670593177.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying to understand what\u2019s the best way to troubleshoot and debug data inconsistency in prod or downstream applications. &lt;/p&gt;\n\n&lt;p&gt;Definitely live debugging and tinkering around prod data is not an option, although I\u2019m guilty of having done that on few occasions. &lt;/p&gt;\n\n&lt;p&gt;What do you folks do? What does the process look like? Reproducing is not exactly possible bcz the state of data keeps changing and you never know which data caused the error. &lt;/p&gt;\n\n&lt;p&gt;One rogue way of dealing with it is blindly rerunning that pipeline hoping and praying it writes clean data this time. &lt;/p&gt;\n\n&lt;p&gt;How do you troubleshoot data issues in prod?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zgxm83", "is_robot_indexable": true, "report_reasons": null, "author": "money_noob_007", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zgxm83/debugging_data_errors_or_inconsistencies_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zgxm83/debugging_data_errors_or_inconsistencies_in/", "subreddit_subscribers": 82401, "created_utc": 1670593177.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tutorial: Multi-Table Transactions on the Lakehouse \u2013 Enabled by Dremio Arctic", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_zgv89y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/q5-aSKAzjU-CqI2KRGxhX1sFkncEcNbrqUmQ7DhIgR8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670586601.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dremio.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.dremio.com/blog/multi-table-transactions-on-the-lakehouse-enabled-by-dremio-arctic/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-STl7dV3co2QunLN9qv77qAjg6DlJj4RxCYeZzRo9Gw.jpg?auto=webp&amp;s=677cfd2acf5f5314a32e08944e0951a1f33653f6", "width": 1201, "height": 629}, "resolutions": [{"url": "https://external-preview.redd.it/-STl7dV3co2QunLN9qv77qAjg6DlJj4RxCYeZzRo9Gw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=44822d4e1e6d4168f34ab6113de12db8eb8237fa", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/-STl7dV3co2QunLN9qv77qAjg6DlJj4RxCYeZzRo9Gw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8ca6804f857e3ac1eeb4cdfdefda2979d98a202c", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/-STl7dV3co2QunLN9qv77qAjg6DlJj4RxCYeZzRo9Gw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ac4453013c6e922f576686e26eaf4f02abc504ae", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/-STl7dV3co2QunLN9qv77qAjg6DlJj4RxCYeZzRo9Gw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fba584a4d0519c1a5d41c1cf6ab8d567abea9fac", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/-STl7dV3co2QunLN9qv77qAjg6DlJj4RxCYeZzRo9Gw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c2b91903c24fc515615dda409ebf8c60adcbf5c4", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/-STl7dV3co2QunLN9qv77qAjg6DlJj4RxCYeZzRo9Gw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=28a6061daf8a4c19c2cbe3e8970f1b8bdc882434", "width": 1080, "height": 565}], "variants": {}, "id": "LBpbW9OLTwQyp-VamoofyQF1Ff8aV6ZdpWiaa-KyRig"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zgv89y", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zgv89y/tutorial_multitable_transactions_on_the_lakehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.dremio.com/blog/multi-table-transactions-on-the-lakehouse-enabled-by-dremio-arctic/", "subreddit_subscribers": 82401, "created_utc": 1670586601.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Long Story Short: Company sent laptop early before joining - Later, I clearly mentioned I am not joining and asked them how to return it. Both on call and mail, but no response.\n\nIt's been almost 2 years, can I start using the laptop? Is there anyway they track it? \n\nPS: It's Windows laptop       \n\n[View Poll](https://www.reddit.com/poll/zgv4a8)", "author_fullname": "t2_8h8kwca0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can I Start using Startup Laptop? It's been 2 years and they did not collet it!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zgv4a8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670586289.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Long Story Short: Company sent laptop early before joining - Later, I clearly mentioned I am not joining and asked them how to return it. Both on call and mail, but no response.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s been almost 2 years, can I start using the laptop? Is there anyway they track it? &lt;/p&gt;\n\n&lt;p&gt;PS: It&amp;#39;s Windows laptop       &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/zgv4a8\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zgv4a8", "is_robot_indexable": true, "report_reasons": null, "author": "Rude-Veterinarian-45", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1670845489290, "options": [{"text": "Start Using, its been 2 years", "id": "20279087"}, {"text": "Don't Use it, they can track", "id": "20279088"}, {"text": "Other, please comment", "id": "20279089"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 99, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zgv4a8/can_i_start_using_startup_laptop_its_been_2_years/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/zgv4a8/can_i_start_using_startup_laptop_its_been_2_years/", "subreddit_subscribers": 82401, "created_utc": 1670586289.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have mostly been a full-stack developer with experience in cloud technology as well. This is my first big work involving data pipeline.\n\nProblem - currently data scientists run ad-hoc sqoop jobs to query data periodically. We need to schedule the same using airflow. We need to store the query results in s3 bucket as it is used for ML mod training.\n\nConstraint- we have to run these airflow jobs to trigger queries with kubeOperator, which I don\u2019t think can handle millions of records that are generated everyday. Much worse if it has to be done monthly. \n\nHow should we go about it? Use the airflow job to remotely run sqoop job? Or use Kafka connect ( have no clue about it) or something else?", "author_fullname": "t2_yn202", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moving from ad-hoc sqoop job to Airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zgtata", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670580827.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have mostly been a full-stack developer with experience in cloud technology as well. This is my first big work involving data pipeline.&lt;/p&gt;\n\n&lt;p&gt;Problem - currently data scientists run ad-hoc sqoop jobs to query data periodically. We need to schedule the same using airflow. We need to store the query results in s3 bucket as it is used for ML mod training.&lt;/p&gt;\n\n&lt;p&gt;Constraint- we have to run these airflow jobs to trigger queries with kubeOperator, which I don\u2019t think can handle millions of records that are generated everyday. Much worse if it has to be done monthly. &lt;/p&gt;\n\n&lt;p&gt;How should we go about it? Use the airflow job to remotely run sqoop job? Or use Kafka connect ( have no clue about it) or something else?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zgtata", "is_robot_indexable": true, "report_reasons": null, "author": "litti_wala", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zgtata/moving_from_adhoc_sqoop_job_to_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zgtata/moving_from_adhoc_sqoop_job_to_airflow/", "subreddit_subscribers": 82401, "created_utc": 1670580827.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Ever wonder what BI tools other teams are using? We've gathered data from over 250 data teams and outlined the most popular BI tools used by Secoda customers in 2022: https://www.secoda.co/blog/top-5-business-intelligence-tools", "author_fullname": "t2_aiinah9q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Top 5 business intelligence tools (based on over 250 data teams)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zh768a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1670616241.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Ever wonder what BI tools other teams are using? We&amp;#39;ve gathered data from over 250 data teams and outlined the most popular BI tools used by Secoda customers in 2022: &lt;a href=\"https://www.secoda.co/blog/top-5-business-intelligence-tools\"&gt;https://www.secoda.co/blog/top-5-business-intelligence-tools&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ObfKZ_8zvF5Srb8sORcNGuFAE3Pm1xV-29YAl3ZpLU0.jpg?auto=webp&amp;s=4a7be7b670f7bcda1ada014d20855437305db957", "width": 767, "height": 448}, "resolutions": [{"url": "https://external-preview.redd.it/ObfKZ_8zvF5Srb8sORcNGuFAE3Pm1xV-29YAl3ZpLU0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1d26e8292fce31a830851ce27b2ec0ce70efc60c", "width": 108, "height": 63}, {"url": "https://external-preview.redd.it/ObfKZ_8zvF5Srb8sORcNGuFAE3Pm1xV-29YAl3ZpLU0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c026311ccad9c2794d7fedd61ef5fe6f7070e499", "width": 216, "height": 126}, {"url": "https://external-preview.redd.it/ObfKZ_8zvF5Srb8sORcNGuFAE3Pm1xV-29YAl3ZpLU0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4cbbf6b73c3a26e61840a55fda9ed4a4eb09eda3", "width": 320, "height": 186}, {"url": "https://external-preview.redd.it/ObfKZ_8zvF5Srb8sORcNGuFAE3Pm1xV-29YAl3ZpLU0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=21032ca66176918321a8b632697179c12a1b9849", "width": 640, "height": 373}], "variants": {}, "id": "3xy2BqEaM_UDTGtVbw-A3eDKj-kygQF7HPVI6AuGkz4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zh768a", "is_robot_indexable": true, "report_reasons": null, "author": "secodaHQ", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zh768a/top_5_business_intelligence_tools_based_on_over/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zh768a/top_5_business_intelligence_tools_based_on_over/", "subreddit_subscribers": 82401, "created_utc": 1670616241.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_12wi0d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sync all your cloud infrastructure assets into BigQuery", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_zgrju3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/aBlm9vnhUvh0PD-3ARChL4j4iHnx5FMfh-tXTxTdBN0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670575262.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "cloudquery.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.cloudquery.io/blog/announcing-cloudquery-bigquery-destination", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YlfL8-AOuil8-IpsluyfwlK_5hNXotVCNv9P7zsIHFE.jpg?auto=webp&amp;s=06467692df481293b758d26594c5147b6b63b2d3", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/YlfL8-AOuil8-IpsluyfwlK_5hNXotVCNv9P7zsIHFE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=09e0a082fc3485b4df92817cddf61ae7250f7a0f", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/YlfL8-AOuil8-IpsluyfwlK_5hNXotVCNv9P7zsIHFE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d34f56f7edab68efc36c640112d35c2e0dfbad2c", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/YlfL8-AOuil8-IpsluyfwlK_5hNXotVCNv9P7zsIHFE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=86a13c5fe8e59368937e51a4ca938f940b4b8473", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/YlfL8-AOuil8-IpsluyfwlK_5hNXotVCNv9P7zsIHFE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=04d351047bf2404a61299a9c3475f8946951dcb6", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/YlfL8-AOuil8-IpsluyfwlK_5hNXotVCNv9P7zsIHFE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1674eb00a4ab095c47c66c85f5879506f7d3c201", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/YlfL8-AOuil8-IpsluyfwlK_5hNXotVCNv9P7zsIHFE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=15f9459140fe2df83a60e925845bb43764059855", "width": 1080, "height": 565}], "variants": {}, "id": "J78hqafJ5qywvaZDhu92dGfhCECysqtNi7F3y4mdOv4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "zgrju3", "is_robot_indexable": true, "report_reasons": null, "author": "jekapats", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zgrju3/sync_all_your_cloud_infrastructure_assets_into/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.cloudquery.io/blog/announcing-cloudquery-bigquery-destination", "subreddit_subscribers": 82401, "created_utc": 1670575262.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_84xrtbqe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "12 Things You Need to Know to Become a Better Data Engineer in 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 79, "top_awarded_type": null, "hide_score": false, "name": "t3_zgz4ni", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/2o6lzN7ghCNOG0o2D-2G9iBBe-geR5bSvhiP05MC_5E.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670597074.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "airbyte.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://airbyte.com/blog/becoming-a-data-engineer-2023", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/VyrnDv1FRK1NSGjHrJplPcW6P3yfjBizZ6tMpJ0oE_A.jpg?auto=webp&amp;s=5ba71dbc3bf1c81068203680c20655c7c739161c", "width": 1270, "height": 720}, "resolutions": [{"url": "https://external-preview.redd.it/VyrnDv1FRK1NSGjHrJplPcW6P3yfjBizZ6tMpJ0oE_A.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=598014d76fe87bcbe5425ba224b18d0f33a28122", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/VyrnDv1FRK1NSGjHrJplPcW6P3yfjBizZ6tMpJ0oE_A.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b9984d4cae382c7bf02ec161f01d2fae46896e39", "width": 216, "height": 122}, {"url": "https://external-preview.redd.it/VyrnDv1FRK1NSGjHrJplPcW6P3yfjBizZ6tMpJ0oE_A.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bc40d791ac2124a074a434a08d95dd542b1dcf0f", "width": 320, "height": 181}, {"url": "https://external-preview.redd.it/VyrnDv1FRK1NSGjHrJplPcW6P3yfjBizZ6tMpJ0oE_A.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1efa22c91e893b9e3fb57d86f42617aa8f17ca93", "width": 640, "height": 362}, {"url": "https://external-preview.redd.it/VyrnDv1FRK1NSGjHrJplPcW6P3yfjBizZ6tMpJ0oE_A.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=aa2628ef1bddd819537f242ecec216bfcfd8c3a1", "width": 960, "height": 544}, {"url": "https://external-preview.redd.it/VyrnDv1FRK1NSGjHrJplPcW6P3yfjBizZ6tMpJ0oE_A.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ca31c42595b399f0305503027be9716588ac6c37", "width": 1080, "height": 612}], "variants": {}, "id": "5uuiIe-mg11I_ivnIzUZgADA_tpO8q63QPFtqoL_G48"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zgz4ni", "is_robot_indexable": true, "report_reasons": null, "author": "sspaeti", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zgz4ni/12_things_you_need_to_know_to_become_a_better/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://airbyte.com/blog/becoming-a-data-engineer-2023", "subreddit_subscribers": 82401, "created_utc": 1670597074.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What's the salary I can quote for a remote position in the US (im not in us). Please share the figure. Thanks\n\n\n\nYoe: 5+ \nTech stack: Data engineering \nLocation: Remote\n\n[View Poll](https://www.reddit.com/poll/zgs1g8)", "author_fullname": "t2_8h8kwca0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What monthly salary $ should I quote for remote position (US Company)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zgs1g8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1670580334.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670576873.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What&amp;#39;s the salary I can quote for a remote position in the US (im not in us). Please share the figure. Thanks&lt;/p&gt;\n\n&lt;p&gt;Yoe: 5+ \nTech stack: Data engineering \nLocation: Remote&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/zgs1g8\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zgs1g8", "is_robot_indexable": true, "report_reasons": null, "author": "Rude-Veterinarian-45", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1670749673337, "options": [{"text": "&lt;2k USD", "id": "20277487"}, {"text": "3k USD", "id": "20277488"}, {"text": "&gt;3k USD", "id": "20277489"}, {"text": "Others pls comment down", "id": "20277490"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 437, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zgs1g8/what_monthly_salary_should_i_quote_for_remote/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/zgs1g8/what_monthly_salary_should_i_quote_for_remote/", "subreddit_subscribers": 82401, "created_utc": 1670576873.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What if I tell you that there is a no-code portal where you sign up, turn a few knobs and you can start dropping excel and csvs and they are queryable or your existing dashboard is already populated?  \nNothing fancy, drag and drop csvs, populate data and refresh reports. Would your small to medium business buy this?", "author_fullname": "t2_ya36aq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A no/low code data warehouse SaaS - would your org use it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zh8n3m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670619744.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What if I tell you that there is a no-code portal where you sign up, turn a few knobs and you can start dropping excel and csvs and they are queryable or your existing dashboard is already populated?&lt;br/&gt;\nNothing fancy, drag and drop csvs, populate data and refresh reports. Would your small to medium business buy this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zh8n3m", "is_robot_indexable": true, "report_reasons": null, "author": "droaak", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zh8n3m/a_nolow_code_data_warehouse_saas_would_your_org/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zh8n3m/a_nolow_code_data_warehouse_saas_would_your_org/", "subreddit_subscribers": 82401, "created_utc": 1670619744.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}