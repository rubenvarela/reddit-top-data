{"kind": "Listing", "data": {"after": null, "dist": 24, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm ok with take home programming tests and leetcode.  However, I noticed during my last job search that every company that had a take home project that I completed ended up rejecting me.\n\n\n\n\nIt almost seems like a better time investment to spend 3-5 hours studying leetcode than doing a take home project.", "author_fullname": "t2_3v6ob2bf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone else turn down interviews that involve a take home project?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zlao51", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 56, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 56, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670974196.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m ok with take home programming tests and leetcode.  However, I noticed during my last job search that every company that had a take home project that I completed ended up rejecting me.&lt;/p&gt;\n\n&lt;p&gt;It almost seems like a better time investment to spend 3-5 hours studying leetcode than doing a take home project.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zlao51", "is_robot_indexable": true, "report_reasons": null, "author": "data_preprocessing", "discussion_type": null, "num_comments": 53, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zlao51/does_anyone_else_turn_down_interviews_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zlao51/does_anyone_else_turn_down_interviews_that/", "subreddit_subscribers": 82933, "created_utc": 1670974196.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been reading the data warehouse toolkit as well as data engineering blog posts but I'm still having a hard time fleshing out a full picture of how everything integrates. Are there any really good resources that show a \"real-world\" data pipeline being built out? From modeling the data to designing the ETL/ELT pipeline to distributing the data via a data mart or dataset?  \n\nIdeally, a guide or two that show how this would be applied on-prem as well as in the cloud would be helpful.", "author_fullname": "t2_nhdew", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any really good end-to-end walkthroughs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zltid3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 57, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 57, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671030752.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been reading the data warehouse toolkit as well as data engineering blog posts but I&amp;#39;m still having a hard time fleshing out a full picture of how everything integrates. Are there any really good resources that show a &amp;quot;real-world&amp;quot; data pipeline being built out? From modeling the data to designing the ETL/ELT pipeline to distributing the data via a data mart or dataset?  &lt;/p&gt;\n\n&lt;p&gt;Ideally, a guide or two that show how this would be applied on-prem as well as in the cloud would be helpful.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zltid3", "is_robot_indexable": true, "report_reasons": null, "author": "MonkeyMaster64", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zltid3/any_really_good_endtoend_walkthroughs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zltid3/any_really_good_endtoend_walkthroughs/", "subreddit_subscribers": 82933, "created_utc": 1671030752.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When I had my first analyst job 11 years ago, I was at a microsoft shop. I learned SQL on MS SQL Server 2012. To this day, I think it was the best console I've ever used for just writing and executing queries.I use pycharm as my IDE which works great for DBT development but the console sucks. The snowflake browser-based console slows me down. I don't need an IDE that is for hardcore software development. I'd like to get something that is designed for SQL queries--has a good database object explorer and possibly saves query history. A feature I have been searching for since SQL Server is just the ability to execute multiple statements at the same time and see all the results in the output pane at once. Cost is not an issue; I can get a license. Suggestions?", "author_fullname": "t2_yxzao", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best SQL Console?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zlh26w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670991068.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When I had my first analyst job 11 years ago, I was at a microsoft shop. I learned SQL on MS SQL Server 2012. To this day, I think it was the best console I&amp;#39;ve ever used for just writing and executing queries.I use pycharm as my IDE which works great for DBT development but the console sucks. The snowflake browser-based console slows me down. I don&amp;#39;t need an IDE that is for hardcore software development. I&amp;#39;d like to get something that is designed for SQL queries--has a good database object explorer and possibly saves query history. A feature I have been searching for since SQL Server is just the ability to execute multiple statements at the same time and see all the results in the output pane at once. Cost is not an issue; I can get a license. Suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zlh26w", "is_robot_indexable": true, "report_reasons": null, "author": "mrp4434", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zlh26w/best_sql_console/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zlh26w/best_sql_console/", "subreddit_subscribers": 82933, "created_utc": 1670991068.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_uyypntfr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recently laid off, please review my Resume and throw me some hard truths! Interested in Data Engineer/Science roles. Thanks! (~1 Year of FT experience)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_zlvtte", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/iYD6KdXdbhHPCKltV-AGkcIjduCshG_YsZ7bpCSm_-I.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671036375.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/wlb5dn0k7w5a1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/wlb5dn0k7w5a1.png?auto=webp&amp;v=enabled&amp;s=66b1e2c0cf90be74b58a960b8e9fb3ecb9140fdb", "width": 1009, "height": 1287}, "resolutions": [{"url": "https://preview.redd.it/wlb5dn0k7w5a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=09708a9db65ec6a152c6dd8763eef769224b27a9", "width": 108, "height": 137}, {"url": "https://preview.redd.it/wlb5dn0k7w5a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e6c9db823f22f16a432a7d97d00b9d06f9f701b6", "width": 216, "height": 275}, {"url": "https://preview.redd.it/wlb5dn0k7w5a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b50be64de44ba703ed7af7962cfb3e6e20869dae", "width": 320, "height": 408}, {"url": "https://preview.redd.it/wlb5dn0k7w5a1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ba91ca86d6d00c0c42428b173771a3d45741d5b3", "width": 640, "height": 816}, {"url": "https://preview.redd.it/wlb5dn0k7w5a1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b2c4ff91547d8f55720d586a86d00302cb80f0ab", "width": 960, "height": 1224}], "variants": {}, "id": "KpKLL9X-Sku68vV72ubLy39J3ApK8l-g4SlT_cJxp9M"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "zlvtte", "is_robot_indexable": true, "report_reasons": null, "author": "throw_me_away_2424", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zlvtte/recently_laid_off_please_review_my_resume_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/wlb5dn0k7w5a1.png", "subreddit_subscribers": 82933, "created_utc": 1671036375.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I am trying to switch to data engineering after taking a break from my career. I was thinking of creating a portfolio project using data from a subreddit. I wanted to use the Reddit API for the same. Can I use the free version of the API given the project will be available publically and I won't benefit financially from it?", "author_fullname": "t2_6960i650", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using Reddit API for a portfolio project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zln02b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671011674.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am trying to switch to data engineering after taking a break from my career. I was thinking of creating a portfolio project using data from a subreddit. I wanted to use the Reddit API for the same. Can I use the free version of the API given the project will be available publically and I won&amp;#39;t benefit financially from it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zln02b", "is_robot_indexable": true, "report_reasons": null, "author": "TheBrownViking20", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zln02b/using_reddit_api_for_a_portfolio_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zln02b/using_reddit_api_for_a_portfolio_project/", "subreddit_subscribers": 82933, "created_utc": 1671011674.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Did you know that the bio mass of all bacteria is way bigger then the bio mass of all human? I wonder if the same relation is or will be true for IoT and server calculation power. \n\nWhile Server are obviously so powerful compared to IoT, I wonder if the sheer amount of the devices will compensate that. \n\nI am working with IoT devices and we currently do all the hard calculation on a server but I was thinking about the fact that we are wasting capacity on the devices. If the utilization is just 20% why not using the rest for stuff we are currently doing server-side. Maybe we also could stream data back from server to device for calculation jobs. \n\nIf that would work, I wonder how I can design a good DE architecture that accounts for that functionality.", "author_fullname": "t2_s3omzbn3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "IoT vs Server Computing Power", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zlkr8j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671003124.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Did you know that the bio mass of all bacteria is way bigger then the bio mass of all human? I wonder if the same relation is or will be true for IoT and server calculation power. &lt;/p&gt;\n\n&lt;p&gt;While Server are obviously so powerful compared to IoT, I wonder if the sheer amount of the devices will compensate that. &lt;/p&gt;\n\n&lt;p&gt;I am working with IoT devices and we currently do all the hard calculation on a server but I was thinking about the fact that we are wasting capacity on the devices. If the utilization is just 20% why not using the rest for stuff we are currently doing server-side. Maybe we also could stream data back from server to device for calculation jobs. &lt;/p&gt;\n\n&lt;p&gt;If that would work, I wonder how I can design a good DE architecture that accounts for that functionality.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zlkr8j", "is_robot_indexable": true, "report_reasons": null, "author": "ZenCoding", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zlkr8j/iot_vs_server_computing_power/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zlkr8j/iot_vs_server_computing_power/", "subreddit_subscribers": 82933, "created_utc": 1671003124.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_r6aazfpz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Data Bus: a helpful pattern for data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_zljykk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/xc2oOcKlC56QpG9ceRCnfgfIa-FYfwTM-cQWmvf8YsE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671000277.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "leblancfg.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://leblancfg.com/data-bus-pattern-for-data-engineering.html", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/IAin_BO0uoU85zBrMwe-V0pGua4DeradcEfq_pr9kZY.jpg?auto=webp&amp;v=enabled&amp;s=5f5a43f44e9980937b2260e3484b64fe1a335fbb", "width": 400, "height": 400}, "resolutions": [{"url": "https://external-preview.redd.it/IAin_BO0uoU85zBrMwe-V0pGua4DeradcEfq_pr9kZY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a782d98084acb8436dfc533764ec333629e66a28", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/IAin_BO0uoU85zBrMwe-V0pGua4DeradcEfq_pr9kZY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e44ce5e2c788193c859a80b218cb8fa03211ffff", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/IAin_BO0uoU85zBrMwe-V0pGua4DeradcEfq_pr9kZY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ca88872bdf0526ad369cb1457d0293f9dfffb8cb", "width": 320, "height": 320}], "variants": {}, "id": "HqKsU0Z01QouRbVlVBlldvDv37FPvmA0Ckt6IkisE2w"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zljykk", "is_robot_indexable": true, "report_reasons": null, "author": "Realistic-Cap6526", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zljykk/the_data_bus_a_helpful_pattern_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://leblancfg.com/data-bus-pattern-for-data-engineering.html", "subreddit_subscribers": 82933, "created_utc": 1671000277.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "# 1. Define schemas.\n\nA schema defines the structure of your data. The fields and types the other side expects to receive. Having well-defined schemas and a single source of truth that store all your different models is a must as you scale and more interfaces join the party and request to consume from different data sources.\n\nAs schema changes will be requested, you would only need to perform the change once. \n\n# 2. Enforce.\n\nYou have to govern, or you will lose control. If you made a data contract both theoretically or technically, you need to enforce it.  \nEnsure data will not reach clients in a way they didn\u2019t ask for.\n\n# 3. Dedicated identity per client.\n\nAs your organization grows, more and more \u201chands\u201d will request to interact with the ingested data. It can be different clients, applications, and/or stakeholders.  \nMake sure each client receives a unique identity that can be traced and monitored, and in case some data-level / infra-level occurred, you would know who got affected, from which team, and the business impact instantly. It will help reach root-cause much faster than shooting slack messages and emails to the entire organization.\n\n# 4. Auditing.\n\nIn a federated architecture and data pipelines, where multiple domains, teams, and clients are often intertwined, one configuration change can create a chain of reactions that ultimately will crash the entire process. Auditing is crucial to ensure you approach the upstream rather than the middle.\n\n# 5. Notifications.\n\nLast but not least, notifications. Don\u2019t react when your staging environment or your tables/documents are already unaligned, or backends start to crash. Make sure you have notifications configured in every step of your pipeline. You get notified immediately if something goes wrong and data is not ingested as it should. Combining dedicated identity with auditing and a clear notification will enable you to sleep better. In case you awaken in the middle of the night, it will be for a short time and with all the information needed to fix it.\n\n&amp;#x200B;\n\nSource: [https://medium.com/memphis-dev/five-methods-to-increase-governance-over-your-data-clients-4eb7423510d6](https://medium.com/memphis-dev/five-methods-to-increase-governance-over-your-data-clients-4eb7423510d6)", "author_fullname": "t2_bqjrmnud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Five methods to increase governance over your data clients", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zluj0s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1671033219.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;1. Define schemas.&lt;/h1&gt;\n\n&lt;p&gt;A schema defines the structure of your data. The fields and types the other side expects to receive. Having well-defined schemas and a single source of truth that store all your different models is a must as you scale and more interfaces join the party and request to consume from different data sources.&lt;/p&gt;\n\n&lt;p&gt;As schema changes will be requested, you would only need to perform the change once. &lt;/p&gt;\n\n&lt;h1&gt;2. Enforce.&lt;/h1&gt;\n\n&lt;p&gt;You have to govern, or you will lose control. If you made a data contract both theoretically or technically, you need to enforce it.&lt;br/&gt;\nEnsure data will not reach clients in a way they didn\u2019t ask for.&lt;/p&gt;\n\n&lt;h1&gt;3. Dedicated identity per client.&lt;/h1&gt;\n\n&lt;p&gt;As your organization grows, more and more \u201chands\u201d will request to interact with the ingested data. It can be different clients, applications, and/or stakeholders.&lt;br/&gt;\nMake sure each client receives a unique identity that can be traced and monitored, and in case some data-level / infra-level occurred, you would know who got affected, from which team, and the business impact instantly. It will help reach root-cause much faster than shooting slack messages and emails to the entire organization.&lt;/p&gt;\n\n&lt;h1&gt;4. Auditing.&lt;/h1&gt;\n\n&lt;p&gt;In a federated architecture and data pipelines, where multiple domains, teams, and clients are often intertwined, one configuration change can create a chain of reactions that ultimately will crash the entire process. Auditing is crucial to ensure you approach the upstream rather than the middle.&lt;/p&gt;\n\n&lt;h1&gt;5. Notifications.&lt;/h1&gt;\n\n&lt;p&gt;Last but not least, notifications. Don\u2019t react when your staging environment or your tables/documents are already unaligned, or backends start to crash. Make sure you have notifications configured in every step of your pipeline. You get notified immediately if something goes wrong and data is not ingested as it should. Combining dedicated identity with auditing and a clear notification will enable you to sleep better. In case you awaken in the middle of the night, it will be for a short time and with all the information needed to fix it.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Source: &lt;a href=\"https://medium.com/memphis-dev/five-methods-to-increase-governance-over-your-data-clients-4eb7423510d6\"&gt;https://medium.com/memphis-dev/five-methods-to-increase-governance-over-your-data-clients-4eb7423510d6&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/r63d0peK7lR4hC-TgNGij3atmde2nRzwT52TjWbR1FE.jpg?auto=webp&amp;v=enabled&amp;s=050b22d042d9f08091aad6e45e7e846a107a1a5f", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/r63d0peK7lR4hC-TgNGij3atmde2nRzwT52TjWbR1FE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5d0435823d970aaec969980f55114d8e64723c8d", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/r63d0peK7lR4hC-TgNGij3atmde2nRzwT52TjWbR1FE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6cad6a166590b366b3eb10440f225fc290909c79", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/r63d0peK7lR4hC-TgNGij3atmde2nRzwT52TjWbR1FE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=63288dbd31e8da3a4f47eb9cc9aa1bd74b802010", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/r63d0peK7lR4hC-TgNGij3atmde2nRzwT52TjWbR1FE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c75e2c7bb99042534b77d93f834fe12084e19a5b", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/r63d0peK7lR4hC-TgNGij3atmde2nRzwT52TjWbR1FE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=22216e9dc1bad0db47cb1e35ff37a447c7cb4627", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/r63d0peK7lR4hC-TgNGij3atmde2nRzwT52TjWbR1FE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=189ed93707cbe92fad81537b9cdfa3f16b417c7d", "width": 1080, "height": 607}], "variants": {}, "id": "wnRFDkKH4_zSESjf-dKgPIz6PGGNHscbt6D41poYtBM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zluj0s", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering_Bug105", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zluj0s/five_methods_to_increase_governance_over_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zluj0s/five_methods_to_increase_governance_over_your/", "subreddit_subscribers": 82933, "created_utc": 1671033219.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I'm preparing a presentation about Hadoop and Spark and I have to explain a use case where hadoop only is used and another use case where spark only is used , I've been looking in the internet but I didn't find an explanation of how exactly hadoop and spark has been used.\n\nAny help please ?", "author_fullname": "t2_byxenypn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hadoop and Spark use cases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zla8iv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670973155.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;m preparing a presentation about Hadoop and Spark and I have to explain a use case where hadoop only is used and another use case where spark only is used , I&amp;#39;ve been looking in the internet but I didn&amp;#39;t find an explanation of how exactly hadoop and spark has been used.&lt;/p&gt;\n\n&lt;p&gt;Any help please ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zla8iv", "is_robot_indexable": true, "report_reasons": null, "author": "AB3NZ", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zla8iv/hadoop_and_spark_use_cases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zla8iv/hadoop_and_spark_use_cases/", "subreddit_subscribers": 82933, "created_utc": 1670973155.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a recent CS graduate and I managed to work with a few languages to keep myself open to whichever route I ended up committing to. Therefore, at uni, I learnt (not mastered): \n\n* Python\n* Java\n* PHP \n* MySQL\n* HTML and CSS\n* JavaScript\n\nThe main issue I find with my CV is that for DE roles, the most useful *languages* I could put are Python and MySQL. I was going to learn a bit of Go but I've decided to start tinkering with PySpark instead. I've played around with pandas this past year with my courses. \n\nMy Skills section isn't as good as many CVs I've seen, so not sure how to go with things. I'm thinking of removing HTML, CSS and JavaScript from the list of languages, perhaps PHP too, which leaves me with just Python, Java and MySQL. My Java isn't as good, so I might just end up removing it.\n\nHere is how it looks: https://imgur.com/a/vKHRUV6\n\n***\n\nTo make my life easier, what things do you guys recommend me to learn while I'm applying for jobs? \n\nI wasn't taught cloud technologies, DevOps or most technologies I'm seeing floating around as well. Again, I'm going to be learning PySpark but not sure what else I could need?", "author_fullname": "t2_5902cw6k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lack of \"Languages\" to show on CV", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zlqqu4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1671024234.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1671023952.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a recent CS graduate and I managed to work with a few languages to keep myself open to whichever route I ended up committing to. Therefore, at uni, I learnt (not mastered): &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Python&lt;/li&gt;\n&lt;li&gt;Java&lt;/li&gt;\n&lt;li&gt;PHP &lt;/li&gt;\n&lt;li&gt;MySQL&lt;/li&gt;\n&lt;li&gt;HTML and CSS&lt;/li&gt;\n&lt;li&gt;JavaScript&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The main issue I find with my CV is that for DE roles, the most useful &lt;em&gt;languages&lt;/em&gt; I could put are Python and MySQL. I was going to learn a bit of Go but I&amp;#39;ve decided to start tinkering with PySpark instead. I&amp;#39;ve played around with pandas this past year with my courses. &lt;/p&gt;\n\n&lt;p&gt;My Skills section isn&amp;#39;t as good as many CVs I&amp;#39;ve seen, so not sure how to go with things. I&amp;#39;m thinking of removing HTML, CSS and JavaScript from the list of languages, perhaps PHP too, which leaves me with just Python, Java and MySQL. My Java isn&amp;#39;t as good, so I might just end up removing it.&lt;/p&gt;\n\n&lt;p&gt;Here is how it looks: &lt;a href=\"https://imgur.com/a/vKHRUV6\"&gt;https://imgur.com/a/vKHRUV6&lt;/a&gt;&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;To make my life easier, what things do you guys recommend me to learn while I&amp;#39;m applying for jobs? &lt;/p&gt;\n\n&lt;p&gt;I wasn&amp;#39;t taught cloud technologies, DevOps or most technologies I&amp;#39;m seeing floating around as well. Again, I&amp;#39;m going to be learning PySpark but not sure what else I could need?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/LarpdkIBJEfaTF1erGpKG0rmh1TkiO7SRI-r7rvZSxI.jpg?auto=webp&amp;v=enabled&amp;s=c3d73e42521e8baf9e7da06988477e00085f46a4", "width": 687, "height": 93}, "resolutions": [{"url": "https://external-preview.redd.it/LarpdkIBJEfaTF1erGpKG0rmh1TkiO7SRI-r7rvZSxI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9b70ea58bbf092d187a2780899fc92b7b9fd30f8", "width": 108, "height": 14}, {"url": "https://external-preview.redd.it/LarpdkIBJEfaTF1erGpKG0rmh1TkiO7SRI-r7rvZSxI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=670c9ac286e382470ae8da71e3f966bea7daafb5", "width": 216, "height": 29}, {"url": "https://external-preview.redd.it/LarpdkIBJEfaTF1erGpKG0rmh1TkiO7SRI-r7rvZSxI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0c08bf615a6143cd95afdac97dd89017c66b4ee6", "width": 320, "height": 43}, {"url": "https://external-preview.redd.it/LarpdkIBJEfaTF1erGpKG0rmh1TkiO7SRI-r7rvZSxI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8cfff9f685ee9343730b83b6231bfdb158e34c26", "width": 640, "height": 86}], "variants": {}, "id": "nrQ-wZXIPnVL2QlZAo-94qukF8DcavHFWJmrrcTQcT4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zlqqu4", "is_robot_indexable": true, "report_reasons": null, "author": "a_bigdonger", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zlqqu4/lack_of_languages_to_show_on_cv/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zlqqu4/lack_of_languages_to_show_on_cv/", "subreddit_subscribers": 82933, "created_utc": 1671023952.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I am building ETL batch pipeline to transfer data from AWS RDS (MySQL) to Salesforce on daily basis. Now I am confused how should I approach this. Should I build everything locally and then deploy the container into AWS or should build my pipeline on the AWS using different services?\n\nPlease give me your suggestion.\n\nThanks!", "author_fullname": "t2_udvutrbv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Aws services or local development", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zlpbh3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "spoiler", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671019799.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I am building ETL batch pipeline to transfer data from AWS RDS (MySQL) to Salesforce on daily basis. Now I am confused how should I approach this. Should I build everything locally and then deploy the container into AWS or should build my pipeline on the AWS using different services?&lt;/p&gt;\n\n&lt;p&gt;Please give me your suggestion.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": true, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zlpbh3", "is_robot_indexable": true, "report_reasons": null, "author": "Usamacheema12345", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zlpbh3/aws_services_or_local_development/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zlpbh3/aws_services_or_local_development/", "subreddit_subscribers": 82933, "created_utc": 1671019799.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am starting a new position and need to get up to speed on this new stack:  \nPrefect - dbt - Snowflake  \nWith an emphasis on Snowflake first\n\nWhat are some good resources **that you may recommend** to learn quickly and with best-practices in mind? I can some $ for online courses\n\nbackground: extensive SQL Server, some python ETL. No dbt or orchestration tool, but plenty comfortable with yaml from docker and ci/cd tools.", "author_fullname": "t2_qhsi5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "need learning recommendations for Snowflake, dbt, prefect", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zlv893", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671034908.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am starting a new position and need to get up to speed on this new stack:&lt;br/&gt;\nPrefect - dbt - Snowflake&lt;br/&gt;\nWith an emphasis on Snowflake first&lt;/p&gt;\n\n&lt;p&gt;What are some good resources &lt;strong&gt;that you may recommend&lt;/strong&gt; to learn quickly and with best-practices in mind? I can some $ for online courses&lt;/p&gt;\n\n&lt;p&gt;background: extensive SQL Server, some python ETL. No dbt or orchestration tool, but plenty comfortable with yaml from docker and ci/cd tools.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zlv893", "is_robot_indexable": true, "report_reasons": null, "author": "NoUsernames1eft", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zlv893/need_learning_recommendations_for_snowflake_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zlv893/need_learning_recommendations_for_snowflake_dbt/", "subreddit_subscribers": 82933, "created_utc": 1671034908.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_nrfxa5al", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Get Value from Unstructured Data - Father of the Data Warehouse Bill Inmon", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_zlw3l1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/So-vd2e6WeI?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Get Value from Unstructured Data - Father of the Data Warehouse Bill Inmon\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Get Value from Unstructured Data - Father of the Data Warehouse Bill Inmon", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/So-vd2e6WeI?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Get Value from Unstructured Data - Father of the Data Warehouse Bill Inmon\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/So-vd2e6WeI/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/So-vd2e6WeI?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Get Value from Unstructured Data - Father of the Data Warehouse Bill Inmon\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/zlw3l1", "height": 200}, "link_flair_text": "Interview", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/xGreVRIj-uTiAxuIFesiDfbGQYS84DG-20f0qCiZVdI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671037044.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/So-vd2e6WeI", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1uOXDV6V0SVpiJKI66Ovhhyw2G_XIdx4W8gtz1c5qD8.jpg?auto=webp&amp;v=enabled&amp;s=213d6faed52ce31d774bc03ea46ce7c9e8c0c763", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/1uOXDV6V0SVpiJKI66Ovhhyw2G_XIdx4W8gtz1c5qD8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e06d2a9affc835f2a91c3b5543009e0913ec2331", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/1uOXDV6V0SVpiJKI66Ovhhyw2G_XIdx4W8gtz1c5qD8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a605528e603fc9c047e0f128f46b02b1f62109a2", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/1uOXDV6V0SVpiJKI66Ovhhyw2G_XIdx4W8gtz1c5qD8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=09b4626e5e2f4bde206ad01cb7b073249bb95f60", "width": 320, "height": 240}], "variants": {}, "id": "dNQBv9cSV6v-9xtn1U5MuYVbXNQlIupj17TQNs4EA0s"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "zlw3l1", "is_robot_indexable": true, "report_reasons": null, "author": "CatanNicollo", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zlw3l1/get_value_from_unstructured_data_father_of_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/So-vd2e6WeI", "subreddit_subscribers": 82933, "created_utc": 1671037044.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Get Value from Unstructured Data - Father of the Data Warehouse Bill Inmon", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/So-vd2e6WeI?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Get Value from Unstructured Data - Father of the Data Warehouse Bill Inmon\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/So-vd2e6WeI/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_sppgx30r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Docker Containerization and Devops Data Virtual machine", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_zlvbua", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/ORu4y_-u1t8?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Introduction to Containers in Docker | Virtual Machine and Containerization Explained | DevOps\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Introduction to Containers in Docker | Virtual Machine and Containerization Explained | DevOps", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/ORu4y_-u1t8?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Introduction to Containers in Docker | Virtual Machine and Containerization Explained | DevOps\"&gt;&lt;/iframe&gt;", "author_name": " Code with Scaler", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/ORu4y_-u1t8/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@CodewithScaler"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/ORu4y_-u1t8?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Introduction to Containers in Docker | Virtual Machine and Containerization Explained | DevOps\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/zlvbua", "height": 200}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/YaWLZi2IHf-a8KCYde3qcbgM6TU9PkBPC00Ejmp-IiA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671035150.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/ORu4y_-u1t8", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yY0z_yNeqmzr0wNwXqAhHfeUWhmZaLyj85xQPQj2kW8.jpg?auto=webp&amp;v=enabled&amp;s=dde02dea038e1d5813dbd0b0c7023bdd6b761b9a", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/yY0z_yNeqmzr0wNwXqAhHfeUWhmZaLyj85xQPQj2kW8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=51d67dffec08168590ed738ce94e2707333a96ac", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/yY0z_yNeqmzr0wNwXqAhHfeUWhmZaLyj85xQPQj2kW8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1e060ed6e00a429ce05ae799269f8ccc8efafef7", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/yY0z_yNeqmzr0wNwXqAhHfeUWhmZaLyj85xQPQj2kW8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=664a14be06b098dbf00c93bb7cfc53067b4aaad0", "width": 320, "height": 240}], "variants": {}, "id": "sXOsexTgn_uvLmSWE74mXvXLISFjFURVBHi_tEwETI4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "zlvbua", "is_robot_indexable": true, "report_reasons": null, "author": "thetech_learner", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zlvbua/docker_containerization_and_devops_data_virtual/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/ORu4y_-u1t8", "subreddit_subscribers": 82933, "created_utc": 1671035150.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Introduction to Containers in Docker | Virtual Machine and Containerization Explained | DevOps", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/ORu4y_-u1t8?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Introduction to Containers in Docker | Virtual Machine and Containerization Explained | DevOps\"&gt;&lt;/iframe&gt;", "author_name": " Code with Scaler", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/ORu4y_-u1t8/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@CodewithScaler"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, thanks for reading this - I\u2019ll try to make it short! Essentially, I have been working in corporate finance for the past 7 years (budgeting, forecasting, analyzing finance data, reporting etc) &amp; have been working with data engineers throughout  past few years automating these processes and eventually creating front end power BI dashboards. I\u2019ve realized this is a powerful skill set to have and plan on learning SQL &amp; Python for a year or 2 to eventually get some experience doing this stuff myself. My main question is how much would someone expect to earn with my background with these skill sets? I know it depends on the industry and company but a ballpark number? After some experience at my current company I would want to leave and only focus on data automation of financial processes. This is the ballpark figure I am looking for.\n\nThank you!!!!", "author_fullname": "t2_7qlpxamu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Becoming a data engineer with 7 years experience in Corporate Finance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zlhv19", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670993483.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, thanks for reading this - I\u2019ll try to make it short! Essentially, I have been working in corporate finance for the past 7 years (budgeting, forecasting, analyzing finance data, reporting etc) &amp;amp; have been working with data engineers throughout  past few years automating these processes and eventually creating front end power BI dashboards. I\u2019ve realized this is a powerful skill set to have and plan on learning SQL &amp;amp; Python for a year or 2 to eventually get some experience doing this stuff myself. My main question is how much would someone expect to earn with my background with these skill sets? I know it depends on the industry and company but a ballpark number? After some experience at my current company I would want to leave and only focus on data automation of financial processes. This is the ballpark figure I am looking for.&lt;/p&gt;\n\n&lt;p&gt;Thank you!!!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zlhv19", "is_robot_indexable": true, "report_reasons": null, "author": "ashton5569", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zlhv19/becoming_a_data_engineer_with_7_years_experience/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zlhv19/becoming_a_data_engineer_with_7_years_experience/", "subreddit_subscribers": 82933, "created_utc": 1670993483.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As a Software Engineer, I am always curious to know what others are doing in tech space. The best way to learn about what is happening in other companies is to read their tech blogs and get inspiration for my next project.  \nI created SourceFeed as platform that fetch ingest tech blogs from facebook, AWS, Google Cloud, Netflix and so on.  \nAt the moment it covers 50+ sources , with blogs filter by time, but i have plan to include many features in future based on audience response.  \n[https://engineeringblogs.asyncq.com](https://engineeringblogs.asyncq.com)", "author_fullname": "t2_72ydmy92", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Source Feed App Released!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zm4dej", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671057204.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a Software Engineer, I am always curious to know what others are doing in tech space. The best way to learn about what is happening in other companies is to read their tech blogs and get inspiration for my next project.&lt;br/&gt;\nI created SourceFeed as platform that fetch ingest tech blogs from facebook, AWS, Google Cloud, Netflix and so on.&lt;br/&gt;\nAt the moment it covers 50+ sources , with blogs filter by time, but i have plan to include many features in future based on audience response.&lt;br/&gt;\n&lt;a href=\"https://engineeringblogs.asyncq.com\"&gt;https://engineeringblogs.asyncq.com&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "zm4dej", "is_robot_indexable": true, "report_reasons": null, "author": "Educational-Ad2036", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zm4dej/source_feed_app_released/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zm4dej/source_feed_app_released/", "subreddit_subscribers": 82933, "created_utc": 1671057204.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\\*\\* Market Research for an idea \\*\\*  \nOver the last 5 years I have worked for several companies as an Analytics Engineer (implementing tracking and tagging solutions) and Data Manager. \n\nMy job normally included getting a picture of online and offline data and unite them. \n\nIn each company I started auditing the different data and marketing platforms to understand the data structure, naming conventions and platform integration status. \n\nAll of the companies I worked for had a big problem with old, cluttered and incorrect data.   \nIn one company we ripped out the complete tagging and tracking system and set up a brand new tag management system and platform end points (mainly Google Analytics, Databricks and some other platforms)  \n\n\nIn the other company I spent a very long time manually auditing the data and raising bug ticket after bug ticket to align data schema, streamline data endpoints and fix duplicated or broken properties. \n\nEven not being involved in one new website feature can mean derailing all naming conventions for that feature and headaches for any analysts or scientists who need to use that data further.   \nI feel like this is a recurring theme in companies. Over time you get clutter or old data concepts that are no longer used due to team. focus or platform changes.   \nI am currently investigating an automatic auditing solution for different data platforms, starting with the biggest, to quickly and easily get a view of what is currently collected and how.   \nAfter this I would like to come up with automated platform enhancing tips based on best practices for that specific business (you are not using this GA feature, enabling this would give you x etc.)\n\nYou could also define conversion steps for different products/ areas of the website and see if the tracking is coherent or needs adjusting, simplifying the whole naming convention of your website tracking to keep it easy for analysts. \n\n I would like to discuss with you if you also experience this problem in your companies and if it involves a lot of manual work that could benefit from an automated tool like the one described.   \n\n\nIf it would help, which features would you be interested in the most?   \n\n\nThank you for your help!", "author_fullname": "t2_g6h4ln0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this a problem in the industry?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zm443h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "620fb7b8-ac9d-11eb-a99a-0ed5d8300de1", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671056567.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;** Market Research for an idea **&lt;br/&gt;\nOver the last 5 years I have worked for several companies as an Analytics Engineer (implementing tracking and tagging solutions) and Data Manager. &lt;/p&gt;\n\n&lt;p&gt;My job normally included getting a picture of online and offline data and unite them. &lt;/p&gt;\n\n&lt;p&gt;In each company I started auditing the different data and marketing platforms to understand the data structure, naming conventions and platform integration status. &lt;/p&gt;\n\n&lt;p&gt;All of the companies I worked for had a big problem with old, cluttered and incorrect data.&lt;br/&gt;\nIn one company we ripped out the complete tagging and tracking system and set up a brand new tag management system and platform end points (mainly Google Analytics, Databricks and some other platforms)  &lt;/p&gt;\n\n&lt;p&gt;In the other company I spent a very long time manually auditing the data and raising bug ticket after bug ticket to align data schema, streamline data endpoints and fix duplicated or broken properties. &lt;/p&gt;\n\n&lt;p&gt;Even not being involved in one new website feature can mean derailing all naming conventions for that feature and headaches for any analysts or scientists who need to use that data further.&lt;br/&gt;\nI feel like this is a recurring theme in companies. Over time you get clutter or old data concepts that are no longer used due to team. focus or platform changes.&lt;br/&gt;\nI am currently investigating an automatic auditing solution for different data platforms, starting with the biggest, to quickly and easily get a view of what is currently collected and how.&lt;br/&gt;\nAfter this I would like to come up with automated platform enhancing tips based on best practices for that specific business (you are not using this GA feature, enabling this would give you x etc.)&lt;/p&gt;\n\n&lt;p&gt;You could also define conversion steps for different products/ areas of the website and see if the tracking is coherent or needs adjusting, simplifying the whole naming convention of your website tracking to keep it easy for analysts. &lt;/p&gt;\n\n&lt;p&gt;I would like to discuss with you if you also experience this problem in your companies and if it involves a lot of manual work that could benefit from an automated tool like the one described.   &lt;/p&gt;\n\n&lt;p&gt;If it would help, which features would you be interested in the most?   &lt;/p&gt;\n\n&lt;p&gt;Thank you for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Product Manager", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zm443h", "is_robot_indexable": true, "report_reasons": null, "author": "Itchypupskit", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/zm443h/is_this_a_problem_in_the_industry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zm443h/is_this_a_problem_in_the_industry/", "subreddit_subscribers": 82933, "created_utc": 1671056567.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[Learn how to route osquery logs.](https://www.decodable.co/blog/routing-osquery-events-via-apache-pulsar)\n\nOSQuery is an open source tool that lets you query operating system events using SQL.The events can be fed into a #streaming platform, in this case Pulsar, for subsequent transformation and routing on the stream using Decodable.\n\n&amp;#x200B;\n\n[Route OSQuery Logs](https://preview.redd.it/3r1wlfxggv5a1.jpg?width=377&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=0afa17ba946be69ecbc94426f1d6560611565e9f)\n\n\\#apache-flink #flink #security #logs #cybersecurity #osquery #sql #decodable #streaming #apache-pulsar #pulsar", "author_fullname": "t2_90mri5a8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Routing OSQuery Events via Apache Pulsar", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"3r1wlfxggv5a1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 112, "x": 108, "u": "https://preview.redd.it/3r1wlfxggv5a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8b2645c6182b9db2155a15a563e2b3d7a170af4a"}, {"y": 224, "x": 216, "u": "https://preview.redd.it/3r1wlfxggv5a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d31c808ed7d52b5616bb5656a9c0ff752b817423"}, {"y": 332, "x": 320, "u": "https://preview.redd.it/3r1wlfxggv5a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8b6c1a346ce4d7b612efa1e02d90e42b6b107ee8"}], "s": {"y": 392, "x": 377, "u": "https://preview.redd.it/3r1wlfxggv5a1.jpg?width=377&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=0afa17ba946be69ecbc94426f1d6560611565e9f"}, "id": "3r1wlfxggv5a1"}}, "name": "t3_zlrthq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/_vWcCSxdycUXpyHuCUEWopmghIdmzOB99FjnvKWYHCs.jpg", "edited": 1671027318.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671026752.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.decodable.co/blog/routing-osquery-events-via-apache-pulsar\"&gt;Learn how to route osquery logs.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;OSQuery is an open source tool that lets you query operating system events using SQL.The events can be fed into a #streaming platform, in this case Pulsar, for subsequent transformation and routing on the stream using Decodable.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/3r1wlfxggv5a1.jpg?width=377&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=0afa17ba946be69ecbc94426f1d6560611565e9f\"&gt;Route OSQuery Logs&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;#apache-flink #flink #security #logs #cybersecurity #osquery #sql #decodable #streaming #apache-pulsar #pulsar&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zlrthq", "is_robot_indexable": true, "report_reasons": null, "author": "hkdelay", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zlrthq/routing_osquery_events_via_apache_pulsar/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zlrthq/routing_osquery_events_via_apache_pulsar/", "subreddit_subscribers": 82933, "created_utc": 1671026752.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, first of all i am using Databricks. I have a raw dataframe, where based on some business logic i have to apply different filters. This is my preprocessing step, right now  i have 10 different jobs which produces processed dataframe(filtered).Since this is fairly easy task and not so expensive. I want to merge it into one single job.\n\nDo i benefit from something like this? How would u done it?How would u later write it to s3 lets say.\n\nIs map() ideal solution for this?\n\nShould i write some PandasUDF? Any opinion is good. =)\n\n     def _apply_filter(filter_: str) -&gt; pyspark.sql.DataFrame:\n        return rawDataFrame.filter(F.expr(filter_))\n    \n    FILTERS: List[str]\n    result: List[DataFrame] = list(map(_apply_filter, FILTERS))", "author_fullname": "t2_sx1wry60", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "applying set of filters on same dataframe", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zlqwag", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671024385.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, first of all i am using Databricks. I have a raw dataframe, where based on some business logic i have to apply different filters. This is my preprocessing step, right now  i have 10 different jobs which produces processed dataframe(filtered).Since this is fairly easy task and not so expensive. I want to merge it into one single job.&lt;/p&gt;\n\n&lt;p&gt;Do i benefit from something like this? How would u done it?How would u later write it to s3 lets say.&lt;/p&gt;\n\n&lt;p&gt;Is map() ideal solution for this?&lt;/p&gt;\n\n&lt;p&gt;Should i write some PandasUDF? Any opinion is good. =)&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt; def _apply_filter(filter_: str) -&amp;gt; pyspark.sql.DataFrame:\n    return rawDataFrame.filter(F.expr(filter_))\n\nFILTERS: List[str]\nresult: List[DataFrame] = list(map(_apply_filter, FILTERS))\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zlqwag", "is_robot_indexable": true, "report_reasons": null, "author": "AcceptableProcess772", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zlqwag/applying_set_of_filters_on_same_dataframe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zlqwag/applying_set_of_filters_on_same_dataframe/", "subreddit_subscribers": 82933, "created_utc": 1671024385.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a self employed CPA making very good money, however find the job to be stressful and although one of my strong suits is dealing with clients, I hate it. \n\nThis field interests me, always has, and I see some synergies between accounting/data. Where do I need to go from here to explore a career? What is ground zero? Any help appreciated.", "author_fullname": "t2_ogss1t18", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zledv4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670983666.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a self employed CPA making very good money, however find the job to be stressful and although one of my strong suits is dealing with clients, I hate it. &lt;/p&gt;\n\n&lt;p&gt;This field interests me, always has, and I see some synergies between accounting/data. Where do I need to go from here to explore a career? What is ground zero? Any help appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zledv4", "is_robot_indexable": true, "report_reasons": null, "author": "Sea_Escape_1306", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zledv4/career_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zledv4/career_advice/", "subreddit_subscribers": 82933, "created_utc": 1670983666.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m wanting to build a data engineering project to show potential employers I have some skills.\n\nThere seems to be tons of ways a project can be built. So, question is, **which tools should a data engineering project include** to not be overly complex but not very simple?\n\nMaybe even a better question: what would a good project look like that would impress you?\n\nThe plethora of tools out there makes it overwhelming and a bit complicated to a beginner. \n\nWould appreciate some ideas!", "author_fullname": "t2_a4wvyz1l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which tools should a project use?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zle5wj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670983086.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m wanting to build a data engineering project to show potential employers I have some skills.&lt;/p&gt;\n\n&lt;p&gt;There seems to be tons of ways a project can be built. So, question is, &lt;strong&gt;which tools should a data engineering project include&lt;/strong&gt; to not be overly complex but not very simple?&lt;/p&gt;\n\n&lt;p&gt;Maybe even a better question: what would a good project look like that would impress you?&lt;/p&gt;\n\n&lt;p&gt;The plethora of tools out there makes it overwhelming and a bit complicated to a beginner. &lt;/p&gt;\n\n&lt;p&gt;Would appreciate some ideas!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zle5wj", "is_robot_indexable": true, "report_reasons": null, "author": "HeavyFuckingMetalx", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zle5wj/which_tools_should_a_project_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zle5wj/which_tools_should_a_project_use/", "subreddit_subscribers": 82933, "created_utc": 1670983086.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_22rg4hgk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Simplest Realtime Streaming Data Pipeline On Google Cloud Platform - Async Queue", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_zlkymb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/Ghsa8S-JHiWfPdAxHgyLCXwrcgvCdq_DPYdQmaoBXe8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671003915.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "asyncq.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://asyncq.com/simplest-realtime-streaming-data-pipeline-on-google-cloud-platform", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/iPVZMYwFqR_2pa4b4RRwmN2xwwal7fXyiOr-jYjx8_s.jpg?auto=webp&amp;v=enabled&amp;s=50ecb5039c3516cece844bb80100cf33e591a856", "width": 1400, "height": 788}, "resolutions": [{"url": "https://external-preview.redd.it/iPVZMYwFqR_2pa4b4RRwmN2xwwal7fXyiOr-jYjx8_s.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8e048161e27fa7ac00ad47b4a682ce4c80332161", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/iPVZMYwFqR_2pa4b4RRwmN2xwwal7fXyiOr-jYjx8_s.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=53e51c6b3cf7492fad6da9cfe83aea49da503b11", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/iPVZMYwFqR_2pa4b4RRwmN2xwwal7fXyiOr-jYjx8_s.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d923ea80c8198a8981b7b1a52b6f82d552294a1a", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/iPVZMYwFqR_2pa4b4RRwmN2xwwal7fXyiOr-jYjx8_s.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1eb924e61a1c7af78b2053d38c1a2282aed91bd4", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/iPVZMYwFqR_2pa4b4RRwmN2xwwal7fXyiOr-jYjx8_s.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=21092b8d4684dac8835f531c7c5c339ea6eff5cb", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/iPVZMYwFqR_2pa4b4RRwmN2xwwal7fXyiOr-jYjx8_s.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9960f239b85a7d1fd056e112f9af235e8e32fc4f", "width": 1080, "height": 607}], "variants": {}, "id": "9QZBw_1mmz-BUBHXcsWVMrwBObI2aua05JGTL3QKJGs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zlkymb", "is_robot_indexable": true, "report_reasons": null, "author": "suraj-mishra15", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zlkymb/simplest_realtime_streaming_data_pipeline_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://asyncq.com/simplest-realtime-streaming-data-pipeline-on-google-cloud-platform", "subreddit_subscribers": 82933, "created_utc": 1671003915.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Have any of you worked with extracting mongo collections to s3 via the change stream and run into this issue? \n\nEssentially mongo has a cap at documents being no greater than 16MB. However, the update data also included in the change stream can easily get you over 16 MB and throw a read error on the client side.\n\nWe are trying to either work around these errors ideally on the mongo side, but if not just ignore them on client side (specifically we are using amazon DMS).\n\nAny recommendations?", "author_fullname": "t2_2nfde5yl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mongo change stream exceeds max file size of 16MB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zlc18i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670977593.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have any of you worked with extracting mongo collections to s3 via the change stream and run into this issue? &lt;/p&gt;\n\n&lt;p&gt;Essentially mongo has a cap at documents being no greater than 16MB. However, the update data also included in the change stream can easily get you over 16 MB and throw a read error on the client side.&lt;/p&gt;\n\n&lt;p&gt;We are trying to either work around these errors ideally on the mongo side, but if not just ignore them on client side (specifically we are using amazon DMS).&lt;/p&gt;\n\n&lt;p&gt;Any recommendations?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zlc18i", "is_robot_indexable": true, "report_reasons": null, "author": "pmarct", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zlc18i/mongo_change_stream_exceeds_max_file_size_of_16mb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zlc18i/mongo_change_stream_exceeds_max_file_size_of_16mb/", "subreddit_subscribers": 82933, "created_utc": 1670977593.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all,\n\nI know there have already been a few posts on this- but for those of us just getting started in software/data engineering, the ability for chatgpt to write code is pretty scary...\n\nWhat do you all think the impact to Data Engr will be?\n\nI know it won't completely replace us, but do you foresee a big reduction in hiring?", "author_fullname": "t2_8chdw7c4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "chatgpt anxiety", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zlecvg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670983592.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;I know there have already been a few posts on this- but for those of us just getting started in software/data engineering, the ability for chatgpt to write code is pretty scary...&lt;/p&gt;\n\n&lt;p&gt;What do you all think the impact to Data Engr will be?&lt;/p&gt;\n\n&lt;p&gt;I know it won&amp;#39;t completely replace us, but do you foresee a big reduction in hiring?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zlecvg", "is_robot_indexable": true, "report_reasons": null, "author": "pdxtechnologist", "discussion_type": null, "num_comments": 38, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zlecvg/chatgpt_anxiety/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zlecvg/chatgpt_anxiety/", "subreddit_subscribers": 82933, "created_utc": 1670983592.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}