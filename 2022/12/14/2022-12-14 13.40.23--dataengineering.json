{"kind": "Listing", "data": {"after": "t3_zl287g", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What kind of scripts ir programs do you develop?\n\nI'm currently a data engineer only using a low code cloud platform (informatica) and i am unmotivated with my routine.", "author_fullname": "t2_2s92xxvc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you need to code in your job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zl7gvh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 68, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 68, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670966783.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What kind of scripts ir programs do you develop?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently a data engineer only using a low code cloud platform (informatica) and i am unmotivated with my routine.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zl7gvh", "is_robot_indexable": true, "report_reasons": null, "author": "Idalen", "discussion_type": null, "num_comments": 61, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zl7gvh/do_you_need_to_code_in_your_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zl7gvh/do_you_need_to_code_in_your_job/", "subreddit_subscribers": 82893, "created_utc": 1670966783.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm ok with take home programming tests and leetcode.  However, I noticed during my last job search that every company that had a take home project that I completed ended up rejecting me.\n\n\n\n\nIt almost seems like a better time investment to spend 3-5 hours studying leetcode than doing a take home project.", "author_fullname": "t2_3v6ob2bf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone else turn down interviews that involve a take home project?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zlao51", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670974196.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m ok with take home programming tests and leetcode.  However, I noticed during my last job search that every company that had a take home project that I completed ended up rejecting me.&lt;/p&gt;\n\n&lt;p&gt;It almost seems like a better time investment to spend 3-5 hours studying leetcode than doing a take home project.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zlao51", "is_robot_indexable": true, "report_reasons": null, "author": "data_preprocessing", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zlao51/does_anyone_else_turn_down_interviews_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zlao51/does_anyone_else_turn_down_interviews_that/", "subreddit_subscribers": 82893, "created_utc": 1670974196.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\n&amp;#x200B;\n\nI am recently tasked with switching over some ETL tasks from Fivetran to Keboola. The only good thing I see in this switch is that we save some $$$.\n\n&amp;#x200B;\n\nThe Keboola UI and the connectors seem suitable with what we need, but then there comes the Dev and Test time + the risk of messing up ETL jobs / data integrity. Aand the time table is that we shall finish this in 4 weeks (not many tables, not very big)\n\n&amp;#x200B;\n\nDoes anybody else have any intuition? I was arguing with some colleagues -&gt; that it\\`s not worth it to put in 3-4 weeks in hardcore keboola dev + new tests, just to save 2000$/month - keboola cost(which they said it\\`s under 1000$ a month)\n\nI am not a decision maker.\n\nAny help is appreciated!", "author_fullname": "t2_2i1av4aw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Keboola pros and cons", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zl0d5i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670950192.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I am recently tasked with switching over some ETL tasks from Fivetran to Keboola. The only good thing I see in this switch is that we save some $$$.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The Keboola UI and the connectors seem suitable with what we need, but then there comes the Dev and Test time + the risk of messing up ETL jobs / data integrity. Aand the time table is that we shall finish this in 4 weeks (not many tables, not very big)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Does anybody else have any intuition? I was arguing with some colleagues -&amp;gt; that it`s not worth it to put in 3-4 weeks in hardcore keboola dev + new tests, just to save 2000$/month - keboola cost(which they said it`s under 1000$ a month)&lt;/p&gt;\n\n&lt;p&gt;I am not a decision maker.&lt;/p&gt;\n\n&lt;p&gt;Any help is appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zl0d5i", "is_robot_indexable": true, "report_reasons": null, "author": "younggamech", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zl0d5i/keboola_pros_and_cons/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zl0d5i/keboola_pros_and_cons/", "subreddit_subscribers": 82893, "created_utc": 1670950192.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all\n\nI recently started a new position at a small ERP software company (Whose main product is built on top of Microsoft's Business Central) as what was going to be mainly a BI Dev/Data Coordinator. My main relevant experience previous to this position was mostly as a BI Dev and some small SSIS projects and a bit of Python dabbling, so nothing advanced at the Data engineering level. In this new position I'm inheriting the reports and not so great documentation left by a previoul developer which only worked on Power BI part-time and I am totally alone, without mentor or colleague.\n\nThe main data related task I've had to dealt with in the first few weeks is evaluating and improving a package of Power BI Reports we offer to our clients. These reports contain zero external sources and get all their data from the ERP through published ODATA web services.\nManagement has plans to develop some sort of data strategy, which I can broadly describe as using our ERP client's anonymized data (Previously agreed under contract) to generate industry insights and feed them back into their reports, adding related data from external sources like regional or central government datasets and, as a medium-term goal, becoming a local industry reference as information/insight/dataset providers.\n\nWe have no central data infrastructure, not even an On-Prem SQL Server DB so I've been tasked to look for solutions that would help us get on track. I've even been told not to ask our current Microsoft CSP as we're in the process of changing partners. \nI've thought of the simplest solution as being a cloud  ETL/ELT service + DB/DWH (Our data volumes are not extreme at the moment)\n\nI've been reading the subreddit for the past week and I must admit it's been a bit overwhelming. The sheer number of different technologies and ways to implement a project can drive somebody without experience crazy. \nAs we're a Microsoft shop, it seems to me we should head towards Azure as it should have the least challenging barrier to entry.\n\nWhat would be a first step for us, just start with Azure Data Factory + Azure SQL Database? Any other solution from the big providers worth considering?\n\nThank you!", "author_fullname": "t2_5ho6r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What would be a solid first step for a small company with zero data infrastructure?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zl4dpw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1670965501.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670959486.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all&lt;/p&gt;\n\n&lt;p&gt;I recently started a new position at a small ERP software company (Whose main product is built on top of Microsoft&amp;#39;s Business Central) as what was going to be mainly a BI Dev/Data Coordinator. My main relevant experience previous to this position was mostly as a BI Dev and some small SSIS projects and a bit of Python dabbling, so nothing advanced at the Data engineering level. In this new position I&amp;#39;m inheriting the reports and not so great documentation left by a previoul developer which only worked on Power BI part-time and I am totally alone, without mentor or colleague.&lt;/p&gt;\n\n&lt;p&gt;The main data related task I&amp;#39;ve had to dealt with in the first few weeks is evaluating and improving a package of Power BI Reports we offer to our clients. These reports contain zero external sources and get all their data from the ERP through published ODATA web services.\nManagement has plans to develop some sort of data strategy, which I can broadly describe as using our ERP client&amp;#39;s anonymized data (Previously agreed under contract) to generate industry insights and feed them back into their reports, adding related data from external sources like regional or central government datasets and, as a medium-term goal, becoming a local industry reference as information/insight/dataset providers.&lt;/p&gt;\n\n&lt;p&gt;We have no central data infrastructure, not even an On-Prem SQL Server DB so I&amp;#39;ve been tasked to look for solutions that would help us get on track. I&amp;#39;ve even been told not to ask our current Microsoft CSP as we&amp;#39;re in the process of changing partners. \nI&amp;#39;ve thought of the simplest solution as being a cloud  ETL/ELT service + DB/DWH (Our data volumes are not extreme at the moment)&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been reading the subreddit for the past week and I must admit it&amp;#39;s been a bit overwhelming. The sheer number of different technologies and ways to implement a project can drive somebody without experience crazy. \nAs we&amp;#39;re a Microsoft shop, it seems to me we should head towards Azure as it should have the least challenging barrier to entry.&lt;/p&gt;\n\n&lt;p&gt;What would be a first step for us, just start with Azure Data Factory + Azure SQL Database? Any other solution from the big providers worth considering?&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zl4dpw", "is_robot_indexable": true, "report_reasons": null, "author": "pescawito", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zl4dpw/what_would_be_a_solid_first_step_for_a_small/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zl4dpw/what_would_be_a_solid_first_step_for_a_small/", "subreddit_subscribers": 82893, "created_utc": 1670959486.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_nrfxa5al", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is Apache Arrow? by Pandas Creator Wes McKinnley", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_zl5a2m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 9, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/DTqGMRYcEt0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"What is Apache Arrow? by Pandas Creator Wes McKinnley\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "What is Apache Arrow? by Pandas Creator Wes McKinnley", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/DTqGMRYcEt0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"What is Apache Arrow? by Pandas Creator Wes McKinnley\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/DTqGMRYcEt0/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/DTqGMRYcEt0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"What is Apache Arrow? by Pandas Creator Wes McKinnley\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/zl5a2m", "height": 200}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/GqCdTbaIFGEoShSFL1FwWisYm4s3b2tKBLm-aYkCCnw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670961650.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/DTqGMRYcEt0", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bvvF3--YXb2Cbs7ufOk9v3dHzOFOy_T8vkjoswbrpxk.jpg?auto=webp&amp;s=54deb22453ac102aff639c647882a00e95e0d3fd", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/bvvF3--YXb2Cbs7ufOk9v3dHzOFOy_T8vkjoswbrpxk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4ff5eb2f4cf6b4950dd9673f01da3f6f9e592f0b", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/bvvF3--YXb2Cbs7ufOk9v3dHzOFOy_T8vkjoswbrpxk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8927b0b5478b719dc45518e42ee808ef6cd74889", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/bvvF3--YXb2Cbs7ufOk9v3dHzOFOy_T8vkjoswbrpxk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=49cae82af9b7da8a958dbb6862d6d25279b101da", "width": 320, "height": 240}], "variants": {}, "id": "ov7EwPXX779b4PjEgaZifspj4-Ctcov99EXmQ_FkDmM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zl5a2m", "is_robot_indexable": true, "report_reasons": null, "author": "CatanNicollo", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zl5a2m/what_is_apache_arrow_by_pandas_creator_wes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/DTqGMRYcEt0", "subreddit_subscribers": 82893, "created_utc": 1670961650.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "What is Apache Arrow? by Pandas Creator Wes McKinnley", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/DTqGMRYcEt0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"What is Apache Arrow? by Pandas Creator Wes McKinnley\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/DTqGMRYcEt0/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When I had my first analyst job 11 years ago, I was at a microsoft shop. I learned SQL on MS SQL Server 2012. To this day, I think it was the best console I've ever used for just writing and executing queries.I use pycharm as my IDE which works great for DBT development but the console sucks. The snowflake browser-based console slows me down. I don't need an IDE that is for hardcore software development. I'd like to get something that is designed for SQL queries--has a good database object explorer and possibly saves query history. A feature I have been searching for since SQL Server is just the ability to execute multiple statements at the same time and see all the results in the output pane at once. Cost is not an issue; I can get a license. Suggestions?", "author_fullname": "t2_yxzao", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best SQL Console?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zlh26w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670991068.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When I had my first analyst job 11 years ago, I was at a microsoft shop. I learned SQL on MS SQL Server 2012. To this day, I think it was the best console I&amp;#39;ve ever used for just writing and executing queries.I use pycharm as my IDE which works great for DBT development but the console sucks. The snowflake browser-based console slows me down. I don&amp;#39;t need an IDE that is for hardcore software development. I&amp;#39;d like to get something that is designed for SQL queries--has a good database object explorer and possibly saves query history. A feature I have been searching for since SQL Server is just the ability to execute multiple statements at the same time and see all the results in the output pane at once. Cost is not an issue; I can get a license. Suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zlh26w", "is_robot_indexable": true, "report_reasons": null, "author": "mrp4434", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zlh26w/best_sql_console/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zlh26w/best_sql_console/", "subreddit_subscribers": 82893, "created_utc": 1670991068.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "While reading comparisons of Python and Rust, I saw distinctions of the former as dynamic and dynamically typed and the latter as compiled before runtime and strongly typed. \n\nI understand this can help discover bugs earlier in a pipeline or process, but does anyone have specific examples illustrating how this might work in practice? As someone who doesn\u2019t come from a CS background, I\u2019m trying to form a mental picture and grasp the impact of these distinctions. \n\nThank you!", "author_fullname": "t2_8l7mjk80", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Examples of Differences Between Python &amp; Rust", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zkywai", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670946593.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;While reading comparisons of Python and Rust, I saw distinctions of the former as dynamic and dynamically typed and the latter as compiled before runtime and strongly typed. &lt;/p&gt;\n\n&lt;p&gt;I understand this can help discover bugs earlier in a pipeline or process, but does anyone have specific examples illustrating how this might work in practice? As someone who doesn\u2019t come from a CS background, I\u2019m trying to form a mental picture and grasp the impact of these distinctions. &lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zkywai", "is_robot_indexable": true, "report_reasons": null, "author": "epcot32", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zkywai/examples_of_differences_between_python_rust/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zkywai/examples_of_differences_between_python_rust/", "subreddit_subscribers": 82893, "created_utc": 1670946593.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can dagster be used for real time data processing?", "author_fullname": "t2_c2d7ldip", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dagster with real time data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zkym9q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670945822.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can dagster be used for real time data processing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zkym9q", "is_robot_indexable": true, "report_reasons": null, "author": "Steve-Quix", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zkym9q/dagster_with_real_time_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zkym9q/dagster_with_real_time_data/", "subreddit_subscribers": 82893, "created_utc": 1670945822.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2mhgth69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Never again forget what happened to your tasks or DAGs with this new feature in Airflow \ud83d\udc47", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 109, "top_awarded_type": null, "hide_score": false, "name": "t3_zkxtvo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/b0WATacQTrYkeMSGUBWwxYjXiu9hcDf-IUSPL8Wmma4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670943657.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "linkedin.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.linkedin.com/feed/update/urn:li:activity:7008439403761016832/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/prVmHwCP8q45i1BiaWznZJu5HgDZHLZhjPP6oOj488Y.jpg?auto=webp&amp;s=a6dce6ab12b87285ccf19fdd797a4ae6af4ad49d", "width": 480, "height": 374}, "resolutions": [{"url": "https://external-preview.redd.it/prVmHwCP8q45i1BiaWznZJu5HgDZHLZhjPP6oOj488Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f1403448d563ac1c5ee29545b7a0f5f9210b367d", "width": 108, "height": 84}, {"url": "https://external-preview.redd.it/prVmHwCP8q45i1BiaWznZJu5HgDZHLZhjPP6oOj488Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c3675b2094d78e8d8eefa013a8b2ed2c793ba9cb", "width": 216, "height": 168}, {"url": "https://external-preview.redd.it/prVmHwCP8q45i1BiaWznZJu5HgDZHLZhjPP6oOj488Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8cbda18dedaf931daf8a9ca62a90b496b899a1b0", "width": 320, "height": 249}], "variants": {}, "id": "yU6TMOzsrTJOTZmSXiiIEDYEDO7LWfOTHTDZRPXQ2u0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zkxtvo", "is_robot_indexable": true, "report_reasons": null, "author": "marclamberti", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zkxtvo/never_again_forget_what_happened_to_your_tasks_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.linkedin.com/feed/update/urn:li:activity:7008439403761016832/", "subreddit_subscribers": 82893, "created_utc": 1670943657.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Did you know that the bio mass of all bacteria is way bigger then the bio mass of all human? I wonder if the same relation is or will be true for IoT and server calculation power. \n\nWhile Server are obviously so powerful compared to IoT, I wonder if the sheer amount of the devices will compensate that. \n\nI am working with IoT devices and we currently do all the hard calculation on a server but I was thinking about the fact that we are wasting capacity on the devices. If the utilization is just 20% why not using the rest for stuff we are currently doing server-side. Maybe we also could stream data back from server to device for calculation jobs. \n\nIf that would work, I wonder how I can design a good DE architecture that accounts for that functionality.", "author_fullname": "t2_s3omzbn3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "IoT vs Server Computing Power", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zlkr8j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671003124.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Did you know that the bio mass of all bacteria is way bigger then the bio mass of all human? I wonder if the same relation is or will be true for IoT and server calculation power. &lt;/p&gt;\n\n&lt;p&gt;While Server are obviously so powerful compared to IoT, I wonder if the sheer amount of the devices will compensate that. &lt;/p&gt;\n\n&lt;p&gt;I am working with IoT devices and we currently do all the hard calculation on a server but I was thinking about the fact that we are wasting capacity on the devices. If the utilization is just 20% why not using the rest for stuff we are currently doing server-side. Maybe we also could stream data back from server to device for calculation jobs. &lt;/p&gt;\n\n&lt;p&gt;If that would work, I wonder how I can design a good DE architecture that accounts for that functionality.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zlkr8j", "is_robot_indexable": true, "report_reasons": null, "author": "ZenCoding", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zlkr8j/iot_vs_server_computing_power/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zlkr8j/iot_vs_server_computing_power/", "subreddit_subscribers": 82893, "created_utc": 1671003124.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I'm preparing a presentation about Hadoop and Spark and I have to explain a use case where hadoop only is used and another use case where spark only is used , I've been looking in the internet but I didn't find an explanation of how exactly hadoop and spark has been used.\n\nAny help please ?", "author_fullname": "t2_byxenypn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hadoop and Spark use cases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zla8iv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670973155.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;m preparing a presentation about Hadoop and Spark and I have to explain a use case where hadoop only is used and another use case where spark only is used , I&amp;#39;ve been looking in the internet but I didn&amp;#39;t find an explanation of how exactly hadoop and spark has been used.&lt;/p&gt;\n\n&lt;p&gt;Any help please ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zla8iv", "is_robot_indexable": true, "report_reasons": null, "author": "AB3NZ", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zla8iv/hadoop_and_spark_use_cases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zla8iv/hadoop_and_spark_use_cases/", "subreddit_subscribers": 82893, "created_utc": 1670973155.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Pretty much the title, but I've had 3 final interviews this past year, and 0 offers. I could really use specific advice on handling deficiencies in my resume, and encouraging someone I'm worth a shot.\n\nSome info:\n\nCurrently hybrid, and underemployed/under-challenged as BI Dev for state government. Looking for fully remote, and a broader, more hands on role that will help me move toward a senior DE/BI Dev. I've failed to get into a direct hire role, and I am considering contract/temp if it could help me reach my end goal.\n\nTop Skills:\n\nSQL - 5+ years \n\nDatabase Design/Development - 5+ years \n\nUnderstanding of DW design (Star/Snowflake/OBT) - 2 years \n\nETL/ELT process - 2 years \n\nDocumentation/Communication/Other Soft-Skills - 20+ years\n\n&amp;#x200B;\n\nRusty/Inexperienced in other areas (strongest to weakest): \n\nMicrosoft Stack (SSIS/SSAS/SSRS) - Last Used(2019/2015/2017) \n\nAzure DE Associate Cert - June 2022 \n\nOOP/Prog Languages (C#, [VB.Net](https://VB.Net), Python, Java, Powershell) \n\nPower BI/DAX - Currently use (&lt;1 year) \n\nDBA \n\nGitHub (no experience and keep getting dinged hard)", "author_fullname": "t2_crjzt05k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any leaders/seniors willing to let me DM for advice on breaking through on final interviews?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zkxbsw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670942393.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Pretty much the title, but I&amp;#39;ve had 3 final interviews this past year, and 0 offers. I could really use specific advice on handling deficiencies in my resume, and encouraging someone I&amp;#39;m worth a shot.&lt;/p&gt;\n\n&lt;p&gt;Some info:&lt;/p&gt;\n\n&lt;p&gt;Currently hybrid, and underemployed/under-challenged as BI Dev for state government. Looking for fully remote, and a broader, more hands on role that will help me move toward a senior DE/BI Dev. I&amp;#39;ve failed to get into a direct hire role, and I am considering contract/temp if it could help me reach my end goal.&lt;/p&gt;\n\n&lt;p&gt;Top Skills:&lt;/p&gt;\n\n&lt;p&gt;SQL - 5+ years &lt;/p&gt;\n\n&lt;p&gt;Database Design/Development - 5+ years &lt;/p&gt;\n\n&lt;p&gt;Understanding of DW design (Star/Snowflake/OBT) - 2 years &lt;/p&gt;\n\n&lt;p&gt;ETL/ELT process - 2 years &lt;/p&gt;\n\n&lt;p&gt;Documentation/Communication/Other Soft-Skills - 20+ years&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Rusty/Inexperienced in other areas (strongest to weakest): &lt;/p&gt;\n\n&lt;p&gt;Microsoft Stack (SSIS/SSAS/SSRS) - Last Used(2019/2015/2017) &lt;/p&gt;\n\n&lt;p&gt;Azure DE Associate Cert - June 2022 &lt;/p&gt;\n\n&lt;p&gt;OOP/Prog Languages (C#, &lt;a href=\"https://VB.Net\"&gt;VB.Net&lt;/a&gt;, Python, Java, Powershell) &lt;/p&gt;\n\n&lt;p&gt;Power BI/DAX - Currently use (&amp;lt;1 year) &lt;/p&gt;\n\n&lt;p&gt;DBA &lt;/p&gt;\n\n&lt;p&gt;GitHub (no experience and keep getting dinged hard)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zkxbsw", "is_robot_indexable": true, "report_reasons": null, "author": "humanist-misanthrope", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zkxbsw/any_leadersseniors_willing_to_let_me_dm_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zkxbsw/any_leadersseniors_willing_to_let_me_dm_for/", "subreddit_subscribers": 82893, "created_utc": 1670942393.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Problem: I need to merge (upsert) incremental data with target delta table everyday. I want to make a dynamic function where I can simply pass the table name and other information to get the job done. \nSample code :\n\nsourceDF.alias('people') \\\n  .merge(\n    targetTable.alias('updates'), 'people.id = updates.id') \\\n  .whenMatchedUpdate(set =\n    {\n      \"id\": \"updates.id\",\n      \"firstName\": \"updates.firstName\",\n      \"middleName\": \"updates.middleName\",\n    }\n  ) \\\n  .whenNotMatchedInsert(values =\n    {\n      \"id\": \"updates.id\",\n      \"firstName\": \"updates.firstName\",\n      \"middleName\": \"updates.middleName\",\n      \"\n    }\n  ) \\\n  .execute()\n\nThe above code is limited for a single table, how can I implement the same dynamically?", "author_fullname": "t2_7yg1kqfr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Implement dynamic merge in PySpark.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zkw6mw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670939332.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Problem: I need to merge (upsert) incremental data with target delta table everyday. I want to make a dynamic function where I can simply pass the table name and other information to get the job done. \nSample code :&lt;/p&gt;\n\n&lt;p&gt;sourceDF.alias(&amp;#39;people&amp;#39;) \\\n  .merge(\n    targetTable.alias(&amp;#39;updates&amp;#39;), &amp;#39;people.id = updates.id&amp;#39;) \\\n  .whenMatchedUpdate(set =\n    {\n      &amp;quot;id&amp;quot;: &amp;quot;updates.id&amp;quot;,\n      &amp;quot;firstName&amp;quot;: &amp;quot;updates.firstName&amp;quot;,\n      &amp;quot;middleName&amp;quot;: &amp;quot;updates.middleName&amp;quot;,\n    }\n  ) \\\n  .whenNotMatchedInsert(values =\n    {\n      &amp;quot;id&amp;quot;: &amp;quot;updates.id&amp;quot;,\n      &amp;quot;firstName&amp;quot;: &amp;quot;updates.firstName&amp;quot;,\n      &amp;quot;middleName&amp;quot;: &amp;quot;updates.middleName&amp;quot;,\n      &amp;quot;\n    }\n  ) \\\n  .execute()&lt;/p&gt;\n\n&lt;p&gt;The above code is limited for a single table, how can I implement the same dynamically?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zkw6mw", "is_robot_indexable": true, "report_reasons": null, "author": "little-kid-hater", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zkw6mw/implement_dynamic_merge_in_pyspark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zkw6mw/implement_dynamic_merge_in_pyspark/", "subreddit_subscribers": 82893, "created_utc": 1670939332.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I am trying to switch to data engineering after taking a break from my career. I was thinking of creating a portfolio project using data from a subreddit. I wanted to use the Reddit API for the same. Can I use the free version of the API given the project will be available publically and I won't benefit financially from it?", "author_fullname": "t2_6960i650", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using Reddit API for a portfolio project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zln02b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671011674.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am trying to switch to data engineering after taking a break from my career. I was thinking of creating a portfolio project using data from a subreddit. I wanted to use the Reddit API for the same. Can I use the free version of the API given the project will be available publically and I won&amp;#39;t benefit financially from it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zln02b", "is_robot_indexable": true, "report_reasons": null, "author": "TheBrownViking20", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zln02b/using_reddit_api_for_a_portfolio_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zln02b/using_reddit_api_for_a_portfolio_project/", "subreddit_subscribers": 82893, "created_utc": 1671011674.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_r6aazfpz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Data Bus: a helpful pattern for data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_zljykk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/xc2oOcKlC56QpG9ceRCnfgfIa-FYfwTM-cQWmvf8YsE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671000277.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "leblancfg.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://leblancfg.com/data-bus-pattern-for-data-engineering.html", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/IAin_BO0uoU85zBrMwe-V0pGua4DeradcEfq_pr9kZY.jpg?auto=webp&amp;s=57ea8c5bbdd88965488afbde56858f8f503de304", "width": 400, "height": 400}, "resolutions": [{"url": "https://external-preview.redd.it/IAin_BO0uoU85zBrMwe-V0pGua4DeradcEfq_pr9kZY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=586ef3e224311d6a1288fc9c9562d36388a43114", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/IAin_BO0uoU85zBrMwe-V0pGua4DeradcEfq_pr9kZY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5081cc583f1e9b3b7a1e57db49762c20d025d432", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/IAin_BO0uoU85zBrMwe-V0pGua4DeradcEfq_pr9kZY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=604f05ee53d07d0e10cb81d2b2e6bd3c5316b957", "width": 320, "height": 320}], "variants": {}, "id": "HqKsU0Z01QouRbVlVBlldvDv37FPvmA0Ckt6IkisE2w"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zljykk", "is_robot_indexable": true, "report_reasons": null, "author": "Realistic-Cap6526", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zljykk/the_data_bus_a_helpful_pattern_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://leblancfg.com/data-bus-pattern-for-data-engineering.html", "subreddit_subscribers": 82893, "created_utc": 1671000277.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "(Disclaimer: I am new to Databricks and data engineering)\n\nI am looking for guidance/best practice to approach my task. I want to use Azure and Databricks.\n\nTask: Load and prepare data so that it can be efficiently/quickly analyzed in the future. The analysis will involve summary statistics, exploratory data analysis and maybe simple ML (regression)\n\nData: session level data (12TB) stored in 100 000 single line json files. Json schema is nested, includes arrays.\n\nAs I said above the task is to build infrastructure so the data can be processed efficiently in the future. There will be no new data flowing in. \n\nMy initial plan was to:\n1. Load data into blob storage\n2. Process data using PySpark \n    - flatten by reading into data frame \n    - save as parquet\n3. Store in a DB so the data can be quickly queried and analyzed \n    - I am not sure which Azure solution (DB) would work here\n4. Analyse the data using PySpark by querying it from DB\n\nDoes this sound reasonable? Does anyone has materials/tutorials that follow similar process so I could use them as blueprints for my pipeline?\n\nAny comments, suggestions are very welcome! Thanks.", "author_fullname": "t2_55s3bmua", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Processing large number of jsons (~12TB)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zl7hvk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670966849.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;(Disclaimer: I am new to Databricks and data engineering)&lt;/p&gt;\n\n&lt;p&gt;I am looking for guidance/best practice to approach my task. I want to use Azure and Databricks.&lt;/p&gt;\n\n&lt;p&gt;Task: Load and prepare data so that it can be efficiently/quickly analyzed in the future. The analysis will involve summary statistics, exploratory data analysis and maybe simple ML (regression)&lt;/p&gt;\n\n&lt;p&gt;Data: session level data (12TB) stored in 100 000 single line json files. Json schema is nested, includes arrays.&lt;/p&gt;\n\n&lt;p&gt;As I said above the task is to build infrastructure so the data can be processed efficiently in the future. There will be no new data flowing in. &lt;/p&gt;\n\n&lt;p&gt;My initial plan was to:\n1. Load data into blob storage\n2. Process data using PySpark \n    - flatten by reading into data frame \n    - save as parquet\n3. Store in a DB so the data can be quickly queried and analyzed \n    - I am not sure which Azure solution (DB) would work here\n4. Analyse the data using PySpark by querying it from DB&lt;/p&gt;\n\n&lt;p&gt;Does this sound reasonable? Does anyone has materials/tutorials that follow similar process so I could use them as blueprints for my pipeline?&lt;/p&gt;\n\n&lt;p&gt;Any comments, suggestions are very welcome! Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zl7hvk", "is_robot_indexable": true, "report_reasons": null, "author": "ovcee", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zl7hvk/processing_large_number_of_jsons_12tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zl7hvk/processing_large_number_of_jsons_12tb/", "subreddit_subscribers": 82893, "created_utc": 1670966849.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello\nFellow BI developer here. I want to learn data engineering , but I cannot get an access on client side to his warehouse - they supply me with views requested by me. How can I develop my skills regarding that subject \"at home\" and utilise that?", "author_fullname": "t2_ajcdrgrx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get an experience without access to the warehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zkxwjo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670943860.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello\nFellow BI developer here. I want to learn data engineering , but I cannot get an access on client side to his warehouse - they supply me with views requested by me. How can I develop my skills regarding that subject &amp;quot;at home&amp;quot; and utilise that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zkxwjo", "is_robot_indexable": true, "report_reasons": null, "author": "Commercial-Ask971", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zkxwjo/how_to_get_an_experience_without_access_to_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zkxwjo/how_to_get_an_experience_without_access_to_the/", "subreddit_subscribers": 82893, "created_utc": 1670943860.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello folks, especially airflow users.  \nI have 4 servers (A1, A2, B1, B2). Servers A1, and A2 have, for example, permissions to api XA and can handle locally some ETLa of type A. On the other hand servers B1, and B2 don't have any way to connect to API XA and don't have dependencies installed for ETL of type A.  \n\n\nOn server C (5th) one I want to install airflow scheduler and for example start some ETL which can be handled parallelly on A1 and A2 and without worrying that this task will be also sent to B1 or B2 serwer and vice versa  \nHow to achieve this with airflow?", "author_fullname": "t2_170b3o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can Airflow workers have some kind of tags which allow them pick only some kinds of tasks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zl5xzv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670963196.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello folks, especially airflow users.&lt;br/&gt;\nI have 4 servers (A1, A2, B1, B2). Servers A1, and A2 have, for example, permissions to api XA and can handle locally some ETLa of type A. On the other hand servers B1, and B2 don&amp;#39;t have any way to connect to API XA and don&amp;#39;t have dependencies installed for ETL of type A.  &lt;/p&gt;\n\n&lt;p&gt;On server C (5th) one I want to install airflow scheduler and for example start some ETL which can be handled parallelly on A1 and A2 and without worrying that this task will be also sent to B1 or B2 serwer and vice versa&lt;br/&gt;\nHow to achieve this with airflow?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zl5xzv", "is_robot_indexable": true, "report_reasons": null, "author": "kiwimic", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zl5xzv/can_airflow_workers_have_some_kind_of_tags_which/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zl5xzv/can_airflow_workers_have_some_kind_of_tags_which/", "subreddit_subscribers": 82893, "created_utc": 1670963196.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What's going on everyone, I'm majoring in physics and believe I'll pursue a minor in math or statistics, and want to be able to pursue an entry level data job upon graduation if I want to. Was wondering if anyone specifically had any certifications or projects specific to data engineering I could attempt during my time in school outside of classes in order to make me more appealing to employers.\n\nSome friends who currently work in the field basically just said that an entry level job is the best possible thing for learning anything in the field, and I understand that, however I'm looking for something I can do in the meantime.\n\nThanks so much for any advice.", "author_fullname": "t2_ug51jle0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for Undergrad", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zl2oou", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670955499.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What&amp;#39;s going on everyone, I&amp;#39;m majoring in physics and believe I&amp;#39;ll pursue a minor in math or statistics, and want to be able to pursue an entry level data job upon graduation if I want to. Was wondering if anyone specifically had any certifications or projects specific to data engineering I could attempt during my time in school outside of classes in order to make me more appealing to employers.&lt;/p&gt;\n\n&lt;p&gt;Some friends who currently work in the field basically just said that an entry level job is the best possible thing for learning anything in the field, and I understand that, however I&amp;#39;m looking for something I can do in the meantime.&lt;/p&gt;\n\n&lt;p&gt;Thanks so much for any advice.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zl2oou", "is_robot_indexable": true, "report_reasons": null, "author": "Western-Pangolin4820", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zl2oou/advice_for_undergrad/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zl2oou/advice_for_undergrad/", "subreddit_subscribers": 82893, "created_utc": 1670955499.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey r/dataengineering!\n\nHow many of you struggle with scaling your Jupyter notebooks?\n\n&amp;#x200B;\n\nhttps://i.redd.it/trcc778vvo5a1.gif\n\nWe just launched a new UI to scale notebooks on the cloud, this allows you to drop your .ipynb notebooks, execute it (with scale) and get the results to your local environment. It\u2019s all based on our APIs/open-source software and allows you to scale your work without infrastructure!\n\n[Read more about it here](https://ploomber.io/blog/cloud-notebooks-gui/).\n\nFeel free to comment with any questions or insights!", "author_fullname": "t2_sy01bb7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scaling notebooks in the cloud with zero infrastructure configuration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 87, "top_awarded_type": null, "hide_score": false, "media_metadata": {"trcc778vvo5a1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 67, "x": 108, "u": "https://preview.redd.it/trcc778vvo5a1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=9ec3ea284b79d84b65f1c13fb83898f41785401d"}, {"y": 135, "x": 216, "u": "https://preview.redd.it/trcc778vvo5a1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=7648ed9814d6cb06893f860aefc471ccf1284482"}, {"y": 200, "x": 320, "u": "https://preview.redd.it/trcc778vvo5a1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=b6c5e3a9337d1b328437042a2269e8514e94b434"}, {"y": 400, "x": 640, "u": "https://preview.redd.it/trcc778vvo5a1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=a0a5a64363a40e8d7975f8447d67c3d20ae264bd"}, {"y": 600, "x": 960, "u": "https://preview.redd.it/trcc778vvo5a1.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=4b7ac34d611317ba1072cb3dd0a6ccc02492d190"}, {"y": 675, "x": 1080, "u": "https://preview.redd.it/trcc778vvo5a1.gif?width=1080&amp;crop=smart&amp;format=png8&amp;s=84362f619a34bbbd15d955d681248426a4c3fbd7"}], "s": {"y": 1200, "gif": "https://i.redd.it/trcc778vvo5a1.gif", "mp4": "https://preview.redd.it/trcc778vvo5a1.gif?format=mp4&amp;s=02adfdc99f08c583f7d3317b69a3093b436357e7", "x": 1920}, "id": "trcc778vvo5a1"}}, "name": "t3_zkzb6p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/yiYOpT1yODfo-s1BM4pZW4xiyZMxnBqqJr4RhLXhT6A.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670947731.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt;!&lt;/p&gt;\n\n&lt;p&gt;How many of you struggle with scaling your Jupyter notebooks?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://i.redd.it/trcc778vvo5a1.gif\"&gt;https://i.redd.it/trcc778vvo5a1.gif&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;We just launched a new UI to scale notebooks on the cloud, this allows you to drop your .ipynb notebooks, execute it (with scale) and get the results to your local environment. It\u2019s all based on our APIs/open-source software and allows you to scale your work without infrastructure!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://ploomber.io/blog/cloud-notebooks-gui/\"&gt;Read more about it here&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Feel free to comment with any questions or insights!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zkzb6p", "is_robot_indexable": true, "report_reasons": null, "author": "idomic", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zkzb6p/scaling_notebooks_in_the_cloud_with_zero/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zkzb6p/scaling_notebooks_in_the_cloud_with_zero/", "subreddit_subscribers": 82893, "created_utc": 1670947731.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I am building ETL batch pipeline to transfer data from AWS RDS (MySQL) to Salesforce on daily basis. Now I am confused how should I approach this. Should I build everything locally and then deploy the container into AWS or should build my pipeline on the AWS using different services?\n\nPlease give me your suggestion.\n\nThanks!", "author_fullname": "t2_udvutrbv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Aws services or local development", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zlpbh3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "spoiler", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671019799.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I am building ETL batch pipeline to transfer data from AWS RDS (MySQL) to Salesforce on daily basis. Now I am confused how should I approach this. Should I build everything locally and then deploy the container into AWS or should build my pipeline on the AWS using different services?&lt;/p&gt;\n\n&lt;p&gt;Please give me your suggestion.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": true, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zlpbh3", "is_robot_indexable": true, "report_reasons": null, "author": "Usamacheema12345", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zlpbh3/aws_services_or_local_development/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zlpbh3/aws_services_or_local_development/", "subreddit_subscribers": 82893, "created_utc": 1671019799.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, thanks for reading this - I\u2019ll try to make it short! Essentially, I have been working in corporate finance for the past 7 years (budgeting, forecasting, analyzing finance data, reporting etc) &amp; have been working with data engineers throughout  past few years automating these processes and eventually creating front end power BI dashboards. I\u2019ve realized this is a powerful skill set to have and plan on learning SQL &amp; Python for a year or 2 to eventually get some experience doing this stuff myself. My main question is how much would someone expect to earn with my background with these skill sets? I know it depends on the industry and company but a ballpark number? After some experience at my current company I would want to leave and only focus on data automation of financial processes. This is the ballpark figure I am looking for.\n\nThank you!!!!", "author_fullname": "t2_7qlpxamu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Becoming a data engineer with 7 years experience in Corporate Finance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zlhv19", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670993483.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, thanks for reading this - I\u2019ll try to make it short! Essentially, I have been working in corporate finance for the past 7 years (budgeting, forecasting, analyzing finance data, reporting etc) &amp;amp; have been working with data engineers throughout  past few years automating these processes and eventually creating front end power BI dashboards. I\u2019ve realized this is a powerful skill set to have and plan on learning SQL &amp;amp; Python for a year or 2 to eventually get some experience doing this stuff myself. My main question is how much would someone expect to earn with my background with these skill sets? I know it depends on the industry and company but a ballpark number? After some experience at my current company I would want to leave and only focus on data automation of financial processes. This is the ballpark figure I am looking for.&lt;/p&gt;\n\n&lt;p&gt;Thank you!!!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zlhv19", "is_robot_indexable": true, "report_reasons": null, "author": "ashton5569", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zlhv19/becoming_a_data_engineer_with_7_years_experience/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zlhv19/becoming_a_data_engineer_with_7_years_experience/", "subreddit_subscribers": 82893, "created_utc": 1670993483.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a self employed CPA making very good money, however find the job to be stressful and although one of my strong suits is dealing with clients, I hate it. \n\nThis field interests me, always has, and I see some synergies between accounting/data. Where do I need to go from here to explore a career? What is ground zero? Any help appreciated.", "author_fullname": "t2_ogss1t18", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zledv4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670983666.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a self employed CPA making very good money, however find the job to be stressful and although one of my strong suits is dealing with clients, I hate it. &lt;/p&gt;\n\n&lt;p&gt;This field interests me, always has, and I see some synergies between accounting/data. Where do I need to go from here to explore a career? What is ground zero? Any help appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zledv4", "is_robot_indexable": true, "report_reasons": null, "author": "Sea_Escape_1306", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zledv4/career_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zledv4/career_advice/", "subreddit_subscribers": 82893, "created_utc": 1670983666.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m wanting to build a data engineering project to show potential employers I have some skills.\n\nThere seems to be tons of ways a project can be built. So, question is, **which tools should a data engineering project include** to not be overly complex but not very simple?\n\nMaybe even a better question: what would a good project look like that would impress you?\n\nThe plethora of tools out there makes it overwhelming and a bit complicated to a beginner. \n\nWould appreciate some ideas!", "author_fullname": "t2_a4wvyz1l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which tools should a project use?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zle5wj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670983086.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m wanting to build a data engineering project to show potential employers I have some skills.&lt;/p&gt;\n\n&lt;p&gt;There seems to be tons of ways a project can be built. So, question is, &lt;strong&gt;which tools should a data engineering project include&lt;/strong&gt; to not be overly complex but not very simple?&lt;/p&gt;\n\n&lt;p&gt;Maybe even a better question: what would a good project look like that would impress you?&lt;/p&gt;\n\n&lt;p&gt;The plethora of tools out there makes it overwhelming and a bit complicated to a beginner. &lt;/p&gt;\n\n&lt;p&gt;Would appreciate some ideas!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zle5wj", "is_robot_indexable": true, "report_reasons": null, "author": "HeavyFuckingMetalx", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zle5wj/which_tools_should_a_project_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zle5wj/which_tools_should_a_project_use/", "subreddit_subscribers": 82893, "created_utc": 1670983086.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need a database that can find a row in a few seconds in a 14gb database. Redis would use too much ram so I am using MongoDB as of now.", "author_fullname": "t2_doifhh58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "14 gb read only database", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zl287g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670954447.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need a database that can find a row in a few seconds in a 14gb database. Redis would use too much ram so I am using MongoDB as of now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zl287g", "is_robot_indexable": true, "report_reasons": null, "author": "leggyybtw", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zl287g/14_gb_read_only_database/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zl287g/14_gb_read_only_database/", "subreddit_subscribers": 82893, "created_utc": 1670954447.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}