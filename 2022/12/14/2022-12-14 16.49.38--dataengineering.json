{"kind": "Listing", "data": {"after": "t3_zlkymb", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What kind of scripts ir programs do you develop?\n\nI'm currently a data engineer only using a low code cloud platform (informatica) and i am unmotivated with my routine.", "author_fullname": "t2_2s92xxvc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you need to code in your job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zl7gvh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 77, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 77, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670966783.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What kind of scripts ir programs do you develop?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently a data engineer only using a low code cloud platform (informatica) and i am unmotivated with my routine.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zl7gvh", "is_robot_indexable": true, "report_reasons": null, "author": "Idalen", "discussion_type": null, "num_comments": 74, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zl7gvh/do_you_need_to_code_in_your_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zl7gvh/do_you_need_to_code_in_your_job/", "subreddit_subscribers": 82908, "created_utc": 1670966783.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm ok with take home programming tests and leetcode.  However, I noticed during my last job search that every company that had a take home project that I completed ended up rejecting me.\n\n\n\n\nIt almost seems like a better time investment to spend 3-5 hours studying leetcode than doing a take home project.", "author_fullname": "t2_3v6ob2bf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone else turn down interviews that involve a take home project?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zlao51", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 42, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 42, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670974196.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m ok with take home programming tests and leetcode.  However, I noticed during my last job search that every company that had a take home project that I completed ended up rejecting me.&lt;/p&gt;\n\n&lt;p&gt;It almost seems like a better time investment to spend 3-5 hours studying leetcode than doing a take home project.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zlao51", "is_robot_indexable": true, "report_reasons": null, "author": "data_preprocessing", "discussion_type": null, "num_comments": 46, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zlao51/does_anyone_else_turn_down_interviews_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zlao51/does_anyone_else_turn_down_interviews_that/", "subreddit_subscribers": 82908, "created_utc": 1670974196.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When I had my first analyst job 11 years ago, I was at a microsoft shop. I learned SQL on MS SQL Server 2012. To this day, I think it was the best console I've ever used for just writing and executing queries.I use pycharm as my IDE which works great for DBT development but the console sucks. The snowflake browser-based console slows me down. I don't need an IDE that is for hardcore software development. I'd like to get something that is designed for SQL queries--has a good database object explorer and possibly saves query history. A feature I have been searching for since SQL Server is just the ability to execute multiple statements at the same time and see all the results in the output pane at once. Cost is not an issue; I can get a license. Suggestions?", "author_fullname": "t2_yxzao", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best SQL Console?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zlh26w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670991068.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When I had my first analyst job 11 years ago, I was at a microsoft shop. I learned SQL on MS SQL Server 2012. To this day, I think it was the best console I&amp;#39;ve ever used for just writing and executing queries.I use pycharm as my IDE which works great for DBT development but the console sucks. The snowflake browser-based console slows me down. I don&amp;#39;t need an IDE that is for hardcore software development. I&amp;#39;d like to get something that is designed for SQL queries--has a good database object explorer and possibly saves query history. A feature I have been searching for since SQL Server is just the ability to execute multiple statements at the same time and see all the results in the output pane at once. Cost is not an issue; I can get a license. Suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zlh26w", "is_robot_indexable": true, "report_reasons": null, "author": "mrp4434", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zlh26w/best_sql_console/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zlh26w/best_sql_console/", "subreddit_subscribers": 82908, "created_utc": 1670991068.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\n&amp;#x200B;\n\nI am recently tasked with switching over some ETL tasks from Fivetran to Keboola. The only good thing I see in this switch is that we save some $$$.\n\n&amp;#x200B;\n\nThe Keboola UI and the connectors seem suitable with what we need, but then there comes the Dev and Test time + the risk of messing up ETL jobs / data integrity. Aand the time table is that we shall finish this in 4 weeks (not many tables, not very big)\n\n&amp;#x200B;\n\nDoes anybody else have any intuition? I was arguing with some colleagues -&gt; that it\\`s not worth it to put in 3-4 weeks in hardcore keboola dev + new tests, just to save 2000$/month - keboola cost(which they said it\\`s under 1000$ a month)\n\nI am not a decision maker.\n\nAny help is appreciated!", "author_fullname": "t2_2i1av4aw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Keboola pros and cons", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zl0d5i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670950192.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I am recently tasked with switching over some ETL tasks from Fivetran to Keboola. The only good thing I see in this switch is that we save some $$$.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The Keboola UI and the connectors seem suitable with what we need, but then there comes the Dev and Test time + the risk of messing up ETL jobs / data integrity. Aand the time table is that we shall finish this in 4 weeks (not many tables, not very big)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Does anybody else have any intuition? I was arguing with some colleagues -&amp;gt; that it`s not worth it to put in 3-4 weeks in hardcore keboola dev + new tests, just to save 2000$/month - keboola cost(which they said it`s under 1000$ a month)&lt;/p&gt;\n\n&lt;p&gt;I am not a decision maker.&lt;/p&gt;\n\n&lt;p&gt;Any help is appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zl0d5i", "is_robot_indexable": true, "report_reasons": null, "author": "younggamech", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zl0d5i/keboola_pros_and_cons/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zl0d5i/keboola_pros_and_cons/", "subreddit_subscribers": 82908, "created_utc": 1670950192.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all\n\nI recently started a new position at a small ERP software company (Whose main product is built on top of Microsoft's Business Central) as what was going to be mainly a BI Dev/Data Coordinator. My main relevant experience previous to this position was mostly as a BI Dev and some small SSIS projects and a bit of Python dabbling, so nothing advanced at the Data engineering level. In this new position I'm inheriting the reports and not so great documentation left by a previoul developer which only worked on Power BI part-time and I am totally alone, without mentor or colleague.\n\nThe main data related task I've had to dealt with in the first few weeks is evaluating and improving a package of Power BI Reports we offer to our clients. These reports contain zero external sources and get all their data from the ERP through published ODATA web services.\nManagement has plans to develop some sort of data strategy, which I can broadly describe as using our ERP client's anonymized data (Previously agreed under contract) to generate industry insights and feed them back into their reports, adding related data from external sources like regional or central government datasets and, as a medium-term goal, becoming a local industry reference as information/insight/dataset providers.\n\nWe have no central data infrastructure, not even an On-Prem SQL Server DB so I've been tasked to look for solutions that would help us get on track. I've even been told not to ask our current Microsoft CSP as we're in the process of changing partners. \nI've thought of the simplest solution as being a cloud  ETL/ELT service + DB/DWH (Our data volumes are not extreme at the moment)\n\nI've been reading the subreddit for the past week and I must admit it's been a bit overwhelming. The sheer number of different technologies and ways to implement a project can drive somebody without experience crazy. \nAs we're a Microsoft shop, it seems to me we should head towards Azure as it should have the least challenging barrier to entry.\n\nWhat would be a first step for us, just start with Azure Data Factory + Azure SQL Database? Any other solution from the big providers worth considering?\n\nThank you!", "author_fullname": "t2_5ho6r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What would be a solid first step for a small company with zero data infrastructure?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zl4dpw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1670965501.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670959486.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all&lt;/p&gt;\n\n&lt;p&gt;I recently started a new position at a small ERP software company (Whose main product is built on top of Microsoft&amp;#39;s Business Central) as what was going to be mainly a BI Dev/Data Coordinator. My main relevant experience previous to this position was mostly as a BI Dev and some small SSIS projects and a bit of Python dabbling, so nothing advanced at the Data engineering level. In this new position I&amp;#39;m inheriting the reports and not so great documentation left by a previoul developer which only worked on Power BI part-time and I am totally alone, without mentor or colleague.&lt;/p&gt;\n\n&lt;p&gt;The main data related task I&amp;#39;ve had to dealt with in the first few weeks is evaluating and improving a package of Power BI Reports we offer to our clients. These reports contain zero external sources and get all their data from the ERP through published ODATA web services.\nManagement has plans to develop some sort of data strategy, which I can broadly describe as using our ERP client&amp;#39;s anonymized data (Previously agreed under contract) to generate industry insights and feed them back into their reports, adding related data from external sources like regional or central government datasets and, as a medium-term goal, becoming a local industry reference as information/insight/dataset providers.&lt;/p&gt;\n\n&lt;p&gt;We have no central data infrastructure, not even an On-Prem SQL Server DB so I&amp;#39;ve been tasked to look for solutions that would help us get on track. I&amp;#39;ve even been told not to ask our current Microsoft CSP as we&amp;#39;re in the process of changing partners. \nI&amp;#39;ve thought of the simplest solution as being a cloud  ETL/ELT service + DB/DWH (Our data volumes are not extreme at the moment)&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been reading the subreddit for the past week and I must admit it&amp;#39;s been a bit overwhelming. The sheer number of different technologies and ways to implement a project can drive somebody without experience crazy. \nAs we&amp;#39;re a Microsoft shop, it seems to me we should head towards Azure as it should have the least challenging barrier to entry.&lt;/p&gt;\n\n&lt;p&gt;What would be a first step for us, just start with Azure Data Factory + Azure SQL Database? Any other solution from the big providers worth considering?&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zl4dpw", "is_robot_indexable": true, "report_reasons": null, "author": "pescawito", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zl4dpw/what_would_be_a_solid_first_step_for_a_small/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zl4dpw/what_would_be_a_solid_first_step_for_a_small/", "subreddit_subscribers": 82908, "created_utc": 1670959486.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_nrfxa5al", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is Apache Arrow? by Pandas Creator Wes McKinnley", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_zl5a2m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "ups": 10, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/DTqGMRYcEt0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"What is Apache Arrow? by Pandas Creator Wes McKinnley\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "What is Apache Arrow? by Pandas Creator Wes McKinnley", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/DTqGMRYcEt0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"What is Apache Arrow? by Pandas Creator Wes McKinnley\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/DTqGMRYcEt0/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/DTqGMRYcEt0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"What is Apache Arrow? by Pandas Creator Wes McKinnley\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/zl5a2m", "height": 200}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/GqCdTbaIFGEoShSFL1FwWisYm4s3b2tKBLm-aYkCCnw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1670961650.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/DTqGMRYcEt0", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bvvF3--YXb2Cbs7ufOk9v3dHzOFOy_T8vkjoswbrpxk.jpg?auto=webp&amp;v=enabled&amp;s=3278c9988988664214cf9199a3c2bdafdf6e1233", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/bvvF3--YXb2Cbs7ufOk9v3dHzOFOy_T8vkjoswbrpxk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=edd04f188d68886b939f70115145d677c8baa7c3", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/bvvF3--YXb2Cbs7ufOk9v3dHzOFOy_T8vkjoswbrpxk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=440c2e7ef05e96d2c657595b4426a29b49a2acde", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/bvvF3--YXb2Cbs7ufOk9v3dHzOFOy_T8vkjoswbrpxk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dfa29f3215584f668465fa9d8c84d3114aae5b1b", "width": 320, "height": 240}], "variants": {}, "id": "ov7EwPXX779b4PjEgaZifspj4-Ctcov99EXmQ_FkDmM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zl5a2m", "is_robot_indexable": true, "report_reasons": null, "author": "CatanNicollo", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zl5a2m/what_is_apache_arrow_by_pandas_creator_wes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/DTqGMRYcEt0", "subreddit_subscribers": 82908, "created_utc": 1670961650.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "What is Apache Arrow? by Pandas Creator Wes McKinnley", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/DTqGMRYcEt0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"What is Apache Arrow? by Pandas Creator Wes McKinnley\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/DTqGMRYcEt0/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I am trying to switch to data engineering after taking a break from my career. I was thinking of creating a portfolio project using data from a subreddit. I wanted to use the Reddit API for the same. Can I use the free version of the API given the project will be available publically and I won't benefit financially from it?", "author_fullname": "t2_6960i650", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using Reddit API for a portfolio project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zln02b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671011674.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am trying to switch to data engineering after taking a break from my career. I was thinking of creating a portfolio project using data from a subreddit. I wanted to use the Reddit API for the same. Can I use the free version of the API given the project will be available publically and I won&amp;#39;t benefit financially from it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zln02b", "is_robot_indexable": true, "report_reasons": null, "author": "TheBrownViking20", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zln02b/using_reddit_api_for_a_portfolio_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zln02b/using_reddit_api_for_a_portfolio_project/", "subreddit_subscribers": 82908, "created_utc": 1671011674.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Did you know that the bio mass of all bacteria is way bigger then the bio mass of all human? I wonder if the same relation is or will be true for IoT and server calculation power. \n\nWhile Server are obviously so powerful compared to IoT, I wonder if the sheer amount of the devices will compensate that. \n\nI am working with IoT devices and we currently do all the hard calculation on a server but I was thinking about the fact that we are wasting capacity on the devices. If the utilization is just 20% why not using the rest for stuff we are currently doing server-side. Maybe we also could stream data back from server to device for calculation jobs. \n\nIf that would work, I wonder how I can design a good DE architecture that accounts for that functionality.", "author_fullname": "t2_s3omzbn3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "IoT vs Server Computing Power", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zlkr8j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671003124.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Did you know that the bio mass of all bacteria is way bigger then the bio mass of all human? I wonder if the same relation is or will be true for IoT and server calculation power. &lt;/p&gt;\n\n&lt;p&gt;While Server are obviously so powerful compared to IoT, I wonder if the sheer amount of the devices will compensate that. &lt;/p&gt;\n\n&lt;p&gt;I am working with IoT devices and we currently do all the hard calculation on a server but I was thinking about the fact that we are wasting capacity on the devices. If the utilization is just 20% why not using the rest for stuff we are currently doing server-side. Maybe we also could stream data back from server to device for calculation jobs. &lt;/p&gt;\n\n&lt;p&gt;If that would work, I wonder how I can design a good DE architecture that accounts for that functionality.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zlkr8j", "is_robot_indexable": true, "report_reasons": null, "author": "ZenCoding", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zlkr8j/iot_vs_server_computing_power/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zlkr8j/iot_vs_server_computing_power/", "subreddit_subscribers": 82908, "created_utc": 1671003124.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I'm preparing a presentation about Hadoop and Spark and I have to explain a use case where hadoop only is used and another use case where spark only is used , I've been looking in the internet but I didn't find an explanation of how exactly hadoop and spark has been used.\n\nAny help please ?", "author_fullname": "t2_byxenypn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hadoop and Spark use cases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zla8iv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670973155.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;m preparing a presentation about Hadoop and Spark and I have to explain a use case where hadoop only is used and another use case where spark only is used , I&amp;#39;ve been looking in the internet but I didn&amp;#39;t find an explanation of how exactly hadoop and spark has been used.&lt;/p&gt;\n\n&lt;p&gt;Any help please ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zla8iv", "is_robot_indexable": true, "report_reasons": null, "author": "AB3NZ", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zla8iv/hadoop_and_spark_use_cases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zla8iv/hadoop_and_spark_use_cases/", "subreddit_subscribers": 82908, "created_utc": 1670973155.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_r6aazfpz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Data Bus: a helpful pattern for data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_zljykk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/xc2oOcKlC56QpG9ceRCnfgfIa-FYfwTM-cQWmvf8YsE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671000277.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "leblancfg.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://leblancfg.com/data-bus-pattern-for-data-engineering.html", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/IAin_BO0uoU85zBrMwe-V0pGua4DeradcEfq_pr9kZY.jpg?auto=webp&amp;v=enabled&amp;s=5f5a43f44e9980937b2260e3484b64fe1a335fbb", "width": 400, "height": 400}, "resolutions": [{"url": "https://external-preview.redd.it/IAin_BO0uoU85zBrMwe-V0pGua4DeradcEfq_pr9kZY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a782d98084acb8436dfc533764ec333629e66a28", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/IAin_BO0uoU85zBrMwe-V0pGua4DeradcEfq_pr9kZY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e44ce5e2c788193c859a80b218cb8fa03211ffff", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/IAin_BO0uoU85zBrMwe-V0pGua4DeradcEfq_pr9kZY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ca88872bdf0526ad369cb1457d0293f9dfffb8cb", "width": 320, "height": 320}], "variants": {}, "id": "HqKsU0Z01QouRbVlVBlldvDv37FPvmA0Ckt6IkisE2w"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zljykk", "is_robot_indexable": true, "report_reasons": null, "author": "Realistic-Cap6526", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zljykk/the_data_bus_a_helpful_pattern_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://leblancfg.com/data-bus-pattern-for-data-engineering.html", "subreddit_subscribers": 82908, "created_utc": 1671000277.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I am building ETL batch pipeline to transfer data from AWS RDS (MySQL) to Salesforce on daily basis. Now I am confused how should I approach this. Should I build everything locally and then deploy the container into AWS or should build my pipeline on the AWS using different services?\n\nPlease give me your suggestion.\n\nThanks!", "author_fullname": "t2_udvutrbv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Aws services or local development", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zlpbh3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "spoiler", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671019799.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I am building ETL batch pipeline to transfer data from AWS RDS (MySQL) to Salesforce on daily basis. Now I am confused how should I approach this. Should I build everything locally and then deploy the container into AWS or should build my pipeline on the AWS using different services?&lt;/p&gt;\n\n&lt;p&gt;Please give me your suggestion.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": true, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zlpbh3", "is_robot_indexable": true, "report_reasons": null, "author": "Usamacheema12345", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zlpbh3/aws_services_or_local_development/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zlpbh3/aws_services_or_local_development/", "subreddit_subscribers": 82908, "created_utc": 1671019799.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "(Disclaimer: I am new to Databricks and data engineering)\n\nI am looking for guidance/best practice to approach my task. I want to use Azure and Databricks.\n\nTask: Load and prepare data so that it can be efficiently/quickly analyzed in the future. The analysis will involve summary statistics, exploratory data analysis and maybe simple ML (regression)\n\nData: session level data (12TB) stored in 100 000 single line json files. Json schema is nested, includes arrays.\n\nAs I said above the task is to build infrastructure so the data can be processed efficiently in the future. There will be no new data flowing in. \n\nMy initial plan was to:\n1. Load data into blob storage\n2. Process data using PySpark \n    - flatten by reading into data frame \n    - save as parquet\n3. Store in a DB so the data can be quickly queried and analyzed \n    - I am not sure which Azure solution (DB) would work here\n4. Analyse the data using PySpark by querying it from DB\n\nDoes this sound reasonable? Does anyone has materials/tutorials that follow similar process so I could use them as blueprints for my pipeline?\n\nAny comments, suggestions are very welcome! Thanks.", "author_fullname": "t2_55s3bmua", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Processing large number of jsons (~12TB)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zl7hvk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670966849.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;(Disclaimer: I am new to Databricks and data engineering)&lt;/p&gt;\n\n&lt;p&gt;I am looking for guidance/best practice to approach my task. I want to use Azure and Databricks.&lt;/p&gt;\n\n&lt;p&gt;Task: Load and prepare data so that it can be efficiently/quickly analyzed in the future. The analysis will involve summary statistics, exploratory data analysis and maybe simple ML (regression)&lt;/p&gt;\n\n&lt;p&gt;Data: session level data (12TB) stored in 100 000 single line json files. Json schema is nested, includes arrays.&lt;/p&gt;\n\n&lt;p&gt;As I said above the task is to build infrastructure so the data can be processed efficiently in the future. There will be no new data flowing in. &lt;/p&gt;\n\n&lt;p&gt;My initial plan was to:\n1. Load data into blob storage\n2. Process data using PySpark \n    - flatten by reading into data frame \n    - save as parquet\n3. Store in a DB so the data can be quickly queried and analyzed \n    - I am not sure which Azure solution (DB) would work here\n4. Analyse the data using PySpark by querying it from DB&lt;/p&gt;\n\n&lt;p&gt;Does this sound reasonable? Does anyone has materials/tutorials that follow similar process so I could use them as blueprints for my pipeline?&lt;/p&gt;\n\n&lt;p&gt;Any comments, suggestions are very welcome! Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zl7hvk", "is_robot_indexable": true, "report_reasons": null, "author": "ovcee", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zl7hvk/processing_large_number_of_jsons_12tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zl7hvk/processing_large_number_of_jsons_12tb/", "subreddit_subscribers": 82908, "created_utc": 1670966849.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been reading the data warehouse toolkit as well as data engineering blog posts but I'm still having a hard time fleshing out a full picture of how everything integrates. Are there any really good resources that show a \"real-world\" data pipeline being built out? From modeling the data to designing the ETL/ELT pipeline to distributing the data via a data mart or dataset?  \n\nIdeally, a guide or two that show how this would be applied on-prem as well as in the cloud would be helpful.", "author_fullname": "t2_nhdew", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any really good end-to-end walkthroughs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zltid3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671030752.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been reading the data warehouse toolkit as well as data engineering blog posts but I&amp;#39;m still having a hard time fleshing out a full picture of how everything integrates. Are there any really good resources that show a &amp;quot;real-world&amp;quot; data pipeline being built out? From modeling the data to designing the ETL/ELT pipeline to distributing the data via a data mart or dataset?  &lt;/p&gt;\n\n&lt;p&gt;Ideally, a guide or two that show how this would be applied on-prem as well as in the cloud would be helpful.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zltid3", "is_robot_indexable": true, "report_reasons": null, "author": "MonkeyMaster64", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zltid3/any_really_good_endtoend_walkthroughs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zltid3/any_really_good_endtoend_walkthroughs/", "subreddit_subscribers": 82908, "created_utc": 1671030752.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, thanks for reading this - I\u2019ll try to make it short! Essentially, I have been working in corporate finance for the past 7 years (budgeting, forecasting, analyzing finance data, reporting etc) &amp; have been working with data engineers throughout  past few years automating these processes and eventually creating front end power BI dashboards. I\u2019ve realized this is a powerful skill set to have and plan on learning SQL &amp; Python for a year or 2 to eventually get some experience doing this stuff myself. My main question is how much would someone expect to earn with my background with these skill sets? I know it depends on the industry and company but a ballpark number? After some experience at my current company I would want to leave and only focus on data automation of financial processes. This is the ballpark figure I am looking for.\n\nThank you!!!!", "author_fullname": "t2_7qlpxamu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Becoming a data engineer with 7 years experience in Corporate Finance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zlhv19", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670993483.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, thanks for reading this - I\u2019ll try to make it short! Essentially, I have been working in corporate finance for the past 7 years (budgeting, forecasting, analyzing finance data, reporting etc) &amp;amp; have been working with data engineers throughout  past few years automating these processes and eventually creating front end power BI dashboards. I\u2019ve realized this is a powerful skill set to have and plan on learning SQL &amp;amp; Python for a year or 2 to eventually get some experience doing this stuff myself. My main question is how much would someone expect to earn with my background with these skill sets? I know it depends on the industry and company but a ballpark number? After some experience at my current company I would want to leave and only focus on data automation of financial processes. This is the ballpark figure I am looking for.&lt;/p&gt;\n\n&lt;p&gt;Thank you!!!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zlhv19", "is_robot_indexable": true, "report_reasons": null, "author": "ashton5569", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zlhv19/becoming_a_data_engineer_with_7_years_experience/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zlhv19/becoming_a_data_engineer_with_7_years_experience/", "subreddit_subscribers": 82908, "created_utc": 1670993483.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello folks, especially airflow users.  \nI have 4 servers (A1, A2, B1, B2). Servers A1, and A2 have, for example, permissions to api XA and can handle locally some ETLa of type A. On the other hand servers B1, and B2 don't have any way to connect to API XA and don't have dependencies installed for ETL of type A.  \n\n\nOn server C (5th) one I want to install airflow scheduler and for example start some ETL which can be handled parallelly on A1 and A2 and without worrying that this task will be also sent to B1 or B2 serwer and vice versa  \nHow to achieve this with airflow?", "author_fullname": "t2_170b3o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can Airflow workers have some kind of tags which allow them pick only some kinds of tasks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zl5xzv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670963196.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello folks, especially airflow users.&lt;br/&gt;\nI have 4 servers (A1, A2, B1, B2). Servers A1, and A2 have, for example, permissions to api XA and can handle locally some ETLa of type A. On the other hand servers B1, and B2 don&amp;#39;t have any way to connect to API XA and don&amp;#39;t have dependencies installed for ETL of type A.  &lt;/p&gt;\n\n&lt;p&gt;On server C (5th) one I want to install airflow scheduler and for example start some ETL which can be handled parallelly on A1 and A2 and without worrying that this task will be also sent to B1 or B2 serwer and vice versa&lt;br/&gt;\nHow to achieve this with airflow?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zl5xzv", "is_robot_indexable": true, "report_reasons": null, "author": "kiwimic", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zl5xzv/can_airflow_workers_have_some_kind_of_tags_which/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zl5xzv/can_airflow_workers_have_some_kind_of_tags_which/", "subreddit_subscribers": 82908, "created_utc": 1670963196.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What's going on everyone, I'm majoring in physics and believe I'll pursue a minor in math or statistics, and want to be able to pursue an entry level data job upon graduation if I want to. Was wondering if anyone specifically had any certifications or projects specific to data engineering I could attempt during my time in school outside of classes in order to make me more appealing to employers.\n\nSome friends who currently work in the field basically just said that an entry level job is the best possible thing for learning anything in the field, and I understand that, however I'm looking for something I can do in the meantime.\n\nThanks so much for any advice.", "author_fullname": "t2_ug51jle0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for Undergrad", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zl2oou", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670955499.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What&amp;#39;s going on everyone, I&amp;#39;m majoring in physics and believe I&amp;#39;ll pursue a minor in math or statistics, and want to be able to pursue an entry level data job upon graduation if I want to. Was wondering if anyone specifically had any certifications or projects specific to data engineering I could attempt during my time in school outside of classes in order to make me more appealing to employers.&lt;/p&gt;\n\n&lt;p&gt;Some friends who currently work in the field basically just said that an entry level job is the best possible thing for learning anything in the field, and I understand that, however I&amp;#39;m looking for something I can do in the meantime.&lt;/p&gt;\n\n&lt;p&gt;Thanks so much for any advice.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zl2oou", "is_robot_indexable": true, "report_reasons": null, "author": "Western-Pangolin4820", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zl2oou/advice_for_undergrad/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zl2oou/advice_for_undergrad/", "subreddit_subscribers": 82908, "created_utc": 1670955499.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey r/dataengineering!\n\nHow many of you struggle with scaling your Jupyter notebooks?\n\n&amp;#x200B;\n\nhttps://i.redd.it/trcc778vvo5a1.gif\n\nWe just launched a new UI to scale notebooks on the cloud, this allows you to drop your .ipynb notebooks, execute it (with scale) and get the results to your local environment. It\u2019s all based on our APIs/open-source software and allows you to scale your work without infrastructure!\n\n[Read more about it here](https://ploomber.io/blog/cloud-notebooks-gui/).\n\nFeel free to comment with any questions or insights!", "author_fullname": "t2_sy01bb7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scaling notebooks in the cloud with zero infrastructure configuration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 87, "top_awarded_type": null, "hide_score": false, "media_metadata": {"trcc778vvo5a1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 67, "x": 108, "u": "https://preview.redd.it/trcc778vvo5a1.gif?width=108&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=65503397fff6fd9e51bb3ae2b4c58ec112f19a66"}, {"y": 135, "x": 216, "u": "https://preview.redd.it/trcc778vvo5a1.gif?width=216&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=04acd1eec1b2faab1c8f88567fcdb0e49d73b117"}, {"y": 200, "x": 320, "u": "https://preview.redd.it/trcc778vvo5a1.gif?width=320&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=f71a0990dec0250167914e81e64a2f2150310e26"}, {"y": 400, "x": 640, "u": "https://preview.redd.it/trcc778vvo5a1.gif?width=640&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=a0d75cb1998d5295beaf408ca6b4cc876062c5b2"}, {"y": 600, "x": 960, "u": "https://preview.redd.it/trcc778vvo5a1.gif?width=960&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=bcd82635380ab165aedcc78312b51917e6f20a27"}, {"y": 675, "x": 1080, "u": "https://preview.redd.it/trcc778vvo5a1.gif?width=1080&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=e9b360c1f2218834ace9b69461dc29b47cf6cde2"}], "s": {"y": 1200, "gif": "https://i.redd.it/trcc778vvo5a1.gif", "mp4": "https://preview.redd.it/trcc778vvo5a1.gif?format=mp4&amp;v=enabled&amp;s=6957bc6717d2a0a4f5b20dc65ea1305c82afa5a6", "x": 1920}, "id": "trcc778vvo5a1"}}, "name": "t3_zkzb6p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/yiYOpT1yODfo-s1BM4pZW4xiyZMxnBqqJr4RhLXhT6A.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670947731.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt;!&lt;/p&gt;\n\n&lt;p&gt;How many of you struggle with scaling your Jupyter notebooks?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://i.redd.it/trcc778vvo5a1.gif\"&gt;https://i.redd.it/trcc778vvo5a1.gif&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;We just launched a new UI to scale notebooks on the cloud, this allows you to drop your .ipynb notebooks, execute it (with scale) and get the results to your local environment. It\u2019s all based on our APIs/open-source software and allows you to scale your work without infrastructure!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://ploomber.io/blog/cloud-notebooks-gui/\"&gt;Read more about it here&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Feel free to comment with any questions or insights!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zkzb6p", "is_robot_indexable": true, "report_reasons": null, "author": "idomic", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zkzb6p/scaling_notebooks_in_the_cloud_with_zero/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zkzb6p/scaling_notebooks_in_the_cloud_with_zero/", "subreddit_subscribers": 82908, "created_utc": 1670947731.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "# 1. Define schemas.\n\nA schema defines the structure of your data. The fields and types the other side expects to receive. Having well-defined schemas and a single source of truth that store all your different models is a must as you scale and more interfaces join the party and request to consume from different data sources.\n\nAs schema changes will be requested, you would only need to perform the change once. \n\n# 2. Enforce.\n\nYou have to govern, or you will lose control. If you made a data contract both theoretically or technically, you need to enforce it.  \nEnsure data will not reach clients in a way they didn\u2019t ask for.\n\n# 3. Dedicated identity per client.\n\nAs your organization grows, more and more \u201chands\u201d will request to interact with the ingested data. It can be different clients, applications, and/or stakeholders.  \nMake sure each client receives a unique identity that can be traced and monitored, and in case some data-level / infra-level occurred, you would know who got affected, from which team, and the business impact instantly. It will help reach root-cause much faster than shooting slack messages and emails to the entire organization.\n\n# 4. Auditing.\n\nIn a federated architecture and data pipelines, where multiple domains, teams, and clients are often intertwined, one configuration change can create a chain of reactions that ultimately will crash the entire process. Auditing is crucial to ensure you approach the upstream rather than the middle.\n\n# 5. Notifications.\n\nLast but not least, notifications. Don\u2019t react when your staging environment or your tables/documents are already unaligned, or backends start to crash. Make sure you have notifications configured in every step of your pipeline. You get notified immediately if something goes wrong and data is not ingested as it should. Combining dedicated identity with auditing and a clear notification will enable you to sleep better. In case you awaken in the middle of the night, it will be for a short time and with all the information needed to fix it.\n\n&amp;#x200B;\n\nSource: [https://medium.com/memphis-dev/five-methods-to-increase-governance-over-your-data-clients-4eb7423510d6](https://medium.com/memphis-dev/five-methods-to-increase-governance-over-your-data-clients-4eb7423510d6)", "author_fullname": "t2_bqjrmnud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Five methods to increase governance over your data clients", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zluj0s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1671033219.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;1. Define schemas.&lt;/h1&gt;\n\n&lt;p&gt;A schema defines the structure of your data. The fields and types the other side expects to receive. Having well-defined schemas and a single source of truth that store all your different models is a must as you scale and more interfaces join the party and request to consume from different data sources.&lt;/p&gt;\n\n&lt;p&gt;As schema changes will be requested, you would only need to perform the change once. &lt;/p&gt;\n\n&lt;h1&gt;2. Enforce.&lt;/h1&gt;\n\n&lt;p&gt;You have to govern, or you will lose control. If you made a data contract both theoretically or technically, you need to enforce it.&lt;br/&gt;\nEnsure data will not reach clients in a way they didn\u2019t ask for.&lt;/p&gt;\n\n&lt;h1&gt;3. Dedicated identity per client.&lt;/h1&gt;\n\n&lt;p&gt;As your organization grows, more and more \u201chands\u201d will request to interact with the ingested data. It can be different clients, applications, and/or stakeholders.&lt;br/&gt;\nMake sure each client receives a unique identity that can be traced and monitored, and in case some data-level / infra-level occurred, you would know who got affected, from which team, and the business impact instantly. It will help reach root-cause much faster than shooting slack messages and emails to the entire organization.&lt;/p&gt;\n\n&lt;h1&gt;4. Auditing.&lt;/h1&gt;\n\n&lt;p&gt;In a federated architecture and data pipelines, where multiple domains, teams, and clients are often intertwined, one configuration change can create a chain of reactions that ultimately will crash the entire process. Auditing is crucial to ensure you approach the upstream rather than the middle.&lt;/p&gt;\n\n&lt;h1&gt;5. Notifications.&lt;/h1&gt;\n\n&lt;p&gt;Last but not least, notifications. Don\u2019t react when your staging environment or your tables/documents are already unaligned, or backends start to crash. Make sure you have notifications configured in every step of your pipeline. You get notified immediately if something goes wrong and data is not ingested as it should. Combining dedicated identity with auditing and a clear notification will enable you to sleep better. In case you awaken in the middle of the night, it will be for a short time and with all the information needed to fix it.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Source: &lt;a href=\"https://medium.com/memphis-dev/five-methods-to-increase-governance-over-your-data-clients-4eb7423510d6\"&gt;https://medium.com/memphis-dev/five-methods-to-increase-governance-over-your-data-clients-4eb7423510d6&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/r63d0peK7lR4hC-TgNGij3atmde2nRzwT52TjWbR1FE.jpg?auto=webp&amp;v=enabled&amp;s=050b22d042d9f08091aad6e45e7e846a107a1a5f", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/r63d0peK7lR4hC-TgNGij3atmde2nRzwT52TjWbR1FE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5d0435823d970aaec969980f55114d8e64723c8d", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/r63d0peK7lR4hC-TgNGij3atmde2nRzwT52TjWbR1FE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6cad6a166590b366b3eb10440f225fc290909c79", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/r63d0peK7lR4hC-TgNGij3atmde2nRzwT52TjWbR1FE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=63288dbd31e8da3a4f47eb9cc9aa1bd74b802010", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/r63d0peK7lR4hC-TgNGij3atmde2nRzwT52TjWbR1FE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c75e2c7bb99042534b77d93f834fe12084e19a5b", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/r63d0peK7lR4hC-TgNGij3atmde2nRzwT52TjWbR1FE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=22216e9dc1bad0db47cb1e35ff37a447c7cb4627", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/r63d0peK7lR4hC-TgNGij3atmde2nRzwT52TjWbR1FE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=189ed93707cbe92fad81537b9cdfa3f16b417c7d", "width": 1080, "height": 607}], "variants": {}, "id": "wnRFDkKH4_zSESjf-dKgPIz6PGGNHscbt6D41poYtBM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zluj0s", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering_Bug105", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zluj0s/five_methods_to_increase_governance_over_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zluj0s/five_methods_to_increase_governance_over_your/", "subreddit_subscribers": 82908, "created_utc": 1671033219.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[Learn how to route osquery logs.](https://www.decodable.co/blog/routing-osquery-events-via-apache-pulsar)\n\nOSQuery is an open source tool that lets you query operating system events using SQL.The events can be fed into a #streaming platform, in this case Pulsar, for subsequent transformation and routing on the stream using Decodable.\n\n&amp;#x200B;\n\n[Route OSQuery Logs](https://preview.redd.it/3r1wlfxggv5a1.jpg?width=377&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=0afa17ba946be69ecbc94426f1d6560611565e9f)\n\n\\#apache-flink #flink #security #logs #cybersecurity #osquery #sql #decodable #streaming #apache-pulsar #pulsar", "author_fullname": "t2_90mri5a8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Routing OSQuery Events via Apache Pulsar", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"3r1wlfxggv5a1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 112, "x": 108, "u": "https://preview.redd.it/3r1wlfxggv5a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8b2645c6182b9db2155a15a563e2b3d7a170af4a"}, {"y": 224, "x": 216, "u": "https://preview.redd.it/3r1wlfxggv5a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d31c808ed7d52b5616bb5656a9c0ff752b817423"}, {"y": 332, "x": 320, "u": "https://preview.redd.it/3r1wlfxggv5a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8b6c1a346ce4d7b612efa1e02d90e42b6b107ee8"}], "s": {"y": 392, "x": 377, "u": "https://preview.redd.it/3r1wlfxggv5a1.jpg?width=377&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=0afa17ba946be69ecbc94426f1d6560611565e9f"}, "id": "3r1wlfxggv5a1"}}, "name": "t3_zlrthq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/_vWcCSxdycUXpyHuCUEWopmghIdmzOB99FjnvKWYHCs.jpg", "edited": 1671027318.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671026752.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.decodable.co/blog/routing-osquery-events-via-apache-pulsar\"&gt;Learn how to route osquery logs.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;OSQuery is an open source tool that lets you query operating system events using SQL.The events can be fed into a #streaming platform, in this case Pulsar, for subsequent transformation and routing on the stream using Decodable.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/3r1wlfxggv5a1.jpg?width=377&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=0afa17ba946be69ecbc94426f1d6560611565e9f\"&gt;Route OSQuery Logs&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;#apache-flink #flink #security #logs #cybersecurity #osquery #sql #decodable #streaming #apache-pulsar #pulsar&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zlrthq", "is_robot_indexable": true, "report_reasons": null, "author": "hkdelay", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zlrthq/routing_osquery_events_via_apache_pulsar/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zlrthq/routing_osquery_events_via_apache_pulsar/", "subreddit_subscribers": 82908, "created_utc": 1671026752.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, first of all i am using Databricks. I have a raw dataframe, where based on some business logic i have to apply different filters. This is my preprocessing step, right now  i have 10 different jobs which produces processed dataframe(filtered).Since this is fairly easy task and not so expensive. I want to merge it into one single job.\n\nDo i benefit from something like this? How would u done it?How would u later write it to s3 lets say.\n\nIs map() ideal solution for this?\n\nShould i write some PandasUDF? Any opinion is good. =)\n\n     def _apply_filter(filter_: str) -&gt; pyspark.sql.DataFrame:\n        return rawDataFrame.filter(F.expr(filter_))\n    \n    FILTERS: List[str]\n    result: List[DataFrame] = list(map(_apply_filter, FILTERS))", "author_fullname": "t2_sx1wry60", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "applying set of filters on same dataframe", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zlqwag", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671024385.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, first of all i am using Databricks. I have a raw dataframe, where based on some business logic i have to apply different filters. This is my preprocessing step, right now  i have 10 different jobs which produces processed dataframe(filtered).Since this is fairly easy task and not so expensive. I want to merge it into one single job.&lt;/p&gt;\n\n&lt;p&gt;Do i benefit from something like this? How would u done it?How would u later write it to s3 lets say.&lt;/p&gt;\n\n&lt;p&gt;Is map() ideal solution for this?&lt;/p&gt;\n\n&lt;p&gt;Should i write some PandasUDF? Any opinion is good. =)&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt; def _apply_filter(filter_: str) -&amp;gt; pyspark.sql.DataFrame:\n    return rawDataFrame.filter(F.expr(filter_))\n\nFILTERS: List[str]\nresult: List[DataFrame] = list(map(_apply_filter, FILTERS))\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zlqwag", "is_robot_indexable": true, "report_reasons": null, "author": "AcceptableProcess772", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zlqwag/applying_set_of_filters_on_same_dataframe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zlqwag/applying_set_of_filters_on_same_dataframe/", "subreddit_subscribers": 82908, "created_utc": 1671024385.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a self employed CPA making very good money, however find the job to be stressful and although one of my strong suits is dealing with clients, I hate it. \n\nThis field interests me, always has, and I see some synergies between accounting/data. Where do I need to go from here to explore a career? What is ground zero? Any help appreciated.", "author_fullname": "t2_ogss1t18", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zledv4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670983666.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a self employed CPA making very good money, however find the job to be stressful and although one of my strong suits is dealing with clients, I hate it. &lt;/p&gt;\n\n&lt;p&gt;This field interests me, always has, and I see some synergies between accounting/data. Where do I need to go from here to explore a career? What is ground zero? Any help appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zledv4", "is_robot_indexable": true, "report_reasons": null, "author": "Sea_Escape_1306", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zledv4/career_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zledv4/career_advice/", "subreddit_subscribers": 82908, "created_utc": 1670983666.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m wanting to build a data engineering project to show potential employers I have some skills.\n\nThere seems to be tons of ways a project can be built. So, question is, **which tools should a data engineering project include** to not be overly complex but not very simple?\n\nMaybe even a better question: what would a good project look like that would impress you?\n\nThe plethora of tools out there makes it overwhelming and a bit complicated to a beginner. \n\nWould appreciate some ideas!", "author_fullname": "t2_a4wvyz1l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which tools should a project use?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zle5wj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670983086.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m wanting to build a data engineering project to show potential employers I have some skills.&lt;/p&gt;\n\n&lt;p&gt;There seems to be tons of ways a project can be built. So, question is, &lt;strong&gt;which tools should a data engineering project include&lt;/strong&gt; to not be overly complex but not very simple?&lt;/p&gt;\n\n&lt;p&gt;Maybe even a better question: what would a good project look like that would impress you?&lt;/p&gt;\n\n&lt;p&gt;The plethora of tools out there makes it overwhelming and a bit complicated to a beginner. &lt;/p&gt;\n\n&lt;p&gt;Would appreciate some ideas!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zle5wj", "is_robot_indexable": true, "report_reasons": null, "author": "HeavyFuckingMetalx", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zle5wj/which_tools_should_a_project_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zle5wj/which_tools_should_a_project_use/", "subreddit_subscribers": 82908, "created_utc": 1670983086.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need a database that can find a row in a few seconds in a 14gb database. Redis would use too much ram so I am using MongoDB as of now.", "author_fullname": "t2_doifhh58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "14 gb read only database", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zl287g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1670954447.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need a database that can find a row in a few seconds in a 14gb database. Redis would use too much ram so I am using MongoDB as of now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zl287g", "is_robot_indexable": true, "report_reasons": null, "author": "leggyybtw", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zl287g/14_gb_read_only_database/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zl287g/14_gb_read_only_database/", "subreddit_subscribers": 82908, "created_utc": 1670954447.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a recent CS graduate and I managed to work with a few languages to keep myself open to whichever route I ended up committing to. Therefore, at uni, I learnt (not mastered): \n\n* Python\n* Java\n* PHP \n* MySQL\n* HTML and CSS\n* JavaScript\n\nThe main issue I find with my CV is that for DE roles, the most useful *languages* I could put are Python and MySQL. I was going to learn a bit of Go but I've decided to start tinkering with PySpark instead. I've played around with pandas this past year with my courses. \n\nMy Skills section isn't as good as many CVs I've seen, so not sure how to go with things. I'm thinking of removing HTML, CSS and JavaScript from the list of languages, perhaps PHP too, which leaves me with just Python, Java and MySQL. My Java isn't as good, so I might just end up removing it.\n\nHere is how it looks: https://imgur.com/a/vKHRUV6\n\n***\n\nTo make my life easier, what things do you guys recommend me to learn while I'm applying for jobs? \n\nI wasn't taught cloud technologies, DevOps or most technologies I'm seeing floating around as well. Again, I'm going to be learning PySpark but not sure what else I could need?", "author_fullname": "t2_5902cw6k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lack of \"Languages\" to show on CV", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zlqqu4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1671024234.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1671023952.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a recent CS graduate and I managed to work with a few languages to keep myself open to whichever route I ended up committing to. Therefore, at uni, I learnt (not mastered): &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Python&lt;/li&gt;\n&lt;li&gt;Java&lt;/li&gt;\n&lt;li&gt;PHP &lt;/li&gt;\n&lt;li&gt;MySQL&lt;/li&gt;\n&lt;li&gt;HTML and CSS&lt;/li&gt;\n&lt;li&gt;JavaScript&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The main issue I find with my CV is that for DE roles, the most useful &lt;em&gt;languages&lt;/em&gt; I could put are Python and MySQL. I was going to learn a bit of Go but I&amp;#39;ve decided to start tinkering with PySpark instead. I&amp;#39;ve played around with pandas this past year with my courses. &lt;/p&gt;\n\n&lt;p&gt;My Skills section isn&amp;#39;t as good as many CVs I&amp;#39;ve seen, so not sure how to go with things. I&amp;#39;m thinking of removing HTML, CSS and JavaScript from the list of languages, perhaps PHP too, which leaves me with just Python, Java and MySQL. My Java isn&amp;#39;t as good, so I might just end up removing it.&lt;/p&gt;\n\n&lt;p&gt;Here is how it looks: &lt;a href=\"https://imgur.com/a/vKHRUV6\"&gt;https://imgur.com/a/vKHRUV6&lt;/a&gt;&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;To make my life easier, what things do you guys recommend me to learn while I&amp;#39;m applying for jobs? &lt;/p&gt;\n\n&lt;p&gt;I wasn&amp;#39;t taught cloud technologies, DevOps or most technologies I&amp;#39;m seeing floating around as well. Again, I&amp;#39;m going to be learning PySpark but not sure what else I could need?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/LarpdkIBJEfaTF1erGpKG0rmh1TkiO7SRI-r7rvZSxI.jpg?auto=webp&amp;v=enabled&amp;s=c3d73e42521e8baf9e7da06988477e00085f46a4", "width": 687, "height": 93}, "resolutions": [{"url": "https://external-preview.redd.it/LarpdkIBJEfaTF1erGpKG0rmh1TkiO7SRI-r7rvZSxI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9b70ea58bbf092d187a2780899fc92b7b9fd30f8", "width": 108, "height": 14}, {"url": "https://external-preview.redd.it/LarpdkIBJEfaTF1erGpKG0rmh1TkiO7SRI-r7rvZSxI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=670c9ac286e382470ae8da71e3f966bea7daafb5", "width": 216, "height": 29}, {"url": "https://external-preview.redd.it/LarpdkIBJEfaTF1erGpKG0rmh1TkiO7SRI-r7rvZSxI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0c08bf615a6143cd95afdac97dd89017c66b4ee6", "width": 320, "height": 43}, {"url": "https://external-preview.redd.it/LarpdkIBJEfaTF1erGpKG0rmh1TkiO7SRI-r7rvZSxI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8cfff9f685ee9343730b83b6231bfdb158e34c26", "width": 640, "height": 86}], "variants": {}, "id": "nrQ-wZXIPnVL2QlZAo-94qukF8DcavHFWJmrrcTQcT4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zlqqu4", "is_robot_indexable": true, "report_reasons": null, "author": "a_bigdonger", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zlqqu4/lack_of_languages_to_show_on_cv/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zlqqu4/lack_of_languages_to_show_on_cv/", "subreddit_subscribers": 82908, "created_utc": 1671023952.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_22rg4hgk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Simplest Realtime Streaming Data Pipeline On Google Cloud Platform - Async Queue", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_zlkymb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/Ghsa8S-JHiWfPdAxHgyLCXwrcgvCdq_DPYdQmaoBXe8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671003915.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "asyncq.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://asyncq.com/simplest-realtime-streaming-data-pipeline-on-google-cloud-platform", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/iPVZMYwFqR_2pa4b4RRwmN2xwwal7fXyiOr-jYjx8_s.jpg?auto=webp&amp;v=enabled&amp;s=50ecb5039c3516cece844bb80100cf33e591a856", "width": 1400, "height": 788}, "resolutions": [{"url": "https://external-preview.redd.it/iPVZMYwFqR_2pa4b4RRwmN2xwwal7fXyiOr-jYjx8_s.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8e048161e27fa7ac00ad47b4a682ce4c80332161", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/iPVZMYwFqR_2pa4b4RRwmN2xwwal7fXyiOr-jYjx8_s.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=53e51c6b3cf7492fad6da9cfe83aea49da503b11", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/iPVZMYwFqR_2pa4b4RRwmN2xwwal7fXyiOr-jYjx8_s.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d923ea80c8198a8981b7b1a52b6f82d552294a1a", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/iPVZMYwFqR_2pa4b4RRwmN2xwwal7fXyiOr-jYjx8_s.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1eb924e61a1c7af78b2053d38c1a2282aed91bd4", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/iPVZMYwFqR_2pa4b4RRwmN2xwwal7fXyiOr-jYjx8_s.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=21092b8d4684dac8835f531c7c5c339ea6eff5cb", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/iPVZMYwFqR_2pa4b4RRwmN2xwwal7fXyiOr-jYjx8_s.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9960f239b85a7d1fd056e112f9af235e8e32fc4f", "width": 1080, "height": 607}], "variants": {}, "id": "9QZBw_1mmz-BUBHXcsWVMrwBObI2aua05JGTL3QKJGs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zlkymb", "is_robot_indexable": true, "report_reasons": null, "author": "suraj-mishra15", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zlkymb/simplest_realtime_streaming_data_pipeline_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://asyncq.com/simplest-realtime-streaming-data-pipeline-on-google-cloud-platform", "subreddit_subscribers": 82908, "created_utc": 1671003915.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}