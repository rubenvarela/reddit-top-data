{"kind": "Listing", "data": {"after": null, "dist": 22, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Let me start of with myself first. But when stating your duties please include:\n- if you work for a large firm or small firm.\n- are you remote, work from home, hybrid or office only.\n- how many hours you work a day, how's the work life balance\n- do you code? Or mainly people manage\n- AWS / Azure / GCP or on prem etc\n\nHopefully this thread can help out other data engineers, especially newbies.\n\nI have started my first role as a junior data engineer, been around 11 months, recently graduated, predominantly using python on AWS.\n\nOn a day to basis (small firm):\n- wfh\n- 2-3 hours writing code but depends, mostly less, more planning.\n- building scalable web scrapers using scrapy and selenium.\n- cleaning and manipulating data from jsons and csvs.\n- use the following AWS services: lambda, sqs, s3 etc\n- transforming between excel and jsons and csvs.\n- creating etl pipelines on AWS.\n\nAny tips would be appreciated on: if this is a good career, tools used (airflow? Is it better than step functions?)", "author_fullname": "t2_45tfneon", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Share what you do as a data engineer on a day to day basis?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ztpk9z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 68, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 68, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1671839941.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671821434.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let me start of with myself first. But when stating your duties please include:\n- if you work for a large firm or small firm.\n- are you remote, work from home, hybrid or office only.\n- how many hours you work a day, how&amp;#39;s the work life balance\n- do you code? Or mainly people manage\n- AWS / Azure / GCP or on prem etc&lt;/p&gt;\n\n&lt;p&gt;Hopefully this thread can help out other data engineers, especially newbies.&lt;/p&gt;\n\n&lt;p&gt;I have started my first role as a junior data engineer, been around 11 months, recently graduated, predominantly using python on AWS.&lt;/p&gt;\n\n&lt;p&gt;On a day to basis (small firm):\n- wfh\n- 2-3 hours writing code but depends, mostly less, more planning.\n- building scalable web scrapers using scrapy and selenium.\n- cleaning and manipulating data from jsons and csvs.\n- use the following AWS services: lambda, sqs, s3 etc\n- transforming between excel and jsons and csvs.\n- creating etl pipelines on AWS.&lt;/p&gt;\n\n&lt;p&gt;Any tips would be appreciated on: if this is a good career, tools used (airflow? Is it better than step functions?)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ztpk9z", "is_robot_indexable": true, "report_reasons": null, "author": "Administrative_Ad768", "discussion_type": null, "num_comments": 59, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ztpk9z/share_what_you_do_as_a_data_engineer_on_a_day_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ztpk9z/share_what_you_do_as_a_data_engineer_on_a_day_to/", "subreddit_subscribers": 83990, "created_utc": 1671821434.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I came into a DE role about 5 years back with the prior five years having been experience as more of a BI Engineer. One thing I've been grappling with is I keep moving to companies that only have a few people to support data.  I hate that I climb to the top of a small ladder in just a few years and then need to look externally to try and figure out what my next career advancement looks like.\n\nDo most of you all work in environments like this where there are only a handful of data roles and your career path is mostly formed by moving around?  How do you plan and navigate your career progression?\n\nIn my current role we have one senior engineer other than myself and we support most underlying data processes at the company. There isn't really an \"up\" from here, and without more people I don't see them ever having staff engineers etc.\n\nMy thinking is I need to look for larger companies with bigger teams and probably more established such that there is something of a career track to progress through over 10+ years but I'm wondering how common that actually is.", "author_fullname": "t2_a8fiar", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you have a career path in your company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zte32g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 39, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 39, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671798491.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I came into a DE role about 5 years back with the prior five years having been experience as more of a BI Engineer. One thing I&amp;#39;ve been grappling with is I keep moving to companies that only have a few people to support data.  I hate that I climb to the top of a small ladder in just a few years and then need to look externally to try and figure out what my next career advancement looks like.&lt;/p&gt;\n\n&lt;p&gt;Do most of you all work in environments like this where there are only a handful of data roles and your career path is mostly formed by moving around?  How do you plan and navigate your career progression?&lt;/p&gt;\n\n&lt;p&gt;In my current role we have one senior engineer other than myself and we support most underlying data processes at the company. There isn&amp;#39;t really an &amp;quot;up&amp;quot; from here, and without more people I don&amp;#39;t see them ever having staff engineers etc.&lt;/p&gt;\n\n&lt;p&gt;My thinking is I need to look for larger companies with bigger teams and probably more established such that there is something of a career track to progress through over 10+ years but I&amp;#39;m wondering how common that actually is.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zte32g", "is_robot_indexable": true, "report_reasons": null, "author": "Cynot88", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zte32g/do_you_have_a_career_path_in_your_company/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zte32g/do_you_have_a_career_path_in_your_company/", "subreddit_subscribers": 83990, "created_utc": 1671798491.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All, \n\nI accepted an offer to join a new company that is primarily using pyspark, airflow, and kubernetes for their workflow. ( mostly an on-prem stack with open source tools) \n\nMy current job uses snowflake, sql scripts, python, airflow, kubernetes, and AWS. \n\nIt\u2019s going to be a transition to move from the Snowflake SQL based workflow to purely Pyspark. I am quite familiar with python and I have used Pandas, but I am not sure of what to expect for Pyspark? \n\nDoes anyone know of a great resource to learn Pyspark? I love reading print books whenever possible, but I also like shorter online courses for introduction.", "author_fullname": "t2_tsrtqcem", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning Pyspark for a new role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ztkkjy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671811450.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All, &lt;/p&gt;\n\n&lt;p&gt;I accepted an offer to join a new company that is primarily using pyspark, airflow, and kubernetes for their workflow. ( mostly an on-prem stack with open source tools) &lt;/p&gt;\n\n&lt;p&gt;My current job uses snowflake, sql scripts, python, airflow, kubernetes, and AWS. &lt;/p&gt;\n\n&lt;p&gt;It\u2019s going to be a transition to move from the Snowflake SQL based workflow to purely Pyspark. I am quite familiar with python and I have used Pandas, but I am not sure of what to expect for Pyspark? &lt;/p&gt;\n\n&lt;p&gt;Does anyone know of a great resource to learn Pyspark? I love reading print books whenever possible, but I also like shorter online courses for introduction.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ztkkjy", "is_robot_indexable": true, "report_reasons": null, "author": "CookingGoBlue", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ztkkjy/learning_pyspark_for_a_new_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ztkkjy/learning_pyspark_for_a_new_role/", "subreddit_subscribers": 83990, "created_utc": 1671811450.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just put the finishing touches on my first data project and wanted to share.\n\nIt's pretty simple and doesn't use big data engineering tools but data is nonetheless flowing from one place to another. I built this to get an understanding of how data can move from a raw format to a visualization. Plus, learning the basics of different tools/concepts (i.e., BigQuery, Cloud Storage, Compute Engine, cron, Python, APIs)\n\nThis project basically calls out to an API, processes the data, creates a csv file with the data, uploads it to Google Cloud Storage then to BigQuery. Then, my website queries BigQuery to pull the data for a simple table visualization.\n\n**Flowchart:**\n\n[Flowchart for my project](https://preview.redd.it/tw6ubvwdyn7a1.png?width=6430&amp;format=png&amp;auto=webp&amp;s=e1c45cbc2d3e704c3d5935b122c23ad02204b020)\n\nHere is the [GitHub repository](https://github.com/digitalghost-dev/stock-data-pipeline) if you're interested.", "author_fullname": "t2_bix7v2w5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Small Data Project that I Built", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 54, "top_awarded_type": null, "hide_score": false, "media_metadata": {"tw6ubvwdyn7a1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 41, "x": 108, "u": "https://preview.redd.it/tw6ubvwdyn7a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7042e9a8a66cce0bdcaff07686fecf476cf50fa7"}, {"y": 83, "x": 216, "u": "https://preview.redd.it/tw6ubvwdyn7a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9a13a7c8774628c5e49cca89e17066f21fde0751"}, {"y": 123, "x": 320, "u": "https://preview.redd.it/tw6ubvwdyn7a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d041e0863a7b08b9f94f3f0ccc08b5eb96ca192f"}, {"y": 247, "x": 640, "u": "https://preview.redd.it/tw6ubvwdyn7a1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=658470e62d1144db04fbec55e39d9417d0912cb9"}, {"y": 371, "x": 960, "u": "https://preview.redd.it/tw6ubvwdyn7a1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=1628c45e35bc2b8b8727d35c389ea19ff40038ac"}, {"y": 417, "x": 1080, "u": "https://preview.redd.it/tw6ubvwdyn7a1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c6f7898b56dc29a013d8c1ebc4ab743c414cea3f"}], "s": {"y": 2488, "x": 6430, "u": "https://preview.redd.it/tw6ubvwdyn7a1.png?width=6430&amp;format=png&amp;auto=webp&amp;s=e1c45cbc2d3e704c3d5935b122c23ad02204b020"}, "id": "tw6ubvwdyn7a1"}}, "name": "t3_ztiy4z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/vch6QDvTkjXD-v5lsuo1V1_abymKwrGSZ6xqmIvmVA8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671808605.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just put the finishing touches on my first data project and wanted to share.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s pretty simple and doesn&amp;#39;t use big data engineering tools but data is nonetheless flowing from one place to another. I built this to get an understanding of how data can move from a raw format to a visualization. Plus, learning the basics of different tools/concepts (i.e., BigQuery, Cloud Storage, Compute Engine, cron, Python, APIs)&lt;/p&gt;\n\n&lt;p&gt;This project basically calls out to an API, processes the data, creates a csv file with the data, uploads it to Google Cloud Storage then to BigQuery. Then, my website queries BigQuery to pull the data for a simple table visualization.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Flowchart:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/tw6ubvwdyn7a1.png?width=6430&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e1c45cbc2d3e704c3d5935b122c23ad02204b020\"&gt;Flowchart for my project&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Here is the &lt;a href=\"https://github.com/digitalghost-dev/stock-data-pipeline\"&gt;GitHub repository&lt;/a&gt; if you&amp;#39;re interested.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 50, "id": "award_02d9ab2c-162e-4c01-8438-317a016ed3d9", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=16&amp;height=16&amp;auto=webp&amp;s=10034f3fdf8214c8377134bb60c5b832d4bbf588", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=32&amp;height=32&amp;auto=webp&amp;s=100f785bf261fa9452a5d82ee0ef0793369dbfa5", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=48&amp;height=48&amp;auto=webp&amp;s=b15d030fdfbbe4af4a5b34ab9dc90a174df40a23", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=64&amp;height=64&amp;auto=webp&amp;s=601c75be6ee30dc4b47a5c65d64dea9a185502a1", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=128&amp;height=128&amp;auto=webp&amp;s=540f36e65c0e2f1347fe32020e4a1565e3680437", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "I'm in this with you.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Take My Energy", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=16&amp;height=16&amp;auto=webp&amp;s=045db73f47a9513c44823d132b4c393ab9241b6a", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=32&amp;height=32&amp;auto=webp&amp;s=298a02e0edbb5b5e293087eeede63802cbe1d2c7", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=48&amp;height=48&amp;auto=webp&amp;s=7d06d606eb23dbcd6dbe39ee0e60588c5eb89065", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=64&amp;height=64&amp;auto=webp&amp;s=ecd9854b14104a36a210028c43420f0dababd96b", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=128&amp;height=128&amp;auto=webp&amp;s=0d5d7b92c1d66aff435f2ad32e6330ca2b971f6d", "width": 128, "height": 128}], "icon_format": "PNG", "icon_height": 2048, "penny_price": 0, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "ztiy4z", "is_robot_indexable": true, "report_reasons": null, "author": "digitalghost-dev", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ztiy4z/small_data_project_that_i_built/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ztiy4z/small_data_project_that_i_built/", "subreddit_subscribers": 83990, "created_utc": 1671808605.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to learn AWS tools for big data and do a mini project to put on resume and gradually get that certificatio. I bought this udemy course AWS solutions architect by Stephen Marek and i need some help on is there anything should i follow along with course videos? Like documentation or anything as such. People who already done it any suggestions?", "author_fullname": "t2_71fs5pjg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggestions for learning AWS services for big data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zt9e0a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671780709.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to learn AWS tools for big data and do a mini project to put on resume and gradually get that certificatio. I bought this udemy course AWS solutions architect by Stephen Marek and i need some help on is there anything should i follow along with course videos? Like documentation or anything as such. People who already done it any suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zt9e0a", "is_robot_indexable": true, "report_reasons": null, "author": "Altruistic-Base1277", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zt9e0a/suggestions_for_learning_aws_services_for_big_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zt9e0a/suggestions_for_learning_aws_services_for_big_data/", "subreddit_subscribers": 83990, "created_utc": 1671780709.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "With the sunsetting of Universal Analytics, there's a need to convert historical UA bigquery export tables to a schema that allows for common queries between historical data and new data coming from GA4. I have been searching for some time and have been unable to find any sort of guide for developing a common schema between the UA and GA4 exports. \n\nHas anyone else run into this issue and can speak to how you're addressing it? My initial thought was to flatten both schemas out into a series of common tables both schemas could be transformed to, but again I haven't really found any examples out there so not sure if it's just not a very realistic approach or if there's a better approach to the problem.", "author_fullname": "t2_4y6y8mq9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "UA to GA4 Bigquery schema migration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ztuje6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671834588.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With the sunsetting of Universal Analytics, there&amp;#39;s a need to convert historical UA bigquery export tables to a schema that allows for common queries between historical data and new data coming from GA4. I have been searching for some time and have been unable to find any sort of guide for developing a common schema between the UA and GA4 exports. &lt;/p&gt;\n\n&lt;p&gt;Has anyone else run into this issue and can speak to how you&amp;#39;re addressing it? My initial thought was to flatten both schemas out into a series of common tables both schemas could be transformed to, but again I haven&amp;#39;t really found any examples out there so not sure if it&amp;#39;s just not a very realistic approach or if there&amp;#39;s a better approach to the problem.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ztuje6", "is_robot_indexable": true, "report_reasons": null, "author": "Br0steen", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/ztuje6/ua_to_ga4_bigquery_schema_migration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ztuje6/ua_to_ga4_bigquery_schema_migration/", "subreddit_subscribers": 83990, "created_utc": 1671834588.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello fellows. After 2 decades in c#, I want to become a DE. My goal is to do advanced spark/scala etl with heavy code and emphasis on performance optimization. I want to avoid easy tools that don't involve code.\n\nI took courses on rockthejvm. I've learned Scala (love it!) and spark (finishing up the bundle, I really enjoy performance optimization techniques).\n\nEveryone I know says cloud is central to the big data field. Job postings confirm it. Problem is I got ZERO cloud experience (except learning exercises on AWS EMR).\n\nTwo data managers I know told me the AWS data analytics certification is what they would value. I browsed the exam material, it looks easy, but just time consuming (maybe 2 months).\n\nIs this certification going to help get a heavy coding job? Is it going to corner me into the Glue/noncoding/easy tools? Maybe focus instead on streaming like kafka or AWS MSK?\n\nI appreciate any opinions or feedback. I'm open to other certifications you'd strongly recommend. I especially need feedback from heavy coders in scala and spark. TIA.", "author_fullname": "t2_9egc89u4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS certification?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_ztz7yp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671848190.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellows. After 2 decades in c#, I want to become a DE. My goal is to do advanced spark/scala etl with heavy code and emphasis on performance optimization. I want to avoid easy tools that don&amp;#39;t involve code.&lt;/p&gt;\n\n&lt;p&gt;I took courses on rockthejvm. I&amp;#39;ve learned Scala (love it!) and spark (finishing up the bundle, I really enjoy performance optimization techniques).&lt;/p&gt;\n\n&lt;p&gt;Everyone I know says cloud is central to the big data field. Job postings confirm it. Problem is I got ZERO cloud experience (except learning exercises on AWS EMR).&lt;/p&gt;\n\n&lt;p&gt;Two data managers I know told me the AWS data analytics certification is what they would value. I browsed the exam material, it looks easy, but just time consuming (maybe 2 months).&lt;/p&gt;\n\n&lt;p&gt;Is this certification going to help get a heavy coding job? Is it going to corner me into the Glue/noncoding/easy tools? Maybe focus instead on streaming like kafka or AWS MSK?&lt;/p&gt;\n\n&lt;p&gt;I appreciate any opinions or feedback. I&amp;#39;m open to other certifications you&amp;#39;d strongly recommend. I especially need feedback from heavy coders in scala and spark. TIA.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ztz7yp", "is_robot_indexable": true, "report_reasons": null, "author": "Tricky_Ad7760", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ztz7yp/aws_certification/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ztz7yp/aws_certification/", "subreddit_subscribers": 83990, "created_utc": 1671848190.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Basically, title, with some additional info. Like many MSCS programs, the one I want to do focuses on CS fundamentals (OS, programming, algorithms, networks, architecture) with electives for cloud computing and ML lite courses. Even a course using hadoop/pig/hive/pandas.\n\nMost of the courses are based in C/C++ and/or python. Very little Java.\n\nIt\u2019s definitely a time commitment which takes away from additional DE learning outside of work hours (if that\u2019s a thing).\n\nDon\u2019t have a clear career plan except for staying in DE and/or a dev role. Late 30s so also wonder about throughput and ageism.", "author_fullname": "t2_3uoce3bn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is the time spent obtaining an MSCS worth it for DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ztuvve", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671835546.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically, title, with some additional info. Like many MSCS programs, the one I want to do focuses on CS fundamentals (OS, programming, algorithms, networks, architecture) with electives for cloud computing and ML lite courses. Even a course using hadoop/pig/hive/pandas.&lt;/p&gt;\n\n&lt;p&gt;Most of the courses are based in C/C++ and/or python. Very little Java.&lt;/p&gt;\n\n&lt;p&gt;It\u2019s definitely a time commitment which takes away from additional DE learning outside of work hours (if that\u2019s a thing).&lt;/p&gt;\n\n&lt;p&gt;Don\u2019t have a clear career plan except for staying in DE and/or a dev role. Late 30s so also wonder about throughput and ageism.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ztuvve", "is_robot_indexable": true, "report_reasons": null, "author": "Tender_Figs", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ztuvve/is_the_time_spent_obtaining_an_mscs_worth_it_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ztuvve/is_the_time_spent_obtaining_an_mscs_worth_it_for/", "subreddit_subscribers": 83990, "created_utc": 1671835546.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nWe have a bigquery table that is connected to our looker. \n\nRecently we have encountered optimization issue when looker query from the bq table.\n\nLookers query has a limit of 5 gig. We have several tiles on which query amount is over 5 gig. \n\nI was able to fix it using lookers aggregate awareness , wherein looker would create a temporary aggregated table in looker scratch schema  in our bq.  \n\n\n```\nParameter:p_dynamic_date{\nType:unquoted\nAllowed_value:{\n\tlabel:\u201dDaily\u201d\n\tvalue:\u201ddaily\u201d}\nAllowed_value:{\n\tlabel:\u201dMonthly\u201d\n\tvalue:\u201dmonthly\u201d}\nDefault_value:\u201ddaily\u201d\n}\nDimension:dynamic_date{\nType:string\nSql: {%if p_dynamic_date._parameter_value == \u2018daily\u2019 %}\n${OrderDate_dims_date1}\n{%elsif p_dynamic_date.parameter_value == \u2018monthly\u2019 %}\n${customer_happiness_order.OrderDate_dims_month}\n}\n{%else%}\n${default_dimension}\n{%endif%}\n\n```\n\n \nThe problem is that when using parameter dimension, base on the lookers documentation I can only put those parameters on filter parameter in aggregate awareness . \n\nWe do have several parameter dimension in our views that we use for our dynamic measures and dimensions. \n\nIs there any workaround or solutions for this? \nOther than creating aggregate awareness for each parameter value. \n\nSidenote: Our bq table already have partitioned column and cluster column. \nIt is a historical data with a 30 min time interval.", "author_fullname": "t2_are11xb5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bigquery and Looker optimization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ztc53z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671791441.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;We have a bigquery table that is connected to our looker. &lt;/p&gt;\n\n&lt;p&gt;Recently we have encountered optimization issue when looker query from the bq table.&lt;/p&gt;\n\n&lt;p&gt;Lookers query has a limit of 5 gig. We have several tiles on which query amount is over 5 gig. &lt;/p&gt;\n\n&lt;p&gt;I was able to fix it using lookers aggregate awareness , wherein looker would create a temporary aggregated table in looker scratch schema  in our bq.  &lt;/p&gt;\n\n&lt;p&gt;```\nParameter:p_dynamic_date{\nType:unquoted\nAllowed_value:{\n    label:\u201dDaily\u201d\n    value:\u201ddaily\u201d}\nAllowed_value:{\n    label:\u201dMonthly\u201d\n    value:\u201dmonthly\u201d}\nDefault_value:\u201ddaily\u201d\n}\nDimension:dynamic_date{\nType:string\nSql: {%if p_dynamic_date._parameter_value == \u2018daily\u2019 %}\n${OrderDate_dims_date1}\n{%elsif p_dynamic_date.parameter_value == \u2018monthly\u2019 %}\n${customer_happiness_order.OrderDate_dims_month}\n}\n{%else%}\n${default_dimension}\n{%endif%}&lt;/p&gt;\n\n&lt;p&gt;```&lt;/p&gt;\n\n&lt;p&gt;The problem is that when using parameter dimension, base on the lookers documentation I can only put those parameters on filter parameter in aggregate awareness . &lt;/p&gt;\n\n&lt;p&gt;We do have several parameter dimension in our views that we use for our dynamic measures and dimensions. &lt;/p&gt;\n\n&lt;p&gt;Is there any workaround or solutions for this? \nOther than creating aggregate awareness for each parameter value. &lt;/p&gt;\n\n&lt;p&gt;Sidenote: Our bq table already have partitioned column and cluster column. \nIt is a historical data with a 30 min time interval.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ztc53z", "is_robot_indexable": true, "report_reasons": null, "author": "Sublime-01", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ztc53z/bigquery_and_looker_optimization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ztc53z/bigquery_and_looker_optimization/", "subreddit_subscribers": 83990, "created_utc": 1671791441.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nIn recent days, I heard a lot about Rust for data engineering. What are your thoughts on this?  \nWhat do you think, will Rust suppress Scala? Will Rust rule over?\n\n\\#dataengineering", "author_fullname": "t2_ci308gob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scala or Rust? which one will rule in future?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ztbebo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671788577.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;In recent days, I heard a lot about Rust for data engineering. What are your thoughts on this?&lt;br/&gt;\nWhat do you think, will Rust suppress Scala? Will Rust rule over?&lt;/p&gt;\n\n&lt;p&gt;#dataengineering&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ztbebo", "is_robot_indexable": true, "report_reasons": null, "author": "Delicious_Attempt_99", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ztbebo/scala_or_rust_which_one_will_rule_in_future/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ztbebo/scala_or_rust_which_one_will_rule_in_future/", "subreddit_subscribers": 83990, "created_utc": 1671788577.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All,\n\nI'm a bit new to this community but I have a few questions I'd like your opinion on. I'm extracting data from an API which has a lot of nested fields. I'm currently unpacking this all. There are also some nested arrays in the data and currently we unnest them which results in a new row for each value in the array. \n\nSo for example we have a companies table, one column lists the countries that the company is active in. So the original table would be:\n\n \n\n|Company\\_id|Company\\_name|Countries|\n|:-|:-|:-|\n|1|Foo|\\[\"USA\", \"Canada\", \"Spain\"\\]|\n\nAfter flattening this becomes\n\n&amp;#x200B;\n\n|Company\\_id|Company\\_name|Countries|\n|:-|:-|:-|\n|1|Foo|USA|\n|1|Foo|Canada|\n|1|Foo|Spain|\n\nI am trying to model this in a STAR-Schema. The fact table currently lists the monthly value of a subscription and the companies table is actually a dimension. Flattening the table like I showed creates a many-to-many relation for the fact and dimension (because now the dimension has multiple rows per company). Furthermore I would like to use the countries as a filter, for example I want to show the sales of companies that are active in the USA. I am unsure what the best practice is in this case and I am curious on your views on this.", "author_fullname": "t2_ipra12z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Flattening arrays in dimenion table, what is best practice?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ztahb0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671784980.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a bit new to this community but I have a few questions I&amp;#39;d like your opinion on. I&amp;#39;m extracting data from an API which has a lot of nested fields. I&amp;#39;m currently unpacking this all. There are also some nested arrays in the data and currently we unnest them which results in a new row for each value in the array. &lt;/p&gt;\n\n&lt;p&gt;So for example we have a companies table, one column lists the countries that the company is active in. So the original table would be:&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Company_id&lt;/th&gt;\n&lt;th align=\"left\"&gt;Company_name&lt;/th&gt;\n&lt;th align=\"left\"&gt;Countries&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;Foo&lt;/td&gt;\n&lt;td align=\"left\"&gt;[&amp;quot;USA&amp;quot;, &amp;quot;Canada&amp;quot;, &amp;quot;Spain&amp;quot;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;After flattening this becomes&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Company_id&lt;/th&gt;\n&lt;th align=\"left\"&gt;Company_name&lt;/th&gt;\n&lt;th align=\"left\"&gt;Countries&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;Foo&lt;/td&gt;\n&lt;td align=\"left\"&gt;USA&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;Foo&lt;/td&gt;\n&lt;td align=\"left\"&gt;Canada&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;Foo&lt;/td&gt;\n&lt;td align=\"left\"&gt;Spain&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;I am trying to model this in a STAR-Schema. The fact table currently lists the monthly value of a subscription and the companies table is actually a dimension. Flattening the table like I showed creates a many-to-many relation for the fact and dimension (because now the dimension has multiple rows per company). Furthermore I would like to use the countries as a filter, for example I want to show the sales of companies that are active in the USA. I am unsure what the best practice is in this case and I am curious on your views on this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ztahb0", "is_robot_indexable": true, "report_reasons": null, "author": "starslet93", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ztahb0/flattening_arrays_in_dimenion_table_what_is_best/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ztahb0/flattening_arrays_in_dimenion_table_what_is_best/", "subreddit_subscribers": 83990, "created_utc": 1671784980.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Let\u2019s give a shout-out to the OGs \n\nAny one here been a data engineer for 15+ years? (I\u2019m sure some titles would have changed over time)", "author_fullname": "t2_3p620rl9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "15+ year veterans", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ztwsku", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671840865.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let\u2019s give a shout-out to the OGs &lt;/p&gt;\n\n&lt;p&gt;Any one here been a data engineer for 15+ years? (I\u2019m sure some titles would have changed over time)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "DE @ Amazon/Lyft/Author of Ace DE Interview", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ztwsku", "is_robot_indexable": true, "report_reasons": null, "author": "chrisgarzon19", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/ztwsku/15_year_veterans/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ztwsku/15_year_veterans/", "subreddit_subscribers": 83990, "created_utc": 1671840865.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company uses Databricks to spin up spark clusters and run spark applications/jobs on them. But when I asked for a staging cluster to be set up for testing purposes (1 master node and 1 worker which will go down after 1 hour of inactivity), they say it will double the cost. Does spinning up another small cluster incur any fixed fee which I am missing? I checked out the Databricks pricing on a very surface level: [https://www.databricks.com/product/pricing](https://www.databricks.com/product/pricing) and didn't find any fixed fee.\n\nThis also made me wonder if setting up staging clusters for testing spark applications/jobs is normal (it might be easier for companies managing in-house spark clusters, I feel) or if what I am asking for is far-fetched. This is my first time working on Spark, I am just curious. Thanks!", "author_fullname": "t2_uqx8q0b4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do companies set up staging environments for their spark pipeline(s)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ztgp64", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1671805105.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company uses Databricks to spin up spark clusters and run spark applications/jobs on them. But when I asked for a staging cluster to be set up for testing purposes (1 master node and 1 worker which will go down after 1 hour of inactivity), they say it will double the cost. Does spinning up another small cluster incur any fixed fee which I am missing? I checked out the Databricks pricing on a very surface level: &lt;a href=\"https://www.databricks.com/product/pricing\"&gt;https://www.databricks.com/product/pricing&lt;/a&gt; and didn&amp;#39;t find any fixed fee.&lt;/p&gt;\n\n&lt;p&gt;This also made me wonder if setting up staging clusters for testing spark applications/jobs is normal (it might be easier for companies managing in-house spark clusters, I feel) or if what I am asking for is far-fetched. This is my first time working on Spark, I am just curious. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/KQ6LtUPbNzOmSQucv-4d7A_9HFIwm2xgCV2yC7KKql8.jpg?auto=webp&amp;s=afbcf6c0a382f562f827b0c2c6f522c11c337cbe", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/KQ6LtUPbNzOmSQucv-4d7A_9HFIwm2xgCV2yC7KKql8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9548268e474bfa947a6d3486dac50b79a84a04bc", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/KQ6LtUPbNzOmSQucv-4d7A_9HFIwm2xgCV2yC7KKql8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7ebd62be4af601d1e09ae1cd9d9ee91065af4242", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/KQ6LtUPbNzOmSQucv-4d7A_9HFIwm2xgCV2yC7KKql8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=02919e6c9ddb4e8e87863d61487437299bb24c49", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/KQ6LtUPbNzOmSQucv-4d7A_9HFIwm2xgCV2yC7KKql8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=131f4845cdb1282ddb789a6eb9f04238f19b3a80", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/KQ6LtUPbNzOmSQucv-4d7A_9HFIwm2xgCV2yC7KKql8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=eee206a496dc7eca55db2b06e528bf544ddb73c5", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/KQ6LtUPbNzOmSQucv-4d7A_9HFIwm2xgCV2yC7KKql8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=65ec0864683118aefee5006e88b78842e5cba2a0", "width": 1080, "height": 567}], "variants": {}, "id": "chr5A0PJvePhRJ7lI3sFaxKWyQXhWy3BRSTRcBAQKNs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ztgp64", "is_robot_indexable": true, "report_reasons": null, "author": "the-fake-me", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ztgp64/do_companies_set_up_staging_environments_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ztgp64/do_companies_set_up_staging_environments_for/", "subreddit_subscribers": 83990, "created_utc": 1671805105.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious if there are roles or industries out there that combine a little bit of physical hands on work and pipelining/infra/modeling the usual stuff. \n\nTo elaborate, I really enjoy tinkering with microcontrollers and raspberry pis. I've set up small pipelines that required configuration of physical sensors and building the actual device and of course the data collection and software behind it. \n\nI'd imagine I could only find something like this in a robotics or similar startup where I could wear many hats. At a larger organization I'm sure these DEs exist but they're probably siloed from the physical hardware. \n\nAnyone else have any thoughts?", "author_fullname": "t2_3aaaxf9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering and Hands On?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ztetmq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671800873.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious if there are roles or industries out there that combine a little bit of physical hands on work and pipelining/infra/modeling the usual stuff. &lt;/p&gt;\n\n&lt;p&gt;To elaborate, I really enjoy tinkering with microcontrollers and raspberry pis. I&amp;#39;ve set up small pipelines that required configuration of physical sensors and building the actual device and of course the data collection and software behind it. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d imagine I could only find something like this in a robotics or similar startup where I could wear many hats. At a larger organization I&amp;#39;m sure these DEs exist but they&amp;#39;re probably siloed from the physical hardware. &lt;/p&gt;\n\n&lt;p&gt;Anyone else have any thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ztetmq", "is_robot_indexable": true, "report_reasons": null, "author": "felmalorne", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ztetmq/data_engineering_and_hands_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ztetmq/data_engineering_and_hands_on/", "subreddit_subscribers": 83990, "created_utc": 1671800873.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m working on an application that requires a Python backend. \n\nThere\u2019s a fair amount of: ingesting text file, manipulating with data frames and storing data. During development we store as CSVs and then import again.\n\nWhat storage would you recommend? \n\nI come from a typescript background and I\u2019m used to SQL databases. Would prefer to stick to this. I was thinking of using S3 and referencing the data in a SQL database. \n\nWhat do you think?", "author_fullname": "t2_77b0idef", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best data store for python use case", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ztcoy2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671793497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m working on an application that requires a Python backend. &lt;/p&gt;\n\n&lt;p&gt;There\u2019s a fair amount of: ingesting text file, manipulating with data frames and storing data. During development we store as CSVs and then import again.&lt;/p&gt;\n\n&lt;p&gt;What storage would you recommend? &lt;/p&gt;\n\n&lt;p&gt;I come from a typescript background and I\u2019m used to SQL databases. Would prefer to stick to this. I was thinking of using S3 and referencing the data in a SQL database. &lt;/p&gt;\n\n&lt;p&gt;What do you think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ztcoy2", "is_robot_indexable": true, "report_reasons": null, "author": "SnooPears6317", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ztcoy2/best_data_store_for_python_use_case/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ztcoy2/best_data_store_for_python_use_case/", "subreddit_subscribers": 83990, "created_utc": 1671793497.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working on a project that requires a dataset over 2gb. I will use this dataset to architect, design, and implement a solution that performs data collection, preparation, analysis, and simple visualization. \n\nI'm only familiar with using Nifi's gethttp request. If Python is a better method, is anyone able to give me a short jump off point as to how to automate the collection? \n\nIs anyone able to help me with incorporating either Kaggle's CLI dataset download method with Nifi or  could someone point me towards somewhere where I can find .json Http API's that are over 2GB?\n\nSorry for the dumb questions. Relatively new beginner here. Thank you in advance.", "author_fullname": "t2_lelpgwu7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help using Nifi with Kaggle Dataset", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ztvcdu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671836785.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on a project that requires a dataset over 2gb. I will use this dataset to architect, design, and implement a solution that performs data collection, preparation, analysis, and simple visualization. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m only familiar with using Nifi&amp;#39;s gethttp request. If Python is a better method, is anyone able to give me a short jump off point as to how to automate the collection? &lt;/p&gt;\n\n&lt;p&gt;Is anyone able to help me with incorporating either Kaggle&amp;#39;s CLI dataset download method with Nifi or  could someone point me towards somewhere where I can find .json Http API&amp;#39;s that are over 2GB?&lt;/p&gt;\n\n&lt;p&gt;Sorry for the dumb questions. Relatively new beginner here. Thank you in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ztvcdu", "is_robot_indexable": true, "report_reasons": null, "author": "JacksonHole45", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ztvcdu/need_help_using_nifi_with_kaggle_dataset/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ztvcdu/need_help_using_nifi_with_kaggle_dataset/", "subreddit_subscribers": 83990, "created_utc": 1671836785.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a new to data engineering, but have been in the industry as a Database engineer/dev ops for about 8 years.\n\nPreviously done ETL with specific SAP tools which didn't require much transformation. Doing more of transformation work now using internal tools.  \nI have an example scenario and wondering what would typically be the best practices to apply.  \n\n\nWith HR related data there are department level 1 (about 8 entries) and department level 2 (each L1 department will have 10+ L2 departments). I need to group the L2 departments into a high level grouping like group#1, group#2, etc..\n\nMy thought process would either be:\n\n* case statement to add a new column to the query where if L2 departments = this/that it would be renamed to group#1 and such. I don' think is ideal as there would be likely too many entries to maintain and long term maintenance is likely very poor.\n* The other option would be to have a separate table to maintain only L2 department naming and a separate column for its grouping. Then in the final query i would want to match on the L2 department name to pull the grouping name.  \n\n\nI think the latter option would be easier to maintain in the long run. The original table doesn't exactly have ID's to represent the L2 name so it would be a name matching instead of ID.   \nAnd for general practice is it always better to create a separate table for referencing a potentially growing dataset? And that any query that have dependencies would just join on that table?", "author_fullname": "t2_4bo597fw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering best practices", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ztqmvp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671824234.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a new to data engineering, but have been in the industry as a Database engineer/dev ops for about 8 years.&lt;/p&gt;\n\n&lt;p&gt;Previously done ETL with specific SAP tools which didn&amp;#39;t require much transformation. Doing more of transformation work now using internal tools.&lt;br/&gt;\nI have an example scenario and wondering what would typically be the best practices to apply.  &lt;/p&gt;\n\n&lt;p&gt;With HR related data there are department level 1 (about 8 entries) and department level 2 (each L1 department will have 10+ L2 departments). I need to group the L2 departments into a high level grouping like group#1, group#2, etc..&lt;/p&gt;\n\n&lt;p&gt;My thought process would either be:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;case statement to add a new column to the query where if L2 departments = this/that it would be renamed to group#1 and such. I don&amp;#39; think is ideal as there would be likely too many entries to maintain and long term maintenance is likely very poor.&lt;/li&gt;\n&lt;li&gt;The other option would be to have a separate table to maintain only L2 department naming and a separate column for its grouping. Then in the final query i would want to match on the L2 department name to pull the grouping name.&lt;br/&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I think the latter option would be easier to maintain in the long run. The original table doesn&amp;#39;t exactly have ID&amp;#39;s to represent the L2 name so it would be a name matching instead of ID.&lt;br/&gt;\nAnd for general practice is it always better to create a separate table for referencing a potentially growing dataset? And that any query that have dependencies would just join on that table?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ztqmvp", "is_robot_indexable": true, "report_reasons": null, "author": "billyboee", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ztqmvp/data_engineering_best_practices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ztqmvp/data_engineering_best_practices/", "subreddit_subscribers": 83990, "created_utc": 1671824234.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_ffabopog", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Release 0.3.1 of Qbeast Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_ztft08", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/XUvfYJOP4pJhPu_dR1w3Vku1nD4q8HoVeUaoSdmTPz0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671803144.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/Qbeast-io/qbeast-spark/releases/tag/v0.3.1", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/AzmtQfJlpODTzny_oo-wc6U16bMHAREkatkoklwn8pU.jpg?auto=webp&amp;s=2a0525af9d70eeec3aba1b04b7787a31e0966ce7", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/AzmtQfJlpODTzny_oo-wc6U16bMHAREkatkoklwn8pU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4e3e9aa329e17effafb0e8d8770e1388167e4e12", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/AzmtQfJlpODTzny_oo-wc6U16bMHAREkatkoklwn8pU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b4d80ed10e7054903134747a102c8c1f00a964c1", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/AzmtQfJlpODTzny_oo-wc6U16bMHAREkatkoklwn8pU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d373c319c63b0c5bfbd681d8d6d136c99224f9ae", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/AzmtQfJlpODTzny_oo-wc6U16bMHAREkatkoklwn8pU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a31f7b5e217854df3db7506587f068b621d5e086", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/AzmtQfJlpODTzny_oo-wc6U16bMHAREkatkoklwn8pU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b89d4cd2ffd300752a5fb611c359339cca05f371", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/AzmtQfJlpODTzny_oo-wc6U16bMHAREkatkoklwn8pU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f468b7ca092608820284bd02106d17dd22da2850", "width": 1080, "height": 540}], "variants": {}, "id": "Izt85EhhkGzbGdpryLd1c_Y_1Dp0qafMg_Kwkgz9FvA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "ztft08", "is_robot_indexable": true, "report_reasons": null, "author": "paolapardo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ztft08/release_031_of_qbeast_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/Qbeast-io/qbeast-spark/releases/tag/v0.3.1", "subreddit_subscribers": 83990, "created_utc": 1671803144.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How did you prepare for the exam? I have been going through the content online though did initially struggle to answer some practice questions I found online.\n\nDo you have any recommendations on where I can find practice exams? Hard to find outside of YouTube. I am willing to pay :)", "author_fullname": "t2_12rfbr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Preparing for DP-203?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zte255", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1671807851.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671798399.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How did you prepare for the exam? I have been going through the content online though did initially struggle to answer some practice questions I found online.&lt;/p&gt;\n\n&lt;p&gt;Do you have any recommendations on where I can find practice exams? Hard to find outside of YouTube. I am willing to pay :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zte255", "is_robot_indexable": true, "report_reasons": null, "author": "That_Sweet_Science", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zte255/preparing_for_dp203/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zte255/preparing_for_dp203/", "subreddit_subscribers": 83990, "created_utc": 1671798399.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys,\n\nI recently accepted a long internship for a Saas company similar to e.g. Talend where I will work on improving the platform and on customer use cases. I consider myself very lucky because they seemed to take the personal fit into consideration a lot (we got along very well but i didn't know a few theoretical questions they asked, but gave my best at communicating my thoughts).\n\nNow to me it seems that a lot of students want to work in the data space. Heck there's even hundreds of Data Science college majors, MOOC's and Boot Camps popping up everywhere (I know Data Science != Data Engineering but I'm sure the tendency also applies to any other Data job). So I am a bit afraid about my future self getting a full time job in the field.\n\nDo you think an Internship will be enough to help me a job in the field?\n\nedit: grammar", "author_fullname": "t2_jgn9fqry", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is an Internship enough to get a job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ztvkva", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671837413.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,&lt;/p&gt;\n\n&lt;p&gt;I recently accepted a long internship for a Saas company similar to e.g. Talend where I will work on improving the platform and on customer use cases. I consider myself very lucky because they seemed to take the personal fit into consideration a lot (we got along very well but i didn&amp;#39;t know a few theoretical questions they asked, but gave my best at communicating my thoughts).&lt;/p&gt;\n\n&lt;p&gt;Now to me it seems that a lot of students want to work in the data space. Heck there&amp;#39;s even hundreds of Data Science college majors, MOOC&amp;#39;s and Boot Camps popping up everywhere (I know Data Science != Data Engineering but I&amp;#39;m sure the tendency also applies to any other Data job). So I am a bit afraid about my future self getting a full time job in the field.&lt;/p&gt;\n\n&lt;p&gt;Do you think an Internship will be enough to help me a job in the field?&lt;/p&gt;\n\n&lt;p&gt;edit: grammar&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ztvkva", "is_robot_indexable": true, "report_reasons": null, "author": "mar-lor", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ztvkva/is_an_internship_enough_to_get_a_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ztvkva/is_an_internship_enough_to_get_a_job/", "subreddit_subscribers": 83990, "created_utc": 1671837413.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_49cfbl1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Tricks: How To Get Dirty Data Cleaned", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_ztbrbd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/AhA5peXfRoU4SU3x_KFQlQkBmJAiQBMcW_yE1_Af-rQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671789997.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/geekculture/data-engineering-tricks-how-to-get-dirty-data-cleaned-through-vdk-60eeeda11ba0", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bLdk5J-q_X10nkIminSlOyMeBfabAnkCkH7AAFzTmBU.jpg?auto=webp&amp;s=61a2b14e210e164f032c2b4eec791f24f4f9fd85", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/bLdk5J-q_X10nkIminSlOyMeBfabAnkCkH7AAFzTmBU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cfdfbefd2f2adcacc11fbc125a026aed3d874592", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/bLdk5J-q_X10nkIminSlOyMeBfabAnkCkH7AAFzTmBU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4a9bf1c447be23b118a91983dce2fac38ca1709a", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/bLdk5J-q_X10nkIminSlOyMeBfabAnkCkH7AAFzTmBU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bea6c673475c653fd36f14bd90657a6c43d544d0", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/bLdk5J-q_X10nkIminSlOyMeBfabAnkCkH7AAFzTmBU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ce88110a8107775586321e1bd82709757e652f8f", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/bLdk5J-q_X10nkIminSlOyMeBfabAnkCkH7AAFzTmBU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a4f309631dbebf825ff9324380cbcdb0722c80a5", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/bLdk5J-q_X10nkIminSlOyMeBfabAnkCkH7AAFzTmBU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b38b3383ba7bddb1efcfd48298fd49df2588bae4", "width": 1080, "height": 720}], "variants": {}, "id": "scIcfeKfFRoglimi8T69xKstBaawo5kLc9fWIR8punI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "ztbrbd", "is_robot_indexable": true, "report_reasons": null, "author": "zverulacis", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ztbrbd/data_engineering_tricks_how_to_get_dirty_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/geekculture/data-engineering-tricks-how-to-get-dirty-data-cleaned-through-vdk-60eeeda11ba0", "subreddit_subscribers": 83990, "created_utc": 1671789997.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_r1v4k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "We created this to advertise some new data health work we had been doing for the wider (non technical) business.... Thought you might enjoy as well!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_zttf3l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.25, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/LVcZ9XgEgPylT8X7muTQj-GWegfrdEd6Thh8WOOUXGU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671831673.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/z9p7pgk5wp7a1.gif", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/z9p7pgk5wp7a1.gif?format=png8&amp;s=a6a37f7f7753dad879dabe1a1a757955d74212c3", "width": 600, "height": 338}, "resolutions": [{"url": "https://preview.redd.it/z9p7pgk5wp7a1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=fccb110c398bc1bd990a4937de530d8d7a9fde24", "width": 108, "height": 60}, {"url": "https://preview.redd.it/z9p7pgk5wp7a1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=0f48b95d1c7581cd45d6f4eca9cddab023cba6b3", "width": 216, "height": 121}, {"url": "https://preview.redd.it/z9p7pgk5wp7a1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=910dd3dee0f54f458e74edf52acc2c5b6173805f", "width": 320, "height": 180}], "variants": {"gif": {"source": {"url": "https://preview.redd.it/z9p7pgk5wp7a1.gif?s=9b8edbe68a0a55d0d0bd0d8ceaf402dd65273e2f", "width": 600, "height": 338}, "resolutions": [{"url": "https://preview.redd.it/z9p7pgk5wp7a1.gif?width=108&amp;crop=smart&amp;s=5464bed05a7f909e92c825c3fd1b97c738043999", "width": 108, "height": 60}, {"url": "https://preview.redd.it/z9p7pgk5wp7a1.gif?width=216&amp;crop=smart&amp;s=6586fbcb0b262d85292097528d9f44ed1ff8b834", "width": 216, "height": 121}, {"url": "https://preview.redd.it/z9p7pgk5wp7a1.gif?width=320&amp;crop=smart&amp;s=c31df8dc36324730d52c8757f5c2e3839918889d", "width": 320, "height": 180}]}, "mp4": {"source": {"url": "https://preview.redd.it/z9p7pgk5wp7a1.gif?format=mp4&amp;s=1161b96617652f61ea06b0729bef515c0df00baf", "width": 600, "height": 338}, "resolutions": [{"url": "https://preview.redd.it/z9p7pgk5wp7a1.gif?width=108&amp;format=mp4&amp;s=3599a794f9c020ef2b90e92026c452d7a52ca7e1", "width": 108, "height": 60}, {"url": "https://preview.redd.it/z9p7pgk5wp7a1.gif?width=216&amp;format=mp4&amp;s=eedc54367b2801fa1947584186401d7d661fec15", "width": 216, "height": 121}, {"url": "https://preview.redd.it/z9p7pgk5wp7a1.gif?width=320&amp;format=mp4&amp;s=19581a64708ab31dd76b62213f83b1aac3f93f0e", "width": 320, "height": 180}]}}, "id": "G30MWgocER86UYS-QovsNgPgXN-Qc9nnTC03c7djJgI"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "zttf3l", "is_robot_indexable": true, "report_reasons": null, "author": "cjvogel", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zttf3l/we_created_this_to_advertise_some_new_data_health/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/z9p7pgk5wp7a1.gif", "subreddit_subscribers": 83990, "created_utc": 1671831673.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}