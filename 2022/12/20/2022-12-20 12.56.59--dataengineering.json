{"kind": "Listing", "data": {"after": null, "dist": 22, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_69a5f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "explaining what the data modeler on the team does", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_zq4eg6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 132, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 132, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/oKNUA7sY1Eh2aloDHp4Q-2QbFqqpb4h5homJ0tTEae8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671485970.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/4svii7iyty6a1.gif", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/4svii7iyty6a1.gif?format=png8&amp;s=4bd9c72626681c8ab5f84b9f177e29fc9e05f6c4", "width": 480, "height": 360}, "resolutions": [{"url": "https://preview.redd.it/4svii7iyty6a1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=fe04087d34b32b14c5d236d9b58bb5840f693c1f", "width": 108, "height": 81}, {"url": "https://preview.redd.it/4svii7iyty6a1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=7ca3dbf483553b27cd31ce551b1b040379cf5ce2", "width": 216, "height": 162}, {"url": "https://preview.redd.it/4svii7iyty6a1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=c280a6b4d28e30ed54f2e5fd5a81b54dcb884ca9", "width": 320, "height": 240}], "variants": {"gif": {"source": {"url": "https://preview.redd.it/4svii7iyty6a1.gif?s=e7723bc482be0b0026b05fe53ee196f60f98aa6d", "width": 480, "height": 360}, "resolutions": [{"url": "https://preview.redd.it/4svii7iyty6a1.gif?width=108&amp;crop=smart&amp;s=f89dbb860b65ec70b99a348a3cd7dd4ec108e602", "width": 108, "height": 81}, {"url": "https://preview.redd.it/4svii7iyty6a1.gif?width=216&amp;crop=smart&amp;s=6e814c7d821378c262c3345090f92e2e76f199ed", "width": 216, "height": 162}, {"url": "https://preview.redd.it/4svii7iyty6a1.gif?width=320&amp;crop=smart&amp;s=dcb652318b88d353cfd9091b4c44599fdd0ee95d", "width": 320, "height": 240}]}, "mp4": {"source": {"url": "https://preview.redd.it/4svii7iyty6a1.gif?format=mp4&amp;s=79c646a6091a2054ecc51083894f393f601296e0", "width": 480, "height": 360}, "resolutions": [{"url": "https://preview.redd.it/4svii7iyty6a1.gif?width=108&amp;format=mp4&amp;s=70fad6d8c2188e0ffcde10e091198fadcadeaa9b", "width": 108, "height": 81}, {"url": "https://preview.redd.it/4svii7iyty6a1.gif?width=216&amp;format=mp4&amp;s=a4b6826456166838c71df8356d2f4a3ee4f46dee", "width": 216, "height": 162}, {"url": "https://preview.redd.it/4svii7iyty6a1.gif?width=320&amp;format=mp4&amp;s=3e090612250734014da0751f7e93c82c54d17efb", "width": 320, "height": 240}]}}, "id": "v7U3z_ZRcPCLfYaFGIe2eihy6KZVGMFdg-7Mzcfk9Sg"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "zq4eg6", "is_robot_indexable": true, "report_reasons": null, "author": "DiceboyT", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zq4eg6/explaining_what_the_data_modeler_on_the_team_does/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/4svii7iyty6a1.gif", "subreddit_subscribers": 83366, "created_utc": 1671485970.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Recruiter ends interview because candidate has no experience with Databricks but the job description is not explicit about it being required. The unprofessionalism that some of these companies display is astonishing..\n\n&amp;#x200B;\n\n&gt;The first interview was scheduled on Tuesday and 20 minutes before, I receive an email from the recruiter asking to postpone for Friday because the hiring manager had an \u201cemergency\u201d. I was extremely annoyed, but I accepted, nonetheless.  \n&gt;  \n&gt;We start the interview on Friday, and I immediately notice the hiring manager avoiding eye contact. I found that to be strange and it made me uncomfortable. Then, 12 minutes in, he asks if I have experience with DataBricks which I promptly told him that I do not, and he proceeds to say \u201cI have to end the interview because DataBricks is a requirement\u201d  \n&gt;  \n&gt;I pressed him by stating that the Job Description clearly states *(Airflow, Databricks, Snowflake, Serverless Functions, Cloud storage preferred)* and that I never included Databricks on my resume.  \n&gt;  \n&gt;He then says \u201cWell, we are looking for someone Senior\u201d which I replied by saying that the recruiter assured me on 3 different conversations that this was not a senior role. We went back and forth for some 5 minutes, and I eventually end the call.  \n&gt;  \n&gt;I emailed the recruiter right away to share my displeasure of the session and she calls my phone. She explains to me that the hiring manager had decided a few hours before that he wanted someone senior which angered me because he basically wasted my time twice.\n\n[https://www.reddit.com/r/recruitinghell/comments/zpflbr/name\\_and\\_shame\\_nielseniq\\_interviewer\\_ends/](https://www.reddit.com/r/recruitinghell/comments/zpflbr/name_and_shame_nielseniq_interviewer_ends/)", "author_fullname": "t2_7698zbc7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "From /recruitinghell - (Name and Shame: NielsenIQ - Interviewer ends interview 12 mins in.)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zpt1ri", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 82, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 82, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671460090.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Recruiter ends interview because candidate has no experience with Databricks but the job description is not explicit about it being required. The unprofessionalism that some of these companies display is astonishing..&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;The first interview was scheduled on Tuesday and 20 minutes before, I receive an email from the recruiter asking to postpone for Friday because the hiring manager had an \u201cemergency\u201d. I was extremely annoyed, but I accepted, nonetheless.  &lt;/p&gt;\n\n&lt;p&gt;We start the interview on Friday, and I immediately notice the hiring manager avoiding eye contact. I found that to be strange and it made me uncomfortable. Then, 12 minutes in, he asks if I have experience with DataBricks which I promptly told him that I do not, and he proceeds to say \u201cI have to end the interview because DataBricks is a requirement\u201d  &lt;/p&gt;\n\n&lt;p&gt;I pressed him by stating that the Job Description clearly states &lt;em&gt;(Airflow, Databricks, Snowflake, Serverless Functions, Cloud storage preferred)&lt;/em&gt; and that I never included Databricks on my resume.  &lt;/p&gt;\n\n&lt;p&gt;He then says \u201cWell, we are looking for someone Senior\u201d which I replied by saying that the recruiter assured me on 3 different conversations that this was not a senior role. We went back and forth for some 5 minutes, and I eventually end the call.  &lt;/p&gt;\n\n&lt;p&gt;I emailed the recruiter right away to share my displeasure of the session and she calls my phone. She explains to me that the hiring manager had decided a few hours before that he wanted someone senior which angered me because he basically wasted my time twice.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/recruitinghell/comments/zpflbr/name_and_shame_nielseniq_interviewer_ends/\"&gt;https://www.reddit.com/r/recruitinghell/comments/zpflbr/name_and_shame_nielseniq_interviewer_ends/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zpt1ri", "is_robot_indexable": true, "report_reasons": null, "author": "Manoloskinny", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zpt1ri/from_recruitinghell_name_and_shame_nielseniq/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zpt1ri/from_recruitinghell_name_and_shame_nielseniq/", "subreddit_subscribers": 83366, "created_utc": 1671460090.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_hissmiq8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "This is what a single engineering consisting of a team lead, a PM, an engineering manager, a technical program manager, a scrum master, and a product owner looks like.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 79, "top_awarded_type": null, "hide_score": false, "name": "t3_zqkjk3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 40, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 40, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/yFW0EGukH-lKQOuc0yc0JW-fGLAcdJ2jfnPv1sm00rg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671530377.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/3yte0gif017a1.gif", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/3yte0gif017a1.gif?format=png8&amp;s=0523f0ac1cf350940732cfbe66a6586d312f1ce8", "width": 330, "height": 187}, "resolutions": [{"url": "https://preview.redd.it/3yte0gif017a1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=e550e839a7b3d0d3035834cfd6d72d288edab83f", "width": 108, "height": 61}, {"url": "https://preview.redd.it/3yte0gif017a1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=5d19c1b6720664538399ad4cb7e6650f632acb6d", "width": 216, "height": 122}, {"url": "https://preview.redd.it/3yte0gif017a1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=271c7921cc908343fed0223af1e6f4e99ab128c8", "width": 320, "height": 181}], "variants": {"gif": {"source": {"url": "https://preview.redd.it/3yte0gif017a1.gif?s=2d45e52f762982454273862288a5cba769d94460", "width": 330, "height": 187}, "resolutions": [{"url": "https://preview.redd.it/3yte0gif017a1.gif?width=108&amp;crop=smart&amp;s=b5bf9a9434b80454cb589bb37f571a0c62885857", "width": 108, "height": 61}, {"url": "https://preview.redd.it/3yte0gif017a1.gif?width=216&amp;crop=smart&amp;s=e82a804f05e6f0580c77b97f3d962fc6d001b210", "width": 216, "height": 122}, {"url": "https://preview.redd.it/3yte0gif017a1.gif?width=320&amp;crop=smart&amp;s=ef361d101d5bf55503684a3c35fe814e819fcf9c", "width": 320, "height": 181}]}, "mp4": {"source": {"url": "https://preview.redd.it/3yte0gif017a1.gif?format=mp4&amp;s=960f7745a039b448b61e58e7672a89c77983abf4", "width": 330, "height": 187}, "resolutions": [{"url": "https://preview.redd.it/3yte0gif017a1.gif?width=108&amp;format=mp4&amp;s=a2c081ea07f1bd3b11fef5754c1135af56f3b67c", "width": 108, "height": 61}, {"url": "https://preview.redd.it/3yte0gif017a1.gif?width=216&amp;format=mp4&amp;s=d4322738650aad03cb812bcf7d8bfa90e04afe9d", "width": 216, "height": 122}, {"url": "https://preview.redd.it/3yte0gif017a1.gif?width=320&amp;format=mp4&amp;s=9a19c352874909ff9093378ec974f990a31353a9", "width": 320, "height": 181}]}}, "id": "lhEr_PyLDwzA7MmZ2pUiSDSVnUUHL52UhsqV-r2eTB8"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "zqkjk3", "is_robot_indexable": true, "report_reasons": null, "author": "Nice_Score_7552", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zqkjk3/this_is_what_a_single_engineering_consisting_of_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/3yte0gif017a1.gif", "subreddit_subscribers": 83366, "created_utc": 1671530377.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " The Pipeline for updating data between OLTP and OLAP environments \n\n&amp;#x200B;\n\n[ The Pipeline for updating data between OLTP and OLAP environments ](https://preview.redd.it/8cgophq7bw6a1.png?width=1354&amp;format=png&amp;auto=webp&amp;s=a6d55303e4550c15144385ffd1f18005de1b9a50)\n\n[https://medium.com/@stefentaime\\_10958/elt-airflow-pipeline-project-dcf834c1be17](https://medium.com/@stefentaime_10958/elt-airflow-pipeline-project-dcf834c1be17)", "author_fullname": "t2_7sisbd20", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ELT Airflow Pipeline Project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 80, "top_awarded_type": null, "hide_score": false, "media_metadata": {"8cgophq7bw6a1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 62, "x": 108, "u": "https://preview.redd.it/8cgophq7bw6a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0b8c6416e54039afe098eaac5e375d404c018b48"}, {"y": 124, "x": 216, "u": "https://preview.redd.it/8cgophq7bw6a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9ee4f58bb59f8b8873de1ed245ec2202ba94cf77"}, {"y": 183, "x": 320, "u": "https://preview.redd.it/8cgophq7bw6a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c6c41b7a53f55f78a40bb1c42c46bb5cbe1bcc10"}, {"y": 367, "x": 640, "u": "https://preview.redd.it/8cgophq7bw6a1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8316045e2b4bafa09121961b432e11ce3f678eac"}, {"y": 551, "x": 960, "u": "https://preview.redd.it/8cgophq7bw6a1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=5fb7cae10a1a09ee9e1c1a4bd2a3f5e7bf9b8e7b"}, {"y": 620, "x": 1080, "u": "https://preview.redd.it/8cgophq7bw6a1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=bdfbd841a8083146df5ca23ac2b9d08a9d42c1e4"}], "s": {"y": 778, "x": 1354, "u": "https://preview.redd.it/8cgophq7bw6a1.png?width=1354&amp;format=png&amp;auto=webp&amp;s=a6d55303e4550c15144385ffd1f18005de1b9a50"}, "id": "8cgophq7bw6a1"}}, "name": "t3_zpyyg3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/W-QDl95mFueasfk1yi2Y6SgdkXxW8mCJsP8DoPRbrn4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1671473515.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The Pipeline for updating data between OLTP and OLAP environments &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/8cgophq7bw6a1.png?width=1354&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a6d55303e4550c15144385ffd1f18005de1b9a50\"&gt; The Pipeline for updating data between OLTP and OLAP environments &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@stefentaime_10958/elt-airflow-pipeline-project-dcf834c1be17\"&gt;https://medium.com/@stefentaime_10958/elt-airflow-pipeline-project-dcf834c1be17&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/d51pTwrTqzOE_YsYg-xnX7l3X78A57o4PTo_-_7mDrU.jpg?auto=webp&amp;s=189a6b24f481906e17128d1b5a6ce2b10ceb8ce5", "width": 1200, "height": 689}, "resolutions": [{"url": "https://external-preview.redd.it/d51pTwrTqzOE_YsYg-xnX7l3X78A57o4PTo_-_7mDrU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=17fac23626ad5fcf3da6a672329f1395f6b67a27", "width": 108, "height": 62}, {"url": "https://external-preview.redd.it/d51pTwrTqzOE_YsYg-xnX7l3X78A57o4PTo_-_7mDrU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1b947e27d92a4477f6dc0e8a996c34d8eb2906f4", "width": 216, "height": 124}, {"url": "https://external-preview.redd.it/d51pTwrTqzOE_YsYg-xnX7l3X78A57o4PTo_-_7mDrU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ba2767011db48b488445199fc41003d3b7ef246b", "width": 320, "height": 183}, {"url": "https://external-preview.redd.it/d51pTwrTqzOE_YsYg-xnX7l3X78A57o4PTo_-_7mDrU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2edf3c6efc64db37a516d43b13ca29119005ecce", "width": 640, "height": 367}, {"url": "https://external-preview.redd.it/d51pTwrTqzOE_YsYg-xnX7l3X78A57o4PTo_-_7mDrU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f5e057d195010417e4dbe8ee7f0d50dec6b55ffd", "width": 960, "height": 551}, {"url": "https://external-preview.redd.it/d51pTwrTqzOE_YsYg-xnX7l3X78A57o4PTo_-_7mDrU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ed86019ba3ebb3c6dea7e2b42faec21e954f4e65", "width": 1080, "height": 620}], "variants": {}, "id": "30-hhPvTjai8fSVRjgRQJhYhB7ZWkwAJX3v0K0Z5WOg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "zpyyg3", "is_robot_indexable": true, "report_reasons": null, "author": "Jealous_Ad6059", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zpyyg3/elt_airflow_pipeline_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zpyyg3/elt_airflow_pipeline_project/", "subreddit_subscribers": 83366, "created_utc": 1671473515.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Looking for good technical interview questions and tips for interviewing entry to mid-level 'Data &amp; Analytics Engineers'. \n\nI've interviewed a number of people already for this position but want to make sure I'm asking good questions and being fair to the candidates \n\nI'm a young software engineer at a large IT consulting firm. I have a strong background in MS SQL Server, ETL, MDM and tuning queries for large transactional databases\n\nHowever.. I have little to NO experience with Azure/AWS, data warehousing, machine learning, Python, R, data visualization tools like Tableau, etc. This can make interviews difficult because the candidates often have these tools/disciplines listed on their resume.. \n\nI usually end up asking broad questions about their past project/work to gauge their communication skills (important because this is consulting). Then asking if they have experience with source control, performance tuning, or have worked with sensitive data. Then finish by asking basic SQL/database questions like: what is the difference between INNER vs LEFT join, what are some ways to eliminate duplicates in a query, what is a temp table, what is a database index, etc..", "author_fullname": "t2_8jq30m4x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good technical interview questions for 'Data &amp; Analytics Engineer'?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zqeco3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671510570.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for good technical interview questions and tips for interviewing entry to mid-level &amp;#39;Data &amp;amp; Analytics Engineers&amp;#39;. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve interviewed a number of people already for this position but want to make sure I&amp;#39;m asking good questions and being fair to the candidates &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a young software engineer at a large IT consulting firm. I have a strong background in MS SQL Server, ETL, MDM and tuning queries for large transactional databases&lt;/p&gt;\n\n&lt;p&gt;However.. I have little to NO experience with Azure/AWS, data warehousing, machine learning, Python, R, data visualization tools like Tableau, etc. This can make interviews difficult because the candidates often have these tools/disciplines listed on their resume.. &lt;/p&gt;\n\n&lt;p&gt;I usually end up asking broad questions about their past project/work to gauge their communication skills (important because this is consulting). Then asking if they have experience with source control, performance tuning, or have worked with sensitive data. Then finish by asking basic SQL/database questions like: what is the difference between INNER vs LEFT join, what are some ways to eliminate duplicates in a query, what is a temp table, what is a database index, etc..&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "zqeco3", "is_robot_indexable": true, "report_reasons": null, "author": "patheticadam", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zqeco3/good_technical_interview_questions_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zqeco3/good_technical_interview_questions_for_data/", "subreddit_subscribers": 83366, "created_utc": 1671510570.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My goal is to eventually get a new grad data engineering position at a big tech company. Are companies usually willing to hire data engineering new grads? I also only have a bachelors and at best two internships at the same company for data engineering.\n\nI am scared of specializing in data engineering and then not be able to move forward in my career because I lack the qualifications (ex: masters degree, full time job experience as business analyst). Could anyone shed some light on this? \n\nMy other option would be to intern as a general SWE and pursue that path, but data engineering is a lot more interesting to me. I am not uninterested in software engineering but I definitely prefer data engineering over it.", "author_fullname": "t2_3508a2bu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Breaking into data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zpzkvv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671474895.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My goal is to eventually get a new grad data engineering position at a big tech company. Are companies usually willing to hire data engineering new grads? I also only have a bachelors and at best two internships at the same company for data engineering.&lt;/p&gt;\n\n&lt;p&gt;I am scared of specializing in data engineering and then not be able to move forward in my career because I lack the qualifications (ex: masters degree, full time job experience as business analyst). Could anyone shed some light on this? &lt;/p&gt;\n\n&lt;p&gt;My other option would be to intern as a general SWE and pursue that path, but data engineering is a lot more interesting to me. I am not uninterested in software engineering but I definitely prefer data engineering over it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zpzkvv", "is_robot_indexable": true, "report_reasons": null, "author": "SomeYak", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zpzkvv/breaking_into_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zpzkvv/breaking_into_data_engineering/", "subreddit_subscribers": 83366, "created_utc": 1671474895.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nI am an IT project manager with over 7 years of professional experience. With experiences in western Europe and Canada (where I actually live).\n\nActually, I work as a contractor Scrum Master/Agile Coach for a big company here in Canada. Long story short I am tired of project management; controlling nothing and being responsible for everything and I can't keep up with the BS and the politics anymore. Plus I feel like the future for scrum masters and agile coaches isn't any bright.\n\nI've been interested in data engineering for a couple of years now and I am seriously thinking about switching careers. I found a bootcamp that starts the summer of 2023 for 8 months and now I am taking some udemy courses on data science and data engineering.\n\n1- Is there any \"full blooded\" project managers who switched careers to move to data engineering? If yes give your honest feedback about your experiences please (sorry if you have already made posts about it before I've looked up with no success)\n\n2- In terms of salary how much can I expect for a first job in DE? (I live in Quebec)\n\nThank you all for the amazing info you share", "author_fullname": "t2_v1okhnih", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "From project manager to DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zpynn1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671472877.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I am an IT project manager with over 7 years of professional experience. With experiences in western Europe and Canada (where I actually live).&lt;/p&gt;\n\n&lt;p&gt;Actually, I work as a contractor Scrum Master/Agile Coach for a big company here in Canada. Long story short I am tired of project management; controlling nothing and being responsible for everything and I can&amp;#39;t keep up with the BS and the politics anymore. Plus I feel like the future for scrum masters and agile coaches isn&amp;#39;t any bright.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been interested in data engineering for a couple of years now and I am seriously thinking about switching careers. I found a bootcamp that starts the summer of 2023 for 8 months and now I am taking some udemy courses on data science and data engineering.&lt;/p&gt;\n\n&lt;p&gt;1- Is there any &amp;quot;full blooded&amp;quot; project managers who switched careers to move to data engineering? If yes give your honest feedback about your experiences please (sorry if you have already made posts about it before I&amp;#39;ve looked up with no success)&lt;/p&gt;\n\n&lt;p&gt;2- In terms of salary how much can I expect for a first job in DE? (I live in Quebec)&lt;/p&gt;\n\n&lt;p&gt;Thank you all for the amazing info you share&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zpynn1", "is_robot_indexable": true, "report_reasons": null, "author": "JustNeighborhood5885", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zpynn1/from_project_manager_to_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zpynn1/from_project_manager_to_de/", "subreddit_subscribers": 83366, "created_utc": 1671472877.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_meq7wkla", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Build Software Products Faster by Thinking Like a Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_zpvxqw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/pCLmNzUxajwO7jBxQ8gp9ZUwS8yeC9vwjxXVVbAWwSI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671466844.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "airbyte.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://airbyte.com/blog/data-tools-for-software-products", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5JzLEuMwaPEvQjD3Tw5GWtLOCzBrzzqa55GFhfH0ip8.jpg?auto=webp&amp;s=5cc02c375d8680bee5e0b20b3871b400892fb822", "width": 2400, "height": 1256}, "resolutions": [{"url": "https://external-preview.redd.it/5JzLEuMwaPEvQjD3Tw5GWtLOCzBrzzqa55GFhfH0ip8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7151b2861b19305dcbc8f1e8df0f13949fe1f214", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/5JzLEuMwaPEvQjD3Tw5GWtLOCzBrzzqa55GFhfH0ip8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=47b0e597de51faafadba850210ccc30b40eb6f6d", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/5JzLEuMwaPEvQjD3Tw5GWtLOCzBrzzqa55GFhfH0ip8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=aa281ba3235c5bcebcc0c8d1d1beaafa4e178dc4", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/5JzLEuMwaPEvQjD3Tw5GWtLOCzBrzzqa55GFhfH0ip8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fd3718bb54d1f3d439e8921006f1dff26afb5681", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/5JzLEuMwaPEvQjD3Tw5GWtLOCzBrzzqa55GFhfH0ip8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4baf5dfd013d4c1841de015ed51f04a795c79e27", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/5JzLEuMwaPEvQjD3Tw5GWtLOCzBrzzqa55GFhfH0ip8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c651e22f1cbbff3cb2bfb895706e2ea353fd3def", "width": 1080, "height": 565}], "variants": {}, "id": "49_OU6o3Y49GYyFgZQO6hAXFuRQvHuBF3Eb68msMus0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zpvxqw", "is_robot_indexable": true, "report_reasons": null, "author": "thabarrera", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zpvxqw/how_to_build_software_products_faster_by_thinking/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://airbyte.com/blog/data-tools-for-software-products", "subreddit_subscribers": 83366, "created_utc": 1671466844.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Ignoring things like user requested deletes, how long do you generally retain data? Is your retention policy based on regulation, costs, or something else?\n\n[View Poll](https://www.reddit.com/poll/zpsxzd)", "author_fullname": "t2_txvugrht", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How long do you retain data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zpsxzd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671459848.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Ignoring things like user requested deletes, how long do you generally retain data? Is your retention policy based on regulation, costs, or something else?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/zpsxzd\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineering Company", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zpsxzd", "is_robot_indexable": true, "report_reasons": null, "author": "prequel_co", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1671719048206, "options": [{"text": "See Results", "id": "20487440"}, {"text": "6 months or less", "id": "20487441"}, {"text": "1 year or less", "id": "20487442"}, {"text": "5 years or less", "id": "20487443"}, {"text": "10 years or less", "id": "20487444"}, {"text": "Forever", "id": "20487445"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 237, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/zpsxzd/how_long_do_you_retain_data/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/zpsxzd/how_long_do_you_retain_data/", "subreddit_subscribers": 83366, "created_utc": 1671459848.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I am trying to figure it out, but am feeling a little lost. Is there any good documentation or videos where I can learn about it?\n\n\"LMDB is written in C with API Bindings for several programming languages.\"\n\nWhere can I get a list of these languages? Is it available for Go or JavaScript? Or is it a library for query languages like SQL?\n\nI am working on a personal project that is scraping large amounts of data using JavaScript. A friend recommended LMDB. Where do I start?", "author_fullname": "t2_7y9rju54", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is Lightning Memory Mapped Database (LMDB)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zq13us", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671478295.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to figure it out, but am feeling a little lost. Is there any good documentation or videos where I can learn about it?&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;LMDB is written in C with API Bindings for several programming languages.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Where can I get a list of these languages? Is it available for Go or JavaScript? Or is it a library for query languages like SQL?&lt;/p&gt;\n\n&lt;p&gt;I am working on a personal project that is scraping large amounts of data using JavaScript. A friend recommended LMDB. Where do I start?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zq13us", "is_robot_indexable": true, "report_reasons": null, "author": "emosk8rboi4206969", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zq13us/what_is_lightning_memory_mapped_database_lmdb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zq13us/what_is_lightning_memory_mapped_database_lmdb/", "subreddit_subscribers": 83366, "created_utc": 1671478295.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "First off, I am pretty new to Azure Data Factory, but not new to data engineering.  I have a pipeline that is copying files from a file share.  The directories are moving over fine but the files in root are not.  On the source, I am using a \u201cwildcard path\u201d of \u201c*\u201d, recursively is checked, as well as \u201cDelete files after completion.\u201d  On the sink, I have \u201cPreserve Hierarchy\u201d selected.  What am I doing wrong?  I need files in root to copy to the destination.  Thanks!", "author_fullname": "t2_4270ek0g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ADF pipeline Copy Activity not copying files in root directory.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zq07h1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671476288.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First off, I am pretty new to Azure Data Factory, but not new to data engineering.  I have a pipeline that is copying files from a file share.  The directories are moving over fine but the files in root are not.  On the source, I am using a \u201cwildcard path\u201d of \u201c*\u201d, recursively is checked, as well as \u201cDelete files after completion.\u201d  On the sink, I have \u201cPreserve Hierarchy\u201d selected.  What am I doing wrong?  I need files in root to copy to the destination.  Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zq07h1", "is_robot_indexable": true, "report_reasons": null, "author": "mr_electric_wizard", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zq07h1/adf_pipeline_copy_activity_not_copying_files_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zq07h1/adf_pipeline_copy_activity_not_copying_files_in/", "subreddit_subscribers": 83366, "created_utc": 1671476288.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello.\n\nAre there any resources or documentation on how to run a jar on Glue instead of a Scala script?\n\nWe currently submit jobs to EMR which run jars that do a lot of heavy lifting. The Glue documentation is largely about running Python or Scala scripts.\n\nThanks.", "author_fullname": "t2_flx2tw2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resources on running a JAR (Scala, Spark) on AWS Glue instead of script", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zpwh5o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671468091.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello.&lt;/p&gt;\n\n&lt;p&gt;Are there any resources or documentation on how to run a jar on Glue instead of a Scala script?&lt;/p&gt;\n\n&lt;p&gt;We currently submit jobs to EMR which run jars that do a lot of heavy lifting. The Glue documentation is largely about running Python or Scala scripts.&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zpwh5o", "is_robot_indexable": true, "report_reasons": null, "author": "thegoodhunter-9115", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zpwh5o/resources_on_running_a_jar_scala_spark_on_aws/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zpwh5o/resources_on_running_a_jar_scala_spark_on_aws/", "subreddit_subscribers": 83366, "created_utc": 1671468091.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI would like to request for your guidance/advice to understand if the streaming pipeline I am working on can be somehow optimised, both in term of costs and performances.\n\nThis pipeline uses Debezium to ingest data from different MySQL databases (each of them containing \\~20-30 schemas, each of them containing \\~450-500 tables). Data is written by Debezium to a Kafka broker, and from there it is consumed by a Spark Structured streaming application that reads these events and performs upserts to Delta Tables stored on S3. These delta tables are accessed directly by our BI/reporting tools, that currently rely on a 1:1 copy of the source database (long-term solution to this at the end).\n\n&amp;#x200B;\n\nIn the current implementation of this pipeline, I have a Debezium worker for each MySQL server, and I am rerouting all events from all tables/schemas of each server to a single topic, named like the source MySQL server, so I have one connector and one topic for each MySQL server. Each topic has 12 partitions (number picked randomly, to be \"future-proof\"). For each topic there is a dedicated Spark Streaming application reading events from Kafka and upserting them to Delta tables.\n\nThis implementation is currently running, but I have some concerns and I hope someone with more experience on similar use cases could help:\n\n* I need to have one Spark streaming application for each mysql server, this can make costs levitate in case instances increase to high numbers (e.g. 100-200)\n* The Spark streaming job needs to group events by table and each batch contains events belonging to \\~70-100 different tables, therefore for each batch the same amount of upserts is performed, resulting in a latency of 20-30 minutes, which for now is acceptable.\n* I was thinking about reorganising topics by table, but:\n   * I should have \\~450-500 active Spark Streaming apps/queries, even though this would solve the problem of \\~70-100 different upserts per batch. \n   * There are tables that are written more frequently than others, meaning the upserts will take longer, thus producing potential inconsistency between tables (if I need to join two or more tables, the largest ones might not be up to date). The current solution of using a dedicated Spark App for each DB prevents this from happening\n\nIn the long term the strategy would be to convince the product team to implement CQRS pattern, in such a way I can directly consume events that already contain most of the context, so I won't have to copy so many tables from our relational DB. \n\nBut for the time being, is there any change that you would suggest to reduce both latency and potential costs growth?", "author_fullname": "t2_do2bj7xa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to optimize a streaming pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zqia5w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "08789422-ac9d-11eb-aade-0e32c0bdd4fb", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671522521.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I would like to request for your guidance/advice to understand if the streaming pipeline I am working on can be somehow optimised, both in term of costs and performances.&lt;/p&gt;\n\n&lt;p&gt;This pipeline uses Debezium to ingest data from different MySQL databases (each of them containing ~20-30 schemas, each of them containing ~450-500 tables). Data is written by Debezium to a Kafka broker, and from there it is consumed by a Spark Structured streaming application that reads these events and performs upserts to Delta Tables stored on S3. These delta tables are accessed directly by our BI/reporting tools, that currently rely on a 1:1 copy of the source database (long-term solution to this at the end).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;In the current implementation of this pipeline, I have a Debezium worker for each MySQL server, and I am rerouting all events from all tables/schemas of each server to a single topic, named like the source MySQL server, so I have one connector and one topic for each MySQL server. Each topic has 12 partitions (number picked randomly, to be &amp;quot;future-proof&amp;quot;). For each topic there is a dedicated Spark Streaming application reading events from Kafka and upserting them to Delta tables.&lt;/p&gt;\n\n&lt;p&gt;This implementation is currently running, but I have some concerns and I hope someone with more experience on similar use cases could help:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I need to have one Spark streaming application for each mysql server, this can make costs levitate in case instances increase to high numbers (e.g. 100-200)&lt;/li&gt;\n&lt;li&gt;The Spark streaming job needs to group events by table and each batch contains events belonging to ~70-100 different tables, therefore for each batch the same amount of upserts is performed, resulting in a latency of 20-30 minutes, which for now is acceptable.&lt;/li&gt;\n&lt;li&gt;I was thinking about reorganising topics by table, but:\n\n&lt;ul&gt;\n&lt;li&gt;I should have ~450-500 active Spark Streaming apps/queries, even though this would solve the problem of ~70-100 different upserts per batch. &lt;/li&gt;\n&lt;li&gt;There are tables that are written more frequently than others, meaning the upserts will take longer, thus producing potential inconsistency between tables (if I need to join two or more tables, the largest ones might not be up to date). The current solution of using a dedicated Spark App for each DB prevents this from happening&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;In the long term the strategy would be to convince the product team to implement CQRS pattern, in such a way I can directly consume events that already contain most of the context, so I won&amp;#39;t have to copy so many tables from our relational DB. &lt;/p&gt;\n\n&lt;p&gt;But for the time being, is there any change that you would suggest to reduce both latency and potential costs growth?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Big Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zqia5w", "is_robot_indexable": true, "report_reasons": null, "author": "somerandomdataeng", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/zqia5w/best_way_to_optimize_a_streaming_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zqia5w/best_way_to_optimize_a_streaming_pipeline/", "subreddit_subscribers": 83366, "created_utc": 1671522521.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to upskill in my general knowledge of databases; currently, I can fumble about and work with whatever database management system reasonably well and am most familiar with relational databases, but I know my knowledge of database models (e.g. relational, document, graph) and when, how, and why to use them is lacking.\n\nI've found bits and pieces online, but I'm looking for something more comprehensive / book-length, ideally walking through different case studies comparing database models/data designs, how they integrate with systems, how efficient/resilient/changeable they are for different tasks etc. If anyone knows of such resources, that would be amazing. Alternatively, would it be best to find separate books on these different models and work through them to get a feel for each? If so, any recommendations?", "author_fullname": "t2_bh9ilzdq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resouces comprehensively comparing different database models?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zqd8l3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671507565.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to upskill in my general knowledge of databases; currently, I can fumble about and work with whatever database management system reasonably well and am most familiar with relational databases, but I know my knowledge of database models (e.g. relational, document, graph) and when, how, and why to use them is lacking.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve found bits and pieces online, but I&amp;#39;m looking for something more comprehensive / book-length, ideally walking through different case studies comparing database models/data designs, how they integrate with systems, how efficient/resilient/changeable they are for different tasks etc. If anyone knows of such resources, that would be amazing. Alternatively, would it be best to find separate books on these different models and work through them to get a feel for each? If so, any recommendations?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zqd8l3", "is_robot_indexable": true, "report_reasons": null, "author": "zazzedcoffee", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zqd8l3/resouces_comprehensively_comparing_different/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zqd8l3/resouces_comprehensively_comparing_different/", "subreddit_subscribers": 83366, "created_utc": 1671507565.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all! At the companies where I've worked as a developer, I've found that business stakeholders typically want a *concrete* way to check and assure the quality of data that pipelines are producing, before other downstream systems and users get impacted. I've tested solutions like Deequ, but I found that it made building compliance and data rules a bit more complicated and put a greater emphasis on developers to get the rules right that business was expecting. I also experienced issues with running checks in parallel and getting row level details about the failures.\n\nSo I'm trying to create an easier solution that both dev teams and business stakeholders can use to write consistent data quality checks and rules that run on various data sources and tell the truth about the data and catch potential failures in the data.\n\nIf you want to follow along or provide any feedback, please checkout: [DATAQLTY](https://dataqlty.webflow.io/)", "author_fullname": "t2_127oi7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building a data quality solution for devs and business people", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zqd0lp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1671507961.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671506979.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all! At the companies where I&amp;#39;ve worked as a developer, I&amp;#39;ve found that business stakeholders typically want a &lt;em&gt;concrete&lt;/em&gt; way to check and assure the quality of data that pipelines are producing, before other downstream systems and users get impacted. I&amp;#39;ve tested solutions like Deequ, but I found that it made building compliance and data rules a bit more complicated and put a greater emphasis on developers to get the rules right that business was expecting. I also experienced issues with running checks in parallel and getting row level details about the failures.&lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;m trying to create an easier solution that both dev teams and business stakeholders can use to write consistent data quality checks and rules that run on various data sources and tell the truth about the data and catch potential failures in the data.&lt;/p&gt;\n\n&lt;p&gt;If you want to follow along or provide any feedback, please checkout: &lt;a href=\"https://dataqlty.webflow.io/\"&gt;DATAQLTY&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zqd0lp", "is_robot_indexable": true, "report_reasons": null, "author": "guru223", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zqd0lp/building_a_data_quality_solution_for_devs_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zqd0lp/building_a_data_quality_solution_for_devs_and/", "subreddit_subscribers": 83366, "created_utc": 1671506979.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys, I recently starter as  a data engineer and already struggling with the job. not the technical part but mostly business logic. We are developing a solution for D365 tool where we ingest the data and process it throughout the bronze silver and gold layers. Most difficult part is creating dimension tables as I have no clue what they should include, which columns and so on. I could not find a proper source where I could see all the dimensions tables per module (finance, sales, production etc) as template to use for my project. any tips? sources?", "author_fullname": "t2_56g5f4cg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dimensions and fact tables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zprh9o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671456219.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I recently starter as  a data engineer and already struggling with the job. not the technical part but mostly business logic. We are developing a solution for D365 tool where we ingest the data and process it throughout the bronze silver and gold layers. Most difficult part is creating dimension tables as I have no clue what they should include, which columns and so on. I could not find a proper source where I could see all the dimensions tables per module (finance, sales, production etc) as template to use for my project. any tips? sources?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zprh9o", "is_robot_indexable": true, "report_reasons": null, "author": "9gg6", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zprh9o/dimensions_and_fact_tables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zprh9o/dimensions_and_fact_tables/", "subreddit_subscribers": 83366, "created_utc": 1671456219.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_r570xlc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Project - Personal Finances with Airflow, Docker, Great Expectations and Metabase", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zqkowp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1671530903.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "eliasbenaddouidrissi.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://eliasbenaddouidrissi.dev/posts/data_engineering_project_monzo/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "zqkowp", "is_robot_indexable": true, "report_reasons": null, "author": "homosapienhomodeus", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zqkowp/data_engineering_project_personal_finances_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://eliasbenaddouidrissi.dev/posts/data_engineering_project_monzo/", "subreddit_subscribers": 83366, "created_utc": 1671530903.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\nSo In my use case I need to constantly read new files which arrive in a GCS bucket. I don't want to use event base like Cloud function. I am running a batch spark process on Gcp dataproc. Is there some workaround or way via which we can only read unprocessed files ? (Something like job bookmarking feature in AWS Glue)", "author_fullname": "t2_57e44nxs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to develop something like Job bookmarking (AWS glue feature) in Google Cloud ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zqjvmy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671528024.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So In my use case I need to constantly read new files which arrive in a GCS bucket. I don&amp;#39;t want to use event base like Cloud function. I am running a batch spark process on Gcp dataproc. Is there some workaround or way via which we can only read unprocessed files ? (Something like job bookmarking feature in AWS Glue)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zqjvmy", "is_robot_indexable": true, "report_reasons": null, "author": "RstarPhoneix", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zqjvmy/how_to_develop_something_like_job_bookmarking_aws/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zqjvmy/how_to_develop_something_like_job_bookmarking_aws/", "subreddit_subscribers": 83366, "created_utc": 1671528024.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Last week I had my first session in taking the Azure for data engineers webinar.  During the session I covered various tasks:  \n\\- Introduction and data manipulation using PySpark.\n\n\\-  Introduction to Databricks (UI, Cluster &amp; Dataset).\n\n\\- Mounting Azure Storage in Databricks (Blob Storage &amp; Data Lake).\n\n\\- Activating Transform Activity from Azure Data Factory.\n\n\\- Connect Transformed Data to Microsoft Power BI.  \n\ud83c\udfa5 YouTube Link: https://youtu.be/zTwevLbRfpE \n\n\u2022GitHub Repo: https://github.com/kiddojazz/Data-Transformation-using-Azure-Databricks", "author_fullname": "t2_6fwa4j9d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Transformation using Azure Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zq5jlb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1671488582.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Last week I had my first session in taking the Azure for data engineers webinar.  During the session I covered various tasks:&lt;br/&gt;\n- Introduction and data manipulation using PySpark.&lt;/p&gt;\n\n&lt;p&gt;-  Introduction to Databricks (UI, Cluster &amp;amp; Dataset).&lt;/p&gt;\n\n&lt;p&gt;- Mounting Azure Storage in Databricks (Blob Storage &amp;amp; Data Lake).&lt;/p&gt;\n\n&lt;p&gt;- Activating Transform Activity from Azure Data Factory.&lt;/p&gt;\n\n&lt;p&gt;- Connect Transformed Data to Microsoft Power BI.&lt;br/&gt;\n\ud83c\udfa5 YouTube Link: &lt;a href=\"https://youtu.be/zTwevLbRfpE\"&gt;https://youtu.be/zTwevLbRfpE&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;\u2022GitHub Repo: &lt;a href=\"https://github.com/kiddojazz/Data-Transformation-using-Azure-Databricks\"&gt;https://github.com/kiddojazz/Data-Transformation-using-Azure-Databricks&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/60hu9Woxfra3pwTH9A7GtZrX2h3bjHAnExttROIR5VM.jpg?auto=webp&amp;s=69ee3f3c553f2fd0fe85a7dd6721908154ec3c71", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/60hu9Woxfra3pwTH9A7GtZrX2h3bjHAnExttROIR5VM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d28e721f2a4a8eade8e982ec2cb7efdc155e920e", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/60hu9Woxfra3pwTH9A7GtZrX2h3bjHAnExttROIR5VM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=192c1cd4113196c542b8727f428c05b9768ba5b1", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/60hu9Woxfra3pwTH9A7GtZrX2h3bjHAnExttROIR5VM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a9963513139eb524d670a5a9f08e53d312a3e502", "width": 320, "height": 240}], "variants": {}, "id": "XP66OiJjgYCGmtcsqMtj_zrpniIltUg-88PfnRaP8mA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zq5jlb", "is_robot_indexable": true, "report_reasons": null, "author": "kiddojazz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zq5jlb/data_transformation_using_azure_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zq5jlb/data_transformation_using_azure_databricks/", "subreddit_subscribers": 83366, "created_utc": 1671488582.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_ggio6wps", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The top 6 lessons learned why companies struggle with cloud data efficiency", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_zpx6oh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/XIPIVVcri4sBrRdLu6AtblfRs3N5GZiM-s9dOV1zeFY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671469622.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/sync-computing/the-top-6-reasons-why-companies-struggle-with-improving-cloud-data-infrastructure-37a79d40805a", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yu1qol6u--XPiGQbbaKC0eRZfpBQeCCkyfdo9suLY5I.jpg?auto=webp&amp;s=55dc0af37157e0206d4b66ce444d7397c3964b1c", "width": 1200, "height": 627}, "resolutions": [{"url": "https://external-preview.redd.it/yu1qol6u--XPiGQbbaKC0eRZfpBQeCCkyfdo9suLY5I.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ac7596dd85de5ee80a23ac28ee63f7fae520d6e7", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/yu1qol6u--XPiGQbbaKC0eRZfpBQeCCkyfdo9suLY5I.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=743bfd4636ef2313769a5ec644fea848f5d847b4", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/yu1qol6u--XPiGQbbaKC0eRZfpBQeCCkyfdo9suLY5I.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a657095e4bbd8d68144d8adac45d015d3a6d92c7", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/yu1qol6u--XPiGQbbaKC0eRZfpBQeCCkyfdo9suLY5I.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=75e94f6f9411e25bb00aa6e6535c539481f08e8c", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/yu1qol6u--XPiGQbbaKC0eRZfpBQeCCkyfdo9suLY5I.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d4e4f333dcdecae2880b2054c8aafcf3f0472428", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/yu1qol6u--XPiGQbbaKC0eRZfpBQeCCkyfdo9suLY5I.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=972450929ccd4c4e6dd92cac1669686032977172", "width": 1080, "height": 564}], "variants": {}, "id": "q16jmHo04kNL7wRSdPn1Sy-rtOR_CQq32oQnJKcO_9E"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zpx6oh", "is_robot_indexable": true, "report_reasons": null, "author": "gobstopper_chicken", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zpx6oh/the_top_6_lessons_learned_why_companies_struggle/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/sync-computing/the-top-6-reasons-why-companies-struggle-with-improving-cloud-data-infrastructure-37a79d40805a", "subreddit_subscribers": 83366, "created_utc": 1671469622.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://medium.com/p/911486a644ff](https://medium.com/p/911486a644ff)", "author_fullname": "t2_bqjrmnud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Design Considerations for Cloud-Native Data Systems", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zpvupr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1671466649.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://medium.com/p/911486a644ff\"&gt;https://medium.com/p/911486a644ff&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/j7g6I3muaSOABsUTW-37-2v0SFppYeRaloELfGJtLvs.jpg?auto=webp&amp;s=7f831751953c8b17f416893730d373d86b357a32", "width": 1200, "height": 1024}, "resolutions": [{"url": "https://external-preview.redd.it/j7g6I3muaSOABsUTW-37-2v0SFppYeRaloELfGJtLvs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cbfd0b61baed8fc22ac09a215e47382b95bd669b", "width": 108, "height": 92}, {"url": "https://external-preview.redd.it/j7g6I3muaSOABsUTW-37-2v0SFppYeRaloELfGJtLvs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=256dfb3c6347c6cf47b7ac3defd6f9909646cafd", "width": 216, "height": 184}, {"url": "https://external-preview.redd.it/j7g6I3muaSOABsUTW-37-2v0SFppYeRaloELfGJtLvs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bc2041db176a00e67e146d818a25549e2fd278c2", "width": 320, "height": 273}, {"url": "https://external-preview.redd.it/j7g6I3muaSOABsUTW-37-2v0SFppYeRaloELfGJtLvs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e60fd39edc994837279628f0f5ee4f17ccbae495", "width": 640, "height": 546}, {"url": "https://external-preview.redd.it/j7g6I3muaSOABsUTW-37-2v0SFppYeRaloELfGJtLvs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d15a44610406d097c40160fd295e48792d8ed8ba", "width": 960, "height": 819}, {"url": "https://external-preview.redd.it/j7g6I3muaSOABsUTW-37-2v0SFppYeRaloELfGJtLvs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c44da0444db4c60e54769923bab860a1c8fdd99e", "width": 1080, "height": 921}], "variants": {}, "id": "7DNa-AVFwD2dfKYbcXqtc12ncZBzpZB_ciPUgvaQAAM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zpvupr", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering_Bug105", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zpvupr/design_considerations_for_cloudnative_data_systems/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zpvupr/design_considerations_for_cloudnative_data_systems/", "subreddit_subscribers": 83366, "created_utc": 1671466649.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We used text to SQL to build a \"Webflow for Web3 Dashboards\". We discovered loads of problems in the entire blockchain data space outlined in the thread.\n\nDemo: Design your dashboard, type your query in English.\n\nWe're open-sourcing everything.\n\n[https://twitter.com/vatsal\\_aggarwal/status/1604995355468173312?s=20&amp;t=DJ-zmyaV7g5jgbUGpsssmQ](https://twitter.com/vatsal_aggarwal/status/1604995355468173312?s=20&amp;t=DJ-zmyaV7g5jgbUGpsssmQ)", "author_fullname": "t2_ea8d3w57", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Open-sourcing text-to-SQL for blockchain data!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zq9hyk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1671498014.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We used text to SQL to build a &amp;quot;Webflow for Web3 Dashboards&amp;quot;. We discovered loads of problems in the entire blockchain data space outlined in the thread.&lt;/p&gt;\n\n&lt;p&gt;Demo: Design your dashboard, type your query in English.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re open-sourcing everything.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://twitter.com/vatsal_aggarwal/status/1604995355468173312?s=20&amp;amp;t=DJ-zmyaV7g5jgbUGpsssmQ\"&gt;https://twitter.com/vatsal_aggarwal/status/1604995355468173312?s=20&amp;amp;t=DJ-zmyaV7g5jgbUGpsssmQ&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/soVXxY3in1C5Xb1xu9X0epwwcbmX2yQZDLHcDwYl0Go.jpg?auto=webp&amp;s=28b738ba55e892a6dd8d8dffd2e23f97ed59837f", "width": 140, "height": 90}, "resolutions": [{"url": "https://external-preview.redd.it/soVXxY3in1C5Xb1xu9X0epwwcbmX2yQZDLHcDwYl0Go.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=aba91d8de11ec54f0a9f913c4274c369a2263b16", "width": 108, "height": 69}], "variants": {}, "id": "atjhhl11daWVVuu8SYGQEqyjtZXvbh4CM2nQ97YctLI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zq9hyk", "is_robot_indexable": true, "report_reasons": null, "author": "Apprehensive-Tax-214", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zq9hyk/opensourcing_texttosql_for_blockchain_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zq9hyk/opensourcing_texttosql_for_blockchain_data/", "subreddit_subscribers": 83366, "created_utc": 1671498014.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}