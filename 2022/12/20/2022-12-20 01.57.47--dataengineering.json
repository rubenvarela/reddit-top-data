{"kind": "Listing", "data": {"after": null, "dist": 24, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Recruiter ends interview because candidate has no experience with Databricks but the job description is not explicit about it being required. The unprofessionalism that some of these companies display is astonishing..\n\n&amp;#x200B;\n\n&gt;The first interview was scheduled on Tuesday and 20 minutes before, I receive an email from the recruiter asking to postpone for Friday because the hiring manager had an \u201cemergency\u201d. I was extremely annoyed, but I accepted, nonetheless.  \n&gt;  \n&gt;We start the interview on Friday, and I immediately notice the hiring manager avoiding eye contact. I found that to be strange and it made me uncomfortable. Then, 12 minutes in, he asks if I have experience with DataBricks which I promptly told him that I do not, and he proceeds to say \u201cI have to end the interview because DataBricks is a requirement\u201d  \n&gt;  \n&gt;I pressed him by stating that the Job Description clearly states *(Airflow, Databricks, Snowflake, Serverless Functions, Cloud storage preferred)* and that I never included Databricks on my resume.  \n&gt;  \n&gt;He then says \u201cWell, we are looking for someone Senior\u201d which I replied by saying that the recruiter assured me on 3 different conversations that this was not a senior role. We went back and forth for some 5 minutes, and I eventually end the call.  \n&gt;  \n&gt;I emailed the recruiter right away to share my displeasure of the session and she calls my phone. She explains to me that the hiring manager had decided a few hours before that he wanted someone senior which angered me because he basically wasted my time twice.\n\n[https://www.reddit.com/r/recruitinghell/comments/zpflbr/name\\_and\\_shame\\_nielseniq\\_interviewer\\_ends/](https://www.reddit.com/r/recruitinghell/comments/zpflbr/name_and_shame_nielseniq_interviewer_ends/)", "author_fullname": "t2_7698zbc7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "From /recruitinghell - (Name and Shame: NielsenIQ - Interviewer ends interview 12 mins in.)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zpt1ri", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 69, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 69, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671460090.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Recruiter ends interview because candidate has no experience with Databricks but the job description is not explicit about it being required. The unprofessionalism that some of these companies display is astonishing..&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;The first interview was scheduled on Tuesday and 20 minutes before, I receive an email from the recruiter asking to postpone for Friday because the hiring manager had an \u201cemergency\u201d. I was extremely annoyed, but I accepted, nonetheless.  &lt;/p&gt;\n\n&lt;p&gt;We start the interview on Friday, and I immediately notice the hiring manager avoiding eye contact. I found that to be strange and it made me uncomfortable. Then, 12 minutes in, he asks if I have experience with DataBricks which I promptly told him that I do not, and he proceeds to say \u201cI have to end the interview because DataBricks is a requirement\u201d  &lt;/p&gt;\n\n&lt;p&gt;I pressed him by stating that the Job Description clearly states &lt;em&gt;(Airflow, Databricks, Snowflake, Serverless Functions, Cloud storage preferred)&lt;/em&gt; and that I never included Databricks on my resume.  &lt;/p&gt;\n\n&lt;p&gt;He then says \u201cWell, we are looking for someone Senior\u201d which I replied by saying that the recruiter assured me on 3 different conversations that this was not a senior role. We went back and forth for some 5 minutes, and I eventually end the call.  &lt;/p&gt;\n\n&lt;p&gt;I emailed the recruiter right away to share my displeasure of the session and she calls my phone. She explains to me that the hiring manager had decided a few hours before that he wanted someone senior which angered me because he basically wasted my time twice.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/recruitinghell/comments/zpflbr/name_and_shame_nielseniq_interviewer_ends/\"&gt;https://www.reddit.com/r/recruitinghell/comments/zpflbr/name_and_shame_nielseniq_interviewer_ends/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zpt1ri", "is_robot_indexable": true, "report_reasons": null, "author": "Manoloskinny", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zpt1ri/from_recruitinghell_name_and_shame_nielseniq/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zpt1ri/from_recruitinghell_name_and_shame_nielseniq/", "subreddit_subscribers": 83337, "created_utc": 1671460090.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_69a5f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "explaining what the data modeler on the team does", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_zq4eg6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 60, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 60, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/oKNUA7sY1Eh2aloDHp4Q-2QbFqqpb4h5homJ0tTEae8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671485970.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/4svii7iyty6a1.gif", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/4svii7iyty6a1.gif?format=png8&amp;s=4bd9c72626681c8ab5f84b9f177e29fc9e05f6c4", "width": 480, "height": 360}, "resolutions": [{"url": "https://preview.redd.it/4svii7iyty6a1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=fe04087d34b32b14c5d236d9b58bb5840f693c1f", "width": 108, "height": 81}, {"url": "https://preview.redd.it/4svii7iyty6a1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=7ca3dbf483553b27cd31ce551b1b040379cf5ce2", "width": 216, "height": 162}, {"url": "https://preview.redd.it/4svii7iyty6a1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=c280a6b4d28e30ed54f2e5fd5a81b54dcb884ca9", "width": 320, "height": 240}], "variants": {"gif": {"source": {"url": "https://preview.redd.it/4svii7iyty6a1.gif?s=e7723bc482be0b0026b05fe53ee196f60f98aa6d", "width": 480, "height": 360}, "resolutions": [{"url": "https://preview.redd.it/4svii7iyty6a1.gif?width=108&amp;crop=smart&amp;s=f89dbb860b65ec70b99a348a3cd7dd4ec108e602", "width": 108, "height": 81}, {"url": "https://preview.redd.it/4svii7iyty6a1.gif?width=216&amp;crop=smart&amp;s=6e814c7d821378c262c3345090f92e2e76f199ed", "width": 216, "height": 162}, {"url": "https://preview.redd.it/4svii7iyty6a1.gif?width=320&amp;crop=smart&amp;s=dcb652318b88d353cfd9091b4c44599fdd0ee95d", "width": 320, "height": 240}]}, "mp4": {"source": {"url": "https://preview.redd.it/4svii7iyty6a1.gif?format=mp4&amp;s=79c646a6091a2054ecc51083894f393f601296e0", "width": 480, "height": 360}, "resolutions": [{"url": "https://preview.redd.it/4svii7iyty6a1.gif?width=108&amp;format=mp4&amp;s=70fad6d8c2188e0ffcde10e091198fadcadeaa9b", "width": 108, "height": 81}, {"url": "https://preview.redd.it/4svii7iyty6a1.gif?width=216&amp;format=mp4&amp;s=a4b6826456166838c71df8356d2f4a3ee4f46dee", "width": 216, "height": 162}, {"url": "https://preview.redd.it/4svii7iyty6a1.gif?width=320&amp;format=mp4&amp;s=3e090612250734014da0751f7e93c82c54d17efb", "width": 320, "height": 240}]}}, "id": "v7U3z_ZRcPCLfYaFGIe2eihy6KZVGMFdg-7Mzcfk9Sg"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "zq4eg6", "is_robot_indexable": true, "report_reasons": null, "author": "DiceboyT", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zq4eg6/explaining_what_the_data_modeler_on_the_team_does/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/4svii7iyty6a1.gif", "subreddit_subscribers": 83337, "created_utc": 1671485970.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a fresh CS graduate with few internships but fancy getting into Data Engineering. have already taken the Associate certification (relatively easy exam) And prepping to take the professional data engineering exam.\nSo my question are certification along with a solid end to end project get me a job?\nAnd has anyone gotten a job solely on project and certifications? \nPS. have no DE work experience except for the data engineering zoomcamp by datatalkclub", "author_fullname": "t2_2584wlci", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is the Google Professional DE Certification Worth it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zpmb7b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671439332.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a fresh CS graduate with few internships but fancy getting into Data Engineering. have already taken the Associate certification (relatively easy exam) And prepping to take the professional data engineering exam.\nSo my question are certification along with a solid end to end project get me a job?\nAnd has anyone gotten a job solely on project and certifications? \nPS. have no DE work experience except for the data engineering zoomcamp by datatalkclub&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zpmb7b", "is_robot_indexable": true, "report_reasons": null, "author": "donbigi", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zpmb7b/is_the_google_professional_de_certification_worth/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zpmb7b/is_the_google_professional_de_certification_worth/", "subreddit_subscribers": 83337, "created_utc": 1671439332.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3hhpxtkh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Warehouse vs. Operational Database! What? How? Which One? -- the fundamental difference between a data warehouse and an operational database", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 88, "top_awarded_type": null, "hide_score": false, "name": "t3_zpozxv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/tHQu9Ka67XvlGDSatxV84dwPRcRZ3JqWvmfKufwC9hA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671449008.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "airbyte.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://airbyte.com/blog/data-warehouse-vs-operational-database", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/NvNbVUPU4V6doNJnkdfCrpmAJ4GZFnfNFrKgFUorwCM.jpg?auto=webp&amp;s=4717ec05188dbee99c00957e20f16a67b0a816ea", "width": 1800, "height": 1139}, "resolutions": [{"url": "https://external-preview.redd.it/NvNbVUPU4V6doNJnkdfCrpmAJ4GZFnfNFrKgFUorwCM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=08b9cc28d2a73c6a4b1e7a0d34d87f88b3f03404", "width": 108, "height": 68}, {"url": "https://external-preview.redd.it/NvNbVUPU4V6doNJnkdfCrpmAJ4GZFnfNFrKgFUorwCM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=af67d98bb82d08179d391d1d45098692a4d62158", "width": 216, "height": 136}, {"url": "https://external-preview.redd.it/NvNbVUPU4V6doNJnkdfCrpmAJ4GZFnfNFrKgFUorwCM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=07c45632ddd29ef5b92da17a6d40d691374bc66a", "width": 320, "height": 202}, {"url": "https://external-preview.redd.it/NvNbVUPU4V6doNJnkdfCrpmAJ4GZFnfNFrKgFUorwCM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=80a60e82ea4900a55d26622c1c37265465289841", "width": 640, "height": 404}, {"url": "https://external-preview.redd.it/NvNbVUPU4V6doNJnkdfCrpmAJ4GZFnfNFrKgFUorwCM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6baef0dedbf7018fee4c9eb25193253138fb058f", "width": 960, "height": 607}, {"url": "https://external-preview.redd.it/NvNbVUPU4V6doNJnkdfCrpmAJ4GZFnfNFrKgFUorwCM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=44a4a170abd63ac26744b08da61847c3d5ecabde", "width": 1080, "height": 683}], "variants": {}, "id": "ZUtreMWiHWMXc_MynMY_0pMeEi4GPWVCRrAMpVxPVNg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zpozxv", "is_robot_indexable": true, "report_reasons": null, "author": "alexmarquardt", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zpozxv/data_warehouse_vs_operational_database_what_how/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://airbyte.com/blog/data-warehouse-vs-operational-database", "subreddit_subscribers": 83337, "created_utc": 1671449008.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work for a small fintect business (around 100 employees) as a data engineer. The majority of the company's key data is stored on a 1 TB prod Azure sql database (with matching dev and QA, and another smalled 300 GB SQL Server on-prem DB. A few analysts do power BI reporting off these data sources, and one of them connects to a pricing app our sales team uses. We are a microsoft shop basically.\n\nWe are trying to implement true data management program, knowing that we have these needs but also wanting to cover some that we aren't even aware we need. We do know we want:\n\n\\- Data dictionary/catalog so analysts know what are the main tables that have the data they want power BI reports and our own compliance\n\n\\- Some way to assign data stewards who can keep the data catalog up to date\n\n\\- Ways to tag data as PHI, or what it's retention time is, to encourage privacy and retention compliance\n\n\\- Seeing lineage of our pipelines\n\n\\- Features that help consolidate records and the 'golden record' pursuit\n\n\\- In general anything helping us get to the goal of practicing data management.\n\nThe obvious answer is Microsoft Purview, and it seems to click a lot of boxes and we are a microsoft shop, but I'm worried about the pricing. It seems like it could get expensive really quickly with the pay for use model, beyond any value it brings. We have a reasonable budget for data management but it's going to be hard to justify huge bills for what to most people will just be a data catalog.\n\nOther's I've looked at are [data.world](https://data.world), altan, collibri, and alation. Then I see these open source versions with apache atlas or linkedin datahub and wonder if I should be going the free route and spin something entirely myself? I'm not trying to turn this into a sales post because I am skeptical of all of them despite knowing we need something :)\n\nHas anyone solved similar data management wants with any of these tools? Or have any general advice.", "author_fullname": "t2_jrhnhrj0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommended Data Governance solution for smaller businesses?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zpjoid", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671429845.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work for a small fintect business (around 100 employees) as a data engineer. The majority of the company&amp;#39;s key data is stored on a 1 TB prod Azure sql database (with matching dev and QA, and another smalled 300 GB SQL Server on-prem DB. A few analysts do power BI reporting off these data sources, and one of them connects to a pricing app our sales team uses. We are a microsoft shop basically.&lt;/p&gt;\n\n&lt;p&gt;We are trying to implement true data management program, knowing that we have these needs but also wanting to cover some that we aren&amp;#39;t even aware we need. We do know we want:&lt;/p&gt;\n\n&lt;p&gt;- Data dictionary/catalog so analysts know what are the main tables that have the data they want power BI reports and our own compliance&lt;/p&gt;\n\n&lt;p&gt;- Some way to assign data stewards who can keep the data catalog up to date&lt;/p&gt;\n\n&lt;p&gt;- Ways to tag data as PHI, or what it&amp;#39;s retention time is, to encourage privacy and retention compliance&lt;/p&gt;\n\n&lt;p&gt;- Seeing lineage of our pipelines&lt;/p&gt;\n\n&lt;p&gt;- Features that help consolidate records and the &amp;#39;golden record&amp;#39; pursuit&lt;/p&gt;\n\n&lt;p&gt;- In general anything helping us get to the goal of practicing data management.&lt;/p&gt;\n\n&lt;p&gt;The obvious answer is Microsoft Purview, and it seems to click a lot of boxes and we are a microsoft shop, but I&amp;#39;m worried about the pricing. It seems like it could get expensive really quickly with the pay for use model, beyond any value it brings. We have a reasonable budget for data management but it&amp;#39;s going to be hard to justify huge bills for what to most people will just be a data catalog.&lt;/p&gt;\n\n&lt;p&gt;Other&amp;#39;s I&amp;#39;ve looked at are &lt;a href=\"https://data.world\"&gt;data.world&lt;/a&gt;, altan, collibri, and alation. Then I see these open source versions with apache atlas or linkedin datahub and wonder if I should be going the free route and spin something entirely myself? I&amp;#39;m not trying to turn this into a sales post because I am skeptical of all of them despite knowing we need something :)&lt;/p&gt;\n\n&lt;p&gt;Has anyone solved similar data management wants with any of these tools? Or have any general advice.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zpjoid", "is_robot_indexable": true, "report_reasons": null, "author": "firelink_kink", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zpjoid/recommended_data_governance_solution_for_smaller/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zpjoid/recommended_data_governance_solution_for_smaller/", "subreddit_subscribers": 83337, "created_utc": 1671429845.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I am looking for any tutorials that you know of where I can create some kind of project end-to-end, getting introduced to a variety of technologies and skills. \n\nFor example, if I want to create an ETL workflow that ends up feeding a Tableau dashboard. In this process I want to learn/pracitce version control, Python or SQL, etc. \n\nI ask because job descriptions ask things like \u201crequires experience with front-end development of data visualization environments from scratch using Python\u201d and \u201cexperience implementing production code and automation tooling.\u201d\n\nThanks!", "author_fullname": "t2_e62drqi5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Project ideas/tutorials Recommendations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zphsfl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671423855.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am looking for any tutorials that you know of where I can create some kind of project end-to-end, getting introduced to a variety of technologies and skills. &lt;/p&gt;\n\n&lt;p&gt;For example, if I want to create an ETL workflow that ends up feeding a Tableau dashboard. In this process I want to learn/pracitce version control, Python or SQL, etc. &lt;/p&gt;\n\n&lt;p&gt;I ask because job descriptions ask things like \u201crequires experience with front-end development of data visualization environments from scratch using Python\u201d and \u201cexperience implementing production code and automation tooling.\u201d&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zphsfl", "is_robot_indexable": true, "report_reasons": null, "author": "Bubbly-Woodpecker-26", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zphsfl/project_ideastutorials_recommendations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zphsfl/project_ideastutorials_recommendations/", "subreddit_subscribers": 83337, "created_utc": 1671423855.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " The Pipeline for updating data between OLTP and OLAP environments \n\n&amp;#x200B;\n\n[ The Pipeline for updating data between OLTP and OLAP environments ](https://preview.redd.it/8cgophq7bw6a1.png?width=1354&amp;format=png&amp;auto=webp&amp;s=a6d55303e4550c15144385ffd1f18005de1b9a50)\n\n[https://medium.com/@stefentaime\\_10958/elt-airflow-pipeline-project-dcf834c1be17](https://medium.com/@stefentaime_10958/elt-airflow-pipeline-project-dcf834c1be17)", "author_fullname": "t2_7sisbd20", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ELT Airflow Pipeline Project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 80, "top_awarded_type": null, "hide_score": false, "media_metadata": {"8cgophq7bw6a1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 62, "x": 108, "u": "https://preview.redd.it/8cgophq7bw6a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0b8c6416e54039afe098eaac5e375d404c018b48"}, {"y": 124, "x": 216, "u": "https://preview.redd.it/8cgophq7bw6a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9ee4f58bb59f8b8873de1ed245ec2202ba94cf77"}, {"y": 183, "x": 320, "u": "https://preview.redd.it/8cgophq7bw6a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c6c41b7a53f55f78a40bb1c42c46bb5cbe1bcc10"}, {"y": 367, "x": 640, "u": "https://preview.redd.it/8cgophq7bw6a1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8316045e2b4bafa09121961b432e11ce3f678eac"}, {"y": 551, "x": 960, "u": "https://preview.redd.it/8cgophq7bw6a1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=5fb7cae10a1a09ee9e1c1a4bd2a3f5e7bf9b8e7b"}, {"y": 620, "x": 1080, "u": "https://preview.redd.it/8cgophq7bw6a1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=bdfbd841a8083146df5ca23ac2b9d08a9d42c1e4"}], "s": {"y": 778, "x": 1354, "u": "https://preview.redd.it/8cgophq7bw6a1.png?width=1354&amp;format=png&amp;auto=webp&amp;s=a6d55303e4550c15144385ffd1f18005de1b9a50"}, "id": "8cgophq7bw6a1"}}, "name": "t3_zpyyg3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/W-QDl95mFueasfk1yi2Y6SgdkXxW8mCJsP8DoPRbrn4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1671473515.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The Pipeline for updating data between OLTP and OLAP environments &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/8cgophq7bw6a1.png?width=1354&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a6d55303e4550c15144385ffd1f18005de1b9a50\"&gt; The Pipeline for updating data between OLTP and OLAP environments &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@stefentaime_10958/elt-airflow-pipeline-project-dcf834c1be17\"&gt;https://medium.com/@stefentaime_10958/elt-airflow-pipeline-project-dcf834c1be17&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/d51pTwrTqzOE_YsYg-xnX7l3X78A57o4PTo_-_7mDrU.jpg?auto=webp&amp;s=189a6b24f481906e17128d1b5a6ce2b10ceb8ce5", "width": 1200, "height": 689}, "resolutions": [{"url": "https://external-preview.redd.it/d51pTwrTqzOE_YsYg-xnX7l3X78A57o4PTo_-_7mDrU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=17fac23626ad5fcf3da6a672329f1395f6b67a27", "width": 108, "height": 62}, {"url": "https://external-preview.redd.it/d51pTwrTqzOE_YsYg-xnX7l3X78A57o4PTo_-_7mDrU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1b947e27d92a4477f6dc0e8a996c34d8eb2906f4", "width": 216, "height": 124}, {"url": "https://external-preview.redd.it/d51pTwrTqzOE_YsYg-xnX7l3X78A57o4PTo_-_7mDrU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ba2767011db48b488445199fc41003d3b7ef246b", "width": 320, "height": 183}, {"url": "https://external-preview.redd.it/d51pTwrTqzOE_YsYg-xnX7l3X78A57o4PTo_-_7mDrU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2edf3c6efc64db37a516d43b13ca29119005ecce", "width": 640, "height": 367}, {"url": "https://external-preview.redd.it/d51pTwrTqzOE_YsYg-xnX7l3X78A57o4PTo_-_7mDrU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f5e057d195010417e4dbe8ee7f0d50dec6b55ffd", "width": 960, "height": 551}, {"url": "https://external-preview.redd.it/d51pTwrTqzOE_YsYg-xnX7l3X78A57o4PTo_-_7mDrU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ed86019ba3ebb3c6dea7e2b42faec21e954f4e65", "width": 1080, "height": 620}], "variants": {}, "id": "30-hhPvTjai8fSVRjgRQJhYhB7ZWkwAJX3v0K0Z5WOg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "zpyyg3", "is_robot_indexable": true, "report_reasons": null, "author": "Jealous_Ad6059", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zpyyg3/elt_airflow_pipeline_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zpyyg3/elt_airflow_pipeline_project/", "subreddit_subscribers": 83337, "created_utc": 1671473515.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nI am an IT project manager with over 7 years of professional experience. With experiences in western Europe and Canada (where I actually live).\n\nActually, I work as a contractor Scrum Master/Agile Coach for a big company here in Canada. Long story short I am tired of project management; controlling nothing and being responsible for everything and I can't keep up with the BS and the politics anymore. Plus I feel like the future for scrum masters and agile coaches isn't any bright.\n\nI've been interested in data engineering for a couple of years now and I am seriously thinking about switching careers. I found a bootcamp that starts the summer of 2023 for 8 months and now I am taking some udemy courses on data science and data engineering.\n\n1- Is there any \"full blooded\" project managers who switched careers to move to data engineering? If yes give your honest feedback about your experiences please (sorry if you have already made posts about it before I've looked up with no success)\n\n2- In terms of salary how much can I expect for a first job in DE? (I live in Quebec)\n\nThank you all for the amazing info you share", "author_fullname": "t2_v1okhnih", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "From project manager to DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zpynn1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671472877.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I am an IT project manager with over 7 years of professional experience. With experiences in western Europe and Canada (where I actually live).&lt;/p&gt;\n\n&lt;p&gt;Actually, I work as a contractor Scrum Master/Agile Coach for a big company here in Canada. Long story short I am tired of project management; controlling nothing and being responsible for everything and I can&amp;#39;t keep up with the BS and the politics anymore. Plus I feel like the future for scrum masters and agile coaches isn&amp;#39;t any bright.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been interested in data engineering for a couple of years now and I am seriously thinking about switching careers. I found a bootcamp that starts the summer of 2023 for 8 months and now I am taking some udemy courses on data science and data engineering.&lt;/p&gt;\n\n&lt;p&gt;1- Is there any &amp;quot;full blooded&amp;quot; project managers who switched careers to move to data engineering? If yes give your honest feedback about your experiences please (sorry if you have already made posts about it before I&amp;#39;ve looked up with no success)&lt;/p&gt;\n\n&lt;p&gt;2- In terms of salary how much can I expect for a first job in DE? (I live in Quebec)&lt;/p&gt;\n\n&lt;p&gt;Thank you all for the amazing info you share&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zpynn1", "is_robot_indexable": true, "report_reasons": null, "author": "JustNeighborhood5885", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zpynn1/from_project_manager_to_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zpynn1/from_project_manager_to_de/", "subreddit_subscribers": 83337, "created_utc": 1671472877.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My goal is to eventually get a new grad data engineering position at a big tech company. Are companies usually willing to hire data engineering new grads? I also only have a bachelors and at best two internships at the same company for data engineering.\n\nI am scared of specializing in data engineering and then not be able to move forward in my career because I lack the qualifications (ex: masters degree, full time job experience as business analyst). Could anyone shed some light on this? \n\nMy other option would be to intern as a general SWE and pursue that path, but data engineering is a lot more interesting to me. I am not uninterested in software engineering but I definitely prefer data engineering over it.", "author_fullname": "t2_3508a2bu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Breaking into data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zpzkvv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671474895.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My goal is to eventually get a new grad data engineering position at a big tech company. Are companies usually willing to hire data engineering new grads? I also only have a bachelors and at best two internships at the same company for data engineering.&lt;/p&gt;\n\n&lt;p&gt;I am scared of specializing in data engineering and then not be able to move forward in my career because I lack the qualifications (ex: masters degree, full time job experience as business analyst). Could anyone shed some light on this? &lt;/p&gt;\n\n&lt;p&gt;My other option would be to intern as a general SWE and pursue that path, but data engineering is a lot more interesting to me. I am not uninterested in software engineering but I definitely prefer data engineering over it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zpzkvv", "is_robot_indexable": true, "report_reasons": null, "author": "SomeYak", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zpzkvv/breaking_into_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zpzkvv/breaking_into_data_engineering/", "subreddit_subscribers": 83337, "created_utc": 1671474895.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_meq7wkla", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Build Software Products Faster by Thinking Like a Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_zpvxqw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/pCLmNzUxajwO7jBxQ8gp9ZUwS8yeC9vwjxXVVbAWwSI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671466844.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "airbyte.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://airbyte.com/blog/data-tools-for-software-products", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5JzLEuMwaPEvQjD3Tw5GWtLOCzBrzzqa55GFhfH0ip8.jpg?auto=webp&amp;s=5cc02c375d8680bee5e0b20b3871b400892fb822", "width": 2400, "height": 1256}, "resolutions": [{"url": "https://external-preview.redd.it/5JzLEuMwaPEvQjD3Tw5GWtLOCzBrzzqa55GFhfH0ip8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7151b2861b19305dcbc8f1e8df0f13949fe1f214", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/5JzLEuMwaPEvQjD3Tw5GWtLOCzBrzzqa55GFhfH0ip8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=47b0e597de51faafadba850210ccc30b40eb6f6d", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/5JzLEuMwaPEvQjD3Tw5GWtLOCzBrzzqa55GFhfH0ip8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=aa281ba3235c5bcebcc0c8d1d1beaafa4e178dc4", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/5JzLEuMwaPEvQjD3Tw5GWtLOCzBrzzqa55GFhfH0ip8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fd3718bb54d1f3d439e8921006f1dff26afb5681", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/5JzLEuMwaPEvQjD3Tw5GWtLOCzBrzzqa55GFhfH0ip8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4baf5dfd013d4c1841de015ed51f04a795c79e27", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/5JzLEuMwaPEvQjD3Tw5GWtLOCzBrzzqa55GFhfH0ip8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c651e22f1cbbff3cb2bfb895706e2ea353fd3def", "width": 1080, "height": 565}], "variants": {}, "id": "49_OU6o3Y49GYyFgZQO6hAXFuRQvHuBF3Eb68msMus0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zpvxqw", "is_robot_indexable": true, "report_reasons": null, "author": "thabarrera", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zpvxqw/how_to_build_software_products_faster_by_thinking/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://airbyte.com/blog/data-tools-for-software-products", "subreddit_subscribers": 83337, "created_utc": 1671466844.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "First off, I am pretty new to Azure Data Factory, but not new to data engineering.  I have a pipeline that is copying files from a file share.  The directories are moving over fine but the files in root are not.  On the source, I am using a \u201cwildcard path\u201d of \u201c*\u201d, recursively is checked, as well as \u201cDelete files after completion.\u201d  On the sink, I have \u201cPreserve Hierarchy\u201d selected.  What am I doing wrong?  I need files in root to copy to the destination.  Thanks!", "author_fullname": "t2_4270ek0g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ADF pipeline Copy Activity not copying files in root directory.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zq07h1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671476288.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First off, I am pretty new to Azure Data Factory, but not new to data engineering.  I have a pipeline that is copying files from a file share.  The directories are moving over fine but the files in root are not.  On the source, I am using a \u201cwildcard path\u201d of \u201c*\u201d, recursively is checked, as well as \u201cDelete files after completion.\u201d  On the sink, I have \u201cPreserve Hierarchy\u201d selected.  What am I doing wrong?  I need files in root to copy to the destination.  Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zq07h1", "is_robot_indexable": true, "report_reasons": null, "author": "mr_electric_wizard", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zq07h1/adf_pipeline_copy_activity_not_copying_files_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zq07h1/adf_pipeline_copy_activity_not_copying_files_in/", "subreddit_subscribers": 83337, "created_utc": 1671476288.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello.\n\nAre there any resources or documentation on how to run a jar on Glue instead of a Scala script?\n\nWe currently submit jobs to EMR which run jars that do a lot of heavy lifting. The Glue documentation is largely about running Python or Scala scripts.\n\nThanks.", "author_fullname": "t2_flx2tw2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resources on running a JAR (Scala, Spark) on AWS Glue instead of script", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zpwh5o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671468091.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello.&lt;/p&gt;\n\n&lt;p&gt;Are there any resources or documentation on how to run a jar on Glue instead of a Scala script?&lt;/p&gt;\n\n&lt;p&gt;We currently submit jobs to EMR which run jars that do a lot of heavy lifting. The Glue documentation is largely about running Python or Scala scripts.&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zpwh5o", "is_robot_indexable": true, "report_reasons": null, "author": "thegoodhunter-9115", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zpwh5o/resources_on_running_a_jar_scala_spark_on_aws/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zpwh5o/resources_on_running_a_jar_scala_spark_on_aws/", "subreddit_subscribers": 83337, "created_utc": 1671468091.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Ignoring things like user requested deletes, how long do you generally retain data? Is your retention policy based on regulation, costs, or something else?\n\n[View Poll](https://www.reddit.com/poll/zpsxzd)", "author_fullname": "t2_txvugrht", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How long do you retain data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zpsxzd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671459848.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Ignoring things like user requested deletes, how long do you generally retain data? Is your retention policy based on regulation, costs, or something else?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/zpsxzd\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineering Company", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zpsxzd", "is_robot_indexable": true, "report_reasons": null, "author": "prequel_co", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1671719048206, "options": [{"text": "See Results", "id": "20487440"}, {"text": "6 months or less", "id": "20487441"}, {"text": "1 year or less", "id": "20487442"}, {"text": "5 years or less", "id": "20487443"}, {"text": "10 years or less", "id": "20487444"}, {"text": "Forever", "id": "20487445"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 182, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/zpsxzd/how_long_do_you_retain_data/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/zpsxzd/how_long_do_you_retain_data/", "subreddit_subscribers": 83337, "created_utc": 1671459848.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_b7f9ay9o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Connect Azure Data Factory with Log Analytics and setup alerts", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_zpm2cg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/qPpm3X4wgEI?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"How to Connect Azure Data Factory with Log Analytics and setup alerts\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "How to Connect Azure Data Factory with Log Analytics and setup alerts", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/qPpm3X4wgEI?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"How to Connect Azure Data Factory with Log Analytics and setup alerts\"&gt;&lt;/iframe&gt;", "author_name": "SoftWiz Circle", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/qPpm3X4wgEI/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@SoftWizCircle"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/qPpm3X4wgEI?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"How to Connect Azure Data Factory with Log Analytics and setup alerts\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/zpm2cg", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/rVsoThz0n5GnDUOZ4dvWK49g7cGV6T83VjBFiy9x07g.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671438351.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/qPpm3X4wgEI", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/WmyvkaN1lteM_a8OQHp7l-SmH5wd4ogWUsuCYF0jscg.jpg?auto=webp&amp;s=e111cda8d6a6619a63034e924f708a370635b235", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/WmyvkaN1lteM_a8OQHp7l-SmH5wd4ogWUsuCYF0jscg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=46452634f9c6ab2f7ff22f7e64984066e98fdf75", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/WmyvkaN1lteM_a8OQHp7l-SmH5wd4ogWUsuCYF0jscg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fd0fd237285360e9b7dc286211cbd51d6a411997", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/WmyvkaN1lteM_a8OQHp7l-SmH5wd4ogWUsuCYF0jscg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a87c88824a7b927212ee6860320006bc7040b87b", "width": 320, "height": 240}], "variants": {}, "id": "4sJFtCLHhq3C30uR7K71Zi5od-aUERVZFGlHW_30Ar0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zpm2cg", "is_robot_indexable": true, "report_reasons": null, "author": "balramprasad", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zpm2cg/how_to_connect_azure_data_factory_with_log/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/qPpm3X4wgEI", "subreddit_subscribers": 83337, "created_utc": 1671438351.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "How to Connect Azure Data Factory with Log Analytics and setup alerts", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/qPpm3X4wgEI?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"How to Connect Azure Data Factory with Log Analytics and setup alerts\"&gt;&lt;/iframe&gt;", "author_name": "SoftWiz Circle", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/qPpm3X4wgEI/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@SoftWizCircle"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I am trying to figure it out, but am feeling a little lost. Is there any good documentation or videos where I can learn about it?\n\n\"LMDB is written in C with API Bindings for several programming languages.\"\n\nWhere can I get a list of these languages? Is it available for Go or JavaScript? Or is it a library for query languages like SQL?\n\nI am working on a personal project that is scraping large amounts of data using JavaScript. A friend recommended LMDB. Where do I start?", "author_fullname": "t2_7y9rju54", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is Lightning Memory Mapped Database (LMDB)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zq13us", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671478295.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to figure it out, but am feeling a little lost. Is there any good documentation or videos where I can learn about it?&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;LMDB is written in C with API Bindings for several programming languages.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Where can I get a list of these languages? Is it available for Go or JavaScript? Or is it a library for query languages like SQL?&lt;/p&gt;\n\n&lt;p&gt;I am working on a personal project that is scraping large amounts of data using JavaScript. A friend recommended LMDB. Where do I start?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zq13us", "is_robot_indexable": true, "report_reasons": null, "author": "emosk8rboi4206969", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zq13us/what_is_lightning_memory_mapped_database_lmdb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zq13us/what_is_lightning_memory_mapped_database_lmdb/", "subreddit_subscribers": 83337, "created_utc": 1671478295.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_ggio6wps", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The top 6 lessons learned why companies struggle with cloud data efficiency", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_zpx6oh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/XIPIVVcri4sBrRdLu6AtblfRs3N5GZiM-s9dOV1zeFY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671469622.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/sync-computing/the-top-6-reasons-why-companies-struggle-with-improving-cloud-data-infrastructure-37a79d40805a", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yu1qol6u--XPiGQbbaKC0eRZfpBQeCCkyfdo9suLY5I.jpg?auto=webp&amp;s=55dc0af37157e0206d4b66ce444d7397c3964b1c", "width": 1200, "height": 627}, "resolutions": [{"url": "https://external-preview.redd.it/yu1qol6u--XPiGQbbaKC0eRZfpBQeCCkyfdo9suLY5I.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ac7596dd85de5ee80a23ac28ee63f7fae520d6e7", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/yu1qol6u--XPiGQbbaKC0eRZfpBQeCCkyfdo9suLY5I.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=743bfd4636ef2313769a5ec644fea848f5d847b4", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/yu1qol6u--XPiGQbbaKC0eRZfpBQeCCkyfdo9suLY5I.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a657095e4bbd8d68144d8adac45d015d3a6d92c7", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/yu1qol6u--XPiGQbbaKC0eRZfpBQeCCkyfdo9suLY5I.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=75e94f6f9411e25bb00aa6e6535c539481f08e8c", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/yu1qol6u--XPiGQbbaKC0eRZfpBQeCCkyfdo9suLY5I.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d4e4f333dcdecae2880b2054c8aafcf3f0472428", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/yu1qol6u--XPiGQbbaKC0eRZfpBQeCCkyfdo9suLY5I.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=972450929ccd4c4e6dd92cac1669686032977172", "width": 1080, "height": 564}], "variants": {}, "id": "q16jmHo04kNL7wRSdPn1Sy-rtOR_CQq32oQnJKcO_9E"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zpx6oh", "is_robot_indexable": true, "report_reasons": null, "author": "gobstopper_chicken", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zpx6oh/the_top_6_lessons_learned_why_companies_struggle/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/sync-computing/the-top-6-reasons-why-companies-struggle-with-improving-cloud-data-infrastructure-37a79d40805a", "subreddit_subscribers": 83337, "created_utc": 1671469622.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We used text to SQL to build a \"Webflow for Web3 Dashboards\". We discovered loads of problems in the entire blockchain data space outlined in the thread.\n\nDemo: Design your dashboard, type your query in English.\n\nWe're open-sourcing everything.\n\n[https://twitter.com/vatsal\\_aggarwal/status/1604995355468173312?s=20&amp;t=DJ-zmyaV7g5jgbUGpsssmQ](https://twitter.com/vatsal_aggarwal/status/1604995355468173312?s=20&amp;t=DJ-zmyaV7g5jgbUGpsssmQ)", "author_fullname": "t2_ea8d3w57", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Open-sourcing text-to-SQL for blockchain data!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zq9hyk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1671498014.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We used text to SQL to build a &amp;quot;Webflow for Web3 Dashboards&amp;quot;. We discovered loads of problems in the entire blockchain data space outlined in the thread.&lt;/p&gt;\n\n&lt;p&gt;Demo: Design your dashboard, type your query in English.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re open-sourcing everything.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://twitter.com/vatsal_aggarwal/status/1604995355468173312?s=20&amp;amp;t=DJ-zmyaV7g5jgbUGpsssmQ\"&gt;https://twitter.com/vatsal_aggarwal/status/1604995355468173312?s=20&amp;amp;t=DJ-zmyaV7g5jgbUGpsssmQ&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/soVXxY3in1C5Xb1xu9X0epwwcbmX2yQZDLHcDwYl0Go.jpg?auto=webp&amp;s=28b738ba55e892a6dd8d8dffd2e23f97ed59837f", "width": 140, "height": 90}, "resolutions": [{"url": "https://external-preview.redd.it/soVXxY3in1C5Xb1xu9X0epwwcbmX2yQZDLHcDwYl0Go.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=aba91d8de11ec54f0a9f913c4274c369a2263b16", "width": 108, "height": 69}], "variants": {}, "id": "atjhhl11daWVVuu8SYGQEqyjtZXvbh4CM2nQ97YctLI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zq9hyk", "is_robot_indexable": true, "report_reasons": null, "author": "Apprehensive-Tax-214", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zq9hyk/opensourcing_texttosql_for_blockchain_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zq9hyk/opensourcing_texttosql_for_blockchain_data/", "subreddit_subscribers": 83337, "created_utc": 1671498014.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://medium.com/p/911486a644ff](https://medium.com/p/911486a644ff)", "author_fullname": "t2_bqjrmnud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Design Considerations for Cloud-Native Data Systems", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zpvupr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1671466649.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://medium.com/p/911486a644ff\"&gt;https://medium.com/p/911486a644ff&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/j7g6I3muaSOABsUTW-37-2v0SFppYeRaloELfGJtLvs.jpg?auto=webp&amp;s=7f831751953c8b17f416893730d373d86b357a32", "width": 1200, "height": 1024}, "resolutions": [{"url": "https://external-preview.redd.it/j7g6I3muaSOABsUTW-37-2v0SFppYeRaloELfGJtLvs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cbfd0b61baed8fc22ac09a215e47382b95bd669b", "width": 108, "height": 92}, {"url": "https://external-preview.redd.it/j7g6I3muaSOABsUTW-37-2v0SFppYeRaloELfGJtLvs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=256dfb3c6347c6cf47b7ac3defd6f9909646cafd", "width": 216, "height": 184}, {"url": "https://external-preview.redd.it/j7g6I3muaSOABsUTW-37-2v0SFppYeRaloELfGJtLvs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bc2041db176a00e67e146d818a25549e2fd278c2", "width": 320, "height": 273}, {"url": "https://external-preview.redd.it/j7g6I3muaSOABsUTW-37-2v0SFppYeRaloELfGJtLvs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e60fd39edc994837279628f0f5ee4f17ccbae495", "width": 640, "height": 546}, {"url": "https://external-preview.redd.it/j7g6I3muaSOABsUTW-37-2v0SFppYeRaloELfGJtLvs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d15a44610406d097c40160fd295e48792d8ed8ba", "width": 960, "height": 819}, {"url": "https://external-preview.redd.it/j7g6I3muaSOABsUTW-37-2v0SFppYeRaloELfGJtLvs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c44da0444db4c60e54769923bab860a1c8fdd99e", "width": 1080, "height": 921}], "variants": {}, "id": "7DNa-AVFwD2dfKYbcXqtc12ncZBzpZB_ciPUgvaQAAM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zpvupr", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering_Bug105", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zpvupr/design_considerations_for_cloudnative_data_systems/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zpvupr/design_considerations_for_cloudnative_data_systems/", "subreddit_subscribers": 83337, "created_utc": 1671466649.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys, I recently starter as  a data engineer and already struggling with the job. not the technical part but mostly business logic. We are developing a solution for D365 tool where we ingest the data and process it throughout the bronze silver and gold layers. Most difficult part is creating dimension tables as I have no clue what they should include, which columns and so on. I could not find a proper source where I could see all the dimensions tables per module (finance, sales, production etc) as template to use for my project. any tips? sources?", "author_fullname": "t2_56g5f4cg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dimensions and fact tables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zprh9o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671456219.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I recently starter as  a data engineer and already struggling with the job. not the technical part but mostly business logic. We are developing a solution for D365 tool where we ingest the data and process it throughout the bronze silver and gold layers. Most difficult part is creating dimension tables as I have no clue what they should include, which columns and so on. I could not find a proper source where I could see all the dimensions tables per module (finance, sales, production etc) as template to use for my project. any tips? sources?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zprh9o", "is_robot_indexable": true, "report_reasons": null, "author": "9gg6", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zprh9o/dimensions_and_fact_tables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zprh9o/dimensions_and_fact_tables/", "subreddit_subscribers": 83337, "created_utc": 1671456219.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it always best to use latest Databricks runtime version? Is there a reason beside dependency versions and conflicts to make decision on that?", "author_fullname": "t2_sx1wry60", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks runtime version", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zpnhb7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671443805.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it always best to use latest Databricks runtime version? Is there a reason beside dependency versions and conflicts to make decision on that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zpnhb7", "is_robot_indexable": true, "report_reasons": null, "author": "AcceptableProcess772", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zpnhb7/databricks_runtime_version/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zpnhb7/databricks_runtime_version/", "subreddit_subscribers": 83337, "created_utc": 1671443805.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I got allocated to a new group within the company and my task is to test / run manually:\n\n1. Open Remote Desktop Connection\n2. Connect to Postgres (=Source)\n3. Manually run SQL to get information schema\n4. Take Screenshot\n5. Open Databricks (=Target)\n6. Manually run SQL to get information schema\n7. Take screenshot\n8. Compare Source with Target\n9. Upload Screenshots to qTest Test Case\n10. Mark as passed\n11. GoTo next task, repeat steps 1-10\n\nAm I the only one who thinks that this is an extreme waste of time and resources; and even more error-prone?\n\nHow do you handle tests like these? Shouldn't this be run by scripts?\n\nAnd, when done manually, what about changes in the source? Would mean to manually re-do everything? This can't be true.\n\nAs far as I understand this, there should be scripts run in the background, not only once, but continually?\n\nBackgroung: Really big pharma company. Data Engineering / Data Architecture got outsourced to really big consulting company. Majority of workers sits in India. And maybe that's why nobody questions this manual approach? No offense by any means but as manager I would hold back my employees as they are simly too expensive for such tasks. (Background 2: I'm sitting in Central Europe)", "author_fullname": "t2_4fb1g9yu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "qTest - Compare Source Table with Target Table", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zpl4dg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1671435578.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671434863.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I got allocated to a new group within the company and my task is to test / run manually:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Open Remote Desktop Connection&lt;/li&gt;\n&lt;li&gt;Connect to Postgres (=Source)&lt;/li&gt;\n&lt;li&gt;Manually run SQL to get information schema&lt;/li&gt;\n&lt;li&gt;Take Screenshot&lt;/li&gt;\n&lt;li&gt;Open Databricks (=Target)&lt;/li&gt;\n&lt;li&gt;Manually run SQL to get information schema&lt;/li&gt;\n&lt;li&gt;Take screenshot&lt;/li&gt;\n&lt;li&gt;Compare Source with Target&lt;/li&gt;\n&lt;li&gt;Upload Screenshots to qTest Test Case&lt;/li&gt;\n&lt;li&gt;Mark as passed&lt;/li&gt;\n&lt;li&gt;GoTo next task, repeat steps 1-10&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Am I the only one who thinks that this is an extreme waste of time and resources; and even more error-prone?&lt;/p&gt;\n\n&lt;p&gt;How do you handle tests like these? Shouldn&amp;#39;t this be run by scripts?&lt;/p&gt;\n\n&lt;p&gt;And, when done manually, what about changes in the source? Would mean to manually re-do everything? This can&amp;#39;t be true.&lt;/p&gt;\n\n&lt;p&gt;As far as I understand this, there should be scripts run in the background, not only once, but continually?&lt;/p&gt;\n\n&lt;p&gt;Backgroung: Really big pharma company. Data Engineering / Data Architecture got outsourced to really big consulting company. Majority of workers sits in India. And maybe that&amp;#39;s why nobody questions this manual approach? No offense by any means but as manager I would hold back my employees as they are simly too expensive for such tasks. (Background 2: I&amp;#39;m sitting in Central Europe)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zpl4dg", "is_robot_indexable": true, "report_reasons": null, "author": "cptstoneee", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zpl4dg/qtest_compare_source_table_with_target_table/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zpl4dg/qtest_compare_source_table_with_target_table/", "subreddit_subscribers": 83337, "created_utc": 1671434863.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are some common pitfalls or mistakes that beginners in data engineering might encounter, and how can they be avoided?", "author_fullname": "t2_3p620rl9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Common Pitfalls For Beginners", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zpfidd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.56, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671417138.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are some common pitfalls or mistakes that beginners in data engineering might encounter, and how can they be avoided?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "DE @ Amazon/Lyft/Author of Ace DE Interview", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zpfidd", "is_robot_indexable": true, "report_reasons": null, "author": "chrisgarzon19", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/zpfidd/common_pitfalls_for_beginners/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zpfidd/common_pitfalls_for_beginners/", "subreddit_subscribers": 83337, "created_utc": 1671417138.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Last week I had my first session in taking the Azure for data engineers webinar.  During the session I covered various tasks:  \n\\- Introduction and data manipulation using PySpark.\n\n\\-  Introduction to Databricks (UI, Cluster &amp; Dataset).\n\n\\- Mounting Azure Storage in Databricks (Blob Storage &amp; Data Lake).\n\n\\- Activating Transform Activity from Azure Data Factory.\n\n\\- Connect Transformed Data to Microsoft Power BI.  \n\ud83c\udfa5 YouTube Link: https://youtu.be/zTwevLbRfpE \n\n\u2022GitHub Repo: https://github.com/kiddojazz/Data-Transformation-using-Azure-Databricks", "author_fullname": "t2_6fwa4j9d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Transformation using Azure Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zq5jlb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1671488582.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Last week I had my first session in taking the Azure for data engineers webinar.  During the session I covered various tasks:&lt;br/&gt;\n- Introduction and data manipulation using PySpark.&lt;/p&gt;\n\n&lt;p&gt;-  Introduction to Databricks (UI, Cluster &amp;amp; Dataset).&lt;/p&gt;\n\n&lt;p&gt;- Mounting Azure Storage in Databricks (Blob Storage &amp;amp; Data Lake).&lt;/p&gt;\n\n&lt;p&gt;- Activating Transform Activity from Azure Data Factory.&lt;/p&gt;\n\n&lt;p&gt;- Connect Transformed Data to Microsoft Power BI.&lt;br/&gt;\n\ud83c\udfa5 YouTube Link: &lt;a href=\"https://youtu.be/zTwevLbRfpE\"&gt;https://youtu.be/zTwevLbRfpE&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;\u2022GitHub Repo: &lt;a href=\"https://github.com/kiddojazz/Data-Transformation-using-Azure-Databricks\"&gt;https://github.com/kiddojazz/Data-Transformation-using-Azure-Databricks&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/60hu9Woxfra3pwTH9A7GtZrX2h3bjHAnExttROIR5VM.jpg?auto=webp&amp;s=69ee3f3c553f2fd0fe85a7dd6721908154ec3c71", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/60hu9Woxfra3pwTH9A7GtZrX2h3bjHAnExttROIR5VM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d28e721f2a4a8eade8e982ec2cb7efdc155e920e", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/60hu9Woxfra3pwTH9A7GtZrX2h3bjHAnExttROIR5VM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=192c1cd4113196c542b8727f428c05b9768ba5b1", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/60hu9Woxfra3pwTH9A7GtZrX2h3bjHAnExttROIR5VM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a9963513139eb524d670a5a9f08e53d312a3e502", "width": 320, "height": 240}], "variants": {}, "id": "XP66OiJjgYCGmtcsqMtj_zrpniIltUg-88PfnRaP8mA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zq5jlb", "is_robot_indexable": true, "report_reasons": null, "author": "kiddojazz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zq5jlb/data_transformation_using_azure_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zq5jlb/data_transformation_using_azure_databricks/", "subreddit_subscribers": 83337, "created_utc": 1671488582.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What would be the job or tasks to take on if I wanted to begin my journey toward a data engineering role?\n\nI am a software automation engineer with basic python knowledge.", "author_fullname": "t2_ufwrsaef", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best job to begin", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zpf74t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1671416573.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671416256.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What would be the job or tasks to take on if I wanted to begin my journey toward a data engineering role?&lt;/p&gt;\n\n&lt;p&gt;I am a software automation engineer with basic python knowledge.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zpf74t", "is_robot_indexable": true, "report_reasons": null, "author": "YouTubeAnon", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zpf74t/best_job_to_begin/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zpf74t/best_job_to_begin/", "subreddit_subscribers": 83337, "created_utc": 1671416256.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}