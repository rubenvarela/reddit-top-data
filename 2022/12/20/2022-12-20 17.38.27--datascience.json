{"kind": "Listing", "data": {"after": "t3_zqfuzi", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_oxgj60x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why business data science irritates me", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_zq30tn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 234, "domain": "shakoist.substack.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 234, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/AXe9r7il4LBu36QlAizp5N8-d1-6dhVq2_yRoDsxKOc.jpg", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671482748.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 1, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://shakoist.substack.com/p/why-business-data-science-irritates?utm_source=twitter&amp;sd=pf", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/GkOmXq5e_3MS_cWaAQ7RWi0eLrP118sKvkUfKy-XSFU.jpg?auto=webp&amp;s=f56ca257ce707b018be2510c20de4906e4417958", "width": 1066, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/GkOmXq5e_3MS_cWaAQ7RWi0eLrP118sKvkUfKy-XSFU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4367004bca7ed1c2bc42667dd6871ceb60797929", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/GkOmXq5e_3MS_cWaAQ7RWi0eLrP118sKvkUfKy-XSFU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=818e3eebc2e8c7b511d195a9c150f4040178a9c0", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/GkOmXq5e_3MS_cWaAQ7RWi0eLrP118sKvkUfKy-XSFU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b9db3ee316c83cd00c84899870b344b7cb131120", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/GkOmXq5e_3MS_cWaAQ7RWi0eLrP118sKvkUfKy-XSFU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=17e80500e6b8248056239ec840fb54559203b1db", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/GkOmXq5e_3MS_cWaAQ7RWi0eLrP118sKvkUfKy-XSFU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=25ca766a3b513bccffaaea46abd7e866e51dcdf3", "width": 960, "height": 540}], "variants": {}, "id": "Gd29rlJxSoGdKrc45YavqlPTDWd364kSymEjm_TyAa8"}], "enabled": false}, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 150, "id": "award_f44611f1-b89e-46dc-97fe-892280b13b82", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Thank you stranger. Shows the award.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Helpful", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "zq30tn", "is_robot_indexable": true, "report_reasons": null, "author": "jerrylessthanthree", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zq30tn/why_business_data_science_irritates_me/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://shakoist.substack.com/p/why-business-data-science-irritates?utm_source=twitter&amp;sd=pf", "subreddit_subscribers": 828704, "created_utc": 1671482748.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My boss is providing funds to further my education for my Inventory Analyst role. I currently use Power BI and Power Automate at a slightly higher than entry level. Can anyone recommend courses that would help me progress in this type of role? Thank you in advance.", "author_fullname": "t2_7w35o79", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Analyst Courses", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zqamfk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671500784.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My boss is providing funds to further my education for my Inventory Analyst role. I currently use Power BI and Power Automate at a slightly higher than entry level. Can anyone recommend courses that would help me progress in this type of role? Thank you in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zqamfk", "is_robot_indexable": true, "report_reasons": null, "author": "babulthegreat", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zqamfk/data_analyst_courses/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zqamfk/data_analyst_courses/", "subreddit_subscribers": 828704, "created_utc": 1671500784.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For some more background, my company has a few data science teams rolling up to separate business units - some more hardcore science, others more business-oriented (where I sit). Our data engineer will be a liaison between the other teams, but mostly serving my needs for reliable, well-structured data and model deployments.", "author_fullname": "t2_jhyrhtus", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm a data scientist on an island in my organization, and we're finally adding a data engineer to the team. As someone who hasn't worked with one before, what kinds of things should I study to best partner with them?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zqqdtl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671547714.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For some more background, my company has a few data science teams rolling up to separate business units - some more hardcore science, others more business-oriented (where I sit). Our data engineer will be a liaison between the other teams, but mostly serving my needs for reliable, well-structured data and model deployments.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zqqdtl", "is_robot_indexable": true, "report_reasons": null, "author": "bubbastars", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zqqdtl/im_a_data_scientist_on_an_island_in_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zqqdtl/im_a_data_scientist_on_an_island_in_my/", "subreddit_subscribers": 828704, "created_utc": 1671547714.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a dilemma at work.  We have this simple algorithm that provides good/bad for a given issue.  The task we have is to find an algo that can outperform this.\n\nNow I walk into a discussion and see that people are using the good/bad labels for the current algo as the ground truth to compare many other algos from pyOD.    I see a bunch of ROC curves for all of these models.  And talk about one model is better than another...\n\nNow I ask what is the performance of the current running algorithm?  And how do we compare to that?    I get pushback on how it isn't possible to quantify that and that ground truth is subjective....   However I am saying how can any new model outperform the existing one if the existing one is perfect, they say it isnt perfect but just use it for labeling...\n\nIt is hard to convince them that we need to get manual labels to quantify the current model, then we can see if anything useful can be detected beyond that.  I feel like nobody understands the issue and I would like to convince them that their approach doesn't make sense. Or am I missing something?  Is it not valid to use one algo as ground truth to compare algos?\n\nSeems suspicious...  There is no example that can show any new algo detecting something new, because old algo is the truth...", "author_fullname": "t2_3qgvuco6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to compare current algorithm to others ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zqpat0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1671547055.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671544870.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a dilemma at work.  We have this simple algorithm that provides good/bad for a given issue.  The task we have is to find an algo that can outperform this.&lt;/p&gt;\n\n&lt;p&gt;Now I walk into a discussion and see that people are using the good/bad labels for the current algo as the ground truth to compare many other algos from pyOD.    I see a bunch of ROC curves for all of these models.  And talk about one model is better than another...&lt;/p&gt;\n\n&lt;p&gt;Now I ask what is the performance of the current running algorithm?  And how do we compare to that?    I get pushback on how it isn&amp;#39;t possible to quantify that and that ground truth is subjective....   However I am saying how can any new model outperform the existing one if the existing one is perfect, they say it isnt perfect but just use it for labeling...&lt;/p&gt;\n\n&lt;p&gt;It is hard to convince them that we need to get manual labels to quantify the current model, then we can see if anything useful can be detected beyond that.  I feel like nobody understands the issue and I would like to convince them that their approach doesn&amp;#39;t make sense. Or am I missing something?  Is it not valid to use one algo as ground truth to compare algos?&lt;/p&gt;\n\n&lt;p&gt;Seems suspicious...  There is no example that can show any new algo detecting something new, because old algo is the truth...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zqpat0", "is_robot_indexable": true, "report_reasons": null, "author": "Atxaquariguy", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zqpat0/how_to_compare_current_algorithm_to_others/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zqpat0/how_to_compare_current_algorithm_to_others/", "subreddit_subscribers": 828704, "created_utc": 1671544870.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi.\nI am a college student pursuing a degree in maths and also interested in data science.. I have statistics subject in this semester..\n\nI want to buy a statistics book for my college [syllabus](https://imgur.com/a/1GgfCWC) as well as data science. Is there any book that'll be really helpful in the long run for me as a data scientist?\nWhat is the perfect statistics book that data scientists recommend?\n\nA book with a mix of theoretical as well as practical knowledge would be really good.\n\nI am really confused please help..", "author_fullname": "t2_56io9ome", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "recommendations for a good statistics book?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zqomp1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1671543334.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1671543148.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi.\nI am a college student pursuing a degree in maths and also interested in data science.. I have statistics subject in this semester..&lt;/p&gt;\n\n&lt;p&gt;I want to buy a statistics book for my college &lt;a href=\"https://imgur.com/a/1GgfCWC\"&gt;syllabus&lt;/a&gt; as well as data science. Is there any book that&amp;#39;ll be really helpful in the long run for me as a data scientist?\nWhat is the perfect statistics book that data scientists recommend?&lt;/p&gt;\n\n&lt;p&gt;A book with a mix of theoretical as well as practical knowledge would be really good.&lt;/p&gt;\n\n&lt;p&gt;I am really confused please help..&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yQyZZANkz-lBTes2sWvbTCOs0RhS9cGSpozce6kX9Jw.jpg?auto=webp&amp;s=21d45d2b52f167d725cb52b8024c3b855a0aa38e", "width": 1080, "height": 371}, "resolutions": [{"url": "https://external-preview.redd.it/yQyZZANkz-lBTes2sWvbTCOs0RhS9cGSpozce6kX9Jw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e31ef2228fb7d7dafb7829556bf449c9e511e3ce", "width": 108, "height": 37}, {"url": "https://external-preview.redd.it/yQyZZANkz-lBTes2sWvbTCOs0RhS9cGSpozce6kX9Jw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=878eb23c750860d059c6e43c5347b3944390ba8f", "width": 216, "height": 74}, {"url": "https://external-preview.redd.it/yQyZZANkz-lBTes2sWvbTCOs0RhS9cGSpozce6kX9Jw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=306c9c2f4e241956f1c60847a2287655435e495d", "width": 320, "height": 109}, {"url": "https://external-preview.redd.it/yQyZZANkz-lBTes2sWvbTCOs0RhS9cGSpozce6kX9Jw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=de1c456cd4b4413ae0b2b235fba07dbc18fa10be", "width": 640, "height": 219}, {"url": "https://external-preview.redd.it/yQyZZANkz-lBTes2sWvbTCOs0RhS9cGSpozce6kX9Jw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b81207ae5e3656c56310eada9652e0f31b1b3866", "width": 960, "height": 329}, {"url": "https://external-preview.redd.it/yQyZZANkz-lBTes2sWvbTCOs0RhS9cGSpozce6kX9Jw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=320c970e8a224d8eb50de346f88f0788b191ffe7", "width": 1080, "height": 371}], "variants": {}, "id": "e1-vzS9T0NNVWZ34_CK2hZX2ibYXUI2HE6xT6MktCR8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zqomp1", "is_robot_indexable": true, "report_reasons": null, "author": "iam_smaindola", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zqomp1/recommendations_for_a_good_statistics_book/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zqomp1/recommendations_for_a_good_statistics_book/", "subreddit_subscribers": 828704, "created_utc": 1671543148.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello Dear reditors, \nSome posts exist about this topic, but are at minimum 2years old, and our job evolves fast... \n\nI approach 3 years of experience, and in the market I am in (France) it might be a time where you'll be promoted from junior to senior. From what I've seen in the market so far, the title are \"data scientist\", \"senior datascientist\", \"lead datascientist\", with respectively 0y of experience, 3-5y of experience, 5-8 y\n\nAnyway, according to you, what distinguishes a junior from a senior (or vice versa?)\n\nSecond question : is it common that decisions are taken solely based on a junior, or is it more a thing for senior/lead? I am basically the only DS in my company. For modeling, A/B testing, statistical analysis, I do everything from interviewing the \"clients\", I design the solution, model it, help our DE putting it in production,present it back to C levels. The only lead DS I've encountered in the company is a consultant and works alone on a specific project (and only that one) . I've had 2hours maximum with him in 8months. \n\nThank you in advance for your help!", "author_fullname": "t2_bl8dhx5v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DS position ladder : junior, mid, lead...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zqhaoc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671519339.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Dear reditors, \nSome posts exist about this topic, but are at minimum 2years old, and our job evolves fast... &lt;/p&gt;\n\n&lt;p&gt;I approach 3 years of experience, and in the market I am in (France) it might be a time where you&amp;#39;ll be promoted from junior to senior. From what I&amp;#39;ve seen in the market so far, the title are &amp;quot;data scientist&amp;quot;, &amp;quot;senior datascientist&amp;quot;, &amp;quot;lead datascientist&amp;quot;, with respectively 0y of experience, 3-5y of experience, 5-8 y&lt;/p&gt;\n\n&lt;p&gt;Anyway, according to you, what distinguishes a junior from a senior (or vice versa?)&lt;/p&gt;\n\n&lt;p&gt;Second question : is it common that decisions are taken solely based on a junior, or is it more a thing for senior/lead? I am basically the only DS in my company. For modeling, A/B testing, statistical analysis, I do everything from interviewing the &amp;quot;clients&amp;quot;, I design the solution, model it, help our DE putting it in production,present it back to C levels. The only lead DS I&amp;#39;ve encountered in the company is a consultant and works alone on a specific project (and only that one) . I&amp;#39;ve had 2hours maximum with him in 8months. &lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zqhaoc", "is_robot_indexable": true, "report_reasons": null, "author": "Zealousideal-Yak5547", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zqhaoc/ds_position_ladder_junior_mid_lead/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zqhaoc/ds_position_ladder_junior_mid_lead/", "subreddit_subscribers": 828704, "created_utc": 1671519339.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey people, I'd like to share with you guys the project that I've been working on. It is an automated tool for data scientists, data science students, and data analysts, and generates visualizations on-flight.\n\nOur GitHub: [https://github.com/Kanaries/Rath](https://github.com/Kanaries/Rath)\n\nSo what is RATH, anyway? It is an open-sourced Tableau, to summarize it a little bit. You do not need sound programming experience to get on hand with it. Fun fact: You can embed this Tableau-like module into your own apps with ease! Check it out here: [https://github.com/Kanaries/graphic-walker](https://github.com/Kanaries/graphic-walker)\n\nRATH is more than just Tableau. It is designed as a \"copilot\" for data scientists. For most of the people working in this field, you probably already have an established workflow that you do not want to disturb. Good. That's also what we thought. What RATH can do is, RATH automatically generates visualizations and recommendations, which could help, or guide you to explore your data and boost your efficiency. It is like a helper sitting next to you, helping you go through your datasets and giving you ideas in real-time, without disturbing your workflow.\n\nWe are also working on many other creative features! One of the features is called: Data Painter, which allows you to explore your database in an interface similar to Microsoft Painter. You can select, edit, clean, and explore your data using the paint tool and eraser tool. We have a video here to demonstrate these features more visually: [https://www.youtube.com/watch?v=djqePNyhz7w](https://www.youtube.com/watch?v=djqePNyhz7w)\n\nIf you find our project interesting or have any other thoughts or suggestions, don't be hesitated to ask! Cheers :)", "author_fullname": "t2_usk7jj3j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "RATH: An Open-sourced Exploratory Data Analysis &amp; Visualization tool for data analysts", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zqobjc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1671542398.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey people, I&amp;#39;d like to share with you guys the project that I&amp;#39;ve been working on. It is an automated tool for data scientists, data science students, and data analysts, and generates visualizations on-flight.&lt;/p&gt;\n\n&lt;p&gt;Our GitHub: &lt;a href=\"https://github.com/Kanaries/Rath\"&gt;https://github.com/Kanaries/Rath&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;So what is RATH, anyway? It is an open-sourced Tableau, to summarize it a little bit. You do not need sound programming experience to get on hand with it. Fun fact: You can embed this Tableau-like module into your own apps with ease! Check it out here: &lt;a href=\"https://github.com/Kanaries/graphic-walker\"&gt;https://github.com/Kanaries/graphic-walker&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;RATH is more than just Tableau. It is designed as a &amp;quot;copilot&amp;quot; for data scientists. For most of the people working in this field, you probably already have an established workflow that you do not want to disturb. Good. That&amp;#39;s also what we thought. What RATH can do is, RATH automatically generates visualizations and recommendations, which could help, or guide you to explore your data and boost your efficiency. It is like a helper sitting next to you, helping you go through your datasets and giving you ideas in real-time, without disturbing your workflow.&lt;/p&gt;\n\n&lt;p&gt;We are also working on many other creative features! One of the features is called: Data Painter, which allows you to explore your database in an interface similar to Microsoft Painter. You can select, edit, clean, and explore your data using the paint tool and eraser tool. We have a video here to demonstrate these features more visually: &lt;a href=\"https://www.youtube.com/watch?v=djqePNyhz7w\"&gt;https://www.youtube.com/watch?v=djqePNyhz7w&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If you find our project interesting or have any other thoughts or suggestions, don&amp;#39;t be hesitated to ask! Cheers :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/W_YuANmSKPj-s9mhkHM7BlCwj3UureWR7Mc668aANi4.jpg?auto=webp&amp;s=9e8637973a0c258b035d8805161436b3a4fb052e", "width": 600, "height": 200}, "resolutions": [{"url": "https://external-preview.redd.it/W_YuANmSKPj-s9mhkHM7BlCwj3UureWR7Mc668aANi4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f0dab5884e0ec6f4f0d7e8afbd3fc931c4c3f3c0", "width": 108, "height": 36}, {"url": "https://external-preview.redd.it/W_YuANmSKPj-s9mhkHM7BlCwj3UureWR7Mc668aANi4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=306bc398f77b299f8a0dfc0b08f4c30da96794d0", "width": 216, "height": 72}, {"url": "https://external-preview.redd.it/W_YuANmSKPj-s9mhkHM7BlCwj3UureWR7Mc668aANi4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2ecac9e317ba1c30f97f90b05498aec6a27692b3", "width": 320, "height": 106}], "variants": {}, "id": "3lk4sCS5GdZw7pk7pTnSukFy1gn1XJzhya5VP6ca8Zw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zqobjc", "is_robot_indexable": true, "report_reasons": null, "author": "Repulsive-Round-4366", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zqobjc/rath_an_opensourced_exploratory_data_analysis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zqobjc/rath_an_opensourced_exploratory_data_analysis/", "subreddit_subscribers": 828704, "created_utc": 1671542398.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm a Product Analyst, and my product manager wants to improve the metric Time to Value (TTV) (how long it takes for a user to start a process and finish it). Our goal is to lower the TTV for our users.\n\nWe are seeing TTV ranges from 2 minutes to 15+ days, and this is not unexpected. It's long tail data, heavily clustered in the 10-20 minutes zone, and then slowly tapering off.  \n\n\nThe mean or median alone doesn't really tell us anything, because the data is so long tailed.\n\nWhat metric can I use that will show if we are improving? I thought the mode and the interquartile range could work. A decrease in the mode would show that we are decreasing the hump of the tail, and a decrease in the IQR would show that the spread is also decreasing. (I chose the mode because it is typically the smallest value in a left tail distribution; all of the numbers are long decimals, so I'll probably need to round them.)  \n\n\nAnyone have better ideas? Google tells me a common choice with skewed data is to transform it logarithmically, but I don't know what to do with that transformed data set- just measure the mean?", "author_fullname": "t2_13b1f3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Way to Measure Improvements in Data Dispersion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zqth6h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671555527.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a Product Analyst, and my product manager wants to improve the metric Time to Value (TTV) (how long it takes for a user to start a process and finish it). Our goal is to lower the TTV for our users.&lt;/p&gt;\n\n&lt;p&gt;We are seeing TTV ranges from 2 minutes to 15+ days, and this is not unexpected. It&amp;#39;s long tail data, heavily clustered in the 10-20 minutes zone, and then slowly tapering off.  &lt;/p&gt;\n\n&lt;p&gt;The mean or median alone doesn&amp;#39;t really tell us anything, because the data is so long tailed.&lt;/p&gt;\n\n&lt;p&gt;What metric can I use that will show if we are improving? I thought the mode and the interquartile range could work. A decrease in the mode would show that we are decreasing the hump of the tail, and a decrease in the IQR would show that the spread is also decreasing. (I chose the mode because it is typically the smallest value in a left tail distribution; all of the numbers are long decimals, so I&amp;#39;ll probably need to round them.)  &lt;/p&gt;\n\n&lt;p&gt;Anyone have better ideas? Google tells me a common choice with skewed data is to transform it logarithmically, but I don&amp;#39;t know what to do with that transformed data set- just measure the mean?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zqth6h", "is_robot_indexable": true, "report_reasons": null, "author": "aaquad", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zqth6h/way_to_measure_improvements_in_data_dispersion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zqth6h/way_to_measure_improvements_in_data_dispersion/", "subreddit_subscribers": 828704, "created_utc": 1671555527.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I recently learned about a Kolkata-based tech startup that provides location-based, transactional, consumer behaviour, footfall etc. data to new businesses. It's called Data Sutram.\n\n[https:\\/\\/datasutram.com\\/](https://preview.redd.it/onh71fit137a1.jpg?width=1366&amp;format=pjpg&amp;auto=webp&amp;s=4ec30ccac7e26ab4e819e16128ec04a3eddc169d)\n\nI would like to know how they work, and where they get all the data from.\n\nWhere can I get all the data from if I want to provide similar services? **GeoIQ** is one more company that does similar things as Data Sutram.\n\nDoes anyone have any idea about it?", "author_fullname": "t2_32dvl0pq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where does \"Data Sutram\" get so much consumer data from? How does their architecture work? Any idea?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 66, "top_awarded_type": null, "hide_score": true, "media_metadata": {"onh71fit137a1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 51, "x": 108, "u": "https://preview.redd.it/onh71fit137a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1be8b4840579bc4d18a80a793afdafbf9d0af2f9"}, {"y": 102, "x": 216, "u": "https://preview.redd.it/onh71fit137a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5a3682f20c80b97e27d6a0b3e2bb5ce85c07d095"}, {"y": 151, "x": 320, "u": "https://preview.redd.it/onh71fit137a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a4f3a31225d34fc39c7328a04a4cb3a33c08edf7"}, {"y": 303, "x": 640, "u": "https://preview.redd.it/onh71fit137a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4d0eb7ef3f84abfa27e9d1961ab91f68cb32ae46"}, {"y": 455, "x": 960, "u": "https://preview.redd.it/onh71fit137a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=cf36eb70c23cba35a29d8bcd9cdcf2473bb1d324"}, {"y": 512, "x": 1080, "u": "https://preview.redd.it/onh71fit137a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=547b227f6917332b43adbd650b6a97c3f03ec7e8"}], "s": {"y": 648, "x": 1366, "u": "https://preview.redd.it/onh71fit137a1.jpg?width=1366&amp;format=pjpg&amp;auto=webp&amp;s=4ec30ccac7e26ab4e819e16128ec04a3eddc169d"}, "id": "onh71fit137a1"}}, "name": "t3_zqtfcg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/FrUJ_O2IRRY5owl8Mm32_-KMvufoUKNNXsiaS-QNNpw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671555399.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently learned about a Kolkata-based tech startup that provides location-based, transactional, consumer behaviour, footfall etc. data to new businesses. It&amp;#39;s called Data Sutram.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/onh71fit137a1.jpg?width=1366&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=4ec30ccac7e26ab4e819e16128ec04a3eddc169d\"&gt;https://datasutram.com/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I would like to know how they work, and where they get all the data from.&lt;/p&gt;\n\n&lt;p&gt;Where can I get all the data from if I want to provide similar services? &lt;strong&gt;GeoIQ&lt;/strong&gt; is one more company that does similar things as Data Sutram.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any idea about it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zqtfcg", "is_robot_indexable": true, "report_reasons": null, "author": "thesouvikpaul", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zqtfcg/where_does_data_sutram_get_so_much_consumer_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zqtfcg/where_does_data_sutram_get_so_much_consumer_data/", "subreddit_subscribers": 828704, "created_utc": 1671555399.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_7jta6154", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Agree?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 114, "top_awarded_type": null, "hide_score": true, "name": "t3_zqsseu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/gPir-dGkplRQs256zVrw3jaLSk7aK6_DB6t8V_p4XZw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671553809.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/q9b3rccof47a1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/q9b3rccof47a1.jpg?auto=webp&amp;s=bf7ac5d87e366423349d708ba50d69d79ceb6f22", "width": 1170, "height": 961}, "resolutions": [{"url": "https://preview.redd.it/q9b3rccof47a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5948646e0eb2b20512b92443976da884ef968f4e", "width": 108, "height": 88}, {"url": "https://preview.redd.it/q9b3rccof47a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ac58457d7f1712a10bbf621fcf7b6835966aef30", "width": 216, "height": 177}, {"url": "https://preview.redd.it/q9b3rccof47a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=78308e49d06cbc36a99837320732949152e04c70", "width": 320, "height": 262}, {"url": "https://preview.redd.it/q9b3rccof47a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9ce14aac7a506e1776983a9a2218300c2f8d1cf5", "width": 640, "height": 525}, {"url": "https://preview.redd.it/q9b3rccof47a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=89a343ebb369b4063c7abe6f39508f14d0a514ce", "width": 960, "height": 788}, {"url": "https://preview.redd.it/q9b3rccof47a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6c4bb5c042023f289d6e9d9f6bd96d6d98f4a494", "width": 1080, "height": 887}], "variants": {}, "id": "_cvUHZvfjH7oASMUxPnOoBKLyGsCLcLzdb3PJzDpulc"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "zqsseu", "is_robot_indexable": true, "report_reasons": null, "author": "Apprehensive_Level_8", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zqsseu/agree/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/q9b3rccof47a1.jpg", "subreddit_subscribers": 828704, "created_utc": 1671553809.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Title basically. I know a little SQL and I have knowledge of NoSQL DBs as well. Also know a little basic Comp. Sci.\n\nI'll be starting a semester-long Python class in about 2 weeks.\n\nWhat can I do between now and then to prepare better for Python? I'm asking cuz job is super-demanding.\n\nAre there any quick data science certifications I can take?\n\nAny and all advice is appreciated. Thanks!", "author_fullname": "t2_d39xc5n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I have 15 days between now and when my new Python class takes up all my free time. I work in the database space but not as a data scientist. Do you know of any good and quick beginner-friendly courses I can finish in a couple of weeks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zqrb2p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671550107.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title basically. I know a little SQL and I have knowledge of NoSQL DBs as well. Also know a little basic Comp. Sci.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ll be starting a semester-long Python class in about 2 weeks.&lt;/p&gt;\n\n&lt;p&gt;What can I do between now and then to prepare better for Python? I&amp;#39;m asking cuz job is super-demanding.&lt;/p&gt;\n\n&lt;p&gt;Are there any quick data science certifications I can take?&lt;/p&gt;\n\n&lt;p&gt;Any and all advice is appreciated. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zqrb2p", "is_robot_indexable": true, "report_reasons": null, "author": "DrMBison", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zqrb2p/i_have_15_days_between_now_and_when_my_new_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zqrb2p/i_have_15_days_between_now_and_when_my_new_python/", "subreddit_subscribers": 828704, "created_utc": 1671550107.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data scientist resume (Sheets &amp; giggles template). Any and all input is appreciated.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_zqqfne", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_b88cp4pv", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/chh84LTb_Th0ox6K61HMxdia5GDzpCmjg7gjme80co0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "Resume", "selftext": "Removed all local and personal info. \n\nhttps://preview.redd.it/26ipelrre27a1.png?width=757&amp;format=png&amp;auto=webp&amp;s=d90ff8b75cb937ebd873c448eed1b6f4196d8945", "author_fullname": "t2_b88cp4pv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data scientist resume (Sheets &amp; giggles template). Any and all input is appreciated.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/Resume", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"26ipelrre27a1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 140, "x": 108, "u": "https://preview.redd.it/26ipelrre27a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a5d510fdc00bad39f3a945f1b5020f45a171879a"}, {"y": 280, "x": 216, "u": "https://preview.redd.it/26ipelrre27a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7acccf8ab5944ec3be849da7bd03a76d667a712d"}, {"y": 415, "x": 320, "u": "https://preview.redd.it/26ipelrre27a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=6bc8151a47c07121c48853813c0c719fccad8700"}, {"y": 831, "x": 640, "u": "https://preview.redd.it/26ipelrre27a1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=88d8c395ef171a3220e6f71a956e523b288b76da"}], "s": {"y": 983, "x": 757, "u": "https://preview.redd.it/26ipelrre27a1.png?width=757&amp;format=png&amp;auto=webp&amp;s=d90ff8b75cb937ebd873c448eed1b6f4196d8945"}, "id": "26ipelrre27a1"}}, "name": "t3_zqq9to", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671547402.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.Resume", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Removed all local and personal info. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/26ipelrre27a1.png?width=757&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d90ff8b75cb937ebd873c448eed1b6f4196d8945\"&gt;https://preview.redd.it/26ipelrre27a1.png?width=757&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d90ff8b75cb937ebd873c448eed1b6f4196d8945&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "new", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qv6z", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zqq9to", "is_robot_indexable": true, "report_reasons": null, "author": "Potential_Quality_36", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/Resume/comments/zqq9to/data_scientist_resume_sheets_giggles_template_any/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/Resume/comments/zqq9to/data_scientist_resume_sheets_giggles_template_any/", "subreddit_subscribers": 29910, "created_utc": 1671547402.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1671547854.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.Resume", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/Resume/comments/zqq9to/data_scientist_resume_sheets_giggles_template_any/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "zqqfne", "is_robot_indexable": true, "report_reasons": null, "author": "Potential_Quality_36", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_zqq9to", "author_flair_text_color": null, "permalink": "/r/datascience/comments/zqqfne/data_scientist_resume_sheets_giggles_template_any/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/Resume/comments/zqq9to/data_scientist_resume_sheets_giggles_template_any/", "subreddit_subscribers": 828704, "created_utc": 1671547854.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys,\n\nRecently I got shortlisted for the position of data scientist in a govt. Org. And they have asked all the shortlisted candidates to complete a take home test which would be provided at a particular date. \n\nSo. \n\nI turn to you for help. \n\nThis is the first time I'm doing a take home test, so if you guys give me an idea as to what to expect and what are dos and don'ts for these things. \n\nAny insights that you might be able to provide would be much appreciated. \n\nThanks", "author_fullname": "t2_jo4irqsu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "what to expect for a data science take home test?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zqhyj1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671521446.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,&lt;/p&gt;\n\n&lt;p&gt;Recently I got shortlisted for the position of data scientist in a govt. Org. And they have asked all the shortlisted candidates to complete a take home test which would be provided at a particular date. &lt;/p&gt;\n\n&lt;p&gt;So. &lt;/p&gt;\n\n&lt;p&gt;I turn to you for help. &lt;/p&gt;\n\n&lt;p&gt;This is the first time I&amp;#39;m doing a take home test, so if you guys give me an idea as to what to expect and what are dos and don&amp;#39;ts for these things. &lt;/p&gt;\n\n&lt;p&gt;Any insights that you might be able to provide would be much appreciated. &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "zqhyj1", "is_robot_indexable": true, "report_reasons": null, "author": "thanderrine", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zqhyj1/what_to_expect_for_a_data_science_take_home_test/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zqhyj1/what_to_expect_for_a_data_science_take_home_test/", "subreddit_subscribers": 828704, "created_utc": 1671521446.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Are y'all aware of any online programs or group hackathons that involve mentorship from other people? There's the WiDS hackathon and the WiBD mentorship program but apart from these, any other things y'all can tell me about?\nThanks!", "author_fullname": "t2_v3e14wl8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any programs or online events that include things like a group hackathon and mentoring?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zqg8fj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671516079.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are y&amp;#39;all aware of any online programs or group hackathons that involve mentorship from other people? There&amp;#39;s the WiDS hackathon and the WiBD mentorship program but apart from these, any other things y&amp;#39;all can tell me about?\nThanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zqg8fj", "is_robot_indexable": true, "report_reasons": null, "author": "carrotbean_14", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zqg8fj/any_programs_or_online_events_that_include_things/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zqg8fj/any_programs_or_online_events_that_include_things/", "subreddit_subscribers": 828704, "created_utc": 1671516079.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm training a Poisson model on count data and passing in log(distance) as my offset term.  This is how I called I made the model:\n\n`model &lt;- glm(next_target_both_collision_count ~ weekday_daytime_brake_count +`\n\n`weekend_daytime_brake_count + weekend_nighttime_distraction_count`\n\n`+ weekday_daytime_distraction_count`\n\n`+ weekend_daytime_following_distance_count +`\n\n`weekday_nighttime_following_distance_count +`\n\n`weekday_daytime_following_distance_count,`\n\n`maxit = 100,data = train_df, family = poisson(),`\n\n`offset=log(train_df$distance))`\n\n&amp;#x200B;\n\nHowever, the length of my train set is about 100,000 and the length of my test set is about 10,000.  As a result, when I try to run the following code:\n\n&amp;#x200B;\n\n`predictions &lt;- predict(model, type = \"response\", newdata = test_df)`\n\nI get the following error message:\n\nWarning in offset + eval(object$call$offset, newdata) :\n\nlonger object length is not a multiple of shorter object length\n\nWarning in predictor + offset :\n\nlonger object length is not a multiple of shorter object length\n\n&amp;#x200B;\n\nHow do I properly call the predict function so I don't get this error?  I tried updating the model's offset by doing\n\n`model$offset &lt;- log(test_df$distance)`\n\n`predictions &lt;- predict(model, type = \"response\", newdata = test_df)`\n\n&amp;#x200B;\n\nBut the warning still pops up.", "author_fullname": "t2_8avdky0a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "In R, how would you account for the offset term when doing predict? [Q]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zq3rux", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671484502.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m training a Poisson model on count data and passing in log(distance) as my offset term.  This is how I called I made the model:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;model &amp;lt;- glm(next_target_both_collision_count ~ weekday_daytime_brake_count +&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;weekend_daytime_brake_count + weekend_nighttime_distraction_count&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;+ weekday_daytime_distraction_count&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;+ weekend_daytime_following_distance_count +&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;weekday_nighttime_following_distance_count +&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;weekday_daytime_following_distance_count,&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;maxit = 100,data = train_df, family = poisson(),&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;offset=log(train_df$distance))&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;However, the length of my train set is about 100,000 and the length of my test set is about 10,000.  As a result, when I try to run the following code:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;predictions &amp;lt;- predict(model, type = &amp;quot;response&amp;quot;, newdata = test_df)&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;I get the following error message:&lt;/p&gt;\n\n&lt;p&gt;Warning in offset + eval(object$call$offset, newdata) :&lt;/p&gt;\n\n&lt;p&gt;longer object length is not a multiple of shorter object length&lt;/p&gt;\n\n&lt;p&gt;Warning in predictor + offset :&lt;/p&gt;\n\n&lt;p&gt;longer object length is not a multiple of shorter object length&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;How do I properly call the predict function so I don&amp;#39;t get this error?  I tried updating the model&amp;#39;s offset by doing&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;model$offset &amp;lt;- log(test_df$distance)&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;predictions &amp;lt;- predict(model, type = &amp;quot;response&amp;quot;, newdata = test_df)&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;But the warning still pops up.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zq3rux", "is_robot_indexable": true, "report_reasons": null, "author": "Significant-Work-204", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zq3rux/in_r_how_would_you_account_for_the_offset_term/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zq3rux/in_r_how_would_you_account_for_the_offset_term/", "subreddit_subscribers": 828704, "created_utc": 1671484502.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am facing the dilemma while cleaning data, do i clean the data and halved\n the dataset as a result, will this have a impact on the accuracy of my data model?", "author_fullname": "t2_k6463b03", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much data is needed for a good linear regression model?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zqrlgv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671550841.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am facing the dilemma while cleaning data, do i clean the data and halved\n the dataset as a result, will this have a impact on the accuracy of my data model?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zqrlgv", "is_robot_indexable": true, "report_reasons": null, "author": "weliveincitiesunever", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zqrlgv/how_much_data_is_needed_for_a_good_linear/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zqrlgv/how_much_data_is_needed_for_a_good_linear/", "subreddit_subscribers": 828704, "created_utc": 1671550841.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all. Longtime SPSS user using statsmodels in Python for the first time. I have a dataset with the following factors: \n\nFactor A: Group with two levels\nFactor B: Group with two levels\nThe outcome measure (Y) is repeated for each subject over two time points. Each subject is in a different group. \n\nI\u2019m trying to see if there is an interaction effect of group allocation on the outcome measure as a function of time. I think I know how to model the groups (Y ~ A*B), but I\u2019m lost as how to model the repeated measure factor of Time. \n\nCan anyone help me with this and/or direct me to some resources for learning how to write model formulas?", "author_fullname": "t2_w9k2y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Setting up a Linear Mixed Effect Model for repeated measures in statsmodels", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zq63ur", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671489913.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all. Longtime SPSS user using statsmodels in Python for the first time. I have a dataset with the following factors: &lt;/p&gt;\n\n&lt;p&gt;Factor A: Group with two levels\nFactor B: Group with two levels\nThe outcome measure (Y) is repeated for each subject over two time points. Each subject is in a different group. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m trying to see if there is an interaction effect of group allocation on the outcome measure as a function of time. I think I know how to model the groups (Y ~ A*B), but I\u2019m lost as how to model the repeated measure factor of Time. &lt;/p&gt;\n\n&lt;p&gt;Can anyone help me with this and/or direct me to some resources for learning how to write model formulas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zq63ur", "is_robot_indexable": true, "report_reasons": null, "author": "tweedrobot", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zq63ur/setting_up_a_linear_mixed_effect_model_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zq63ur/setting_up_a_linear_mixed_effect_model_for/", "subreddit_subscribers": 828704, "created_utc": 1671489913.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Say I build a classification model with a training dataset that has a column Favourite Colour which has values Yellow, Red, and Blue. Then there is the dependent variable column Gender which has values 0 - for Male, and 1 - for Female. After categorical encoding the Favourite Colour column I'll end up with 2 Independent variable (IV) columns (as we drop one column cause of the dummy variable trap). \n\nBut then in a new test dataset the Favourite Color column only contains values Red, and Blue. After encoding I'll then have 1 IV column, but my model was trained on a dataset with 2 IVs. How will my model be able to run considering the input size is now different?\n\nI know that I have run into this problem when creating a Random Forest Model (it throws an array that the model was expecting a certain input size but got a different one), but I am asking about models in general.\n\nThanks", "author_fullname": "t2_frwys", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do to do when test input size is not the same as training input size?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zq3wnd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671484810.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Say I build a classification model with a training dataset that has a column Favourite Colour which has values Yellow, Red, and Blue. Then there is the dependent variable column Gender which has values 0 - for Male, and 1 - for Female. After categorical encoding the Favourite Colour column I&amp;#39;ll end up with 2 Independent variable (IV) columns (as we drop one column cause of the dummy variable trap). &lt;/p&gt;\n\n&lt;p&gt;But then in a new test dataset the Favourite Color column only contains values Red, and Blue. After encoding I&amp;#39;ll then have 1 IV column, but my model was trained on a dataset with 2 IVs. How will my model be able to run considering the input size is now different?&lt;/p&gt;\n\n&lt;p&gt;I know that I have run into this problem when creating a Random Forest Model (it throws an array that the model was expecting a certain input size but got a different one), but I am asking about models in general.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zq3wnd", "is_robot_indexable": true, "report_reasons": null, "author": "fouried96", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zq3wnd/what_do_to_do_when_test_input_size_is_not_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zq3wnd/what_do_to_do_when_test_input_size_is_not_the/", "subreddit_subscribers": 828704, "created_utc": 1671484810.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_c25i55k3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a digital library of data science books. I have looked at Kindle Unlimited and Scribd. Does anyone know of an good source to read / refer to data science books?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zq2xer", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671482525.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zq2xer", "is_robot_indexable": true, "report_reasons": null, "author": "moltra_1", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zq2xer/looking_for_a_digital_library_of_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zq2xer/looking_for_a_digital_library_of_data_science/", "subreddit_subscribers": 828704, "created_utc": 1671482525.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello all hoping someone can answer this question. \n\nI am working on a project where health care providers will be collecting data about the patient. The patient is fully aware we are collecting the data as part of the program. My organization is not HIPAA compliment so we need all data de-identified. \n\n\nWhat way can this be done? The offices will be sending me monthly blood pressure updates so they have to be able to look at the chart and be able to determine which patient is which I can\u2019t just number them 1-100 or something. My first thought was patient first/last name initial plus birth day/month but I believe for hipaa that is not stripped enough. Appreciate the help and fully understand y\u2019all are not lawyers but I am not finding any concrete resources online!", "author_fullname": "t2_3bxtfsum", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "De-Identify Health Info", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zq2ike", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671481536.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all hoping someone can answer this question. &lt;/p&gt;\n\n&lt;p&gt;I am working on a project where health care providers will be collecting data about the patient. The patient is fully aware we are collecting the data as part of the program. My organization is not HIPAA compliment so we need all data de-identified. &lt;/p&gt;\n\n&lt;p&gt;What way can this be done? The offices will be sending me monthly blood pressure updates so they have to be able to look at the chart and be able to determine which patient is which I can\u2019t just number them 1-100 or something. My first thought was patient first/last name initial plus birth day/month but I believe for hipaa that is not stripped enough. Appreciate the help and fully understand y\u2019all are not lawyers but I am not finding any concrete resources online!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zq2ike", "is_robot_indexable": true, "report_reasons": null, "author": "HPGOTTOP", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zq2ike/deidentify_health_info/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zq2ike/deidentify_health_info/", "subreddit_subscribers": 828704, "created_utc": 1671481536.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "It's brutal. When I have used ImportXML the first time, it looked like a miracle! I can retrieve data from external website *AND extract data from HTML in one function call*, wow! Now I am sick of it.\n\n**Custom processing and conversions of data is painful in Google Sheets.** Let's say you want to import just 32.22 number from \"cost: 32.22 USD\" string extracted from some website. It is possible to do it in Google Sheets, with some fiddling around formulas and scratching your head, but obviously it is much easier to accomplish this task Javascript or Python, especially if you have lots and lots of data to cleanup!\n\n**There is no proper launch and cache control in ImportXML.** There is no \"scrape now\" button in your Google Sheet. You can't control how often the ImportXML is triggered (well, unless you are a huge fan of Goole Apps Script!) and if you have many cells populated with importXML, it is very easy to occasionally trigger an avalanche of external http calls when opening and editing your sheet. There are also no caching mechanisms in Google Sheets, so if the last call to ImportXML fails, the cell will get *ERR!* value.\n\n**ImportXML only works with basic websites** (no SPAs rendered in browsers can be scraped this way, any basic web scraping protection or connectivity issue breaks the process, no control over HTTP request geo location, or number of retries)\n\nImportXML just fails to extract data from a huge amount of websites for me.\n\nI have finally found an alternative solution which I have been using for some time, it's more complicated to start but is just infinitely flexible and it just.. works for web scraping. My recipe consists of two ingredients:\n\n1. Proper automation framework: I choose [Make.com](https://make.com/) because it is essentially a cheaper and more techy Zapier competitor, it is mature, and it works great. Free plan.\n2. Web scraping API: I use [ScrapeNinja.net](https://scrapeninja.net/) because it allows to write custom Javascript extractors which allow me to extract any data from infinitely complex HTML of the target website, and convert it into arbitrary JSON structure for later usage. It has free plan. **And it can render SPAs like a real browser.**\n\nI am now using Google Sheets like a plain, stupid database - read data, write data back. No external HTTP calls.\n\nHere is my recipe in action: [**https://youtu.be/Uu1uw\\_koznA**](https://youtu.be/Uu1uw_koznA)", "author_fullname": "t2_13hqmc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I am sick of Google Sheets ImportXML and I have finally replaced it.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zq1bef", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671478778.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s brutal. When I have used ImportXML the first time, it looked like a miracle! I can retrieve data from external website &lt;em&gt;AND extract data from HTML in one function call&lt;/em&gt;, wow! Now I am sick of it.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Custom processing and conversions of data is painful in Google Sheets.&lt;/strong&gt; Let&amp;#39;s say you want to import just 32.22 number from &amp;quot;cost: 32.22 USD&amp;quot; string extracted from some website. It is possible to do it in Google Sheets, with some fiddling around formulas and scratching your head, but obviously it is much easier to accomplish this task Javascript or Python, especially if you have lots and lots of data to cleanup!&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;There is no proper launch and cache control in ImportXML.&lt;/strong&gt; There is no &amp;quot;scrape now&amp;quot; button in your Google Sheet. You can&amp;#39;t control how often the ImportXML is triggered (well, unless you are a huge fan of Goole Apps Script!) and if you have many cells populated with importXML, it is very easy to occasionally trigger an avalanche of external http calls when opening and editing your sheet. There are also no caching mechanisms in Google Sheets, so if the last call to ImportXML fails, the cell will get &lt;em&gt;ERR!&lt;/em&gt; value.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;ImportXML only works with basic websites&lt;/strong&gt; (no SPAs rendered in browsers can be scraped this way, any basic web scraping protection or connectivity issue breaks the process, no control over HTTP request geo location, or number of retries)&lt;/p&gt;\n\n&lt;p&gt;ImportXML just fails to extract data from a huge amount of websites for me.&lt;/p&gt;\n\n&lt;p&gt;I have finally found an alternative solution which I have been using for some time, it&amp;#39;s more complicated to start but is just infinitely flexible and it just.. works for web scraping. My recipe consists of two ingredients:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Proper automation framework: I choose &lt;a href=\"https://make.com/\"&gt;Make.com&lt;/a&gt; because it is essentially a cheaper and more techy Zapier competitor, it is mature, and it works great. Free plan.&lt;/li&gt;\n&lt;li&gt;Web scraping API: I use &lt;a href=\"https://scrapeninja.net/\"&gt;ScrapeNinja.net&lt;/a&gt; because it allows to write custom Javascript extractors which allow me to extract any data from infinitely complex HTML of the target website, and convert it into arbitrary JSON structure for later usage. It has free plan. &lt;strong&gt;And it can render SPAs like a real browser.&lt;/strong&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I am now using Google Sheets like a plain, stupid database - read data, write data back. No external HTTP calls.&lt;/p&gt;\n\n&lt;p&gt;Here is my recipe in action: &lt;a href=\"https://youtu.be/Uu1uw_koznA\"&gt;&lt;strong&gt;https://youtu.be/Uu1uw_koznA&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zq1bef", "is_robot_indexable": true, "report_reasons": null, "author": "superjet1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zq1bef/i_am_sick_of_google_sheets_importxml_and_i_have/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zq1bef/i_am_sick_of_google_sheets_importxml_and_i_have/", "subreddit_subscribers": 828704, "created_utc": 1671478778.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What are your experience with recruiters and which ones have you worked with? \nI\u2019m changing careers. I have contract data science and contract analytics engineer roles on my resume after my last career. A bit less than a year total. But I\u2019m having trouble getting interviews. Would a recruiter give me their time, do you think?", "author_fullname": "t2_nwog5zl6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which recruiters to work with?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zq1853", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671478569.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are your experience with recruiters and which ones have you worked with? \nI\u2019m changing careers. I have contract data science and contract analytics engineer roles on my resume after my last career. A bit less than a year total. But I\u2019m having trouble getting interviews. Would a recruiter give me their time, do you think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "zq1853", "is_robot_indexable": true, "report_reasons": null, "author": "Delicious-Cicada9307", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zq1853/which_recruiters_to_work_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zq1853/which_recruiters_to_work_with/", "subreddit_subscribers": 828704, "created_utc": 1671478569.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "No matter how much companies claims it to be(Use Yubikey) and Web3(decentralised web and blockchain) is not better than Web2 and will not replace the current Web2 tech.\n\nTo elaborate for the MFA part, it can be hacked by sending multiple push requests and the person accepting the push which gave attackers the access, many recent organisations faced this hack.\n\nI wanna know what you guys think?", "author_fullname": "t2_jjuvhqid", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Take - MFA push notifications are no secure way of login.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zqt4ys", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.2, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671554688.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;No matter how much companies claims it to be(Use Yubikey) and Web3(decentralised web and blockchain) is not better than Web2 and will not replace the current Web2 tech.&lt;/p&gt;\n\n&lt;p&gt;To elaborate for the MFA part, it can be hacked by sending multiple push requests and the person accepting the push which gave attackers the access, many recent organisations faced this hack.&lt;/p&gt;\n\n&lt;p&gt;I wanna know what you guys think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zqt4ys", "is_robot_indexable": true, "report_reasons": null, "author": "VeliVoy", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zqt4ys/take_mfa_push_notifications_are_no_secure_way_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zqt4ys/take_mfa_push_notifications_are_no_secure_way_of/", "subreddit_subscribers": 828704, "created_utc": 1671554688.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What are the tools that you're using for analyzing texts, survey responses, research abstracts \u2014\u00a0something affordable and that provides good results? \n\nI am aware of NetBase Quid and [Primer.Ai](https://Primer.Ai), but their prices start at tens thousands $$$ a year. Then I know some tools like [https://textrazor.com/](https://textrazor.com/) but it's too technical and works through an API. [https://voyant-tools.org/](https://voyant-tools.org/) is free but not suited to work with survey responses and multiple snippets of data...\n\nThanks!", "author_fullname": "t2_1rpr94lc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are affordable tools for self-employed data scientists who work with text?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zqmgyu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671537280.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the tools that you&amp;#39;re using for analyzing texts, survey responses, research abstracts \u2014\u00a0something affordable and that provides good results? &lt;/p&gt;\n\n&lt;p&gt;I am aware of NetBase Quid and &lt;a href=\"https://Primer.Ai\"&gt;Primer.Ai&lt;/a&gt;, but their prices start at tens thousands $$$ a year. Then I know some tools like &lt;a href=\"https://textrazor.com/\"&gt;https://textrazor.com/&lt;/a&gt; but it&amp;#39;s too technical and works through an API. &lt;a href=\"https://voyant-tools.org/\"&gt;https://voyant-tools.org/&lt;/a&gt; is free but not suited to work with survey responses and multiple snippets of data...&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zqmgyu", "is_robot_indexable": true, "report_reasons": null, "author": "noduslabs", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zqmgyu/what_are_affordable_tools_for_selfemployed_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zqmgyu/what_are_affordable_tools_for_selfemployed_data/", "subreddit_subscribers": 828704, "created_utc": 1671537280.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\n\ud83d\udd25 We\u2019re thrilled to introduce BastionLab, our simple privacy framework for data science collaboration! To see what remote data exploration looks like when all privacy concerns are automatically handled for you, you can check [our GitHub](https://github.com/mithril-security/bastionlab/) or directly go to our [Quick Tour](https://bastionlab.readthedocs.io/en/latest/docs/quick-tour/quick-tour/) tutorial, which is also available on [Colab ](https://colab.research.google.com/github/mithril-security/bastionlab/blob/v0.3.5/docs/docs/quick-tour/quick-tour.ipynb)\ud83d\udd12\n\n# Built for sensitive data collaboration\n\nCollaboration between data owners and data scientists is a big challenge for highly regulated fields like health, finance, or advertising due to security and privacy issues. When collaborating remotely, data owners have to open their whole dataset, often through a Jupyter notebook. This too-broad access creates huge privacy gaps because too many operations are allowed, which enables data scientists to extract information from the remote infrastructure (print the whole database, save the dataset in the weights, etc). \n\n\u2699\ufe0f BastionLab solves this problem by providing fine-grained access control. It guarantees data owners that data scientists can only perform privacy-friendly operations on their data and that only anonymized outputs are shared with them.\n\n# How does BastionLab work?\n\nBastionLab makes sure that the data owner\u2019s remote data is never accessed directly by the data scientist. Three main elements ensure this: \n\n* First, a \u2018safe zone\u2019 is defined by the data owner to filter the data scientist\u2019s queries, which enforces control while allowing for interactivity. \n* Second, expressivity is limited. This means that the type of operations that can be executed by the data scientists is restricted to avoid arbitrary code execution. \n* Finally, the data scientist never accesses the dataset locally. They only manipulate a local object that contains metadata to interact with the remotely hosted dataset - and data owners can always see the calls made by that object. \n\n# Ready to try?\n\nIf you like the project, drop a \u2b50 on our [GitHub](https://github.com/mithril-security/bastionlab/)! We\u2019re open-source, so it\u2019s a big help \\^\\^", "author_fullname": "t2_dwuoduiq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introducing BastionLab - A simple privacy framework for data science collaboration!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zqfuzi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1671514964.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;\ud83d\udd25 We\u2019re thrilled to introduce BastionLab, our simple privacy framework for data science collaboration! To see what remote data exploration looks like when all privacy concerns are automatically handled for you, you can check &lt;a href=\"https://github.com/mithril-security/bastionlab/\"&gt;our GitHub&lt;/a&gt; or directly go to our &lt;a href=\"https://bastionlab.readthedocs.io/en/latest/docs/quick-tour/quick-tour/\"&gt;Quick Tour&lt;/a&gt; tutorial, which is also available on &lt;a href=\"https://colab.research.google.com/github/mithril-security/bastionlab/blob/v0.3.5/docs/docs/quick-tour/quick-tour.ipynb\"&gt;Colab &lt;/a&gt;\ud83d\udd12&lt;/p&gt;\n\n&lt;h1&gt;Built for sensitive data collaboration&lt;/h1&gt;\n\n&lt;p&gt;Collaboration between data owners and data scientists is a big challenge for highly regulated fields like health, finance, or advertising due to security and privacy issues. When collaborating remotely, data owners have to open their whole dataset, often through a Jupyter notebook. This too-broad access creates huge privacy gaps because too many operations are allowed, which enables data scientists to extract information from the remote infrastructure (print the whole database, save the dataset in the weights, etc). &lt;/p&gt;\n\n&lt;p&gt;\u2699\ufe0f BastionLab solves this problem by providing fine-grained access control. It guarantees data owners that data scientists can only perform privacy-friendly operations on their data and that only anonymized outputs are shared with them.&lt;/p&gt;\n\n&lt;h1&gt;How does BastionLab work?&lt;/h1&gt;\n\n&lt;p&gt;BastionLab makes sure that the data owner\u2019s remote data is never accessed directly by the data scientist. Three main elements ensure this: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;First, a \u2018safe zone\u2019 is defined by the data owner to filter the data scientist\u2019s queries, which enforces control while allowing for interactivity. &lt;/li&gt;\n&lt;li&gt;Second, expressivity is limited. This means that the type of operations that can be executed by the data scientists is restricted to avoid arbitrary code execution. &lt;/li&gt;\n&lt;li&gt;Finally, the data scientist never accesses the dataset locally. They only manipulate a local object that contains metadata to interact with the remotely hosted dataset - and data owners can always see the calls made by that object. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;Ready to try?&lt;/h1&gt;\n\n&lt;p&gt;If you like the project, drop a \u2b50 on our &lt;a href=\"https://github.com/mithril-security/bastionlab/\"&gt;GitHub&lt;/a&gt;! We\u2019re open-source, so it\u2019s a big help ^^&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8l1gCfTSVG63eDA7vFvFsBRQiHDkGmHtUd4k4PukPVE.jpg?auto=webp&amp;s=2de6f12ed23c4f54c28751887e7ccc14a4aaaefa", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/8l1gCfTSVG63eDA7vFvFsBRQiHDkGmHtUd4k4PukPVE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6ebcdedc34e047780945fe53807dc8403cc5dc76", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/8l1gCfTSVG63eDA7vFvFsBRQiHDkGmHtUd4k4PukPVE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=74f45f7bd67da8ca6cdf837ec79b5c3eb6258b2d", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/8l1gCfTSVG63eDA7vFvFsBRQiHDkGmHtUd4k4PukPVE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=de5496bf970e334f81781ca7c83199a5290c8de4", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/8l1gCfTSVG63eDA7vFvFsBRQiHDkGmHtUd4k4PukPVE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=500be71718c43cf5483e0dfed22431627794ddea", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/8l1gCfTSVG63eDA7vFvFsBRQiHDkGmHtUd4k4PukPVE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4931a8e07568a2f9003d5fbbefd5ce0170f62823", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/8l1gCfTSVG63eDA7vFvFsBRQiHDkGmHtUd4k4PukPVE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8a0360728028f8b37456d9f676f8a0b51b9702c5", "width": 1080, "height": 540}], "variants": {}, "id": "4I5yjoJax0kR52ybWpt_vvGQ6G0zj4fk8619okQsBrg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zqfuzi", "is_robot_indexable": true, "report_reasons": null, "author": "Separate-Still3770", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zqfuzi/introducing_bastionlab_a_simple_privacy_framework/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zqfuzi/introducing_bastionlab_a_simple_privacy_framework/", "subreddit_subscribers": 828704, "created_utc": 1671514964.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}