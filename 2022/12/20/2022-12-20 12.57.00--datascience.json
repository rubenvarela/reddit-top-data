{"kind": "Listing", "data": {"after": "t3_zpsxpf", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_14z3t1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The real reason ChatGPT was created", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 75, "top_awarded_type": null, "hide_score": false, "name": "t3_zpraee", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 706, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 706, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/I3qmOhxHk8m1KrglQM1-6HA-33jZgxlJZeZVdUTLP6o.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671455711.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/g5z2t4zeuu6a1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/g5z2t4zeuu6a1.png?auto=webp&amp;s=88894e844011e00446480ff28bb04cd59c4c5f53", "width": 2880, "height": 1548}, "resolutions": [{"url": "https://preview.redd.it/g5z2t4zeuu6a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b4e9f6720120c9d217f7fdc85b8ad4e8383c35a3", "width": 108, "height": 58}, {"url": "https://preview.redd.it/g5z2t4zeuu6a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2d4225677c898c548cfe640271ea2051eb6a92d9", "width": 216, "height": 116}, {"url": "https://preview.redd.it/g5z2t4zeuu6a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a17d949009da80cfeed89e91a5c6521297e18bb3", "width": 320, "height": 172}, {"url": "https://preview.redd.it/g5z2t4zeuu6a1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9efd35e36e031ee8332528645423f24f38feb429", "width": 640, "height": 344}, {"url": "https://preview.redd.it/g5z2t4zeuu6a1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ed11f66e66b288d8f28a578f1f0cc66ec09d3c2e", "width": 960, "height": 516}, {"url": "https://preview.redd.it/g5z2t4zeuu6a1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8321fe83c82d50d7d07146e0042463c2533466d4", "width": 1080, "height": 580}], "variants": {}, "id": "s7-gx_SuRZ-m6pZfP60Koagg9hEurc51DaBGZFqvy0w"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "zpraee", "is_robot_indexable": true, "report_reasons": null, "author": "xdonvanx", "discussion_type": null, "num_comments": 66, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zpraee/the_real_reason_chatgpt_was_created/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/g5z2t4zeuu6a1.png", "subreddit_subscribers": 828633, "created_utc": 1671455711.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_oxgj60x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why business data science irritates me", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_zq30tn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 142, "domain": "shakoist.substack.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 142, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/AXe9r7il4LBu36QlAizp5N8-d1-6dhVq2_yRoDsxKOc.jpg", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671482748.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://shakoist.substack.com/p/why-business-data-science-irritates?utm_source=twitter&amp;sd=pf", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/GkOmXq5e_3MS_cWaAQ7RWi0eLrP118sKvkUfKy-XSFU.jpg?auto=webp&amp;s=f56ca257ce707b018be2510c20de4906e4417958", "width": 1066, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/GkOmXq5e_3MS_cWaAQ7RWi0eLrP118sKvkUfKy-XSFU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4367004bca7ed1c2bc42667dd6871ceb60797929", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/GkOmXq5e_3MS_cWaAQ7RWi0eLrP118sKvkUfKy-XSFU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=818e3eebc2e8c7b511d195a9c150f4040178a9c0", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/GkOmXq5e_3MS_cWaAQ7RWi0eLrP118sKvkUfKy-XSFU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b9db3ee316c83cd00c84899870b344b7cb131120", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/GkOmXq5e_3MS_cWaAQ7RWi0eLrP118sKvkUfKy-XSFU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=17e80500e6b8248056239ec840fb54559203b1db", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/GkOmXq5e_3MS_cWaAQ7RWi0eLrP118sKvkUfKy-XSFU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=25ca766a3b513bccffaaea46abd7e866e51dcdf3", "width": 960, "height": 540}], "variants": {}, "id": "Gd29rlJxSoGdKrc45YavqlPTDWd364kSymEjm_TyAa8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "zq30tn", "is_robot_indexable": true, "report_reasons": null, "author": "jerrylessthanthree", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zq30tn/why_business_data_science_irritates_me/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://shakoist.substack.com/p/why-business-data-science-irritates?utm_source=twitter&amp;sd=pf", "subreddit_subscribers": 828633, "created_utc": 1671482748.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So i have historical human classification labels for some data and am training a model with it. I got the same people to label the data a second time more recently and saw that their labels only matched 70% of the time. Does this mean than my model can only ever be 70% accurate also? (I appreciate accuracy isnt the best measure, im using it here just for explination).", "author_fullname": "t2_gm8b3iu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If im building a classification model using human labelled data, does that mean it can only ever be as accurate as the humans that originally labelled the data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zprd3e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671455913.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So i have historical human classification labels for some data and am training a model with it. I got the same people to label the data a second time more recently and saw that their labels only matched 70% of the time. Does this mean than my model can only ever be 70% accurate also? (I appreciate accuracy isnt the best measure, im using it here just for explination).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zprd3e", "is_robot_indexable": true, "report_reasons": null, "author": "poppycocknbalderdash", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zprd3e/if_im_building_a_classification_model_using_human/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zprd3e/if_im_building_a_classification_model_using_human/", "subreddit_subscribers": 828633, "created_utc": 1671455913.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My boss is providing funds to further my education for my Inventory Analyst role. I currently use Power BI and Power Automate at a slightly higher than entry level. Can anyone recommend courses that would help me progress in this type of role? Thank you in advance.", "author_fullname": "t2_7w35o79", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Analyst Courses", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zqamfk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671500784.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My boss is providing funds to further my education for my Inventory Analyst role. I currently use Power BI and Power Automate at a slightly higher than entry level. Can anyone recommend courses that would help me progress in this type of role? Thank you in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zqamfk", "is_robot_indexable": true, "report_reasons": null, "author": "babulthegreat", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zqamfk/data_analyst_courses/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zqamfk/data_analyst_courses/", "subreddit_subscribers": 828633, "created_utc": 1671500784.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I know MS in Data Science/Analytics degrees are scoffed at by most of the DS community, but that more often than not has to do with the egregious price. I imagine if the majority of programs out there were cheap, they would be viewed in a different light. GT's program is a whopping \\~$12k or so after fees and if you complete it part time as intended, it's theoretically free as most large size employers offer to pay for it since it's below their annual tax credit threshold. So, thoughts? Degree mill or actually decent for people seeking a Masters degree?", "author_fullname": "t2_3kg3ev32", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is this sub's opinion of Georgia Tech's online MS Analytics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zqbn9o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671503360.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know MS in Data Science/Analytics degrees are scoffed at by most of the DS community, but that more often than not has to do with the egregious price. I imagine if the majority of programs out there were cheap, they would be viewed in a different light. GT&amp;#39;s program is a whopping ~$12k or so after fees and if you complete it part time as intended, it&amp;#39;s theoretically free as most large size employers offer to pay for it since it&amp;#39;s below their annual tax credit threshold. So, thoughts? Degree mill or actually decent for people seeking a Masters degree?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zqbn9o", "is_robot_indexable": true, "report_reasons": null, "author": "terraninteractive", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zqbn9o/what_is_this_subs_opinion_of_georgia_techs_online/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zqbn9o/what_is_this_subs_opinion_of_georgia_techs_online/", "subreddit_subscribers": 828633, "created_utc": 1671503360.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_jcdyk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How an AI Stole $35 Million", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_zptdjz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/Y-bneGyk4k0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"How an AI Stole $35 Million\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "How an AI Stole $35 Million", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/Y-bneGyk4k0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"How an AI Stole $35 Million\"&gt;&lt;/iframe&gt;", "author_name": "Chill Fuel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/Y-bneGyk4k0/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@ChillFuel"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/Y-bneGyk4k0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"How an AI Stole $35 Million\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/zptdjz", "height": 200}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/uVen1tja_bGfwG5cjUEVVQwwa2csHAKnxJfrvw99-Io.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671460909.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=Y-bneGyk4k0", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XDxxy_ulkit2juQYZcf6XMvpSy7wbjus0rOH9awiyiw.jpg?auto=webp&amp;s=869b3e7a7d794fb58ed35cca14cc7b4bda0b8ff5", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/XDxxy_ulkit2juQYZcf6XMvpSy7wbjus0rOH9awiyiw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a681269a11342c5764b3e0c490f2847ba3800566", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/XDxxy_ulkit2juQYZcf6XMvpSy7wbjus0rOH9awiyiw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=95fad9a10798240cdca5b99d3f38174dcb469dc1", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/XDxxy_ulkit2juQYZcf6XMvpSy7wbjus0rOH9awiyiw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f5e4c2384ca5c79dcc639b8fdc0a71058a7dda0b", "width": 320, "height": 240}], "variants": {}, "id": "JZv8jw1RIwUyS3h6l6GtUUERv1gAn41welyoe6rBhfo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "zptdjz", "is_robot_indexable": true, "report_reasons": null, "author": "gordon22", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zptdjz/how_an_ai_stole_35_million/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=Y-bneGyk4k0", "subreddit_subscribers": 828633, "created_utc": 1671460909.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "How an AI Stole $35 Million", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/Y-bneGyk4k0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"How an AI Stole $35 Million\"&gt;&lt;/iframe&gt;", "author_name": "Chill Fuel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/Y-bneGyk4k0/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@ChillFuel"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Sorry if this isn't a place for questions like this but I was trying to implement the research paper  [Siamese neural networks for one-shot image recognition | Papers With Code](https://paperswithcode.com/paper/siamese-neural-networks-for-one-shot-image) but the approach I am trying to use is not giving any results at all it's giving the worst possible result with at max only two correct answers out of 250 cases, I took inspiration from this Github repo  [One-Shot-Learning-with-Siamese-Networks/Siamese on Omniglot Dataset.ipynb at master \u00b7 hlamba28/One-Shot-Learning-with-Siamese-Networks (github.com)](https://github.com/hlamba28/One-Shot-Learning-with-Siamese-Networks/blob/master/Siamese%20on%20Omniglot%20Dataset.ipynb) and for the most part my notebook is exactly similar with a few minor changes here and there nothing that should affect the result this drastically.\n\n&amp;#x200B;\n\nI wanted to know if anyone had any experience in working with Siamese Models before who could help understand my issues.", "author_fullname": "t2_5dba85st", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I am working on a Siamese model for one-shot image classification but the approach I am using to implement my model is not working at all", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zpwdg6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1671467846.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sorry if this isn&amp;#39;t a place for questions like this but I was trying to implement the research paper  &lt;a href=\"https://paperswithcode.com/paper/siamese-neural-networks-for-one-shot-image\"&gt;Siamese neural networks for one-shot image recognition | Papers With Code&lt;/a&gt; but the approach I am trying to use is not giving any results at all it&amp;#39;s giving the worst possible result with at max only two correct answers out of 250 cases, I took inspiration from this Github repo  &lt;a href=\"https://github.com/hlamba28/One-Shot-Learning-with-Siamese-Networks/blob/master/Siamese%20on%20Omniglot%20Dataset.ipynb\"&gt;One-Shot-Learning-with-Siamese-Networks/Siamese on Omniglot Dataset.ipynb at master \u00b7 hlamba28/One-Shot-Learning-with-Siamese-Networks (github.com)&lt;/a&gt; and for the most part my notebook is exactly similar with a few minor changes here and there nothing that should affect the result this drastically.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I wanted to know if anyone had any experience in working with Siamese Models before who could help understand my issues.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/3PKDHjR7bNNRtXKDSAgi8fBSNMgT1ynm04bHL_w3zQo.jpg?auto=webp&amp;s=1f2f3358ee695685b7da48813bb70483fc865e5f", "width": 382, "height": 248}, "resolutions": [{"url": "https://external-preview.redd.it/3PKDHjR7bNNRtXKDSAgi8fBSNMgT1ynm04bHL_w3zQo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f41664ed766d816568c3a121b08b53edb46de0a6", "width": 108, "height": 70}, {"url": "https://external-preview.redd.it/3PKDHjR7bNNRtXKDSAgi8fBSNMgT1ynm04bHL_w3zQo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bec7130e4da02889a0a1d828ee0fd3f8bac8a631", "width": 216, "height": 140}, {"url": "https://external-preview.redd.it/3PKDHjR7bNNRtXKDSAgi8fBSNMgT1ynm04bHL_w3zQo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d2182341665c014ae1e774c45f26128f93acf0db", "width": 320, "height": 207}], "variants": {}, "id": "aAMnSpDxn5pvDSe_CLquRhqBevtKHywF6qOTdN12ofM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zpwdg6", "is_robot_indexable": true, "report_reasons": null, "author": "DemonCyborg27", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zpwdg6/i_am_working_on_a_siamese_model_for_oneshot_image/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zpwdg6/i_am_working_on_a_siamese_model_for_oneshot_image/", "subreddit_subscribers": 828633, "created_utc": 1671467846.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Data Science is a booming industry with new job roles, various responsibilities, updated tools and technologies, programming languages, and exponential career growth. It is used in global businesses widely for extracting useful insights from gathered raw data. The learning of [data science](https://www.slajobs.com/data-science-training-in-chennai/) brings a promising future for freshers and working professionals with updated technology utilization. Data Scientist and Data Engineer is the top trending and in-demand profile and we explain here the differences in responsibilities, required skills, useful tools, and job outlook that can be useful for you to choose your desired career path easily and effectively.\n\n**Responsibilities of Data Scientist**\n\nData Scientists should have combined knowledge of computer science, mathematics, and statistics to analyze, process, and model data for interpreting the results into actionable plans for organizations. They should work closely with stakeholders to understand the goals for deciding how data can be used to achieve those goals. They have to generate algorithms, processes, and predictive models to gather and analyze data. Following are the detailed responsibilities of the data scientist.\n\n* Raising the right questions for discovery processes\n* Acquiring the related data to begin the process\n* Cleansing and integrating the processed data\n* Storing data after the integration\n* Performing data investigation and exploratory data analysis\n* Creating or applying predictive models or algorithms\n* Implementing data science techniques such as machine learning, AI, or statistical modeling\n* Measuring solutions to improve results\n* Displaying final results to stakeholders\n* Collecting feedback to adjust solutions based on them\n* Repeating the process for solving new problems\n\nThey will perform the responsibilities in various job titles such as data scientists, data analysts, data engineers, business intelligence specialists, and data architects.\n\n**Required skills for data scientists**\n\nData Scientists are required to have the following skills for performing various activities.\n\n* Statistical Analysis for identifying data patterns that includes pattern direction and anomaly detection.\n* Machine Learning for implementing algorithms and statistical models for enabling a computer to learn data automatically.\n* Computer Science skills for applying the principles of Artificial Intelligence, Database Systems, Computer Interaction, Numerical Analysis, and Software Engineering.\n* Programming skills in Java, R, Python, and SQL to write computer programs for analyzing large datasets to explore answers for complicated problems.\n* Data Storytelling to explain the actionable insights to non-technical clients.\n* Business Intuition to connect with stakeholders and understand the exact problems\n* Analytical Thinking to find an analytical solution for solving business issues\n* Critical Thinking to apply objective analysis of facts\n* Inquisitiveness to discover patterns and solutions within the data\n* Interpersonal skills to communicate with an audience of various organizations.\n\n**Useful tools to learn by data scientists**\n\nThere are some tools used for data scientists to build a bright and promising career through effective data analytics.\n\n* SAS used granular analysis of textual data and generate insightful reports\n* Apache Hadoop for parallel processing of large file or big data\n* Tableau for data visualization in decision-making and data analysis\n* TensorFlow for building and training data science models\n* BigML for building datasets and sharing with other systems\n* Knime for data reporting, data mining, and data analysis\n* Rapid Miner for providing a suitable platform for data preparation\n* Excel for understanding the basics of data science to high-end analytics\n* Apache Flink for performing scalable data science computations\n* PowerBI for data visualization to gain rich insights from a given dataset\n* DataRobot for utilizing high-end automation to users\n* Apache Spark for performing data science calculations to handle interactive queries\n* Sap Hana for easy data storage and data retrieval\n* MongoDB for storing large volumes of data\n* Python to perform mathematical, statistical, and scientific calculations along with libraries\n* Trifacta for data cleaning and data preparation\n* Minitab for data manipulation and data analysis\n* Apache Kafka is a distributed messaging system for transferring large volumes of data\n* R for statistical analysis used in data clustering and data classification\n* QlikView for deriving relationships between unstructured data and performing data analysis\n* MicroStrategy to utilize analytical capabilities along with data visualization and discovery\n* Google Analytics for digital marketing purposes to access, visualize, and analyze the web data\n* Julia for performing complex statistical calculations related to data science\n* SPSS for performing statistical data analysis\n* MATLAB for accessing data from flat files, cloud platforms, and databases in reduced time for pre-processing.\n\n**Job Outlook for data scientists**\n\nCompanies around the world are looking for data scientists who have communication skills, creativity skills, curiosity, cleverness, and technical expertise. There are nearly 1.5 million data scientists who are required to fill the skill gap of the companies with the right skills and certifications. The average salary of the data scientist is $ 1,35,000 per annum and it may vary as per the location and size of the companies. The New York Times, Boomerang, Verizon, Spotify, Facebook, Amazon, Dropbox, Microsoft, Walmart, and Deloitte are the popular companies hiring data scientists regularly.\n\n**Responsibilities of Data Engineers**\n\nData Engineers are responsible for developing, constructing, testing, and maintaining architectures such as databases and large-scale processing systems. They should also clean, massage, and organize big data by dealing with raw data that includes human, machine, or instrumental errors. Data Engineers are expected to have in-depth knowledge to recommend and implement ways to improve data reliability, efficiency, and quality along with the responsibility of ensuring the architecture that supports the requirements of data scientists, stakeholders, and businesses. Following are the detailed responsibilities of data engineers.\n\n* Developing, constructing, testing, and maintaining architectures\n* Align the planned architecture with business requirements\n* Performing data acquisition and developing dataset processes\n* Utilizing programming languages and tools\n* Identifying solutions to improve data reliability, efficiency, and quality\n* Conducting research for business queries\n* Implementing datasets to address business problems\n* Deploying sophisticated analytical programs, machine learning, and statistical methods\n* Preparing data for predictive and prospective modeling\n* Uncover the hidden patterns using data\n* Use data to explore tasks that can be automated\n* Presenting the updates to stakeholders based on analytics\n\nData Engineers will perform their roles through various job roles such as Hadoop Developer, BI Developer, Quantitative Data Engineer, Search Engineer, Technical Architect, Big Data Analyst, Solutions Architect, Data Warehouse Engineer, Software Engineer, and ETL Developer.\n\n**Required skills for data engineers**\n\nFollowing are the expected skills in top companies to perform data engineering positions.\n\n* Database Systems for building and managing relational database systems\n* Data Warehousing solutions to store and analyze huge volumes of data\n* ETL tools to understand how data is extracted from the source, how it is transformed or converted, and how it is loaded into data warehouses.\n* Machine Learning skills to implement proper algorithms and models for working on historical data to build accurate data pipelines.\n* Data APIs for implementing software applications to access data\n* Programming knowledge in Java, Scala, Python, or R for statistical analysis and modeling\n* Distributed systems for understanding large data across data clusters\n* Algorithms and data structures for data filtering and data optimization\n* Communication skills to work with a team of engineers, analysts, CTOs, and developers\n* Collaboration skills to work effectively on the deliverables\n* Presentation skills to perform data analysis and present their findings to stakeholders.\n\n**Useful tools to learn by data engineers**\n\nFollowing are the tools that are useful for data engineers\n\n* Apache Hadoop for performing well on distributed data processing\n* Apache Spark for performing stream processing and batch processing\n* C++ is used for computing large datasets quickly and generating or utilizing a predefined algorithm\n* AWS or RedShift for data warehousing processes\n* Azure for cloud technology implementation\n* HDFS for storing and processing data\n* Amazon S3 for virtual storage of files and data.\n\n**Job Outlook for Data Engineers**\n\nData Engineers are in high demand for companies and job postings are gradually increased over the past decade. They are recruited by companies for delivering flexible and scalable solutions to store and manage the organizational data along with cloud migration. They will take care of cleaning, aggregating, and organizing data from disparate sources and transfer them into data warehouses. They will earn around $157,273 Per annum as an average salary and it may differ from companies as per the size and location. Top companies such as Shell, IBM, LinkedIn, Accenture, Freshworks, Ericsson, Capgemini, TCS, CTS, Amazon, Google, Microsoft, Happiest Minds Technologies, and McKinsey and Co are recruiting certified and talented Data engineers to take care of various responsibilities for their clients.\n\n**Conclusion**\n\nData Scientist and Data Engineer are the popular job roles in global companies to perform predictive analysis, statistical modeling, big data, data mining, enterprise analytics, data-driven decision making, data visualization, and data storytelling. Taking a best Data Science Course helps you to employ statistics, analytical systems technology, and business intelligence for achieving organizational goals and it also helps in your career growth. The learning of data science requires a basic degree in computer-related courses to obtain specialized certification in some tools and technologies. We offer experiential learning at SLA to offer expertise in required industry skills through our [Data Science Training in Chennai](https://www.slajobs.com/data-science-training-in-chennai/).", "author_fullname": "t2_v2t6r0wt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Scientist Vs Data Engineers - Guide to choosing your desired path", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zqip3u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1671523882.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data Science is a booming industry with new job roles, various responsibilities, updated tools and technologies, programming languages, and exponential career growth. It is used in global businesses widely for extracting useful insights from gathered raw data. The learning of &lt;a href=\"https://www.slajobs.com/data-science-training-in-chennai/\"&gt;data science&lt;/a&gt; brings a promising future for freshers and working professionals with updated technology utilization. Data Scientist and Data Engineer is the top trending and in-demand profile and we explain here the differences in responsibilities, required skills, useful tools, and job outlook that can be useful for you to choose your desired career path easily and effectively.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Responsibilities of Data Scientist&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Data Scientists should have combined knowledge of computer science, mathematics, and statistics to analyze, process, and model data for interpreting the results into actionable plans for organizations. They should work closely with stakeholders to understand the goals for deciding how data can be used to achieve those goals. They have to generate algorithms, processes, and predictive models to gather and analyze data. Following are the detailed responsibilities of the data scientist.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Raising the right questions for discovery processes&lt;/li&gt;\n&lt;li&gt;Acquiring the related data to begin the process&lt;/li&gt;\n&lt;li&gt;Cleansing and integrating the processed data&lt;/li&gt;\n&lt;li&gt;Storing data after the integration&lt;/li&gt;\n&lt;li&gt;Performing data investigation and exploratory data analysis&lt;/li&gt;\n&lt;li&gt;Creating or applying predictive models or algorithms&lt;/li&gt;\n&lt;li&gt;Implementing data science techniques such as machine learning, AI, or statistical modeling&lt;/li&gt;\n&lt;li&gt;Measuring solutions to improve results&lt;/li&gt;\n&lt;li&gt;Displaying final results to stakeholders&lt;/li&gt;\n&lt;li&gt;Collecting feedback to adjust solutions based on them&lt;/li&gt;\n&lt;li&gt;Repeating the process for solving new problems&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;They will perform the responsibilities in various job titles such as data scientists, data analysts, data engineers, business intelligence specialists, and data architects.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Required skills for data scientists&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Data Scientists are required to have the following skills for performing various activities.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Statistical Analysis for identifying data patterns that includes pattern direction and anomaly detection.&lt;/li&gt;\n&lt;li&gt;Machine Learning for implementing algorithms and statistical models for enabling a computer to learn data automatically.&lt;/li&gt;\n&lt;li&gt;Computer Science skills for applying the principles of Artificial Intelligence, Database Systems, Computer Interaction, Numerical Analysis, and Software Engineering.&lt;/li&gt;\n&lt;li&gt;Programming skills in Java, R, Python, and SQL to write computer programs for analyzing large datasets to explore answers for complicated problems.&lt;/li&gt;\n&lt;li&gt;Data Storytelling to explain the actionable insights to non-technical clients.&lt;/li&gt;\n&lt;li&gt;Business Intuition to connect with stakeholders and understand the exact problems&lt;/li&gt;\n&lt;li&gt;Analytical Thinking to find an analytical solution for solving business issues&lt;/li&gt;\n&lt;li&gt;Critical Thinking to apply objective analysis of facts&lt;/li&gt;\n&lt;li&gt;Inquisitiveness to discover patterns and solutions within the data&lt;/li&gt;\n&lt;li&gt;Interpersonal skills to communicate with an audience of various organizations.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Useful tools to learn by data scientists&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;There are some tools used for data scientists to build a bright and promising career through effective data analytics.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;SAS used granular analysis of textual data and generate insightful reports&lt;/li&gt;\n&lt;li&gt;Apache Hadoop for parallel processing of large file or big data&lt;/li&gt;\n&lt;li&gt;Tableau for data visualization in decision-making and data analysis&lt;/li&gt;\n&lt;li&gt;TensorFlow for building and training data science models&lt;/li&gt;\n&lt;li&gt;BigML for building datasets and sharing with other systems&lt;/li&gt;\n&lt;li&gt;Knime for data reporting, data mining, and data analysis&lt;/li&gt;\n&lt;li&gt;Rapid Miner for providing a suitable platform for data preparation&lt;/li&gt;\n&lt;li&gt;Excel for understanding the basics of data science to high-end analytics&lt;/li&gt;\n&lt;li&gt;Apache Flink for performing scalable data science computations&lt;/li&gt;\n&lt;li&gt;PowerBI for data visualization to gain rich insights from a given dataset&lt;/li&gt;\n&lt;li&gt;DataRobot for utilizing high-end automation to users&lt;/li&gt;\n&lt;li&gt;Apache Spark for performing data science calculations to handle interactive queries&lt;/li&gt;\n&lt;li&gt;Sap Hana for easy data storage and data retrieval&lt;/li&gt;\n&lt;li&gt;MongoDB for storing large volumes of data&lt;/li&gt;\n&lt;li&gt;Python to perform mathematical, statistical, and scientific calculations along with libraries&lt;/li&gt;\n&lt;li&gt;Trifacta for data cleaning and data preparation&lt;/li&gt;\n&lt;li&gt;Minitab for data manipulation and data analysis&lt;/li&gt;\n&lt;li&gt;Apache Kafka is a distributed messaging system for transferring large volumes of data&lt;/li&gt;\n&lt;li&gt;R for statistical analysis used in data clustering and data classification&lt;/li&gt;\n&lt;li&gt;QlikView for deriving relationships between unstructured data and performing data analysis&lt;/li&gt;\n&lt;li&gt;MicroStrategy to utilize analytical capabilities along with data visualization and discovery&lt;/li&gt;\n&lt;li&gt;Google Analytics for digital marketing purposes to access, visualize, and analyze the web data&lt;/li&gt;\n&lt;li&gt;Julia for performing complex statistical calculations related to data science&lt;/li&gt;\n&lt;li&gt;SPSS for performing statistical data analysis&lt;/li&gt;\n&lt;li&gt;MATLAB for accessing data from flat files, cloud platforms, and databases in reduced time for pre-processing.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Job Outlook for data scientists&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Companies around the world are looking for data scientists who have communication skills, creativity skills, curiosity, cleverness, and technical expertise. There are nearly 1.5 million data scientists who are required to fill the skill gap of the companies with the right skills and certifications. The average salary of the data scientist is $ 1,35,000 per annum and it may vary as per the location and size of the companies. The New York Times, Boomerang, Verizon, Spotify, Facebook, Amazon, Dropbox, Microsoft, Walmart, and Deloitte are the popular companies hiring data scientists regularly.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Responsibilities of Data Engineers&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Data Engineers are responsible for developing, constructing, testing, and maintaining architectures such as databases and large-scale processing systems. They should also clean, massage, and organize big data by dealing with raw data that includes human, machine, or instrumental errors. Data Engineers are expected to have in-depth knowledge to recommend and implement ways to improve data reliability, efficiency, and quality along with the responsibility of ensuring the architecture that supports the requirements of data scientists, stakeholders, and businesses. Following are the detailed responsibilities of data engineers.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Developing, constructing, testing, and maintaining architectures&lt;/li&gt;\n&lt;li&gt;Align the planned architecture with business requirements&lt;/li&gt;\n&lt;li&gt;Performing data acquisition and developing dataset processes&lt;/li&gt;\n&lt;li&gt;Utilizing programming languages and tools&lt;/li&gt;\n&lt;li&gt;Identifying solutions to improve data reliability, efficiency, and quality&lt;/li&gt;\n&lt;li&gt;Conducting research for business queries&lt;/li&gt;\n&lt;li&gt;Implementing datasets to address business problems&lt;/li&gt;\n&lt;li&gt;Deploying sophisticated analytical programs, machine learning, and statistical methods&lt;/li&gt;\n&lt;li&gt;Preparing data for predictive and prospective modeling&lt;/li&gt;\n&lt;li&gt;Uncover the hidden patterns using data&lt;/li&gt;\n&lt;li&gt;Use data to explore tasks that can be automated&lt;/li&gt;\n&lt;li&gt;Presenting the updates to stakeholders based on analytics&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Data Engineers will perform their roles through various job roles such as Hadoop Developer, BI Developer, Quantitative Data Engineer, Search Engineer, Technical Architect, Big Data Analyst, Solutions Architect, Data Warehouse Engineer, Software Engineer, and ETL Developer.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Required skills for data engineers&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Following are the expected skills in top companies to perform data engineering positions.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Database Systems for building and managing relational database systems&lt;/li&gt;\n&lt;li&gt;Data Warehousing solutions to store and analyze huge volumes of data&lt;/li&gt;\n&lt;li&gt;ETL tools to understand how data is extracted from the source, how it is transformed or converted, and how it is loaded into data warehouses.&lt;/li&gt;\n&lt;li&gt;Machine Learning skills to implement proper algorithms and models for working on historical data to build accurate data pipelines.&lt;/li&gt;\n&lt;li&gt;Data APIs for implementing software applications to access data&lt;/li&gt;\n&lt;li&gt;Programming knowledge in Java, Scala, Python, or R for statistical analysis and modeling&lt;/li&gt;\n&lt;li&gt;Distributed systems for understanding large data across data clusters&lt;/li&gt;\n&lt;li&gt;Algorithms and data structures for data filtering and data optimization&lt;/li&gt;\n&lt;li&gt;Communication skills to work with a team of engineers, analysts, CTOs, and developers&lt;/li&gt;\n&lt;li&gt;Collaboration skills to work effectively on the deliverables&lt;/li&gt;\n&lt;li&gt;Presentation skills to perform data analysis and present their findings to stakeholders.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Useful tools to learn by data engineers&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Following are the tools that are useful for data engineers&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Apache Hadoop for performing well on distributed data processing&lt;/li&gt;\n&lt;li&gt;Apache Spark for performing stream processing and batch processing&lt;/li&gt;\n&lt;li&gt;C++ is used for computing large datasets quickly and generating or utilizing a predefined algorithm&lt;/li&gt;\n&lt;li&gt;AWS or RedShift for data warehousing processes&lt;/li&gt;\n&lt;li&gt;Azure for cloud technology implementation&lt;/li&gt;\n&lt;li&gt;HDFS for storing and processing data&lt;/li&gt;\n&lt;li&gt;Amazon S3 for virtual storage of files and data.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Job Outlook for Data Engineers&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Data Engineers are in high demand for companies and job postings are gradually increased over the past decade. They are recruited by companies for delivering flexible and scalable solutions to store and manage the organizational data along with cloud migration. They will take care of cleaning, aggregating, and organizing data from disparate sources and transfer them into data warehouses. They will earn around $157,273 Per annum as an average salary and it may differ from companies as per the size and location. Top companies such as Shell, IBM, LinkedIn, Accenture, Freshworks, Ericsson, Capgemini, TCS, CTS, Amazon, Google, Microsoft, Happiest Minds Technologies, and McKinsey and Co are recruiting certified and talented Data engineers to take care of various responsibilities for their clients.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Data Scientist and Data Engineer are the popular job roles in global companies to perform predictive analysis, statistical modeling, big data, data mining, enterprise analytics, data-driven decision making, data visualization, and data storytelling. Taking a best Data Science Course helps you to employ statistics, analytical systems technology, and business intelligence for achieving organizational goals and it also helps in your career growth. The learning of data science requires a basic degree in computer-related courses to obtain specialized certification in some tools and technologies. We offer experiential learning at SLA to offer expertise in required industry skills through our &lt;a href=\"https://www.slajobs.com/data-science-training-in-chennai/\"&gt;Data Science Training in Chennai&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/E0F3miJI87HA3278h4G0lPe4Ep3drmsvBuU2SDjnXRs.jpg?auto=webp&amp;s=53b9487b727772228456c35a3a249a56333bb0a5", "width": 800, "height": 250}, "resolutions": [{"url": "https://external-preview.redd.it/E0F3miJI87HA3278h4G0lPe4Ep3drmsvBuU2SDjnXRs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=60089f47d56cbee200fa98e0e7af6cf9356d486b", "width": 108, "height": 33}, {"url": "https://external-preview.redd.it/E0F3miJI87HA3278h4G0lPe4Ep3drmsvBuU2SDjnXRs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f862fb6b2e68db124f49115a6f70f5232d0b79b0", "width": 216, "height": 67}, {"url": "https://external-preview.redd.it/E0F3miJI87HA3278h4G0lPe4Ep3drmsvBuU2SDjnXRs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=274a1ca126829a9508168ffb95f66a0ee3631767", "width": 320, "height": 100}, {"url": "https://external-preview.redd.it/E0F3miJI87HA3278h4G0lPe4Ep3drmsvBuU2SDjnXRs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b03a2fbe0655bd68dceba51167a832833e9d1062", "width": 640, "height": 200}], "variants": {}, "id": "zCR25Ts1ziyB37pNqFhO9QAjsiuhgmO7sr8dWoyN1WU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zqip3u", "is_robot_indexable": true, "report_reasons": null, "author": "slajobs987", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zqip3u/data_scientist_vs_data_engineers_guide_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zqip3u/data_scientist_vs_data_engineers_guide_to/", "subreddit_subscribers": 828633, "created_utc": 1671523882.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Are y'all aware of any online programs or group hackathons that involve mentorship from other people? There's the WiDS hackathon and the WiBD mentorship program but apart from these, any other things y'all can tell me about?\nThanks!", "author_fullname": "t2_v3e14wl8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any programs or online events that include things like a group hackathon and mentoring?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zqg8fj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671516079.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are y&amp;#39;all aware of any online programs or group hackathons that involve mentorship from other people? There&amp;#39;s the WiDS hackathon and the WiBD mentorship program but apart from these, any other things y&amp;#39;all can tell me about?\nThanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zqg8fj", "is_robot_indexable": true, "report_reasons": null, "author": "carrotbean_14", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zqg8fj/any_programs_or_online_events_that_include_things/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zqg8fj/any_programs_or_online_events_that_include_things/", "subreddit_subscribers": 828633, "created_utc": 1671516079.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all. Longtime SPSS user using statsmodels in Python for the first time. I have a dataset with the following factors: \n\nFactor A: Group with two levels\nFactor B: Group with two levels\nThe outcome measure (Y) is repeated for each subject over two time points. Each subject is in a different group. \n\nI\u2019m trying to see if there is an interaction effect of group allocation on the outcome measure as a function of time. I think I know how to model the groups (Y ~ A*B), but I\u2019m lost as how to model the repeated measure factor of Time. \n\nCan anyone help me with this and/or direct me to some resources for learning how to write model formulas?", "author_fullname": "t2_w9k2y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Setting up a Linear Mixed Effect Model for repeated measures in statsmodels", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zq63ur", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671489913.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all. Longtime SPSS user using statsmodels in Python for the first time. I have a dataset with the following factors: &lt;/p&gt;\n\n&lt;p&gt;Factor A: Group with two levels\nFactor B: Group with two levels\nThe outcome measure (Y) is repeated for each subject over two time points. Each subject is in a different group. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m trying to see if there is an interaction effect of group allocation on the outcome measure as a function of time. I think I know how to model the groups (Y ~ A*B), but I\u2019m lost as how to model the repeated measure factor of Time. &lt;/p&gt;\n\n&lt;p&gt;Can anyone help me with this and/or direct me to some resources for learning how to write model formulas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zq63ur", "is_robot_indexable": true, "report_reasons": null, "author": "tweedrobot", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zq63ur/setting_up_a_linear_mixed_effect_model_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zq63ur/setting_up_a_linear_mixed_effect_model_for/", "subreddit_subscribers": 828633, "created_utc": 1671489913.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm training a Poisson model on count data and passing in log(distance) as my offset term.  This is how I called I made the model:\n\n`model &lt;- glm(next_target_both_collision_count ~ weekday_daytime_brake_count +`\n\n`weekend_daytime_brake_count + weekend_nighttime_distraction_count`\n\n`+ weekday_daytime_distraction_count`\n\n`+ weekend_daytime_following_distance_count +`\n\n`weekday_nighttime_following_distance_count +`\n\n`weekday_daytime_following_distance_count,`\n\n`maxit = 100,data = train_df, family = poisson(),`\n\n`offset=log(train_df$distance))`\n\n&amp;#x200B;\n\nHowever, the length of my train set is about 100,000 and the length of my test set is about 10,000.  As a result, when I try to run the following code:\n\n&amp;#x200B;\n\n`predictions &lt;- predict(model, type = \"response\", newdata = test_df)`\n\nI get the following error message:\n\nWarning in offset + eval(object$call$offset, newdata) :\n\nlonger object length is not a multiple of shorter object length\n\nWarning in predictor + offset :\n\nlonger object length is not a multiple of shorter object length\n\n&amp;#x200B;\n\nHow do I properly call the predict function so I don't get this error?  I tried updating the model's offset by doing\n\n`model$offset &lt;- log(test_df$distance)`\n\n`predictions &lt;- predict(model, type = \"response\", newdata = test_df)`\n\n&amp;#x200B;\n\nBut the warning still pops up.", "author_fullname": "t2_8avdky0a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "In R, how would you account for the offset term when doing predict? [Q]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zq3rux", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671484502.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m training a Poisson model on count data and passing in log(distance) as my offset term.  This is how I called I made the model:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;model &amp;lt;- glm(next_target_both_collision_count ~ weekday_daytime_brake_count +&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;weekend_daytime_brake_count + weekend_nighttime_distraction_count&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;+ weekday_daytime_distraction_count&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;+ weekend_daytime_following_distance_count +&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;weekday_nighttime_following_distance_count +&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;weekday_daytime_following_distance_count,&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;maxit = 100,data = train_df, family = poisson(),&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;offset=log(train_df$distance))&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;However, the length of my train set is about 100,000 and the length of my test set is about 10,000.  As a result, when I try to run the following code:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;predictions &amp;lt;- predict(model, type = &amp;quot;response&amp;quot;, newdata = test_df)&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;I get the following error message:&lt;/p&gt;\n\n&lt;p&gt;Warning in offset + eval(object$call$offset, newdata) :&lt;/p&gt;\n\n&lt;p&gt;longer object length is not a multiple of shorter object length&lt;/p&gt;\n\n&lt;p&gt;Warning in predictor + offset :&lt;/p&gt;\n\n&lt;p&gt;longer object length is not a multiple of shorter object length&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;How do I properly call the predict function so I don&amp;#39;t get this error?  I tried updating the model&amp;#39;s offset by doing&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;model$offset &amp;lt;- log(test_df$distance)&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;predictions &amp;lt;- predict(model, type = &amp;quot;response&amp;quot;, newdata = test_df)&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;But the warning still pops up.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zq3rux", "is_robot_indexable": true, "report_reasons": null, "author": "Significant-Work-204", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zq3rux/in_r_how_would_you_account_for_the_offset_term/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zq3rux/in_r_how_would_you_account_for_the_offset_term/", "subreddit_subscribers": 828633, "created_utc": 1671484502.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "It's brutal. When I have used ImportXML the first time, it looked like a miracle! I can retrieve data from external website *AND extract data from HTML in one function call*, wow! Now I am sick of it.\n\n**Custom processing and conversions of data is painful in Google Sheets.** Let's say you want to import just 32.22 number from \"cost: 32.22 USD\" string extracted from some website. It is possible to do it in Google Sheets, with some fiddling around formulas and scratching your head, but obviously it is much easier to accomplish this task Javascript or Python, especially if you have lots and lots of data to cleanup!\n\n**There is no proper launch and cache control in ImportXML.** There is no \"scrape now\" button in your Google Sheet. You can't control how often the ImportXML is triggered (well, unless you are a huge fan of Goole Apps Script!) and if you have many cells populated with importXML, it is very easy to occasionally trigger an avalanche of external http calls when opening and editing your sheet. There are also no caching mechanisms in Google Sheets, so if the last call to ImportXML fails, the cell will get *ERR!* value.\n\n**ImportXML only works with basic websites** (no SPAs rendered in browsers can be scraped this way, any basic web scraping protection or connectivity issue breaks the process, no control over HTTP request geo location, or number of retries)\n\nImportXML just fails to extract data from a huge amount of websites for me.\n\nI have finally found an alternative solution which I have been using for some time, it's more complicated to start but is just infinitely flexible and it just.. works for web scraping. My recipe consists of two ingredients:\n\n1. Proper automation framework: I choose [Make.com](https://make.com/) because it is essentially a cheaper and more techy Zapier competitor, it is mature, and it works great. Free plan.\n2. Web scraping API: I use [ScrapeNinja.net](https://scrapeninja.net/) because it allows to write custom Javascript extractors which allow me to extract any data from infinitely complex HTML of the target website, and convert it into arbitrary JSON structure for later usage. It has free plan. **And it can render SPAs like a real browser.**\n\nI am now using Google Sheets like a plain, stupid database - read data, write data back. No external HTTP calls.\n\nHere is my recipe in action: [**https://youtu.be/Uu1uw\\_koznA**](https://youtu.be/Uu1uw_koznA)", "author_fullname": "t2_13hqmc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I am sick of Google Sheets ImportXML and I have finally replaced it.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zq1bef", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671478778.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s brutal. When I have used ImportXML the first time, it looked like a miracle! I can retrieve data from external website &lt;em&gt;AND extract data from HTML in one function call&lt;/em&gt;, wow! Now I am sick of it.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Custom processing and conversions of data is painful in Google Sheets.&lt;/strong&gt; Let&amp;#39;s say you want to import just 32.22 number from &amp;quot;cost: 32.22 USD&amp;quot; string extracted from some website. It is possible to do it in Google Sheets, with some fiddling around formulas and scratching your head, but obviously it is much easier to accomplish this task Javascript or Python, especially if you have lots and lots of data to cleanup!&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;There is no proper launch and cache control in ImportXML.&lt;/strong&gt; There is no &amp;quot;scrape now&amp;quot; button in your Google Sheet. You can&amp;#39;t control how often the ImportXML is triggered (well, unless you are a huge fan of Goole Apps Script!) and if you have many cells populated with importXML, it is very easy to occasionally trigger an avalanche of external http calls when opening and editing your sheet. There are also no caching mechanisms in Google Sheets, so if the last call to ImportXML fails, the cell will get &lt;em&gt;ERR!&lt;/em&gt; value.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;ImportXML only works with basic websites&lt;/strong&gt; (no SPAs rendered in browsers can be scraped this way, any basic web scraping protection or connectivity issue breaks the process, no control over HTTP request geo location, or number of retries)&lt;/p&gt;\n\n&lt;p&gt;ImportXML just fails to extract data from a huge amount of websites for me.&lt;/p&gt;\n\n&lt;p&gt;I have finally found an alternative solution which I have been using for some time, it&amp;#39;s more complicated to start but is just infinitely flexible and it just.. works for web scraping. My recipe consists of two ingredients:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Proper automation framework: I choose &lt;a href=\"https://make.com/\"&gt;Make.com&lt;/a&gt; because it is essentially a cheaper and more techy Zapier competitor, it is mature, and it works great. Free plan.&lt;/li&gt;\n&lt;li&gt;Web scraping API: I use &lt;a href=\"https://scrapeninja.net/\"&gt;ScrapeNinja.net&lt;/a&gt; because it allows to write custom Javascript extractors which allow me to extract any data from infinitely complex HTML of the target website, and convert it into arbitrary JSON structure for later usage. It has free plan. &lt;strong&gt;And it can render SPAs like a real browser.&lt;/strong&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I am now using Google Sheets like a plain, stupid database - read data, write data back. No external HTTP calls.&lt;/p&gt;\n\n&lt;p&gt;Here is my recipe in action: &lt;a href=\"https://youtu.be/Uu1uw_koznA\"&gt;&lt;strong&gt;https://youtu.be/Uu1uw_koznA&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zq1bef", "is_robot_indexable": true, "report_reasons": null, "author": "superjet1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zq1bef/i_am_sick_of_google_sheets_importxml_and_i_have/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zq1bef/i_am_sick_of_google_sheets_importxml_and_i_have/", "subreddit_subscribers": 828633, "created_utc": 1671478778.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What are the tools that you're using for analyzing texts, survey responses, research abstracts \u2014\u00a0something affordable and that provides good results? \n\nI am aware of NetBase Quid and [Primer.Ai](https://Primer.Ai), but their prices start at tens thousands $$$ a year. Then I know some tools like [https://textrazor.com/](https://textrazor.com/) but it's too technical and works through an API. [https://voyant-tools.org/](https://voyant-tools.org/) is free but not suited to work with survey responses and multiple snippets of data...\n\nThanks!", "author_fullname": "t2_1rpr94lc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are affordable tools for self-employed data scientists who work with text?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zqmgyu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671537280.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the tools that you&amp;#39;re using for analyzing texts, survey responses, research abstracts \u2014\u00a0something affordable and that provides good results? &lt;/p&gt;\n\n&lt;p&gt;I am aware of NetBase Quid and &lt;a href=\"https://Primer.Ai\"&gt;Primer.Ai&lt;/a&gt;, but their prices start at tens thousands $$$ a year. Then I know some tools like &lt;a href=\"https://textrazor.com/\"&gt;https://textrazor.com/&lt;/a&gt; but it&amp;#39;s too technical and works through an API. &lt;a href=\"https://voyant-tools.org/\"&gt;https://voyant-tools.org/&lt;/a&gt; is free but not suited to work with survey responses and multiple snippets of data...&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zqmgyu", "is_robot_indexable": true, "report_reasons": null, "author": "noduslabs", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zqmgyu/what_are_affordable_tools_for_selfemployed_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zqmgyu/what_are_affordable_tools_for_selfemployed_data/", "subreddit_subscribers": 828633, "created_utc": 1671537280.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys,\n\nRecently I got shortlisted for the position of data scientist in a govt. Org. And they have asked all the shortlisted candidates to complete a take home test which would be provided at a particular date. \n\nSo. \n\nI turn to you for help. \n\nThis is the first time I'm doing a take home test, so if you guys give me an idea as to what to expect and what are dos and don'ts for these things. \n\nAny insights that you might be able to provide would be much appreciated. \n\nThanks", "author_fullname": "t2_jo4irqsu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "what to expect for a data science take home test?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zqhyj1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671521446.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,&lt;/p&gt;\n\n&lt;p&gt;Recently I got shortlisted for the position of data scientist in a govt. Org. And they have asked all the shortlisted candidates to complete a take home test which would be provided at a particular date. &lt;/p&gt;\n\n&lt;p&gt;So. &lt;/p&gt;\n\n&lt;p&gt;I turn to you for help. &lt;/p&gt;\n\n&lt;p&gt;This is the first time I&amp;#39;m doing a take home test, so if you guys give me an idea as to what to expect and what are dos and don&amp;#39;ts for these things. &lt;/p&gt;\n\n&lt;p&gt;Any insights that you might be able to provide would be much appreciated. &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "zqhyj1", "is_robot_indexable": true, "report_reasons": null, "author": "thanderrine", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zqhyj1/what_to_expect_for_a_data_science_take_home_test/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zqhyj1/what_to_expect_for_a_data_science_take_home_test/", "subreddit_subscribers": 828633, "created_utc": 1671521446.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello Dear reditors, \nSome posts exist about this topic, but are at minimum 2years old, and our job evolves fast... \n\nI approach 3 years of experience, and in the market I am in (France) it might be a time where you'll be promoted from junior to senior. From what I've seen in the market so far, the title are \"data scientist\", \"senior datascientist\", \"lead datascientist\", with respectively 0y of experience, 3-5y of experience, 5-8 y\n\nAnyway, according to you, what distinguishes a junior from a senior (or vice versa?)\n\nSecond question : is it common that decisions are taken solely based on a junior, or is it more a thing for senior/lead? I am basically the only DS in my company. For modeling, A/B testing, statistical analysis, I do everything from interviewing the \"clients\", I design the solution, model it, help our DE putting it in production,present it back to C levels. The only lead DS I've encountered in the company is a consultant and works alone on a specific project (and only that one) . I've had 2hours maximum with him in 8months. \n\nThank you in advance for your help!", "author_fullname": "t2_bl8dhx5v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DS position ladder : junior, mid, lead...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zqhaoc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671519339.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Dear reditors, \nSome posts exist about this topic, but are at minimum 2years old, and our job evolves fast... &lt;/p&gt;\n\n&lt;p&gt;I approach 3 years of experience, and in the market I am in (France) it might be a time where you&amp;#39;ll be promoted from junior to senior. From what I&amp;#39;ve seen in the market so far, the title are &amp;quot;data scientist&amp;quot;, &amp;quot;senior datascientist&amp;quot;, &amp;quot;lead datascientist&amp;quot;, with respectively 0y of experience, 3-5y of experience, 5-8 y&lt;/p&gt;\n\n&lt;p&gt;Anyway, according to you, what distinguishes a junior from a senior (or vice versa?)&lt;/p&gt;\n\n&lt;p&gt;Second question : is it common that decisions are taken solely based on a junior, or is it more a thing for senior/lead? I am basically the only DS in my company. For modeling, A/B testing, statistical analysis, I do everything from interviewing the &amp;quot;clients&amp;quot;, I design the solution, model it, help our DE putting it in production,present it back to C levels. The only lead DS I&amp;#39;ve encountered in the company is a consultant and works alone on a specific project (and only that one) . I&amp;#39;ve had 2hours maximum with him in 8months. &lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zqhaoc", "is_robot_indexable": true, "report_reasons": null, "author": "Zealousideal-Yak5547", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zqhaoc/ds_position_ladder_junior_mid_lead/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zqhaoc/ds_position_ladder_junior_mid_lead/", "subreddit_subscribers": 828633, "created_utc": 1671519339.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_jeooiop5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "3D COMPARISON: HEAT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_zqdaub", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/cAkv60mjBeY?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"3D COMPARISON: HEAT\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "3D COMPARISON: HEAT", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/cAkv60mjBeY?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"3D COMPARISON: HEAT\"&gt;&lt;/iframe&gt;", "author_name": "Data Centre", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/cAkv60mjBeY/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@SangamNews"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/cAkv60mjBeY?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"3D COMPARISON: HEAT\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/zqdaub", "height": 200}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/SizGoz-LMOWtC8YQDoyzPOMUmbBqvzesmuXTYoVuF40.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671507729.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://youtube.com/watch?v=cAkv60mjBeY&amp;feature=share", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7N_GFyBL45tdZJ3-ow9eFzDkBbotq-LyV_8L-zzBKRg.jpg?auto=webp&amp;s=6b5a6e7803c74e7b6958090db9c6543e87f0f554", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/7N_GFyBL45tdZJ3-ow9eFzDkBbotq-LyV_8L-zzBKRg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e49dd0f3afb2e7dc2cc4e0d180f3bd49167993da", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/7N_GFyBL45tdZJ3-ow9eFzDkBbotq-LyV_8L-zzBKRg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3e1b5db68c435d81df97db5fad5a30e5144e732e", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/7N_GFyBL45tdZJ3-ow9eFzDkBbotq-LyV_8L-zzBKRg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8635843bc0928602ba03f7d58005a7c71e5e05a0", "width": 320, "height": 240}], "variants": {}, "id": "id0-g2W7ehunak_bDv4VEuYhmixZbbr-ZhJaRmUl4jk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "zqdaub", "is_robot_indexable": true, "report_reasons": null, "author": "guptasangam", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zqdaub/3d_comparison_heat/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtube.com/watch?v=cAkv60mjBeY&amp;feature=share", "subreddit_subscribers": 828633, "created_utc": 1671507729.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "3D COMPARISON: HEAT", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/cAkv60mjBeY?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"3D COMPARISON: HEAT\"&gt;&lt;/iframe&gt;", "author_name": "Data Centre", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/cAkv60mjBeY/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@SangamNews"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone,\n\nI've been laid off for about 2 months now and recently just got a job offer. The company is located in the UK and I am located in the US. The contract states I would be an \"independent contractor\" not an \"employee\" and the pay is in GBP and there is no healthcare offered.\n\nWhat does independent contrator mean? Is this a standard practice for hiring somebody from a foreign country? What does this mean for my taxes? Should I even take this job? Thanks!", "author_fullname": "t2_mmsqh3aw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Got offered a job but as an independent contractor ? help!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zq5t69", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671489213.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been laid off for about 2 months now and recently just got a job offer. The company is located in the UK and I am located in the US. The contract states I would be an &amp;quot;independent contractor&amp;quot; not an &amp;quot;employee&amp;quot; and the pay is in GBP and there is no healthcare offered.&lt;/p&gt;\n\n&lt;p&gt;What does independent contrator mean? Is this a standard practice for hiring somebody from a foreign country? What does this mean for my taxes? Should I even take this job? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zq5t69", "is_robot_indexable": true, "report_reasons": null, "author": "almightynem", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zq5t69/got_offered_a_job_but_as_an_independent/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zq5t69/got_offered_a_job_but_as_an_independent/", "subreddit_subscribers": 828633, "created_utc": 1671489213.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So im trying to train a tensorflow multoheaded neural network, passed and POC and everything works fine. However, the pipeline in our team is based on sklearn pipelines. I tried to figure out a way to split the labels from two dimensional numpy array to lists, and pass it through the pipeline but it doesnt work well, the transformers expect ndarrays and not list of arrays. Any advice?", "author_fullname": "t2_rq3qsw3g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scikit learn multioutput pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zq542n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671487584.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So im trying to train a tensorflow multoheaded neural network, passed and POC and everything works fine. However, the pipeline in our team is based on sklearn pipelines. I tried to figure out a way to split the labels from two dimensional numpy array to lists, and pass it through the pipeline but it doesnt work well, the transformers expect ndarrays and not list of arrays. Any advice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zq542n", "is_robot_indexable": true, "report_reasons": null, "author": "No-Front-4346", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zq542n/scikit_learn_multioutput_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zq542n/scikit_learn_multioutput_pipelines/", "subreddit_subscribers": 828633, "created_utc": 1671487584.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Say I build a classification model with a training dataset that has a column Favourite Colour which has values Yellow, Red, and Blue. Then there is the dependent variable column Gender which has values 0 - for Male, and 1 - for Female. After categorical encoding the Favourite Colour column I'll end up with 2 Independent variable (IV) columns (as we drop one column cause of the dummy variable trap). \n\nBut then in a new test dataset the Favourite Color column only contains values Red, and Blue. After encoding I'll then have 1 IV column, but my model was trained on a dataset with 2 IVs. How will my model be able to run considering the input size is now different?\n\nI know that I have run into this problem when creating a Random Forest Model (it throws an array that the model was expecting a certain input size but got a different one), but I am asking about models in general.\n\nThanks", "author_fullname": "t2_frwys", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do to do when test input size is not the same as training input size?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zq3wnd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671484810.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Say I build a classification model with a training dataset that has a column Favourite Colour which has values Yellow, Red, and Blue. Then there is the dependent variable column Gender which has values 0 - for Male, and 1 - for Female. After categorical encoding the Favourite Colour column I&amp;#39;ll end up with 2 Independent variable (IV) columns (as we drop one column cause of the dummy variable trap). &lt;/p&gt;\n\n&lt;p&gt;But then in a new test dataset the Favourite Color column only contains values Red, and Blue. After encoding I&amp;#39;ll then have 1 IV column, but my model was trained on a dataset with 2 IVs. How will my model be able to run considering the input size is now different?&lt;/p&gt;\n\n&lt;p&gt;I know that I have run into this problem when creating a Random Forest Model (it throws an array that the model was expecting a certain input size but got a different one), but I am asking about models in general.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zq3wnd", "is_robot_indexable": true, "report_reasons": null, "author": "fouried96", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zq3wnd/what_do_to_do_when_test_input_size_is_not_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zq3wnd/what_do_to_do_when_test_input_size_is_not_the/", "subreddit_subscribers": 828633, "created_utc": 1671484810.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_c25i55k3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a digital library of data science books. I have looked at Kindle Unlimited and Scribd. Does anyone know of an good source to read / refer to data science books?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zq2xer", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671482525.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zq2xer", "is_robot_indexable": true, "report_reasons": null, "author": "moltra_1", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zq2xer/looking_for_a_digital_library_of_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zq2xer/looking_for_a_digital_library_of_data_science/", "subreddit_subscribers": 828633, "created_utc": 1671482525.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello all hoping someone can answer this question. \n\nI am working on a project where health care providers will be collecting data about the patient. The patient is fully aware we are collecting the data as part of the program. My organization is not HIPAA compliment so we need all data de-identified. \n\n\nWhat way can this be done? The offices will be sending me monthly blood pressure updates so they have to be able to look at the chart and be able to determine which patient is which I can\u2019t just number them 1-100 or something. My first thought was patient first/last name initial plus birth day/month but I believe for hipaa that is not stripped enough. Appreciate the help and fully understand y\u2019all are not lawyers but I am not finding any concrete resources online!", "author_fullname": "t2_3bxtfsum", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "De-Identify Health Info", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zq2ike", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671481536.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all hoping someone can answer this question. &lt;/p&gt;\n\n&lt;p&gt;I am working on a project where health care providers will be collecting data about the patient. The patient is fully aware we are collecting the data as part of the program. My organization is not HIPAA compliment so we need all data de-identified. &lt;/p&gt;\n\n&lt;p&gt;What way can this be done? The offices will be sending me monthly blood pressure updates so they have to be able to look at the chart and be able to determine which patient is which I can\u2019t just number them 1-100 or something. My first thought was patient first/last name initial plus birth day/month but I believe for hipaa that is not stripped enough. Appreciate the help and fully understand y\u2019all are not lawyers but I am not finding any concrete resources online!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zq2ike", "is_robot_indexable": true, "report_reasons": null, "author": "HPGOTTOP", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zq2ike/deidentify_health_info/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zq2ike/deidentify_health_info/", "subreddit_subscribers": 828633, "created_utc": 1671481536.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What are your experience with recruiters and which ones have you worked with? \nI\u2019m changing careers. I have contract data science and contract analytics engineer roles on my resume after my last career. A bit less than a year total. But I\u2019m having trouble getting interviews. Would a recruiter give me their time, do you think?", "author_fullname": "t2_nwog5zl6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which recruiters to work with?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zq1853", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671478569.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are your experience with recruiters and which ones have you worked with? \nI\u2019m changing careers. I have contract data science and contract analytics engineer roles on my resume after my last career. A bit less than a year total. But I\u2019m having trouble getting interviews. Would a recruiter give me their time, do you think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "zq1853", "is_robot_indexable": true, "report_reasons": null, "author": "Delicious-Cicada9307", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zq1853/which_recruiters_to_work_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zq1853/which_recruiters_to_work_with/", "subreddit_subscribers": 828633, "created_utc": 1671478569.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi there,\n\nBeing into the topic of web scraping and deep learning lately, I am asking myself how well the two topics could be combined. How feasible would it for example be to build a deep learning model that could extract the relevant information from a screenshot of a website? More generally, I would say that a lot of e-commerce sites are build up almost the same way (structure and product display) when it comes to their visual appearance. Would it here be possibel to build and train a generalizable model that could extract the necessary product information of other e-commerce sites by getting a screenshot of a page as input? Additionally, what architecture would you probably use, a RNN like model and are there already similar solutions?", "author_fullname": "t2_qrf0fsnc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Web scraping with Deep Learning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zq133q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671478248.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there,&lt;/p&gt;\n\n&lt;p&gt;Being into the topic of web scraping and deep learning lately, I am asking myself how well the two topics could be combined. How feasible would it for example be to build a deep learning model that could extract the relevant information from a screenshot of a website? More generally, I would say that a lot of e-commerce sites are build up almost the same way (structure and product display) when it comes to their visual appearance. Would it here be possibel to build and train a generalizable model that could extract the necessary product information of other e-commerce sites by getting a screenshot of a page as input? Additionally, what architecture would you probably use, a RNN like model and are there already similar solutions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zq133q", "is_robot_indexable": true, "report_reasons": null, "author": "Odd-Concert-4591", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zq133q/web_scraping_with_deep_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zq133q/web_scraping_with_deep_learning/", "subreddit_subscribers": 828633, "created_utc": 1671478248.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_sppgx30r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Docker Basics and data science devops integration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_zpwh4l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/2_YGrAbX5Ck?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Master Docker in 30 Minutes | Introduction, Architecture and Commands | DevOps Tutorial\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Master Docker in 30 Minutes | Introduction, Architecture and Commands | DevOps Tutorial", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/2_YGrAbX5Ck?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Master Docker in 30 Minutes | Introduction, Architecture and Commands | DevOps Tutorial\"&gt;&lt;/iframe&gt;", "author_name": " Code with Scaler", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/2_YGrAbX5Ck/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@CodewithScaler"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/2_YGrAbX5Ck?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Master Docker in 30 Minutes | Introduction, Architecture and Commands | DevOps Tutorial\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/zpwh4l", "height": 200}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/m_6y3EPsbFDjMWkt1rdzJfxIR5Bf41vvNAlrbuEtqD4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671468089.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/2_YGrAbX5Ck", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ujSq04ppJ8wTypANKd9k2bxbgTcyjUbdhPgBuCMH020.jpg?auto=webp&amp;s=9dc857126f2b0d16487bd3dae962f3a7bda5e1f2", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/ujSq04ppJ8wTypANKd9k2bxbgTcyjUbdhPgBuCMH020.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=565c6585b4be6cee9720f692fe84acdcfff628ad", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/ujSq04ppJ8wTypANKd9k2bxbgTcyjUbdhPgBuCMH020.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e2bd6ef8689bd8d18c6c9de9e1b97d8fc0053f05", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/ujSq04ppJ8wTypANKd9k2bxbgTcyjUbdhPgBuCMH020.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=be10cf13c2888e562e2e34b63a87404281feee07", "width": 320, "height": 240}], "variants": {}, "id": "KabfInI-6CSIuonyYX_CsxqIFlsvM_q4cIuXIpJXy_I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "zpwh4l", "is_robot_indexable": true, "report_reasons": null, "author": "thetech_learner", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zpwh4l/docker_basics_and_data_science_devops_integration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/2_YGrAbX5Ck", "subreddit_subscribers": 828633, "created_utc": 1671468089.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Master Docker in 30 Minutes | Introduction, Architecture and Commands | DevOps Tutorial", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/2_YGrAbX5Ck?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Master Docker in 30 Minutes | Introduction, Architecture and Commands | DevOps Tutorial\"&gt;&lt;/iframe&gt;", "author_name": " Code with Scaler", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/2_YGrAbX5Ck/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@CodewithScaler"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello Everyone. I hope guys are doing well. I am about to start a new job as a data analyst with major focus on building dashboards in various tools like Excel, Microsoft PowerBI and Tableau to derive meaningful insights while I am also tasked with making executive level presentations displaying those insights strategically.\n\nMy question is that what frameworks, methods or processes do I follow to derive those insights in the 1st place? Any suggestions would be highly helpful.", "author_fullname": "t2_lw641n38", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I derive meaningful insights from a raw database?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zpsxpf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671459828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone. I hope guys are doing well. I am about to start a new job as a data analyst with major focus on building dashboards in various tools like Excel, Microsoft PowerBI and Tableau to derive meaningful insights while I am also tasked with making executive level presentations displaying those insights strategically.&lt;/p&gt;\n\n&lt;p&gt;My question is that what frameworks, methods or processes do I follow to derive those insights in the 1st place? Any suggestions would be highly helpful.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "zpsxpf", "is_robot_indexable": true, "report_reasons": null, "author": "The_Alexander_3141", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/zpsxpf/how_do_i_derive_meaningful_insights_from_a_raw/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/zpsxpf/how_do_i_derive_meaningful_insights_from_a_raw/", "subreddit_subscribers": 828633, "created_utc": 1671459828.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}