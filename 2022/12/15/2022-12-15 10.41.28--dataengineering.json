{"kind": "Listing", "data": {"after": null, "dist": 14, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been reading the data warehouse toolkit as well as data engineering blog posts but I'm still having a hard time fleshing out a full picture of how everything integrates. Are there any really good resources that show a \"real-world\" data pipeline being built out? From modeling the data to designing the ETL/ELT pipeline to distributing the data via a data mart or dataset?  \n\nIdeally, a guide or two that show how this would be applied on-prem as well as in the cloud would be helpful.", "author_fullname": "t2_nhdew", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any really good end-to-end walkthroughs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zltid3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 100, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 100, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671030752.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been reading the data warehouse toolkit as well as data engineering blog posts but I&amp;#39;m still having a hard time fleshing out a full picture of how everything integrates. Are there any really good resources that show a &amp;quot;real-world&amp;quot; data pipeline being built out? From modeling the data to designing the ETL/ELT pipeline to distributing the data via a data mart or dataset?  &lt;/p&gt;\n\n&lt;p&gt;Ideally, a guide or two that show how this would be applied on-prem as well as in the cloud would be helpful.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zltid3", "is_robot_indexable": true, "report_reasons": null, "author": "MonkeyMaster64", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zltid3/any_really_good_endtoend_walkthroughs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zltid3/any_really_good_endtoend_walkthroughs/", "subreddit_subscribers": 82973, "created_utc": 1671030752.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_uyypntfr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recently laid off, please review my Resume and throw me some hard truths! Interested in Data Engineer/Science roles. Thanks! (~1 Year of FT experience)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_zlvtte", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 67, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 67, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/iYD6KdXdbhHPCKltV-AGkcIjduCshG_YsZ7bpCSm_-I.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671036375.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/wlb5dn0k7w5a1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/wlb5dn0k7w5a1.png?auto=webp&amp;v=enabled&amp;s=66b1e2c0cf90be74b58a960b8e9fb3ecb9140fdb", "width": 1009, "height": 1287}, "resolutions": [{"url": "https://preview.redd.it/wlb5dn0k7w5a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=09708a9db65ec6a152c6dd8763eef769224b27a9", "width": 108, "height": 137}, {"url": "https://preview.redd.it/wlb5dn0k7w5a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e6c9db823f22f16a432a7d97d00b9d06f9f701b6", "width": 216, "height": 275}, {"url": "https://preview.redd.it/wlb5dn0k7w5a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b50be64de44ba703ed7af7962cfb3e6e20869dae", "width": 320, "height": 408}, {"url": "https://preview.redd.it/wlb5dn0k7w5a1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ba91ca86d6d00c0c42428b173771a3d45741d5b3", "width": 640, "height": 816}, {"url": "https://preview.redd.it/wlb5dn0k7w5a1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b2c4ff91547d8f55720d586a86d00302cb80f0ab", "width": 960, "height": 1224}], "variants": {}, "id": "KpKLL9X-Sku68vV72ubLy39J3ApK8l-g4SlT_cJxp9M"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "zlvtte", "is_robot_indexable": true, "report_reasons": null, "author": "throw_me_away_2424", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zlvtte/recently_laid_off_please_review_my_resume_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/wlb5dn0k7w5a1.png", "subreddit_subscribers": 82973, "created_utc": 1671036375.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Background: We are trying to implement incremental ingestion using AWS DMS to fetch the changes from SQL Server (RDS) and write those changes to S3 and then use spark DLT to ingest and merge those changes to the final raw delta tables.  \n\nWe have enabled CDC in the SQL server at both DB and table levels for this to happen. This truned DB status to storage full. Looks like TLog is taking up all the space. What's causing TLog to fill up and not truncate? How does enabling the CDC block TLog truncation? What can we do to avoid (automatically) this in the future?", "author_fullname": "t2_2adeipr4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Issues with implementing incremental ingestion in SQL Server (TLog full)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zm6xe0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671063693.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Background: We are trying to implement incremental ingestion using AWS DMS to fetch the changes from SQL Server (RDS) and write those changes to S3 and then use spark DLT to ingest and merge those changes to the final raw delta tables.  &lt;/p&gt;\n\n&lt;p&gt;We have enabled CDC in the SQL server at both DB and table levels for this to happen. This truned DB status to storage full. Looks like TLog is taking up all the space. What&amp;#39;s causing TLog to fill up and not truncate? How does enabling the CDC block TLog truncation? What can we do to avoid (automatically) this in the future?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zm6xe0", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Outlandishness-74", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zm6xe0/issues_with_implementing_incremental_ingestion_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zm6xe0/issues_with_implementing_incremental_ingestion_in/", "subreddit_subscribers": 82973, "created_utc": 1671063693.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "# 1. Define schemas.\n\nA schema defines the structure of your data. The fields and types the other side expects to receive. Having well-defined schemas and a single source of truth that store all your different models is a must as you scale and more interfaces join the party and request to consume from different data sources.\n\nAs schema changes will be requested, you would only need to perform the change once. \n\n# 2. Enforce.\n\nYou have to govern, or you will lose control. If you made a data contract both theoretically or technically, you need to enforce it.  \nEnsure data will not reach clients in a way they didn\u2019t ask for.\n\n# 3. Dedicated identity per client.\n\nAs your organization grows, more and more \u201chands\u201d will request to interact with the ingested data. It can be different clients, applications, and/or stakeholders.  \nMake sure each client receives a unique identity that can be traced and monitored, and in case some data-level / infra-level occurred, you would know who got affected, from which team, and the business impact instantly. It will help reach root-cause much faster than shooting slack messages and emails to the entire organization.\n\n# 4. Auditing.\n\nIn a federated architecture and data pipelines, where multiple domains, teams, and clients are often intertwined, one configuration change can create a chain of reactions that ultimately will crash the entire process. Auditing is crucial to ensure you approach the upstream rather than the middle.\n\n# 5. Notifications.\n\nLast but not least, notifications. Don\u2019t react when your staging environment or your tables/documents are already unaligned, or backends start to crash. Make sure you have notifications configured in every step of your pipeline. You get notified immediately if something goes wrong and data is not ingested as it should. Combining dedicated identity with auditing and a clear notification will enable you to sleep better. In case you awaken in the middle of the night, it will be for a short time and with all the information needed to fix it.\n\n&amp;#x200B;\n\nSource: [https://medium.com/memphis-dev/five-methods-to-increase-governance-over-your-data-clients-4eb7423510d6](https://medium.com/memphis-dev/five-methods-to-increase-governance-over-your-data-clients-4eb7423510d6)", "author_fullname": "t2_bqjrmnud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Five methods to increase governance over your data clients", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zluj0s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1671033219.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;1. Define schemas.&lt;/h1&gt;\n\n&lt;p&gt;A schema defines the structure of your data. The fields and types the other side expects to receive. Having well-defined schemas and a single source of truth that store all your different models is a must as you scale and more interfaces join the party and request to consume from different data sources.&lt;/p&gt;\n\n&lt;p&gt;As schema changes will be requested, you would only need to perform the change once. &lt;/p&gt;\n\n&lt;h1&gt;2. Enforce.&lt;/h1&gt;\n\n&lt;p&gt;You have to govern, or you will lose control. If you made a data contract both theoretically or technically, you need to enforce it.&lt;br/&gt;\nEnsure data will not reach clients in a way they didn\u2019t ask for.&lt;/p&gt;\n\n&lt;h1&gt;3. Dedicated identity per client.&lt;/h1&gt;\n\n&lt;p&gt;As your organization grows, more and more \u201chands\u201d will request to interact with the ingested data. It can be different clients, applications, and/or stakeholders.&lt;br/&gt;\nMake sure each client receives a unique identity that can be traced and monitored, and in case some data-level / infra-level occurred, you would know who got affected, from which team, and the business impact instantly. It will help reach root-cause much faster than shooting slack messages and emails to the entire organization.&lt;/p&gt;\n\n&lt;h1&gt;4. Auditing.&lt;/h1&gt;\n\n&lt;p&gt;In a federated architecture and data pipelines, where multiple domains, teams, and clients are often intertwined, one configuration change can create a chain of reactions that ultimately will crash the entire process. Auditing is crucial to ensure you approach the upstream rather than the middle.&lt;/p&gt;\n\n&lt;h1&gt;5. Notifications.&lt;/h1&gt;\n\n&lt;p&gt;Last but not least, notifications. Don\u2019t react when your staging environment or your tables/documents are already unaligned, or backends start to crash. Make sure you have notifications configured in every step of your pipeline. You get notified immediately if something goes wrong and data is not ingested as it should. Combining dedicated identity with auditing and a clear notification will enable you to sleep better. In case you awaken in the middle of the night, it will be for a short time and with all the information needed to fix it.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Source: &lt;a href=\"https://medium.com/memphis-dev/five-methods-to-increase-governance-over-your-data-clients-4eb7423510d6\"&gt;https://medium.com/memphis-dev/five-methods-to-increase-governance-over-your-data-clients-4eb7423510d6&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/r63d0peK7lR4hC-TgNGij3atmde2nRzwT52TjWbR1FE.jpg?auto=webp&amp;v=enabled&amp;s=050b22d042d9f08091aad6e45e7e846a107a1a5f", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/r63d0peK7lR4hC-TgNGij3atmde2nRzwT52TjWbR1FE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5d0435823d970aaec969980f55114d8e64723c8d", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/r63d0peK7lR4hC-TgNGij3atmde2nRzwT52TjWbR1FE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6cad6a166590b366b3eb10440f225fc290909c79", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/r63d0peK7lR4hC-TgNGij3atmde2nRzwT52TjWbR1FE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=63288dbd31e8da3a4f47eb9cc9aa1bd74b802010", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/r63d0peK7lR4hC-TgNGij3atmde2nRzwT52TjWbR1FE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c75e2c7bb99042534b77d93f834fe12084e19a5b", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/r63d0peK7lR4hC-TgNGij3atmde2nRzwT52TjWbR1FE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=22216e9dc1bad0db47cb1e35ff37a447c7cb4627", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/r63d0peK7lR4hC-TgNGij3atmde2nRzwT52TjWbR1FE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=189ed93707cbe92fad81537b9cdfa3f16b417c7d", "width": 1080, "height": 607}], "variants": {}, "id": "wnRFDkKH4_zSESjf-dKgPIz6PGGNHscbt6D41poYtBM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zluj0s", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering_Bug105", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zluj0s/five_methods_to_increase_governance_over_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zluj0s/five_methods_to_increase_governance_over_your/", "subreddit_subscribers": 82973, "created_utc": 1671033219.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nWould greatly appreciate to have career advice?\n\nI am majoring in Finance with a concentration in investment analysis and will be graduating in May 2023. I am 26 year old.\n\nI did an internship with Raymond James this summer in the Mutual Fund and ETF research team. And current doing an internship at a SearchFund company as an unpaid private equity intern. \n\nI have been talking to my friends who are studying data engineering, which made me realize that I like technology and technical skills, and it also would suit me best since English is my second language. I have been in touch with my finance professor to see if I should do an M.S. in computer science to start my career over. He told me not to because he saw more people regret pursuing a master's and Ph.D. than getting a job and making a slow transition. \n\nI am currently enrolled in a data science BootCamp and taking five classes. I am fresh to computer science. \n\nI wonder what possible ways for me to land a data engineering job or something data related to making a smooth transition since I will graduate in May of 2023.\n\nThank you.", "author_fullname": "t2_fqu0xxky", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Senior Finance student to Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zmdv9p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671084536.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;Would greatly appreciate to have career advice?&lt;/p&gt;\n\n&lt;p&gt;I am majoring in Finance with a concentration in investment analysis and will be graduating in May 2023. I am 26 year old.&lt;/p&gt;\n\n&lt;p&gt;I did an internship with Raymond James this summer in the Mutual Fund and ETF research team. And current doing an internship at a SearchFund company as an unpaid private equity intern. &lt;/p&gt;\n\n&lt;p&gt;I have been talking to my friends who are studying data engineering, which made me realize that I like technology and technical skills, and it also would suit me best since English is my second language. I have been in touch with my finance professor to see if I should do an M.S. in computer science to start my career over. He told me not to because he saw more people regret pursuing a master&amp;#39;s and Ph.D. than getting a job and making a slow transition. &lt;/p&gt;\n\n&lt;p&gt;I am currently enrolled in a data science BootCamp and taking five classes. I am fresh to computer science. &lt;/p&gt;\n\n&lt;p&gt;I wonder what possible ways for me to land a data engineering job or something data related to making a smooth transition since I will graduate in May of 2023.&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zmdv9p", "is_robot_indexable": true, "report_reasons": null, "author": "SangThai6879", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zmdv9p/senior_finance_student_to_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zmdv9p/senior_finance_student_to_data_engineering/", "subreddit_subscribers": 82973, "created_utc": 1671084536.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am starting a new position and need to get up to speed on this new stack:  \nPrefect - dbt - Snowflake  \nWith an emphasis on Snowflake first\n\nWhat are some good resources **that you may recommend** to learn quickly and with best-practices in mind? I can some $ for online courses\n\nbackground: extensive SQL Server, some python ETL. No dbt or orchestration tool, but plenty comfortable with yaml from docker and ci/cd tools.", "author_fullname": "t2_qhsi5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "need learning recommendations for Snowflake, dbt, prefect", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zlv893", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671034908.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am starting a new position and need to get up to speed on this new stack:&lt;br/&gt;\nPrefect - dbt - Snowflake&lt;br/&gt;\nWith an emphasis on Snowflake first&lt;/p&gt;\n\n&lt;p&gt;What are some good resources &lt;strong&gt;that you may recommend&lt;/strong&gt; to learn quickly and with best-practices in mind? I can some $ for online courses&lt;/p&gt;\n\n&lt;p&gt;background: extensive SQL Server, some python ETL. No dbt or orchestration tool, but plenty comfortable with yaml from docker and ci/cd tools.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zlv893", "is_robot_indexable": true, "report_reasons": null, "author": "NoUsernames1eft", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zlv893/need_learning_recommendations_for_snowflake_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zlv893/need_learning_recommendations_for_snowflake_dbt/", "subreddit_subscribers": 82973, "created_utc": 1671034908.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I am building ETL batch pipeline to transfer data from AWS RDS (MySQL) to Salesforce on daily basis. Now I am confused how should I approach this. Should I build everything locally and then deploy the container into AWS or should build my pipeline on the AWS using different services?\n\nPlease give me your suggestion.\n\nThanks!", "author_fullname": "t2_udvutrbv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Aws services or local development", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zlpbh3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "spoiler", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671019799.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I am building ETL batch pipeline to transfer data from AWS RDS (MySQL) to Salesforce on daily basis. Now I am confused how should I approach this. Should I build everything locally and then deploy the container into AWS or should build my pipeline on the AWS using different services?&lt;/p&gt;\n\n&lt;p&gt;Please give me your suggestion.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": true, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zlpbh3", "is_robot_indexable": true, "report_reasons": null, "author": "Usamacheema12345", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zlpbh3/aws_services_or_local_development/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zlpbh3/aws_services_or_local_development/", "subreddit_subscribers": 82973, "created_utc": 1671019799.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a recent CS graduate and I managed to work with a few languages to keep myself open to whichever route I ended up committing to. Therefore, at uni, I learnt (not mastered): \n\n* Python\n* Java\n* PHP \n* MySQL\n* HTML and CSS\n* JavaScript\n\nThe main issue I find with my CV is that for DE roles, the most useful *languages* I could put are Python and MySQL. I was going to learn a bit of Go but I've decided to start tinkering with PySpark instead. I've played around with pandas this past year with my courses. \n\nMy Skills section isn't as good as many CVs I've seen, so not sure how to go with things. I'm thinking of removing HTML, CSS and JavaScript from the list of languages, perhaps PHP too, which leaves me with just Python, Java and MySQL. My Java isn't as good, so I might just end up removing it.\n\nHere is how it looks: https://imgur.com/a/vKHRUV6\n\n***\n\nTo make my life easier, what things do you guys recommend me to learn while I'm applying for jobs? \n\nI wasn't taught cloud technologies, DevOps or most technologies I'm seeing floating around as well. Again, I'm going to be learning PySpark but not sure what else I could need?", "author_fullname": "t2_5902cw6k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lack of \"Languages\" to show on CV", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zlqqu4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1671024234.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1671023952.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a recent CS graduate and I managed to work with a few languages to keep myself open to whichever route I ended up committing to. Therefore, at uni, I learnt (not mastered): &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Python&lt;/li&gt;\n&lt;li&gt;Java&lt;/li&gt;\n&lt;li&gt;PHP &lt;/li&gt;\n&lt;li&gt;MySQL&lt;/li&gt;\n&lt;li&gt;HTML and CSS&lt;/li&gt;\n&lt;li&gt;JavaScript&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The main issue I find with my CV is that for DE roles, the most useful &lt;em&gt;languages&lt;/em&gt; I could put are Python and MySQL. I was going to learn a bit of Go but I&amp;#39;ve decided to start tinkering with PySpark instead. I&amp;#39;ve played around with pandas this past year with my courses. &lt;/p&gt;\n\n&lt;p&gt;My Skills section isn&amp;#39;t as good as many CVs I&amp;#39;ve seen, so not sure how to go with things. I&amp;#39;m thinking of removing HTML, CSS and JavaScript from the list of languages, perhaps PHP too, which leaves me with just Python, Java and MySQL. My Java isn&amp;#39;t as good, so I might just end up removing it.&lt;/p&gt;\n\n&lt;p&gt;Here is how it looks: &lt;a href=\"https://imgur.com/a/vKHRUV6\"&gt;https://imgur.com/a/vKHRUV6&lt;/a&gt;&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;To make my life easier, what things do you guys recommend me to learn while I&amp;#39;m applying for jobs? &lt;/p&gt;\n\n&lt;p&gt;I wasn&amp;#39;t taught cloud technologies, DevOps or most technologies I&amp;#39;m seeing floating around as well. Again, I&amp;#39;m going to be learning PySpark but not sure what else I could need?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/LarpdkIBJEfaTF1erGpKG0rmh1TkiO7SRI-r7rvZSxI.jpg?auto=webp&amp;v=enabled&amp;s=c3d73e42521e8baf9e7da06988477e00085f46a4", "width": 687, "height": 93}, "resolutions": [{"url": "https://external-preview.redd.it/LarpdkIBJEfaTF1erGpKG0rmh1TkiO7SRI-r7rvZSxI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9b70ea58bbf092d187a2780899fc92b7b9fd30f8", "width": 108, "height": 14}, {"url": "https://external-preview.redd.it/LarpdkIBJEfaTF1erGpKG0rmh1TkiO7SRI-r7rvZSxI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=670c9ac286e382470ae8da71e3f966bea7daafb5", "width": 216, "height": 29}, {"url": "https://external-preview.redd.it/LarpdkIBJEfaTF1erGpKG0rmh1TkiO7SRI-r7rvZSxI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0c08bf615a6143cd95afdac97dd89017c66b4ee6", "width": 320, "height": 43}, {"url": "https://external-preview.redd.it/LarpdkIBJEfaTF1erGpKG0rmh1TkiO7SRI-r7rvZSxI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8cfff9f685ee9343730b83b6231bfdb158e34c26", "width": 640, "height": 86}], "variants": {}, "id": "nrQ-wZXIPnVL2QlZAo-94qukF8DcavHFWJmrrcTQcT4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zlqqu4", "is_robot_indexable": true, "report_reasons": null, "author": "a_bigdonger", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zlqqu4/lack_of_languages_to_show_on_cv/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zlqqu4/lack_of_languages_to_show_on_cv/", "subreddit_subscribers": 82973, "created_utc": 1671023952.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_nrfxa5al", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Get Value from Unstructured Data - Father of the Data Warehouse Bill Inmon", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_zlw3l1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/So-vd2e6WeI?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Get Value from Unstructured Data - Father of the Data Warehouse Bill Inmon\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"oembed": {"provider_url": "https://www.youtube.com/", "title": "Get Value from Unstructured Data - Father of the Data Warehouse Bill Inmon", "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/So-vd2e6WeI?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Get Value from Unstructured Data - Father of the Data Warehouse Bill Inmon\"&gt;&lt;/iframe&gt;", "thumbnail_width": 480, "height": 200, "width": 356, "version": "1.0", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/So-vd2e6WeI/hqdefault.jpg", "type": "video", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}, "type": "youtube.com"}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/So-vd2e6WeI?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Get Value from Unstructured Data - Father of the Data Warehouse Bill Inmon\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/zlw3l1", "height": 200}, "link_flair_text": "Interview", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/xGreVRIj-uTiAxuIFesiDfbGQYS84DG-20f0qCiZVdI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671037044.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/So-vd2e6WeI", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1uOXDV6V0SVpiJKI66Ovhhyw2G_XIdx4W8gtz1c5qD8.jpg?auto=webp&amp;v=enabled&amp;s=213d6faed52ce31d774bc03ea46ce7c9e8c0c763", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/1uOXDV6V0SVpiJKI66Ovhhyw2G_XIdx4W8gtz1c5qD8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e06d2a9affc835f2a91c3b5543009e0913ec2331", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/1uOXDV6V0SVpiJKI66Ovhhyw2G_XIdx4W8gtz1c5qD8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a605528e603fc9c047e0f128f46b02b1f62109a2", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/1uOXDV6V0SVpiJKI66Ovhhyw2G_XIdx4W8gtz1c5qD8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=09b4626e5e2f4bde206ad01cb7b073249bb95f60", "width": 320, "height": 240}], "variants": {}, "id": "dNQBv9cSV6v-9xtn1U5MuYVbXNQlIupj17TQNs4EA0s"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "zlw3l1", "is_robot_indexable": true, "report_reasons": null, "author": "CatanNicollo", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zlw3l1/get_value_from_unstructured_data_father_of_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/So-vd2e6WeI", "subreddit_subscribers": 82973, "created_utc": 1671037044.0, "num_crossposts": 0, "media": {"oembed": {"provider_url": "https://www.youtube.com/", "title": "Get Value from Unstructured Data - Father of the Data Warehouse Bill Inmon", "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/So-vd2e6WeI?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Get Value from Unstructured Data - Father of the Data Warehouse Bill Inmon\"&gt;&lt;/iframe&gt;", "thumbnail_width": 480, "height": 200, "width": 356, "version": "1.0", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/So-vd2e6WeI/hqdefault.jpg", "type": "video", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}, "type": "youtube.com"}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Title. \n\nPls give me some tips on how to build my resume. To be honest i havent done any personal projects related tO DE but i work with databases and on servers linux solaris aix windows. sometimes i pull data from databases. how can i go forward with this? \n\nif u have any part time work, some menial DE tasks, i would do them just for the sake of learning. I am more involved when someone assigns a task to me.", "author_fullname": "t2_ob5w9xxc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Oracle DBA wanting to switch to Data Engineering.pls read", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_zmgxk3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671096244.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title. &lt;/p&gt;\n\n&lt;p&gt;Pls give me some tips on how to build my resume. To be honest i havent done any personal projects related tO DE but i work with databases and on servers linux solaris aix windows. sometimes i pull data from databases. how can i go forward with this? &lt;/p&gt;\n\n&lt;p&gt;if u have any part time work, some menial DE tasks, i would do them just for the sake of learning. I am more involved when someone assigns a task to me.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "zmgxk3", "is_robot_indexable": true, "report_reasons": null, "author": "GenZb00m3r", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zmgxk3/oracle_dba_wanting_to_switch_to_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zmgxk3/oracle_dba_wanting_to_switch_to_data/", "subreddit_subscribers": 82973, "created_utc": 1671096244.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_sppgx30r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Docker Containerization and Devops Data Virtual machine", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_zlvbua", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/ORu4y_-u1t8?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Introduction to Containers in Docker | Virtual Machine and Containerization Explained | DevOps\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"oembed": {"provider_url": "https://www.youtube.com/", "title": "Introduction to Containers in Docker | Virtual Machine and Containerization Explained | DevOps", "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/ORu4y_-u1t8?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Introduction to Containers in Docker | Virtual Machine and Containerization Explained | DevOps\"&gt;&lt;/iframe&gt;", "thumbnail_width": 480, "height": 200, "width": 356, "version": "1.0", "author_name": " Code with Scaler", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/ORu4y_-u1t8/hqdefault.jpg", "type": "video", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@CodewithScaler"}, "type": "youtube.com"}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/ORu4y_-u1t8?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Introduction to Containers in Docker | Virtual Machine and Containerization Explained | DevOps\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/zlvbua", "height": 200}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/YaWLZi2IHf-a8KCYde3qcbgM6TU9PkBPC00Ejmp-IiA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1671035150.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/ORu4y_-u1t8", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yY0z_yNeqmzr0wNwXqAhHfeUWhmZaLyj85xQPQj2kW8.jpg?auto=webp&amp;v=enabled&amp;s=dde02dea038e1d5813dbd0b0c7023bdd6b761b9a", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/yY0z_yNeqmzr0wNwXqAhHfeUWhmZaLyj85xQPQj2kW8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=51d67dffec08168590ed738ce94e2707333a96ac", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/yY0z_yNeqmzr0wNwXqAhHfeUWhmZaLyj85xQPQj2kW8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1e060ed6e00a429ce05ae799269f8ccc8efafef7", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/yY0z_yNeqmzr0wNwXqAhHfeUWhmZaLyj85xQPQj2kW8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=664a14be06b098dbf00c93bb7cfc53067b4aaad0", "width": 320, "height": 240}], "variants": {}, "id": "sXOsexTgn_uvLmSWE74mXvXLISFjFURVBHi_tEwETI4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "zlvbua", "is_robot_indexable": true, "report_reasons": null, "author": "thetech_learner", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zlvbua/docker_containerization_and_devops_data_virtual/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/ORu4y_-u1t8", "subreddit_subscribers": 82973, "created_utc": 1671035150.0, "num_crossposts": 0, "media": {"oembed": {"provider_url": "https://www.youtube.com/", "title": "Introduction to Containers in Docker | Virtual Machine and Containerization Explained | DevOps", "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/ORu4y_-u1t8?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Introduction to Containers in Docker | Virtual Machine and Containerization Explained | DevOps\"&gt;&lt;/iframe&gt;", "thumbnail_width": 480, "height": 200, "width": 356, "version": "1.0", "author_name": " Code with Scaler", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/ORu4y_-u1t8/hqdefault.jpg", "type": "video", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@CodewithScaler"}, "type": "youtube.com"}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[Learn how to route osquery logs.](https://www.decodable.co/blog/routing-osquery-events-via-apache-pulsar)\n\nOSQuery is an open source tool that lets you query operating system events using SQL.The events can be fed into a #streaming platform, in this case Pulsar, for subsequent transformation and routing on the stream using Decodable.\n\n&amp;#x200B;\n\n[Route OSQuery Logs](https://preview.redd.it/3r1wlfxggv5a1.jpg?width=377&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=0afa17ba946be69ecbc94426f1d6560611565e9f)\n\n\\#apache-flink #flink #security #logs #cybersecurity #osquery #sql #decodable #streaming #apache-pulsar #pulsar", "author_fullname": "t2_90mri5a8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Routing OSQuery Events via Apache Pulsar", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"3r1wlfxggv5a1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 112, "x": 108, "u": "https://preview.redd.it/3r1wlfxggv5a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8b2645c6182b9db2155a15a563e2b3d7a170af4a"}, {"y": 224, "x": 216, "u": "https://preview.redd.it/3r1wlfxggv5a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d31c808ed7d52b5616bb5656a9c0ff752b817423"}, {"y": 332, "x": 320, "u": "https://preview.redd.it/3r1wlfxggv5a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8b6c1a346ce4d7b612efa1e02d90e42b6b107ee8"}], "s": {"y": 392, "x": 377, "u": "https://preview.redd.it/3r1wlfxggv5a1.jpg?width=377&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=0afa17ba946be69ecbc94426f1d6560611565e9f"}, "id": "3r1wlfxggv5a1"}}, "name": "t3_zlrthq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/_vWcCSxdycUXpyHuCUEWopmghIdmzOB99FjnvKWYHCs.jpg", "edited": 1671027318.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671026752.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.decodable.co/blog/routing-osquery-events-via-apache-pulsar\"&gt;Learn how to route osquery logs.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;OSQuery is an open source tool that lets you query operating system events using SQL.The events can be fed into a #streaming platform, in this case Pulsar, for subsequent transformation and routing on the stream using Decodable.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/3r1wlfxggv5a1.jpg?width=377&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=0afa17ba946be69ecbc94426f1d6560611565e9f\"&gt;Route OSQuery Logs&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;#apache-flink #flink #security #logs #cybersecurity #osquery #sql #decodable #streaming #apache-pulsar #pulsar&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "zlrthq", "is_robot_indexable": true, "report_reasons": null, "author": "hkdelay", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zlrthq/routing_osquery_events_via_apache_pulsar/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zlrthq/routing_osquery_events_via_apache_pulsar/", "subreddit_subscribers": 82973, "created_utc": 1671026752.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, first of all i am using Databricks. I have a raw dataframe, where based on some business logic i have to apply different filters. This is my preprocessing step, right now  i have 10 different jobs which produces processed dataframe(filtered).Since this is fairly easy task and not so expensive. I want to merge it into one single job.\n\nDo i benefit from something like this? How would u done it?How would u later write it to s3 lets say.\n\nIs map() ideal solution for this?\n\nShould i write some PandasUDF? Any opinion is good. =)\n\n     def _apply_filter(filter_: str) -&gt; pyspark.sql.DataFrame:\n        return rawDataFrame.filter(F.expr(filter_))\n    \n    FILTERS: List[str]\n    result: List[DataFrame] = list(map(_apply_filter, FILTERS))", "author_fullname": "t2_sx1wry60", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "applying set of filters on same dataframe", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zlqwag", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671024385.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, first of all i am using Databricks. I have a raw dataframe, where based on some business logic i have to apply different filters. This is my preprocessing step, right now  i have 10 different jobs which produces processed dataframe(filtered).Since this is fairly easy task and not so expensive. I want to merge it into one single job.&lt;/p&gt;\n\n&lt;p&gt;Do i benefit from something like this? How would u done it?How would u later write it to s3 lets say.&lt;/p&gt;\n\n&lt;p&gt;Is map() ideal solution for this?&lt;/p&gt;\n\n&lt;p&gt;Should i write some PandasUDF? Any opinion is good. =)&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt; def _apply_filter(filter_: str) -&amp;gt; pyspark.sql.DataFrame:\n    return rawDataFrame.filter(F.expr(filter_))\n\nFILTERS: List[str]\nresult: List[DataFrame] = list(map(_apply_filter, FILTERS))\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "zlqwag", "is_robot_indexable": true, "report_reasons": null, "author": "AcceptableProcess772", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/zlqwag/applying_set_of_filters_on_same_dataframe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zlqwag/applying_set_of_filters_on_same_dataframe/", "subreddit_subscribers": 82973, "created_utc": 1671024385.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\\*\\* Market Research for an idea \\*\\*  \nOver the last 5 years I have worked for several companies as an Analytics Engineer (implementing tracking and tagging solutions) and Data Manager. \n\nMy job normally included getting a picture of online and offline data and unite them. \n\nIn each company I started auditing the different data and marketing platforms to understand the data structure, naming conventions and platform integration status. \n\nAll of the companies I worked for had a big problem with old, cluttered and incorrect data.   \nIn one company we ripped out the complete tagging and tracking system and set up a brand new tag management system and platform end points (mainly Google Analytics, Databricks and some other platforms)  \n\n\nIn the other company I spent a very long time manually auditing the data and raising bug ticket after bug ticket to align data schema, streamline data endpoints and fix duplicated or broken properties. \n\nEven not being involved in one new website feature can mean derailing all naming conventions for that feature and headaches for any analysts or scientists who need to use that data further.   \nI feel like this is a recurring theme in companies. Over time you get clutter or old data concepts that are no longer used due to team. focus or platform changes.   \nI am currently investigating an automatic auditing solution for different data platforms, starting with the biggest, to quickly and easily get a view of what is currently collected and how.   \nAfter this I would like to come up with automated platform enhancing tips based on best practices for that specific business (you are not using this GA feature, enabling this would give you x etc.)\n\nYou could also define conversion steps for different products/ areas of the website and see if the tracking is coherent or needs adjusting, simplifying the whole naming convention of your website tracking to keep it easy for analysts. \n\n I would like to discuss with you if you also experience this problem in your companies and if it involves a lot of manual work that could benefit from an automated tool like the one described.   \n\n\nIf it would help, which features would you be interested in the most?   \n\n\nThank you for your help!", "author_fullname": "t2_g6h4ln0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this a problem in the industry?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_zm443h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "620fb7b8-ac9d-11eb-a99a-0ed5d8300de1", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1671056567.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;** Market Research for an idea **&lt;br/&gt;\nOver the last 5 years I have worked for several companies as an Analytics Engineer (implementing tracking and tagging solutions) and Data Manager. &lt;/p&gt;\n\n&lt;p&gt;My job normally included getting a picture of online and offline data and unite them. &lt;/p&gt;\n\n&lt;p&gt;In each company I started auditing the different data and marketing platforms to understand the data structure, naming conventions and platform integration status. &lt;/p&gt;\n\n&lt;p&gt;All of the companies I worked for had a big problem with old, cluttered and incorrect data.&lt;br/&gt;\nIn one company we ripped out the complete tagging and tracking system and set up a brand new tag management system and platform end points (mainly Google Analytics, Databricks and some other platforms)  &lt;/p&gt;\n\n&lt;p&gt;In the other company I spent a very long time manually auditing the data and raising bug ticket after bug ticket to align data schema, streamline data endpoints and fix duplicated or broken properties. &lt;/p&gt;\n\n&lt;p&gt;Even not being involved in one new website feature can mean derailing all naming conventions for that feature and headaches for any analysts or scientists who need to use that data further.&lt;br/&gt;\nI feel like this is a recurring theme in companies. Over time you get clutter or old data concepts that are no longer used due to team. focus or platform changes.&lt;br/&gt;\nI am currently investigating an automatic auditing solution for different data platforms, starting with the biggest, to quickly and easily get a view of what is currently collected and how.&lt;br/&gt;\nAfter this I would like to come up with automated platform enhancing tips based on best practices for that specific business (you are not using this GA feature, enabling this would give you x etc.)&lt;/p&gt;\n\n&lt;p&gt;You could also define conversion steps for different products/ areas of the website and see if the tracking is coherent or needs adjusting, simplifying the whole naming convention of your website tracking to keep it easy for analysts. &lt;/p&gt;\n\n&lt;p&gt;I would like to discuss with you if you also experience this problem in your companies and if it involves a lot of manual work that could benefit from an automated tool like the one described.   &lt;/p&gt;\n\n&lt;p&gt;If it would help, which features would you be interested in the most?   &lt;/p&gt;\n\n&lt;p&gt;Thank you for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Product Manager", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "zm443h", "is_robot_indexable": true, "report_reasons": null, "author": "Itchypupskit", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/zm443h/is_this_a_problem_in_the_industry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/zm443h/is_this_a_problem_in_the_industry/", "subreddit_subscribers": 82973, "created_utc": 1671056567.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}