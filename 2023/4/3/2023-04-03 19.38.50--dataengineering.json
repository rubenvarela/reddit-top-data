{"kind": "Listing", "data": {"after": "t3_12ajow3", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I felt the need to let everyone on this subreddit know I got my dream job offer.\n\nYou gave me a bollocking for calling OLAP cubes outdated. I'm sorry I pissed all of you off. \n\nYou pointed out I'm applying for the wrong jobs, and the platform engineering roles are sometimes hidden in devops and software engineering adverts.\n\nYou advised that an in-person second stage interview is likely to be a whiteboarding session when I didn't know what to expect.\n\nI made it!\n\nThank You!", "author_fullname": "t2_r7bmwiee", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I got the job!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_129w7vp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 246, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 246, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1680477286.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680465531.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I felt the need to let everyone on this subreddit know I got my dream job offer.&lt;/p&gt;\n\n&lt;p&gt;You gave me a bollocking for calling OLAP cubes outdated. I&amp;#39;m sorry I pissed all of you off. &lt;/p&gt;\n\n&lt;p&gt;You pointed out I&amp;#39;m applying for the wrong jobs, and the platform engineering roles are sometimes hidden in devops and software engineering adverts.&lt;/p&gt;\n\n&lt;p&gt;You advised that an in-person second stage interview is likely to be a whiteboarding session when I didn&amp;#39;t know what to expect.&lt;/p&gt;\n\n&lt;p&gt;I made it!&lt;/p&gt;\n\n&lt;p&gt;Thank You!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "129w7vp", "is_robot_indexable": true, "report_reasons": null, "author": "va1kyrja-kara", "discussion_type": null, "num_comments": 48, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/129w7vp/i_got_the_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/129w7vp/i_got_the_job/", "subreddit_subscribers": 95630, "created_utc": 1680465531.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just read this and loved it (who doesn't like a bit of drama?)! I'm not to well versed, so I'd be interested in hearing what other people in the industry are thinking? Given the previous posts about costs of data teams etc, I think it's quite interesting.   \n\n\n[https://medium.com/@laurengreerbalik/customer-empathy-is-dead-10f412782b5e](https://medium.com/@laurengreerbalik/customer-empathy-is-dead-10f412782b5e)  \n\n\n*Airbyte is such a joke that Reddit* r/dataengineering *users \u201cMyDixonsCider\u201d (say that out loud) and \u201cThunderCuntAU\u201d seem to have done more due diligence on Airbyte than any venture capitalist willing to give tens of millions of dollars of other peoples\u2019 money to Airbyte\u2019s founders to make the twentieth-worst version of a data replication EL tool that exists on market.*  \n\n\n*I should be firing Fivetran potentially, when all we mostly use it for is Postgres and Salesforce replications, and I should look into Keboola (or similar) which can give me the same thing with better SLA adherence and better uptime for $10k a year and allows me to \u201ctransform and denormalize\u201d before dumping data into my Snowflake, which also will get rid of 25 dbt models and lower my Snowflake bills by a run rate of $30k this year.*", "author_fullname": "t2_opyjpm1x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The roast of the modern data stack?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12acdrk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 58, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 58, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1680505464.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just read this and loved it (who doesn&amp;#39;t like a bit of drama?)! I&amp;#39;m not to well versed, so I&amp;#39;d be interested in hearing what other people in the industry are thinking? Given the previous posts about costs of data teams etc, I think it&amp;#39;s quite interesting.   &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@laurengreerbalik/customer-empathy-is-dead-10f412782b5e\"&gt;https://medium.com/@laurengreerbalik/customer-empathy-is-dead-10f412782b5e&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Airbyte is such a joke that Reddit&lt;/em&gt; &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt; &lt;em&gt;users \u201cMyDixonsCider\u201d (say that out loud) and \u201cThunderCuntAU\u201d seem to have done more due diligence on Airbyte than any venture capitalist willing to give tens of millions of dollars of other peoples\u2019 money to Airbyte\u2019s founders to make the twentieth-worst version of a data replication EL tool that exists on market.&lt;/em&gt;  &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;I should be firing Fivetran potentially, when all we mostly use it for is Postgres and Salesforce replications, and I should look into Keboola (or similar) which can give me the same thing with better SLA adherence and better uptime for $10k a year and allows me to \u201ctransform and denormalize\u201d before dumping data into my Snowflake, which also will get rid of 25 dbt models and lower my Snowflake bills by a run rate of $30k this year.&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Kb5csAa7A2R_K-bXN5tIdgtcw4DTzQtMir9cE-BmxOA.jpg?auto=webp&amp;v=enabled&amp;s=3fe186f30f581409007f9c13188249e177cf3876", "width": 667, "height": 668}, "resolutions": [{"url": "https://external-preview.redd.it/Kb5csAa7A2R_K-bXN5tIdgtcw4DTzQtMir9cE-BmxOA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=08bdd8e2ad496235907f68c603d243bfc633a969", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/Kb5csAa7A2R_K-bXN5tIdgtcw4DTzQtMir9cE-BmxOA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=24d6cd38cadb2dbac42ab8d364680c07a48031c7", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/Kb5csAa7A2R_K-bXN5tIdgtcw4DTzQtMir9cE-BmxOA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=90e2b74056fa4bd92022da5298ed2caf28bee6e8", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/Kb5csAa7A2R_K-bXN5tIdgtcw4DTzQtMir9cE-BmxOA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f88ca9b8fa743c61259dcc016d02372733a1eeb5", "width": 640, "height": 640}], "variants": {}, "id": "Z57inWsHlf2DtghpGCHs36ZdZlpktVyZzo041Nbs5LA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12acdrk", "is_robot_indexable": true, "report_reasons": null, "author": "CalleKeboola", "discussion_type": null, "num_comments": 46, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12acdrk/the_roast_of_the_modern_data_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12acdrk/the_roast_of_the_modern_data_stack/", "subreddit_subscribers": 95630, "created_utc": 1680505464.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8v6mk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "COVID-19 data pipeline on AWS feat. Glue/PySpark, Docker, Great Expectations, Airflow, and Redshift, templated in CF/CDK, deployable via Github Actions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 87, "top_awarded_type": null, "hide_score": false, "name": "t3_12anr2k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 57, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 57, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/BuxerbOZQ8bp-v8D4PAY2i18rpnPXbhZKvGZC3MzBpA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1680535484.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/4qpi4llisora1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/4qpi4llisora1.png?auto=webp&amp;v=enabled&amp;s=c238cb4d6ad3085913d8ca57fe1c8454c7560a49", "width": 2999, "height": 1879}, "resolutions": [{"url": "https://preview.redd.it/4qpi4llisora1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=57e1f51cbcd1c5fdddb4ca0393bba2d6190c3a11", "width": 108, "height": 67}, {"url": "https://preview.redd.it/4qpi4llisora1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bf4c1f52e4c1839854449c9de73b945f6a24a721", "width": 216, "height": 135}, {"url": "https://preview.redd.it/4qpi4llisora1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eb6f9628dc35d1f82519602cff65ec9db5d9be4a", "width": 320, "height": 200}, {"url": "https://preview.redd.it/4qpi4llisora1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=71ad88d64e69170d4ad6b65d1bf0f339103f2082", "width": 640, "height": 400}, {"url": "https://preview.redd.it/4qpi4llisora1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c83db1d0e09a58dc397200876fc33bdaee0718e4", "width": 960, "height": 601}, {"url": "https://preview.redd.it/4qpi4llisora1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=039a2067db6dc0ab43a59e4ac4266ecfabac8c0c", "width": 1080, "height": 676}], "variants": {}, "id": "ipqQE0lb9pWDLD6MolmjOmGuaaIeU8jS-PJ20BcCN-0"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "12anr2k", "is_robot_indexable": true, "report_reasons": null, "author": "smoochie100", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12anr2k/covid19_data_pipeline_on_aws_feat_gluepyspark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/4qpi4llisora1.png", "subreddit_subscribers": 95630, "created_utc": 1680535484.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all. I\u2019m an AWS SolArc by trade but big data and data lakes are not my area of expertise. I\u2019ve traditionally been more on the Ops and Dev side of the house. But we don\u2019t always get to pick the projects we are handed and I\u2019ve been tasked with building out a data lake for my Org. \n\nWe\u2019ve got about 10 Lines Of Business whose data we need to ingest, something close to 100 tables total. Data size in the terabytes when it\u2019s all said and done.\n\nQuery engine is assumed to be Athena. Analytics will be either Tableau or Quicksight. \n\nMy current sketch has 3 buckets: \n\n1) Raw data bucket.  \n2) Transformed Data Bucket. \n3) Curated Data Bucket\n\nTurn on Intelligent Tiering for all the buckets. Bucket format would follow\u2026. \n\n&lt;bucket&gt;/&lt;LineOfBusiness&gt;/&lt;DatabaseName&gt;/table=&lt;tableName&gt;/&lt;partitions&gt;/&lt;DataFiles&gt;.parquet\n\nFor Time Series data we are looking at Kinesis Firehose to continually write new files, partitioned on year/month/day of ingest. Backing up the raw json data to the raw data bucket and writing the transformed, batched, data to the transformed bucket. Batch 5 minutes at a time, possibly less of lots of partitions, 128MB target file size, parquet format. \n\nFor the non time series data, my plan was two fold:\n\nEnable CDC on the tables and ingest the CDC data as time series data. Batch to 128MB or 5 minutes, write out as parquet files. Expose the CDC data as a table to be queried incase people want to run queries against data churn. \n\nRun daily snapshots of the tables and dump them to S3 using Glue Jobs. These snapshots would have a partition field of \u201csnapshot_date\u201d. We would also have an Athena View that would always point to the latest snapshot by defining the view with a where clause and use the GetDate function to figure out the current date minus one day. The idea being people\nCan write queries against the view and it\u2019ll always pick up yesterdays snapshot as the most current without them needing to actually modify their queries. Expose these snapshots as tables so that people can reference them. My coworker calls these non series tables \u201cenrichment data\u201d though I don\u2019t know if that\u2019s an industry term or a him-term.\n\nMy questions: \n\n1) Does the above seem reasonable? Any problems? My DBA hates the idea of us taking daily snapshots, he would prefer that we use the CDC data and an Athena Apache Iceberg table to run upserts &amp; merges, I have concerns about the performance of doing those constantly but I don\u2019t know if those concerns are warranted? I also don\u2019t love the idea of us doing those modifications non-stop without having a backup available. \n\n2) Most of our relational DBs are MSFT SQL Server, is there a better/best way to get that data into S3 other than Glue Jobs and just letting them doing Select * on a loop to chunk the data and upload it 100,000 rows at a time or something? \n\n3) Are there strong opinions on whether we should keep the data normalized or should we denormalize it? I was thinking about doing all the joins as part of the glue job to convert from raw data to transformed\nData but I wasn\u2019t sure if there was a downside to doing so?\n\n4) does glue table type really matter? I saw that Lake Formation Governed Tables and Athena Iceberg tables both support automatic performance optimization through data compaction, but is the performance noticeably different? We don\u2019t, today, have any PII data that needs protected so not having LF\u2019s row/column level security isn\u2019t a concern -today- if we went with a traditional hive table or Iceberg table. \n\n5) Are we missing anything? Seriously assume I\u2019m a Dumbass who knows nothing. This is a huge project for me and I want to make sure we aren\u2019t walking into a minefield accidentally", "author_fullname": "t2_me6kj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building a new data lake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_129uytu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1680463140.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680462901.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all. I\u2019m an AWS SolArc by trade but big data and data lakes are not my area of expertise. I\u2019ve traditionally been more on the Ops and Dev side of the house. But we don\u2019t always get to pick the projects we are handed and I\u2019ve been tasked with building out a data lake for my Org. &lt;/p&gt;\n\n&lt;p&gt;We\u2019ve got about 10 Lines Of Business whose data we need to ingest, something close to 100 tables total. Data size in the terabytes when it\u2019s all said and done.&lt;/p&gt;\n\n&lt;p&gt;Query engine is assumed to be Athena. Analytics will be either Tableau or Quicksight. &lt;/p&gt;\n\n&lt;p&gt;My current sketch has 3 buckets: &lt;/p&gt;\n\n&lt;p&gt;1) Raw data bucket.&lt;br/&gt;\n2) Transformed Data Bucket. \n3) Curated Data Bucket&lt;/p&gt;\n\n&lt;p&gt;Turn on Intelligent Tiering for all the buckets. Bucket format would follow\u2026. &lt;/p&gt;\n\n&lt;p&gt;&amp;lt;bucket&amp;gt;/&amp;lt;LineOfBusiness&amp;gt;/&amp;lt;DatabaseName&amp;gt;/table=&amp;lt;tableName&amp;gt;/&amp;lt;partitions&amp;gt;/&amp;lt;DataFiles&amp;gt;.parquet&lt;/p&gt;\n\n&lt;p&gt;For Time Series data we are looking at Kinesis Firehose to continually write new files, partitioned on year/month/day of ingest. Backing up the raw json data to the raw data bucket and writing the transformed, batched, data to the transformed bucket. Batch 5 minutes at a time, possibly less of lots of partitions, 128MB target file size, parquet format. &lt;/p&gt;\n\n&lt;p&gt;For the non time series data, my plan was two fold:&lt;/p&gt;\n\n&lt;p&gt;Enable CDC on the tables and ingest the CDC data as time series data. Batch to 128MB or 5 minutes, write out as parquet files. Expose the CDC data as a table to be queried incase people want to run queries against data churn. &lt;/p&gt;\n\n&lt;p&gt;Run daily snapshots of the tables and dump them to S3 using Glue Jobs. These snapshots would have a partition field of \u201csnapshot_date\u201d. We would also have an Athena View that would always point to the latest snapshot by defining the view with a where clause and use the GetDate function to figure out the current date minus one day. The idea being people\nCan write queries against the view and it\u2019ll always pick up yesterdays snapshot as the most current without them needing to actually modify their queries. Expose these snapshots as tables so that people can reference them. My coworker calls these non series tables \u201cenrichment data\u201d though I don\u2019t know if that\u2019s an industry term or a him-term.&lt;/p&gt;\n\n&lt;p&gt;My questions: &lt;/p&gt;\n\n&lt;p&gt;1) Does the above seem reasonable? Any problems? My DBA hates the idea of us taking daily snapshots, he would prefer that we use the CDC data and an Athena Apache Iceberg table to run upserts &amp;amp; merges, I have concerns about the performance of doing those constantly but I don\u2019t know if those concerns are warranted? I also don\u2019t love the idea of us doing those modifications non-stop without having a backup available. &lt;/p&gt;\n\n&lt;p&gt;2) Most of our relational DBs are MSFT SQL Server, is there a better/best way to get that data into S3 other than Glue Jobs and just letting them doing Select * on a loop to chunk the data and upload it 100,000 rows at a time or something? &lt;/p&gt;\n\n&lt;p&gt;3) Are there strong opinions on whether we should keep the data normalized or should we denormalize it? I was thinking about doing all the joins as part of the glue job to convert from raw data to transformed\nData but I wasn\u2019t sure if there was a downside to doing so?&lt;/p&gt;\n\n&lt;p&gt;4) does glue table type really matter? I saw that Lake Formation Governed Tables and Athena Iceberg tables both support automatic performance optimization through data compaction, but is the performance noticeably different? We don\u2019t, today, have any PII data that needs protected so not having LF\u2019s row/column level security isn\u2019t a concern -today- if we went with a traditional hive table or Iceberg table. &lt;/p&gt;\n\n&lt;p&gt;5) Are we missing anything? Seriously assume I\u2019m a Dumbass who knows nothing. This is a huge project for me and I want to make sure we aren\u2019t walking into a minefield accidentally&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "129uytu", "is_robot_indexable": true, "report_reasons": null, "author": "Flakmaster92", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/129uytu/building_a_new_data_lake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/129uytu/building_a_new_data_lake/", "subreddit_subscribers": 95630, "created_utc": 1680462901.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_34twt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Parquet: more than just \"Turbo CSV\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_12al33e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/kDz2FtSxZfuo8nsWRVgJjHhzhpnkfAZv-HNu7_u9JnY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1680529800.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "csvbase.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://csvbase.com/blog/3", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qO6j-Oc50yisyKVVOCCfqO4EoVnf2OSvAwAr3zR07A8.jpg?auto=webp&amp;v=enabled&amp;s=eb063fe1d0f31434c427e80392457b4df5d3529b", "width": 800, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/qO6j-Oc50yisyKVVOCCfqO4EoVnf2OSvAwAr3zR07A8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f0dd3d76a43223524cdc72db650cefdf3b311d56", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/qO6j-Oc50yisyKVVOCCfqO4EoVnf2OSvAwAr3zR07A8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=af1a87545730f3e2dfabab418431189de2c7da8d", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/qO6j-Oc50yisyKVVOCCfqO4EoVnf2OSvAwAr3zR07A8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=95679e111fdd0a760ebb59daaef9d08ef54d6433", "width": 320, "height": 240}, {"url": "https://external-preview.redd.it/qO6j-Oc50yisyKVVOCCfqO4EoVnf2OSvAwAr3zR07A8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=130e5d87d9ae55aaa23c580a22dd1040d3e847a8", "width": 640, "height": 480}], "variants": {}, "id": "IfQge5tEzdN69CBwaua7mx3ljdv2t0UnAz-SSztYbHM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12al33e", "is_robot_indexable": true, "report_reasons": null, "author": "calp", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12al33e/parquet_more_than_just_turbo_csv/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://csvbase.com/blog/3", "subreddit_subscribers": 95630, "created_utc": 1680529800.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m trying to put together a growth plan for myself and having a hard time coming up with where I want to be in 2-3 years. I\u2019m looking for examples of how you or you\u2019ve seen others grow as a DE. \n\nAbout myself: I really enjoyed DE-style work in order to run my small side hobbies before I ever got into the industry. I\u2019m E5 level at my current company and I\u2019ve always enjoyed enabling my team to better understand their products through core datasets with scalable offshoots of that.", "author_fullname": "t2_fo0y6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Growth plan ideas for senior data engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ajqoz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680526849.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying to put together a growth plan for myself and having a hard time coming up with where I want to be in 2-3 years. I\u2019m looking for examples of how you or you\u2019ve seen others grow as a DE. &lt;/p&gt;\n\n&lt;p&gt;About myself: I really enjoyed DE-style work in order to run my small side hobbies before I ever got into the industry. I\u2019m E5 level at my current company and I\u2019ve always enjoyed enabling my team to better understand their products through core datasets with scalable offshoots of that.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12ajqoz", "is_robot_indexable": true, "report_reasons": null, "author": "sharpchicity", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ajqoz/growth_plan_ideas_for_senior_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ajqoz/growth_plan_ideas_for_senior_data_engineer/", "subreddit_subscribers": 95630, "created_utc": 1680526849.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Preferably open source, preferably free, definitely hosted in-house, but anything that isn't too ridiculously expensive would be considered.\n\nThere's so many options, most of which either a) have zero documentation, not even system requirements, b) won't tell you what it costs until after a demo (that will inevitably be a waste of time with high pressure sales pitches), c) obscenely expensive (with subscription fees), or d) so complicated to set up as to be impossible (see a)).", "author_fullname": "t2_c8eislj4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can anybody recommend a document management system?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12a969n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680495488.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Preferably open source, preferably free, definitely hosted in-house, but anything that isn&amp;#39;t too ridiculously expensive would be considered.&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s so many options, most of which either a) have zero documentation, not even system requirements, b) won&amp;#39;t tell you what it costs until after a demo (that will inevitably be a waste of time with high pressure sales pitches), c) obscenely expensive (with subscription fees), or d) so complicated to set up as to be impossible (see a)).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12a969n", "is_robot_indexable": true, "report_reasons": null, "author": "DwaywelayTOP", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12a969n/can_anybody_recommend_a_document_management_system/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12a969n/can_anybody_recommend_a_document_management_system/", "subreddit_subscribers": 95630, "created_utc": 1680495488.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Say you built a data warehouse (DW) for a few reports.\nNow you are serving many BI teams with multiple report on the same database.\n\nOne more reporting requests comes along the way.\n\nBut the reporting queries are becoming inefficient. You need to change the design schema to make it more efficient. (aggregation, denormalize, add more columns etc ) \n\nThe cost for serving those reports are also rising.\n\nWhat is most common reason you would consider to redesign a schema?\n\nIs it a common practice? How often have you done it?", "author_fullname": "t2_7t9felxr4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How often do you redesign a data warehouse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12a64bq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680487393.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Say you built a data warehouse (DW) for a few reports.\nNow you are serving many BI teams with multiple report on the same database.&lt;/p&gt;\n\n&lt;p&gt;One more reporting requests comes along the way.&lt;/p&gt;\n\n&lt;p&gt;But the reporting queries are becoming inefficient. You need to change the design schema to make it more efficient. (aggregation, denormalize, add more columns etc ) &lt;/p&gt;\n\n&lt;p&gt;The cost for serving those reports are also rising.&lt;/p&gt;\n\n&lt;p&gt;What is most common reason you would consider to redesign a schema?&lt;/p&gt;\n\n&lt;p&gt;Is it a common practice? How often have you done it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12a64bq", "is_robot_indexable": true, "report_reasons": null, "author": "query_optimization", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12a64bq/how_often_do_you_redesign_a_data_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12a64bq/how_often_do_you_redesign_a_data_warehouse/", "subreddit_subscribers": 95630, "created_utc": 1680487393.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "After a few years and with the hype gone, it has become apparent that MLOps overlap more with Data Engineering than most people believed.\n\nI wrote my thoughts on the matter and the awesome people of the MLOps community were kind enough to host them on their blog as a guest post. You can find the post here:\n\n[https://mlops.community/mlops-is-mostly-data-engineering/](https://mlops.community/mlops-is-mostly-data-engineering/)", "author_fullname": "t2_fb1s1pke", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MLOps is 98% Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12asp78", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1680545604.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After a few years and with the hype gone, it has become apparent that MLOps overlap more with Data Engineering than most people believed.&lt;/p&gt;\n\n&lt;p&gt;I wrote my thoughts on the matter and the awesome people of the MLOps community were kind enough to host them on their blog as a guest post. You can find the post here:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://mlops.community/mlops-is-mostly-data-engineering/\"&gt;https://mlops.community/mlops-is-mostly-data-engineering/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bVjWIf0rrdbCKPd_Xzn3W6W1rfXxA5DUGfQ4vOGB5OI.jpg?auto=webp&amp;v=enabled&amp;s=0d81c32dcfb93ea8d28ca754c33326a81e0c224e", "width": 700, "height": 467}, "resolutions": [{"url": "https://external-preview.redd.it/bVjWIf0rrdbCKPd_Xzn3W6W1rfXxA5DUGfQ4vOGB5OI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=744fe705c8924b38a5cb5812da49becb067c8ef7", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/bVjWIf0rrdbCKPd_Xzn3W6W1rfXxA5DUGfQ4vOGB5OI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4ee10e129b5a63d0843b3853372afea177faaddd", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/bVjWIf0rrdbCKPd_Xzn3W6W1rfXxA5DUGfQ4vOGB5OI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=454128534ee7c02c4eb208d07b925cfb60adaa53", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/bVjWIf0rrdbCKPd_Xzn3W6W1rfXxA5DUGfQ4vOGB5OI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=322afdd685f97911331712d0c443345267967c7b", "width": 640, "height": 426}], "variants": {}, "id": "jLhsBd_EDLM0YfBqf4uOPydrZ4w5DXOH2lHMgyZ6lXw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12asp78", "is_robot_indexable": true, "report_reasons": null, "author": "cpardl", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12asp78/mlops_is_98_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12asp78/mlops_is_98_data_engineering/", "subreddit_subscribers": 95630, "created_utc": 1680545604.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Dear community,\n\nI've developed an online tool that allows loading raw unstructured data from files (csv, xml, json, logs and others) into sql database (ClickHouse) in a normalized and structured way. I.e. it automatically parses data, flattens it (for json and xml), recognizes the type of columns, generates sql schema and imports structured data into the sql tables.   \nThe tool also provides SQL console in the UI that allows transforming data, subquerying loaded data to aggregate, filtering, sorting, etc.   \nFinally, user can share the ingested data via a standard db connector and explore all imported data in other data apps or BI, or download tables as csv, xml, json files. \n\nThe question is:\n\n1. Which niches would this solution be most useful for?\n2. Do you have any specific use cases where you could benefit from it?\n\nThanks for any comments. Also, if you believe that any features are missing from this type of product, I would greatly appreciate it if you could share your thoughts.", "author_fullname": "t2_1z5jdh5h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data ingestion product questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ae9cx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680511691.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dear community,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve developed an online tool that allows loading raw unstructured data from files (csv, xml, json, logs and others) into sql database (ClickHouse) in a normalized and structured way. I.e. it automatically parses data, flattens it (for json and xml), recognizes the type of columns, generates sql schema and imports structured data into the sql tables.&lt;br/&gt;\nThe tool also provides SQL console in the UI that allows transforming data, subquerying loaded data to aggregate, filtering, sorting, etc.&lt;br/&gt;\nFinally, user can share the ingested data via a standard db connector and explore all imported data in other data apps or BI, or download tables as csv, xml, json files. &lt;/p&gt;\n\n&lt;p&gt;The question is:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Which niches would this solution be most useful for?&lt;/li&gt;\n&lt;li&gt;Do you have any specific use cases where you could benefit from it?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thanks for any comments. Also, if you believe that any features are missing from this type of product, I would greatly appreciate it if you could share your thoughts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12ae9cx", "is_robot_indexable": true, "report_reasons": null, "author": "Greg_Z_", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ae9cx/data_ingestion_product_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ae9cx/data_ingestion_product_questions/", "subreddit_subscribers": 95630, "created_utc": 1680511691.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am studying for a DP exam since the company I am working with are heavy users of Azure.  Is it worth going for DP203 or should DP 900 suffice and learn the rest on the job? \n\nIs the DP 203 extremely hard?  I hear it has more industry credibility than the DP 900.", "author_fullname": "t2_o3vqiyj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DP 900 vs DP 203", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12a5qkn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680486481.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am studying for a DP exam since the company I am working with are heavy users of Azure.  Is it worth going for DP203 or should DP 900 suffice and learn the rest on the job? &lt;/p&gt;\n\n&lt;p&gt;Is the DP 203 extremely hard?  I hear it has more industry credibility than the DP 900.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12a5qkn", "is_robot_indexable": true, "report_reasons": null, "author": "InvestingNerd2020", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12a5qkn/dp_900_vs_dp_203/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12a5qkn/dp_900_vs_dp_203/", "subreddit_subscribers": 95630, "created_utc": 1680486481.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\n&amp;#x200B;\n\nTLDR; we are doing a lot of forecasting on time series data and are currently using SQL databases for storing the data. We are wanting to switch over to time series databases like InfluxDB or AWS Timestream.\n\n&amp;#x200B;\n\nAny suggestions ? Do you have any experience with time series DBs? Is the switch worth it ?", "author_fullname": "t2_2i1av4aw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using time series databases ? InfluxDB?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12aca4z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680505165.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;TLDR; we are doing a lot of forecasting on time series data and are currently using SQL databases for storing the data. We are wanting to switch over to time series databases like InfluxDB or AWS Timestream.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any suggestions ? Do you have any experience with time series DBs? Is the switch worth it ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12aca4z", "is_robot_indexable": true, "report_reasons": null, "author": "younggamech", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12aca4z/using_time_series_databases_influxdb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12aca4z/using_time_series_databases_influxdb/", "subreddit_subscribers": 95630, "created_utc": 1680505165.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am trying to migrate a Database with multiple schemas from SQL Server to Databricks Delta Lake. What is the equivalent of SQL Server's schema in databricks? In the unity catalog database or schema is the same and we put tables directly in the databricks database. Do I need to create multiple databases to account for each schema in SQL Server?", "author_fullname": "t2_c9y3v2w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL Server to Databricks Delta Lake Unity Catalog", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12abg1s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680502385.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to migrate a Database with multiple schemas from SQL Server to Databricks Delta Lake. What is the equivalent of SQL Server&amp;#39;s schema in databricks? In the unity catalog database or schema is the same and we put tables directly in the databricks database. Do I need to create multiple databases to account for each schema in SQL Server?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12abg1s", "is_robot_indexable": true, "report_reasons": null, "author": "mdghouse1986", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12abg1s/sql_server_to_databricks_delta_lake_unity_catalog/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12abg1s/sql_server_to_databricks_delta_lake_unity_catalog/", "subreddit_subscribers": 95630, "created_utc": 1680502385.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Connection here is for postgresql and we are running a test for null values.  \n\n\nHere is the sample code for Airflow:  \n\n\n    from airflow import DAG\n    from airflow.operators.python_operator import PythonOperator\n    from datetime import datetime\n    import psycopg2\n    \n    def check_null_or_empty():\n        # Set up a connection to the PostgreSQL database\n        conn = psycopg2.connect(\n            host=\"your_host_name\",\n            database=\"your_database_name\",\n            user=\"your_username\",\n            password=\"your_password\"\n        )\n    \n        # Open a cursor to perform database operations\n        cur = conn.cursor()\n    \n        # Define the query to run\n        query = \"SELECT COUNT(*) FROM users WHERE column_name IS NULL OR column_name=''\"\n    \n        # Execute the query\n        cur.execute(query)\n    \n        # Fetch the results\n        result = cur.fetchone()[0]\n    \n        # Close the cursor and the connection\n        cur.close()\n        conn.close()\n    \n        # Raise an error if the result is not 0\n        if result != 0:\n            raise ValueError(f\"Data quality check failed. {result} rows have null or empty values in column_name.\")\n        else:\n            print(\"Data quality check passed. All rows have a value in column_name.\")\n    \n    # Define the DAG\n    dag = DAG('data_quality_dag', description='Data quality check for null or empty values in users.column_name',\n              schedule_interval='@daily', start_date=datetime(2023, 4, 1))\n    \n    # Define the task\n    check_null_or_empty_task = PythonOperator(task_id='check_null_or_empty', python_callable=check_null_or_empty, dag=dag)\n    \n    # Define the task order\n    check_null_or_empty_task\n\nNot lets take the example of GE:  \n\n\n    name: data_quality_check\n    \n    steps:\n      - name: check_null_or_empty\n        action:\n          module_name: great_expectations.dataset.sqlalchemy_dataset\n          class_name: SqlAlchemyDataset\n          datasource: your_postgresql_datasource\n          batch_kwargs:\n            table: users\n            schema: public\n          expectation_suite_name: data_quality_check\n          action_list_operator: OR\n          failing_expectation_results_in_triggered_actions: True\n          action_on_failure:\n            exit: True\n            message: \"Data quality check failed. {{ result['result'] }} rows have null or empty values in column_name.\"\n        expectations:\n          - expectation_type: not_null\n            kwargs:\n              column: column_name\n          - expectation_type: expect_column_values_to_not_be_null\n            kwargs:\n              column: column_name\n          - expectation_type: expect_column_values_to_not_be_empty\n            kwargs:\n              column: column_name\n    \n    datasources:\n      your_postgresql_datasource:\n        class_name: Datasource\n        module_name: great_expectations.datasource\n        credentials:\n          username: your_username\n          password: your_password\n        module_name: great_expectations.datasource\n        class_name: SqlAlchemyDatasource\n        data_asset_type:\n          module_name: great_expectations.dataset\n          class_name: SqlAlchemyDataset\n        credentials:\n          username: your_username\n          password: your_password\n        drivername: postgresql\n        host: your_host_name\n        port: 5432\n        database: your_database_name\n        schema: public", "author_fullname": "t2_5b3y9jqyc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Sample Code] : Data quality null check for Airflow vs GreatExpectations [GE]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12aao4m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680499971.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Connection here is for postgresql and we are running a test for null values.  &lt;/p&gt;\n\n&lt;p&gt;Here is the sample code for Airflow:  &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;from airflow import DAG\nfrom airflow.operators.python_operator import PythonOperator\nfrom datetime import datetime\nimport psycopg2\n\ndef check_null_or_empty():\n    # Set up a connection to the PostgreSQL database\n    conn = psycopg2.connect(\n        host=&amp;quot;your_host_name&amp;quot;,\n        database=&amp;quot;your_database_name&amp;quot;,\n        user=&amp;quot;your_username&amp;quot;,\n        password=&amp;quot;your_password&amp;quot;\n    )\n\n    # Open a cursor to perform database operations\n    cur = conn.cursor()\n\n    # Define the query to run\n    query = &amp;quot;SELECT COUNT(*) FROM users WHERE column_name IS NULL OR column_name=&amp;#39;&amp;#39;&amp;quot;\n\n    # Execute the query\n    cur.execute(query)\n\n    # Fetch the results\n    result = cur.fetchone()[0]\n\n    # Close the cursor and the connection\n    cur.close()\n    conn.close()\n\n    # Raise an error if the result is not 0\n    if result != 0:\n        raise ValueError(f&amp;quot;Data quality check failed. {result} rows have null or empty values in column_name.&amp;quot;)\n    else:\n        print(&amp;quot;Data quality check passed. All rows have a value in column_name.&amp;quot;)\n\n# Define the DAG\ndag = DAG(&amp;#39;data_quality_dag&amp;#39;, description=&amp;#39;Data quality check for null or empty values in users.column_name&amp;#39;,\n          schedule_interval=&amp;#39;@daily&amp;#39;, start_date=datetime(2023, 4, 1))\n\n# Define the task\ncheck_null_or_empty_task = PythonOperator(task_id=&amp;#39;check_null_or_empty&amp;#39;, python_callable=check_null_or_empty, dag=dag)\n\n# Define the task order\ncheck_null_or_empty_task\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Not lets take the example of GE:  &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;name: data_quality_check\n\nsteps:\n  - name: check_null_or_empty\n    action:\n      module_name: great_expectations.dataset.sqlalchemy_dataset\n      class_name: SqlAlchemyDataset\n      datasource: your_postgresql_datasource\n      batch_kwargs:\n        table: users\n        schema: public\n      expectation_suite_name: data_quality_check\n      action_list_operator: OR\n      failing_expectation_results_in_triggered_actions: True\n      action_on_failure:\n        exit: True\n        message: &amp;quot;Data quality check failed. {{ result[&amp;#39;result&amp;#39;] }} rows have null or empty values in column_name.&amp;quot;\n    expectations:\n      - expectation_type: not_null\n        kwargs:\n          column: column_name\n      - expectation_type: expect_column_values_to_not_be_null\n        kwargs:\n          column: column_name\n      - expectation_type: expect_column_values_to_not_be_empty\n        kwargs:\n          column: column_name\n\ndatasources:\n  your_postgresql_datasource:\n    class_name: Datasource\n    module_name: great_expectations.datasource\n    credentials:\n      username: your_username\n      password: your_password\n    module_name: great_expectations.datasource\n    class_name: SqlAlchemyDatasource\n    data_asset_type:\n      module_name: great_expectations.dataset\n      class_name: SqlAlchemyDataset\n    credentials:\n      username: your_username\n      password: your_password\n    drivername: postgresql\n    host: your_host_name\n    port: 5432\n    database: your_database_name\n    schema: public\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12aao4m", "is_robot_indexable": true, "report_reasons": null, "author": "de4all", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12aao4m/sample_code_data_quality_null_check_for_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12aao4m/sample_code_data_quality_null_check_for_airflow/", "subreddit_subscribers": 95630, "created_utc": 1680499971.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m currently working as a controls engineering  (1yr) with a degree in industrial engineering, minor in data analysis. I\u2019m just curious if anyone has made a similar jump, how you did it, and how you would improve it if you did it again? Thanks for reading!", "author_fullname": "t2_zl24e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Controls Engineer Migration?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12aajgp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680499580.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m currently working as a controls engineering  (1yr) with a degree in industrial engineering, minor in data analysis. I\u2019m just curious if anyone has made a similar jump, how you did it, and how you would improve it if you did it again? Thanks for reading!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12aajgp", "is_robot_indexable": true, "report_reasons": null, "author": "MrGreat_Value", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12aajgp/controls_engineer_migration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12aajgp/controls_engineer_migration/", "subreddit_subscribers": 95630, "created_utc": 1680499580.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to understand the difference between spark.kubernetes.executor.request.cores and spark.executor.cores?\n\nI am running spark 3.2 on Kubernetes. So in YARN I was using spark.executor.cores to set the core per executor. \n\nDoes spark.kubernetes.executor.request.cores takes precedence for executor cores when used on Kubernetes? \nAnd should I not use spark.executor.cores on Kubernetes?", "author_fullname": "t2_7ht6c4ggj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark on Kubernetes config", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12a7ebg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680490640.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to understand the difference between spark.kubernetes.executor.request.cores and spark.executor.cores?&lt;/p&gt;\n\n&lt;p&gt;I am running spark 3.2 on Kubernetes. So in YARN I was using spark.executor.cores to set the core per executor. &lt;/p&gt;\n\n&lt;p&gt;Does spark.kubernetes.executor.request.cores takes precedence for executor cores when used on Kubernetes? \nAnd should I not use spark.executor.cores on Kubernetes?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12a7ebg", "is_robot_indexable": true, "report_reasons": null, "author": "Weird_Implement_2960", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12a7ebg/spark_on_kubernetes_config/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12a7ebg/spark_on_kubernetes_config/", "subreddit_subscribers": 95630, "created_utc": 1680490640.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "You get a SQL connection to a vendor created/managed backend that has zero documentation over function or a data dictionary. Tables have 100+ poorly named columns each, majority of which are filled with nulls. What are you gonna do?\n\nI\u2019ve repeatedly experienced this situation and beyond writing some simple python/sql in a notebook that profiles the seemingly useful columns, I\u2019m curious if there\u2019s a better approach. We have some off the shelf software that can do really impressive discovery/profiling but it\u2019s a bit of a pain to setup for every schema/database being looked at for the initial pass through", "author_fullname": "t2_ao7u40a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Open Source Data Exploration tools/approach?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12aruh2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1680544248.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680543916.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;You get a SQL connection to a vendor created/managed backend that has zero documentation over function or a data dictionary. Tables have 100+ poorly named columns each, majority of which are filled with nulls. What are you gonna do?&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve repeatedly experienced this situation and beyond writing some simple python/sql in a notebook that profiles the seemingly useful columns, I\u2019m curious if there\u2019s a better approach. We have some off the shelf software that can do really impressive discovery/profiling but it\u2019s a bit of a pain to setup for every schema/database being looked at for the initial pass through&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12aruh2", "is_robot_indexable": true, "report_reasons": null, "author": "minormisgnomer", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12aruh2/open_source_data_exploration_toolsapproach/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12aruh2/open_source_data_exploration_toolsapproach/", "subreddit_subscribers": 95630, "created_utc": 1680543916.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_ui4m14ke", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Modelling for Data Architects - Points for further deep dive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 38, "top_awarded_type": null, "hide_score": true, "name": "t3_12arpt8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/tPNMNuEBgh6pYXncq44fRfVRkBk2tWwkB9YXNIq3hfg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1680543660.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@anupmoncy/how-to-become-a-data-architect-data-modelling-8b3faac402f4", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/43-inUTiXvHPaFWTNITf0l_bp7aFbKey_635B4pazM0.jpg?auto=webp&amp;v=enabled&amp;s=f45c3ccedc146666ff336f6994f5bff1da13ecfe", "width": 1200, "height": 330}, "resolutions": [{"url": "https://external-preview.redd.it/43-inUTiXvHPaFWTNITf0l_bp7aFbKey_635B4pazM0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=79080e95e1ace9ddbd0e0919f4510c9dd9560ca1", "width": 108, "height": 29}, {"url": "https://external-preview.redd.it/43-inUTiXvHPaFWTNITf0l_bp7aFbKey_635B4pazM0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7b735e113429f6b3609db51088f4cc0dd86cc5fd", "width": 216, "height": 59}, {"url": "https://external-preview.redd.it/43-inUTiXvHPaFWTNITf0l_bp7aFbKey_635B4pazM0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3b3da1b26a9b0f6e81f361b7f09212c9b84894a4", "width": 320, "height": 88}, {"url": "https://external-preview.redd.it/43-inUTiXvHPaFWTNITf0l_bp7aFbKey_635B4pazM0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=37bb518e875bf4f24de10e6ddfee8788f4b1ece5", "width": 640, "height": 176}, {"url": "https://external-preview.redd.it/43-inUTiXvHPaFWTNITf0l_bp7aFbKey_635B4pazM0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4601c588b008d71d188c44b4865e2db615cbc578", "width": 960, "height": 264}, {"url": "https://external-preview.redd.it/43-inUTiXvHPaFWTNITf0l_bp7aFbKey_635B4pazM0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0c6dd0d70f458a8856ced1edafa8ea5e381d3553", "width": 1080, "height": 297}], "variants": {}, "id": "BlpXO1H7BlpQkVRahLk9smqlyLwQbXRpyMKL-e8At8g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12arpt8", "is_robot_indexable": true, "report_reasons": null, "author": "Alarmed-Sock4915", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12arpt8/data_modelling_for_data_architects_points_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@anupmoncy/how-to-become-a-data-architect-data-modelling-8b3faac402f4", "subreddit_subscribers": 95630, "created_utc": 1680543660.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Convert CSV Files into an Apache Iceberg table with Dremio", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 69, "top_awarded_type": null, "hide_score": false, "name": "t3_12ao2yz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/zJLYGk27_trmg3IH-_G6_WbU1yek7ofr3Env6Cnyrzg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1680536183.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dremio.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.dremio.com/blog/how-to-convert-csv-files-into-an-apache-iceberg-table-with-dremio/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/zxtJIagLDWZpguzI98Z8v1WVgeWXJPiJyJ0u1CfrlI0.jpg?auto=webp&amp;v=enabled&amp;s=d5d907b9a9975befd2ec14af693fffd7f02db06a", "width": 769, "height": 383}, "resolutions": [{"url": "https://external-preview.redd.it/zxtJIagLDWZpguzI98Z8v1WVgeWXJPiJyJ0u1CfrlI0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7e5cd0de85bd15073379ab76d6bc47d255ca77a1", "width": 108, "height": 53}, {"url": "https://external-preview.redd.it/zxtJIagLDWZpguzI98Z8v1WVgeWXJPiJyJ0u1CfrlI0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=034aa77eea51b1d8efaf2bde8f41a37b7e29ccf8", "width": 216, "height": 107}, {"url": "https://external-preview.redd.it/zxtJIagLDWZpguzI98Z8v1WVgeWXJPiJyJ0u1CfrlI0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c8734975ae57b97cbf48ca73f29181ce08ce63f0", "width": 320, "height": 159}, {"url": "https://external-preview.redd.it/zxtJIagLDWZpguzI98Z8v1WVgeWXJPiJyJ0u1CfrlI0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=81fc6c53c4f04461f00db53d2a6c84e9bdcdf64f", "width": 640, "height": 318}], "variants": {}, "id": "xNN4H40qu3ZhdZbvj47-RKZKZmtuObPJoFXNJ9YX5E0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12ao2yz", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ao2yz/how_to_convert_csv_files_into_an_apache_iceberg/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.dremio.com/blog/how-to-convert-csv-files-into-an-apache-iceberg-table-with-dremio/", "subreddit_subscribers": 95630, "created_utc": 1680536183.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_uu592ayo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Druid, TiDB, ClickHouse, or Apache Doris? A Comparison of OLAP Tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 85, "top_awarded_type": null, "hide_score": false, "name": "t3_12amyoq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/KY_eA60Pajpyh40hxXd4AdOyi0jRVD_ZuwSZxOmPjx8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1680533813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "hackernoon.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://hackernoon.com/apache-druid-tidb-clickhouse-or-apache-doris-a-comparison-of-olap-tools", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/99pDedvXWvN91zPtwZMHoHSINiRo67T40uxD4rP4GL4.jpg?auto=webp&amp;v=enabled&amp;s=9bb5b71e58f9e9a1308bdcebb9a30efe17c6df24", "width": 984, "height": 602}, "resolutions": [{"url": "https://external-preview.redd.it/99pDedvXWvN91zPtwZMHoHSINiRo67T40uxD4rP4GL4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3e5c79dd10941c590c5e43dbaaedb86869c4bf4a", "width": 108, "height": 66}, {"url": "https://external-preview.redd.it/99pDedvXWvN91zPtwZMHoHSINiRo67T40uxD4rP4GL4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8ee202e59d44b4d3099c5d4762ec74edf7fdc54b", "width": 216, "height": 132}, {"url": "https://external-preview.redd.it/99pDedvXWvN91zPtwZMHoHSINiRo67T40uxD4rP4GL4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=98cfb0ecd556ca4b14bcd846e536cd0b5267f46b", "width": 320, "height": 195}, {"url": "https://external-preview.redd.it/99pDedvXWvN91zPtwZMHoHSINiRo67T40uxD4rP4GL4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ced54e027694fe731250129caed940e5b9d47393", "width": 640, "height": 391}, {"url": "https://external-preview.redd.it/99pDedvXWvN91zPtwZMHoHSINiRo67T40uxD4rP4GL4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9d79115aa6e82a8c4ca4e228514717844e50bf5c", "width": 960, "height": 587}], "variants": {}, "id": "8jRxUhwcxfTMJ4WTUJ-E9gSvvoRG1BQ2OLWSVMMjKpE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12amyoq", "is_robot_indexable": true, "report_reasons": null, "author": "Any_Opportunity1234", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12amyoq/apache_druid_tidb_clickhouse_or_apache_doris_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://hackernoon.com/apache-druid-tidb-clickhouse-or-apache-doris-a-comparison-of-olap-tools", "subreddit_subscribers": 95630, "created_utc": 1680533813.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hey, is there any reason to use docker-compose if you can just make a playbook like this:\n\nall commands:\n\n[https://docs.ansible.com/ansible/latest/collections/community/docker/index.html#scenario-guide](https://docs.ansible.com/ansible/latest/collections/community/docker/index.html#scenario-guide)\n\nexample (scroll to bottom):\n\n[https://docs.ansible.com/ansible/latest/collections/community/docker/docker\\_container\\_exec\\_module.html#ansible-collections-community-docker-docker-container-exec-module](https://docs.ansible.com/ansible/latest/collections/community/docker/docker_container_exec_module.html#ansible-collections-community-docker-docker-container-exec-module)\n\nwith ansible you can call on any module, shell script, command line, and it will take care of it.\n\ncompose seems kind of limiting?  wondering if i'm missing something here.\n\nedit:\n\ni'm trying to understand what the benefit of creating a docker-compose.yml file is vs having an ansible playbook which pulls/builds and image, then creates however many containers i want.\n\nwhen i run compose, sometimes i get an issue with one container, and i have to shut down the entire pod vs just simply restarting a container or creating a new one to plug in with some kind of change.  (maybe this is due to my inexperience, but regardless i can't see what the use is vs ansible)\n\ngiven the down votes, people here seem to know some universal truth which i would like to be privy to.", "author_fullname": "t2_5qteskd9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ansible vs docker-compose", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ajf0v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1680539442.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680526117.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey, is there any reason to use docker-compose if you can just make a playbook like this:&lt;/p&gt;\n\n&lt;p&gt;all commands:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://docs.ansible.com/ansible/latest/collections/community/docker/index.html#scenario-guide\"&gt;https://docs.ansible.com/ansible/latest/collections/community/docker/index.html#scenario-guide&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;example (scroll to bottom):&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://docs.ansible.com/ansible/latest/collections/community/docker/docker_container_exec_module.html#ansible-collections-community-docker-docker-container-exec-module\"&gt;https://docs.ansible.com/ansible/latest/collections/community/docker/docker_container_exec_module.html#ansible-collections-community-docker-docker-container-exec-module&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;with ansible you can call on any module, shell script, command line, and it will take care of it.&lt;/p&gt;\n\n&lt;p&gt;compose seems kind of limiting?  wondering if i&amp;#39;m missing something here.&lt;/p&gt;\n\n&lt;p&gt;edit:&lt;/p&gt;\n\n&lt;p&gt;i&amp;#39;m trying to understand what the benefit of creating a docker-compose.yml file is vs having an ansible playbook which pulls/builds and image, then creates however many containers i want.&lt;/p&gt;\n\n&lt;p&gt;when i run compose, sometimes i get an issue with one container, and i have to shut down the entire pod vs just simply restarting a container or creating a new one to plug in with some kind of change.  (maybe this is due to my inexperience, but regardless i can&amp;#39;t see what the use is vs ansible)&lt;/p&gt;\n\n&lt;p&gt;given the down votes, people here seem to know some universal truth which i would like to be privy to.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12ajf0v", "is_robot_indexable": true, "report_reasons": null, "author": "iseestupid", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ajf0v/ansible_vs_dockercompose/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ajf0v/ansible_vs_dockercompose/", "subreddit_subscribers": 95630, "created_utc": 1680526117.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "creating visualizers for a local network packet spark kafka stream.  \nIs cassandra or hbase optimal options to link sql into javascript ui?\n\nsorting best practice options.  \nideas / library workflows ? appreciate, thanks !", "author_fullname": "t2_b356h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "best practice? spark kafka streaming visualizer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_129yef9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680470040.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;creating visualizers for a local network packet spark kafka stream.&lt;br/&gt;\nIs cassandra or hbase optimal options to link sql into javascript ui?&lt;/p&gt;\n\n&lt;p&gt;sorting best practice options.&lt;br/&gt;\nideas / library workflows ? appreciate, thanks !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "129yef9", "is_robot_indexable": true, "report_reasons": null, "author": "Kubrickann", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/129yef9/best_practice_spark_kafka_streaming_visualizer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/129yef9/best_practice_spark_kafka_streaming_visualizer/", "subreddit_subscribers": 95630, "created_utc": 1680470040.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://cumulativedata.com/power-of-functional-data-eng-p1-immutable-data/](https://cumulativedata.com/power-of-functional-data-eng-p1-immutable-data/)", "author_fullname": "t2_bkula0u9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Benefits of Immutable Data. Any thoughts on this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12aq8w8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1680540707.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://cumulativedata.com/power-of-functional-data-eng-p1-immutable-data/\"&gt;https://cumulativedata.com/power-of-functional-data-eng-p1-immutable-data/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9K4NDosRhAZ6KKgBiTz8P3MWmeZNtr8hSfhr8mE-2DE.jpg?auto=webp&amp;v=enabled&amp;s=aeb3e52e68df613846b3dfe1a916ded0959e2aa6", "width": 1280, "height": 720}, "resolutions": [{"url": "https://external-preview.redd.it/9K4NDosRhAZ6KKgBiTz8P3MWmeZNtr8hSfhr8mE-2DE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b27adcca11ba5d8e17e3169c154c03cc23732cbd", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/9K4NDosRhAZ6KKgBiTz8P3MWmeZNtr8hSfhr8mE-2DE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b1e53994de00b4c43a80aef4ddc597bae9eaacd5", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/9K4NDosRhAZ6KKgBiTz8P3MWmeZNtr8hSfhr8mE-2DE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3364e732c4da3b29306ff7bab63eabb7e12eafec", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/9K4NDosRhAZ6KKgBiTz8P3MWmeZNtr8hSfhr8mE-2DE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a26828dd753b4420f564053899cac6fdfecb8c62", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/9K4NDosRhAZ6KKgBiTz8P3MWmeZNtr8hSfhr8mE-2DE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b270202407da347125290565be8b3bb5f91e44b2", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/9K4NDosRhAZ6KKgBiTz8P3MWmeZNtr8hSfhr8mE-2DE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9eb8184d3947b1157f9e7e266085b88464b397d6", "width": 1080, "height": 607}], "variants": {}, "id": "HheWTeOZ7IR2Kx2CJdqe14TRaZNukZFIIgAkbK15EXg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12aq8w8", "is_robot_indexable": true, "report_reasons": null, "author": "ganildata", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12aq8w8/benefits_of_immutable_data_any_thoughts_on_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12aq8w8/benefits_of_immutable_data_any_thoughts_on_this/", "subreddit_subscribers": 95630, "created_utc": 1680540707.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So the company Im working for is going to start using informatica and snowflake this year. \n\nUsing informatica for attribution and snowflake over SQL server when we get the data loaded. \n\nI use python and SQL to create exhibits and I wanted to look at automation of the code we have written but everything I've seen looks like some compromise where I'll have rewrite my code either in an older version with distribution limits,( informatica ) or rewrite with snowflake syntax to take advantage of snowflakes automation. \n\nAny advice or suggestions to get work scheduled and executed with minimal overhead?", "author_fullname": "t2_og7kb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Workflow Advice (AXON, snowflake)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12apdq5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680538902.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So the company Im working for is going to start using informatica and snowflake this year. &lt;/p&gt;\n\n&lt;p&gt;Using informatica for attribution and snowflake over SQL server when we get the data loaded. &lt;/p&gt;\n\n&lt;p&gt;I use python and SQL to create exhibits and I wanted to look at automation of the code we have written but everything I&amp;#39;ve seen looks like some compromise where I&amp;#39;ll have rewrite my code either in an older version with distribution limits,( informatica ) or rewrite with snowflake syntax to take advantage of snowflakes automation. &lt;/p&gt;\n\n&lt;p&gt;Any advice or suggestions to get work scheduled and executed with minimal overhead?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12apdq5", "is_robot_indexable": true, "report_reasons": null, "author": "siddartha08", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12apdq5/workflow_advice_axon_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12apdq5/workflow_advice_axon_snowflake/", "subreddit_subscribers": 95630, "created_utc": 1680538902.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_84xrtbqe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Modeling \u2014 The Unsung Hero of Data Engineering: An Introduction to Data Modeling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 76, "top_awarded_type": null, "hide_score": false, "name": "t3_12ajow3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": "transparent", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/bjK3CBU3n488r2y3p_w1kyvEnfgdjkEK0En5isT7Leo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1680526746.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "airbyte.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://airbyte.com/blog/data-modeling-unsung-hero-data-engineering-introduction", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/SAyoTlavOaWSD9QIIOjDBgA-oR7v1CSPNjEG4w4qv2s.jpg?auto=webp&amp;v=enabled&amp;s=1e009804efda7b7b7b6c1104f73bb62d41e998b5", "width": 1398, "height": 759}, "resolutions": [{"url": "https://external-preview.redd.it/SAyoTlavOaWSD9QIIOjDBgA-oR7v1CSPNjEG4w4qv2s.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=255f9b3720522ccc5f459ab6d4a4b3103181aef8", "width": 108, "height": 58}, {"url": "https://external-preview.redd.it/SAyoTlavOaWSD9QIIOjDBgA-oR7v1CSPNjEG4w4qv2s.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=efcdc875d65e2b894e3b47ea6b698d528ff50415", "width": 216, "height": 117}, {"url": "https://external-preview.redd.it/SAyoTlavOaWSD9QIIOjDBgA-oR7v1CSPNjEG4w4qv2s.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e244af87dbf00d8f032e8f67ba6a60278807470b", "width": 320, "height": 173}, {"url": "https://external-preview.redd.it/SAyoTlavOaWSD9QIIOjDBgA-oR7v1CSPNjEG4w4qv2s.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5bf6e30dc275f40320de5e82f98bfbaf2bd1e847", "width": 640, "height": 347}, {"url": "https://external-preview.redd.it/SAyoTlavOaWSD9QIIOjDBgA-oR7v1CSPNjEG4w4qv2s.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dbb7305a165ec77f701d933a0969a110d4dd4771", "width": 960, "height": 521}, {"url": "https://external-preview.redd.it/SAyoTlavOaWSD9QIIOjDBgA-oR7v1CSPNjEG4w4qv2s.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6d74fbd8ec801f23ce1dc9cceabf5626ba8e99bf", "width": 1080, "height": 586}], "variants": {}, "id": "KGZwY_YJwT4tnaZ5moKRhK-bGNrCeUtsw8K4Srleym4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12ajow3", "is_robot_indexable": true, "report_reasons": null, "author": "sspaeti", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/12ajow3/data_modeling_the_unsung_hero_of_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://airbyte.com/blog/data-modeling-unsung-hero-data-engineering-introduction", "subreddit_subscribers": 95630, "created_utc": 1680526746.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}