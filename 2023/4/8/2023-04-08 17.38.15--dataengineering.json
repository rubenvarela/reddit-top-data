{"kind": "Listing", "data": {"after": null, "dist": 13, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello folks,\n\nI know there would have been many discussions on this before, but being new to the field and going to work as a Data engineer now soon, I wanted to know is there any value in the concept of Data Mesh? Is it the next big thing? Or is this paradigm shift currently being used in the industry already?", "author_fullname": "t2_iascmrib", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Mesh", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12fbvd5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680929346.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello folks,&lt;/p&gt;\n\n&lt;p&gt;I know there would have been many discussions on this before, but being new to the field and going to work as a Data engineer now soon, I wanted to know is there any value in the concept of Data Mesh? Is it the next big thing? Or is this paradigm shift currently being used in the industry already?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12fbvd5", "is_robot_indexable": true, "report_reasons": null, "author": "catchereye22", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12fbvd5/data_mesh/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12fbvd5/data_mesh/", "subreddit_subscribers": 96874, "created_utc": 1680929346.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m not a data engineer so please don\u2019t derail thread if I\u2019m using the wrong terms\n\n but I am having to re do a large data pipeline that moves data between redshift , databrix, and our front end ui\n\nI basically need a way to check if the data is being pulled thru correctly and the transformations are being done correctly\n\nI\u2019m sure you data engineers have ways to QA this in a structured way.\n\nCould you please either give me an online resource to read or the correct terms to Google so I can find it myself :)?\n\nThanks In advance", "author_fullname": "t2_7jjttbji", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resource for creating a QA testing plan", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ez3ca", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680901037.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m not a data engineer so please don\u2019t derail thread if I\u2019m using the wrong terms&lt;/p&gt;\n\n&lt;p&gt;but I am having to re do a large data pipeline that moves data between redshift , databrix, and our front end ui&lt;/p&gt;\n\n&lt;p&gt;I basically need a way to check if the data is being pulled thru correctly and the transformations are being done correctly&lt;/p&gt;\n\n&lt;p&gt;I\u2019m sure you data engineers have ways to QA this in a structured way.&lt;/p&gt;\n\n&lt;p&gt;Could you please either give me an online resource to read or the correct terms to Google so I can find it myself :)?&lt;/p&gt;\n\n&lt;p&gt;Thanks In advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12ez3ca", "is_robot_indexable": true, "report_reasons": null, "author": "Mysterious-Recipe-38", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ez3ca/resource_for_creating_a_qa_testing_plan/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ez3ca/resource_for_creating_a_qa_testing_plan/", "subreddit_subscribers": 96874, "created_utc": 1680901037.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys,\n\nI am terrible at writing SQL and struggle with the most simple queries. I am basically a visualisation analyst. However I am really good at knowing how data should be modelled so it can be used for reporting (in a flexible way). I often get frustrated in waiting for engineers to model the data and wish I could do it myself. \n\nIs it worth learning the code side of things and becoming a data engineer given I generally know the upstream requirements so well?", "author_fullname": "t2_a7nec5bo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this a strange skill as an analyst?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12fm8md", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680960798.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,&lt;/p&gt;\n\n&lt;p&gt;I am terrible at writing SQL and struggle with the most simple queries. I am basically a visualisation analyst. However I am really good at knowing how data should be modelled so it can be used for reporting (in a flexible way). I often get frustrated in waiting for engineers to model the data and wish I could do it myself. &lt;/p&gt;\n\n&lt;p&gt;Is it worth learning the code side of things and becoming a data engineer given I generally know the upstream requirements so well?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12fm8md", "is_robot_indexable": true, "report_reasons": null, "author": "TheCumCopter", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12fm8md/is_this_a_strange_skill_as_an_analyst/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12fm8md/is_this_a_strange_skill_as_an_analyst/", "subreddit_subscribers": 96874, "created_utc": 1680960798.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a PythonOperator task in Airflow that outputs e.g. `['instance-id', 128.2.4.33]` and in the downstream task I reference this task' output using dynamic task mapping by `expand` and I reference the output like `upstream_python_task.output`, however this gives me the entire list with both values but my downstream task (`EC2StartInstanceOperator`) needs only 1 value (`instance_id`). I tried `upstream_python_task.output[0]` but that gives an error. How to reference the first element of the output?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow - get value at specific index of the task output", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12fdqf0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680935315.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a PythonOperator task in Airflow that outputs e.g. &lt;code&gt;[&amp;#39;instance-id&amp;#39;, 128.2.4.33]&lt;/code&gt; and in the downstream task I reference this task&amp;#39; output using dynamic task mapping by &lt;code&gt;expand&lt;/code&gt; and I reference the output like &lt;code&gt;upstream_python_task.output&lt;/code&gt;, however this gives me the entire list with both values but my downstream task (&lt;code&gt;EC2StartInstanceOperator&lt;/code&gt;) needs only 1 value (&lt;code&gt;instance_id&lt;/code&gt;). I tried &lt;code&gt;upstream_python_task.output[0]&lt;/code&gt; but that gives an error. How to reference the first element of the output?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12fdqf0", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12fdqf0/airflow_get_value_at_specific_index_of_the_task/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12fdqf0/airflow_get_value_at_specific_index_of_the_task/", "subreddit_subscribers": 96874, "created_utc": 1680935315.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**Context**\n\nWorking at startup, where I own the entire analytics function - it's a blast, but I'm very time constrained at the moment.\n\nI've been using Redshift in an analyst capacity on and off for 10 years and I have considerable experience creating my own Python+S3+Redshift pipelines (e.g. frustrated analyst turning into data engineer).\n\nI don't have as much experience with some of the other AWS DE-related offerings (aside from tinkering here and there).\n\n&amp;#x200B;\n\n**Dilemma**\n\nI have what I thought would be a fairly routine. Perhaps not simple, but nothing unorthodox either and the data is structured well. I thought.\n\nI mainly am looking for some guidance on if I'm off track, making a simple error, using the wrong tool/approach  or anything else? I'm fine doggedly getting to the solution if I know I'm on track, but I'm beginning to wonder if I have some faulty thinking.\n\n&amp;#x200B;\n\n**Details**\n\nWe license a data set which consists of 18 tables.  \nUnless otherwise noted, all \"files\" here are received as gzipped JSONL.   \nWe receive the following:\n\n1. One time snapshot/data dump of each table as a single file (in S3)\n2. Daily updates\n   1. 0-18 delta files each day (1 file/table, but may not be a file the source table hasn't been modified). These files include both new records to create and updates to existing records.\n      1. Fairly standard directory structure where each day has a directory nested as /YYYY/MM/DD/ containng up to 18 data files named using the convention: ***table\\_name***\\_deltas\\_***YYYYMMDD.json.gz***\n      2. The delta files are not materially different from the original snapshot files... there are just a lot fewer rows.\n   2. 1 file containing records to delete plus which table that record is in (e.g. *deleted\\_id,* *deleted\\_from\\_table\\_name).* This also contains records to *merge*, but for reason I'll note in a moment, let's just ignore that for now.\n   3. 1 \"manifest\" file that contains the following for each file in bullet 2.1\n      1. Filename\n      2. \\# total records in file\n      3. \\# new records\n      4. \\# update existing record\n\n&amp;#x200B;\n\nAt the point, I am not trying to deal with any transformation/deletes/merges etc. I simply want to take all of the files an continue appending each daily delta. I was planning to do the same and to create 2 more tables to track the contents of the manifest and delete/merge files. \n\n&amp;#x200B;\n\nMy logic was that if I can just get all the records into Redshift I'll at quickly check facts for certain records or group of records. I don't need all of the updates/merges/deletes neatly reconciled into the final state for each record.\n\nI'd also prefer to keep that logic in dbt/Redshift, with a clear audit trail of any edits.\n\n&amp;#x200B;\n\n**Questions**\n\n1. Given the description of the data and the desire to get the files from S3&gt;Redshift.... what would folks recommend here? Is there anything \"out of the box\" option to simply continue appending the daily updates... then I can sort of the rest later as long as I know the complete delta history is there.\n2. I had envisioned Glue as a solution to create a catalog of the files, which would also make it easy to \"re-run\" the entire job when there is the occasional schema change e.g. new column  (which entails a new snapshot data dump, and then picking up with daily deltas from that new snapshot date. In my experience, I could not even get the crawler to recognize the original 18 files to create the snapshot... never mind appending the new records for each day. Am I totally off base with what I was trying to accomplish? Or does this sound more like user error, which could be solved by a little more effort/patience on my part?", "author_fullname": "t2_657ct", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Daily JSONL files in S3 &gt;&gt; ?? &gt;&gt; Redshift... am I on the right track?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12f6old", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680916738.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Context&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Working at startup, where I own the entire analytics function - it&amp;#39;s a blast, but I&amp;#39;m very time constrained at the moment.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been using Redshift in an analyst capacity on and off for 10 years and I have considerable experience creating my own Python+S3+Redshift pipelines (e.g. frustrated analyst turning into data engineer).&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have as much experience with some of the other AWS DE-related offerings (aside from tinkering here and there).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Dilemma&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I have what I thought would be a fairly routine. Perhaps not simple, but nothing unorthodox either and the data is structured well. I thought.&lt;/p&gt;\n\n&lt;p&gt;I mainly am looking for some guidance on if I&amp;#39;m off track, making a simple error, using the wrong tool/approach  or anything else? I&amp;#39;m fine doggedly getting to the solution if I know I&amp;#39;m on track, but I&amp;#39;m beginning to wonder if I have some faulty thinking.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Details&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;We license a data set which consists of 18 tables.&lt;br/&gt;\nUnless otherwise noted, all &amp;quot;files&amp;quot; here are received as gzipped JSONL.&lt;br/&gt;\nWe receive the following:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;One time snapshot/data dump of each table as a single file (in S3)&lt;/li&gt;\n&lt;li&gt;Daily updates\n\n&lt;ol&gt;\n&lt;li&gt;0-18 delta files each day (1 file/table, but may not be a file the source table hasn&amp;#39;t been modified). These files include both new records to create and updates to existing records.\n\n&lt;ol&gt;\n&lt;li&gt;Fairly standard directory structure where each day has a directory nested as /YYYY/MM/DD/ containng up to 18 data files named using the convention: &lt;strong&gt;&lt;em&gt;table_name&lt;/em&gt;&lt;/strong&gt;_deltas_&lt;strong&gt;&lt;em&gt;YYYYMMDD.json.gz&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;The delta files are not materially different from the original snapshot files... there are just a lot fewer rows.&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;1 file containing records to delete plus which table that record is in (e.g. &lt;em&gt;deleted_id,&lt;/em&gt; &lt;em&gt;deleted_from_table_name).&lt;/em&gt; This also contains records to &lt;em&gt;merge&lt;/em&gt;, but for reason I&amp;#39;ll note in a moment, let&amp;#39;s just ignore that for now.&lt;/li&gt;\n&lt;li&gt;1 &amp;quot;manifest&amp;quot; file that contains the following for each file in bullet 2.1\n\n&lt;ol&gt;\n&lt;li&gt;Filename&lt;/li&gt;\n&lt;li&gt;# total records in file&lt;/li&gt;\n&lt;li&gt;# new records&lt;/li&gt;\n&lt;li&gt;# update existing record&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;At the point, I am not trying to deal with any transformation/deletes/merges etc. I simply want to take all of the files an continue appending each daily delta. I was planning to do the same and to create 2 more tables to track the contents of the manifest and delete/merge files. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My logic was that if I can just get all the records into Redshift I&amp;#39;ll at quickly check facts for certain records or group of records. I don&amp;#39;t need all of the updates/merges/deletes neatly reconciled into the final state for each record.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d also prefer to keep that logic in dbt/Redshift, with a clear audit trail of any edits.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Questions&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Given the description of the data and the desire to get the files from S3&amp;gt;Redshift.... what would folks recommend here? Is there anything &amp;quot;out of the box&amp;quot; option to simply continue appending the daily updates... then I can sort of the rest later as long as I know the complete delta history is there.&lt;/li&gt;\n&lt;li&gt;I had envisioned Glue as a solution to create a catalog of the files, which would also make it easy to &amp;quot;re-run&amp;quot; the entire job when there is the occasional schema change e.g. new column  (which entails a new snapshot data dump, and then picking up with daily deltas from that new snapshot date. In my experience, I could not even get the crawler to recognize the original 18 files to create the snapshot... never mind appending the new records for each day. Am I totally off base with what I was trying to accomplish? Or does this sound more like user error, which could be solved by a little more effort/patience on my part?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12f6old", "is_robot_indexable": true, "report_reasons": null, "author": "jslacks", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12f6old/daily_jsonl_files_in_s3_redshift_am_i_on_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12f6old/daily_jsonl_files_in_s3_redshift_am_i_on_the/", "subreddit_subscribers": 96874, "created_utc": 1680916738.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys,\n\nI've been working for a large IT consultant for over 8 months now. I started here as a data engineering trainee, earning certificates etc. After a short training of two months I was put on a data migration project which is currently running. My responsibility is to write SQL that completely transform the data to make it compatible with the SAP S4 HANA system to which we are migrating. I like this project and I am learning a lot. My manager said that \"he is so impressed by my skills\" that he doesn't want me to leave the migration team after this project ends. It is considered an honor to be able to join the migration experts as it is one of the most complex stuff that you can do with data. \n\nIn the past few months I have noticed how much I like SQL. I've written code in all kinds of procedural languages but SQL is different. Every query is like a puzzle and I like that. Especially the SQL that I am writing for data migration requires very deep thinking. So I really want to delve deeper into SQL and learn everything there is about it. \n\nThe issue is that data migration, while fun, doesn't allow me to fully explore SQL Server. Its mainly (admittedly) complex DML. So, I am planning to join the Microsoft team at our company as a DBA (if the opportunity presents itself). Do you guys think this is a wise career move?", "author_fullname": "t2_idmfe2je", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I aspire to become a SQL DBA", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12fd84i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680933554.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been working for a large IT consultant for over 8 months now. I started here as a data engineering trainee, earning certificates etc. After a short training of two months I was put on a data migration project which is currently running. My responsibility is to write SQL that completely transform the data to make it compatible with the SAP S4 HANA system to which we are migrating. I like this project and I am learning a lot. My manager said that &amp;quot;he is so impressed by my skills&amp;quot; that he doesn&amp;#39;t want me to leave the migration team after this project ends. It is considered an honor to be able to join the migration experts as it is one of the most complex stuff that you can do with data. &lt;/p&gt;\n\n&lt;p&gt;In the past few months I have noticed how much I like SQL. I&amp;#39;ve written code in all kinds of procedural languages but SQL is different. Every query is like a puzzle and I like that. Especially the SQL that I am writing for data migration requires very deep thinking. So I really want to delve deeper into SQL and learn everything there is about it. &lt;/p&gt;\n\n&lt;p&gt;The issue is that data migration, while fun, doesn&amp;#39;t allow me to fully explore SQL Server. Its mainly (admittedly) complex DML. So, I am planning to join the Microsoft team at our company as a DBA (if the opportunity presents itself). Do you guys think this is a wise career move?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12fd84i", "is_robot_indexable": true, "report_reasons": null, "author": "DarthDatar-4058", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12fd84i/i_aspire_to_become_a_sql_dba/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12fd84i/i_aspire_to_become_a_sql_dba/", "subreddit_subscribers": 96874, "created_utc": 1680933554.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The main objective was to scale down redshift nodes.\n\nSo i deleted the data from the cluster to free up one node.\n\nI don't have complete acces to the data warehouse so my task was to just delete the data.\n\nNow we will be scaling it down.\n\nI just want to make sure of some points:\n* Do we have to move data from one node to another to delete. \nI read multiple articles some stated that you would have to redistribute the data from the deleting to other nodes manually.\n\nOthers stated while scaling down the Redshift will take care of redsitributon itself.\n\nI just want to make sure that is there any action require from my side.\n\n\n* Scaling Down :\n\nWe can scale down using queries and UI  both, right?\n\nWhat practice are the best?\n\nI read that we can only scale up and down in a pair i.e we can go 2 up or 2 down. While i read somewhere that we can go as we choose.\n\n* While Scaling Down: \nWhat things to keep in mind while scaling down.\n\nI can stop all the etl pipelines or any transaction that will be happening while scaling down.\n\nI read while scaling down the all transactional queries are put on hold, but it would be better to stop them while scaling down, i think.\n\nPlease let me know any thing i have to keep in mind while scaling down.", "author_fullname": "t2_l38csc3b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scaling Down AWS Redshift", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12faj3u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680925921.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The main objective was to scale down redshift nodes.&lt;/p&gt;\n\n&lt;p&gt;So i deleted the data from the cluster to free up one node.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have complete acces to the data warehouse so my task was to just delete the data.&lt;/p&gt;\n\n&lt;p&gt;Now we will be scaling it down.&lt;/p&gt;\n\n&lt;p&gt;I just want to make sure of some points:\n* Do we have to move data from one node to another to delete. \nI read multiple articles some stated that you would have to redistribute the data from the deleting to other nodes manually.&lt;/p&gt;\n\n&lt;p&gt;Others stated while scaling down the Redshift will take care of redsitributon itself.&lt;/p&gt;\n\n&lt;p&gt;I just want to make sure that is there any action require from my side.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Scaling Down :&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;We can scale down using queries and UI  both, right?&lt;/p&gt;\n\n&lt;p&gt;What practice are the best?&lt;/p&gt;\n\n&lt;p&gt;I read that we can only scale up and down in a pair i.e we can go 2 up or 2 down. While i read somewhere that we can go as we choose.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;While Scaling Down: \nWhat things to keep in mind while scaling down.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I can stop all the etl pipelines or any transaction that will be happening while scaling down.&lt;/p&gt;\n\n&lt;p&gt;I read while scaling down the all transactional queries are put on hold, but it would be better to stop them while scaling down, i think.&lt;/p&gt;\n\n&lt;p&gt;Please let me know any thing i have to keep in mind while scaling down.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12faj3u", "is_robot_indexable": true, "report_reasons": null, "author": "AdSure744", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12faj3u/scaling_down_aws_redshift/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12faj3u/scaling_down_aws_redshift/", "subreddit_subscribers": 96874, "created_utc": 1680925921.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been a DE now for about 5 years working at startups, FAANG, and medium sized companies. I'm currently a Sr DE at medium sized company and honestly feel I've plateaued in terms of technical skills. I've worked with all the big data frameworks (Kafka, Spark, Airflow, etc) in a managed setting, meaning Databricks spark, Confluence Kafka, Astronomer Airflow. I honestly don't know if it's worth me investing time into Kubernetes to actually deploy all these things internally. My goal is to switch careers and transition into a ML Engineer focusing on infrastructure. I think the best course of action in the short-term would be to transition into a backend Software Engineer. Anyone have thoughts or has gone through a similar situation in their data engineering career?\n\n[View Poll](https://www.reddit.com/poll/12f47e2)", "author_fullname": "t2_hffo35vl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Starting to plateau", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12f47e2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680911403.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been a DE now for about 5 years working at startups, FAANG, and medium sized companies. I&amp;#39;m currently a Sr DE at medium sized company and honestly feel I&amp;#39;ve plateaued in terms of technical skills. I&amp;#39;ve worked with all the big data frameworks (Kafka, Spark, Airflow, etc) in a managed setting, meaning Databricks spark, Confluence Kafka, Astronomer Airflow. I honestly don&amp;#39;t know if it&amp;#39;s worth me investing time into Kubernetes to actually deploy all these things internally. My goal is to switch careers and transition into a ML Engineer focusing on infrastructure. I think the best course of action in the short-term would be to transition into a backend Software Engineer. Anyone have thoughts or has gone through a similar situation in their data engineering career?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/12f47e2\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12f47e2", "is_robot_indexable": true, "report_reasons": null, "author": "domestic_protobuf", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1681343403028, "options": [{"text": "Learn Kubernetes", "id": "22451396"}, {"text": "Switch to Software Engineering", "id": "22451397"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 251, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12f47e2/starting_to_plateau/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/12f47e2/starting_to_plateau/", "subreddit_subscribers": 96874, "created_utc": 1680911403.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ll keep this short. As a DE do you ever build server and client applications? Whether you\u2019re collecting custom logs, dealing with RPCs, or whatever. \n\nMaybe you have platform tools provided, or use existing stacks for queues or Kafka or whatever. I\u2019m looking to see your experiences in this area.", "author_fullname": "t2_v98q7m1n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much server and client building do you do?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12f2hty", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680907865.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ll keep this short. As a DE do you ever build server and client applications? Whether you\u2019re collecting custom logs, dealing with RPCs, or whatever. &lt;/p&gt;\n\n&lt;p&gt;Maybe you have platform tools provided, or use existing stacks for queues or Kafka or whatever. I\u2019m looking to see your experiences in this area.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12f2hty", "is_robot_indexable": true, "report_reasons": null, "author": "bryangoodrich", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12f2hty/how_much_server_and_client_building_do_you_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12f2hty/how_much_server_and_client_building_do_you_do/", "subreddit_subscribers": 96874, "created_utc": 1680907865.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been using chatGPT for a while now. It's great at making boilerplate code and can get most of the way there to getting a working script on the first try.  So while I don't think it's coming for any Data Engineering jobs (companies will surely try though), it does make the interviewing process a little more difficult for testing a candidate's technical capabilities.\n\nThere's various ways to test technical capabilities of a candidate. Common ones have been take home projects, live coding, take home case studies, live case studies. I feel anything take home is pointless at this point because the candidate can just throw it into chatgpt and then spend all their time understanding the code so they can confidently talk to it. Then again, that's the typical development workflow lol.\n\nI haven't interviewed anyone since ChatGPT, so I'm curious how companies are working around that. I've always preferred more of a conversational case study where we role play stakeholder vs hiring role. Different levels of seniority will have different expectations and if the conversation goes well, we move to something like live diagramming a pipeline. I'll usually adapt the conversation to a domain the candidate is experienced in. No real wrong answers, but gives me a sense at how well they understand the fundamentals cause I want someone that can ask chatgpt for code and be like \"nah that's not it\".", "author_fullname": "t2_rdm9w1f0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Leaders: Has your hiring style changed with the release of chatGPT4?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12fp9u5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680967531.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been using chatGPT for a while now. It&amp;#39;s great at making boilerplate code and can get most of the way there to getting a working script on the first try.  So while I don&amp;#39;t think it&amp;#39;s coming for any Data Engineering jobs (companies will surely try though), it does make the interviewing process a little more difficult for testing a candidate&amp;#39;s technical capabilities.&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s various ways to test technical capabilities of a candidate. Common ones have been take home projects, live coding, take home case studies, live case studies. I feel anything take home is pointless at this point because the candidate can just throw it into chatgpt and then spend all their time understanding the code so they can confidently talk to it. Then again, that&amp;#39;s the typical development workflow lol.&lt;/p&gt;\n\n&lt;p&gt;I haven&amp;#39;t interviewed anyone since ChatGPT, so I&amp;#39;m curious how companies are working around that. I&amp;#39;ve always preferred more of a conversational case study where we role play stakeholder vs hiring role. Different levels of seniority will have different expectations and if the conversation goes well, we move to something like live diagramming a pipeline. I&amp;#39;ll usually adapt the conversation to a domain the candidate is experienced in. No real wrong answers, but gives me a sense at how well they understand the fundamentals cause I want someone that can ask chatgpt for code and be like &amp;quot;nah that&amp;#39;s not it&amp;quot;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "12fp9u5", "is_robot_indexable": true, "report_reasons": null, "author": "keeney_arcadia", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12fp9u5/leaders_has_your_hiring_style_changed_with_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12fp9u5/leaders_has_your_hiring_style_changed_with_the/", "subreddit_subscribers": 96874, "created_utc": 1680967531.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nJust wondering what the general consensus is about strings in fact tables when it comes to things like Dedicated Pool or Redshift.\n\nTraditionally I would set the Order Type, Order Status etc. to the FK's that join to the dimension.  When it comes to MPP I'm wondering if I should store those fields as strings instead.  My reasons being:\n\n1) Reduce the need for users to do 2/3/4 extra joins to get descriptions (improving query speed)\n2) Following on from 1, reducing users filtering on the above join table fields, rather than on the fact directly\n3) When doing live queries from Tableau I'd hope the estimates would be more accurate\n\nIs this reasonable?  Or am I best just to test it thoroughly?\n\nTIA \ud83d\ude42", "author_fullname": "t2_9h6gf9pp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dedicated Pool Fact Table: Do you allow strings?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12etz55", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680890982.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;Just wondering what the general consensus is about strings in fact tables when it comes to things like Dedicated Pool or Redshift.&lt;/p&gt;\n\n&lt;p&gt;Traditionally I would set the Order Type, Order Status etc. to the FK&amp;#39;s that join to the dimension.  When it comes to MPP I&amp;#39;m wondering if I should store those fields as strings instead.  My reasons being:&lt;/p&gt;\n\n&lt;p&gt;1) Reduce the need for users to do 2/3/4 extra joins to get descriptions (improving query speed)\n2) Following on from 1, reducing users filtering on the above join table fields, rather than on the fact directly\n3) When doing live queries from Tableau I&amp;#39;d hope the estimates would be more accurate&lt;/p&gt;\n\n&lt;p&gt;Is this reasonable?  Or am I best just to test it thoroughly?&lt;/p&gt;\n\n&lt;p&gt;TIA \ud83d\ude42&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12etz55", "is_robot_indexable": true, "report_reasons": null, "author": "V10Matt", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12etz55/dedicated_pool_fact_table_do_you_allow_strings/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12etz55/dedicated_pool_fact_table_do_you_allow_strings/", "subreddit_subscribers": 96874, "created_utc": 1680890982.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "After 1 one of studying for data engineering, my personal opinion is that data engineering seems more similar to a software engineer/developer role than a data analyst role as I had believed before I started my course of study.  \n\n\nAny thought?", "author_fullname": "t2_liwvvwau", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Software engineer/developer or Data Analyst? Which one is more similar.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12fo8lc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680965175.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After 1 one of studying for data engineering, my personal opinion is that data engineering seems more similar to a software engineer/developer role than a data analyst role as I had believed before I started my course of study.  &lt;/p&gt;\n\n&lt;p&gt;Any thought?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12fo8lc", "is_robot_indexable": true, "report_reasons": null, "author": "post_lupy", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12fo8lc/software_engineerdeveloper_or_data_analyst_which/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12fo8lc/software_engineerdeveloper_or_data_analyst_which/", "subreddit_subscribers": 96874, "created_utc": 1680965175.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've decided to change career last Feb 2022.  \n\n\nSince then I tried to learn all I could.  \nNow, on April 2023 I can say I know **Python** only up to solve **4kyu problems** on Codewars, **SQL** up to **intermediate** problems on Hackerrank and I only have knowledge of how AWS works (but I never tried to use it), CI/CD (but never put into practice, I can use some functionalities of **PyCharm, GitHub and Visual Studio Code**, I know few keywords of **GIT**, and some knowledge (that it doesn't seem to be able to get stuck in my head) about databases, clouds, pipelines and ETL processes...  \n\n\nI'm scared to apply cause I believe I will never pass a technical interview.  \n\n\nI think that at least you gotta know how to build a proper **ETL pipeline** to get started as a Junior data engineer but I just can't remember anything I learn.", "author_fullname": "t2_liwvvwau", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I a fraud? Trying to find a job as Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12fj2we", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.29, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680953228.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve decided to change career last Feb 2022.  &lt;/p&gt;\n\n&lt;p&gt;Since then I tried to learn all I could.&lt;br/&gt;\nNow, on April 2023 I can say I know &lt;strong&gt;Python&lt;/strong&gt; only up to solve &lt;strong&gt;4kyu problems&lt;/strong&gt; on Codewars, &lt;strong&gt;SQL&lt;/strong&gt; up to &lt;strong&gt;intermediate&lt;/strong&gt; problems on Hackerrank and I only have knowledge of how AWS works (but I never tried to use it), CI/CD (but never put into practice, I can use some functionalities of &lt;strong&gt;PyCharm, GitHub and Visual Studio Code&lt;/strong&gt;, I know few keywords of &lt;strong&gt;GIT&lt;/strong&gt;, and some knowledge (that it doesn&amp;#39;t seem to be able to get stuck in my head) about databases, clouds, pipelines and ETL processes...  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m scared to apply cause I believe I will never pass a technical interview.  &lt;/p&gt;\n\n&lt;p&gt;I think that at least you gotta know how to build a proper &lt;strong&gt;ETL pipeline&lt;/strong&gt; to get started as a Junior data engineer but I just can&amp;#39;t remember anything I learn.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12fj2we", "is_robot_indexable": true, "report_reasons": null, "author": "post_lupy", "discussion_type": null, "num_comments": 10, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12fj2we/am_i_a_fraud_trying_to_find_a_job_as_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12fj2we/am_i_a_fraud_trying_to_find_a_job_as_data_engineer/", "subreddit_subscribers": 96874, "created_utc": 1680953228.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}