{"kind": "Listing", "data": {"after": null, "dist": 14, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello folks,\n\nI know there would have been many discussions on this before, but being new to the field and going to work as a Data engineer now soon, I wanted to know is there any value in the concept of Data Mesh? Is it the next big thing? Or is this paradigm shift currently being used in the industry already?", "author_fullname": "t2_iascmrib", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Mesh", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12fbvd5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680929346.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello folks,&lt;/p&gt;\n\n&lt;p&gt;I know there would have been many discussions on this before, but being new to the field and going to work as a Data engineer now soon, I wanted to know is there any value in the concept of Data Mesh? Is it the next big thing? Or is this paradigm shift currently being used in the industry already?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12fbvd5", "is_robot_indexable": true, "report_reasons": null, "author": "catchereye22", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12fbvd5/data_mesh/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12fbvd5/data_mesh/", "subreddit_subscribers": 96912, "created_utc": 1680929346.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys,\n\nI am terrible at writing SQL and struggle with the most simple queries. I am basically a visualisation analyst. However I am really good at knowing how data should be modelled so it can be used for reporting (in a flexible way). I often get frustrated in waiting for engineers to model the data and wish I could do it myself. \n\nIs it worth learning the code side of things and becoming a data engineer given I generally know the upstream requirements so well?", "author_fullname": "t2_a7nec5bo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this a strange skill as an analyst?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12fm8md", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680960798.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,&lt;/p&gt;\n\n&lt;p&gt;I am terrible at writing SQL and struggle with the most simple queries. I am basically a visualisation analyst. However I am really good at knowing how data should be modelled so it can be used for reporting (in a flexible way). I often get frustrated in waiting for engineers to model the data and wish I could do it myself. &lt;/p&gt;\n\n&lt;p&gt;Is it worth learning the code side of things and becoming a data engineer given I generally know the upstream requirements so well?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12fm8md", "is_robot_indexable": true, "report_reasons": null, "author": "TheCumCopter", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12fm8md/is_this_a_strange_skill_as_an_analyst/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12fm8md/is_this_a_strange_skill_as_an_analyst/", "subreddit_subscribers": 96912, "created_utc": 1680960798.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m not a data engineer so please don\u2019t derail thread if I\u2019m using the wrong terms\n\n but I am having to re do a large data pipeline that moves data between redshift , databrix, and our front end ui\n\nI basically need a way to check if the data is being pulled thru correctly and the transformations are being done correctly\n\nI\u2019m sure you data engineers have ways to QA this in a structured way.\n\nCould you please either give me an online resource to read or the correct terms to Google so I can find it myself :)?\n\nThanks In advance", "author_fullname": "t2_7jjttbji", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resource for creating a QA testing plan", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ez3ca", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680901037.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m not a data engineer so please don\u2019t derail thread if I\u2019m using the wrong terms&lt;/p&gt;\n\n&lt;p&gt;but I am having to re do a large data pipeline that moves data between redshift , databrix, and our front end ui&lt;/p&gt;\n\n&lt;p&gt;I basically need a way to check if the data is being pulled thru correctly and the transformations are being done correctly&lt;/p&gt;\n\n&lt;p&gt;I\u2019m sure you data engineers have ways to QA this in a structured way.&lt;/p&gt;\n\n&lt;p&gt;Could you please either give me an online resource to read or the correct terms to Google so I can find it myself :)?&lt;/p&gt;\n\n&lt;p&gt;Thanks In advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12ez3ca", "is_robot_indexable": true, "report_reasons": null, "author": "Mysterious-Recipe-38", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ez3ca/resource_for_creating_a_qa_testing_plan/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ez3ca/resource_for_creating_a_qa_testing_plan/", "subreddit_subscribers": 96912, "created_utc": 1680901037.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys,\n\nI've been working for a large IT consultant for over 8 months now. I started here as a data engineering trainee, earning certificates etc. After a short training of two months I was put on a data migration project which is currently running. My responsibility is to write SQL that completely transform the data to make it compatible with the SAP S4 HANA system to which we are migrating. I like this project and I am learning a lot. My manager said that \"he is so impressed by my skills\" that he doesn't want me to leave the migration team after this project ends. It is considered an honor to be able to join the migration experts as it is one of the most complex stuff that you can do with data. \n\nIn the past few months I have noticed how much I like SQL. I've written code in all kinds of procedural languages but SQL is different. Every query is like a puzzle and I like that. Especially the SQL that I am writing for data migration requires very deep thinking. So I really want to delve deeper into SQL and learn everything there is about it. \n\nThe issue is that data migration, while fun, doesn't allow me to fully explore SQL Server. Its mainly (admittedly) complex DML. So, I am planning to join the Microsoft team at our company as a DBA (if the opportunity presents itself). Do you guys think this is a wise career move?", "author_fullname": "t2_idmfe2je", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I aspire to become a SQL DBA", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12fd84i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680933554.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been working for a large IT consultant for over 8 months now. I started here as a data engineering trainee, earning certificates etc. After a short training of two months I was put on a data migration project which is currently running. My responsibility is to write SQL that completely transform the data to make it compatible with the SAP S4 HANA system to which we are migrating. I like this project and I am learning a lot. My manager said that &amp;quot;he is so impressed by my skills&amp;quot; that he doesn&amp;#39;t want me to leave the migration team after this project ends. It is considered an honor to be able to join the migration experts as it is one of the most complex stuff that you can do with data. &lt;/p&gt;\n\n&lt;p&gt;In the past few months I have noticed how much I like SQL. I&amp;#39;ve written code in all kinds of procedural languages but SQL is different. Every query is like a puzzle and I like that. Especially the SQL that I am writing for data migration requires very deep thinking. So I really want to delve deeper into SQL and learn everything there is about it. &lt;/p&gt;\n\n&lt;p&gt;The issue is that data migration, while fun, doesn&amp;#39;t allow me to fully explore SQL Server. Its mainly (admittedly) complex DML. So, I am planning to join the Microsoft team at our company as a DBA (if the opportunity presents itself). Do you guys think this is a wise career move?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12fd84i", "is_robot_indexable": true, "report_reasons": null, "author": "DarthDatar-4058", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12fd84i/i_aspire_to_become_a_sql_dba/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12fd84i/i_aspire_to_become_a_sql_dba/", "subreddit_subscribers": 96912, "created_utc": 1680933554.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a PythonOperator task in Airflow that outputs e.g. `['instance-id', 128.2.4.33]` and in the downstream task I reference this task' output using dynamic task mapping by `expand` and I reference the output like `upstream_python_task.output`, however this gives me the entire list with both values but my downstream task (`EC2StartInstanceOperator`) needs only 1 value (`instance_id`). I tried `upstream_python_task.output[0]` but that gives an error. How to reference the first element of the output?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow - get value at specific index of the task output", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12fdqf0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680935315.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a PythonOperator task in Airflow that outputs e.g. &lt;code&gt;[&amp;#39;instance-id&amp;#39;, 128.2.4.33]&lt;/code&gt; and in the downstream task I reference this task&amp;#39; output using dynamic task mapping by &lt;code&gt;expand&lt;/code&gt; and I reference the output like &lt;code&gt;upstream_python_task.output&lt;/code&gt;, however this gives me the entire list with both values but my downstream task (&lt;code&gt;EC2StartInstanceOperator&lt;/code&gt;) needs only 1 value (&lt;code&gt;instance_id&lt;/code&gt;). I tried &lt;code&gt;upstream_python_task.output[0]&lt;/code&gt; but that gives an error. How to reference the first element of the output?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12fdqf0", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12fdqf0/airflow_get_value_at_specific_index_of_the_task/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12fdqf0/airflow_get_value_at_specific_index_of_the_task/", "subreddit_subscribers": 96912, "created_utc": 1680935315.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**Context**\n\nWorking at startup, where I own the entire analytics function - it's a blast, but I'm very time constrained at the moment.\n\nI've been using Redshift in an analyst capacity on and off for 10 years and I have considerable experience creating my own Python+S3+Redshift pipelines (e.g. frustrated analyst turning into data engineer).\n\nI don't have as much experience with some of the other AWS DE-related offerings (aside from tinkering here and there).\n\n&amp;#x200B;\n\n**Dilemma**\n\nI have what I thought would be a fairly routine. Perhaps not simple, but nothing unorthodox either and the data is structured well. I thought.\n\nI mainly am looking for some guidance on if I'm off track, making a simple error, using the wrong tool/approach  or anything else? I'm fine doggedly getting to the solution if I know I'm on track, but I'm beginning to wonder if I have some faulty thinking.\n\n&amp;#x200B;\n\n**Details**\n\nWe license a data set which consists of 18 tables.  \nUnless otherwise noted, all \"files\" here are received as gzipped JSONL.   \nWe receive the following:\n\n1. One time snapshot/data dump of each table as a single file (in S3)\n2. Daily updates\n   1. 0-18 delta files each day (1 file/table, but may not be a file the source table hasn't been modified). These files include both new records to create and updates to existing records.\n      1. Fairly standard directory structure where each day has a directory nested as /YYYY/MM/DD/ containng up to 18 data files named using the convention: ***table\\_name***\\_deltas\\_***YYYYMMDD.json.gz***\n      2. The delta files are not materially different from the original snapshot files... there are just a lot fewer rows.\n   2. 1 file containing records to delete plus which table that record is in (e.g. *deleted\\_id,* *deleted\\_from\\_table\\_name).* This also contains records to *merge*, but for reason I'll note in a moment, let's just ignore that for now.\n   3. 1 \"manifest\" file that contains the following for each file in bullet 2.1\n      1. Filename\n      2. \\# total records in file\n      3. \\# new records\n      4. \\# update existing record\n\n&amp;#x200B;\n\nAt the point, I am not trying to deal with any transformation/deletes/merges etc. I simply want to take all of the files an continue appending each daily delta. I was planning to do the same and to create 2 more tables to track the contents of the manifest and delete/merge files. \n\n&amp;#x200B;\n\nMy logic was that if I can just get all the records into Redshift I'll at quickly check facts for certain records or group of records. I don't need all of the updates/merges/deletes neatly reconciled into the final state for each record.\n\nI'd also prefer to keep that logic in dbt/Redshift, with a clear audit trail of any edits.\n\n&amp;#x200B;\n\n**Questions**\n\n1. Given the description of the data and the desire to get the files from S3&gt;Redshift.... what would folks recommend here? Is there anything \"out of the box\" option to simply continue appending the daily updates... then I can sort of the rest later as long as I know the complete delta history is there.\n2. I had envisioned Glue as a solution to create a catalog of the files, which would also make it easy to \"re-run\" the entire job when there is the occasional schema change e.g. new column  (which entails a new snapshot data dump, and then picking up with daily deltas from that new snapshot date. In my experience, I could not even get the crawler to recognize the original 18 files to create the snapshot... never mind appending the new records for each day. Am I totally off base with what I was trying to accomplish? Or does this sound more like user error, which could be solved by a little more effort/patience on my part?", "author_fullname": "t2_657ct", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Daily JSONL files in S3 &gt;&gt; ?? &gt;&gt; Redshift... am I on the right track?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12f6old", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680916738.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Context&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Working at startup, where I own the entire analytics function - it&amp;#39;s a blast, but I&amp;#39;m very time constrained at the moment.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been using Redshift in an analyst capacity on and off for 10 years and I have considerable experience creating my own Python+S3+Redshift pipelines (e.g. frustrated analyst turning into data engineer).&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have as much experience with some of the other AWS DE-related offerings (aside from tinkering here and there).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Dilemma&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I have what I thought would be a fairly routine. Perhaps not simple, but nothing unorthodox either and the data is structured well. I thought.&lt;/p&gt;\n\n&lt;p&gt;I mainly am looking for some guidance on if I&amp;#39;m off track, making a simple error, using the wrong tool/approach  or anything else? I&amp;#39;m fine doggedly getting to the solution if I know I&amp;#39;m on track, but I&amp;#39;m beginning to wonder if I have some faulty thinking.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Details&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;We license a data set which consists of 18 tables.&lt;br/&gt;\nUnless otherwise noted, all &amp;quot;files&amp;quot; here are received as gzipped JSONL.&lt;br/&gt;\nWe receive the following:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;One time snapshot/data dump of each table as a single file (in S3)&lt;/li&gt;\n&lt;li&gt;Daily updates\n\n&lt;ol&gt;\n&lt;li&gt;0-18 delta files each day (1 file/table, but may not be a file the source table hasn&amp;#39;t been modified). These files include both new records to create and updates to existing records.\n\n&lt;ol&gt;\n&lt;li&gt;Fairly standard directory structure where each day has a directory nested as /YYYY/MM/DD/ containng up to 18 data files named using the convention: &lt;strong&gt;&lt;em&gt;table_name&lt;/em&gt;&lt;/strong&gt;_deltas_&lt;strong&gt;&lt;em&gt;YYYYMMDD.json.gz&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;The delta files are not materially different from the original snapshot files... there are just a lot fewer rows.&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;1 file containing records to delete plus which table that record is in (e.g. &lt;em&gt;deleted_id,&lt;/em&gt; &lt;em&gt;deleted_from_table_name).&lt;/em&gt; This also contains records to &lt;em&gt;merge&lt;/em&gt;, but for reason I&amp;#39;ll note in a moment, let&amp;#39;s just ignore that for now.&lt;/li&gt;\n&lt;li&gt;1 &amp;quot;manifest&amp;quot; file that contains the following for each file in bullet 2.1\n\n&lt;ol&gt;\n&lt;li&gt;Filename&lt;/li&gt;\n&lt;li&gt;# total records in file&lt;/li&gt;\n&lt;li&gt;# new records&lt;/li&gt;\n&lt;li&gt;# update existing record&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;At the point, I am not trying to deal with any transformation/deletes/merges etc. I simply want to take all of the files an continue appending each daily delta. I was planning to do the same and to create 2 more tables to track the contents of the manifest and delete/merge files. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My logic was that if I can just get all the records into Redshift I&amp;#39;ll at quickly check facts for certain records or group of records. I don&amp;#39;t need all of the updates/merges/deletes neatly reconciled into the final state for each record.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d also prefer to keep that logic in dbt/Redshift, with a clear audit trail of any edits.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Questions&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Given the description of the data and the desire to get the files from S3&amp;gt;Redshift.... what would folks recommend here? Is there anything &amp;quot;out of the box&amp;quot; option to simply continue appending the daily updates... then I can sort of the rest later as long as I know the complete delta history is there.&lt;/li&gt;\n&lt;li&gt;I had envisioned Glue as a solution to create a catalog of the files, which would also make it easy to &amp;quot;re-run&amp;quot; the entire job when there is the occasional schema change e.g. new column  (which entails a new snapshot data dump, and then picking up with daily deltas from that new snapshot date. In my experience, I could not even get the crawler to recognize the original 18 files to create the snapshot... never mind appending the new records for each day. Am I totally off base with what I was trying to accomplish? Or does this sound more like user error, which could be solved by a little more effort/patience on my part?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12f6old", "is_robot_indexable": true, "report_reasons": null, "author": "jslacks", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12f6old/daily_jsonl_files_in_s3_redshift_am_i_on_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12f6old/daily_jsonl_files_in_s3_redshift_am_i_on_the/", "subreddit_subscribers": 96912, "created_utc": 1680916738.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been a DE now for about 5 years working at startups, FAANG, and medium sized companies. I'm currently a Sr DE at medium sized company and honestly feel I've plateaued in terms of technical skills. I've worked with all the big data frameworks (Kafka, Spark, Airflow, etc) in a managed setting, meaning Databricks spark, Confluence Kafka, Astronomer Airflow. I honestly don't know if it's worth me investing time into Kubernetes to actually deploy all these things internally. My goal is to switch careers and transition into a ML Engineer focusing on infrastructure. I think the best course of action in the short-term would be to transition into a backend Software Engineer. Anyone have thoughts or has gone through a similar situation in their data engineering career?\n\n[View Poll](https://www.reddit.com/poll/12f47e2)", "author_fullname": "t2_hffo35vl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Starting to plateau", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12f47e2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680911403.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been a DE now for about 5 years working at startups, FAANG, and medium sized companies. I&amp;#39;m currently a Sr DE at medium sized company and honestly feel I&amp;#39;ve plateaued in terms of technical skills. I&amp;#39;ve worked with all the big data frameworks (Kafka, Spark, Airflow, etc) in a managed setting, meaning Databricks spark, Confluence Kafka, Astronomer Airflow. I honestly don&amp;#39;t know if it&amp;#39;s worth me investing time into Kubernetes to actually deploy all these things internally. My goal is to switch careers and transition into a ML Engineer focusing on infrastructure. I think the best course of action in the short-term would be to transition into a backend Software Engineer. Anyone have thoughts or has gone through a similar situation in their data engineering career?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/12f47e2\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12f47e2", "is_robot_indexable": true, "report_reasons": null, "author": "domestic_protobuf", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1681343403028, "options": [{"text": "Learn Kubernetes", "id": "22451396"}, {"text": "Switch to Software Engineering", "id": "22451397"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 280, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12f47e2/starting_to_plateau/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/12f47e2/starting_to_plateau/", "subreddit_subscribers": 96912, "created_utc": 1680911403.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The main objective was to scale down redshift nodes.\n\nSo i deleted the data from the cluster to free up one node.\n\nI don't have complete acces to the data warehouse so my task was to just delete the data.\n\nNow we will be scaling it down.\n\nI just want to make sure of some points:\n* Do we have to move data from one node to another to delete. \nI read multiple articles some stated that you would have to redistribute the data from the deleting to other nodes manually.\n\nOthers stated while scaling down the Redshift will take care of redsitributon itself.\n\nI just want to make sure that is there any action require from my side.\n\n\n* Scaling Down :\n\nWe can scale down using queries and UI  both, right?\n\nWhat practice are the best?\n\nI read that we can only scale up and down in a pair i.e we can go 2 up or 2 down. While i read somewhere that we can go as we choose.\n\n* While Scaling Down: \nWhat things to keep in mind while scaling down.\n\nI can stop all the etl pipelines or any transaction that will be happening while scaling down.\n\nI read while scaling down the all transactional queries are put on hold, but it would be better to stop them while scaling down, i think.\n\nPlease let me know any thing i have to keep in mind while scaling down.", "author_fullname": "t2_l38csc3b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scaling Down AWS Redshift", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12faj3u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680925921.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The main objective was to scale down redshift nodes.&lt;/p&gt;\n\n&lt;p&gt;So i deleted the data from the cluster to free up one node.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have complete acces to the data warehouse so my task was to just delete the data.&lt;/p&gt;\n\n&lt;p&gt;Now we will be scaling it down.&lt;/p&gt;\n\n&lt;p&gt;I just want to make sure of some points:\n* Do we have to move data from one node to another to delete. \nI read multiple articles some stated that you would have to redistribute the data from the deleting to other nodes manually.&lt;/p&gt;\n\n&lt;p&gt;Others stated while scaling down the Redshift will take care of redsitributon itself.&lt;/p&gt;\n\n&lt;p&gt;I just want to make sure that is there any action require from my side.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Scaling Down :&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;We can scale down using queries and UI  both, right?&lt;/p&gt;\n\n&lt;p&gt;What practice are the best?&lt;/p&gt;\n\n&lt;p&gt;I read that we can only scale up and down in a pair i.e we can go 2 up or 2 down. While i read somewhere that we can go as we choose.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;While Scaling Down: \nWhat things to keep in mind while scaling down.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I can stop all the etl pipelines or any transaction that will be happening while scaling down.&lt;/p&gt;\n\n&lt;p&gt;I read while scaling down the all transactional queries are put on hold, but it would be better to stop them while scaling down, i think.&lt;/p&gt;\n\n&lt;p&gt;Please let me know any thing i have to keep in mind while scaling down.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12faj3u", "is_robot_indexable": true, "report_reasons": null, "author": "AdSure744", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12faj3u/scaling_down_aws_redshift/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12faj3u/scaling_down_aws_redshift/", "subreddit_subscribers": 96912, "created_utc": 1680925921.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ll keep this short. As a DE do you ever build server and client applications? Whether you\u2019re collecting custom logs, dealing with RPCs, or whatever. \n\nMaybe you have platform tools provided, or use existing stacks for queues or Kafka or whatever. I\u2019m looking to see your experiences in this area.", "author_fullname": "t2_v98q7m1n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much server and client building do you do?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12f2hty", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680907865.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ll keep this short. As a DE do you ever build server and client applications? Whether you\u2019re collecting custom logs, dealing with RPCs, or whatever. &lt;/p&gt;\n\n&lt;p&gt;Maybe you have platform tools provided, or use existing stacks for queues or Kafka or whatever. I\u2019m looking to see your experiences in this area.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12f2hty", "is_robot_indexable": true, "report_reasons": null, "author": "bryangoodrich", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12f2hty/how_much_server_and_client_building_do_you_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12f2hty/how_much_server_and_client_building_do_you_do/", "subreddit_subscribers": 96912, "created_utc": 1680907865.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI'm currently employed as a site reliability engineer and earlier this year I started work on a small python project, initially just to make getting sports statistics from a league site a little easier because I like nerding out about football and baseball stats with friends, and just to have something to keep my python and SQL skills sharp for the day job. \n\nAfter making improvements to the code and researching more and more about how to store and query the stats I started getting really interested in data engineering and data analytics, and ended up turning my script into a python library so I can simply pass certain parameters for players, games and that sort of thing from the API I'm using.\n\nMy intention is to automate as much of the extraction and normalization of these stats as possible in order to spend more time playing with the actual data in something like Tableau and less time having to run the fetch script and refresh the data after every game concludes.\n\nSo off I went and started doing more research and learned about data pipelines via the wiki a bunch of youtube videos on dbt. One of those videos mentioned apache snowflake (also in the wiki), so I went and watched a couple of videos on that and read through the Getting Started series just to understand the concepts of what it does.\n\nThat's when I hit a brick wall.\n\ndbt and snowflake look incredibly powerful and I'd definitely like to learn them in more detail and get the chance to use them in a \"production\" setting (aka \"add to the resume\"), but for a side-project like this I feel like they're both very much 'overkill'. Or are they? I really don't know. \n\nI **think** what I want to build for my project is an ETL pipeline? I have code that essentially extracts and does a rough job structuring the data obtained from the API, and currently just dumps what I get locally into CSVs, which I then import into a SQLite DB and  spend a few minutes creating tables, cleaning up columns via joins before connecting tableau. \n\n---\n**tl;dr questions here:**\n\n1. if my goal is to spend less time doing the importing, cleaning up and normalizing of tables and columns in my db, is dbt the right tool/good option for such a small side project?\n2. if I want to then use a cloud warehouse to store and share my data plus connect other tools (like [hex for example](https://hex.tech/) to make a data story), is snowflake overkill for this, or should I be looking at a different platform?\n\nThanks!", "author_fullname": "t2_8476f0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SRE with aims of interest in pivoting to data engineering and analytics wondering about how to take my project to the next level", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12fw7gm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1680983218.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1680982819.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently employed as a site reliability engineer and earlier this year I started work on a small python project, initially just to make getting sports statistics from a league site a little easier because I like nerding out about football and baseball stats with friends, and just to have something to keep my python and SQL skills sharp for the day job. &lt;/p&gt;\n\n&lt;p&gt;After making improvements to the code and researching more and more about how to store and query the stats I started getting really interested in data engineering and data analytics, and ended up turning my script into a python library so I can simply pass certain parameters for players, games and that sort of thing from the API I&amp;#39;m using.&lt;/p&gt;\n\n&lt;p&gt;My intention is to automate as much of the extraction and normalization of these stats as possible in order to spend more time playing with the actual data in something like Tableau and less time having to run the fetch script and refresh the data after every game concludes.&lt;/p&gt;\n\n&lt;p&gt;So off I went and started doing more research and learned about data pipelines via the wiki a bunch of youtube videos on dbt. One of those videos mentioned apache snowflake (also in the wiki), so I went and watched a couple of videos on that and read through the Getting Started series just to understand the concepts of what it does.&lt;/p&gt;\n\n&lt;p&gt;That&amp;#39;s when I hit a brick wall.&lt;/p&gt;\n\n&lt;p&gt;dbt and snowflake look incredibly powerful and I&amp;#39;d definitely like to learn them in more detail and get the chance to use them in a &amp;quot;production&amp;quot; setting (aka &amp;quot;add to the resume&amp;quot;), but for a side-project like this I feel like they&amp;#39;re both very much &amp;#39;overkill&amp;#39;. Or are they? I really don&amp;#39;t know. &lt;/p&gt;\n\n&lt;p&gt;I &lt;strong&gt;think&lt;/strong&gt; what I want to build for my project is an ETL pipeline? I have code that essentially extracts and does a rough job structuring the data obtained from the API, and currently just dumps what I get locally into CSVs, which I then import into a SQLite DB and  spend a few minutes creating tables, cleaning up columns via joins before connecting tableau. &lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;&lt;strong&gt;tl;dr questions here:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;if my goal is to spend less time doing the importing, cleaning up and normalizing of tables and columns in my db, is dbt the right tool/good option for such a small side project?&lt;/li&gt;\n&lt;li&gt;if I want to then use a cloud warehouse to store and share my data plus connect other tools (like &lt;a href=\"https://hex.tech/\"&gt;hex for example&lt;/a&gt; to make a data story), is snowflake overkill for this, or should I be looking at a different platform?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_H2VDMrHzs3sTn03vbgH_16fMf0uqZt3t_lDFYBYr8o.jpg?auto=webp&amp;v=enabled&amp;s=2d34c3ecae7c1081c66ac264bcf2d3355adad31b", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/_H2VDMrHzs3sTn03vbgH_16fMf0uqZt3t_lDFYBYr8o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e24658b15fb6787d1bc18d93d1b7f49580a65a3f", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/_H2VDMrHzs3sTn03vbgH_16fMf0uqZt3t_lDFYBYr8o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=533999cd318d86322570bdcd79f240b6dd943ec6", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/_H2VDMrHzs3sTn03vbgH_16fMf0uqZt3t_lDFYBYr8o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=03b1fcb860a077e9bae494ed0ea9adc31b1c3cee", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/_H2VDMrHzs3sTn03vbgH_16fMf0uqZt3t_lDFYBYr8o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=151517569fc912fdeadf252d1e1a749ee4cb67cc", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/_H2VDMrHzs3sTn03vbgH_16fMf0uqZt3t_lDFYBYr8o.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7ee4e3d617c2b857cc61d6b15aedaf49801a7e68", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/_H2VDMrHzs3sTn03vbgH_16fMf0uqZt3t_lDFYBYr8o.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1f425a11b0f570761240fcb451f4d1f69352e75e", "width": 1080, "height": 567}], "variants": {}, "id": "YJAnpTCSeaf_UUxCO24arWlVvkKc8-Kg4cvjyLo4kw8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12fw7gm", "is_robot_indexable": true, "report_reasons": null, "author": "baezizbae", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12fw7gm/sre_with_aims_of_interest_in_pivoting_to_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12fw7gm/sre_with_aims_of_interest_in_pivoting_to_data/", "subreddit_subscribers": 96912, "created_utc": 1680982819.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "After 1 one of studying for data engineering, my personal opinion is that data engineering seems more similar to a software engineer/developer role than a data analyst role as I had believed before I started my course of study.  \n\n\nAny thought?", "author_fullname": "t2_liwvvwau", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Software engineer/developer or Data Analyst? Which one is more similar.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12fo8lc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680965175.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After 1 one of studying for data engineering, my personal opinion is that data engineering seems more similar to a software engineer/developer role than a data analyst role as I had believed before I started my course of study.  &lt;/p&gt;\n\n&lt;p&gt;Any thought?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12fo8lc", "is_robot_indexable": true, "report_reasons": null, "author": "post_lupy", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12fo8lc/software_engineerdeveloper_or_data_analyst_which/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12fo8lc/software_engineerdeveloper_or_data_analyst_which/", "subreddit_subscribers": 96912, "created_utc": 1680965175.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, is there anyone who had completed the Correlation One DS4A data engineering cohort 1 last year who is willing to chat with me about the program? I have a pending offer in IT business analyst but not sure if I should hold out to finish the data engineering fellowship(part of cohort 2) to then search for a job in data engineering. Not sure how effective the program is and how easy will it be to find an entry-level position. Thanks in advance!", "author_fullname": "t2_cvf11phr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a DS4A Data Engineer Cohort 1 Fellow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12fswm7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680975642.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, is there anyone who had completed the Correlation One DS4A data engineering cohort 1 last year who is willing to chat with me about the program? I have a pending offer in IT business analyst but not sure if I should hold out to finish the data engineering fellowship(part of cohort 2) to then search for a job in data engineering. Not sure how effective the program is and how easy will it be to find an entry-level position. Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12fswm7", "is_robot_indexable": true, "report_reasons": null, "author": "Mediocre-Barracuda69", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12fswm7/looking_for_a_ds4a_data_engineer_cohort_1_fellow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12fswm7/looking_for_a_ds4a_data_engineer_cohort_1_fellow/", "subreddit_subscribers": 96912, "created_utc": 1680975642.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\nI've been DE for 3 years, I worked with Azure, GCP, AWS. I know pySpark, Python, Java, SQL. But... still I am not able to become Senior DE, expert. At my current company  I am working with Kafka Streams and Data Mesh(I have no possibility to become expert at least in one area)I would like to develop my skills as fast as possible. I have no experience with data modeling, data warehouses and at interviews still I have lacks of Python advanced knowledge, practical knolwedge from pySpark optimizations, no Snowflake experience and so on. I wonder if I should stay at my current company(I get 5euro/h less money than in other companies). I would like to become Senior, get better money, use more trending DE tools. I am looking for some career advices, what I could do. I would like to do some DE things in free time, maybe some open source projects? I am determined and motivated to hone my skills, develop my self. \nI would be more than grateful for some advices :)\nMaybe somebody would like to join me to do some DE project or learn new things, feel free to DM me or leave comment", "author_fullname": "t2_omva4fi3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Master DE skills", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12fw1g0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680982453.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,\nI&amp;#39;ve been DE for 3 years, I worked with Azure, GCP, AWS. I know pySpark, Python, Java, SQL. But... still I am not able to become Senior DE, expert. At my current company  I am working with Kafka Streams and Data Mesh(I have no possibility to become expert at least in one area)I would like to develop my skills as fast as possible. I have no experience with data modeling, data warehouses and at interviews still I have lacks of Python advanced knowledge, practical knolwedge from pySpark optimizations, no Snowflake experience and so on. I wonder if I should stay at my current company(I get 5euro/h less money than in other companies). I would like to become Senior, get better money, use more trending DE tools. I am looking for some career advices, what I could do. I would like to do some DE things in free time, maybe some open source projects? I am determined and motivated to hone my skills, develop my self. \nI would be more than grateful for some advices :)\nMaybe somebody would like to join me to do some DE project or learn new things, feel free to DM me or leave comment&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12fw1g0", "is_robot_indexable": true, "report_reasons": null, "author": "BigDataMax", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12fw1g0/master_de_skills/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12fw1g0/master_de_skills/", "subreddit_subscribers": 96912, "created_utc": 1680982453.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've decided to change career last Feb 2022.  \n\n\nSince then I tried to learn all I could.  \nNow, on April 2023 I can say I know **Python** only up to solve **4kyu problems** on Codewars, **SQL** up to **intermediate** problems on Hackerrank and I only have knowledge of how AWS works (but I never tried to use it), CI/CD (but never put into practice, I can use some functionalities of **PyCharm, GitHub and Visual Studio Code**, I know few keywords of **GIT**, and some knowledge (that it doesn't seem to be able to get stuck in my head) about databases, clouds, pipelines and ETL processes...  \n\n\nI'm scared to apply cause I believe I will never pass a technical interview.  \n\n\nI think that at least you gotta know how to build a proper **ETL pipeline** to get started as a Junior data engineer but I just can't remember anything I learn.", "author_fullname": "t2_liwvvwau", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I a fraud? Trying to find a job as Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12fj2we", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680953228.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve decided to change career last Feb 2022.  &lt;/p&gt;\n\n&lt;p&gt;Since then I tried to learn all I could.&lt;br/&gt;\nNow, on April 2023 I can say I know &lt;strong&gt;Python&lt;/strong&gt; only up to solve &lt;strong&gt;4kyu problems&lt;/strong&gt; on Codewars, &lt;strong&gt;SQL&lt;/strong&gt; up to &lt;strong&gt;intermediate&lt;/strong&gt; problems on Hackerrank and I only have knowledge of how AWS works (but I never tried to use it), CI/CD (but never put into practice, I can use some functionalities of &lt;strong&gt;PyCharm, GitHub and Visual Studio Code&lt;/strong&gt;, I know few keywords of &lt;strong&gt;GIT&lt;/strong&gt;, and some knowledge (that it doesn&amp;#39;t seem to be able to get stuck in my head) about databases, clouds, pipelines and ETL processes...  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m scared to apply cause I believe I will never pass a technical interview.  &lt;/p&gt;\n\n&lt;p&gt;I think that at least you gotta know how to build a proper &lt;strong&gt;ETL pipeline&lt;/strong&gt; to get started as a Junior data engineer but I just can&amp;#39;t remember anything I learn.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12fj2we", "is_robot_indexable": true, "report_reasons": null, "author": "post_lupy", "discussion_type": null, "num_comments": 13, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12fj2we/am_i_a_fraud_trying_to_find_a_job_as_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12fj2we/am_i_a_fraud_trying_to_find_a_job_as_data_engineer/", "subreddit_subscribers": 96912, "created_utc": 1680953228.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}