{"kind": "Listing", "data": {"after": "t3_12ergob", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nI find it hard to decide what to learn. Like I have been working on a project, in the night I learn something about LLMs, then the next day I explore Topic Modelling, the next day I try some Pyspark coding in Azure Databricks, then I decide to study the maths behind Gaussian Mixture Models and then I decide I should explore PyTorch and so on\n\nFor AI/Data Science professionals, how do you prioritize as the things we need to learn seems just.....\n\nENDLESS", "author_fullname": "t2_8pphmf41t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science is so vast, how to prioritize what to learn?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ekysa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 234, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 234, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680873290.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I find it hard to decide what to learn. Like I have been working on a project, in the night I learn something about LLMs, then the next day I explore Topic Modelling, the next day I try some Pyspark coding in Azure Databricks, then I decide to study the maths behind Gaussian Mixture Models and then I decide I should explore PyTorch and so on&lt;/p&gt;\n\n&lt;p&gt;For AI/Data Science professionals, how do you prioritize as the things we need to learn seems just.....&lt;/p&gt;\n\n&lt;p&gt;ENDLESS&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ekysa", "is_robot_indexable": true, "report_reasons": null, "author": "NickRay1234", "discussion_type": null, "num_comments": 68, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12ekysa/data_science_is_so_vast_how_to_prioritize_what_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12ekysa/data_science_is_so_vast_how_to_prioritize_what_to/", "subreddit_subscribers": 869298, "created_utc": 1680873290.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been having difficulties getting interviews for jobs so I decided to try experiment where I tailor my resume to literally mirror match the job requirements and experience required. My tailored resume matches the job description like the job description was tailored specifically for me, as if I am literally the \"unicorn candidate\". If they are Python focused shop, I put Python experience in all of my previous jobs. If they use SAS or R, I put down SAS or R experience in my previous jobs. If it's a healthcare company, all of my previous \"jobs\" are at major healthcare companies. If it's a marketing firm, all of my previous jobs are marketing specific. I also **make sure to not look overqualified or under-qualified**. So if they are asking for 5-7 years of experience, I have **exactly** 5-7 years of job history listed on my resume. For salary expectations, I also put down that I want **less money than the listed salary range**. So for example, if the posted salary range is 120-140k, I will put down that I am only asking for 90-100k in the job application questionnaire (Workday, etc).  I also write a cover letter explaining my technical skills so that it is extremely obvious that I know what I am talking about and can easily do the job. So if the job posting mentions requiring 5 years of Microsoft Azure experience, I will make it painfully obvious that I am extremely knowledgeable in Microsoft Azure, as well as other cloud platforms such as AWS and GCP. I am not using ChatGPT either. Completely hand written tailored specifically to the job requirements using my own experience working as a Data Engineer and also Data Scientist for 10+ years. I basically design an entire cloud based ETL system and data cleaning and machine learning pipeline deployed to production in my cover letter. I also put down that I am willing to work overtime and travel as needed and also open to relocation **at my own expense** in my cover letter. I also only applied to companies that I had never applied for previously in case they tried to match my phone number with my name and old resume's I might have in their HR/Workday system.\n\nResults? **Not a single interview request or phone screen in 2 months. Only rejection emails. Not a single phone call.**\n\nThis has lead me to believe that most companies aren't actually hiring due to the recent market downturn and recession, or that they are hiring internally only, or they are posting fake jobs to appear that they are \"growing\" their data analytics teams to their competition.\n\nThis experiment has also been a philosophical AI experiment as well. With the advent of ChatGPT, the ability to forge a completely fake resume tailored to specific jobs has never been easier. AI bot farms can literally spam apply jobs with thousands of resumes that have been generated to resemble \"perfect candidates\", resulting in HR not knowing who is real and who isn't real. Imagine 1000 job applications flooded for a particular role where literally ALL of them look real and legitimate. Literally ALL of them look like they are qualified for the job. But only 10% of the resume's are actually real people and HR can't distinguish between them without actually spending the time calling and emailing the applicants. A huge time drain on HR to find legitimate people and not bot farm resume's generated by generative LLM AI's with perfectly tailored resume's trained on the job description.\n\nNow - what if I told you this entire post was actually generated by ChatGPT?", "author_fullname": "t2_fztbyin", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job Application Experiment - \"THE Unicorn Candidate\" - Still ghosted 100% of the time", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ew5lq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 169, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 169, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1680897182.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680895234.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been having difficulties getting interviews for jobs so I decided to try experiment where I tailor my resume to literally mirror match the job requirements and experience required. My tailored resume matches the job description like the job description was tailored specifically for me, as if I am literally the &amp;quot;unicorn candidate&amp;quot;. If they are Python focused shop, I put Python experience in all of my previous jobs. If they use SAS or R, I put down SAS or R experience in my previous jobs. If it&amp;#39;s a healthcare company, all of my previous &amp;quot;jobs&amp;quot; are at major healthcare companies. If it&amp;#39;s a marketing firm, all of my previous jobs are marketing specific. I also &lt;strong&gt;make sure to not look overqualified or under-qualified&lt;/strong&gt;. So if they are asking for 5-7 years of experience, I have &lt;strong&gt;exactly&lt;/strong&gt; 5-7 years of job history listed on my resume. For salary expectations, I also put down that I want &lt;strong&gt;less money than the listed salary range&lt;/strong&gt;. So for example, if the posted salary range is 120-140k, I will put down that I am only asking for 90-100k in the job application questionnaire (Workday, etc).  I also write a cover letter explaining my technical skills so that it is extremely obvious that I know what I am talking about and can easily do the job. So if the job posting mentions requiring 5 years of Microsoft Azure experience, I will make it painfully obvious that I am extremely knowledgeable in Microsoft Azure, as well as other cloud platforms such as AWS and GCP. I am not using ChatGPT either. Completely hand written tailored specifically to the job requirements using my own experience working as a Data Engineer and also Data Scientist for 10+ years. I basically design an entire cloud based ETL system and data cleaning and machine learning pipeline deployed to production in my cover letter. I also put down that I am willing to work overtime and travel as needed and also open to relocation &lt;strong&gt;at my own expense&lt;/strong&gt; in my cover letter. I also only applied to companies that I had never applied for previously in case they tried to match my phone number with my name and old resume&amp;#39;s I might have in their HR/Workday system.&lt;/p&gt;\n\n&lt;p&gt;Results? &lt;strong&gt;Not a single interview request or phone screen in 2 months. Only rejection emails. Not a single phone call.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;This has lead me to believe that most companies aren&amp;#39;t actually hiring due to the recent market downturn and recession, or that they are hiring internally only, or they are posting fake jobs to appear that they are &amp;quot;growing&amp;quot; their data analytics teams to their competition.&lt;/p&gt;\n\n&lt;p&gt;This experiment has also been a philosophical AI experiment as well. With the advent of ChatGPT, the ability to forge a completely fake resume tailored to specific jobs has never been easier. AI bot farms can literally spam apply jobs with thousands of resumes that have been generated to resemble &amp;quot;perfect candidates&amp;quot;, resulting in HR not knowing who is real and who isn&amp;#39;t real. Imagine 1000 job applications flooded for a particular role where literally ALL of them look real and legitimate. Literally ALL of them look like they are qualified for the job. But only 10% of the resume&amp;#39;s are actually real people and HR can&amp;#39;t distinguish between them without actually spending the time calling and emailing the applicants. A huge time drain on HR to find legitimate people and not bot farm resume&amp;#39;s generated by generative LLM AI&amp;#39;s with perfectly tailored resume&amp;#39;s trained on the job description.&lt;/p&gt;\n\n&lt;p&gt;Now - what if I told you this entire post was actually generated by ChatGPT?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ew5lq", "is_robot_indexable": true, "report_reasons": null, "author": "Edge779", "discussion_type": null, "num_comments": 73, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12ew5lq/job_application_experiment_the_unicorn_candidate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12ew5lq/job_application_experiment_the_unicorn_candidate/", "subreddit_subscribers": 869298, "created_utc": 1680895234.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_gj8rt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moving estimators (agnostic) vs ARMA-ARCH-like philosophy (arbitrary) on example of Student's t-distributions for economical data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 106, "top_awarded_type": null, "hide_score": false, "name": "t3_12ednms", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/aOp5GxUkW51V_HM3hwzpk-_t3UbVFWKYRdCRtfHtyWo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1680853925.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/jw5b4i304fsa1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/jw5b4i304fsa1.png?auto=webp&amp;v=enabled&amp;s=552232c2a39e50e911e8209fc3127dade1941360", "width": 2127, "height": 1625}, "resolutions": [{"url": "https://preview.redd.it/jw5b4i304fsa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f7a41d4e423ef3c0e19de7f00ed02dac539f2ecb", "width": 108, "height": 82}, {"url": "https://preview.redd.it/jw5b4i304fsa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3f662a311f1d770fca857f5787fe0542b55aa90f", "width": 216, "height": 165}, {"url": "https://preview.redd.it/jw5b4i304fsa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3df04a03ace1d5c8f7a2db86bca2c2e5095db115", "width": 320, "height": 244}, {"url": "https://preview.redd.it/jw5b4i304fsa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=988251d989db849d5a4ce278483fbf92c775c289", "width": 640, "height": 488}, {"url": "https://preview.redd.it/jw5b4i304fsa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cdbe4a2a59b0730de7ad35a73c0f83f0906ef251", "width": 960, "height": 733}, {"url": "https://preview.redd.it/jw5b4i304fsa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2274960b3b0dd9e40e948e3423303ee7b75a1a82", "width": 1080, "height": 825}], "variants": {}, "id": "U3iXumCJAdToRNi7FK6lU4kBvWYQbXy4woxr2dy52tA"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ednms", "is_robot_indexable": true, "report_reasons": null, "author": "jarekduda", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12ednms/moving_estimators_agnostic_vs_armaarchlike/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/jw5b4i304fsa1.png", "subreddit_subscribers": 869298, "created_utc": 1680853925.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello all,\n\nNot sure if this sub is the right place to post (if it's not please redirect me to a better one).\n\nI've started working on an EDA project based on the [IMDB movie datasets](https://www.imdb.com/interfaces/).\n\nThe question I'm stuck answering to is: \"Do directors that directed more movies tend to produce better quality movies overall?\"\n\nThe data that I'm using to answer this is the director's ID, and the movie's average rating.\n\nA movie can have multiple directors so I've considered that each director directed that movie.\n\nTo answer the question I've tried the following methods:\n\n1. Grouping the data based on number of directed movies then binning in increments of 10 and plotting to compare the distributions.\n2. Taking the average rating by director then grouping based on the number of directed movies and plotting the trend of the ratings (mean, 1st quart - 1.5 iqr, 3rd quart + 1.5 iqr).\n3. Aggregated similar to 2nd, but instead of plotting the trend, I've plotted a boxplot for all directors that directed x movies.\n\nAny help/direction is much appreciated,\n\nHave a nice day :)\n\n&amp;#x200B;\n\n[Director distribution](https://preview.redd.it/suwfvi3ivisa1.png?width=1210&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c7715da9c6a453a7c27da6fc01759b0415b7bca4)\n\nHere are the graphs of the methods I've tried:\n\n&amp;#x200B;\n\n[First method](https://preview.redd.it/uhz4v2olvisa1.png?width=1194&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=8c2c0ac372117299b3925ec77266ad3926c8fc0d)\n\n&amp;#x200B;\n\n[Second method](https://preview.redd.it/aro6p9wmvisa1.png?width=958&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=5e445a4a585abafc76a668093c290ccf2cf240a6)\n\n&amp;#x200B;\n\n[Third method](https://preview.redd.it/km6i18wnvisa1.png?width=2404&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9f8e6cae33ab812cb9c27bdea4d42f2ae07b05e9)", "author_fullname": "t2_29zuvsbz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I compare multiple distributions in my case?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 87, "top_awarded_type": null, "hide_score": false, "media_metadata": {"aro6p9wmvisa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 119, "x": 108, "u": "https://preview.redd.it/aro6p9wmvisa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c7c0b6f7c4c7ff732c2595a79d26e538a3791fac"}, {"y": 238, "x": 216, "u": "https://preview.redd.it/aro6p9wmvisa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b9f1abf972b63b2d22f333f6db57bbfbdf481819"}, {"y": 353, "x": 320, "u": "https://preview.redd.it/aro6p9wmvisa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5aa2c70216c3dbaa92024d8a434e1dc5a9421c25"}, {"y": 706, "x": 640, "u": "https://preview.redd.it/aro6p9wmvisa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=49552825d18f939cbb7857d682b7349946a83660"}], "s": {"y": 1057, "x": 958, "u": "https://preview.redd.it/aro6p9wmvisa1.png?width=958&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=5e445a4a585abafc76a668093c290ccf2cf240a6"}, "id": "aro6p9wmvisa1"}, "suwfvi3ivisa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 67, "x": 108, "u": "https://preview.redd.it/suwfvi3ivisa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6297d73784d331eae316708ae23cce86541fe51e"}, {"y": 135, "x": 216, "u": "https://preview.redd.it/suwfvi3ivisa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b734f6eae315d26f09da7b7dc3b59393629e3e79"}, {"y": 200, "x": 320, "u": "https://preview.redd.it/suwfvi3ivisa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3e2ec4cda00c2334e3ee5b030b2629c665845320"}, {"y": 400, "x": 640, "u": "https://preview.redd.it/suwfvi3ivisa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=475386da357823c9799658ea88e12ec5349b2ded"}, {"y": 600, "x": 960, "u": "https://preview.redd.it/suwfvi3ivisa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9a199e022a4426e05347448a5ca7e9ddf928b181"}, {"y": 675, "x": 1080, "u": "https://preview.redd.it/suwfvi3ivisa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=47cc8a451a8920ea4b79452e857ea95d32533172"}], "s": {"y": 757, "x": 1210, "u": "https://preview.redd.it/suwfvi3ivisa1.png?width=1210&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c7715da9c6a453a7c27da6fc01759b0415b7bca4"}, "id": "suwfvi3ivisa1"}, "km6i18wnvisa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 54, "x": 108, "u": "https://preview.redd.it/km6i18wnvisa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5ed23f81b3248bc7f1825b6fe6c48d0d71fda11f"}, {"y": 108, "x": 216, "u": "https://preview.redd.it/km6i18wnvisa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d34e0871249f6fa4d6e38d40e532dfe5cbf5cff5"}, {"y": 161, "x": 320, "u": "https://preview.redd.it/km6i18wnvisa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0d81fbfc75d4c2d87e9127f1154ec82bf001be8e"}, {"y": 322, "x": 640, "u": "https://preview.redd.it/km6i18wnvisa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b428724414f91ed87b1c07343909adfeff47ecc5"}, {"y": 483, "x": 960, "u": "https://preview.redd.it/km6i18wnvisa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b491bd6bbe58d3f59afe66b7601a08d9eb2800a8"}, {"y": 544, "x": 1080, "u": "https://preview.redd.it/km6i18wnvisa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8ba8d87820dcfc4e2c91d30fda49830260d8f30b"}], "s": {"y": 1212, "x": 2404, "u": "https://preview.redd.it/km6i18wnvisa1.png?width=2404&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9f8e6cae33ab812cb9c27bdea4d42f2ae07b05e9"}, "id": "km6i18wnvisa1"}, "uhz4v2olvisa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 109, "x": 108, "u": "https://preview.redd.it/uhz4v2olvisa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cdf225f9ca946dee4f923267f51dd12d4b7b5742"}, {"y": 219, "x": 216, "u": "https://preview.redd.it/uhz4v2olvisa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8a22d6a77a97529fa79f70bb8c021d286e933fa0"}, {"y": 324, "x": 320, "u": "https://preview.redd.it/uhz4v2olvisa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=472b18aff2339d1a619ced71c24268ac39fc4833"}, {"y": 649, "x": 640, "u": "https://preview.redd.it/uhz4v2olvisa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=31fbd9432022dc6b9cc4ae6b3b2d04e19bb784f4"}, {"y": 974, "x": 960, "u": "https://preview.redd.it/uhz4v2olvisa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7ab2369e673099bfe262780df40957f0d058a571"}, {"y": 1096, "x": 1080, "u": "https://preview.redd.it/uhz4v2olvisa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c954ec34367cd45212d05cd664d98e22ad9442cb"}], "s": {"y": 1212, "x": 1194, "u": "https://preview.redd.it/uhz4v2olvisa1.png?width=1194&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=8c2c0ac372117299b3925ec77266ad3926c8fc0d"}, "id": "uhz4v2olvisa1"}}, "name": "t3_12eyfs8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ULBLWkIfm0QmNnzZhnFrTQBZI7994lqETfyakjy-J0w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680899734.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;Not sure if this sub is the right place to post (if it&amp;#39;s not please redirect me to a better one).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve started working on an EDA project based on the &lt;a href=\"https://www.imdb.com/interfaces/\"&gt;IMDB movie datasets&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;The question I&amp;#39;m stuck answering to is: &amp;quot;Do directors that directed more movies tend to produce better quality movies overall?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;The data that I&amp;#39;m using to answer this is the director&amp;#39;s ID, and the movie&amp;#39;s average rating.&lt;/p&gt;\n\n&lt;p&gt;A movie can have multiple directors so I&amp;#39;ve considered that each director directed that movie.&lt;/p&gt;\n\n&lt;p&gt;To answer the question I&amp;#39;ve tried the following methods:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Grouping the data based on number of directed movies then binning in increments of 10 and plotting to compare the distributions.&lt;/li&gt;\n&lt;li&gt;Taking the average rating by director then grouping based on the number of directed movies and plotting the trend of the ratings (mean, 1st quart - 1.5 iqr, 3rd quart + 1.5 iqr).&lt;/li&gt;\n&lt;li&gt;Aggregated similar to 2nd, but instead of plotting the trend, I&amp;#39;ve plotted a boxplot for all directors that directed x movies.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Any help/direction is much appreciated,&lt;/p&gt;\n\n&lt;p&gt;Have a nice day :)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/suwfvi3ivisa1.png?width=1210&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=c7715da9c6a453a7c27da6fc01759b0415b7bca4\"&gt;Director distribution&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Here are the graphs of the methods I&amp;#39;ve tried:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/uhz4v2olvisa1.png?width=1194&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=8c2c0ac372117299b3925ec77266ad3926c8fc0d\"&gt;First method&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/aro6p9wmvisa1.png?width=958&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=5e445a4a585abafc76a668093c290ccf2cf240a6\"&gt;Second method&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/km6i18wnvisa1.png?width=2404&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=9f8e6cae33ab812cb9c27bdea4d42f2ae07b05e9\"&gt;Third method&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12eyfs8", "is_robot_indexable": true, "report_reasons": null, "author": "AlreadyOwnMyself", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12eyfs8/how_can_i_compare_multiple_distributions_in_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12eyfs8/how_can_i_compare_multiple_distributions_in_my/", "subreddit_subscribers": 869298, "created_utc": 1680899734.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For those unfamiliar with it, BOINC is the Berkeley Open Infrastructure for Network Computing. It is a free software and volunteer computing infrastructure focused on science with over 15 active projects. There are teraflops of computing power available to you for absolutely free. If you are working on problems that can be done in a distributed or parallel matter, YSK about it.\n\nThe BOINC server software works with any app you have (such as a protein simulator), and can handle all the workunit creation/delivery/validation. You can run the server [as a docker container](https://github.com/BOINC/boinc-client-docker) and distribute your app as as pre-compiled binary or inside a virtualbox image to instantly work across platforms. BOINC not only supports 32 and 64-bit Windows/OS X/Linux hosts, but ARM and Android as well. And it supports GPU acceleration as well on both Nvidia and AMD cards. It's also open-source so you can modify it to suit your use case. For small projects, you can run the BOINC server on a $10/month VPS or a spare laptop in a closet for larger projects obviously the memory and storage needs will scale with complexity.\n\nOnce you have your server up (or beforehand, if you need to secure a guarantee of computation before investing development resources), you can approach Science United and Gridcoin for your guaranteed computation (\"crunching\"). Neither of these mechanisms require you to be affiliated with a university or other institution, they just require that you are doing interesting scientific research.\n\nScience United is a platform run by the BOINC developers which connects volunteer computing participants to BOINC projects. Once they add you to their list, thousands of volunteers around the globe will immediately start crunching data for your project giving you many teraflops of power. Science United is particularly good for smaller projects which don't have large, ongoing workloads or have sporadic work.\n\nGridcoin is a cryptocurrency (founded 2013, not affiliated with the BOINC developers) which incentivizes people to crunch workunits for you. They currently incentivize most active BOINC projects (with their permission) and hand out approx $500 USD equivalent in incentivization money to your \"crunchers\" monthly. The actual value of the computation you receive is much higher than this. All of this happens without you ever needing to do anything aside from have a BOINC server. There are some requirements you must meet such as having a large amount of work to be done (be an ongoing project), but they can direct petaflops of power your way and have a procedure to \"pre-approve\" your project before it's done being developed.\n\nBOINC can also be used to harvest under-utilized compute resources on your campus or in your company. It can be installed on platforms and set to compute only while the machine is idle, so it doesn't slow it down while in use.\n\nFamous research institutes and major universities across the world use BOINC. World Community Grid, the Large Hadron Collider, Rosetta, University of Texas, and the University of California are a handful of the big names that use BOINC for work distribution.\n\nRelevant links:\n\n/r/BOINC4Science\n\n[http://boinc.berkeley.edu](http://boinc.berkeley.edu)\n\n/r/Gridcoin\n\n[boincworkshop.org](https://boincworkshop.org) (Yearly BOINC conference with video presentations from many BOINC projects about how they use BOINC to process their data)\n\n[(Incomplete) List of Scientific Papers by BOINC projects](https://boinc.berkeley.edu/pubs.php)\n\nHappy to answer any questions folks have, I am involved in these communities have been \"crunching\" workunits for years.", "author_fullname": "t2_ekin26t1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need scientific computing power? BOINC can get you teraflops of it absolutely free", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12f60eo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1680915665.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1680915249.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For those unfamiliar with it, BOINC is the Berkeley Open Infrastructure for Network Computing. It is a free software and volunteer computing infrastructure focused on science with over 15 active projects. There are teraflops of computing power available to you for absolutely free. If you are working on problems that can be done in a distributed or parallel matter, YSK about it.&lt;/p&gt;\n\n&lt;p&gt;The BOINC server software works with any app you have (such as a protein simulator), and can handle all the workunit creation/delivery/validation. You can run the server &lt;a href=\"https://github.com/BOINC/boinc-client-docker\"&gt;as a docker container&lt;/a&gt; and distribute your app as as pre-compiled binary or inside a virtualbox image to instantly work across platforms. BOINC not only supports 32 and 64-bit Windows/OS X/Linux hosts, but ARM and Android as well. And it supports GPU acceleration as well on both Nvidia and AMD cards. It&amp;#39;s also open-source so you can modify it to suit your use case. For small projects, you can run the BOINC server on a $10/month VPS or a spare laptop in a closet for larger projects obviously the memory and storage needs will scale with complexity.&lt;/p&gt;\n\n&lt;p&gt;Once you have your server up (or beforehand, if you need to secure a guarantee of computation before investing development resources), you can approach Science United and Gridcoin for your guaranteed computation (&amp;quot;crunching&amp;quot;). Neither of these mechanisms require you to be affiliated with a university or other institution, they just require that you are doing interesting scientific research.&lt;/p&gt;\n\n&lt;p&gt;Science United is a platform run by the BOINC developers which connects volunteer computing participants to BOINC projects. Once they add you to their list, thousands of volunteers around the globe will immediately start crunching data for your project giving you many teraflops of power. Science United is particularly good for smaller projects which don&amp;#39;t have large, ongoing workloads or have sporadic work.&lt;/p&gt;\n\n&lt;p&gt;Gridcoin is a cryptocurrency (founded 2013, not affiliated with the BOINC developers) which incentivizes people to crunch workunits for you. They currently incentivize most active BOINC projects (with their permission) and hand out approx $500 USD equivalent in incentivization money to your &amp;quot;crunchers&amp;quot; monthly. The actual value of the computation you receive is much higher than this. All of this happens without you ever needing to do anything aside from have a BOINC server. There are some requirements you must meet such as having a large amount of work to be done (be an ongoing project), but they can direct petaflops of power your way and have a procedure to &amp;quot;pre-approve&amp;quot; your project before it&amp;#39;s done being developed.&lt;/p&gt;\n\n&lt;p&gt;BOINC can also be used to harvest under-utilized compute resources on your campus or in your company. It can be installed on platforms and set to compute only while the machine is idle, so it doesn&amp;#39;t slow it down while in use.&lt;/p&gt;\n\n&lt;p&gt;Famous research institutes and major universities across the world use BOINC. World Community Grid, the Large Hadron Collider, Rosetta, University of Texas, and the University of California are a handful of the big names that use BOINC for work distribution.&lt;/p&gt;\n\n&lt;p&gt;Relevant links:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"/r/BOINC4Science\"&gt;/r/BOINC4Science&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://boinc.berkeley.edu\"&gt;http://boinc.berkeley.edu&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"/r/Gridcoin\"&gt;/r/Gridcoin&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://boincworkshop.org\"&gt;boincworkshop.org&lt;/a&gt; (Yearly BOINC conference with video presentations from many BOINC projects about how they use BOINC to process their data)&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://boinc.berkeley.edu/pubs.php\"&gt;(Incomplete) List of Scientific Papers by BOINC projects&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Happy to answer any questions folks have, I am involved in these communities have been &amp;quot;crunching&amp;quot; workunits for years.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/15M4ihUlcclJRsi1gbM1X_IR-kILK82k-TpLCQjfnjQ.jpg?auto=webp&amp;v=enabled&amp;s=84e3f49a6ba7d0bc4ea19782a868f7a21e2750b3", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/15M4ihUlcclJRsi1gbM1X_IR-kILK82k-TpLCQjfnjQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=35743d389768aeeaff83f66fceb5495043ebe0a7", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/15M4ihUlcclJRsi1gbM1X_IR-kILK82k-TpLCQjfnjQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4395f92a509d5eeda7e4f56deaef3ac9ed38f75d", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/15M4ihUlcclJRsi1gbM1X_IR-kILK82k-TpLCQjfnjQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=85b14fc1305ad2d598c97c16dca49feb22dedf15", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/15M4ihUlcclJRsi1gbM1X_IR-kILK82k-TpLCQjfnjQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=faadbea9e029cb33c87df1ce0dbef98a0fc6b5c1", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/15M4ihUlcclJRsi1gbM1X_IR-kILK82k-TpLCQjfnjQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6cad891065c0ea9541639f5c99e36238e6086353", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/15M4ihUlcclJRsi1gbM1X_IR-kILK82k-TpLCQjfnjQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9e2f3b53d817fb4aa8142ddd5aa3bbd3237ef363", "width": 1080, "height": 540}], "variants": {}, "id": "5SRj9ygkqRSsbKe5eKIXebwVPfCzQxxDOTdZltKBDjg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12f60eo", "is_robot_indexable": true, "report_reasons": null, "author": "makeasnek", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12f60eo/need_scientific_computing_power_boinc_can_get_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12f60eo/need_scientific_computing_power_boinc_can_get_you/", "subreddit_subscribers": 869298, "created_utc": 1680915249.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Coming more from a modeling background, I was wondering if there is a difference between the ICC of an ANOVA framework and a multilevel model, and if so, what is the difference? I am aware that the two approaches differ in that the ANOVA uses the sums of squares and the multilevel approach uses the variance components of the random effects. But does this difference affect practice, or will the results be the same?", "author_fullname": "t2_pfyictop", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ICC: ANOVA vs multilevel framework", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12efrzg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680861108.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Coming more from a modeling background, I was wondering if there is a difference between the ICC of an ANOVA framework and a multilevel model, and if so, what is the difference? I am aware that the two approaches differ in that the ANOVA uses the sums of squares and the multilevel approach uses the variance components of the random effects. But does this difference affect practice, or will the results be the same?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12efrzg", "is_robot_indexable": true, "report_reasons": null, "author": "Lazy_Inevitable_9274", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12efrzg/icc_anova_vs_multilevel_framework/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12efrzg/icc_anova_vs_multilevel_framework/", "subreddit_subscribers": 869298, "created_utc": 1680861108.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello guys,\n\nI have a about 6 years of experience as a data analyst in India. And I recently joined a really big financial institution.\n\nI am stuck with a toxic manager at my new job, and I have almost no clue to how to handle this situation. Almost everyone in my team has faced the issues such as, she will berate them, tell them they are slow, everything is priority and everything has to be delivered today.\n\nShe does not have time to discuss challenges in the tasks, and when asked questions, she would say, \"don't ask so many questions, finish the task\".\n\nNow I am sure I don't want to be in this team, but in other teams also, if people have to leave early, they will try to sneak out and steal glances, instead of leaving happily.\n\nAnd this type of culture worries me, because in my previous jobs, if I had to leave early, mostly the permission was granted quite easily. Managers and project leads were available to discuss challanges.\n\nSo the question I have is, should I even try working in another team before leaving the organization?\n\n&amp;#x200B;\n\nPS: Incident examples:\n\n1. I was given an excel to work with, where I had to summarize multiple sheets into one sheet, I used simply three functions Indirect, vlookup and sumif. And she went furious on why did you make the excel so complicated? How am I going to check it?\n2. She treats me with disrespect. My teammates tell me that same has happened with them, but then in a 1:1 they told manager to treat them with respect, and she now treats them with respect.\n3. She has given important deliverable for one of the biggest client to an Intern, who has never written a code before, and then during 8 PM meeting, knowing the data pull has not been completed yet, she still committed to partners that we will be delivering it today.", "author_fullname": "t2_cy32alk9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to deal with toxic culture and toxic manager at a new job? Which option is better between changing the team and leaving the organization?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12f4ntl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1680912635.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680912342.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys,&lt;/p&gt;\n\n&lt;p&gt;I have a about 6 years of experience as a data analyst in India. And I recently joined a really big financial institution.&lt;/p&gt;\n\n&lt;p&gt;I am stuck with a toxic manager at my new job, and I have almost no clue to how to handle this situation. Almost everyone in my team has faced the issues such as, she will berate them, tell them they are slow, everything is priority and everything has to be delivered today.&lt;/p&gt;\n\n&lt;p&gt;She does not have time to discuss challenges in the tasks, and when asked questions, she would say, &amp;quot;don&amp;#39;t ask so many questions, finish the task&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Now I am sure I don&amp;#39;t want to be in this team, but in other teams also, if people have to leave early, they will try to sneak out and steal glances, instead of leaving happily.&lt;/p&gt;\n\n&lt;p&gt;And this type of culture worries me, because in my previous jobs, if I had to leave early, mostly the permission was granted quite easily. Managers and project leads were available to discuss challanges.&lt;/p&gt;\n\n&lt;p&gt;So the question I have is, should I even try working in another team before leaving the organization?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;PS: Incident examples:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I was given an excel to work with, where I had to summarize multiple sheets into one sheet, I used simply three functions Indirect, vlookup and sumif. And she went furious on why did you make the excel so complicated? How am I going to check it?&lt;/li&gt;\n&lt;li&gt;She treats me with disrespect. My teammates tell me that same has happened with them, but then in a 1:1 they told manager to treat them with respect, and she now treats them with respect.&lt;/li&gt;\n&lt;li&gt;She has given important deliverable for one of the biggest client to an Intern, who has never written a code before, and then during 8 PM meeting, knowing the data pull has not been completed yet, she still committed to partners that we will be delivering it today.&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12f4ntl", "is_robot_indexable": true, "report_reasons": null, "author": "ashutosh10pande", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12f4ntl/how_to_deal_with_toxic_culture_and_toxic_manager/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12f4ntl/how_to_deal_with_toxic_culture_and_toxic_manager/", "subreddit_subscribers": 869298, "created_utc": 1680912342.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_lou08wo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can someone please explain to me the benefit of having a data warehouse for processing of \u2018big data\u2019? Such as ETL processes.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12f1f4r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680905637.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12f1f4r", "is_robot_indexable": true, "report_reasons": null, "author": "New_Jammy", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12f1f4r/can_someone_please_explain_to_me_the_benefit_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12f1f4r/can_someone_please_explain_to_me_the_benefit_of/", "subreddit_subscribers": 869298, "created_utc": 1680905637.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So currently, I'm having a hard time making a decision. I want to make a visual representation of some data that I have compiled but don't know if a Force Directed Graph his the best visual graph option for the criteria I have set.\n\n&amp;#x200B;\n\nI currently have my data compiled in a vector DB and want to visualize it to make it more presentable and intuitive for some clients that I have to show it to. I know Force Directed Graphs are good for showing relationships between datapoints and that is already one of my criteria points checked off. The other criteria points are:\n\n* Just optimization features to offer low/reasonable run time via a webpage\n* Interactive visualization for semi-collapsible/Hierarchical data (similar to this old post [https://stackoverflow.com/questions/15927671/collapsible-hierarchical-and-force-directed-graph-in-d3-js](https://stackoverflow.com/questions/15927671/collapsible-hierarchical-and-force-directed-graph-in-d3-js); Also by semi-collapsible, I just want to scrolled out to make the smaller nodes 'disppear/merge' back into a larger node/category)\n\n&amp;#x200B;\n\nI'm really sorry if this is pretty vague in terms of description. If someone has to time to help or even the time to spare to call over discord (DM me if you have time chat over discord) I would much appreciate it. This is mostly a personal project that I want to get off the ground to show a personal friend/potential client in hopes of making my dreams a reality. In all honestly, I'm not a professional or even a student studying in this field. Just wanted input and help so I can get a general idea of what direction I should be taking this project.", "author_fullname": "t2_i0kbalp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Force Directed Graph Question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12eyyuk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1680900791.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So currently, I&amp;#39;m having a hard time making a decision. I want to make a visual representation of some data that I have compiled but don&amp;#39;t know if a Force Directed Graph his the best visual graph option for the criteria I have set.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I currently have my data compiled in a vector DB and want to visualize it to make it more presentable and intuitive for some clients that I have to show it to. I know Force Directed Graphs are good for showing relationships between datapoints and that is already one of my criteria points checked off. The other criteria points are:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Just optimization features to offer low/reasonable run time via a webpage&lt;/li&gt;\n&lt;li&gt;Interactive visualization for semi-collapsible/Hierarchical data (similar to this old post &lt;a href=\"https://stackoverflow.com/questions/15927671/collapsible-hierarchical-and-force-directed-graph-in-d3-js\"&gt;https://stackoverflow.com/questions/15927671/collapsible-hierarchical-and-force-directed-graph-in-d3-js&lt;/a&gt;; Also by semi-collapsible, I just want to scrolled out to make the smaller nodes &amp;#39;disppear/merge&amp;#39; back into a larger node/category)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m really sorry if this is pretty vague in terms of description. If someone has to time to help or even the time to spare to call over discord (DM me if you have time chat over discord) I would much appreciate it. This is mostly a personal project that I want to get off the ground to show a personal friend/potential client in hopes of making my dreams a reality. In all honestly, I&amp;#39;m not a professional or even a student studying in this field. Just wanted input and help so I can get a general idea of what direction I should be taking this project.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&amp;v=enabled&amp;s=19b4a59f036ea2f314ff2033c11e54cdc240f8d8", "width": 316, "height": 316}, "resolutions": [{"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d93e783257998ff2ed865c359d9a00312a5412d7", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=90216f7dc897a869ee852791bafa1e00667cdf07", "width": 216, "height": 216}], "variants": {}, "id": "nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12eyyuk", "is_robot_indexable": true, "report_reasons": null, "author": "Ponketsu", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12eyyuk/force_directed_graph_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12eyyuk/force_directed_graph_question/", "subreddit_subscribers": 869298, "created_utc": 1680900791.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_vuozxz2n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Comparing Workflow orchestrators: Why I'm fascinated by Metaflow and Flyte and will stop using Airflow. Compares prefect, dagster, luigi, and others as well.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 82, "top_awarded_type": null, "hide_score": false, "name": "t3_12eptjp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/7O2Raqq31tVgokW1i_9qxmlOv59uD82kjm35PDTk6ug.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1680883010.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dsdaily.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://dsdaily.substack.com/p/workflow-orchestrators-metaflow-kedro", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/B7967E5kGkGqxs4Lda43PVqY-eNs7YQ6ZZ3CzhQUvlU.jpg?auto=webp&amp;v=enabled&amp;s=a6a802bb2d7efde54ff0ef2559e66e363bf49a5a", "width": 1018, "height": 598}, "resolutions": [{"url": "https://external-preview.redd.it/B7967E5kGkGqxs4Lda43PVqY-eNs7YQ6ZZ3CzhQUvlU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7a90eb229993f8276fb3f03b5a2de1277134e270", "width": 108, "height": 63}, {"url": "https://external-preview.redd.it/B7967E5kGkGqxs4Lda43PVqY-eNs7YQ6ZZ3CzhQUvlU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c7481dd837331da965c18dc15b5976422a51163e", "width": 216, "height": 126}, {"url": "https://external-preview.redd.it/B7967E5kGkGqxs4Lda43PVqY-eNs7YQ6ZZ3CzhQUvlU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fe6d2538e603e9ff23432a09fc2833ac7a295d1b", "width": 320, "height": 187}, {"url": "https://external-preview.redd.it/B7967E5kGkGqxs4Lda43PVqY-eNs7YQ6ZZ3CzhQUvlU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9afb7d19e43b264aa71a446da5da02ffb669588a", "width": 640, "height": 375}, {"url": "https://external-preview.redd.it/B7967E5kGkGqxs4Lda43PVqY-eNs7YQ6ZZ3CzhQUvlU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e0c11dd6aa271307b19698104a9c2ca7db2cc184", "width": 960, "height": 563}], "variants": {}, "id": "k_OJwzSNhRaOxxkROZWgnREqC7dSqVJTRM4y-8YAGys"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "12eptjp", "is_robot_indexable": true, "report_reasons": null, "author": "RAFisherman", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12eptjp/comparing_workflow_orchestrators_why_im/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dsdaily.substack.com/p/workflow-orchestrators-metaflow-kedro", "subreddit_subscribers": 869298, "created_utc": 1680883010.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone I am very new at data science, currently I am interning at a cab aggregator company in India, my task is\n - to automate the process of data collection from a group in telegram where various cab drivers post ride for outstations, and at the same time customers or brokers who have customers that are looking for outstation rides are also posting their demands (they have no particular format and we don't want to constraint them with it). \n- We have to take that random sequence of text posted by drivers and extract fields such as source, destination, type of car, their contact details etc. and store it in a structured manner. \n- this structured data is then required to be pushed onto our application. \n\nSo problem statement is-\n-automating the task of collection and storing of message data so that it can be fed directly to a DL model\n-Identify what language the driver is conversing in, as there are lot of different regional language and they may be conversing in marathi while using English alphabets\n-Identifying important data points in the message \n- Once identified and stored messages in structured format everything should be loaded on the app \n\n\nWould really appreciate any ideas and open source resources to help me solve this task.", "author_fullname": "t2_c43vnolo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help on meaningful data capture from telegram messages", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12epa34", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680881940.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone I am very new at data science, currently I am interning at a cab aggregator company in India, my task is\n - to automate the process of data collection from a group in telegram where various cab drivers post ride for outstations, and at the same time customers or brokers who have customers that are looking for outstation rides are also posting their demands (they have no particular format and we don&amp;#39;t want to constraint them with it). \n- We have to take that random sequence of text posted by drivers and extract fields such as source, destination, type of car, their contact details etc. and store it in a structured manner. \n- this structured data is then required to be pushed onto our application. &lt;/p&gt;\n\n&lt;p&gt;So problem statement is-\n-automating the task of collection and storing of message data so that it can be fed directly to a DL model\n-Identify what language the driver is conversing in, as there are lot of different regional language and they may be conversing in marathi while using English alphabets\n-Identifying important data points in the message \n- Once identified and stored messages in structured format everything should be loaded on the app &lt;/p&gt;\n\n&lt;p&gt;Would really appreciate any ideas and open source resources to help me solve this task.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12epa34", "is_robot_indexable": true, "report_reasons": null, "author": "Asce_119", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12epa34/help_on_meaningful_data_capture_from_telegram/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12epa34/help_on_meaningful_data_capture_from_telegram/", "subreddit_subscribers": 869298, "created_utc": 1680881940.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m a process engineer that has been dabbling in DS / ML over the past 6 months. I have a decent foundation in Pandas, SKLearn, Seaborn, etc. can build out data visualizations, classifications, and models and for data generated from DOE. But for commercial data, it is extremely difficult. \n\nI\u2019ve tried applying some of this to operating plant datasets but it is extremely hard due to the data rarely being collected at steady state, unknown time lag between the change in a process variable and the resultant label, and generally being very high dimensions of data. \n\nWe have a lab that collects data from DOE and can generate very strong models, but for actual operating data in a commercial plant, it is challenging to even see correlations in the data. \n\nDoes anybody have experience working with chemical process engineering data and have any advice for how to make good use of the data?", "author_fullname": "t2_a9c3d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Chemical Process Data / Data Science Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12eopju", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680880828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m a process engineer that has been dabbling in DS / ML over the past 6 months. I have a decent foundation in Pandas, SKLearn, Seaborn, etc. can build out data visualizations, classifications, and models and for data generated from DOE. But for commercial data, it is extremely difficult. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve tried applying some of this to operating plant datasets but it is extremely hard due to the data rarely being collected at steady state, unknown time lag between the change in a process variable and the resultant label, and generally being very high dimensions of data. &lt;/p&gt;\n\n&lt;p&gt;We have a lab that collects data from DOE and can generate very strong models, but for actual operating data in a commercial plant, it is challenging to even see correlations in the data. &lt;/p&gt;\n\n&lt;p&gt;Does anybody have experience working with chemical process engineering data and have any advice for how to make good use of the data?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12eopju", "is_robot_indexable": true, "report_reasons": null, "author": "STFUandLOVE", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12eopju/chemical_process_data_data_science_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12eopju/chemical_process_data_data_science_advice/", "subreddit_subscribers": 869298, "created_utc": 1680880828.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nI tried searching for a roadmap and ended up designing my own, but honestly, I don't know if I'm being too overambitious or just a complete noob about it!\n\n**Some background:** BSc in Econ, Postgraduate in Financial Econ, so stats/finance concepts are not new to me. I work in the pension funds industry but want to switch to a fintech job. I know some R but haven't practised in years.\n\nI would like some advice on this \"roadmap\", feels like it's too short and also that I might not be prioritizing the right stuff! I also can't decide where to start the data analysis journey, on either 2a or 2b!! Thank you all for your help!\n\nhttps://preview.redd.it/amg5evlyahsa1.png?width=2010&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=f5e34a90b1c7d56d23bcce6b3f1ee32c1c27aa49\n\nAll in all a 3+ years plan (as I have a day job) if you add in projects along the way to keep practising (and practising!), which I'm fine sticking to.\n\nNote: I'm not expecting you to open all the links!", "author_fullname": "t2_72vcncwg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science in Finance | help roadmap", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 55, "top_awarded_type": null, "hide_score": false, "media_metadata": {"amg5evlyahsa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 43, "x": 108, "u": "https://preview.redd.it/amg5evlyahsa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3af2320e022d1ebe78226f1df69813498b0a351d"}, {"y": 86, "x": 216, "u": "https://preview.redd.it/amg5evlyahsa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f1b3469e3c9a8a6a73c0b62dd9c7665c0cc26ae0"}, {"y": 127, "x": 320, "u": "https://preview.redd.it/amg5evlyahsa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a838767c26aab2ca3ce1534a275ae772e4c2e7ff"}, {"y": 255, "x": 640, "u": "https://preview.redd.it/amg5evlyahsa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c4dc3dda9e46db8c627f64083bb318937376dfc1"}, {"y": 382, "x": 960, "u": "https://preview.redd.it/amg5evlyahsa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f07bb2dd4ced5317434210d1e50f4bf56b082bb2"}, {"y": 430, "x": 1080, "u": "https://preview.redd.it/amg5evlyahsa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fc2824a86161e38aacb43296bed01c79ac18f908"}], "s": {"y": 801, "x": 2010, "u": "https://preview.redd.it/amg5evlyahsa1.png?width=2010&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=f5e34a90b1c7d56d23bcce6b3f1ee32c1c27aa49"}, "id": "amg5evlyahsa1"}}, "name": "t3_12eol6t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/rU105M8zzcPSw_luY7D8kL4ingBzo8AHvZ7ODrm4oCM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680880596.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I tried searching for a roadmap and ended up designing my own, but honestly, I don&amp;#39;t know if I&amp;#39;m being too overambitious or just a complete noob about it!&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Some background:&lt;/strong&gt; BSc in Econ, Postgraduate in Financial Econ, so stats/finance concepts are not new to me. I work in the pension funds industry but want to switch to a fintech job. I know some R but haven&amp;#39;t practised in years.&lt;/p&gt;\n\n&lt;p&gt;I would like some advice on this &amp;quot;roadmap&amp;quot;, feels like it&amp;#39;s too short and also that I might not be prioritizing the right stuff! I also can&amp;#39;t decide where to start the data analysis journey, on either 2a or 2b!! Thank you all for your help!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/amg5evlyahsa1.png?width=2010&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=f5e34a90b1c7d56d23bcce6b3f1ee32c1c27aa49\"&gt;https://preview.redd.it/amg5evlyahsa1.png?width=2010&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=f5e34a90b1c7d56d23bcce6b3f1ee32c1c27aa49&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;All in all a 3+ years plan (as I have a day job) if you add in projects along the way to keep practising (and practising!), which I&amp;#39;m fine sticking to.&lt;/p&gt;\n\n&lt;p&gt;Note: I&amp;#39;m not expecting you to open all the links!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12eol6t", "is_robot_indexable": true, "report_reasons": null, "author": "badsaying", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12eol6t/data_science_in_finance_help_roadmap/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12eol6t/data_science_in_finance_help_roadmap/", "subreddit_subscribers": 869298, "created_utc": 1680880596.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a 5 years experience in SaaS environment as Tech Engineer Supp and Marketing Operations. I got laid off and would like to change career to DA/DS and in process of taking BS Degree in WGU but I am hesitant to continue due to the quality concern. \n\nDo you have any recommendations for online school that have quality curriculum for BS in DA/DS? Or WGU is enough and just support with other resources like data camp?\n\nI am also in military family that\u2019s why I need something I can bring anywhere. Appreciate the insight!", "author_fullname": "t2_12oxot", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking advise for BS Degree school", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ejqye", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680870659.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a 5 years experience in SaaS environment as Tech Engineer Supp and Marketing Operations. I got laid off and would like to change career to DA/DS and in process of taking BS Degree in WGU but I am hesitant to continue due to the quality concern. &lt;/p&gt;\n\n&lt;p&gt;Do you have any recommendations for online school that have quality curriculum for BS in DA/DS? Or WGU is enough and just support with other resources like data camp?&lt;/p&gt;\n\n&lt;p&gt;I am also in military family that\u2019s why I need something I can bring anywhere. Appreciate the insight!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ejqye", "is_robot_indexable": true, "report_reasons": null, "author": "cloudedmind00", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12ejqye/seeking_advise_for_bs_degree_school/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12ejqye/seeking_advise_for_bs_degree_school/", "subreddit_subscribers": 869298, "created_utc": 1680870659.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm trying to switch company for the first time with 2 yoe. I interviewed at a marketing analytics company for DS role this Monday and Tuesday, a total of 3 rounds and after these rounds the HR said \"they'll get back to me asap as some feedbacks are pending\". I asked for a timeframe or maybe an ETA to which I was told the same thing \"as soon as possible\".\n\nSince this is my first time, i wanted to know what is the appropriate period to maybe reach out to the recruiter maybe an update? Also does this mean that they are interviewing other potential candidates and keeping me on hold? How can I play this the right way?", "author_fullname": "t2_2xjdvpun", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question to DS recruiters.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12egkek", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680863194.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to switch company for the first time with 2 yoe. I interviewed at a marketing analytics company for DS role this Monday and Tuesday, a total of 3 rounds and after these rounds the HR said &amp;quot;they&amp;#39;ll get back to me asap as some feedbacks are pending&amp;quot;. I asked for a timeframe or maybe an ETA to which I was told the same thing &amp;quot;as soon as possible&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Since this is my first time, i wanted to know what is the appropriate period to maybe reach out to the recruiter maybe an update? Also does this mean that they are interviewing other potential candidates and keeping me on hold? How can I play this the right way?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12egkek", "is_robot_indexable": true, "report_reasons": null, "author": "deepcontractor", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12egkek/question_to_ds_recruiters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12egkek/question_to_ds_recruiters/", "subreddit_subscribers": 869298, "created_utc": 1680863194.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am very interested in finding collected write-ups of successful data science projects solving actual business problems, something like one page synopses. Does anyone know of such a thing?", "author_fullname": "t2_ycsml", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Collection of Successful Data Science Projects in Business?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12f4ucq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680912733.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am very interested in finding collected write-ups of successful data science projects solving actual business problems, something like one page synopses. Does anyone know of such a thing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12f4ucq", "is_robot_indexable": true, "report_reasons": null, "author": "kevinpostlewaite", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12f4ucq/collection_of_successful_data_science_projects_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12f4ucq/collection_of_successful_data_science_projects_in/", "subreddit_subscribers": 869298, "created_utc": 1680912733.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "GitHub recently released a feature preview to diff Jupyter Notebooks in pull requests. What you can't do is add comments to these diffs.\n\nI've built a GitHub App that does the same thing, but it allows comments. It's totally free and can work as a stop-gap while you wait for GitHub to complete their feature.\n\nHere's the homepage: [https:/gitnotebooks.com](https://gitnotebooks.com/)\n\nI'd like to eventually port this to BitBucket and Azure DevOps, so for now just looking for early feedback to improve the tool.", "author_fullname": "t2_ke3w4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "While you wait for GitHub to finish building Jupyter Notebook reviews", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12et5gt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680889394.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;GitHub recently released a feature preview to diff Jupyter Notebooks in pull requests. What you can&amp;#39;t do is add comments to these diffs.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve built a GitHub App that does the same thing, but it allows comments. It&amp;#39;s totally free and can work as a stop-gap while you wait for GitHub to complete their feature.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the homepage: &lt;a href=\"https://gitnotebooks.com/\"&gt;https:/gitnotebooks.com&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to eventually port this to BitBucket and Azure DevOps, so for now just looking for early feedback to improve the tool.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12et5gt", "is_robot_indexable": true, "report_reasons": null, "author": "smith-kyle", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12et5gt/while_you_wait_for_github_to_finish_building/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12et5gt/while_you_wait_for_github_to_finish_building/", "subreddit_subscribers": 869298, "created_utc": 1680889394.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys, i am looking for free online courses in data science, machine learning etc. that also provide a free certification. I've checked coursera ,edx,harvard courses,datacamp,udacity and other platforms but i think all of them require payment for the certification.\nIn case there isn't any free one,which one would you recommend being both not expensive and also well structured.\n\nP.s i have b.sc in mathematics and solid understanding of programming (udergrad subjects:C,C++,Java,Matlab).\nMy first step would be to learn Python and mainly it's differences with the above langueges.\n\nEvery advice or recommendation is appreciated,\nthanks in advance.", "author_fullname": "t2_diqixgma", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for online courses that provide free certification", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12estz3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680888776.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, i am looking for free online courses in data science, machine learning etc. that also provide a free certification. I&amp;#39;ve checked coursera ,edx,harvard courses,datacamp,udacity and other platforms but i think all of them require payment for the certification.\nIn case there isn&amp;#39;t any free one,which one would you recommend being both not expensive and also well structured.&lt;/p&gt;\n\n&lt;p&gt;P.s i have b.sc in mathematics and solid understanding of programming (udergrad subjects:C,C++,Java,Matlab).\nMy first step would be to learn Python and mainly it&amp;#39;s differences with the above langueges.&lt;/p&gt;\n\n&lt;p&gt;Every advice or recommendation is appreciated,\nthanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12estz3", "is_robot_indexable": true, "report_reasons": null, "author": "Dependent-Champion49", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12estz3/looking_for_online_courses_that_provide_free/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12estz3/looking_for_online_courses_that_provide_free/", "subreddit_subscribers": 869298, "created_utc": 1680888776.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_8n5hmj1gq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Quantum Machine Learning Can Boost Drug Discovery", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_12erc37", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/2nwFA9De2dkETkZh-c6Tix-wdK7lb09rowKVv1gI5l0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1680885891.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/p/3ce51be223d2", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/UNJzlAmO_oA73WBdV4AVeESLHg0yat5PIhAJefTUtnk.jpg?auto=webp&amp;v=enabled&amp;s=db1b3884785f4907e23bb23f0b7511c75b88225d", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/UNJzlAmO_oA73WBdV4AVeESLHg0yat5PIhAJefTUtnk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2062b0324ef0ec095d62bb26f31c77497c6275e7", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/UNJzlAmO_oA73WBdV4AVeESLHg0yat5PIhAJefTUtnk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4dd4f6c0b178a97198aef5fffaa46f22484348e6", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/UNJzlAmO_oA73WBdV4AVeESLHg0yat5PIhAJefTUtnk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5a56fe087a4e6f6d77cc1dddf321e8afd83f5c07", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/UNJzlAmO_oA73WBdV4AVeESLHg0yat5PIhAJefTUtnk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f23a84fa3467a2cf7bb3c9d6ccaadcede1333587", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/UNJzlAmO_oA73WBdV4AVeESLHg0yat5PIhAJefTUtnk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e0ff53a7c811697f4668e6e454b100362cf1a6ae", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/UNJzlAmO_oA73WBdV4AVeESLHg0yat5PIhAJefTUtnk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1599e1c4022263cbc735824af0c5427d52c3714c", "width": 1080, "height": 720}], "variants": {}, "id": "4bKAEbJxZDaXbdH-P-k7QBWYfdRhRd-FuddQfTxuzU0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "12erc37", "is_robot_indexable": true, "report_reasons": null, "author": "MagazinePerfect9021", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12erc37/how_quantum_machine_learning_can_boost_drug/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/p/3ce51be223d2", "subreddit_subscribers": 869298, "created_utc": 1680885891.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello there! I am a master's student of medical laboratory sciences hoping to get my PhD in bioinformatics or computational biology, and I recently participated in the Datacamp 'Everyone Can Learn Python Scholarship'.\n\nI tried to tackle the two challenges from the point of view of someone who wants their colleagues to have the best possible understanding of the problem, giving them insights and information without overwhelming them with statistics. This is also why I chose Plotly as my only tool for analysis so as not to make the graphs and code complicated for the reader (i.e., my fictional colleague).\n\nI would appreciate any criticisms or opinions you guys have and I would like to know what you think I should've done differently. Also, if you think that the workspace deserves it, I would seriously appreciate an upvote.  \nThank you.\n\nHere's the link to the entry:  \nhttps://app.datacamp.com/workspace/w/a869ebe5-d49f-4e4c-a00a-192b74c03e8f", "author_fullname": "t2_8evqbb7c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Datacamp 'Everyone Can Learn Python Scholarship' entry", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ep9v1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1680881926.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello there! I am a master&amp;#39;s student of medical laboratory sciences hoping to get my PhD in bioinformatics or computational biology, and I recently participated in the Datacamp &amp;#39;Everyone Can Learn Python Scholarship&amp;#39;.&lt;/p&gt;\n\n&lt;p&gt;I tried to tackle the two challenges from the point of view of someone who wants their colleagues to have the best possible understanding of the problem, giving them insights and information without overwhelming them with statistics. This is also why I chose Plotly as my only tool for analysis so as not to make the graphs and code complicated for the reader (i.e., my fictional colleague).&lt;/p&gt;\n\n&lt;p&gt;I would appreciate any criticisms or opinions you guys have and I would like to know what you think I should&amp;#39;ve done differently. Also, if you think that the workspace deserves it, I would seriously appreciate an upvote.&lt;br/&gt;\nThank you.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the link to the entry:&lt;br/&gt;\n&lt;a href=\"https://app.datacamp.com/workspace/w/a869ebe5-d49f-4e4c-a00a-192b74c03e8f\"&gt;https://app.datacamp.com/workspace/w/a869ebe5-d49f-4e4c-a00a-192b74c03e8f&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/zZwb0qbP2fjw_gJGFWasrVdF8LHMCpabmmgPgQoKuFc.jpg?auto=webp&amp;v=enabled&amp;s=6200d7e1b6a8bdc05dcef79f485481bdc5fe4388", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/zZwb0qbP2fjw_gJGFWasrVdF8LHMCpabmmgPgQoKuFc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8f0de0f56f86bea05a370682c3f06ae5ea19cc4d", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/zZwb0qbP2fjw_gJGFWasrVdF8LHMCpabmmgPgQoKuFc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6d8a8c80178ebf9125398b37b9a53a5ddb77eed7", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/zZwb0qbP2fjw_gJGFWasrVdF8LHMCpabmmgPgQoKuFc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=38137b22f12a844be1b7c455448cc55a12e63a3b", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/zZwb0qbP2fjw_gJGFWasrVdF8LHMCpabmmgPgQoKuFc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=182675253b24e5f6db8d18d1e3a4beccdbd9e1ed", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/zZwb0qbP2fjw_gJGFWasrVdF8LHMCpabmmgPgQoKuFc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=190032e55865b8f952cf46c3b897d7de48d6d7dc", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/zZwb0qbP2fjw_gJGFWasrVdF8LHMCpabmmgPgQoKuFc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=91d125c283ae7077c91a702e86233747214c9675", "width": 1080, "height": 567}], "variants": {}, "id": "UZeNBRQYqCTTuggCdhICWS1x95WjUfJ3Zsib1mgPnXI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ep9v1", "is_robot_indexable": true, "report_reasons": null, "author": "No_Tumbleweed_153", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12ep9v1/datacamp_everyone_can_learn_python_scholarship/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12ep9v1/datacamp_everyone_can_learn_python_scholarship/", "subreddit_subscribers": 869298, "created_utc": 1680881926.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone, I wanted to share a Python library I recently came across called TextScribe. This library offers a streamlined and efficient way to read and write data to CSV, JSON, and TXT files, making data processing faster and more convenient.\n\nSome of the key features of the TextScribe library include:\n\n* Writing data to CSV, TXT, and JSON files with custom labels\n* Extracting data from CSV and TXT files based on specific labels\n* Searching a JSON file for all occurrences of a specified label and returning the corresponding values\n\nI've found this library to be really helpful in my own data processing projects, and I think it could be a great tool for anyone working with these types of files.\n\nIf you're interested, you can check out the library on PyPI here: [**https://pypi.org/project/textscribe/**](https://pypi.org/project/textscribe/)\n\n**Here is the GitHub** [**https://github.com/huntert1004/textscribe**](https://github.com/huntert1004/textscribe)\n\nWaidAI LLC Official Website [https://waidai.co/index.html](https://waidai.co/index.html)\n\nAnd if you have any questions or feedback, feel free to share in the comments below. Thanks!", "author_fullname": "t2_kdovct2j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "TextScribe - A Python Library for Efficient Data Processing of CSV, JSON, and TXT Files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12eo0d9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1680879486.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I wanted to share a Python library I recently came across called TextScribe. This library offers a streamlined and efficient way to read and write data to CSV, JSON, and TXT files, making data processing faster and more convenient.&lt;/p&gt;\n\n&lt;p&gt;Some of the key features of the TextScribe library include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Writing data to CSV, TXT, and JSON files with custom labels&lt;/li&gt;\n&lt;li&gt;Extracting data from CSV and TXT files based on specific labels&lt;/li&gt;\n&lt;li&gt;Searching a JSON file for all occurrences of a specified label and returning the corresponding values&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;ve found this library to be really helpful in my own data processing projects, and I think it could be a great tool for anyone working with these types of files.&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re interested, you can check out the library on PyPI here: &lt;a href=\"https://pypi.org/project/textscribe/\"&gt;&lt;strong&gt;https://pypi.org/project/textscribe/&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Here is the GitHub&lt;/strong&gt; &lt;a href=\"https://github.com/huntert1004/textscribe\"&gt;&lt;strong&gt;https://github.com/huntert1004/textscribe&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;WaidAI LLC Official Website &lt;a href=\"https://waidai.co/index.html\"&gt;https://waidai.co/index.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And if you have any questions or feedback, feel free to share in the comments below. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0kryPnq0tdgIBps0GUhMZoZ9rxHjvu2Jd-BPJ8vovPA.jpg?auto=webp&amp;v=enabled&amp;s=f0cc8dce4c4d114433073f7ec64bf299623fcef9", "width": 300, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/0kryPnq0tdgIBps0GUhMZoZ9rxHjvu2Jd-BPJ8vovPA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6b8865fd719f17e774b2178948603d0c4bfb2673", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/0kryPnq0tdgIBps0GUhMZoZ9rxHjvu2Jd-BPJ8vovPA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d7f78455787f3622b85aa8394a3ee4b6f14e35c1", "width": 216, "height": 216}], "variants": {}, "id": "IUHM4ctLZQorzkPuYJ4IkGSag8BtaIqZoyqL1L53KuM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12eo0d9", "is_robot_indexable": true, "report_reasons": null, "author": "waidai_the_real_one", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12eo0d9/textscribe_a_python_library_for_efficient_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12eo0d9/textscribe_a_python_library_for_efficient_data/", "subreddit_subscribers": 869298, "created_utc": 1680879486.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all! I am currently working as a data scientist and have around two years of experience. I am working from home since the job started and I live in a tier 2 city.\nWorking from home does have some advantages for example rent is saved, family support, more time for hobbies etc.\nBut at the same time I'm not able to network, and work on my growth. I just end up doing the assigned work in job and thats it.\nI still prefer Wfh. But just wanted to understand how can i focus more on growth from the perspective of future in data science, I want to make it big\ud83d\ude05.\nI will be highly thankful if you guys can suggest some tips around How can I grow as a data scientist working from home.  \n\nThank you!", "author_fullname": "t2_9v4zx4k9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can i work on my growth.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ejnp9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680870466.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all! I am currently working as a data scientist and have around two years of experience. I am working from home since the job started and I live in a tier 2 city.\nWorking from home does have some advantages for example rent is saved, family support, more time for hobbies etc.\nBut at the same time I&amp;#39;m not able to network, and work on my growth. I just end up doing the assigned work in job and thats it.\nI still prefer Wfh. But just wanted to understand how can i focus more on growth from the perspective of future in data science, I want to make it big\ud83d\ude05.\nI will be highly thankful if you guys can suggest some tips around How can I grow as a data scientist working from home.  &lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ejnp9", "is_robot_indexable": true, "report_reasons": null, "author": "LetterheadFar5316", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12ejnp9/how_can_i_work_on_my_growth/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12ejnp9/how_can_i_work_on_my_growth/", "subreddit_subscribers": 869298, "created_utc": 1680870466.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_82gnk7j1o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Prepare for an SAP Certification Exam\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_12eu21e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/vqLAzANZpkXZrVwhgigbvGGWzLw5FkAej6XbesWQ1PU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1680891139.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "jtrainings.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://jtrainings.com/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9i5gi3MnSnPifdqB1kEMtMrpWqTTZNQltsR7U24fhlk.jpg?auto=webp&amp;v=enabled&amp;s=7408cfe6fd3a23deb35e16415b3f73bd0badb9e5", "width": 1024, "height": 576}, "resolutions": [{"url": "https://external-preview.redd.it/9i5gi3MnSnPifdqB1kEMtMrpWqTTZNQltsR7U24fhlk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7efb46815462f1b841a498bfddadb2f110f33bc2", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/9i5gi3MnSnPifdqB1kEMtMrpWqTTZNQltsR7U24fhlk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cf0c02a1c94317527e79d84919e4274f69efb207", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/9i5gi3MnSnPifdqB1kEMtMrpWqTTZNQltsR7U24fhlk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b369ffe7597a2d0b4b10741c05652875c358b6a3", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/9i5gi3MnSnPifdqB1kEMtMrpWqTTZNQltsR7U24fhlk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6ae9a5df7e2de5e31287598e05ab40602ab0991c", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/9i5gi3MnSnPifdqB1kEMtMrpWqTTZNQltsR7U24fhlk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f19ba9542e2eb81a4a2b85254336c60b309987c7", "width": 960, "height": 540}], "variants": {}, "id": "ysqHo8A_cOgFipXX-653GHH98WUafBrojFua2X8-EnI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "12eu21e", "is_robot_indexable": true, "report_reasons": null, "author": "Sesh9988", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12eu21e/how_to_prepare_for_an_sap_certification_exam/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://jtrainings.com/", "subreddit_subscribers": 869298, "created_utc": 1680891139.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a room impulse response (RIR) sample audio file and trying to find the start and end point of said impulse. This type of sample has relative silence except for the single impulse.\n\nI could find the init point of the impulse by looking at the maxima, but then, how do I find the last from the tail.\n\n&amp;#x200B;\n\nWhen taking the absolute of the RIR, this looks like a time series for which I'm trying to find a peak.\n\n[Absolute values](https://preview.redd.it/6ehg71iithsa1.png?width=474&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=39fb80c4ea1d8826d469b3b3939106e54900a2e5)", "author_fullname": "t2_hfgzs7v2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Q] Anyone knows a simple algorithm to find the start and end point of a peak?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 67, "top_awarded_type": null, "hide_score": false, "media_metadata": {"6ehg71iithsa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 51, "x": 108, "u": "https://preview.redd.it/6ehg71iithsa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4acee4624c798119256c858c2226f1f299dad517"}, {"y": 103, "x": 216, "u": "https://preview.redd.it/6ehg71iithsa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=36d599e7019520d9bd0a81a379514207ea88fbe0"}, {"y": 153, "x": 320, "u": "https://preview.redd.it/6ehg71iithsa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b745a4ab5107c04c48a2aedf7d3ac45d8b041946"}], "s": {"y": 227, "x": 474, "u": "https://preview.redd.it/6ehg71iithsa1.png?width=474&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=39fb80c4ea1d8826d469b3b3939106e54900a2e5"}, "id": "6ehg71iithsa1"}}, "name": "t3_12erq2m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Ek2A-BsQenLyquDJNz6xscyOm1EgxQ9epPrJ2aV39Mg.jpg", "edited": 1680889213.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680886643.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a room impulse response (RIR) sample audio file and trying to find the start and end point of said impulse. This type of sample has relative silence except for the single impulse.&lt;/p&gt;\n\n&lt;p&gt;I could find the init point of the impulse by looking at the maxima, but then, how do I find the last from the tail.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;When taking the absolute of the RIR, this looks like a time series for which I&amp;#39;m trying to find a peak.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/6ehg71iithsa1.png?width=474&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=39fb80c4ea1d8826d469b3b3939106e54900a2e5\"&gt;Absolute values&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12erq2m", "is_robot_indexable": true, "report_reasons": null, "author": "AlternativeDish5596", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12erq2m/q_anyone_knows_a_simple_algorithm_to_find_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12erq2m/q_anyone_knows_a_simple_algorithm_to_find_the/", "subreddit_subscribers": 869298, "created_utc": 1680886643.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi! I applied for the Operations Internship at Uber and was sent an invitation to do an \"Uber Operations Assessment\" via CodeSignal. You are given 75 minutes to complete it, but no information as to what will be asked. Little information online as well. The following is given in the job posting:\n\nSkills: Knowledge of data analytics, SQL and experience with statistical packages or basic programming skills (ie Python) is highly regarded.\n\nSo most likely SQL? If anyone could provide insight as to what to expect it would be much appreciated! Deadline to complete is in 4 days.", "author_fullname": "t2_a3ddnn1j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Uber Analytical Assessment for Operations Internship 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ergob", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680886135.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I applied for the Operations Internship at Uber and was sent an invitation to do an &amp;quot;Uber Operations Assessment&amp;quot; via CodeSignal. You are given 75 minutes to complete it, but no information as to what will be asked. Little information online as well. The following is given in the job posting:&lt;/p&gt;\n\n&lt;p&gt;Skills: Knowledge of data analytics, SQL and experience with statistical packages or basic programming skills (ie Python) is highly regarded.&lt;/p&gt;\n\n&lt;p&gt;So most likely SQL? If anyone could provide insight as to what to expect it would be much appreciated! Deadline to complete is in 4 days.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ergob", "is_robot_indexable": true, "report_reasons": null, "author": "Last-Education4079", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12ergob/uber_analytical_assessment_for_operations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12ergob/uber_analytical_assessment_for_operations/", "subreddit_subscribers": 869298, "created_utc": 1680886135.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}