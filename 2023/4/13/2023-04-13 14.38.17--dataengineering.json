{"kind": "Listing", "data": {"after": "t3_12kkxcl", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI have written my first blog post in medium about what I have learned solving leetcode SQL problems. Shared some tips for those who want to start solving SQL problems too.\n\nAlso added some resources in the post which might be beneficial for you.\n\nHappy reading!\n\n[https://medium.com/@iamrafiul/what-i-have-learned-by-solving-almost-all-the-sql-problems-in-leetcode-670b8a2cb32e](https://medium.com/@iamrafiul/what-i-have-learned-by-solving-almost-all-the-sql-problems-in-leetcode-670b8a2cb32e)", "author_fullname": "t2_hdqq8zi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What I have learned by solving (almost) all the SQL problems in Leetcode", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12jt9hl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 70, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 70, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681320798.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I have written my first blog post in medium about what I have learned solving leetcode SQL problems. Shared some tips for those who want to start solving SQL problems too.&lt;/p&gt;\n\n&lt;p&gt;Also added some resources in the post which might be beneficial for you.&lt;/p&gt;\n\n&lt;p&gt;Happy reading!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@iamrafiul/what-i-have-learned-by-solving-almost-all-the-sql-problems-in-leetcode-670b8a2cb32e\"&gt;https://medium.com/@iamrafiul/what-i-have-learned-by-solving-almost-all-the-sql-problems-in-leetcode-670b8a2cb32e&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12jt9hl", "is_robot_indexable": true, "report_reasons": null, "author": "rsabbir", "discussion_type": null, "num_comments": 42, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12jt9hl/what_i_have_learned_by_solving_almost_all_the_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12jt9hl/what_i_have_learned_by_solving_almost_all_the_sql/", "subreddit_subscribers": 98522, "created_utc": 1681320798.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks, we just published a new blog post about our in-house Metrics Layer for Experimentation. At DoorDash, we faced numerous challenges with our experimentation analysis platform, Curie, due to our ad-hoc approach to metrics. In our latest post, we delve into these challenges and share how a Metrics Layer helped standardize and scale our metrics for Experimentation. We also discuss the design and implementation of our data models, metrics authorship, metrics governance, and our highly scalable metrics computation engine, while documenting our key learnings.\n\nAs the trend of Metrics Layer adoption gains traction in the data space, we're thrilled to share a practical application of its value. We would love for you to give it a read and share your thoughts! [https://doordash.engineering/2023/04/12/using-metrics-layer-to-standardize-and-scale-experimentation-at-doordash/](https://doordash.engineering/2023/04/12/using-metrics-layer-to-standardize-and-scale-experimentation-at-doordash/)", "author_fullname": "t2_a12ijdpz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Blog Post on how DoorDash used the metrics layer to scale and standardize Metrics for Experimentation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12k1o5r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681338087.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks, we just published a new blog post about our in-house Metrics Layer for Experimentation. At DoorDash, we faced numerous challenges with our experimentation analysis platform, Curie, due to our ad-hoc approach to metrics. In our latest post, we delve into these challenges and share how a Metrics Layer helped standardize and scale our metrics for Experimentation. We also discuss the design and implementation of our data models, metrics authorship, metrics governance, and our highly scalable metrics computation engine, while documenting our key learnings.&lt;/p&gt;\n\n&lt;p&gt;As the trend of Metrics Layer adoption gains traction in the data space, we&amp;#39;re thrilled to share a practical application of its value. We would love for you to give it a read and share your thoughts! &lt;a href=\"https://doordash.engineering/2023/04/12/using-metrics-layer-to-standardize-and-scale-experimentation-at-doordash/\"&gt;https://doordash.engineering/2023/04/12/using-metrics-layer-to-standardize-and-scale-experimentation-at-doordash/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12k1o5r", "is_robot_indexable": true, "report_reasons": null, "author": "Electrical-Apricot25", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12k1o5r/blog_post_on_how_doordash_used_the_metrics_layer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12k1o5r/blog_post_on_how_doordash_used_the_metrics_layer/", "subreddit_subscribers": 98522, "created_utc": 1681338087.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Worked as a full stack dev (front end) for four years and pivoted to DA. I enjoy exploring data but found it difficult to produce useful analyses. After being in the role for 4 years, I realized my communication skills do not get better, and I kinda hated sitting in a lot of meetings. A lot of my analyses weren't used, and I want to produce something useful and tangible. I enjoyed the first three years because I mostly built dashboards, wrote SQL and didn't have to attend too many meetings. It's definitely less stressful that SWE.\n\nMy last role as a product analyst in a startup and I hated it. I'm getting good at coming up with metrics but so many meetings and I am expected to work as consultant (i.e. provide recommendations about the product that I didn't know much in the first place. I interviewed around, and it seems really hard to get a role that pays &gt; 150k as DA (unless maybe in big tech). The analysis that took me weeks to produce is also not used. And, there are endless questions to explore. Started to think that I'm not good at this role. \n\nBecause I hate dealing with people, I don't think I'd be a good candidate to be an analytic manager either.  What do you do if you enjoy exploring the data but you are not good at it nor good at presenting the results? I am suck at presentation btw. I don't enjoy SWE as much as DA, but observing how fast I am troubleshooting bugs/researching something, I feel like I'm more natural as SWE. I love the investigation part of data analysis, but don't feel like I'm good at it. I don't find building as enjoyable as exploring, although I don't hate it. \n\nWith someone in my background, is it easier to be front-end dev again, even though it was four/five years ago, or is it easier to pivot to Data engineer? And will the hiring manager think it's strange that I want to be SWE again?", "author_fullname": "t2_a9ij7ckc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SWE --&gt; Data Analyst --&gt; SWE again", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12kd66n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 35, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681363410.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Worked as a full stack dev (front end) for four years and pivoted to DA. I enjoy exploring data but found it difficult to produce useful analyses. After being in the role for 4 years, I realized my communication skills do not get better, and I kinda hated sitting in a lot of meetings. A lot of my analyses weren&amp;#39;t used, and I want to produce something useful and tangible. I enjoyed the first three years because I mostly built dashboards, wrote SQL and didn&amp;#39;t have to attend too many meetings. It&amp;#39;s definitely less stressful that SWE.&lt;/p&gt;\n\n&lt;p&gt;My last role as a product analyst in a startup and I hated it. I&amp;#39;m getting good at coming up with metrics but so many meetings and I am expected to work as consultant (i.e. provide recommendations about the product that I didn&amp;#39;t know much in the first place. I interviewed around, and it seems really hard to get a role that pays &amp;gt; 150k as DA (unless maybe in big tech). The analysis that took me weeks to produce is also not used. And, there are endless questions to explore. Started to think that I&amp;#39;m not good at this role. &lt;/p&gt;\n\n&lt;p&gt;Because I hate dealing with people, I don&amp;#39;t think I&amp;#39;d be a good candidate to be an analytic manager either.  What do you do if you enjoy exploring the data but you are not good at it nor good at presenting the results? I am suck at presentation btw. I don&amp;#39;t enjoy SWE as much as DA, but observing how fast I am troubleshooting bugs/researching something, I feel like I&amp;#39;m more natural as SWE. I love the investigation part of data analysis, but don&amp;#39;t feel like I&amp;#39;m good at it. I don&amp;#39;t find building as enjoyable as exploring, although I don&amp;#39;t hate it. &lt;/p&gt;\n\n&lt;p&gt;With someone in my background, is it easier to be front-end dev again, even though it was four/five years ago, or is it easier to pivot to Data engineer? And will the hiring manager think it&amp;#39;s strange that I want to be SWE again?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12kd66n", "is_robot_indexable": true, "report_reasons": null, "author": "thriftyberry", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12kd66n/swe_data_analyst_swe_again/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12kd66n/swe_data_analyst_swe_again/", "subreddit_subscribers": 98522, "created_utc": 1681363410.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I started out doing a lot of ETL/ELT pipeline development and some devops at my current company, where I have been for more than 2 years.\n\n\n\n\n\nOver the past 6 months, my responsibilities have changed where I mostly meet with data scientists and data analysts and translate their code into something that is better for production.  Now, I spend most of my day trying to understand a data scientist's 4,000 line Jupyter notebook, which is a much different experience than understanding a larger data engineering team's code repository.\n\n\n\n\n\nWhat are my options, as the job market isn't good where I live?  Also, I work at a good company so most likely I would be looking at a huge decrease in pay if I switch jobs.", "author_fullname": "t2_3v6ob2bf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get out of a boring project?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12jxyze", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681331274.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I started out doing a lot of ETL/ELT pipeline development and some devops at my current company, where I have been for more than 2 years.&lt;/p&gt;\n\n&lt;p&gt;Over the past 6 months, my responsibilities have changed where I mostly meet with data scientists and data analysts and translate their code into something that is better for production.  Now, I spend most of my day trying to understand a data scientist&amp;#39;s 4,000 line Jupyter notebook, which is a much different experience than understanding a larger data engineering team&amp;#39;s code repository.&lt;/p&gt;\n\n&lt;p&gt;What are my options, as the job market isn&amp;#39;t good where I live?  Also, I work at a good company so most likely I would be looking at a huge decrease in pay if I switch jobs.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12jxyze", "is_robot_indexable": true, "report_reasons": null, "author": "data_preprocessing", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/12jxyze/how_to_get_out_of_a_boring_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12jxyze/how_to_get_out_of_a_boring_project/", "subreddit_subscribers": 98522, "created_utc": 1681331274.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can the Lakehouse architecture be created without using Databricks in Azure Synapse? I'm not a big fan of notebooks and would rather develop in an IDE, following basic SWE principles.", "author_fullname": "t2_b4yb48b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lakehouse architecture in Azure Synapse without Databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12jp2hw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681312000.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can the Lakehouse architecture be created without using Databricks in Azure Synapse? I&amp;#39;m not a big fan of notebooks and would rather develop in an IDE, following basic SWE principles.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12jp2hw", "is_robot_indexable": true, "report_reasons": null, "author": "optionmonk", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12jp2hw/lakehouse_architecture_in_azure_synapse_without/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12jp2hw/lakehouse_architecture_in_azure_synapse_without/", "subreddit_subscribers": 98522, "created_utc": 1681312000.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the title says. \n\nI'm based in the UK and interviewing for a well known company.\n\nI've been provided an outline of the interview and in it they want me to prepare a diagram of my current company's data architecture and spend 10-20 mins explaining it.\n\nI don't know if it's an odd request or not - I understand wanting to test my knowledge around architecture but it still feels odd.", "author_fullname": "t2_ske3s9us", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interviewer wants me to go into detail about current company's architecture", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12knal1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681388629.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title says. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m based in the UK and interviewing for a well known company.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been provided an outline of the interview and in it they want me to prepare a diagram of my current company&amp;#39;s data architecture and spend 10-20 mins explaining it.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t know if it&amp;#39;s an odd request or not - I understand wanting to test my knowledge around architecture but it still feels odd.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "12knal1", "is_robot_indexable": true, "report_reasons": null, "author": "iamanoob38", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12knal1/interviewer_wants_me_to_go_into_detail_about/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12knal1/interviewer_wants_me_to_go_into_detail_about/", "subreddit_subscribers": 98522, "created_utc": 1681388629.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI'm the sole data engineer at a small company (70-ish employees) and have been tasked with setting up a data warehouse. Currently all our infrastructure is on-prem, but we'd like to start with our DWH in SQL Server on Azure and using analysis services for compute for Power BI. \n\nI'm struggling a lot to come up with reasonable estimates for our expected costs. We have recently started a separate project, done by an external consultant, calls an API using Azure Functions to grab a few hundred rows (a few very straight-forward GET requests through Python), store it in a container, then uses Azure Data Factory to call a few stored procedures on the SQL Server to update the database. So far, the costs seem to be about USD 5.00 per function call (+ about USD 5.00 per day in other costs, totaling in about USD 300 per month), which - to me - seems like a lot for something so simple.\n\nThe consultant mentions the high function costs is due to the use of Azure Function Premium, which is needed as the alternative (consumption plan) doesn't support VNET access. \n\nI'm now concerned how much the costs will be if we want to move our ERP data from our on-prem database to Azure SQL Server using the same methods. \n\nAt this point I'm wondering if it isn't worth it to just use a virtual machine and run dagster/airflow/prefect to replace the Azure Functions &amp; Azure Data Factory. In that case, I'd only have to scale out the virtual machine if the process is taking too long, but at least my company isn't suddenly surprised by hundreds or thousands of dollars in extra costs due to (seemingly) expensive functions. I guess I'm also a bit worried of running into a [Troy Hunt-like situation](https://www.troyhunt.com/how-i-got-pwned-by-my-cloud-costs/) where a misconfiguration suddenly drives up the costs without me noticing in time. \n\nI feel like the only way to get a rough idea about the costs is to just make a proof of concept and try it, which would require quite the time investment (which could be spend on the many other projects I have lined up), plus the costs of the proof of concept may not scale linearly with the real-world data we'd eventually be using. \n\nI believe this problem isn't exclusive to Azure (it just happens to be what we're using) but could be AWS or GCP just as easily. \n\nHow have others dealt with small company budgets and estimating their costs?", "author_fullname": "t2_ko2ybcf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Understanding and estimating cloud costs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12kgajr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681371483.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m the sole data engineer at a small company (70-ish employees) and have been tasked with setting up a data warehouse. Currently all our infrastructure is on-prem, but we&amp;#39;d like to start with our DWH in SQL Server on Azure and using analysis services for compute for Power BI. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m struggling a lot to come up with reasonable estimates for our expected costs. We have recently started a separate project, done by an external consultant, calls an API using Azure Functions to grab a few hundred rows (a few very straight-forward GET requests through Python), store it in a container, then uses Azure Data Factory to call a few stored procedures on the SQL Server to update the database. So far, the costs seem to be about USD 5.00 per function call (+ about USD 5.00 per day in other costs, totaling in about USD 300 per month), which - to me - seems like a lot for something so simple.&lt;/p&gt;\n\n&lt;p&gt;The consultant mentions the high function costs is due to the use of Azure Function Premium, which is needed as the alternative (consumption plan) doesn&amp;#39;t support VNET access. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m now concerned how much the costs will be if we want to move our ERP data from our on-prem database to Azure SQL Server using the same methods. &lt;/p&gt;\n\n&lt;p&gt;At this point I&amp;#39;m wondering if it isn&amp;#39;t worth it to just use a virtual machine and run dagster/airflow/prefect to replace the Azure Functions &amp;amp; Azure Data Factory. In that case, I&amp;#39;d only have to scale out the virtual machine if the process is taking too long, but at least my company isn&amp;#39;t suddenly surprised by hundreds or thousands of dollars in extra costs due to (seemingly) expensive functions. I guess I&amp;#39;m also a bit worried of running into a &lt;a href=\"https://www.troyhunt.com/how-i-got-pwned-by-my-cloud-costs/\"&gt;Troy Hunt-like situation&lt;/a&gt; where a misconfiguration suddenly drives up the costs without me noticing in time. &lt;/p&gt;\n\n&lt;p&gt;I feel like the only way to get a rough idea about the costs is to just make a proof of concept and try it, which would require quite the time investment (which could be spend on the many other projects I have lined up), plus the costs of the proof of concept may not scale linearly with the real-world data we&amp;#39;d eventually be using. &lt;/p&gt;\n\n&lt;p&gt;I believe this problem isn&amp;#39;t exclusive to Azure (it just happens to be what we&amp;#39;re using) but could be AWS or GCP just as easily. &lt;/p&gt;\n\n&lt;p&gt;How have others dealt with small company budgets and estimating their costs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/lPeDJ248ZZFvNTYcuSeaEt0vOZFlzdWp-rN0_LK8rSE.jpg?auto=webp&amp;v=enabled&amp;s=6c5b54e1cbe021264a7db007976eecc17e974733", "width": 1337, "height": 757}, "resolutions": [{"url": "https://external-preview.redd.it/lPeDJ248ZZFvNTYcuSeaEt0vOZFlzdWp-rN0_LK8rSE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9609aac2705508a8fe89456107bc76f863db9ad6", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/lPeDJ248ZZFvNTYcuSeaEt0vOZFlzdWp-rN0_LK8rSE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eb5c66e5c7b247bd993169b65485460302aedc85", "width": 216, "height": 122}, {"url": "https://external-preview.redd.it/lPeDJ248ZZFvNTYcuSeaEt0vOZFlzdWp-rN0_LK8rSE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c3cb2b47e5b9b87fff08fdbb2892318c5113d685", "width": 320, "height": 181}, {"url": "https://external-preview.redd.it/lPeDJ248ZZFvNTYcuSeaEt0vOZFlzdWp-rN0_LK8rSE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cdd573ea39858e84b8b02e46c2fef549fad5ce0d", "width": 640, "height": 362}, {"url": "https://external-preview.redd.it/lPeDJ248ZZFvNTYcuSeaEt0vOZFlzdWp-rN0_LK8rSE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3323cce877ff4f089ddcea63ec7427d30a3799de", "width": 960, "height": 543}, {"url": "https://external-preview.redd.it/lPeDJ248ZZFvNTYcuSeaEt0vOZFlzdWp-rN0_LK8rSE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=96692c752313aba9b74361425bbfd766bb519fa2", "width": 1080, "height": 611}], "variants": {}, "id": "yyHzldgdQM02tfKU160oThzjjeuuF5lm9yQnCmU1Mfk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12kgajr", "is_robot_indexable": true, "report_reasons": null, "author": "nl_dhh", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12kgajr/understanding_and_estimating_cloud_costs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12kgajr/understanding_and_estimating_cloud_costs/", "subreddit_subscribers": 98522, "created_utc": 1681371483.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nI'm trying to create a mapping data flow on ADF with CDC enabled. Both source and destination are Azure SQL DB. For the first full load, it works. But when I try to do an update on the source, the sink doesn't show the changes. It seems the UPSERT operation doesn't work on the sink. However, it says on the data flow metadata that 1 row was written, but the sink table doesn't show the update I made.\n\nFor context, inside my mapping data flow, I'm applying some joins from the CDC-enabled source with some static dimension tables. The schema of the source and the destination are not the same, and the key from the source and the destination is also not the same. I've tried running from activity runtime, trigger run, and data flow debug and all doesn't update the sink.\n\nIs this a bug? Or how does the mapping data flow CDC feature work?", "author_fullname": "t2_64zxitsw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ADF Mapping Data Flow CDC", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12k49fy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681343149.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to create a mapping data flow on ADF with CDC enabled. Both source and destination are Azure SQL DB. For the first full load, it works. But when I try to do an update on the source, the sink doesn&amp;#39;t show the changes. It seems the UPSERT operation doesn&amp;#39;t work on the sink. However, it says on the data flow metadata that 1 row was written, but the sink table doesn&amp;#39;t show the update I made.&lt;/p&gt;\n\n&lt;p&gt;For context, inside my mapping data flow, I&amp;#39;m applying some joins from the CDC-enabled source with some static dimension tables. The schema of the source and the destination are not the same, and the key from the source and the destination is also not the same. I&amp;#39;ve tried running from activity runtime, trigger run, and data flow debug and all doesn&amp;#39;t update the sink.&lt;/p&gt;\n\n&lt;p&gt;Is this a bug? Or how does the mapping data flow CDC feature work?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12k49fy", "is_robot_indexable": true, "report_reasons": null, "author": "vinsanity1603", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12k49fy/adf_mapping_data_flow_cdc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12k49fy/adf_mapping_data_flow_cdc/", "subreddit_subscribers": 98522, "created_utc": 1681343149.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Last week I started an internship at a large pharma company.  The work lays somewhere within the data engineering sphere.  I'm told I am going to be building out data pipelines to automate the collection of experimental data.  It will involve a lot of SQL and Python work, as well as some data visualization tools.\n\nAfter meeting a lot of people and starting to dig into the work, I am getting somewhat anxious.  The underlying data is generated by chemists, biologists, and biochemists.  My academic background is in computer science and data science.  This is also my first professional experience (I am finishing up a masters in data science currently.)\n\nSo, I am a bit overwhelmed right now and I feel like a fish out of water dealing with data of which I have no understanding of the underlying meaning.  It is a lot of chromatographic data dealing with human proteins.  I just have no academic background for it.\n\nHas anyone been in a situation like this?  When working in a new data domain, how long does it take to become productive?  The internship was designed for a data science student, and that was my background.  I'm not sure how the senior employees will react when I have to ask the most basic fundamental questions about the science.", "author_fullname": "t2_946ecf3o1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How long did it take you to be productive in a DE job when working in new business domain?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12k7mup", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681350642.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Last week I started an internship at a large pharma company.  The work lays somewhere within the data engineering sphere.  I&amp;#39;m told I am going to be building out data pipelines to automate the collection of experimental data.  It will involve a lot of SQL and Python work, as well as some data visualization tools.&lt;/p&gt;\n\n&lt;p&gt;After meeting a lot of people and starting to dig into the work, I am getting somewhat anxious.  The underlying data is generated by chemists, biologists, and biochemists.  My academic background is in computer science and data science.  This is also my first professional experience (I am finishing up a masters in data science currently.)&lt;/p&gt;\n\n&lt;p&gt;So, I am a bit overwhelmed right now and I feel like a fish out of water dealing with data of which I have no understanding of the underlying meaning.  It is a lot of chromatographic data dealing with human proteins.  I just have no academic background for it.&lt;/p&gt;\n\n&lt;p&gt;Has anyone been in a situation like this?  When working in a new data domain, how long does it take to become productive?  The internship was designed for a data science student, and that was my background.  I&amp;#39;m not sure how the senior employees will react when I have to ask the most basic fundamental questions about the science.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12k7mup", "is_robot_indexable": true, "report_reasons": null, "author": "Accomplished-Day131", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12k7mup/how_long_did_it_take_you_to_be_productive_in_a_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12k7mup/how_long_did_it_take_you_to_be_productive_in_a_de/", "subreddit_subscribers": 98522, "created_utc": 1681350642.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nWe are building an [open source SDK](https://github.com/syftdata/syft) to collect well-structured (schema-ed) event data from products. It can send events to any analytics provider with plugins. We were curious what kind of providers do folks usually use so that we can prioritize supporting them. Thank you! \n\n&amp;#x200B;\n\n[View Poll](https://www.reddit.com/poll/12k05ax)", "author_fullname": "t2_srog06cd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which analytics service do you use to collect events from your products?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12k05ax", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681335233.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;We are building an &lt;a href=\"https://github.com/syftdata/syft\"&gt;open source SDK&lt;/a&gt; to collect well-structured (schema-ed) event data from products. It can send events to any analytics provider with plugins. We were curious what kind of providers do folks usually use so that we can prioritize supporting them. Thank you! &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/12k05ax\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/gd9jVm8evPRxEVxQYuc6iSxlnIeE55h9srwn-PnDDME.jpg?auto=webp&amp;v=enabled&amp;s=5dfd04e756ee0d251bd69f3047b2117602bbc73b", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/gd9jVm8evPRxEVxQYuc6iSxlnIeE55h9srwn-PnDDME.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cafaf1f322ef99dc525b0d7e7fe422b50a064faa", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/gd9jVm8evPRxEVxQYuc6iSxlnIeE55h9srwn-PnDDME.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2435dd4b9882217f06a50eb9b6061d44a56391d2", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/gd9jVm8evPRxEVxQYuc6iSxlnIeE55h9srwn-PnDDME.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ed5d8ca81945539243bb6f7e51e699ec4a4711a1", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/gd9jVm8evPRxEVxQYuc6iSxlnIeE55h9srwn-PnDDME.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=17c004f7c30e8349a9675b727fb91aeaec807c1f", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/gd9jVm8evPRxEVxQYuc6iSxlnIeE55h9srwn-PnDDME.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8e7dd567123f2146d0ba5f19566610c845679abe", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/gd9jVm8evPRxEVxQYuc6iSxlnIeE55h9srwn-PnDDME.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9b74e820054ab57e8d3286c9066e87082aedbebf", "width": 1080, "height": 540}], "variants": {}, "id": "YhNxENLWlaqrF0j6uW3Za6r_liX2Iq7a3j3kLl0CHxs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "12k05ax", "is_robot_indexable": true, "report_reasons": null, "author": "aesboe", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1681594433943, "options": [{"text": "Google Analytics", "id": "22531628"}, {"text": "Segment", "id": "22531629"}, {"text": "Amplitude", "id": "22531630"}, {"text": "Mixpanel", "id": "22531631"}, {"text": "Heap", "id": "22531632"}, {"text": "Other (reply in comments)", "id": "22531633"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 172, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12k05ax/which_analytics_service_do_you_use_to_collect/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/12k05ax/which_analytics_service_do_you_use_to_collect/", "subreddit_subscribers": 98522, "created_utc": 1681335233.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello fellow data degenerates,\n\nI'm part of a team working on a tool called [Slight](https://www.slight.co/), and we'd love to hear your feedback. Our goal is to simplify and streamline data workflows, making it easier for both technical and non-technical teams, and internal and external teams to access and work with data.\n\nSlight turns your parameterized queries into accessible interfaces, enabling internal &amp; external users to access data seamlessly, in spreadsheets, APIs, the website UI, or anywhere. Basically we create an API from parameterized queries, and then generate interfaces and a caching layer on top of the API.\n\n**Why I'm interested in hearing from data engineers:** even though this tool is more for unlocking the value that data engineering creates (so, it comes in typically \"after\" data engineering, something in the ballpark of a BI tool), it's the post-database \"business tool\" I wanted back when I was doing data eng. With an API-first approach, it's a tool that enables data teams to respond to queries from their team and external users more efficiently. We have no dashboards either \u2014 we do have some simple charts, to avoid the need to leave Slight for simple things, but basically Slight's goal is to be a layer on top of your data warehouse and get data elsewhere. \n\nThe basic goal is to unlock the full potential of your data warehouse for everyone. Things like:\n\n- Automating repetitive data requests\n- Reducing the load on data engineers and data teams when dealing with ad-hoc queries, especially if API-heavy (saw [this example](https://www.reddit.com/r/dataengineering/comments/vbd44r/the_api_i_created_as_an_intern_surprisingly_made/) recently)\n- Making it easy for non-technical teams to access and analyze data without constant support (but without the failed dream of \"self service\"... sort of more like canonical curated queries) \u2014 e.g. we have our [Google Sheets integration](https://www.slight.co/blog/google-sheets)\n- Caching for any use-case: write a query, decide how frequently you want it cached, and you're done\n- Big one: Streamlining the process of sharing data/queries with external users/clients\n\nA video demo: https://www.youtube.com/watch?v=cRspkUKUgZQ\n\nIf you're up for trying Slight, we only charge if you're heavily serving external users with it, or only if internal usage is huge. So basically you can get really far with https://www.slight.co/trial for free. If you want a quicker way to play with Slight, https://slight.run/ is our free public version (runs on BigQuery).\n\nAny thoughts, opinions or suggestions are much appreciated.\n\nCheers,\n\nColman\n\n(btw while I've seen a few posts along these lines, let me know if this is too much \"self promotion)", "author_fullname": "t2_7xlyovao", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Request for Feedback: Slight \u2013 streamlining data workflows on your data warehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12juze7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681325486.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow data degenerates,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m part of a team working on a tool called &lt;a href=\"https://www.slight.co/\"&gt;Slight&lt;/a&gt;, and we&amp;#39;d love to hear your feedback. Our goal is to simplify and streamline data workflows, making it easier for both technical and non-technical teams, and internal and external teams to access and work with data.&lt;/p&gt;\n\n&lt;p&gt;Slight turns your parameterized queries into accessible interfaces, enabling internal &amp;amp; external users to access data seamlessly, in spreadsheets, APIs, the website UI, or anywhere. Basically we create an API from parameterized queries, and then generate interfaces and a caching layer on top of the API.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Why I&amp;#39;m interested in hearing from data engineers:&lt;/strong&gt; even though this tool is more for unlocking the value that data engineering creates (so, it comes in typically &amp;quot;after&amp;quot; data engineering, something in the ballpark of a BI tool), it&amp;#39;s the post-database &amp;quot;business tool&amp;quot; I wanted back when I was doing data eng. With an API-first approach, it&amp;#39;s a tool that enables data teams to respond to queries from their team and external users more efficiently. We have no dashboards either \u2014 we do have some simple charts, to avoid the need to leave Slight for simple things, but basically Slight&amp;#39;s goal is to be a layer on top of your data warehouse and get data elsewhere. &lt;/p&gt;\n\n&lt;p&gt;The basic goal is to unlock the full potential of your data warehouse for everyone. Things like:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Automating repetitive data requests&lt;/li&gt;\n&lt;li&gt;Reducing the load on data engineers and data teams when dealing with ad-hoc queries, especially if API-heavy (saw &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/vbd44r/the_api_i_created_as_an_intern_surprisingly_made/\"&gt;this example&lt;/a&gt; recently)&lt;/li&gt;\n&lt;li&gt;Making it easy for non-technical teams to access and analyze data without constant support (but without the failed dream of &amp;quot;self service&amp;quot;... sort of more like canonical curated queries) \u2014 e.g. we have our &lt;a href=\"https://www.slight.co/blog/google-sheets\"&gt;Google Sheets integration&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Caching for any use-case: write a query, decide how frequently you want it cached, and you&amp;#39;re done&lt;/li&gt;\n&lt;li&gt;Big one: Streamlining the process of sharing data/queries with external users/clients&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;A video demo: &lt;a href=\"https://www.youtube.com/watch?v=cRspkUKUgZQ\"&gt;https://www.youtube.com/watch?v=cRspkUKUgZQ&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re up for trying Slight, we only charge if you&amp;#39;re heavily serving external users with it, or only if internal usage is huge. So basically you can get really far with &lt;a href=\"https://www.slight.co/trial\"&gt;https://www.slight.co/trial&lt;/a&gt; for free. If you want a quicker way to play with Slight, &lt;a href=\"https://slight.run/\"&gt;https://slight.run/&lt;/a&gt; is our free public version (runs on BigQuery).&lt;/p&gt;\n\n&lt;p&gt;Any thoughts, opinions or suggestions are much appreciated.&lt;/p&gt;\n\n&lt;p&gt;Cheers,&lt;/p&gt;\n\n&lt;p&gt;Colman&lt;/p&gt;\n\n&lt;p&gt;(btw while I&amp;#39;ve seen a few posts along these lines, let me know if this is too much &amp;quot;self promotion)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12juze7", "is_robot_indexable": true, "report_reasons": null, "author": "smolcol", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12juze7/request_for_feedback_slight_streamlining_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12juze7/request_for_feedback_slight_streamlining_data/", "subreddit_subscribers": 98522, "created_utc": 1681325486.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently working on implementing a data orchestration tool. To begin with it will be a single node instance.\nI\u2019m confused on how Dagster stores assets. Are the assets stored in the local filesystem? If that\u2019s the case, won\u2019t it blow up with time.\nIs there a project available for a simple \nETL pipeline that runs on a schedule. Thanks!", "author_fullname": "t2_bcs9s7nw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dagster Resources", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12klkq3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681384984.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently working on implementing a data orchestration tool. To begin with it will be a single node instance.\nI\u2019m confused on how Dagster stores assets. Are the assets stored in the local filesystem? If that\u2019s the case, won\u2019t it blow up with time.\nIs there a project available for a simple \nETL pipeline that runs on a schedule. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12klkq3", "is_robot_indexable": true, "report_reasons": null, "author": "Mundane-Compote-2157", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12klkq3/dagster_resources/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12klkq3/dagster_resources/", "subreddit_subscribers": 98522, "created_utc": 1681384984.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_xf2t5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Understanding AWS Regions and Availability Zones: A Guide for Beginners", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_12kcsl5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/IBESTC58YPkLBVQYqOZjCipKmvwU1r35uBK0K5Rl2qs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681362451.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "luminousmen.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://luminousmen.com/post/understanding-aws-regions-and-availability-zones-a-guide-for-beginners", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Er_NQSh5ay3ijtMEO8kCcMP1m3VxwFolKRAe8OWQwxE.jpg?auto=webp&amp;v=enabled&amp;s=ecb9e0c85657f7d483e8c30594eb558fd5881d78", "width": 800, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/Er_NQSh5ay3ijtMEO8kCcMP1m3VxwFolKRAe8OWQwxE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3decc591fa73981368a746092e57d6ad9e274875", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/Er_NQSh5ay3ijtMEO8kCcMP1m3VxwFolKRAe8OWQwxE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9544e57e6dc5e74a63c7041d9260257fb8364ea2", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/Er_NQSh5ay3ijtMEO8kCcMP1m3VxwFolKRAe8OWQwxE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8271e3290637949d07b205c401b2c36d8c512c59", "width": 320, "height": 240}, {"url": "https://external-preview.redd.it/Er_NQSh5ay3ijtMEO8kCcMP1m3VxwFolKRAe8OWQwxE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2358a2f7225322213c2115c1136a2c4a2f089987", "width": 640, "height": 480}], "variants": {}, "id": "2-Tuv6RObVUGGib5vgYAIRrVVPwilSKhzbqf_NQskOk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12kcsl5", "is_robot_indexable": true, "report_reasons": null, "author": "luminoumen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12kcsl5/understanding_aws_regions_and_availability_zones/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://luminousmen.com/post/understanding-aws-regions-and-availability-zones-a-guide-for-beginners", "subreddit_subscribers": 98522, "created_utc": 1681362451.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently joined a digital bank's data engineering team(it has been close to 4 months) and i dont even have read access to the production data. Only a couple of people in my team have access to it. We are using big query as a data lake. \n\nThis has led to me being left out of any business use case requirements, any production issues and has decreased confidence in myself, playing second tier and catch up. \n\nI have discussed this with my manager and he told that since there are regulatory requirements only a handful of people can have access to prod data. \n\n\nMy question is there anything that we can do technically to improve data security to get around this requirement and if anyone is also facing the same issue as me and how to handle it", "author_fullname": "t2_esibz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "No access to prod data as DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12kcs0u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681362411.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently joined a digital bank&amp;#39;s data engineering team(it has been close to 4 months) and i dont even have read access to the production data. Only a couple of people in my team have access to it. We are using big query as a data lake. &lt;/p&gt;\n\n&lt;p&gt;This has led to me being left out of any business use case requirements, any production issues and has decreased confidence in myself, playing second tier and catch up. &lt;/p&gt;\n\n&lt;p&gt;I have discussed this with my manager and he told that since there are regulatory requirements only a handful of people can have access to prod data. &lt;/p&gt;\n\n&lt;p&gt;My question is there anything that we can do technically to improve data security to get around this requirement and if anyone is also facing the same issue as me and how to handle it&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12kcs0u", "is_robot_indexable": true, "report_reasons": null, "author": "ithellam_oru_pollapu", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12kcs0u/no_access_to_prod_data_as_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12kcs0u/no_access_to_prod_data_as_de/", "subreddit_subscribers": 98522, "created_utc": 1681362411.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Long story short: I am currently learning AWS and work at a company that uses S3, but there is so much abstraction embedded via internal packages that I don\u2019t really learn AWS at work at all. That being said, I recently realised that in my country 80-90% (and that is really not overestimating) job offers named Azure either exclusively or as preferred service, with AWS being the rest and GCP non-existent. \n\nSo my question is; given I passed CCP recently, should I keep on learning AWS and just focus on being good at one cloud provider - and then people hiring for Azure will trust me based on my Amazon expertise - or it actually matters to know particular provider more and I should turn to Azure? Personally I prefer AWS but this is no joke - in Belgium easily 80-90% of DE job offers list Azure. I\u2019m really stuck whether I should pursue AWS and just assume it will translate into being good Azure DE for recruiters, or I should pragmatically follow the job market. My feeling is if it can change in any direction, it\u2019s most likely only more Azure in future. Thanks!", "author_fullname": "t2_ihek8y8e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cloud learning in 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12k1wz7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681338558.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Long story short: I am currently learning AWS and work at a company that uses S3, but there is so much abstraction embedded via internal packages that I don\u2019t really learn AWS at work at all. That being said, I recently realised that in my country 80-90% (and that is really not overestimating) job offers named Azure either exclusively or as preferred service, with AWS being the rest and GCP non-existent. &lt;/p&gt;\n\n&lt;p&gt;So my question is; given I passed CCP recently, should I keep on learning AWS and just focus on being good at one cloud provider - and then people hiring for Azure will trust me based on my Amazon expertise - or it actually matters to know particular provider more and I should turn to Azure? Personally I prefer AWS but this is no joke - in Belgium easily 80-90% of DE job offers list Azure. I\u2019m really stuck whether I should pursue AWS and just assume it will translate into being good Azure DE for recruiters, or I should pragmatically follow the job market. My feeling is if it can change in any direction, it\u2019s most likely only more Azure in future. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12k1wz7", "is_robot_indexable": true, "report_reasons": null, "author": "absurdherowaw", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12k1wz7/cloud_learning_in_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12k1wz7/cloud_learning_in_2023/", "subreddit_subscribers": 98522, "created_utc": 1681338558.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want a SQL database and SQL developer in cloudera . How can I install it ..can't find any videos or step by step guide in it . Or should I install whole Hadoop ecosystem on Ubuntu ?", "author_fullname": "t2_167hj0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I install oracle database or any other SQL database in cloudera", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12jreax", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681316635.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want a SQL database and SQL developer in cloudera . How can I install it ..can&amp;#39;t find any videos or step by step guide in it . Or should I install whole Hadoop ecosystem on Ubuntu ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12jreax", "is_robot_indexable": true, "report_reasons": null, "author": "omkargurme616", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12jreax/how_can_i_install_oracle_database_or_any_other/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12jreax/how_can_i_install_oracle_database_or_any_other/", "subreddit_subscribers": 98522, "created_utc": 1681316635.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "While the \u201cmodern data stack\u201d marketing has made the higher execs believe that the ETL/ELT tools solve for all data ingestion problems, but in reality all the platforms offer only handful of connectors that they maintain themselves - rest is outsourced to community which might/might not be very active, depending on the data source. In such scenarios, how do you handle data pipelines?", "author_fullname": "t2_14gits", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Pipelines - how do you build data pipelines for sources not available in today\u2019s ELT tools (Fivetran, Talend, Airbyte)? Old fashioned scripts and YOLO?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12kppyf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681393467.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;While the \u201cmodern data stack\u201d marketing has made the higher execs believe that the ETL/ELT tools solve for all data ingestion problems, but in reality all the platforms offer only handful of connectors that they maintain themselves - rest is outsourced to community which might/might not be very active, depending on the data source. In such scenarios, how do you handle data pipelines?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12kppyf", "is_robot_indexable": true, "report_reasons": null, "author": "nonheuristic", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12kppyf/data_pipelines_how_do_you_build_data_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12kppyf/data_pipelines_how_do_you_build_data_pipelines/", "subreddit_subscribers": 98522, "created_utc": 1681393467.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work as a data lead in a rather large company, but the BI/data infrastructure here is rather outdated. We don't have a dedicated data engineer, and most data-related solutions are coming from my team. In regards to our data infrastructure we don't use any popular cloud solutions (Azure/AWS etc). Also by no means I'm experienced in data engineering.\n\nAt the moment we have developed variety of data related tools for business end-users, related to BI, ETLs, couple ML tools, and other various process automations.\n\n~50 tools across departments (~100 business users). Technologies mostly used are: SAP (data export using VBS), Power Query, Excel &amp; VBA, Power Bi, DAX, Power Automate, Python. \nMajority of these tools are run locally by data analysts, in development environment.  \n\nMy objective is to implement Production environment, and some web-like platform, where end-users would be able to use these tools.\n\nWhat are some practices/options I should start investigating? \nConsidering we are using MS products, first thing that came to my mind is to use MS power apps &amp; pages.", "author_fullname": "t2_13lmug", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Production environment &amp; platform for data tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12km4nl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681386184.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work as a data lead in a rather large company, but the BI/data infrastructure here is rather outdated. We don&amp;#39;t have a dedicated data engineer, and most data-related solutions are coming from my team. In regards to our data infrastructure we don&amp;#39;t use any popular cloud solutions (Azure/AWS etc). Also by no means I&amp;#39;m experienced in data engineering.&lt;/p&gt;\n\n&lt;p&gt;At the moment we have developed variety of data related tools for business end-users, related to BI, ETLs, couple ML tools, and other various process automations.&lt;/p&gt;\n\n&lt;p&gt;~50 tools across departments (~100 business users). Technologies mostly used are: SAP (data export using VBS), Power Query, Excel &amp;amp; VBA, Power Bi, DAX, Power Automate, Python. \nMajority of these tools are run locally by data analysts, in development environment.  &lt;/p&gt;\n\n&lt;p&gt;My objective is to implement Production environment, and some web-like platform, where end-users would be able to use these tools.&lt;/p&gt;\n\n&lt;p&gt;What are some practices/options I should start investigating? \nConsidering we are using MS products, first thing that came to my mind is to use MS power apps &amp;amp; pages.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12km4nl", "is_robot_indexable": true, "report_reasons": null, "author": "artemyp", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12km4nl/production_environment_platform_for_data_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12km4nl/production_environment_platform_for_data_tools/", "subreddit_subscribers": 98522, "created_utc": 1681386184.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am using Cloud Run and Scheduler to spin up a container containing DBT and am running \u2018dbt run\u2019 on start up via ENTRYPOINT. However, DBT cannot authenticate to BigQuery because it can\u2019t access the default auth credentials from the network of the VM that it is hosted on. \n\nDoes anyone have any ideas on how I can allow the container access to the Cloud Run VM network to get the credentials? \n\nThank you in advance for any suggestions!", "author_fullname": "t2_3fxv004y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get a Docker Container started using a Google Cloud Run job to get default auth creds from the VM?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ki3af", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681376385.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am using Cloud Run and Scheduler to spin up a container containing DBT and am running \u2018dbt run\u2019 on start up via ENTRYPOINT. However, DBT cannot authenticate to BigQuery because it can\u2019t access the default auth credentials from the network of the VM that it is hosted on. &lt;/p&gt;\n\n&lt;p&gt;Does anyone have any ideas on how I can allow the container access to the Cloud Run VM network to get the credentials? &lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for any suggestions!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12ki3af", "is_robot_indexable": true, "report_reasons": null, "author": "J1010H", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ki3af/how_to_get_a_docker_container_started_using_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ki3af/how_to_get_a_docker_container_started_using_a/", "subreddit_subscribers": 98522, "created_utc": 1681376385.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have explained the steps involved in preparing and scheduling the \"databricks certified associate developer for apache spark\" certification in this blog\n\n[https://blogs.sibyabin.tech/certification/databricks/associate-developer-spark/how-i-passed-databricks-certified-associate-developer-for-apachespark-certification/](https://blogs.sibyabin.tech/certification/databricks/associate-developer-spark/how-i-passed-databricks-certified-associate-developer-for-apachespark-certification/) \n\n[https:\\/\\/blogs.sibyabin.tech](https://preview.redd.it/urgin921mlta1.png?width=571&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=7ddb8432edc8947537d861583093a7d204b47e5c)\n\n\\#spark #databricks #certification #dataengineering #apachespark", "author_fullname": "t2_c4myu4hh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How I passed the Databricks Certified Associate Developer for Apache Spark 3.0", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"urgin921mlta1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 149, "x": 108, "u": "https://preview.redd.it/urgin921mlta1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=73814fb2cc39b18975e0718674392651ac80889e"}, {"y": 299, "x": 216, "u": "https://preview.redd.it/urgin921mlta1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=362f1611a51fdaa5a0377e082abf10d2196ec75f"}, {"y": 443, "x": 320, "u": "https://preview.redd.it/urgin921mlta1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=09b18dd97b04c383ce545a93ff93084f41a04b3d"}], "s": {"y": 792, "x": 571, "u": "https://preview.redd.it/urgin921mlta1.png?width=571&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=7ddb8432edc8947537d861583093a7d204b47e5c"}, "id": "urgin921mlta1"}}, "name": "t3_12kf5vq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/nFTHArZDcdZvPSQpEqrS0HevM8sMau5-jt0PSdZmN9g.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681368510.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have explained the steps involved in preparing and scheduling the &amp;quot;databricks certified associate developer for apache spark&amp;quot; certification in this blog&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://blogs.sibyabin.tech/certification/databricks/associate-developer-spark/how-i-passed-databricks-certified-associate-developer-for-apachespark-certification/\"&gt;https://blogs.sibyabin.tech/certification/databricks/associate-developer-spark/how-i-passed-databricks-certified-associate-developer-for-apachespark-certification/&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/urgin921mlta1.png?width=571&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=7ddb8432edc8947537d861583093a7d204b47e5c\"&gt;https://blogs.sibyabin.tech&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;#spark #databricks #certification #dataengineering #apachespark&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Senior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12kf5vq", "is_robot_indexable": true, "report_reasons": null, "author": "Satm2021", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/12kf5vq/how_i_passed_the_databricks_certified_associate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12kf5vq/how_i_passed_the_databricks_certified_associate/", "subreddit_subscribers": 98522, "created_utc": 1681368510.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Title might be a bit confusing so let me elaborate. At some point in my career, I'd like to leave the full-time lifestyle and dive into providing contract work and mentorship. The contract work would likely focus on early-stage startups on how to stand up their data infrastructure and hire their first data engineers to keep building it up (it's the aspect of data engineering I enjoy the most). The mentorship ideally would cover how to get into data engineering, how to prepare for interviews, how to go from beginner to senior, and that kind of stuff. I personally enjoy teaching and I've yet to figure out the preferred medium for this content (Youtube, short-term online bootcamp, 1:1 mentorship, etc.), but that's something for me to figure out later on.\n\nHas anyone transitioned into a similar lifestyle after full-time employment? I only have years of experience but no actual certifications (e.g., cloud practitioner certificate), do you find that certifications *actually* do help build credibility from a contractor's perspective? Did you find that starting a blog series and posting your thoughts and projects over time helped with gaining an audience?\n\nAny other thoughts and experiences would be greatly appreciated.\n\n*Noted that I assume this is something best done built up while working a full-time job and that it's not something I can switch to overnight.*", "author_fullname": "t2_hwg7lsz6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone here start their own agency for consulting, contracting and/or mentorship purposes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12kptil", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681393654.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title might be a bit confusing so let me elaborate. At some point in my career, I&amp;#39;d like to leave the full-time lifestyle and dive into providing contract work and mentorship. The contract work would likely focus on early-stage startups on how to stand up their data infrastructure and hire their first data engineers to keep building it up (it&amp;#39;s the aspect of data engineering I enjoy the most). The mentorship ideally would cover how to get into data engineering, how to prepare for interviews, how to go from beginner to senior, and that kind of stuff. I personally enjoy teaching and I&amp;#39;ve yet to figure out the preferred medium for this content (Youtube, short-term online bootcamp, 1:1 mentorship, etc.), but that&amp;#39;s something for me to figure out later on.&lt;/p&gt;\n\n&lt;p&gt;Has anyone transitioned into a similar lifestyle after full-time employment? I only have years of experience but no actual certifications (e.g., cloud practitioner certificate), do you find that certifications &lt;em&gt;actually&lt;/em&gt; do help build credibility from a contractor&amp;#39;s perspective? Did you find that starting a blog series and posting your thoughts and projects over time helped with gaining an audience?&lt;/p&gt;\n\n&lt;p&gt;Any other thoughts and experiences would be greatly appreciated.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Noted that I assume this is something best done built up while working a full-time job and that it&amp;#39;s not something I can switch to overnight.&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12kptil", "is_robot_indexable": true, "report_reasons": null, "author": "spicy_pierogi", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/12kptil/anyone_here_start_their_own_agency_for_consulting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12kptil/anyone_here_start_their_own_agency_for_consulting/", "subreddit_subscribers": 98522, "created_utc": 1681393654.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I just got my position as DataOps from previous job as DataEngineer.   \n\n\nI need some ideas from you about what are daily tasks, responsibilities of DataOps vs DataEngineer and where is the clear cut between the 2 ?  \n\n\nCheers", "author_fullname": "t2_93s65yqu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DataEngineering --&gt; DataOps", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12kpq9i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681393483.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I just got my position as DataOps from previous job as DataEngineer.   &lt;/p&gt;\n\n&lt;p&gt;I need some ideas from you about what are daily tasks, responsibilities of DataOps vs DataEngineer and where is the clear cut between the 2 ?  &lt;/p&gt;\n\n&lt;p&gt;Cheers&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12kpq9i", "is_robot_indexable": true, "report_reasons": null, "author": "Striking_Athlete5685", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12kpq9i/dataengineering_dataops/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12kpq9i/dataengineering_dataops/", "subreddit_subscribers": 98522, "created_utc": 1681393483.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I am looking for guidance on best practices to create cicd pipeline using databrick to run unit and integration test. I am inclined to use databrick connect however devops team is asking me not to use PAT token which will eliminate the option to use db connect however I am not still convinced with that suggestion as it makes us more dependent on databrick. Can someone help me or guide me here", "author_fullname": "t2_54dd8kh6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CICD pipeline using databrick connect", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12kom45", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681391288.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am looking for guidance on best practices to create cicd pipeline using databrick to run unit and integration test. I am inclined to use databrick connect however devops team is asking me not to use PAT token which will eliminate the option to use db connect however I am not still convinced with that suggestion as it makes us more dependent on databrick. Can someone help me or guide me here&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12kom45", "is_robot_indexable": true, "report_reasons": null, "author": "Aromatic_Afternoon31", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12kom45/cicd_pipeline_using_databrick_connect/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12kom45/cicd_pipeline_using_databrick_connect/", "subreddit_subscribers": 98522, "created_utc": 1681391288.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Based on [this](https://docs.databricks.com/structured-streaming/triggers.html#configuring-incremental-batch-processing), Databricks Runtime &gt;= 10.2 supports the \"availableNow\" trigger that can be used in order to perform batch processing in smaller distinct microbatches, whose size can be configured either via total number of files (maxFilesPerTrigger) or total size in bytes (maxBytesPerTrigger). For my purposes, I am currently using both with the following values:\n\n    maxFilesPerTrigger = 10000\n    maxBytesPerTrigger = \"10gb\"\n\nMy daily batch includes a number of files in the range of 15,000 to 20,000. Having set a pretty high \"maxBytesPerTrigger\" limit, at least in relation to my data, I'd expect that during each batch process, there would form two microbatches, the first one containing 10,000 files, and the second containing the rest. However, it is always the case that three microbatches are formed, withe the first one containing a pretty small number of files (about 500 or so), the second one containing 10,000 files, and the third one containing the rest, usually 5,000 to 10,000 files.\n\nDoes anyone have an idea as to why there are three microbatches instead of two, with the first one always containing a small number of files?", "author_fullname": "t2_q7l1xoqo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks Autoloader, Trigger.AvailableNow and batch size", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12kmnha", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681387302.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Based on &lt;a href=\"https://docs.databricks.com/structured-streaming/triggers.html#configuring-incremental-batch-processing\"&gt;this&lt;/a&gt;, Databricks Runtime &amp;gt;= 10.2 supports the &amp;quot;availableNow&amp;quot; trigger that can be used in order to perform batch processing in smaller distinct microbatches, whose size can be configured either via total number of files (maxFilesPerTrigger) or total size in bytes (maxBytesPerTrigger). For my purposes, I am currently using both with the following values:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;maxFilesPerTrigger = 10000\nmaxBytesPerTrigger = &amp;quot;10gb&amp;quot;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;My daily batch includes a number of files in the range of 15,000 to 20,000. Having set a pretty high &amp;quot;maxBytesPerTrigger&amp;quot; limit, at least in relation to my data, I&amp;#39;d expect that during each batch process, there would form two microbatches, the first one containing 10,000 files, and the second containing the rest. However, it is always the case that three microbatches are formed, withe the first one containing a pretty small number of files (about 500 or so), the second one containing 10,000 files, and the third one containing the rest, usually 5,000 to 10,000 files.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have an idea as to why there are three microbatches instead of two, with the first one always containing a small number of files?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/oXmGBjnOGbMLNj6ZyveOgQGOrgxxEmgC0EwkH-pffPo.jpg?auto=webp&amp;v=enabled&amp;s=15e7319434e1e103352a37e7fabfbd9456a168ef", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/oXmGBjnOGbMLNj6ZyveOgQGOrgxxEmgC0EwkH-pffPo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c1176850e76031e71bb122f9c353101bd7abe6bf", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/oXmGBjnOGbMLNj6ZyveOgQGOrgxxEmgC0EwkH-pffPo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=429d70d1e08de4ce9c49426ac4caa101f4c3e264", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/oXmGBjnOGbMLNj6ZyveOgQGOrgxxEmgC0EwkH-pffPo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=29cde5f1616959571c9b58b8c1c1900201c77f7e", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/oXmGBjnOGbMLNj6ZyveOgQGOrgxxEmgC0EwkH-pffPo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=83b58b543aa8701ba0a87a3198960697d53ff22c", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/oXmGBjnOGbMLNj6ZyveOgQGOrgxxEmgC0EwkH-pffPo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dfd2d8ab37cf854034f841dea22a655dc91a5f3b", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/oXmGBjnOGbMLNj6ZyveOgQGOrgxxEmgC0EwkH-pffPo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=47ceb6115a4ccc0e21696967727505ec48f78f37", "width": 1080, "height": 567}], "variants": {}, "id": "RDPFo3n-9ZSpTUT0k9sCNnHc7tSD0wBu2TyDFfITIDs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12kmnha", "is_robot_indexable": true, "report_reasons": null, "author": "WerdenWissen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12kmnha/databricks_autoloader_triggeravailablenow_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12kmnha/databricks_autoloader_triggeravailablenow_and/", "subreddit_subscribers": 98522, "created_utc": 1681387302.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What is your setup for loading and maintaining relational data in S3 data lake? How do you handle incremental updates? How do you extract the most recent data? Do you use versioning or custom ETL?", "author_fullname": "t2_w1tdhbrp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Loading and maintaining relational data in S3 lake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12kkxcl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681383530.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is your setup for loading and maintaining relational data in S3 data lake? How do you handle incremental updates? How do you extract the most recent data? Do you use versioning or custom ETL?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12kkxcl", "is_robot_indexable": true, "report_reasons": null, "author": "data_pie3", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12kkxcl/loading_and_maintaining_relational_data_in_s3_lake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12kkxcl/loading_and_maintaining_relational_data_in_s3_lake/", "subreddit_subscribers": 98522, "created_utc": 1681383530.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}